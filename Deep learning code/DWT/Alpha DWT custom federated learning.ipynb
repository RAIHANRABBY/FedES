{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["ZUR_QwblhNjJ"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Mbfw8uvdftFM","executionInfo":{"status":"ok","timestamp":1717527262812,"user_tz":-360,"elapsed":1768,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sb"]},{"cell_type":"code","source":["from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"INiFJfLjgOkx","executionInfo":{"status":"ok","timestamp":1717527262814,"user_tz":-360,"elapsed":6,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score, cross_val_predict"],"metadata":{"id":"lYo2Uq77gQSH","executionInfo":{"status":"ok","timestamp":1717527266014,"user_tz":-360,"elapsed":3206,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPool1D, Flatten, Dropout,LSTM"],"metadata":{"id":"g66575_xgVzz","executionInfo":{"status":"ok","timestamp":1717527269021,"user_tz":-360,"elapsed":3012,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"MOCNWlamfr3v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717527291882,"user_tz":-360,"elapsed":22869,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"outputId":"02cac8f5-7721-4b97-aa2b-6b9ddecf9143"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Raw_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/only data/raw_data.npz'\n","\n","Theta_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/DWT/Raw/Alpha_DWT.npz'\n","\n","\n","\n","# RAW = np.load(Raw_data, allow_pickle=True)  # Allow loading pickled object arrays\n","# X = RAW['X'].astype('float64')\n","# Y = RAW['Y'].astype('float64')\n","# group = RAW['Group'].astype('float64')"],"metadata":{"id":"iNy9eOGMf2qO","executionInfo":{"status":"ok","timestamp":1717527291883,"user_tz":-360,"elapsed":11,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["This is a good performing model"],"metadata":{"id":"PzeABzSyHgKg"}},{"cell_type":"markdown","source":["# CNN-LSTM"],"metadata":{"id":"6DhAYwXUSE9z"}},{"cell_type":"code","source":["%%capture\n","!pip install tensorflow_addons"],"metadata":{"id":"fxwgRS-C1tES","executionInfo":{"status":"ok","timestamp":1717527307761,"user_tz":-360,"elapsed":15887,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Alpha/CNN_LSTM/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Alpha/CNN_LSTM/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"-kPJ3TCp9vdp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717527307762,"user_tz":-360,"elapsed":10,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"outputId":"7f96e649-b730-430c-e663-e1b3a5d8bf8a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["global_model, metrics_df = federated_learning(Theta_data)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVURUnmYNNNg","outputId":"1da1824e-cf6c-48f3-a419-0f4011a953e7","executionInfo":{"status":"ok","timestamp":1717528603130,"user_tz":-360,"elapsed":1295376,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 1.7700 - accuracy: 0.5067"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 19s 64ms/step - loss: 1.7681 - accuracy: 0.5057 - val_loss: 1.7093 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.6586 - accuracy: 0.4984 - val_loss: 1.6053 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.5593 - accuracy: 0.4978 - val_loss: 1.5111 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4693 - accuracy: 0.5038 - val_loss: 1.4258 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.3878 - accuracy: 0.4879 - val_loss: 1.3484 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3140 - accuracy: 0.4906 - val_loss: 1.2784 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2474 - accuracy: 0.4968 - val_loss: 1.2154 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1874 - accuracy: 0.5040 - val_loss: 1.1587 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1335 - accuracy: 0.5038 - val_loss: 1.1078 - val_accuracy: 0.4849\n","Epoch 10/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0852 - accuracy: 0.5051 - val_loss: 1.0622 - val_accuracy: 0.4849\n","Epoch 11/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.0420 - accuracy: 0.5070 - val_loss: 1.0214 - val_accuracy: 0.4849\n","Epoch 12/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0035 - accuracy: 0.5032 - val_loss: 0.9852 - val_accuracy: 0.4849\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9689 - accuracy: 0.5143 - val_loss: 0.9527 - val_accuracy: 0.4849\n","Epoch 14/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.9380 - accuracy: 0.5358 - val_loss: 0.9235 - val_accuracy: 0.5032\n","Epoch 15/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.9109 - accuracy: 0.5180 - val_loss: 0.8989 - val_accuracy: 0.4849\n","Epoch 16/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8868 - accuracy: 0.5038 - val_loss: 0.8753 - val_accuracy: 0.4849\n","Epoch 17/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.8640 - accuracy: 0.5488 - val_loss: 0.8543 - val_accuracy: 0.5108\n","Epoch 18/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.8437 - accuracy: 0.5380 - val_loss: 0.8338 - val_accuracy: 0.5366\n","Epoch 19/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.8252 - accuracy: 0.5447 - val_loss: 0.8147 - val_accuracy: 0.5593\n","Epoch 20/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8085 - accuracy: 0.5579 - val_loss: 0.7995 - val_accuracy: 0.5528\n","Epoch 21/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.7911 - accuracy: 0.5630 - val_loss: 0.7832 - val_accuracy: 0.5711\n","Epoch 22/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7864 - accuracy: 0.5434 - val_loss: 0.7850 - val_accuracy: 0.5151\n","Epoch 23/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7809 - accuracy: 0.5251 - val_loss: 0.7752 - val_accuracy: 0.5668\n","Epoch 24/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.7670 - accuracy: 0.5668 - val_loss: 0.7564 - val_accuracy: 0.5894\n","Epoch 25/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7579 - accuracy: 0.5482 - val_loss: 0.7557 - val_accuracy: 0.5485\n","Epoch 26/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7457 - accuracy: 0.5744 - val_loss: 0.7710 - val_accuracy: 0.5226\n","Epoch 27/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7342 - accuracy: 0.5752 - val_loss: 0.7359 - val_accuracy: 0.5593\n","Epoch 28/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7338 - accuracy: 0.5585 - val_loss: 0.7271 - val_accuracy: 0.5722\n","Epoch 29/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7255 - accuracy: 0.5784 - val_loss: 0.7277 - val_accuracy: 0.5593\n","Epoch 30/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7219 - accuracy: 0.5795 - val_loss: 0.7167 - val_accuracy: 0.5873\n","Epoch 31/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7142 - accuracy: 0.5889 - val_loss: 0.7264 - val_accuracy: 0.5668\n","Epoch 32/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.7159 - accuracy: 0.5706 - val_loss: 0.7103 - val_accuracy: 0.6056\n","Epoch 33/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7080 - accuracy: 0.5816 - val_loss: 0.7120 - val_accuracy: 0.5873\n","Epoch 34/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7072 - accuracy: 0.5719 - val_loss: 0.7118 - val_accuracy: 0.5776\n","Epoch 35/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.7036 - accuracy: 0.5846 - val_loss: 0.7107 - val_accuracy: 0.5668\n","Epoch 36/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7007 - accuracy: 0.5846 - val_loss: 0.7041 - val_accuracy: 0.5776\n","Epoch 37/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6990 - accuracy: 0.5789 - val_loss: 0.6992 - val_accuracy: 0.5690\n","Epoch 38/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6966 - accuracy: 0.5859 - val_loss: 0.6953 - val_accuracy: 0.5884\n","Epoch 39/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6927 - accuracy: 0.5849 - val_loss: 0.7056 - val_accuracy: 0.5657\n","Epoch 40/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6892 - accuracy: 0.5900 - val_loss: 0.7079 - val_accuracy: 0.5647\n","Epoch 41/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6935 - accuracy: 0.5838 - val_loss: 0.6907 - val_accuracy: 0.5776\n","Epoch 42/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6896 - accuracy: 0.5900 - val_loss: 0.6897 - val_accuracy: 0.5959\n","Epoch 43/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6880 - accuracy: 0.5878 - val_loss: 0.6916 - val_accuracy: 0.5905\n","Epoch 44/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6812 - accuracy: 0.5994 - val_loss: 0.6899 - val_accuracy: 0.5744\n","Epoch 45/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6877 - accuracy: 0.5832 - val_loss: 0.6883 - val_accuracy: 0.5776\n","Epoch 46/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6893 - accuracy: 0.5854 - val_loss: 0.6944 - val_accuracy: 0.5603\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6849 - accuracy: 0.5865 - val_loss: 0.6874 - val_accuracy: 0.5916\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6778 - accuracy: 0.5991 - val_loss: 0.6838 - val_accuracy: 0.6013\n","Epoch 49/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6794 - accuracy: 0.5991 - val_loss: 0.6839 - val_accuracy: 0.5819\n","Epoch 50/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6782 - accuracy: 0.5973 - val_loss: 0.6843 - val_accuracy: 0.5744\n","Epoch 51/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6766 - accuracy: 0.5986 - val_loss: 0.6837 - val_accuracy: 0.5959\n","Epoch 52/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6817 - accuracy: 0.5921 - val_loss: 0.6944 - val_accuracy: 0.5636\n","Epoch 53/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6792 - accuracy: 0.5991 - val_loss: 0.6840 - val_accuracy: 0.5754\n","Epoch 54/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6780 - accuracy: 0.5881 - val_loss: 0.6890 - val_accuracy: 0.5571\n","Epoch 55/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6725 - accuracy: 0.6094 - val_loss: 0.6790 - val_accuracy: 0.5884\n","Epoch 56/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6737 - accuracy: 0.5989 - val_loss: 0.6794 - val_accuracy: 0.5981\n","Epoch 57/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6697 - accuracy: 0.6094 - val_loss: 0.6774 - val_accuracy: 0.5884\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6677 - accuracy: 0.5999 - val_loss: 0.6819 - val_accuracy: 0.5744\n","Epoch 59/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6723 - accuracy: 0.6016 - val_loss: 0.6780 - val_accuracy: 0.5916\n","Epoch 60/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6712 - accuracy: 0.6024 - val_loss: 0.6778 - val_accuracy: 0.5841\n","Epoch 61/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6658 - accuracy: 0.6086 - val_loss: 0.6823 - val_accuracy: 0.5884\n","Epoch 62/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6679 - accuracy: 0.6080 - val_loss: 0.7084 - val_accuracy: 0.5312\n","Epoch 63/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6676 - accuracy: 0.5999 - val_loss: 0.6972 - val_accuracy: 0.5722\n","Epoch 64/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6609 - accuracy: 0.6156 - val_loss: 0.6792 - val_accuracy: 0.5981\n","Epoch 65/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6656 - accuracy: 0.6099 - val_loss: 0.7032 - val_accuracy: 0.5700\n","Epoch 66/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6644 - accuracy: 0.6150 - val_loss: 0.6759 - val_accuracy: 0.5884\n","Epoch 67/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6569 - accuracy: 0.6215 - val_loss: 0.6863 - val_accuracy: 0.5894\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6640 - accuracy: 0.6140 - val_loss: 0.6992 - val_accuracy: 0.5636\n","Epoch 69/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6541 - accuracy: 0.6269 - val_loss: 0.6773 - val_accuracy: 0.5916\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6465 - accuracy: 0.6350 - val_loss: 0.6983 - val_accuracy: 0.5700\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6564 - accuracy: 0.6161 - val_loss: 0.6748 - val_accuracy: 0.6045\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6443 - accuracy: 0.6347 - val_loss: 0.6742 - val_accuracy: 0.5959\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6410 - accuracy: 0.6420 - val_loss: 0.6799 - val_accuracy: 0.5948\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6510 - accuracy: 0.6395 - val_loss: 0.6817 - val_accuracy: 0.5690\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6417 - accuracy: 0.6433 - val_loss: 0.6708 - val_accuracy: 0.6056\n","Epoch 76/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6306 - accuracy: 0.6514 - val_loss: 0.6897 - val_accuracy: 0.5948\n","Epoch 77/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6287 - accuracy: 0.6568 - val_loss: 0.6956 - val_accuracy: 0.5668\n","Epoch 78/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6320 - accuracy: 0.6484 - val_loss: 0.7053 - val_accuracy: 0.5873\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6258 - accuracy: 0.6519 - val_loss: 0.7089 - val_accuracy: 0.5539\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6240 - accuracy: 0.6522 - val_loss: 0.6775 - val_accuracy: 0.6013\n","Epoch 81/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6090 - accuracy: 0.6738 - val_loss: 0.7148 - val_accuracy: 0.5927\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5980 - accuracy: 0.6859 - val_loss: 0.7044 - val_accuracy: 0.5938\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5940 - accuracy: 0.6853 - val_loss: 0.7215 - val_accuracy: 0.5765\n","Epoch 84/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5862 - accuracy: 0.6991 - val_loss: 0.6995 - val_accuracy: 0.5905\n","Epoch 85/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5719 - accuracy: 0.7023 - val_loss: 0.7030 - val_accuracy: 0.5938\n","Epoch 86/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5783 - accuracy: 0.6932 - val_loss: 0.7616 - val_accuracy: 0.5819\n","Epoch 87/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5685 - accuracy: 0.7117 - val_loss: 0.7860 - val_accuracy: 0.5722\n","Epoch 88/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5664 - accuracy: 0.7064 - val_loss: 0.7380 - val_accuracy: 0.5754\n","Epoch 89/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5608 - accuracy: 0.7158 - val_loss: 0.7154 - val_accuracy: 0.5959\n","Epoch 90/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5201 - accuracy: 0.7457 - val_loss: 0.7825 - val_accuracy: 0.5733\n","Epoch 91/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5093 - accuracy: 0.7505 - val_loss: 0.7558 - val_accuracy: 0.5894\n","Epoch 92/100\n","29/29 [==============================] - 1s 52ms/step - loss: 0.5221 - accuracy: 0.7462 - val_loss: 0.7143 - val_accuracy: 0.6175\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5012 - accuracy: 0.7492 - val_loss: 0.7683 - val_accuracy: 0.6002\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4721 - accuracy: 0.7724 - val_loss: 0.8038 - val_accuracy: 0.5981\n","Epoch 95/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4483 - accuracy: 0.7831 - val_loss: 0.8019 - val_accuracy: 0.6013\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4233 - accuracy: 0.8031 - val_loss: 1.0274 - val_accuracy: 0.5690\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4655 - accuracy: 0.7724 - val_loss: 0.8935 - val_accuracy: 0.5841\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4175 - accuracy: 0.8041 - val_loss: 0.8305 - val_accuracy: 0.5970\n","Epoch 99/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3969 - accuracy: 0.8227 - val_loss: 1.0601 - val_accuracy: 0.5830\n","Epoch 100/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3535 - accuracy: 0.8416 - val_loss: 1.0767 - val_accuracy: 0.5668\n","{'loss': [1.7681357860565186, 1.6585708856582642, 1.5592560768127441, 1.4692926406860352, 1.3878284692764282, 1.3139840364456177, 1.2473998069763184, 1.1873763799667358, 1.1335444450378418, 1.0852046012878418, 1.042001724243164, 1.0035197734832764, 0.9689255356788635, 0.9379926919937134, 0.9109258055686951, 0.8868101835250854, 0.8640299439430237, 0.8436920642852783, 0.8252130150794983, 0.8084506988525391, 0.7911477088928223, 0.7864454984664917, 0.7808762788772583, 0.7669932842254639, 0.7578938007354736, 0.7457318305969238, 0.734168291091919, 0.7338314056396484, 0.725518524646759, 0.7219398617744446, 0.7141507863998413, 0.7159305810928345, 0.7079665660858154, 0.707243025302887, 0.7035869359970093, 0.7007296085357666, 0.6989646553993225, 0.696550190448761, 0.6926862597465515, 0.6891521215438843, 0.6934990286827087, 0.6895993947982788, 0.6879990100860596, 0.6811985969543457, 0.6877453327178955, 0.6893196105957031, 0.6848680973052979, 0.6778339147567749, 0.679364800453186, 0.6782047748565674, 0.6766006350517273, 0.6817315816879272, 0.6791830658912659, 0.6780482530593872, 0.6724972128868103, 0.6736837029457092, 0.6697152853012085, 0.6677268743515015, 0.672336757183075, 0.6711503267288208, 0.6658044457435608, 0.6678795218467712, 0.6676027774810791, 0.66093510389328, 0.6656004786491394, 0.6643515229225159, 0.6568615436553955, 0.6639649868011475, 0.654121458530426, 0.6464794874191284, 0.6563929915428162, 0.6442885994911194, 0.6409909725189209, 0.6510275602340698, 0.6416573524475098, 0.6305518746376038, 0.6287074685096741, 0.6319969892501831, 0.6258093118667603, 0.6240232586860657, 0.6089596152305603, 0.5980212092399597, 0.5939679145812988, 0.5861735343933105, 0.5718744993209839, 0.5782933235168457, 0.5685276985168457, 0.5664201378822327, 0.5608041882514954, 0.5201194882392883, 0.5092952847480774, 0.5221389532089233, 0.5012418031692505, 0.4721381664276123, 0.448273628950119, 0.4233182966709137, 0.4654625952243805, 0.41746407747268677, 0.39688369631767273, 0.35347554087638855], 'accuracy': [0.5056573152542114, 0.49838361144065857, 0.4978448152542114, 0.5037715435028076, 0.48787716031074524, 0.49057111144065857, 0.4967672526836395, 0.5040409564971924, 0.5037715435028076, 0.5051185488700867, 0.5070043206214905, 0.5032327771186829, 0.514277994632721, 0.5358297228813171, 0.5180495977401733, 0.5037715435028076, 0.5487607717514038, 0.5379849076271057, 0.5447198152542114, 0.5579202771186829, 0.5630387663841248, 0.5433728694915771, 0.525053858757019, 0.5668103694915771, 0.548222005367279, 0.5743534564971924, 0.5751616358757019, 0.5584590435028076, 0.5783944129943848, 0.579472005367279, 0.5889008641242981, 0.5705819129943848, 0.5816271305084229, 0.571928858757019, 0.584590494632721, 0.584590494632721, 0.5789331793785095, 0.5859375, 0.5848599076271057, 0.5899784564971924, 0.5837823152542114, 0.5899784564971924, 0.5878232717514038, 0.5994073152542114, 0.5832435488700867, 0.5853987336158752, 0.5864762663841248, 0.5991379022598267, 0.5991379022598267, 0.5972521305084229, 0.5985991358757019, 0.592133641242981, 0.5991379022598267, 0.5880926847457886, 0.609375, 0.5988685488700867, 0.609375, 0.599946141242981, 0.6015625, 0.6023706793785095, 0.6085668206214905, 0.608027994632721, 0.599946141242981, 0.615571141242981, 0.6099137663841248, 0.6150323152542114, 0.6214978694915771, 0.6139547228813171, 0.6268857717514038, 0.6349676847457886, 0.6161099076271057, 0.6346982717514038, 0.641972005367279, 0.6395474076271057, 0.6433189511299133, 0.6514008641242981, 0.6567887663841248, 0.6484375, 0.6519396305084229, 0.6522090435028076, 0.6737607717514038, 0.685883641242981, 0.6853448152542114, 0.6990840435028076, 0.7023168206214905, 0.6931573152542114, 0.7117456793785095, 0.7063577771186829, 0.7157866358757019, 0.7456896305084229, 0.7505387663841248, 0.7462284564971924, 0.7491918206214905, 0.7723599076271057, 0.7831357717514038, 0.803071141242981, 0.7723599076271057, 0.8041487336158752, 0.8227370977401733, 0.8415948152542114], 'val_loss': [1.7093110084533691, 1.6053227186203003, 1.5110968351364136, 1.4257992506027222, 1.3483526706695557, 1.2783901691436768, 1.2153847217559814, 1.1586605310440063, 1.1078360080718994, 1.0621849298477173, 1.0214256048202515, 0.9851688742637634, 0.95268315076828, 0.9235377907752991, 0.8988737463951111, 0.87534099817276, 0.8542703986167908, 0.8337549567222595, 0.8146606087684631, 0.7994737029075623, 0.7831724286079407, 0.7850158214569092, 0.7752324938774109, 0.756409764289856, 0.7556955218315125, 0.7709820866584778, 0.7358908653259277, 0.7271309494972229, 0.7276935577392578, 0.7166875600814819, 0.7263633012771606, 0.7103197574615479, 0.7120340466499329, 0.7118113040924072, 0.7107027173042297, 0.7040831446647644, 0.6992361545562744, 0.6953091025352478, 0.7056422829627991, 0.7079049944877625, 0.6907089948654175, 0.6896536350250244, 0.6915709376335144, 0.6898906826972961, 0.6883468627929688, 0.6943995356559753, 0.6874381899833679, 0.6838405132293701, 0.6839357614517212, 0.6842741966247559, 0.6836724281311035, 0.6944416165351868, 0.6839719414710999, 0.6890315413475037, 0.679033100605011, 0.6793887615203857, 0.6774339079856873, 0.6818661093711853, 0.6780358552932739, 0.6778007745742798, 0.682327151298523, 0.7084212303161621, 0.6972069144248962, 0.6791954040527344, 0.7032054662704468, 0.6759079694747925, 0.6863096952438354, 0.6991665959358215, 0.6772621273994446, 0.6983152031898499, 0.6747909784317017, 0.674217700958252, 0.6799051761627197, 0.6816728711128235, 0.6708311438560486, 0.689721941947937, 0.6956343650817871, 0.7053042054176331, 0.7088968753814697, 0.6775356531143188, 0.7148478031158447, 0.70439213514328, 0.7215136289596558, 0.6994579434394836, 0.7030091285705566, 0.7615700364112854, 0.7859999537467957, 0.7380079030990601, 0.7153820395469666, 0.7825137972831726, 0.7557867169380188, 0.7142662405967712, 0.7683472037315369, 0.8037970066070557, 0.8019281625747681, 1.0274426937103271, 0.893515408039093, 0.8304760456085205, 1.0601096153259277, 1.0766624212265015], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.5032327771186829, 0.48491379618644714, 0.48491379618644714, 0.5107758641242981, 0.5366379022598267, 0.5592672228813171, 0.5528017282485962, 0.5711206793785095, 0.5150862336158752, 0.5668103694915771, 0.5894396305084229, 0.548491358757019, 0.5226293206214905, 0.5592672228813171, 0.5721982717514038, 0.5592672228813171, 0.587284505367279, 0.5668103694915771, 0.6056034564971924, 0.587284505367279, 0.5775862336158752, 0.5668103694915771, 0.5775862336158752, 0.568965494632721, 0.5883620977401733, 0.5657327771186829, 0.5646551847457886, 0.5775862336158752, 0.5959051847457886, 0.5905172228813171, 0.5743534564971924, 0.5775862336158752, 0.5603448152542114, 0.5915948152542114, 0.6012930870056152, 0.5818965435028076, 0.5743534564971924, 0.5959051847457886, 0.5635775923728943, 0.5754310488700867, 0.5571120977401733, 0.5883620977401733, 0.5980603694915771, 0.5883620977401733, 0.5743534564971924, 0.5915948152542114, 0.5840517282485962, 0.5883620977401733, 0.53125, 0.5721982717514038, 0.5980603694915771, 0.5700430870056152, 0.5883620977401733, 0.5894396305084229, 0.5635775923728943, 0.5915948152542114, 0.5700430870056152, 0.6045258641242981, 0.5959051847457886, 0.5948275923728943, 0.568965494632721, 0.6056034564971924, 0.5948275923728943, 0.5668103694915771, 0.587284505367279, 0.5538793206214905, 0.6012930870056152, 0.5926724076271057, 0.59375, 0.576508641242981, 0.5905172228813171, 0.59375, 0.5818965435028076, 0.5721982717514038, 0.5754310488700867, 0.5959051847457886, 0.5732758641242981, 0.5894396305084229, 0.6174569129943848, 0.600215494632721, 0.5980603694915771, 0.6012930870056152, 0.568965494632721, 0.5840517282485962, 0.5969827771186829, 0.5829741358757019, 0.5668103694915771]}\n","38/38 [==============================] - 1s 11ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 1.7702 - accuracy: 0.4969"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 9s 100ms/step - loss: 1.7702 - accuracy: 0.4969 - val_loss: 1.7109 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.6606 - accuracy: 0.4952 - val_loss: 1.6066 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.5611 - accuracy: 0.5017 - val_loss: 1.5124 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.4713 - accuracy: 0.5006 - val_loss: 1.4273 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.3904 - accuracy: 0.4892 - val_loss: 1.3506 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.3173 - accuracy: 0.5028 - val_loss: 1.2817 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 35ms/step - loss: 1.2516 - accuracy: 0.5011 - val_loss: 1.2194 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 42ms/step - loss: 1.1923 - accuracy: 0.5011 - val_loss: 1.1634 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 1s 31ms/step - loss: 1.1390 - accuracy: 0.5011 - val_loss: 1.1130 - val_accuracy: 0.4955\n","Epoch 10/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0910 - accuracy: 0.5008 - val_loss: 1.0677 - val_accuracy: 0.4955\n","Epoch 11/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0480 - accuracy: 0.5133 - val_loss: 1.0272 - val_accuracy: 0.4955\n","Epoch 12/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0096 - accuracy: 0.5011 - val_loss: 0.9909 - val_accuracy: 0.4955\n","Epoch 13/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9751 - accuracy: 0.5011 - val_loss: 0.9584 - val_accuracy: 0.4955\n","Epoch 14/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9442 - accuracy: 0.5184 - val_loss: 0.9293 - val_accuracy: 0.4955\n","Epoch 15/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.9167 - accuracy: 0.4884 - val_loss: 0.9034 - val_accuracy: 0.5090\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8922 - accuracy: 0.5079 - val_loss: 0.8802 - val_accuracy: 0.4955\n","Epoch 17/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8702 - accuracy: 0.5062 - val_loss: 0.8596 - val_accuracy: 0.4955\n","Epoch 18/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.8506 - accuracy: 0.5181 - val_loss: 0.8412 - val_accuracy: 0.5769\n","Epoch 19/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8331 - accuracy: 0.5170 - val_loss: 0.8248 - val_accuracy: 0.5181\n","Epoch 20/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.8175 - accuracy: 0.5286 - val_loss: 0.8099 - val_accuracy: 0.5803\n","Epoch 21/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8042 - accuracy: 0.5198 - val_loss: 0.7978 - val_accuracy: 0.5045\n","Epoch 22/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7924 - accuracy: 0.4989 - val_loss: 0.7863 - val_accuracy: 0.5045\n","Epoch 23/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7811 - accuracy: 0.5153 - val_loss: 0.7763 - val_accuracy: 0.4966\n","Epoch 24/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7717 - accuracy: 0.5034 - val_loss: 0.7664 - val_accuracy: 0.5385\n","Epoch 25/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7611 - accuracy: 0.5526 - val_loss: 0.7529 - val_accuracy: 0.5667\n","Epoch 26/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7580 - accuracy: 0.5102 - val_loss: 0.7528 - val_accuracy: 0.5045\n","Epoch 27/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7493 - accuracy: 0.5003 - val_loss: 0.7451 - val_accuracy: 0.5351\n","Epoch 28/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7406 - accuracy: 0.5557 - val_loss: 0.7399 - val_accuracy: 0.5294\n","Epoch 29/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7364 - accuracy: 0.5433 - val_loss: 0.7369 - val_accuracy: 0.4955\n","Epoch 30/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7320 - accuracy: 0.5337 - val_loss: 0.7287 - val_accuracy: 0.5351\n","Epoch 31/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7262 - accuracy: 0.5501 - val_loss: 0.7302 - val_accuracy: 0.5102\n","Epoch 32/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7205 - accuracy: 0.5518 - val_loss: 0.7363 - val_accuracy: 0.5023\n","Epoch 33/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7196 - accuracy: 0.5348 - val_loss: 0.7240 - val_accuracy: 0.5068\n","Epoch 34/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7120 - accuracy: 0.5611 - val_loss: 0.7135 - val_accuracy: 0.5701\n","Epoch 35/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7034 - accuracy: 0.5671 - val_loss: 0.7094 - val_accuracy: 0.5622\n","Epoch 36/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7102 - accuracy: 0.5456 - val_loss: 0.7097 - val_accuracy: 0.5362\n","Epoch 37/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7025 - accuracy: 0.5690 - val_loss: 0.7093 - val_accuracy: 0.5747\n","Epoch 38/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6981 - accuracy: 0.5724 - val_loss: 0.7086 - val_accuracy: 0.5362\n","Epoch 39/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6955 - accuracy: 0.5806 - val_loss: 0.7394 - val_accuracy: 0.5090\n","Epoch 40/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6967 - accuracy: 0.5747 - val_loss: 0.6978 - val_accuracy: 0.5600\n","Epoch 41/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6886 - accuracy: 0.5880 - val_loss: 0.6944 - val_accuracy: 0.5792\n","Epoch 42/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6929 - accuracy: 0.5699 - val_loss: 0.7026 - val_accuracy: 0.5690\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6899 - accuracy: 0.5778 - val_loss: 0.7070 - val_accuracy: 0.5351\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6868 - accuracy: 0.5917 - val_loss: 0.6935 - val_accuracy: 0.5724\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6847 - accuracy: 0.5872 - val_loss: 0.6935 - val_accuracy: 0.5781\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6848 - accuracy: 0.5880 - val_loss: 0.7075 - val_accuracy: 0.5136\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6897 - accuracy: 0.5750 - val_loss: 0.6895 - val_accuracy: 0.5781\n","Epoch 48/100\n","28/28 [==============================] - 1s 51ms/step - loss: 0.6822 - accuracy: 0.5894 - val_loss: 0.6900 - val_accuracy: 0.5826\n","Epoch 49/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6836 - accuracy: 0.5846 - val_loss: 0.7258 - val_accuracy: 0.5011\n","Epoch 50/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.6807 - accuracy: 0.5872 - val_loss: 0.6913 - val_accuracy: 0.5837\n","Epoch 51/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6820 - accuracy: 0.5863 - val_loss: 0.6880 - val_accuracy: 0.5837\n","Epoch 52/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6832 - accuracy: 0.5758 - val_loss: 0.6902 - val_accuracy: 0.5656\n","Epoch 53/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6800 - accuracy: 0.5874 - val_loss: 0.6868 - val_accuracy: 0.5792\n","Epoch 54/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6756 - accuracy: 0.5988 - val_loss: 0.6882 - val_accuracy: 0.5735\n","Epoch 55/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6724 - accuracy: 0.6041 - val_loss: 0.6935 - val_accuracy: 0.5667\n","Epoch 56/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6759 - accuracy: 0.5973 - val_loss: 0.6927 - val_accuracy: 0.5622\n","Epoch 57/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6730 - accuracy: 0.5985 - val_loss: 0.6870 - val_accuracy: 0.5747\n","Epoch 58/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6710 - accuracy: 0.6061 - val_loss: 0.6904 - val_accuracy: 0.5735\n","Epoch 59/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6739 - accuracy: 0.5968 - val_loss: 0.6888 - val_accuracy: 0.5724\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6808 - accuracy: 0.5784 - val_loss: 0.6948 - val_accuracy: 0.5385\n","Epoch 61/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6728 - accuracy: 0.6030 - val_loss: 0.6860 - val_accuracy: 0.5667\n","Epoch 62/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6686 - accuracy: 0.6041 - val_loss: 0.6970 - val_accuracy: 0.5735\n","Epoch 63/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6673 - accuracy: 0.6089 - val_loss: 0.6899 - val_accuracy: 0.5713\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6673 - accuracy: 0.6109 - val_loss: 0.6871 - val_accuracy: 0.5690\n","Epoch 65/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6670 - accuracy: 0.6064 - val_loss: 0.6874 - val_accuracy: 0.5701\n","Epoch 66/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6634 - accuracy: 0.6123 - val_loss: 0.6866 - val_accuracy: 0.5781\n","Epoch 67/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6721 - accuracy: 0.5965 - val_loss: 0.6844 - val_accuracy: 0.5769\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6656 - accuracy: 0.6044 - val_loss: 0.6890 - val_accuracy: 0.5600\n","Epoch 69/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6616 - accuracy: 0.6149 - val_loss: 0.6893 - val_accuracy: 0.5758\n","Epoch 70/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6573 - accuracy: 0.6174 - val_loss: 0.6923 - val_accuracy: 0.5826\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6615 - accuracy: 0.6095 - val_loss: 0.6936 - val_accuracy: 0.5781\n","Epoch 72/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6554 - accuracy: 0.6180 - val_loss: 0.6920 - val_accuracy: 0.5814\n","Epoch 73/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6570 - accuracy: 0.6225 - val_loss: 0.6916 - val_accuracy: 0.5464\n","Epoch 74/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6609 - accuracy: 0.6121 - val_loss: 0.6845 - val_accuracy: 0.5837\n","Epoch 75/100\n","28/28 [==============================] - 1s 53ms/step - loss: 0.6531 - accuracy: 0.6157 - val_loss: 0.6816 - val_accuracy: 0.5848\n","Epoch 76/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6539 - accuracy: 0.6200 - val_loss: 0.6920 - val_accuracy: 0.5543\n","Epoch 77/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6526 - accuracy: 0.6254 - val_loss: 0.6829 - val_accuracy: 0.5860\n","Epoch 78/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6454 - accuracy: 0.6338 - val_loss: 0.6786 - val_accuracy: 0.5939\n","Epoch 79/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6393 - accuracy: 0.6378 - val_loss: 0.6891 - val_accuracy: 0.5826\n","Epoch 80/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6579 - accuracy: 0.6081 - val_loss: 0.6883 - val_accuracy: 0.5690\n","Epoch 81/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6325 - accuracy: 0.6432 - val_loss: 0.6866 - val_accuracy: 0.5928\n","Epoch 82/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6377 - accuracy: 0.6420 - val_loss: 0.6831 - val_accuracy: 0.5747\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6297 - accuracy: 0.6610 - val_loss: 0.6832 - val_accuracy: 0.5792\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6295 - accuracy: 0.6480 - val_loss: 0.7074 - val_accuracy: 0.5441\n","Epoch 85/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6301 - accuracy: 0.6477 - val_loss: 0.7076 - val_accuracy: 0.5882\n","Epoch 86/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6033 - accuracy: 0.6732 - val_loss: 0.7082 - val_accuracy: 0.5769\n","Epoch 87/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6192 - accuracy: 0.6562 - val_loss: 0.7331 - val_accuracy: 0.5769\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6005 - accuracy: 0.6859 - val_loss: 0.7355 - val_accuracy: 0.5837\n","Epoch 89/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6042 - accuracy: 0.6703 - val_loss: 0.6970 - val_accuracy: 0.5950\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5930 - accuracy: 0.6786 - val_loss: 0.7051 - val_accuracy: 0.5792\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5921 - accuracy: 0.6870 - val_loss: 0.8721 - val_accuracy: 0.5724\n","Epoch 92/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6138 - accuracy: 0.6553 - val_loss: 0.6942 - val_accuracy: 0.5894\n","Epoch 93/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5771 - accuracy: 0.6972 - val_loss: 0.7385 - val_accuracy: 0.5543\n","Epoch 94/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5958 - accuracy: 0.6791 - val_loss: 0.7141 - val_accuracy: 0.5814\n","Epoch 95/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5679 - accuracy: 0.7068 - val_loss: 0.7684 - val_accuracy: 0.5826\n","Epoch 96/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5708 - accuracy: 0.7071 - val_loss: 0.7310 - val_accuracy: 0.5758\n","Epoch 97/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5399 - accuracy: 0.7286 - val_loss: 0.7752 - val_accuracy: 0.5701\n","Epoch 98/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5480 - accuracy: 0.7235 - val_loss: 0.7637 - val_accuracy: 0.5724\n","Epoch 99/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.5329 - accuracy: 0.7354 - val_loss: 0.7352 - val_accuracy: 0.5724\n","Epoch 100/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5504 - accuracy: 0.7179 - val_loss: 0.7799 - val_accuracy: 0.5758\n","{'loss': [1.7701802253723145, 1.6606333255767822, 1.5610922574996948, 1.4713051319122314, 1.3904025554656982, 1.3173222541809082, 1.251610279083252, 1.192304253578186, 1.1389820575714111, 1.091049313545227, 1.0480412244796753, 1.009561538696289, 0.9750619530677795, 0.9442188143730164, 0.916723370552063, 0.892164409160614, 0.8701748847961426, 0.8506087064743042, 0.8331490159034729, 0.8174706101417542, 0.8041747212409973, 0.7923659086227417, 0.7811470627784729, 0.7716597318649292, 0.761052668094635, 0.7579607367515564, 0.7493060827255249, 0.7405681610107422, 0.7364391684532166, 0.7320332527160645, 0.7261791825294495, 0.7205250263214111, 0.7195846438407898, 0.7120282649993896, 0.7034093737602234, 0.7102449536323547, 0.7025395035743713, 0.6981117725372314, 0.6954838037490845, 0.6966893076896667, 0.6885721683502197, 0.6928638219833374, 0.6898794174194336, 0.6867586374282837, 0.6847383379936218, 0.6848049163818359, 0.689668595790863, 0.6822177767753601, 0.6835972666740417, 0.6807307004928589, 0.6819665431976318, 0.6831590533256531, 0.6799795031547546, 0.6755552887916565, 0.6724094152450562, 0.6759163737297058, 0.6730054020881653, 0.6710069179534912, 0.6738528609275818, 0.680753231048584, 0.6727516651153564, 0.6685989499092102, 0.667319118976593, 0.6672749519348145, 0.6669633388519287, 0.663375973701477, 0.6720829010009766, 0.6656299829483032, 0.6616361737251282, 0.6572597622871399, 0.6615184545516968, 0.6554394960403442, 0.6570116281509399, 0.6608666181564331, 0.6531429290771484, 0.6538907885551453, 0.6526408791542053, 0.6454175114631653, 0.6392523050308228, 0.6579274535179138, 0.6324677467346191, 0.6377497315406799, 0.6296619772911072, 0.6294924020767212, 0.630073070526123, 0.6032606959342957, 0.6191759705543518, 0.6004751324653625, 0.6041703820228577, 0.5929573774337769, 0.5920976400375366, 0.6137680411338806, 0.5771400928497314, 0.5957686305046082, 0.5678558945655823, 0.5708495378494263, 0.5399457812309265, 0.5479669570922852, 0.53290855884552, 0.5503512620925903], 'accuracy': [0.4968873858451843, 0.4951895773410797, 0.5016977787017822, 0.5005659461021423, 0.48924732208251953, 0.5028296709060669, 0.5011318325996399, 0.5011318325996399, 0.5011318325996399, 0.5008488893508911, 0.5132994055747986, 0.5011318325996399, 0.5011318325996399, 0.5183927416801453, 0.48839840292930603, 0.5079230070114136, 0.5062252283096313, 0.5181097984313965, 0.5169779062271118, 0.5285795331001282, 0.5198075771331787, 0.4988681375980377, 0.5152801275253296, 0.5033955574035645, 0.5526315569877625, 0.5101867318153381, 0.5002829432487488, 0.5557441711425781, 0.5432937145233154, 0.5336728692054749, 0.5500848889350891, 0.5517826676368713, 0.5348047614097595, 0.5611205697059631, 0.5670627951622009, 0.54555743932724, 0.5690435767173767, 0.5724391341209412, 0.5806451439857483, 0.5747028589248657, 0.5880022644996643, 0.5698924660682678, 0.5778155326843262, 0.5916808247566223, 0.5871533751487732, 0.5880022644996643, 0.5749858617782593, 0.5894170999526978, 0.5846067070960999, 0.5871533751487732, 0.5863044857978821, 0.5758347511291504, 0.587436318397522, 0.5987549424171448, 0.604131281375885, 0.5973401069641113, 0.598471999168396, 0.6061120629310608, 0.5967742204666138, 0.5783814191818237, 0.6029994487762451, 0.604131281375885, 0.6089417338371277, 0.6109224557876587, 0.6063950061798096, 0.6123372912406921, 0.5964912176132202, 0.6044142842292786, 0.6148839592933655, 0.6174306869506836, 0.6095076203346252, 0.6179966330528259, 0.6225240230560303, 0.6120543479919434, 0.6157329082489014, 0.6199773550033569, 0.6253536939620972, 0.6338426470756531, 0.6378042101860046, 0.6080927848815918, 0.6431805491447449, 0.6420486569404602, 0.6610073447227478, 0.6479909420013428, 0.647707998752594, 0.6731748580932617, 0.6561969518661499, 0.685908317565918, 0.6703452467918396, 0.678551197052002, 0.6870402097702026, 0.6553480625152588, 0.6972269415855408, 0.6791171431541443, 0.7068477869033813, 0.7071307301521301, 0.7286360859870911, 0.7235427498817444, 0.7354272603988647, 0.7178834080696106], 'val_loss': [1.7108955383300781, 1.6065753698349, 1.5123909711837769, 1.4272624254226685, 1.350643515586853, 1.281659722328186, 1.219437837600708, 1.163411259651184, 1.1130096912384033, 1.0677440166473389, 1.0271917581558228, 0.9908639788627625, 0.9583547711372375, 0.9292897582054138, 0.9033516049385071, 0.8802379965782166, 0.8596268892288208, 0.8412441611289978, 0.8248195052146912, 0.8099358081817627, 0.7978250980377197, 0.7863434553146362, 0.7763416171073914, 0.7664455771446228, 0.7528585195541382, 0.7527577877044678, 0.7451284527778625, 0.7398917078971863, 0.7369363903999329, 0.728705644607544, 0.7301673293113708, 0.7362608909606934, 0.724005401134491, 0.7135166525840759, 0.7094319462776184, 0.7096992135047913, 0.7093124985694885, 0.7086334824562073, 0.7394269704818726, 0.6977688670158386, 0.6943944096565247, 0.7025935649871826, 0.7069917321205139, 0.6935112476348877, 0.6935043931007385, 0.7074882984161377, 0.6895421743392944, 0.6899635195732117, 0.7257695198059082, 0.6912646293640137, 0.6880239844322205, 0.690244734287262, 0.6867728233337402, 0.6881929039955139, 0.6934667825698853, 0.6927119493484497, 0.6870269179344177, 0.6903511881828308, 0.6887975931167603, 0.6947987675666809, 0.6860412359237671, 0.696998119354248, 0.6899382472038269, 0.6871077418327332, 0.6874240636825562, 0.6866300702095032, 0.6843920350074768, 0.6890282034873962, 0.6892666816711426, 0.6923162341117859, 0.6936187148094177, 0.6919710040092468, 0.691597580909729, 0.6845344305038452, 0.6816310882568359, 0.6919955015182495, 0.6828980445861816, 0.6785726547241211, 0.6890691518783569, 0.6882699728012085, 0.686589241027832, 0.6831147074699402, 0.6832179427146912, 0.7074128985404968, 0.707609236240387, 0.7082335948944092, 0.733073353767395, 0.7354859113693237, 0.6969621181488037, 0.7050589323043823, 0.8720850944519043, 0.6941627264022827, 0.7385401725769043, 0.7140527963638306, 0.7684199810028076, 0.731032133102417, 0.7751691937446594, 0.7637063264846802, 0.735158383846283, 0.7798725366592407], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.5090497732162476, 0.4954751133918762, 0.4954751133918762, 0.5769230723381042, 0.5180995464324951, 0.5803167223930359, 0.5045248866081238, 0.5045248866081238, 0.49660632014274597, 0.5384615659713745, 0.5667420625686646, 0.5045248866081238, 0.5350678563117981, 0.529411792755127, 0.4954751133918762, 0.5350678563117981, 0.5101810097694397, 0.5022624731063843, 0.5067873597145081, 0.570135772228241, 0.5622171759605408, 0.5361990928649902, 0.5746606588363647, 0.5361990928649902, 0.5090497732162476, 0.5599547624588013, 0.5791855454444885, 0.5690045356750488, 0.5350678563117981, 0.5723981857299805, 0.5780543088912964, 0.5135746598243713, 0.5780543088912964, 0.5825791954994202, 0.5011312365531921, 0.5837104320526123, 0.5837104320526123, 0.5656108856201172, 0.5791855454444885, 0.5735294222831726, 0.5667420625686646, 0.5622171759605408, 0.5746606588363647, 0.5735294222831726, 0.5723981857299805, 0.5384615659713745, 0.5667420625686646, 0.5735294222831726, 0.5712669491767883, 0.5690045356750488, 0.570135772228241, 0.5780543088912964, 0.5769230723381042, 0.5599547624588013, 0.5757918357849121, 0.5825791954994202, 0.5780543088912964, 0.581447958946228, 0.5463801026344299, 0.5837104320526123, 0.5848416090011597, 0.5542986392974854, 0.5859728455543518, 0.5938913822174072, 0.5825791954994202, 0.5690045356750488, 0.5927602052688599, 0.5746606588363647, 0.5791855454444885, 0.5441176295280457, 0.5882353186607361, 0.5769230723381042, 0.5769230723381042, 0.5837104320526123, 0.5950226187705994, 0.5791855454444885, 0.5723981857299805, 0.5893664956092834, 0.5542986392974854, 0.581447958946228, 0.5825791954994202, 0.5757918357849121, 0.570135772228241, 0.5723981857299805, 0.5723981857299805, 0.5757918357849121]}\n","45/45 [==============================] - 1s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 1.7675 - accuracy: 0.4922"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 9s 76ms/step - loss: 1.7675 - accuracy: 0.4922 - val_loss: 1.7045 - val_accuracy: 0.5145\n","Epoch 2/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.6528 - accuracy: 0.4894 - val_loss: 1.5961 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.5493 - accuracy: 0.4928 - val_loss: 1.4984 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4564 - accuracy: 0.4987 - val_loss: 1.4107 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3730 - accuracy: 0.4902 - val_loss: 1.3318 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2980 - accuracy: 0.4943 - val_loss: 1.2611 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2305 - accuracy: 0.5036 - val_loss: 1.1976 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1702 - accuracy: 0.5036 - val_loss: 1.1408 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1164 - accuracy: 0.4840 - val_loss: 1.0900 - val_accuracy: 0.4855\n","Epoch 10/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0682 - accuracy: 0.5036 - val_loss: 1.0446 - val_accuracy: 0.4855\n","Epoch 11/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0252 - accuracy: 0.5023 - val_loss: 1.0043 - val_accuracy: 0.4855\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9871 - accuracy: 0.5036 - val_loss: 0.9685 - val_accuracy: 0.4855\n","Epoch 13/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9531 - accuracy: 0.5018 - val_loss: 0.9367 - val_accuracy: 0.4855\n","Epoch 14/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9230 - accuracy: 0.5023 - val_loss: 0.9085 - val_accuracy: 0.4855\n","Epoch 15/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8964 - accuracy: 0.5036 - val_loss: 0.8835 - val_accuracy: 0.4855\n","Epoch 16/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8728 - accuracy: 0.5036 - val_loss: 0.8615 - val_accuracy: 0.4855\n","Epoch 17/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8519 - accuracy: 0.5036 - val_loss: 0.8420 - val_accuracy: 0.4855\n","Epoch 18/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8335 - accuracy: 0.5036 - val_loss: 0.8247 - val_accuracy: 0.4855\n","Epoch 19/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8172 - accuracy: 0.5036 - val_loss: 0.8095 - val_accuracy: 0.4855\n","Epoch 20/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8029 - accuracy: 0.5036 - val_loss: 0.7960 - val_accuracy: 0.4855\n","Epoch 21/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7902 - accuracy: 0.5036 - val_loss: 0.7842 - val_accuracy: 0.4855\n","Epoch 22/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7790 - accuracy: 0.5036 - val_loss: 0.7738 - val_accuracy: 0.4855\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7692 - accuracy: 0.5036 - val_loss: 0.7646 - val_accuracy: 0.4855\n","Epoch 24/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7606 - accuracy: 0.5036 - val_loss: 0.7565 - val_accuracy: 0.4855\n","Epoch 25/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7530 - accuracy: 0.5036 - val_loss: 0.7493 - val_accuracy: 0.4855\n","Epoch 26/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7463 - accuracy: 0.5036 - val_loss: 0.7433 - val_accuracy: 0.4855\n","Epoch 27/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7404 - accuracy: 0.5036 - val_loss: 0.7376 - val_accuracy: 0.4855\n","Epoch 28/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7352 - accuracy: 0.5036 - val_loss: 0.7327 - val_accuracy: 0.4855\n","Epoch 29/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7306 - accuracy: 0.5036 - val_loss: 0.7285 - val_accuracy: 0.4855\n","Epoch 30/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7265 - accuracy: 0.5036 - val_loss: 0.7246 - val_accuracy: 0.4855\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7230 - accuracy: 0.5036 - val_loss: 0.7212 - val_accuracy: 0.4855\n","Epoch 32/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7197 - accuracy: 0.5036 - val_loss: 0.7184 - val_accuracy: 0.4855\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7170 - accuracy: 0.5036 - val_loss: 0.7165 - val_accuracy: 0.4855\n","Epoch 34/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7149 - accuracy: 0.5036 - val_loss: 0.7137 - val_accuracy: 0.4855\n","Epoch 35/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7125 - accuracy: 0.5036 - val_loss: 0.7116 - val_accuracy: 0.4855\n","Epoch 36/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7105 - accuracy: 0.5036 - val_loss: 0.7098 - val_accuracy: 0.4855\n","Epoch 37/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7088 - accuracy: 0.5036 - val_loss: 0.7081 - val_accuracy: 0.4855\n","Epoch 38/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7072 - accuracy: 0.5036 - val_loss: 0.7066 - val_accuracy: 0.4855\n","Epoch 39/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7058 - accuracy: 0.5036 - val_loss: 0.7051 - val_accuracy: 0.4855\n","Epoch 40/100\n","31/31 [==============================] - 2s 53ms/step - loss: 0.7044 - accuracy: 0.5028 - val_loss: 0.7038 - val_accuracy: 0.5775\n","Epoch 41/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7039 - accuracy: 0.5093 - val_loss: 0.7035 - val_accuracy: 0.4855\n","Epoch 42/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7025 - accuracy: 0.5266 - val_loss: 0.7021 - val_accuracy: 0.4897\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7014 - accuracy: 0.5354 - val_loss: 0.7005 - val_accuracy: 0.5589\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7012 - accuracy: 0.5088 - val_loss: 0.7010 - val_accuracy: 0.4855\n","Epoch 45/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7001 - accuracy: 0.5225 - val_loss: 0.6995 - val_accuracy: 0.5610\n","Epoch 46/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6992 - accuracy: 0.5315 - val_loss: 0.6979 - val_accuracy: 0.5702\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6994 - accuracy: 0.5000 - val_loss: 0.6989 - val_accuracy: 0.5145\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6989 - accuracy: 0.4964 - val_loss: 0.6985 - val_accuracy: 0.5145\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6984 - accuracy: 0.4956 - val_loss: 0.6981 - val_accuracy: 0.4855\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6979 - accuracy: 0.4868 - val_loss: 0.6977 - val_accuracy: 0.4855\n","Epoch 51/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6976 - accuracy: 0.5036 - val_loss: 0.6974 - val_accuracy: 0.4855\n","Epoch 52/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6972 - accuracy: 0.5036 - val_loss: 0.6971 - val_accuracy: 0.4855\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6969 - accuracy: 0.5036 - val_loss: 0.6968 - val_accuracy: 0.4855\n","Epoch 54/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6966 - accuracy: 0.5036 - val_loss: 0.6965 - val_accuracy: 0.4855\n","Epoch 55/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6964 - accuracy: 0.5036 - val_loss: 0.6963 - val_accuracy: 0.4855\n","Epoch 56/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6961 - accuracy: 0.5036 - val_loss: 0.6961 - val_accuracy: 0.4855\n","Epoch 57/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6959 - accuracy: 0.5036 - val_loss: 0.6959 - val_accuracy: 0.4855\n","Epoch 58/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6957 - accuracy: 0.5036 - val_loss: 0.6957 - val_accuracy: 0.4855\n","Epoch 59/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6955 - accuracy: 0.5036 - val_loss: 0.6956 - val_accuracy: 0.4855\n","Epoch 60/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6954 - accuracy: 0.5036 - val_loss: 0.6954 - val_accuracy: 0.4855\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6952 - accuracy: 0.5036 - val_loss: 0.6953 - val_accuracy: 0.4855\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6951 - accuracy: 0.5036 - val_loss: 0.6952 - val_accuracy: 0.4855\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6950 - accuracy: 0.5036 - val_loss: 0.6950 - val_accuracy: 0.4855\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6949 - accuracy: 0.5036 - val_loss: 0.6950 - val_accuracy: 0.4855\n","Epoch 65/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6948 - accuracy: 0.5036 - val_loss: 0.6949 - val_accuracy: 0.4855\n","Epoch 66/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6947 - accuracy: 0.5036 - val_loss: 0.6948 - val_accuracy: 0.4855\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6946 - accuracy: 0.5036 - val_loss: 0.6947 - val_accuracy: 0.4855\n","Epoch 68/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6945 - accuracy: 0.5036 - val_loss: 0.6946 - val_accuracy: 0.4855\n","Epoch 69/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6944 - accuracy: 0.5036 - val_loss: 0.6945 - val_accuracy: 0.4855\n","Epoch 70/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6944 - accuracy: 0.5036 - val_loss: 0.6945 - val_accuracy: 0.4855\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6943 - accuracy: 0.5036 - val_loss: 0.6944 - val_accuracy: 0.4855\n","Epoch 72/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6942 - accuracy: 0.5036 - val_loss: 0.6943 - val_accuracy: 0.4855\n","Epoch 73/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6942 - accuracy: 0.5036 - val_loss: 0.6943 - val_accuracy: 0.4855\n","Epoch 74/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6941 - accuracy: 0.5036 - val_loss: 0.6943 - val_accuracy: 0.4855\n","Epoch 75/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6941 - accuracy: 0.5036 - val_loss: 0.6942 - val_accuracy: 0.4855\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6940 - accuracy: 0.5036 - val_loss: 0.6942 - val_accuracy: 0.4855\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6940 - accuracy: 0.5036 - val_loss: 0.6941 - val_accuracy: 0.4855\n","Epoch 78/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6940 - accuracy: 0.5036 - val_loss: 0.6941 - val_accuracy: 0.4855\n","Epoch 79/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6939 - accuracy: 0.5036 - val_loss: 0.6940 - val_accuracy: 0.4855\n","Epoch 80/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6939 - accuracy: 0.5036 - val_loss: 0.6940 - val_accuracy: 0.4855\n","Epoch 81/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6938 - accuracy: 0.5036 - val_loss: 0.6940 - val_accuracy: 0.4855\n","Epoch 82/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6938 - accuracy: 0.5036 - val_loss: 0.6940 - val_accuracy: 0.4855\n","Epoch 83/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6938 - accuracy: 0.5036 - val_loss: 0.6939 - val_accuracy: 0.4855\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6938 - accuracy: 0.5036 - val_loss: 0.6939 - val_accuracy: 0.4855\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6937 - accuracy: 0.5036 - val_loss: 0.6939 - val_accuracy: 0.4855\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6937 - accuracy: 0.5036 - val_loss: 0.6939 - val_accuracy: 0.4855\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6937 - accuracy: 0.5036 - val_loss: 0.6938 - val_accuracy: 0.4855\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6937 - accuracy: 0.5036 - val_loss: 0.6938 - val_accuracy: 0.4855\n","Epoch 89/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6937 - accuracy: 0.5036 - val_loss: 0.6938 - val_accuracy: 0.4855\n","Epoch 90/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6936 - accuracy: 0.5036 - val_loss: 0.6938 - val_accuracy: 0.4855\n","Epoch 91/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6936 - accuracy: 0.5036 - val_loss: 0.6938 - val_accuracy: 0.4855\n","Epoch 92/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6936 - accuracy: 0.5036 - val_loss: 0.6938 - val_accuracy: 0.4855\n","Epoch 93/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6936 - accuracy: 0.5036 - val_loss: 0.6937 - val_accuracy: 0.4855\n","Epoch 94/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6936 - accuracy: 0.5036 - val_loss: 0.6937 - val_accuracy: 0.4855\n","Epoch 95/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6936 - accuracy: 0.5036 - val_loss: 0.6937 - val_accuracy: 0.4855\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6935 - accuracy: 0.5036 - val_loss: 0.6937 - val_accuracy: 0.4855\n","Epoch 97/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6935 - accuracy: 0.5036 - val_loss: 0.6937 - val_accuracy: 0.4855\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6935 - accuracy: 0.5036 - val_loss: 0.6937 - val_accuracy: 0.4855\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6935 - accuracy: 0.5036 - val_loss: 0.6937 - val_accuracy: 0.4855\n","Epoch 100/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6935 - accuracy: 0.5036 - val_loss: 0.6937 - val_accuracy: 0.4855\n","{'loss': [1.7674508094787598, 1.652773141860962, 1.5492527484893799, 1.456424593925476, 1.3729674816131592, 1.2979586124420166, 1.230547547340393, 1.1702475547790527, 1.1164348125457764, 1.068161129951477, 1.0251935720443726, 0.9870724678039551, 0.9531390070915222, 0.9230427742004395, 0.8963719010353088, 0.872797429561615, 0.8519037365913391, 0.8334816098213196, 0.8172157406806946, 0.8028537034988403, 0.7901815176010132, 0.7790313363075256, 0.769224226474762, 0.7605734467506409, 0.7529941201210022, 0.7463228702545166, 0.7403616905212402, 0.735194206237793, 0.7305563688278198, 0.7265487909317017, 0.7229801416397095, 0.7197226881980896, 0.7170151472091675, 0.7148565053939819, 0.7124864459037781, 0.7105218172073364, 0.7088204026222229, 0.7072314023971558, 0.7057745456695557, 0.7044206261634827, 0.7039182186126709, 0.7025496959686279, 0.7014204859733582, 0.7011923789978027, 0.7000603675842285, 0.6991801857948303, 0.699393630027771, 0.6988914012908936, 0.6983659267425537, 0.6979387402534485, 0.6975526213645935, 0.6971966624259949, 0.6968861222267151, 0.696600079536438, 0.6963502168655396, 0.6961119771003723, 0.6959013342857361, 0.6957115530967712, 0.6955440044403076, 0.6953813433647156, 0.6952304244041443, 0.6950995326042175, 0.6949836611747742, 0.6948646306991577, 0.6947607398033142, 0.6946650743484497, 0.6945781111717224, 0.6944971084594727, 0.6944224834442139, 0.6943551301956177, 0.6942871809005737, 0.6942290663719177, 0.6941721439361572, 0.6941236257553101, 0.694071888923645, 0.6940345168113708, 0.693989634513855, 0.6939502954483032, 0.6939135193824768, 0.6938796639442444, 0.6938497424125671, 0.6938203573226929, 0.6937907338142395, 0.6937686800956726, 0.6937451362609863, 0.6937169432640076, 0.6936960220336914, 0.6936761736869812, 0.6936585307121277, 0.6936393976211548, 0.6936200857162476, 0.6936056017875671, 0.6935873627662659, 0.6935727596282959, 0.6935566067695618, 0.693543016910553, 0.6935312747955322, 0.693520724773407, 0.6935086846351624, 0.6934953331947327], 'accuracy': [0.4922480583190918, 0.48940569162368774, 0.4927648603916168, 0.49870800971984863, 0.4901808798313141, 0.4943152368068695, 0.5036175847053528, 0.5036175847053528, 0.48397931456565857, 0.5036175847053528, 0.5023255944252014, 0.5036175847053528, 0.501808762550354, 0.5023255944252014, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.502842366695404, 0.5093023180961609, 0.5266149640083313, 0.5354005098342896, 0.5087855458259583, 0.5224806070327759, 0.5315245389938354, 0.5, 0.4963824152946472, 0.4956072270870209, 0.486821711063385, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528], 'val_loss': [1.7044979333877563, 1.5960502624511719, 1.4983702898025513, 1.410715103149414, 1.3318465948104858, 1.261077642440796, 1.1976298093795776, 1.1407650709152222, 1.0899879932403564, 1.0446367263793945, 1.0043389797210693, 0.9685479402542114, 0.9366875886917114, 0.9084871411323547, 0.8835172653198242, 0.8614757657051086, 0.8419638872146606, 0.8246521949768066, 0.8094533085823059, 0.7960453629493713, 0.7841890454292297, 0.7737990021705627, 0.7646224498748779, 0.7564818859100342, 0.7493340969085693, 0.743267834186554, 0.737586498260498, 0.732723593711853, 0.7285489439964294, 0.7245830297470093, 0.7212315797805786, 0.7184298634529114, 0.7165275812149048, 0.7137032747268677, 0.7115944623947144, 0.7098444700241089, 0.7081353068351746, 0.70656818151474, 0.7050537467002869, 0.7037504315376282, 0.7034842371940613, 0.7021357417106628, 0.7004867196083069, 0.7009875178337097, 0.6994922161102295, 0.6979309320449829, 0.698948860168457, 0.6985389590263367, 0.6981350183486938, 0.6977295875549316, 0.6974277496337891, 0.6971051692962646, 0.6968174576759338, 0.6965451240539551, 0.6963102221488953, 0.6961134076118469, 0.6959155201911926, 0.6957399249076843, 0.6955587863922119, 0.6954218745231628, 0.6952874660491943, 0.6951706409454346, 0.6950441002845764, 0.6949554681777954, 0.6948586106300354, 0.6947758197784424, 0.6946733593940735, 0.6946085691452026, 0.694527268409729, 0.6944804191589355, 0.6944044232368469, 0.6943497061729431, 0.6943054795265198, 0.6942553520202637, 0.6942008137702942, 0.6941667199134827, 0.6941201090812683, 0.6940726041793823, 0.6940494179725647, 0.6940118670463562, 0.6939725279808044, 0.6939511895179749, 0.6939136981964111, 0.6938945651054382, 0.6938616037368774, 0.6938518285751343, 0.6938327550888062, 0.6938141584396362, 0.6937917470932007, 0.6937848925590515, 0.6937689781188965, 0.6937639117240906, 0.6937399506568909, 0.6937286257743835, 0.6937271356582642, 0.6937206387519836, 0.6937013268470764, 0.6936973929405212, 0.6936761140823364, 0.6936652064323425], 'val_accuracy': [0.5144628286361694, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.577479362487793, 0.48553720116615295, 0.48966941237449646, 0.55888432264328, 0.48553720116615295, 0.5609503984451294, 0.5702479481697083, 0.5144628286361694, 0.5144628286361694, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295]}\n","32/32 [==============================] - 1s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.6847 - accuracy: 0.5697"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 76ms/step - loss: 0.6848 - accuracy: 0.5687 - val_loss: 0.6964 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6699 - accuracy: 0.5946 - val_loss: 0.6972 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6768 - accuracy: 0.5814 - val_loss: 0.6965 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6689 - accuracy: 0.5959 - val_loss: 0.6969 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6560 - accuracy: 0.6202 - val_loss: 0.6976 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6610 - accuracy: 0.5964 - val_loss: 0.6982 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6533 - accuracy: 0.6175 - val_loss: 0.7000 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6355 - accuracy: 0.6525 - val_loss: 0.7000 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6337 - accuracy: 0.6455 - val_loss: 0.6957 - val_accuracy: 0.4935\n","Epoch 10/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6228 - accuracy: 0.6554 - val_loss: 0.6981 - val_accuracy: 0.4849\n","Epoch 11/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6168 - accuracy: 0.6641 - val_loss: 0.7002 - val_accuracy: 0.4871\n","Epoch 12/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6102 - accuracy: 0.6649 - val_loss: 0.6919 - val_accuracy: 0.5420\n","Epoch 13/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5889 - accuracy: 0.6837 - val_loss: 0.6937 - val_accuracy: 0.5172\n","Epoch 14/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5744 - accuracy: 0.7015 - val_loss: 0.6850 - val_accuracy: 0.5539\n","Epoch 15/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5498 - accuracy: 0.7193 - val_loss: 0.7063 - val_accuracy: 0.4946\n","Epoch 16/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5752 - accuracy: 0.7023 - val_loss: 0.7247 - val_accuracy: 0.5065\n","Epoch 17/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.5213 - accuracy: 0.7390 - val_loss: 0.6940 - val_accuracy: 0.5560\n","Epoch 18/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5107 - accuracy: 0.7462 - val_loss: 0.6739 - val_accuracy: 0.6034\n","Epoch 19/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5156 - accuracy: 0.7425 - val_loss: 0.6974 - val_accuracy: 0.5819\n","Epoch 20/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4737 - accuracy: 0.7732 - val_loss: 0.8275 - val_accuracy: 0.5075\n","Epoch 21/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.4805 - accuracy: 0.7662 - val_loss: 0.7254 - val_accuracy: 0.6045\n","Epoch 22/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4100 - accuracy: 0.8079 - val_loss: 0.7257 - val_accuracy: 0.5905\n","Epoch 23/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4337 - accuracy: 0.7947 - val_loss: 0.7723 - val_accuracy: 0.5884\n","Epoch 24/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3880 - accuracy: 0.8217 - val_loss: 0.7525 - val_accuracy: 0.5970\n","Epoch 25/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3496 - accuracy: 0.8424 - val_loss: 0.8180 - val_accuracy: 0.6013\n","Epoch 26/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3477 - accuracy: 0.8448 - val_loss: 0.9186 - val_accuracy: 0.5991\n","Epoch 27/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3164 - accuracy: 0.8631 - val_loss: 0.9039 - val_accuracy: 0.6196\n","Epoch 28/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2901 - accuracy: 0.8761 - val_loss: 1.0027 - val_accuracy: 0.5884\n","Epoch 29/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2842 - accuracy: 0.8807 - val_loss: 0.9803 - val_accuracy: 0.6164\n","Epoch 30/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2510 - accuracy: 0.8968 - val_loss: 1.1627 - val_accuracy: 0.6034\n","Epoch 31/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2946 - accuracy: 0.8710 - val_loss: 1.1444 - val_accuracy: 0.5636\n","Epoch 32/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2392 - accuracy: 0.9046 - val_loss: 1.1724 - val_accuracy: 0.5981\n","Epoch 33/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2125 - accuracy: 0.9087 - val_loss: 1.3655 - val_accuracy: 0.6067\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2599 - accuracy: 0.8914 - val_loss: 1.3313 - val_accuracy: 0.5765\n","Epoch 35/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1796 - accuracy: 0.9283 - val_loss: 1.3880 - val_accuracy: 0.5873\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1619 - accuracy: 0.9386 - val_loss: 1.3582 - val_accuracy: 0.6056\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1618 - accuracy: 0.9353 - val_loss: 1.5341 - val_accuracy: 0.5927\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1939 - accuracy: 0.9213 - val_loss: 1.2220 - val_accuracy: 0.5927\n","Epoch 39/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1490 - accuracy: 0.9426 - val_loss: 1.5092 - val_accuracy: 0.6056\n","Epoch 40/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1149 - accuracy: 0.9604 - val_loss: 1.6212 - val_accuracy: 0.6142\n","Epoch 41/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1736 - accuracy: 0.9310 - val_loss: 1.3403 - val_accuracy: 0.6110\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1559 - accuracy: 0.9407 - val_loss: 1.4680 - val_accuracy: 0.5948\n","Epoch 43/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1124 - accuracy: 0.9593 - val_loss: 1.6310 - val_accuracy: 0.6067\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0979 - accuracy: 0.9647 - val_loss: 1.6357 - val_accuracy: 0.5884\n","Epoch 45/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.1037 - accuracy: 0.9623 - val_loss: 1.6761 - val_accuracy: 0.6088\n","Epoch 46/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1023 - accuracy: 0.9631 - val_loss: 1.6801 - val_accuracy: 0.5905\n","Epoch 47/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1065 - accuracy: 0.9628 - val_loss: 1.7026 - val_accuracy: 0.5884\n","Epoch 48/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1226 - accuracy: 0.9572 - val_loss: 1.5769 - val_accuracy: 0.5830\n","Epoch 49/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1045 - accuracy: 0.9644 - val_loss: 1.7535 - val_accuracy: 0.5981\n","Epoch 50/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1042 - accuracy: 0.9644 - val_loss: 1.6266 - val_accuracy: 0.6142\n","Epoch 51/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1307 - accuracy: 0.9483 - val_loss: 1.6818 - val_accuracy: 0.5970\n","Epoch 52/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1283 - accuracy: 0.9534 - val_loss: 1.7053 - val_accuracy: 0.5851\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0748 - accuracy: 0.9760 - val_loss: 1.8360 - val_accuracy: 0.5970\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0868 - accuracy: 0.9714 - val_loss: 1.8618 - val_accuracy: 0.5948\n","Epoch 55/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0643 - accuracy: 0.9825 - val_loss: 1.8988 - val_accuracy: 0.5981\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0532 - accuracy: 0.9844 - val_loss: 1.9739 - val_accuracy: 0.6088\n","Epoch 57/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0589 - accuracy: 0.9817 - val_loss: 2.0145 - val_accuracy: 0.5959\n","Epoch 58/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0629 - accuracy: 0.9803 - val_loss: 2.0061 - val_accuracy: 0.5991\n","Epoch 59/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0766 - accuracy: 0.9744 - val_loss: 1.9072 - val_accuracy: 0.5808\n","Epoch 60/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0858 - accuracy: 0.9728 - val_loss: 1.7301 - val_accuracy: 0.6153\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0926 - accuracy: 0.9671 - val_loss: 2.0344 - val_accuracy: 0.5808\n","Epoch 62/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1319 - accuracy: 0.9515 - val_loss: 1.4140 - val_accuracy: 0.5700\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0766 - accuracy: 0.9744 - val_loss: 1.8197 - val_accuracy: 0.5948\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0673 - accuracy: 0.9787 - val_loss: 1.8214 - val_accuracy: 0.5948\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0832 - accuracy: 0.9717 - val_loss: 1.7886 - val_accuracy: 0.6185\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0693 - accuracy: 0.9768 - val_loss: 1.9082 - val_accuracy: 0.6078\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0550 - accuracy: 0.9825 - val_loss: 2.0041 - val_accuracy: 0.6034\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0739 - accuracy: 0.9755 - val_loss: 1.8671 - val_accuracy: 0.5862\n","Epoch 69/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0523 - accuracy: 0.9841 - val_loss: 2.0946 - val_accuracy: 0.6078\n","Epoch 70/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0619 - accuracy: 0.9814 - val_loss: 1.8779 - val_accuracy: 0.6024\n","Epoch 71/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0424 - accuracy: 0.9887 - val_loss: 2.0292 - val_accuracy: 0.6045\n","Epoch 72/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0680 - accuracy: 0.9758 - val_loss: 1.7305 - val_accuracy: 0.5927\n","Epoch 73/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0764 - accuracy: 0.9733 - val_loss: 1.9536 - val_accuracy: 0.5959\n","Epoch 74/100\n","29/29 [==============================] - 2s 66ms/step - loss: 0.0700 - accuracy: 0.9760 - val_loss: 1.8196 - val_accuracy: 0.6282\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0769 - accuracy: 0.9752 - val_loss: 1.9318 - val_accuracy: 0.5916\n","Epoch 76/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0749 - accuracy: 0.9755 - val_loss: 1.7314 - val_accuracy: 0.6056\n","Epoch 77/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0527 - accuracy: 0.9844 - val_loss: 1.8746 - val_accuracy: 0.6002\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0454 - accuracy: 0.9860 - val_loss: 2.0418 - val_accuracy: 0.6099\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0525 - accuracy: 0.9836 - val_loss: 1.9802 - val_accuracy: 0.6056\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0583 - accuracy: 0.9793 - val_loss: 2.0607 - val_accuracy: 0.6024\n","Epoch 81/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0607 - accuracy: 0.9811 - val_loss: 2.0495 - val_accuracy: 0.5959\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0722 - accuracy: 0.9758 - val_loss: 1.8387 - val_accuracy: 0.5916\n","Epoch 83/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0904 - accuracy: 0.9690 - val_loss: 1.6683 - val_accuracy: 0.6067\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0620 - accuracy: 0.9793 - val_loss: 1.9089 - val_accuracy: 0.5862\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0582 - accuracy: 0.9811 - val_loss: 2.0116 - val_accuracy: 0.5916\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0490 - accuracy: 0.9860 - val_loss: 2.1376 - val_accuracy: 0.5927\n","Epoch 87/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0499 - accuracy: 0.9865 - val_loss: 2.0006 - val_accuracy: 0.5991\n","Epoch 88/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0757 - accuracy: 0.9733 - val_loss: 1.7591 - val_accuracy: 0.5959\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0696 - accuracy: 0.9758 - val_loss: 1.9375 - val_accuracy: 0.5894\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0767 - accuracy: 0.9782 - val_loss: 1.9543 - val_accuracy: 0.5873\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0408 - accuracy: 0.9881 - val_loss: 2.0462 - val_accuracy: 0.5991\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0417 - accuracy: 0.9884 - val_loss: 2.0294 - val_accuracy: 0.5765\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0378 - accuracy: 0.9903 - val_loss: 2.0661 - val_accuracy: 0.6142\n","Epoch 94/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0467 - accuracy: 0.9868 - val_loss: 2.1305 - val_accuracy: 0.6034\n","Epoch 95/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0368 - accuracy: 0.9892 - val_loss: 2.1577 - val_accuracy: 0.6056\n","Epoch 96/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0395 - accuracy: 0.9887 - val_loss: 2.1689 - val_accuracy: 0.5948\n","Epoch 97/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0407 - accuracy: 0.9890 - val_loss: 2.1584 - val_accuracy: 0.5981\n","Epoch 98/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0439 - accuracy: 0.9863 - val_loss: 2.0550 - val_accuracy: 0.6121\n","Epoch 99/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0884 - accuracy: 0.9728 - val_loss: 1.6857 - val_accuracy: 0.6056\n","Epoch 100/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0662 - accuracy: 0.9801 - val_loss: 1.8046 - val_accuracy: 0.5959\n","{'loss': [0.6848437786102295, 0.669893741607666, 0.6767545938491821, 0.6689217686653137, 0.6559862494468689, 0.661033034324646, 0.6533430218696594, 0.6354822516441345, 0.6336877346038818, 0.6228241920471191, 0.6167551875114441, 0.6101932525634766, 0.5888628363609314, 0.5743723511695862, 0.5498396158218384, 0.5751518607139587, 0.521304726600647, 0.5106631517410278, 0.5155997276306152, 0.47373953461647034, 0.4804760217666626, 0.41003933548927307, 0.4337407946586609, 0.38797232508659363, 0.34959641098976135, 0.34774014353752136, 0.31640881299972534, 0.29012349247932434, 0.28423941135406494, 0.2510449290275574, 0.2945534586906433, 0.23917502164840698, 0.21246939897537231, 0.25989603996276855, 0.17957359552383423, 0.16188324987888336, 0.1618029773235321, 0.19385524094104767, 0.14898446202278137, 0.11489447951316833, 0.17359329760074615, 0.15590311586856842, 0.11238427460193634, 0.09786062687635422, 0.10372743755578995, 0.10225224494934082, 0.10648055374622345, 0.12257829308509827, 0.10447878390550613, 0.1041516438126564, 0.1306934505701065, 0.12828488647937775, 0.07478314638137817, 0.08684469759464264, 0.06427937746047974, 0.05324851721525192, 0.05885393172502518, 0.06290242075920105, 0.07663574814796448, 0.0858352854847908, 0.09255330264568329, 0.13187351822853088, 0.07662275433540344, 0.06728256493806839, 0.08316874504089355, 0.0693177729845047, 0.05497652664780617, 0.07387550920248032, 0.05228237435221672, 0.0619075782597065, 0.042421821504831314, 0.06803607195615768, 0.07643605768680573, 0.07003868371248245, 0.07690746337175369, 0.07486950606107712, 0.05271231383085251, 0.04544888436794281, 0.05252770334482193, 0.058332037180662155, 0.06070753186941147, 0.07218173146247864, 0.09035129845142365, 0.06198172643780708, 0.05818863958120346, 0.04897380620241165, 0.04992590844631195, 0.07572270184755325, 0.06964734196662903, 0.07673660665750504, 0.04084998741745949, 0.04171827808022499, 0.03779105469584465, 0.04672772437334061, 0.03681659325957298, 0.039468925446271896, 0.040741339325904846, 0.04385253041982651, 0.08841592073440552, 0.06618328392505646], 'accuracy': [0.568696141242981, 0.5945581793785095, 0.5813577771186829, 0.5959051847457886, 0.6201508641242981, 0.5964439511299133, 0.6174569129943848, 0.6524784564971924, 0.6454741358757019, 0.6554418206214905, 0.6640625, 0.6648706793785095, 0.6837284564971924, 0.701508641242981, 0.7192887663841248, 0.7023168206214905, 0.7389547228813171, 0.7462284564971924, 0.7424569129943848, 0.7731680870056152, 0.7661637663841248, 0.8079202771186829, 0.7947198152542114, 0.821659505367279, 0.842402994632721, 0.8448275923728943, 0.8631465435028076, 0.8760775923728943, 0.8806573152542114, 0.896821141242981, 0.8709590435028076, 0.904633641242981, 0.9086745977401733, 0.8914331793785095, 0.928340494632721, 0.9385775923728943, 0.9353448152542114, 0.9213362336158752, 0.9426185488700867, 0.9603987336158752, 0.931034505367279, 0.9407327771186829, 0.959321141242981, 0.9647090435028076, 0.962284505367279, 0.9630926847457886, 0.9628232717514038, 0.9571659564971924, 0.9644396305084229, 0.9644396305084229, 0.9482758641242981, 0.9533944129943848, 0.9760237336158752, 0.9714439511299133, 0.9824892282485962, 0.984375, 0.9816810488700867, 0.9803340435028076, 0.9744073152542114, 0.9727909564971924, 0.967133641242981, 0.951508641242981, 0.9744073152542114, 0.9787176847457886, 0.9717133641242981, 0.9768319129943848, 0.9824892282485962, 0.9754849076271057, 0.9841055870056152, 0.9814116358757019, 0.9886853694915771, 0.9757543206214905, 0.9733297228813171, 0.9760237336158752, 0.975215494632721, 0.9754849076271057, 0.984375, 0.985991358757019, 0.9835668206214905, 0.9792564511299133, 0.9811422228813171, 0.9757543206214905, 0.9690194129943848, 0.9792564511299133, 0.9811422228813171, 0.985991358757019, 0.9865301847457886, 0.9733297228813171, 0.9757543206214905, 0.978178858757019, 0.9881465435028076, 0.9884159564971924, 0.9903017282485962, 0.9867995977401733, 0.9892241358757019, 0.9886853694915771, 0.9889547228813171, 0.9862607717514038, 0.9727909564971924, 0.9800646305084229], 'val_loss': [0.6963672637939453, 0.6971756219863892, 0.6964806318283081, 0.6968852281570435, 0.6975981593132019, 0.6982114911079407, 0.700045645236969, 0.6999984383583069, 0.6957154273986816, 0.6981034874916077, 0.7002301216125488, 0.6918727159500122, 0.6936513185501099, 0.6849574446678162, 0.7062591910362244, 0.7247062921524048, 0.6939917802810669, 0.6739406585693359, 0.6974220275878906, 0.8275246024131775, 0.7253708243370056, 0.7256511449813843, 0.7723477482795715, 0.7525196671485901, 0.817956268787384, 0.9185982942581177, 0.903854250907898, 1.002702236175537, 0.9802868962287903, 1.1626861095428467, 1.1443547010421753, 1.1724121570587158, 1.3655281066894531, 1.3313237428665161, 1.3880236148834229, 1.358212947845459, 1.5341354608535767, 1.2220205068588257, 1.5091663599014282, 1.621226191520691, 1.3403419256210327, 1.4680174589157104, 1.6309943199157715, 1.63566255569458, 1.6760566234588623, 1.6800519227981567, 1.7025889158248901, 1.5769301652908325, 1.7534500360488892, 1.6266449689865112, 1.6818325519561768, 1.7052804231643677, 1.8360130786895752, 1.8617749214172363, 1.8987548351287842, 1.9739429950714111, 2.0144717693328857, 2.0061137676239014, 1.9071907997131348, 1.730074167251587, 2.0344300270080566, 1.4139761924743652, 1.8197365999221802, 1.821359395980835, 1.7886159420013428, 1.9082039594650269, 2.0041255950927734, 1.867072582244873, 2.094578504562378, 1.8778928518295288, 2.029249906539917, 1.7305171489715576, 1.9535605907440186, 1.8195949792861938, 1.9318488836288452, 1.731418490409851, 1.8745816946029663, 2.0418145656585693, 1.98020339012146, 2.0606837272644043, 2.049548387527466, 1.8386509418487549, 1.668264627456665, 1.9089128971099854, 2.011592388153076, 2.137599229812622, 2.000638008117676, 1.759068489074707, 1.9375026226043701, 1.9543426036834717, 2.0461790561676025, 2.029426097869873, 2.0660860538482666, 2.1304521560668945, 2.157747268676758, 2.1688830852508545, 2.1583542823791504, 2.054997682571411, 1.6856534481048584, 1.8045557737350464], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.49353447556495667, 0.48491379618644714, 0.48706895112991333, 0.5420258641242981, 0.517241358757019, 0.5538793206214905, 0.49461206793785095, 0.506465494632721, 0.556034505367279, 0.6034482717514038, 0.5818965435028076, 0.5075430870056152, 0.6045258641242981, 0.5905172228813171, 0.5883620977401733, 0.5969827771186829, 0.6012930870056152, 0.5991379022598267, 0.6196120977401733, 0.5883620977401733, 0.6163793206214905, 0.6034482717514038, 0.5635775923728943, 0.5980603694915771, 0.6066810488700867, 0.576508641242981, 0.587284505367279, 0.6056034564971924, 0.5926724076271057, 0.5926724076271057, 0.6056034564971924, 0.6142241358757019, 0.610991358757019, 0.5948275923728943, 0.6066810488700867, 0.5883620977401733, 0.6088362336158752, 0.5905172228813171, 0.5883620977401733, 0.5829741358757019, 0.5980603694915771, 0.6142241358757019, 0.5969827771186829, 0.5851293206214905, 0.5969827771186829, 0.5948275923728943, 0.5980603694915771, 0.6088362336158752, 0.5959051847457886, 0.5991379022598267, 0.5808189511299133, 0.6153017282485962, 0.5808189511299133, 0.5700430870056152, 0.5948275923728943, 0.5948275923728943, 0.618534505367279, 0.607758641242981, 0.6034482717514038, 0.5862069129943848, 0.607758641242981, 0.6023706793785095, 0.6045258641242981, 0.5926724076271057, 0.5959051847457886, 0.6282327771186829, 0.5915948152542114, 0.6056034564971924, 0.600215494632721, 0.6099137663841248, 0.6056034564971924, 0.6023706793785095, 0.5959051847457886, 0.5915948152542114, 0.6066810488700867, 0.5862069129943848, 0.5915948152542114, 0.5926724076271057, 0.5991379022598267, 0.5959051847457886, 0.5894396305084229, 0.587284505367279, 0.5991379022598267, 0.576508641242981, 0.6142241358757019, 0.6034482717514038, 0.6056034564971924, 0.5948275923728943, 0.5980603694915771, 0.6120689511299133, 0.6056034564971924, 0.5959051847457886]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.6846 - accuracy: 0.5724"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 81ms/step - loss: 0.6841 - accuracy: 0.5741 - val_loss: 0.6960 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.6715 - accuracy: 0.5988 - val_loss: 0.6961 - val_accuracy: 0.4966\n","Epoch 3/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6705 - accuracy: 0.5976 - val_loss: 0.6963 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6644 - accuracy: 0.6121 - val_loss: 0.6966 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6570 - accuracy: 0.6234 - val_loss: 0.6969 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6508 - accuracy: 0.6313 - val_loss: 0.6964 - val_accuracy: 0.4966\n","Epoch 7/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6488 - accuracy: 0.6276 - val_loss: 0.6964 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6386 - accuracy: 0.6480 - val_loss: 0.6983 - val_accuracy: 0.4966\n","Epoch 9/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6169 - accuracy: 0.6647 - val_loss: 0.7013 - val_accuracy: 0.4966\n","Epoch 10/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6116 - accuracy: 0.6769 - val_loss: 0.7001 - val_accuracy: 0.4955\n","Epoch 11/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6035 - accuracy: 0.6777 - val_loss: 0.6971 - val_accuracy: 0.5068\n","Epoch 12/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.5954 - accuracy: 0.6836 - val_loss: 0.6942 - val_accuracy: 0.5158\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5717 - accuracy: 0.7100 - val_loss: 0.7040 - val_accuracy: 0.5011\n","Epoch 14/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6044 - accuracy: 0.6701 - val_loss: 0.6878 - val_accuracy: 0.5633\n","Epoch 15/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5653 - accuracy: 0.7224 - val_loss: 0.7217 - val_accuracy: 0.5113\n","Epoch 16/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5408 - accuracy: 0.7281 - val_loss: 0.7441 - val_accuracy: 0.5068\n","Epoch 17/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5521 - accuracy: 0.7196 - val_loss: 0.7240 - val_accuracy: 0.5136\n","Epoch 18/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5556 - accuracy: 0.7179 - val_loss: 0.7108 - val_accuracy: 0.5396\n","Epoch 19/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5085 - accuracy: 0.7581 - val_loss: 0.7163 - val_accuracy: 0.5713\n","Epoch 20/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.5118 - accuracy: 0.7504 - val_loss: 0.7098 - val_accuracy: 0.5724\n","Epoch 21/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.4963 - accuracy: 0.7612 - val_loss: 0.6838 - val_accuracy: 0.5928\n","Epoch 22/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.4721 - accuracy: 0.7765 - val_loss: 0.7368 - val_accuracy: 0.5962\n","Epoch 23/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.4650 - accuracy: 0.7793 - val_loss: 0.7104 - val_accuracy: 0.6075\n","Epoch 24/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4474 - accuracy: 0.7934 - val_loss: 0.8024 - val_accuracy: 0.5860\n","Epoch 25/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4587 - accuracy: 0.7818 - val_loss: 0.7238 - val_accuracy: 0.5950\n","Epoch 26/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.4183 - accuracy: 0.8045 - val_loss: 0.7930 - val_accuracy: 0.6165\n","Epoch 27/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4009 - accuracy: 0.8144 - val_loss: 0.7883 - val_accuracy: 0.5894\n","Epoch 28/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3736 - accuracy: 0.8263 - val_loss: 0.8209 - val_accuracy: 0.6029\n","Epoch 29/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4200 - accuracy: 0.7999 - val_loss: 0.7870 - val_accuracy: 0.5905\n","Epoch 30/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3666 - accuracy: 0.8294 - val_loss: 1.0333 - val_accuracy: 0.5984\n","Epoch 31/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3444 - accuracy: 0.8427 - val_loss: 0.9480 - val_accuracy: 0.5769\n","Epoch 32/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3239 - accuracy: 0.8444 - val_loss: 1.1841 - val_accuracy: 0.5984\n","Epoch 33/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3183 - accuracy: 0.8531 - val_loss: 1.0630 - val_accuracy: 0.5792\n","Epoch 34/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2957 - accuracy: 0.8642 - val_loss: 1.5316 - val_accuracy: 0.5611\n","Epoch 35/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3251 - accuracy: 0.8500 - val_loss: 1.1190 - val_accuracy: 0.5837\n","Epoch 36/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2939 - accuracy: 0.8636 - val_loss: 1.2402 - val_accuracy: 0.5769\n","Epoch 37/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2831 - accuracy: 0.8704 - val_loss: 1.2239 - val_accuracy: 0.5792\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2730 - accuracy: 0.8718 - val_loss: 1.1256 - val_accuracy: 0.5826\n","Epoch 39/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2675 - accuracy: 0.8786 - val_loss: 1.1664 - val_accuracy: 0.5882\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2321 - accuracy: 0.8964 - val_loss: 1.3040 - val_accuracy: 0.5905\n","Epoch 41/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2512 - accuracy: 0.8823 - val_loss: 1.2827 - val_accuracy: 0.5962\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2498 - accuracy: 0.8865 - val_loss: 1.3344 - val_accuracy: 0.5735\n","Epoch 43/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.1951 - accuracy: 0.9106 - val_loss: 1.5608 - val_accuracy: 0.5747\n","Epoch 44/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2327 - accuracy: 0.8956 - val_loss: 1.2953 - val_accuracy: 0.5803\n","Epoch 45/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1967 - accuracy: 0.9095 - val_loss: 1.4577 - val_accuracy: 0.5701\n","Epoch 46/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.1980 - accuracy: 0.9086 - val_loss: 1.4600 - val_accuracy: 0.5747\n","Epoch 47/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2151 - accuracy: 0.9044 - val_loss: 1.4205 - val_accuracy: 0.5588\n","Epoch 48/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1810 - accuracy: 0.9202 - val_loss: 1.5161 - val_accuracy: 0.5814\n","Epoch 49/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1545 - accuracy: 0.9324 - val_loss: 1.6651 - val_accuracy: 0.5600\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1854 - accuracy: 0.9216 - val_loss: 1.5084 - val_accuracy: 0.5758\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1626 - accuracy: 0.9270 - val_loss: 1.6461 - val_accuracy: 0.5882\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1468 - accuracy: 0.9403 - val_loss: 1.6142 - val_accuracy: 0.5633\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1362 - accuracy: 0.9392 - val_loss: 1.6976 - val_accuracy: 0.5905\n","Epoch 54/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1204 - accuracy: 0.9527 - val_loss: 1.7250 - val_accuracy: 0.5928\n","Epoch 55/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1753 - accuracy: 0.9293 - val_loss: 1.4929 - val_accuracy: 0.5826\n","Epoch 56/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1943 - accuracy: 0.9120 - val_loss: 1.5793 - val_accuracy: 0.5701\n","Epoch 57/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1855 - accuracy: 0.9202 - val_loss: 1.4985 - val_accuracy: 0.5645\n","Epoch 58/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1066 - accuracy: 0.9595 - val_loss: 1.7330 - val_accuracy: 0.5656\n","Epoch 59/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1123 - accuracy: 0.9561 - val_loss: 1.7575 - val_accuracy: 0.5905\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1211 - accuracy: 0.9533 - val_loss: 1.8098 - val_accuracy: 0.5633\n","Epoch 61/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1087 - accuracy: 0.9578 - val_loss: 1.9140 - val_accuracy: 0.5724\n","Epoch 62/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0996 - accuracy: 0.9621 - val_loss: 1.9324 - val_accuracy: 0.5928\n","Epoch 63/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0865 - accuracy: 0.9700 - val_loss: 2.0381 - val_accuracy: 0.5633\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0989 - accuracy: 0.9660 - val_loss: 1.8129 - val_accuracy: 0.5826\n","Epoch 65/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0984 - accuracy: 0.9652 - val_loss: 2.1847 - val_accuracy: 0.5588\n","Epoch 66/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1192 - accuracy: 0.9547 - val_loss: 1.7820 - val_accuracy: 0.5645\n","Epoch 67/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0808 - accuracy: 0.9711 - val_loss: 1.9658 - val_accuracy: 0.5713\n","Epoch 68/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0598 - accuracy: 0.9827 - val_loss: 2.0503 - val_accuracy: 0.5667\n","Epoch 69/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0884 - accuracy: 0.9675 - val_loss: 2.0550 - val_accuracy: 0.5781\n","Epoch 70/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0833 - accuracy: 0.9728 - val_loss: 1.9746 - val_accuracy: 0.5430\n","Epoch 71/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1158 - accuracy: 0.9573 - val_loss: 1.8496 - val_accuracy: 0.5792\n","Epoch 72/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1239 - accuracy: 0.9553 - val_loss: 1.8911 - val_accuracy: 0.5713\n","Epoch 73/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1222 - accuracy: 0.9542 - val_loss: 1.8254 - val_accuracy: 0.5622\n","Epoch 74/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0880 - accuracy: 0.9683 - val_loss: 1.8389 - val_accuracy: 0.5792\n","Epoch 75/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0790 - accuracy: 0.9706 - val_loss: 1.9659 - val_accuracy: 0.5419\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1368 - accuracy: 0.9488 - val_loss: 1.7329 - val_accuracy: 0.5781\n","Epoch 77/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1057 - accuracy: 0.9629 - val_loss: 1.7315 - val_accuracy: 0.5826\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0806 - accuracy: 0.9726 - val_loss: 1.8958 - val_accuracy: 0.5758\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0685 - accuracy: 0.9779 - val_loss: 2.0260 - val_accuracy: 0.5962\n","Epoch 80/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0571 - accuracy: 0.9844 - val_loss: 2.0161 - val_accuracy: 0.5803\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0398 - accuracy: 0.9875 - val_loss: 2.1437 - val_accuracy: 0.5950\n","Epoch 82/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0442 - accuracy: 0.9864 - val_loss: 2.2405 - val_accuracy: 0.5781\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0460 - accuracy: 0.9881 - val_loss: 2.2466 - val_accuracy: 0.5724\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0566 - accuracy: 0.9819 - val_loss: 2.1797 - val_accuracy: 0.5769\n","Epoch 85/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0637 - accuracy: 0.9808 - val_loss: 2.0852 - val_accuracy: 0.5826\n","Epoch 86/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0531 - accuracy: 0.9842 - val_loss: 2.0892 - val_accuracy: 0.5769\n","Epoch 87/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0464 - accuracy: 0.9864 - val_loss: 2.1974 - val_accuracy: 0.5792\n","Epoch 88/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0535 - accuracy: 0.9839 - val_loss: 2.2293 - val_accuracy: 0.6086\n","Epoch 89/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0492 - accuracy: 0.9859 - val_loss: 2.1325 - val_accuracy: 0.5803\n","Epoch 90/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0594 - accuracy: 0.9810 - val_loss: 2.1626 - val_accuracy: 0.5769\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0850 - accuracy: 0.9680 - val_loss: 1.8875 - val_accuracy: 0.5871\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0739 - accuracy: 0.9745 - val_loss: 1.9169 - val_accuracy: 0.5860\n","Epoch 93/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0662 - accuracy: 0.9802 - val_loss: 2.0172 - val_accuracy: 0.5701\n","Epoch 94/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0498 - accuracy: 0.9853 - val_loss: 2.0231 - val_accuracy: 0.5973\n","Epoch 95/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0499 - accuracy: 0.9847 - val_loss: 2.0770 - val_accuracy: 0.5905\n","Epoch 96/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0464 - accuracy: 0.9861 - val_loss: 2.0096 - val_accuracy: 0.5837\n","Epoch 97/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0485 - accuracy: 0.9867 - val_loss: 2.0865 - val_accuracy: 0.5747\n","Epoch 98/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0466 - accuracy: 0.9856 - val_loss: 2.2501 - val_accuracy: 0.5781\n","Epoch 99/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0683 - accuracy: 0.9788 - val_loss: 2.0297 - val_accuracy: 0.5792\n","Epoch 100/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0529 - accuracy: 0.9850 - val_loss: 1.8689 - val_accuracy: 0.5950\n","{'loss': [0.6841362118721008, 0.6714690923690796, 0.6704952120780945, 0.6643788814544678, 0.6569987535476685, 0.6508018374443054, 0.6487763524055481, 0.6386009454727173, 0.6169493794441223, 0.6115586161613464, 0.6034845113754272, 0.5954459309577942, 0.5717443823814392, 0.6043915748596191, 0.5653247237205505, 0.5407922267913818, 0.5520665049552917, 0.5555501580238342, 0.5085063576698303, 0.5117572546005249, 0.4963034391403198, 0.47213324904441833, 0.4650440514087677, 0.44736748933792114, 0.4587096869945526, 0.4182821810245514, 0.40086883306503296, 0.37355902791023254, 0.41995805501937866, 0.3665848970413208, 0.3444001078605652, 0.323856383562088, 0.31825312972068787, 0.29567861557006836, 0.32510146498680115, 0.2939065992832184, 0.28306496143341064, 0.27301695942878723, 0.2674780786037445, 0.23213781416416168, 0.25118306279182434, 0.24984444677829742, 0.19506628811359406, 0.23268242180347443, 0.1967165172100067, 0.19804495573043823, 0.21507778763771057, 0.18099410831928253, 0.15453775227069855, 0.185415580868721, 0.16261717677116394, 0.14676228165626526, 0.13621479272842407, 0.12043192982673645, 0.17531265318393707, 0.1943216174840927, 0.18549856543540955, 0.10657312721014023, 0.11228004097938538, 0.12112792581319809, 0.10874934494495392, 0.09959985315799713, 0.08649232238531113, 0.09893464297056198, 0.09837652742862701, 0.11917725950479507, 0.08080092072486877, 0.05979491025209427, 0.08844918757677078, 0.08327030390501022, 0.11582374572753906, 0.12393815070390701, 0.12218092381954193, 0.08802817016839981, 0.07902071624994278, 0.13677434623241425, 0.10573790222406387, 0.08062002062797546, 0.06851258873939514, 0.05708113685250282, 0.03979058563709259, 0.04420091584324837, 0.04596126079559326, 0.05655718222260475, 0.06367620825767517, 0.05313381925225258, 0.046424563974142075, 0.05350000411272049, 0.04921140894293785, 0.059353720396757126, 0.08498217910528183, 0.07391191273927689, 0.06618553400039673, 0.049849823117256165, 0.049919243901968, 0.046449046581983566, 0.048501256853342056, 0.046567030251026154, 0.06828068941831589, 0.05294900760054588], 'accuracy': [0.5741369724273682, 0.5987549424171448, 0.5976231098175049, 0.6120543479919434, 0.6233729720115662, 0.6312959790229797, 0.6276174187660217, 0.6479909420013428, 0.6646859049797058, 0.6768534183502197, 0.6777023077011108, 0.6836445927619934, 0.709960401058197, 0.670062243938446, 0.7224108576774597, 0.7280701994895935, 0.7195811867713928, 0.7178834080696106, 0.7580645084381104, 0.7504244446754456, 0.761177122592926, 0.7764572501182556, 0.7792869210243225, 0.7934352159500122, 0.7818335890769958, 0.8044708371162415, 0.8143746256828308, 0.826259195804596, 0.7999433875083923, 0.8293718099594116, 0.8426712155342102, 0.8443689942359924, 0.8531408905982971, 0.8641765713691711, 0.8500282764434814, 0.8636106252670288, 0.8704017996788025, 0.8718166351318359, 0.8786078095436096, 0.8964346647262573, 0.8822863698005676, 0.8865308165550232, 0.9105829000473022, 0.8955857157707214, 0.9094510674476624, 0.9086021780967712, 0.9043576717376709, 0.9202037453651428, 0.9323712587356567, 0.9216185808181763, 0.9269949197769165, 0.9402942657470703, 0.9391624331474304, 0.9527447819709778, 0.9292586445808411, 0.9119977355003357, 0.9202037453651428, 0.9595359563827515, 0.9561403393745422, 0.9533106684684753, 0.9578381180763245, 0.9620826244354248, 0.9700056314468384, 0.9660441279411316, 0.9651952385902405, 0.9547255039215088, 0.971137523651123, 0.9827390909194946, 0.967458963394165, 0.9728353023529053, 0.9572722315788269, 0.9552914500236511, 0.9541596174240112, 0.9683078527450562, 0.9705715775489807, 0.9487832188606262, 0.9629315137863159, 0.9725523591041565, 0.9779286980628967, 0.9844368696212769, 0.9875495433807373, 0.9864176511764526, 0.9881154298782349, 0.9818902015686035, 0.9807583689689636, 0.9841539263725281, 0.9864176511764526, 0.9838709831237793, 0.9858517050743103, 0.9810413122177124, 0.9680249094963074, 0.9745330810546875, 0.9801924228668213, 0.9852858185768127, 0.9847198724746704, 0.9861347079277039, 0.9867005944252014, 0.9855687618255615, 0.9787775874137878, 0.9850028157234192], 'val_loss': [0.6959847807884216, 0.6961097121238708, 0.6962716579437256, 0.6966304779052734, 0.696945309638977, 0.6963883638381958, 0.6964004039764404, 0.6982938051223755, 0.7012770175933838, 0.7001181244850159, 0.6970562934875488, 0.6942282319068909, 0.7039568424224854, 0.6877833604812622, 0.7216976284980774, 0.7441384792327881, 0.724022388458252, 0.710768461227417, 0.7163413166999817, 0.7097873091697693, 0.683846116065979, 0.7367815375328064, 0.7103562355041504, 0.8023896813392639, 0.7238365411758423, 0.7929640412330627, 0.7882712483406067, 0.8208673596382141, 0.7870468497276306, 1.0333462953567505, 0.9480442404747009, 1.1841180324554443, 1.0629818439483643, 1.5316212177276611, 1.1190074682235718, 1.2401893138885498, 1.223875880241394, 1.1255924701690674, 1.166377305984497, 1.3040484189987183, 1.2826930284500122, 1.3344330787658691, 1.5608227252960205, 1.295268177986145, 1.4576630592346191, 1.460018277168274, 1.4205416440963745, 1.516110897064209, 1.6651405096054077, 1.5083982944488525, 1.6461328268051147, 1.6141531467437744, 1.697608470916748, 1.7249833345413208, 1.4928655624389648, 1.5793110132217407, 1.4984855651855469, 1.7329894304275513, 1.757487177848816, 1.8098092079162598, 1.9140040874481201, 1.9323810338974, 2.038050889968872, 1.8129018545150757, 2.1846699714660645, 1.7820490598678589, 1.965773344039917, 2.0503036975860596, 2.0550315380096436, 1.9746052026748657, 1.849557638168335, 1.8911489248275757, 1.8254340887069702, 1.838870644569397, 1.9659006595611572, 1.7329399585723877, 1.7315478324890137, 1.8958145380020142, 2.025986433029175, 2.0161283016204834, 2.1436898708343506, 2.240480422973633, 2.246622085571289, 2.179668664932251, 2.0852088928222656, 2.0891871452331543, 2.197406530380249, 2.229314088821411, 2.132472276687622, 2.162623167037964, 1.8874787092208862, 1.9169299602508545, 2.017235279083252, 2.023131847381592, 2.0769829750061035, 2.009629249572754, 2.086541175842285, 2.250096082687378, 2.029728889465332, 1.8688750267028809], 'val_accuracy': [0.4954751133918762, 0.49660632014274597, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.4954751133918762, 0.49660632014274597, 0.49660632014274597, 0.4954751133918762, 0.5067873597145081, 0.5158371329307556, 0.5011312365531921, 0.5633484125137329, 0.5113122463226318, 0.5067873597145081, 0.5135746598243713, 0.5395927429199219, 0.5712669491767883, 0.5723981857299805, 0.5927602052688599, 0.5961538553237915, 0.6074660420417786, 0.5859728455543518, 0.5950226187705994, 0.6165158152580261, 0.5893664956092834, 0.6029411554336548, 0.5904977321624756, 0.598416268825531, 0.5769230723381042, 0.598416268825531, 0.5791855454444885, 0.5610859990119934, 0.5837104320526123, 0.5769230723381042, 0.5791855454444885, 0.5825791954994202, 0.5882353186607361, 0.5904977321624756, 0.5961538553237915, 0.5735294222831726, 0.5746606588363647, 0.5803167223930359, 0.570135772228241, 0.5746606588363647, 0.5588235259056091, 0.581447958946228, 0.5599547624588013, 0.5757918357849121, 0.5882353186607361, 0.5633484125137329, 0.5904977321624756, 0.5927602052688599, 0.5825791954994202, 0.570135772228241, 0.564479649066925, 0.5656108856201172, 0.5904977321624756, 0.5633484125137329, 0.5723981857299805, 0.5927602052688599, 0.5633484125137329, 0.5825791954994202, 0.5588235259056091, 0.564479649066925, 0.5712669491767883, 0.5667420625686646, 0.5780543088912964, 0.5429864525794983, 0.5791855454444885, 0.5712669491767883, 0.5622171759605408, 0.5791855454444885, 0.5418552160263062, 0.5780543088912964, 0.5825791954994202, 0.5757918357849121, 0.5961538553237915, 0.5803167223930359, 0.5950226187705994, 0.5780543088912964, 0.5723981857299805, 0.5769230723381042, 0.5825791954994202, 0.5769230723381042, 0.5791855454444885, 0.6085972785949707, 0.5803167223930359, 0.5769230723381042, 0.587104082107544, 0.5859728455543518, 0.570135772228241, 0.5972850918769836, 0.5904977321624756, 0.5837104320526123, 0.5746606588363647, 0.5780543088912964, 0.5791855454444885, 0.5950226187705994]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.6918 - accuracy: 0.5501"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 59ms/step - loss: 0.6914 - accuracy: 0.5519 - val_loss: 0.6957 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6864 - accuracy: 0.5584 - val_loss: 0.6960 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6794 - accuracy: 0.5793 - val_loss: 0.6960 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6781 - accuracy: 0.5703 - val_loss: 0.6960 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6735 - accuracy: 0.5832 - val_loss: 0.6960 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6702 - accuracy: 0.5984 - val_loss: 0.6966 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6681 - accuracy: 0.5912 - val_loss: 0.6971 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6577 - accuracy: 0.6121 - val_loss: 0.6962 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6624 - accuracy: 0.6062 - val_loss: 0.6939 - val_accuracy: 0.4969\n","Epoch 10/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6592 - accuracy: 0.6067 - val_loss: 0.6967 - val_accuracy: 0.4845\n","Epoch 11/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6497 - accuracy: 0.6150 - val_loss: 0.6923 - val_accuracy: 0.5537\n","Epoch 12/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6521 - accuracy: 0.6124 - val_loss: 0.6950 - val_accuracy: 0.4855\n","Epoch 13/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6416 - accuracy: 0.6349 - val_loss: 0.6944 - val_accuracy: 0.4928\n","Epoch 14/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6372 - accuracy: 0.6388 - val_loss: 0.6969 - val_accuracy: 0.4979\n","Epoch 15/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6245 - accuracy: 0.6429 - val_loss: 0.7152 - val_accuracy: 0.4969\n","Epoch 16/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6193 - accuracy: 0.6599 - val_loss: 0.6957 - val_accuracy: 0.5382\n","Epoch 17/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6265 - accuracy: 0.6475 - val_loss: 0.6823 - val_accuracy: 0.5816\n","Epoch 18/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6187 - accuracy: 0.6491 - val_loss: 0.6672 - val_accuracy: 0.6054\n","Epoch 19/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6061 - accuracy: 0.6656 - val_loss: 0.6760 - val_accuracy: 0.6002\n","Epoch 20/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5966 - accuracy: 0.6817 - val_loss: 0.6875 - val_accuracy: 0.5775\n","Epoch 21/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5733 - accuracy: 0.6969 - val_loss: 0.6854 - val_accuracy: 0.6033\n","Epoch 22/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5820 - accuracy: 0.6873 - val_loss: 0.6720 - val_accuracy: 0.6002\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5587 - accuracy: 0.7070 - val_loss: 0.7382 - val_accuracy: 0.5744\n","Epoch 24/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5457 - accuracy: 0.7173 - val_loss: 0.7062 - val_accuracy: 0.5888\n","Epoch 25/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5315 - accuracy: 0.7390 - val_loss: 0.7086 - val_accuracy: 0.6043\n","Epoch 26/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4870 - accuracy: 0.7561 - val_loss: 0.7911 - val_accuracy: 0.6002\n","Epoch 27/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4959 - accuracy: 0.7519 - val_loss: 0.7400 - val_accuracy: 0.5950\n","Epoch 28/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4838 - accuracy: 0.7643 - val_loss: 0.9178 - val_accuracy: 0.5548\n","Epoch 29/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4593 - accuracy: 0.7765 - val_loss: 0.8182 - val_accuracy: 0.5878\n","Epoch 30/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4405 - accuracy: 0.7863 - val_loss: 0.8310 - val_accuracy: 0.6023\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4051 - accuracy: 0.8052 - val_loss: 0.9406 - val_accuracy: 0.5919\n","Epoch 32/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3840 - accuracy: 0.8233 - val_loss: 0.8901 - val_accuracy: 0.5930\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3814 - accuracy: 0.8142 - val_loss: 0.9356 - val_accuracy: 0.5785\n","Epoch 34/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3797 - accuracy: 0.8165 - val_loss: 0.9941 - val_accuracy: 0.5744\n","Epoch 35/100\n","31/31 [==============================] - 1s 48ms/step - loss: 0.3520 - accuracy: 0.8380 - val_loss: 0.8796 - val_accuracy: 0.6229\n","Epoch 36/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3325 - accuracy: 0.8411 - val_loss: 1.0921 - val_accuracy: 0.5620\n","Epoch 37/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3037 - accuracy: 0.8612 - val_loss: 1.1211 - val_accuracy: 0.5930\n","Epoch 38/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2804 - accuracy: 0.8731 - val_loss: 1.3030 - val_accuracy: 0.5558\n","Epoch 39/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3163 - accuracy: 0.8579 - val_loss: 1.0494 - val_accuracy: 0.5620\n","Epoch 40/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2572 - accuracy: 0.8899 - val_loss: 1.1999 - val_accuracy: 0.5961\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2359 - accuracy: 0.8984 - val_loss: 1.2406 - val_accuracy: 0.5981\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3257 - accuracy: 0.8540 - val_loss: 1.1669 - val_accuracy: 0.5930\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2382 - accuracy: 0.8917 - val_loss: 1.2500 - val_accuracy: 0.5888\n","Epoch 44/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2152 - accuracy: 0.9044 - val_loss: 1.1830 - val_accuracy: 0.5744\n","Epoch 45/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2010 - accuracy: 0.9134 - val_loss: 1.5950 - val_accuracy: 0.5723\n","Epoch 46/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2359 - accuracy: 0.8928 - val_loss: 1.2837 - val_accuracy: 0.5764\n","Epoch 47/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1916 - accuracy: 0.9137 - val_loss: 1.5853 - val_accuracy: 0.5496\n","Epoch 48/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1776 - accuracy: 0.9238 - val_loss: 1.3540 - val_accuracy: 0.5837\n","Epoch 49/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.1660 - accuracy: 0.9261 - val_loss: 1.5972 - val_accuracy: 0.5868\n","Epoch 50/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.2227 - accuracy: 0.9072 - val_loss: 1.4065 - val_accuracy: 0.6002\n","Epoch 51/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2229 - accuracy: 0.9049 - val_loss: 1.2911 - val_accuracy: 0.5888\n","Epoch 52/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1965 - accuracy: 0.9196 - val_loss: 1.3275 - val_accuracy: 0.5775\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1621 - accuracy: 0.9315 - val_loss: 1.4819 - val_accuracy: 0.5930\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1383 - accuracy: 0.9434 - val_loss: 1.5925 - val_accuracy: 0.5888\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1058 - accuracy: 0.9581 - val_loss: 1.7622 - val_accuracy: 0.6147\n","Epoch 56/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1392 - accuracy: 0.9424 - val_loss: 1.6260 - val_accuracy: 0.5826\n","Epoch 57/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1282 - accuracy: 0.9496 - val_loss: 1.5986 - val_accuracy: 0.6054\n","Epoch 58/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1245 - accuracy: 0.9504 - val_loss: 1.7358 - val_accuracy: 0.5733\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0995 - accuracy: 0.9615 - val_loss: 1.7431 - val_accuracy: 0.5919\n","Epoch 60/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0933 - accuracy: 0.9649 - val_loss: 1.9962 - val_accuracy: 0.5930\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1257 - accuracy: 0.9525 - val_loss: 1.7816 - val_accuracy: 0.5558\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1671 - accuracy: 0.9367 - val_loss: 1.5137 - val_accuracy: 0.5486\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1089 - accuracy: 0.9568 - val_loss: 1.7028 - val_accuracy: 0.5899\n","Epoch 64/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0718 - accuracy: 0.9747 - val_loss: 2.0098 - val_accuracy: 0.5764\n","Epoch 65/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1072 - accuracy: 0.9589 - val_loss: 1.9292 - val_accuracy: 0.5702\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1280 - accuracy: 0.9473 - val_loss: 1.6674 - val_accuracy: 0.6023\n","Epoch 67/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0907 - accuracy: 0.9698 - val_loss: 1.9028 - val_accuracy: 0.5630\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0786 - accuracy: 0.9705 - val_loss: 1.8437 - val_accuracy: 0.5682\n","Epoch 69/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0794 - accuracy: 0.9705 - val_loss: 2.0037 - val_accuracy: 0.5702\n","Epoch 70/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.1081 - accuracy: 0.9597 - val_loss: 1.9679 - val_accuracy: 0.5733\n","Epoch 71/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0919 - accuracy: 0.9656 - val_loss: 1.9114 - val_accuracy: 0.5930\n","Epoch 72/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0928 - accuracy: 0.9661 - val_loss: 1.9209 - val_accuracy: 0.5816\n","Epoch 73/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0743 - accuracy: 0.9739 - val_loss: 2.0683 - val_accuracy: 0.5868\n","Epoch 74/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1351 - accuracy: 0.9486 - val_loss: 1.6709 - val_accuracy: 0.5754\n","Epoch 75/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1108 - accuracy: 0.9597 - val_loss: 1.6852 - val_accuracy: 0.5909\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0687 - accuracy: 0.9798 - val_loss: 1.9760 - val_accuracy: 0.5806\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0782 - accuracy: 0.9742 - val_loss: 1.9839 - val_accuracy: 0.5692\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0929 - accuracy: 0.9656 - val_loss: 1.8435 - val_accuracy: 0.5961\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1041 - accuracy: 0.9646 - val_loss: 1.7798 - val_accuracy: 0.5857\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0709 - accuracy: 0.9796 - val_loss: 2.0684 - val_accuracy: 0.5878\n","Epoch 81/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0907 - accuracy: 0.9682 - val_loss: 1.9434 - val_accuracy: 0.5857\n","Epoch 82/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0727 - accuracy: 0.9747 - val_loss: 2.0080 - val_accuracy: 0.5878\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0430 - accuracy: 0.9863 - val_loss: 2.0772 - val_accuracy: 0.5940\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0452 - accuracy: 0.9855 - val_loss: 2.1719 - val_accuracy: 0.5961\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0491 - accuracy: 0.9853 - val_loss: 2.1761 - val_accuracy: 0.5878\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0381 - accuracy: 0.9891 - val_loss: 2.2411 - val_accuracy: 0.5713\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0339 - accuracy: 0.9910 - val_loss: 2.3924 - val_accuracy: 0.5806\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0325 - accuracy: 0.9910 - val_loss: 2.4510 - val_accuracy: 0.5754\n","Epoch 89/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0353 - accuracy: 0.9904 - val_loss: 2.3804 - val_accuracy: 0.5764\n","Epoch 90/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0415 - accuracy: 0.9886 - val_loss: 2.3576 - val_accuracy: 0.5630\n","Epoch 91/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4536 - accuracy: 0.8251 - val_loss: 0.8931 - val_accuracy: 0.5692\n","Epoch 92/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2012 - accuracy: 0.9181 - val_loss: 1.6709 - val_accuracy: 0.5599\n","Epoch 93/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0734 - accuracy: 0.9762 - val_loss: 1.9041 - val_accuracy: 0.5785\n","Epoch 94/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0793 - accuracy: 0.9739 - val_loss: 1.8567 - val_accuracy: 0.5868\n","Epoch 95/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0433 - accuracy: 0.9871 - val_loss: 2.1992 - val_accuracy: 0.5744\n","Epoch 96/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0435 - accuracy: 0.9860 - val_loss: 2.2527 - val_accuracy: 0.5568\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0563 - accuracy: 0.9817 - val_loss: 2.2674 - val_accuracy: 0.5671\n","Epoch 98/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0904 - accuracy: 0.9693 - val_loss: 1.9594 - val_accuracy: 0.5795\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0750 - accuracy: 0.9749 - val_loss: 1.9236 - val_accuracy: 0.5754\n","Epoch 100/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0520 - accuracy: 0.9835 - val_loss: 2.1853 - val_accuracy: 0.5826\n","{'loss': [0.6914231181144714, 0.6864413022994995, 0.679406464099884, 0.6781319379806519, 0.6735438704490662, 0.6702425479888916, 0.6681008338928223, 0.6577374339103699, 0.6623933911323547, 0.6592320203781128, 0.6497418880462646, 0.6520559787750244, 0.6416351795196533, 0.6372218728065491, 0.6245289444923401, 0.6193385124206543, 0.6265271306037903, 0.6187118291854858, 0.6061192154884338, 0.596638560295105, 0.5732530951499939, 0.5820274353027344, 0.5587155222892761, 0.5456811189651489, 0.5315155982971191, 0.48702582716941833, 0.4958859384059906, 0.4837835431098938, 0.45930013060569763, 0.4404628276824951, 0.4050813615322113, 0.38397374749183655, 0.3813987374305725, 0.3796839118003845, 0.351980596780777, 0.3325152099132538, 0.3037002682685852, 0.28041476011276245, 0.31625792384147644, 0.2572019100189209, 0.23589171469211578, 0.32565873861312866, 0.23819367587566376, 0.21516720950603485, 0.2009986788034439, 0.23592033982276917, 0.19159124791622162, 0.17756828665733337, 0.1659674346446991, 0.22272495925426483, 0.22285054624080658, 0.19647373259067535, 0.16210801899433136, 0.13829587399959564, 0.1057666689157486, 0.13918755948543549, 0.12819309532642365, 0.1245194599032402, 0.09949937462806702, 0.0932558998465538, 0.12572821974754333, 0.16713176667690277, 0.10894245654344559, 0.07177799940109253, 0.10724999755620956, 0.12804380059242249, 0.09074317663908005, 0.07863303273916245, 0.07937748730182648, 0.10806698352098465, 0.09187252819538116, 0.09280995279550552, 0.07426515966653824, 0.1350822150707245, 0.11080516874790192, 0.06866034120321274, 0.07815200835466385, 0.09288539737462997, 0.10412255674600601, 0.07089212536811829, 0.09067662060260773, 0.07268784940242767, 0.043025221675634384, 0.04515386372804642, 0.04913751035928726, 0.03813733160495758, 0.033886197954416275, 0.03253019228577614, 0.03530243784189224, 0.04151885583996773, 0.45358386635780334, 0.20118415355682373, 0.0733935758471489, 0.07932449132204056, 0.04333769157528877, 0.043517131358385086, 0.0562702976167202, 0.09041164070367813, 0.07502470165491104, 0.05198550969362259], 'accuracy': [0.551937997341156, 0.5583979487419128, 0.579328179359436, 0.5702842473983765, 0.5832041501998901, 0.5984495878219604, 0.5912144780158997, 0.6121447086334229, 0.6062015295028687, 0.6067183613777161, 0.6149870753288269, 0.6124030947685242, 0.6348837018013, 0.6387596726417542, 0.6428940296173096, 0.6599483489990234, 0.6475452184677124, 0.6490955948829651, 0.6656330823898315, 0.6816537380218506, 0.6968992352485657, 0.6873385310173035, 0.7069767713546753, 0.7173126339912415, 0.7390180826187134, 0.7560723423957825, 0.751937985420227, 0.7643410563468933, 0.776485800743103, 0.7863048911094666, 0.8051679730415344, 0.8232558369636536, 0.814211905002594, 0.8165374398231506, 0.8379845023155212, 0.8410852551460266, 0.8612403273582458, 0.8731266260147095, 0.8578811287879944, 0.8899224996566772, 0.8984495997428894, 0.8540051579475403, 0.8917312622070312, 0.9043927788734436, 0.9134367108345032, 0.8927648663520813, 0.9136950969696045, 0.9237726330757141, 0.9260981678962708, 0.9072351455688477, 0.9049095511436462, 0.9196382164955139, 0.9315245747566223, 0.9434108734130859, 0.9581395387649536, 0.9423772692680359, 0.9496123790740967, 0.9503875970840454, 0.9614987373352051, 0.9648578763008118, 0.9524548053741455, 0.9366925358772278, 0.9568475484848022, 0.9746770262718201, 0.9589147567749023, 0.94728684425354, 0.9697674512863159, 0.9705426096916199, 0.9705426096916199, 0.9596899151802063, 0.9656330943107605, 0.9661498665809631, 0.9739018082618713, 0.9485788345336914, 0.9596899151802063, 0.9798449873924255, 0.9741601943969727, 0.9656330943107605, 0.9645994901657104, 0.9795865416526794, 0.9682170748710632, 0.9746770262718201, 0.9863049387931824, 0.9855297207832336, 0.9852713346481323, 0.9891473054885864, 0.9909560680389404, 0.9909560680389404, 0.9904392957687378, 0.988630473613739, 0.8250645995140076, 0.9180878400802612, 0.9762274026870728, 0.9739018082618713, 0.9870800971984863, 0.9860464930534363, 0.9816537499427795, 0.9692506194114685, 0.9749354124069214, 0.9834625124931335], 'val_loss': [0.6956511735916138, 0.695969820022583, 0.6959552764892578, 0.6959911584854126, 0.6959742307662964, 0.6966408491134644, 0.6971437931060791, 0.6961613893508911, 0.6939461827278137, 0.6966946721076965, 0.6922829151153564, 0.6950176358222961, 0.6944135427474976, 0.6968710422515869, 0.7151891589164734, 0.6957285404205322, 0.6823464632034302, 0.6671819090843201, 0.6759738922119141, 0.6874814033508301, 0.685355007648468, 0.6719639897346497, 0.7382117509841919, 0.7061845064163208, 0.7086039185523987, 0.7911423444747925, 0.7399871945381165, 0.9178336262702942, 0.8182105422019958, 0.8309657573699951, 0.9406136870384216, 0.8901191353797913, 0.9355852603912354, 0.9940817356109619, 0.8796233534812927, 1.0920884609222412, 1.121114730834961, 1.3029593229293823, 1.0494362115859985, 1.1999197006225586, 1.2406437397003174, 1.1668673753738403, 1.2500423192977905, 1.1830449104309082, 1.5949883460998535, 1.2837268114089966, 1.5852621793746948, 1.354020118713379, 1.5972492694854736, 1.4064563512802124, 1.2910716533660889, 1.327487826347351, 1.4818735122680664, 1.5925086736679077, 1.7621625661849976, 1.6260387897491455, 1.5985578298568726, 1.7357838153839111, 1.7430548667907715, 1.9962061643600464, 1.7816351652145386, 1.5137461423873901, 1.7027610540390015, 2.009784698486328, 1.9291588068008423, 1.6674391031265259, 1.9028372764587402, 1.8436672687530518, 2.003716468811035, 1.9679068326950073, 1.9114137887954712, 1.9208601713180542, 2.0683481693267822, 1.6708836555480957, 1.6851537227630615, 1.9760124683380127, 1.9839491844177246, 1.8434799909591675, 1.7798445224761963, 2.068441152572632, 1.943369746208191, 2.008007526397705, 2.0771734714508057, 2.17191481590271, 2.1761372089385986, 2.241056442260742, 2.3924009799957275, 2.4510340690612793, 2.380373477935791, 2.357591390609741, 0.8931221961975098, 1.6709316968917847, 1.9040508270263672, 1.8567042350769043, 2.1992475986480713, 2.2526559829711914, 2.26739764213562, 1.9593515396118164, 1.9236040115356445, 2.18526554107666], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4969008266925812, 0.4845041334629059, 0.5537189841270447, 0.48553720116615295, 0.4927685856819153, 0.49793389439582825, 0.4969008266925812, 0.538223147392273, 0.5816115736961365, 0.60537189245224, 0.6002066135406494, 0.577479362487793, 0.6033057570457458, 0.6002066135406494, 0.5743801593780518, 0.5888429880142212, 0.6043388247489929, 0.6002066135406494, 0.5950413346290588, 0.5547520518302917, 0.5878099203109741, 0.6022727489471436, 0.5919421315193176, 0.5929751992225647, 0.5785123705863953, 0.5743801593780518, 0.6229338645935059, 0.5619834661483765, 0.5929751992225647, 0.5557851195335388, 0.5619834661483765, 0.5960744023323059, 0.5981404781341553, 0.5929751992225647, 0.5888429880142212, 0.5743801593780518, 0.5723140239715576, 0.5764462947845459, 0.5495867729187012, 0.5836777091026306, 0.586776852607727, 0.6002066135406494, 0.5888429880142212, 0.577479362487793, 0.5929751992225647, 0.5888429880142212, 0.6146694421768188, 0.5826446413993835, 0.60537189245224, 0.5733470916748047, 0.5919421315193176, 0.5929751992225647, 0.5557851195335388, 0.5485537052154541, 0.5898760557174683, 0.5764462947845459, 0.5702479481697083, 0.6022727489471436, 0.5630165338516235, 0.5681818127632141, 0.5702479481697083, 0.5733470916748047, 0.5929751992225647, 0.5816115736961365, 0.586776852607727, 0.5754132270812988, 0.5909090638160706, 0.5805785059928894, 0.5692148804664612, 0.5960744023323059, 0.58574378490448, 0.5878099203109741, 0.58574378490448, 0.5878099203109741, 0.5940082669258118, 0.5960744023323059, 0.5878099203109741, 0.5712810158729553, 0.5805785059928894, 0.5754132270812988, 0.5764462947845459, 0.5630165338516235, 0.5692148804664612, 0.5599173307418823, 0.5785123705863953, 0.586776852607727, 0.5743801593780518, 0.5568181872367859, 0.567148745059967, 0.5795454382896423, 0.5754132270812988, 0.5826446413993835]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.3985 - accuracy: 0.8341"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 60ms/step - loss: 0.3869 - accuracy: 0.8376 - val_loss: 0.7699 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2464 - accuracy: 0.9003 - val_loss: 0.8199 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1834 - accuracy: 0.9286 - val_loss: 0.8648 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1778 - accuracy: 0.9294 - val_loss: 0.9136 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1242 - accuracy: 0.9534 - val_loss: 1.0626 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1349 - accuracy: 0.9467 - val_loss: 1.1970 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1409 - accuracy: 0.9467 - val_loss: 1.1302 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1017 - accuracy: 0.9661 - val_loss: 1.3583 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1070 - accuracy: 0.9591 - val_loss: 1.4586 - val_accuracy: 0.4849\n","Epoch 10/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1101 - accuracy: 0.9615 - val_loss: 1.5979 - val_accuracy: 0.4849\n","Epoch 11/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0844 - accuracy: 0.9696 - val_loss: 1.6630 - val_accuracy: 0.4849\n","Epoch 12/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.0877 - accuracy: 0.9725 - val_loss: 1.8162 - val_accuracy: 0.4871\n","Epoch 13/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.0968 - accuracy: 0.9626 - val_loss: 1.4981 - val_accuracy: 0.4989\n","Epoch 14/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1185 - accuracy: 0.9564 - val_loss: 1.5151 - val_accuracy: 0.4957\n","Epoch 15/100\n","29/29 [==============================] - 1s 35ms/step - loss: 0.0839 - accuracy: 0.9725 - val_loss: 1.4287 - val_accuracy: 0.5108\n","Epoch 16/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0803 - accuracy: 0.9728 - val_loss: 1.3543 - val_accuracy: 0.5162\n","Epoch 17/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0853 - accuracy: 0.9698 - val_loss: 1.6076 - val_accuracy: 0.5022\n","Epoch 18/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.1053 - accuracy: 0.9661 - val_loss: 1.0174 - val_accuracy: 0.5905\n","Epoch 19/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0960 - accuracy: 0.9682 - val_loss: 0.9174 - val_accuracy: 0.6185\n","Epoch 20/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0647 - accuracy: 0.9766 - val_loss: 1.2464 - val_accuracy: 0.6121\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0513 - accuracy: 0.9828 - val_loss: 1.3779 - val_accuracy: 0.6024\n","Epoch 22/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0644 - accuracy: 0.9784 - val_loss: 1.0043 - val_accuracy: 0.6692\n","Epoch 23/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0829 - accuracy: 0.9725 - val_loss: 1.0924 - val_accuracy: 0.6498\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0979 - accuracy: 0.9642 - val_loss: 1.4083 - val_accuracy: 0.5981\n","Epoch 25/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.1252 - accuracy: 0.9601 - val_loss: 0.9356 - val_accuracy: 0.6767\n","Epoch 26/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0421 - accuracy: 0.9873 - val_loss: 1.2534 - val_accuracy: 0.6940\n","Epoch 27/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0328 - accuracy: 0.9906 - val_loss: 1.3280 - val_accuracy: 0.7037\n","Epoch 28/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0353 - accuracy: 0.9908 - val_loss: 1.3787 - val_accuracy: 0.6864\n","Epoch 29/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0649 - accuracy: 0.9782 - val_loss: 1.2797 - val_accuracy: 0.6961\n","Epoch 30/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0687 - accuracy: 0.9793 - val_loss: 1.2224 - val_accuracy: 0.6886\n","Epoch 31/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0601 - accuracy: 0.9809 - val_loss: 1.2477 - val_accuracy: 0.6907\n","Epoch 32/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0466 - accuracy: 0.9849 - val_loss: 1.5104 - val_accuracy: 0.6627\n","Epoch 33/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0697 - accuracy: 0.9768 - val_loss: 1.4137 - val_accuracy: 0.6487\n","Epoch 34/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0444 - accuracy: 0.9865 - val_loss: 1.4372 - val_accuracy: 0.6875\n","Epoch 35/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0348 - accuracy: 0.9903 - val_loss: 1.4394 - val_accuracy: 0.6800\n","Epoch 36/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0359 - accuracy: 0.9903 - val_loss: 1.4969 - val_accuracy: 0.6940\n","Epoch 37/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0557 - accuracy: 0.9820 - val_loss: 1.3848 - val_accuracy: 0.6789\n","Epoch 38/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0637 - accuracy: 0.9790 - val_loss: 1.4697 - val_accuracy: 0.6595\n","Epoch 39/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0563 - accuracy: 0.9830 - val_loss: 1.3681 - val_accuracy: 0.6767\n","Epoch 40/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0439 - accuracy: 0.9860 - val_loss: 1.3763 - val_accuracy: 0.6821\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0393 - accuracy: 0.9890 - val_loss: 1.5457 - val_accuracy: 0.6756\n","Epoch 42/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0471 - accuracy: 0.9844 - val_loss: 1.4346 - val_accuracy: 0.6886\n","Epoch 43/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0794 - accuracy: 0.9725 - val_loss: 1.2754 - val_accuracy: 0.6692\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0685 - accuracy: 0.9776 - val_loss: 1.2795 - val_accuracy: 0.6756\n","Epoch 45/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0661 - accuracy: 0.9782 - val_loss: 1.3489 - val_accuracy: 0.6767\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0712 - accuracy: 0.9749 - val_loss: 1.2787 - val_accuracy: 0.6778\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0649 - accuracy: 0.9763 - val_loss: 1.4083 - val_accuracy: 0.6606\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0487 - accuracy: 0.9849 - val_loss: 1.6385 - val_accuracy: 0.6476\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0416 - accuracy: 0.9871 - val_loss: 1.4916 - val_accuracy: 0.6681\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0359 - accuracy: 0.9900 - val_loss: 1.4225 - val_accuracy: 0.6907\n","Epoch 51/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0404 - accuracy: 0.9879 - val_loss: 1.4418 - val_accuracy: 0.6692\n","Epoch 52/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0381 - accuracy: 0.9908 - val_loss: 1.5410 - val_accuracy: 0.6659\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0238 - accuracy: 0.9941 - val_loss: 1.5785 - val_accuracy: 0.6670\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0257 - accuracy: 0.9943 - val_loss: 1.6390 - val_accuracy: 0.6767\n","Epoch 55/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0326 - accuracy: 0.9898 - val_loss: 1.5273 - val_accuracy: 0.6703\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0326 - accuracy: 0.9914 - val_loss: 1.5940 - val_accuracy: 0.6670\n","Epoch 57/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0401 - accuracy: 0.9898 - val_loss: 1.6373 - val_accuracy: 0.6573\n","Epoch 58/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0481 - accuracy: 0.9849 - val_loss: 1.4443 - val_accuracy: 0.6864\n","Epoch 59/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0784 - accuracy: 0.9768 - val_loss: 1.3933 - val_accuracy: 0.6843\n","Epoch 60/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0675 - accuracy: 0.9793 - val_loss: 1.4036 - val_accuracy: 0.6638\n","Epoch 61/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0685 - accuracy: 0.9795 - val_loss: 1.4217 - val_accuracy: 0.6735\n","Epoch 62/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0951 - accuracy: 0.9690 - val_loss: 1.2473 - val_accuracy: 0.6778\n","Epoch 63/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0452 - accuracy: 0.9865 - val_loss: 1.4340 - val_accuracy: 0.6681\n","Epoch 64/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0327 - accuracy: 0.9900 - val_loss: 1.5111 - val_accuracy: 0.6800\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0269 - accuracy: 0.9927 - val_loss: 1.5160 - val_accuracy: 0.6692\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0257 - accuracy: 0.9941 - val_loss: 1.6225 - val_accuracy: 0.6713\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0301 - accuracy: 0.9916 - val_loss: 1.5798 - val_accuracy: 0.6681\n","Epoch 68/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0293 - accuracy: 0.9914 - val_loss: 1.6719 - val_accuracy: 0.6692\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0586 - accuracy: 0.9825 - val_loss: 1.4764 - val_accuracy: 0.6886\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0615 - accuracy: 0.9803 - val_loss: 1.3723 - val_accuracy: 0.6735\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0502 - accuracy: 0.9846 - val_loss: 1.4763 - val_accuracy: 0.6767\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0471 - accuracy: 0.9844 - val_loss: 1.5539 - val_accuracy: 0.6638\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0497 - accuracy: 0.9855 - val_loss: 1.4019 - val_accuracy: 0.6800\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0291 - accuracy: 0.9908 - val_loss: 1.4886 - val_accuracy: 0.6724\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0254 - accuracy: 0.9927 - val_loss: 1.6898 - val_accuracy: 0.6692\n","Epoch 76/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0232 - accuracy: 0.9941 - val_loss: 1.6607 - val_accuracy: 0.6681\n","Epoch 77/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0209 - accuracy: 0.9954 - val_loss: 1.6622 - val_accuracy: 0.6681\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0197 - accuracy: 0.9970 - val_loss: 1.7267 - val_accuracy: 0.6681\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0252 - accuracy: 0.9935 - val_loss: 1.6158 - val_accuracy: 0.6519\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0483 - accuracy: 0.9838 - val_loss: 1.6440 - val_accuracy: 0.6444\n","Epoch 81/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0512 - accuracy: 0.9838 - val_loss: 1.4943 - val_accuracy: 0.6703\n","Epoch 82/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0383 - accuracy: 0.9900 - val_loss: 1.5776 - val_accuracy: 0.6724\n","Epoch 83/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0406 - accuracy: 0.9881 - val_loss: 1.5793 - val_accuracy: 0.6616\n","Epoch 84/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0411 - accuracy: 0.9876 - val_loss: 1.5238 - val_accuracy: 0.6735\n","Epoch 85/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0345 - accuracy: 0.9898 - val_loss: 1.5612 - val_accuracy: 0.6778\n","Epoch 86/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0227 - accuracy: 0.9946 - val_loss: 1.6223 - val_accuracy: 0.6756\n","Epoch 87/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0179 - accuracy: 0.9957 - val_loss: 1.6702 - val_accuracy: 0.6713\n","Epoch 88/100\n","29/29 [==============================] - 1s 37ms/step - loss: 0.0213 - accuracy: 0.9952 - val_loss: 1.5966 - val_accuracy: 0.6713\n","Epoch 89/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.0169 - accuracy: 0.9968 - val_loss: 1.6832 - val_accuracy: 0.6681\n","Epoch 90/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.0192 - accuracy: 0.9960 - val_loss: 1.5719 - val_accuracy: 0.6800\n","Epoch 91/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.0198 - accuracy: 0.9957 - val_loss: 1.7965 - val_accuracy: 0.6627\n","Epoch 92/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0215 - accuracy: 0.9943 - val_loss: 1.5986 - val_accuracy: 0.6649\n","Epoch 93/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0228 - accuracy: 0.9930 - val_loss: 1.6182 - val_accuracy: 0.6703\n","Epoch 94/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0395 - accuracy: 0.9881 - val_loss: 1.5715 - val_accuracy: 0.6573\n","Epoch 95/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0523 - accuracy: 0.9828 - val_loss: 1.7065 - val_accuracy: 0.6455\n","Epoch 96/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0445 - accuracy: 0.9890 - val_loss: 1.3034 - val_accuracy: 0.6703\n","Epoch 97/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0304 - accuracy: 0.9930 - val_loss: 1.9019 - val_accuracy: 0.6573\n","Epoch 98/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0500 - accuracy: 0.9865 - val_loss: 1.6504 - val_accuracy: 0.6616\n","Epoch 99/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0878 - accuracy: 0.9679 - val_loss: 1.3488 - val_accuracy: 0.6444\n","Epoch 100/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0507 - accuracy: 0.9863 - val_loss: 1.7424 - val_accuracy: 0.6455\n","{'loss': [0.3869226574897766, 0.24644550681114197, 0.18335337936878204, 0.1778203547000885, 0.12418049573898315, 0.13489075005054474, 0.14094612002372742, 0.1017497107386589, 0.1070382297039032, 0.11012817174196243, 0.08438821136951447, 0.0876929834485054, 0.09680591523647308, 0.11854291707277298, 0.08390871435403824, 0.08028772473335266, 0.0852808877825737, 0.10531877726316452, 0.09595657885074615, 0.06466272473335266, 0.05128127709031105, 0.06444801390171051, 0.08292978256940842, 0.09787091612815857, 0.12517966330051422, 0.04212446138262749, 0.03284702077507973, 0.03534848615527153, 0.0649413987994194, 0.06869002431631088, 0.06007329374551773, 0.04661795124411583, 0.06965503841638565, 0.04435894638299942, 0.03480720892548561, 0.03593655675649643, 0.05567217990756035, 0.06372573971748352, 0.05630548298358917, 0.04394980147480965, 0.039326220750808716, 0.04710887745022774, 0.07938788086175919, 0.06853508204221725, 0.06612522155046463, 0.07116754353046417, 0.06494954228401184, 0.04868674650788307, 0.04163705185055733, 0.03589841350913048, 0.040407951921224594, 0.03813401609659195, 0.02376336045563221, 0.025722172111272812, 0.0325811430811882, 0.032633133232593536, 0.04006500542163849, 0.048118747770786285, 0.0783856213092804, 0.06748118251562119, 0.06846705824136734, 0.09505882859230042, 0.045154839754104614, 0.032660193741321564, 0.02694716490805149, 0.025726886466145515, 0.03006085194647312, 0.02928466722369194, 0.05859876796603203, 0.06146182864904404, 0.05015107989311218, 0.047090083360672, 0.049674343317747116, 0.029068710282444954, 0.025353582575917244, 0.02318193018436432, 0.02094615250825882, 0.019713006913661957, 0.025157475844025612, 0.0483345091342926, 0.051170628517866135, 0.03829512745141983, 0.040556762367486954, 0.04108860716223717, 0.03452621400356293, 0.02268342114984989, 0.017939236015081406, 0.021252229809761047, 0.01687469705939293, 0.01915932260453701, 0.019763097167015076, 0.021525735035538673, 0.02280454710125923, 0.03952579200267792, 0.05228852480649948, 0.04450440779328346, 0.03040289133787155, 0.04998312145471573, 0.08775191009044647, 0.05069254711270332], 'accuracy': [0.837553858757019, 0.9003232717514038, 0.9286099076271057, 0.9294180870056152, 0.9533944129943848, 0.946659505367279, 0.946659505367279, 0.9660560488700867, 0.9590517282485962, 0.9614762663841248, 0.9695581793785095, 0.9725215435028076, 0.962553858757019, 0.9563577771186829, 0.9725215435028076, 0.9727909564971924, 0.9698275923728943, 0.9660560488700867, 0.9682112336158752, 0.9765625, 0.982758641242981, 0.9784482717514038, 0.9725215435028076, 0.9641702771186829, 0.9601293206214905, 0.9873383641242981, 0.990571141242981, 0.990840494632721, 0.978178858757019, 0.9792564511299133, 0.9808728694915771, 0.9849137663841248, 0.9768319129943848, 0.9865301847457886, 0.9903017282485962, 0.9903017282485962, 0.9819504022598267, 0.9789870977401733, 0.983027994632721, 0.985991358757019, 0.9889547228813171, 0.984375, 0.9725215435028076, 0.9776400923728943, 0.978178858757019, 0.974946141242981, 0.9762930870056152, 0.9849137663841248, 0.9870689511299133, 0.9900323152542114, 0.9878771305084229, 0.990840494632721, 0.9940732717514038, 0.9943426847457886, 0.9897629022598267, 0.9913793206214905, 0.9897629022598267, 0.9849137663841248, 0.9768319129943848, 0.9792564511299133, 0.9795258641242981, 0.9690194129943848, 0.9865301847457886, 0.9900323152542114, 0.9927262663841248, 0.9940732717514038, 0.9916487336158752, 0.9913793206214905, 0.9824892282485962, 0.9803340435028076, 0.9846444129943848, 0.984375, 0.9854525923728943, 0.990840494632721, 0.9927262663841248, 0.9940732717514038, 0.9954202771186829, 0.9970366358757019, 0.993534505367279, 0.9838362336158752, 0.9838362336158752, 0.9900323152542114, 0.9881465435028076, 0.9876077771186829, 0.9897629022598267, 0.9946120977401733, 0.9956896305084229, 0.9951508641242981, 0.9967672228813171, 0.9959590435028076, 0.9956896305084229, 0.9943426847457886, 0.9929956793785095, 0.9881465435028076, 0.982758641242981, 0.9889547228813171, 0.9929956793785095, 0.9865301847457886, 0.9679418206214905, 0.9862607717514038], 'val_loss': [0.7699445486068726, 0.8199374079704285, 0.8647500872612, 0.9135677218437195, 1.0625967979431152, 1.1969927549362183, 1.1302037239074707, 1.3583241701126099, 1.458647608757019, 1.597870111465454, 1.6630085706710815, 1.8161892890930176, 1.4981495141983032, 1.5151419639587402, 1.4287132024765015, 1.3543164730072021, 1.6075940132141113, 1.017362117767334, 0.9174064993858337, 1.246415138244629, 1.377913475036621, 1.0043286085128784, 1.0923930406570435, 1.408292531967163, 0.9356256723403931, 1.2534011602401733, 1.3279789686203003, 1.3787462711334229, 1.2797054052352905, 1.222415804862976, 1.2477251291275024, 1.5104138851165771, 1.4136593341827393, 1.4371663331985474, 1.4394121170043945, 1.4969236850738525, 1.3847767114639282, 1.4696846008300781, 1.3680610656738281, 1.37630033493042, 1.545673131942749, 1.4346017837524414, 1.27543306350708, 1.2794945240020752, 1.3488863706588745, 1.278742790222168, 1.4082891941070557, 1.638458013534546, 1.4916150569915771, 1.422546148300171, 1.441763997077942, 1.540977954864502, 1.578475832939148, 1.6390358209609985, 1.5273319482803345, 1.593960165977478, 1.637264370918274, 1.444304347038269, 1.3933087587356567, 1.4036331176757812, 1.4217429161071777, 1.2473273277282715, 1.4339540004730225, 1.5111174583435059, 1.516040325164795, 1.6225275993347168, 1.579777717590332, 1.671886920928955, 1.4764299392700195, 1.372314214706421, 1.4762794971466064, 1.5539263486862183, 1.40194833278656, 1.4886459112167358, 1.689759373664856, 1.660712718963623, 1.6622406244277954, 1.726745367050171, 1.615814447402954, 1.6439906358718872, 1.4943145513534546, 1.5776315927505493, 1.5792616605758667, 1.5237537622451782, 1.5612154006958008, 1.6223496198654175, 1.670173168182373, 1.5965996980667114, 1.683242917060852, 1.5719069242477417, 1.7964832782745361, 1.5986379384994507, 1.6182008981704712, 1.5714645385742188, 1.7064756155014038, 1.3034344911575317, 1.90190851688385, 1.650391697883606, 1.3487871885299683, 1.74238121509552], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48706895112991333, 0.4989224076271057, 0.49568966031074524, 0.5107758641242981, 0.5161637663841248, 0.5021551847457886, 0.5905172228813171, 0.618534505367279, 0.6120689511299133, 0.6023706793785095, 0.6691810488700867, 0.649784505367279, 0.5980603694915771, 0.6767241358757019, 0.693965494632721, 0.7036637663841248, 0.6864224076271057, 0.6961206793785095, 0.6885775923728943, 0.6907327771186829, 0.662715494632721, 0.6487069129943848, 0.6875, 0.6799569129943848, 0.693965494632721, 0.6788793206214905, 0.6594827771186829, 0.6767241358757019, 0.6821120977401733, 0.6756465435028076, 0.6885775923728943, 0.6691810488700867, 0.6756465435028076, 0.6767241358757019, 0.6778017282485962, 0.6605603694915771, 0.6476293206214905, 0.6681034564971924, 0.6907327771186829, 0.6691810488700867, 0.6659482717514038, 0.6670258641242981, 0.6767241358757019, 0.670258641242981, 0.6670258641242981, 0.6573275923728943, 0.6864224076271057, 0.6842672228813171, 0.6637930870056152, 0.673491358757019, 0.6778017282485962, 0.6681034564971924, 0.6799569129943848, 0.6691810488700867, 0.6713362336158752, 0.6681034564971924, 0.6691810488700867, 0.6885775923728943, 0.673491358757019, 0.6767241358757019, 0.6637930870056152, 0.6799569129943848, 0.6724137663841248, 0.6691810488700867, 0.6681034564971924, 0.6681034564971924, 0.6681034564971924, 0.6519396305084229, 0.6443965435028076, 0.670258641242981, 0.6724137663841248, 0.6616379022598267, 0.673491358757019, 0.6778017282485962, 0.6756465435028076, 0.6713362336158752, 0.6713362336158752, 0.6681034564971924, 0.6799569129943848, 0.662715494632721, 0.6648706793785095, 0.670258641242981, 0.6573275923728943, 0.6454741358757019, 0.670258641242981, 0.6573275923728943, 0.6616379022598267, 0.6443965435028076, 0.6454741358757019]}\n","38/38 [==============================] - 1s 6ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.3726 - accuracy: 0.8400"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 65ms/step - loss: 0.3706 - accuracy: 0.8410 - val_loss: 0.7613 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2715 - accuracy: 0.8933 - val_loss: 0.8003 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2046 - accuracy: 0.9145 - val_loss: 0.8448 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1804 - accuracy: 0.9310 - val_loss: 0.9182 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1770 - accuracy: 0.9318 - val_loss: 0.9687 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1271 - accuracy: 0.9539 - val_loss: 1.1172 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1073 - accuracy: 0.9612 - val_loss: 1.2495 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1106 - accuracy: 0.9601 - val_loss: 1.3267 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1145 - accuracy: 0.9561 - val_loss: 1.5006 - val_accuracy: 0.4955\n","Epoch 10/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.1113 - accuracy: 0.9595 - val_loss: 1.6853 - val_accuracy: 0.4955\n","Epoch 11/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1157 - accuracy: 0.9584 - val_loss: 1.5890 - val_accuracy: 0.4955\n","Epoch 12/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1044 - accuracy: 0.9621 - val_loss: 1.7451 - val_accuracy: 0.4943\n","Epoch 13/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0855 - accuracy: 0.9675 - val_loss: 1.5563 - val_accuracy: 0.4989\n","Epoch 14/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0936 - accuracy: 0.9643 - val_loss: 1.5457 - val_accuracy: 0.5011\n","Epoch 15/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0798 - accuracy: 0.9714 - val_loss: 1.6467 - val_accuracy: 0.5011\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0823 - accuracy: 0.9737 - val_loss: 1.7288 - val_accuracy: 0.5000\n","Epoch 17/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0994 - accuracy: 0.9643 - val_loss: 1.3432 - val_accuracy: 0.5419\n","Epoch 18/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1152 - accuracy: 0.9607 - val_loss: 1.2459 - val_accuracy: 0.5305\n","Epoch 19/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0745 - accuracy: 0.9754 - val_loss: 1.1283 - val_accuracy: 0.5543\n","Epoch 20/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0534 - accuracy: 0.9847 - val_loss: 1.0525 - val_accuracy: 0.6075\n","Epoch 21/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0501 - accuracy: 0.9842 - val_loss: 1.1051 - val_accuracy: 0.6482\n","Epoch 22/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0549 - accuracy: 0.9816 - val_loss: 0.9036 - val_accuracy: 0.6606\n","Epoch 23/100\n","28/28 [==============================] - 1s 43ms/step - loss: 0.0728 - accuracy: 0.9771 - val_loss: 0.8946 - val_accuracy: 0.6799\n","Epoch 24/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1012 - accuracy: 0.9646 - val_loss: 0.9766 - val_accuracy: 0.6731\n","Epoch 25/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.0868 - accuracy: 0.9717 - val_loss: 0.9286 - val_accuracy: 0.6867\n","Epoch 26/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0662 - accuracy: 0.9774 - val_loss: 1.1421 - val_accuracy: 0.6731\n","Epoch 27/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.1005 - accuracy: 0.9672 - val_loss: 1.1594 - val_accuracy: 0.6731\n","Epoch 28/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.1075 - accuracy: 0.9629 - val_loss: 0.9314 - val_accuracy: 0.6923\n","Epoch 29/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.0457 - accuracy: 0.9859 - val_loss: 1.0357 - val_accuracy: 0.7161\n","Epoch 30/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0376 - accuracy: 0.9904 - val_loss: 1.1703 - val_accuracy: 0.6957\n","Epoch 31/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0348 - accuracy: 0.9904 - val_loss: 1.2128 - val_accuracy: 0.7127\n","Epoch 32/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0249 - accuracy: 0.9955 - val_loss: 1.2420 - val_accuracy: 0.7149\n","Epoch 33/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0243 - accuracy: 0.9941 - val_loss: 1.4471 - val_accuracy: 0.7138\n","Epoch 34/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0327 - accuracy: 0.9912 - val_loss: 1.2586 - val_accuracy: 0.7002\n","Epoch 35/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0510 - accuracy: 0.9842 - val_loss: 1.4060 - val_accuracy: 0.6572\n","Epoch 36/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0890 - accuracy: 0.9717 - val_loss: 1.2855 - val_accuracy: 0.6686\n","Epoch 37/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1148 - accuracy: 0.9604 - val_loss: 1.0323 - val_accuracy: 0.6787\n","Epoch 38/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0715 - accuracy: 0.9774 - val_loss: 1.2862 - val_accuracy: 0.6640\n","Epoch 39/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0580 - accuracy: 0.9785 - val_loss: 1.1326 - val_accuracy: 0.7048\n","Epoch 40/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0390 - accuracy: 0.9898 - val_loss: 1.1717 - val_accuracy: 0.7172\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0355 - accuracy: 0.9890 - val_loss: 1.2665 - val_accuracy: 0.7161\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0416 - accuracy: 0.9881 - val_loss: 1.3277 - val_accuracy: 0.6799\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0416 - accuracy: 0.9875 - val_loss: 1.2444 - val_accuracy: 0.7127\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0289 - accuracy: 0.9932 - val_loss: 1.4329 - val_accuracy: 0.6991\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 1.4224 - val_accuracy: 0.6810\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0361 - accuracy: 0.9918 - val_loss: 1.3860 - val_accuracy: 0.6980\n","Epoch 47/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0677 - accuracy: 0.9796 - val_loss: 1.2224 - val_accuracy: 0.6731\n","Epoch 48/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0611 - accuracy: 0.9808 - val_loss: 1.2592 - val_accuracy: 0.6878\n","Epoch 49/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0529 - accuracy: 0.9839 - val_loss: 1.4583 - val_accuracy: 0.6878\n","Epoch 50/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0374 - accuracy: 0.9890 - val_loss: 1.3510 - val_accuracy: 0.7014\n","Epoch 51/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0329 - accuracy: 0.9912 - val_loss: 1.4279 - val_accuracy: 0.7059\n","Epoch 52/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0369 - accuracy: 0.9904 - val_loss: 1.5226 - val_accuracy: 0.6674\n","Epoch 53/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0493 - accuracy: 0.9830 - val_loss: 1.4188 - val_accuracy: 0.7048\n","Epoch 54/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0764 - accuracy: 0.9757 - val_loss: 1.1965 - val_accuracy: 0.6799\n","Epoch 55/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0549 - accuracy: 0.9847 - val_loss: 1.1555 - val_accuracy: 0.7002\n","Epoch 56/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0484 - accuracy: 0.9853 - val_loss: 1.2432 - val_accuracy: 0.6900\n","Epoch 57/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0401 - accuracy: 0.9884 - val_loss: 1.4139 - val_accuracy: 0.6855\n","Epoch 58/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0454 - accuracy: 0.9853 - val_loss: 1.4359 - val_accuracy: 0.7002\n","Epoch 59/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0432 - accuracy: 0.9873 - val_loss: 1.4132 - val_accuracy: 0.7104\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0359 - accuracy: 0.9901 - val_loss: 1.4475 - val_accuracy: 0.6900\n","Epoch 61/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0271 - accuracy: 0.9941 - val_loss: 1.4993 - val_accuracy: 0.6855\n","Epoch 62/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0250 - accuracy: 0.9935 - val_loss: 1.5091 - val_accuracy: 0.6923\n","Epoch 63/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0452 - accuracy: 0.9870 - val_loss: 1.6126 - val_accuracy: 0.6799\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0587 - accuracy: 0.9805 - val_loss: 1.5103 - val_accuracy: 0.6753\n","Epoch 65/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0728 - accuracy: 0.9771 - val_loss: 1.3539 - val_accuracy: 0.6844\n","Epoch 66/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0514 - accuracy: 0.9856 - val_loss: 1.3676 - val_accuracy: 0.6810\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0535 - accuracy: 0.9827 - val_loss: 1.4727 - val_accuracy: 0.6731\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0312 - accuracy: 0.9918 - val_loss: 1.4251 - val_accuracy: 0.6799\n","Epoch 69/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0282 - accuracy: 0.9935 - val_loss: 1.5674 - val_accuracy: 0.6652\n","Epoch 70/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0227 - accuracy: 0.9952 - val_loss: 1.5082 - val_accuracy: 0.6719\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0183 - accuracy: 0.9966 - val_loss: 1.5219 - val_accuracy: 0.6821\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0139 - accuracy: 0.9983 - val_loss: 1.5445 - val_accuracy: 0.6765\n","Epoch 73/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0153 - accuracy: 0.9977 - val_loss: 1.5469 - val_accuracy: 0.7002\n","Epoch 74/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0164 - accuracy: 0.9975 - val_loss: 1.5657 - val_accuracy: 0.6957\n","Epoch 75/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0163 - accuracy: 0.9975 - val_loss: 1.5192 - val_accuracy: 0.6844\n","Epoch 76/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0188 - accuracy: 0.9955 - val_loss: 1.5573 - val_accuracy: 0.6765\n","Epoch 77/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0215 - accuracy: 0.9949 - val_loss: 1.4978 - val_accuracy: 0.6799\n","Epoch 78/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0196 - accuracy: 0.9966 - val_loss: 1.6807 - val_accuracy: 0.6584\n","Epoch 79/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0278 - accuracy: 0.9941 - val_loss: 1.5768 - val_accuracy: 0.6957\n","Epoch 80/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0597 - accuracy: 0.9822 - val_loss: 1.4609 - val_accuracy: 0.6765\n","Epoch 81/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1234 - accuracy: 0.9564 - val_loss: 1.0041 - val_accuracy: 0.6833\n","Epoch 82/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0485 - accuracy: 0.9873 - val_loss: 1.3585 - val_accuracy: 0.6719\n","Epoch 83/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0443 - accuracy: 0.9859 - val_loss: 1.3985 - val_accuracy: 0.6618\n","Epoch 84/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0368 - accuracy: 0.9890 - val_loss: 1.4750 - val_accuracy: 0.6527\n","Epoch 85/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0386 - accuracy: 0.9884 - val_loss: 1.4952 - val_accuracy: 0.6561\n","Epoch 86/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0331 - accuracy: 0.9895 - val_loss: 1.4758 - val_accuracy: 0.6787\n","Epoch 87/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0396 - accuracy: 0.9878 - val_loss: 1.5631 - val_accuracy: 0.6652\n","Epoch 88/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0379 - accuracy: 0.9881 - val_loss: 1.5450 - val_accuracy: 0.6652\n","Epoch 89/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0264 - accuracy: 0.9932 - val_loss: 1.4518 - val_accuracy: 0.6776\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0267 - accuracy: 0.9938 - val_loss: 1.6025 - val_accuracy: 0.6595\n","Epoch 91/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0340 - accuracy: 0.9907 - val_loss: 1.6969 - val_accuracy: 0.6629\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0774 - accuracy: 0.9740 - val_loss: 1.2689 - val_accuracy: 0.6731\n","Epoch 93/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0567 - accuracy: 0.9808 - val_loss: 1.3502 - val_accuracy: 0.6719\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0295 - accuracy: 0.9929 - val_loss: 1.5620 - val_accuracy: 0.6629\n","Epoch 95/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0320 - accuracy: 0.9929 - val_loss: 1.5516 - val_accuracy: 0.6719\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0356 - accuracy: 0.9884 - val_loss: 1.5375 - val_accuracy: 0.6652\n","Epoch 97/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0440 - accuracy: 0.9875 - val_loss: 1.5547 - val_accuracy: 0.6527\n","Epoch 98/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0304 - accuracy: 0.9915 - val_loss: 1.5633 - val_accuracy: 0.6776\n","Epoch 99/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0255 - accuracy: 0.9938 - val_loss: 1.5561 - val_accuracy: 0.6606\n","Epoch 100/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0338 - accuracy: 0.9912 - val_loss: 1.6202 - val_accuracy: 0.6674\n","{'loss': [0.3705509305000305, 0.2714872360229492, 0.20455197989940643, 0.18043823540210724, 0.17699597775936127, 0.12706801295280457, 0.10733139514923096, 0.11062978208065033, 0.11451735347509384, 0.11133145540952682, 0.11568484455347061, 0.10444843024015427, 0.08550386875867844, 0.09356912970542908, 0.07984625548124313, 0.08233696222305298, 0.09942014515399933, 0.11519147455692291, 0.07448021322488785, 0.05337061733007431, 0.05008682981133461, 0.0548512265086174, 0.07283513993024826, 0.10122079402208328, 0.08683936297893524, 0.06621380150318146, 0.10047586262226105, 0.10752026736736298, 0.045668188482522964, 0.03760729730129242, 0.03480036184191704, 0.024882813915610313, 0.02425665594637394, 0.03274763375520706, 0.050986770540475845, 0.08901829272508621, 0.11483775824308395, 0.07150464504957199, 0.05801235884428024, 0.03897836059331894, 0.035531435161828995, 0.04160653427243233, 0.04161300137639046, 0.0289276372641325, 0.029853306710720062, 0.03611524775624275, 0.06773070245981216, 0.061119262129068375, 0.052885305136442184, 0.03737849369645119, 0.03290306776762009, 0.03692622110247612, 0.04930496588349342, 0.07638642936944962, 0.05487806722521782, 0.04844661056995392, 0.040075406432151794, 0.04543530195951462, 0.04316401854157448, 0.03587064892053604, 0.02708406187593937, 0.024957645684480667, 0.04521709680557251, 0.05865726247429848, 0.0728207528591156, 0.051439013332128525, 0.053529269993305206, 0.031249670311808586, 0.028179015964269638, 0.022683633491396904, 0.018279947340488434, 0.013928139582276344, 0.015271416865289211, 0.016361866146326065, 0.016347119584679604, 0.018762456253170967, 0.02148326486349106, 0.019583599641919136, 0.027821283787488937, 0.05968323349952698, 0.12335701286792755, 0.048540808260440826, 0.044338446110486984, 0.03683900833129883, 0.03858020156621933, 0.033074554055929184, 0.039604268968105316, 0.03793640807271004, 0.02638643980026245, 0.026664625853300095, 0.034011900424957275, 0.07742201536893845, 0.05665786564350128, 0.029474791139364243, 0.032036200165748596, 0.035600971430540085, 0.0440133698284626, 0.030442778021097183, 0.025452859699726105, 0.0337895005941391], 'accuracy': [0.8409733772277832, 0.8933219909667969, 0.914544403553009, 0.9309564232826233, 0.9318053126335144, 0.9538766145706177, 0.9612337350845337, 0.960101842880249, 0.9561403393745422, 0.9595359563827515, 0.9584040641784668, 0.9620826244354248, 0.967458963394165, 0.9643463492393494, 0.9714204668998718, 0.9736841917037964, 0.9643463492393494, 0.9606677889823914, 0.9753820300102234, 0.9847198724746704, 0.9841539263725281, 0.9816072583198547, 0.9770798087120056, 0.9646292924880981, 0.9717034697532654, 0.9773627519607544, 0.9671760201454163, 0.9629315137863159, 0.9858517050743103, 0.9903791546821594, 0.9903791546821594, 0.9954725503921509, 0.9940577149391174, 0.9912280440330505, 0.9841539263725281, 0.9717034697532654, 0.9603848457336426, 0.9773627519607544, 0.9784946441650391, 0.9898132681846619, 0.988964319229126, 0.9881154298782349, 0.9875495433807373, 0.9932088255882263, 0.9915110468864441, 0.9917939901351929, 0.979626476764679, 0.9807583689689636, 0.9838709831237793, 0.988964319229126, 0.9912280440330505, 0.9903791546821594, 0.9830220937728882, 0.9756649732589722, 0.9847198724746704, 0.9852858185768127, 0.9883984327316284, 0.9852858185768127, 0.9872665405273438, 0.9900962114334106, 0.9940577149391174, 0.9934917688369751, 0.986983597278595, 0.9804753661155701, 0.9770798087120056, 0.9855687618255615, 0.9827390909194946, 0.9917939901351929, 0.9934917688369751, 0.9951896071434021, 0.9966044425964355, 0.9983022212982178, 0.9977362751960754, 0.9974533319473267, 0.9974533319473267, 0.9954725503921509, 0.9949066042900085, 0.9966044425964355, 0.9940577149391174, 0.9821732044219971, 0.9564233422279358, 0.9872665405273438, 0.9858517050743103, 0.988964319229126, 0.9883984327316284, 0.9895302653312683, 0.9878324866294861, 0.9881154298782349, 0.9932088255882263, 0.9937747716903687, 0.990662157535553, 0.9739671945571899, 0.9807583689689636, 0.9929258823394775, 0.9929258823394775, 0.9883984327316284, 0.9875495433807373, 0.9915110468864441, 0.9937747716903687, 0.9912280440330505], 'val_loss': [0.7612904906272888, 0.8002562522888184, 0.8447798490524292, 0.918204128742218, 0.9686910510063171, 1.1172370910644531, 1.2494771480560303, 1.3266944885253906, 1.5005801916122437, 1.6853080987930298, 1.589029312133789, 1.7451335191726685, 1.556312084197998, 1.545735478401184, 1.6467281579971313, 1.7288035154342651, 1.343210220336914, 1.2458730936050415, 1.1282622814178467, 1.0525298118591309, 1.1051385402679443, 0.9036405682563782, 0.894575834274292, 0.9765547513961792, 0.9286258816719055, 1.1420865058898926, 1.159394383430481, 0.9313573241233826, 1.035683035850525, 1.1702773571014404, 1.2128132581710815, 1.2419596910476685, 1.4471313953399658, 1.2586244344711304, 1.4060451984405518, 1.2854899168014526, 1.0322866439819336, 1.2862043380737305, 1.132590889930725, 1.1717253923416138, 1.2664626836776733, 1.3277126550674438, 1.2444028854370117, 1.4329113960266113, 1.4223657846450806, 1.3860353231430054, 1.222368836402893, 1.2592406272888184, 1.458325982093811, 1.351040005683899, 1.4278818368911743, 1.5225805044174194, 1.4187785387039185, 1.1965394020080566, 1.1555265188217163, 1.2432043552398682, 1.413878321647644, 1.4359380006790161, 1.413219928741455, 1.447494626045227, 1.499282717704773, 1.5090924501419067, 1.612605333328247, 1.5102876424789429, 1.3538707494735718, 1.3676109313964844, 1.4726982116699219, 1.425099492073059, 1.5673861503601074, 1.5082179307937622, 1.5218749046325684, 1.5445195436477661, 1.5469400882720947, 1.5657432079315186, 1.5191676616668701, 1.5572813749313354, 1.4977524280548096, 1.6807336807250977, 1.5767611265182495, 1.4608625173568726, 1.0040843486785889, 1.358528971672058, 1.3985196352005005, 1.4749614000320435, 1.4951565265655518, 1.4757728576660156, 1.5630507469177246, 1.5450210571289062, 1.4518210887908936, 1.6024705171585083, 1.6969187259674072, 1.2688666582107544, 1.3502241373062134, 1.562017560005188, 1.5515720844268799, 1.5374919176101685, 1.5546605587005615, 1.563251256942749, 1.5561357736587524, 1.6201752424240112], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4943438768386841, 0.49886876344680786, 0.5011312365531921, 0.5011312365531921, 0.5, 0.5418552160263062, 0.5305429697036743, 0.5542986392974854, 0.6074660420417786, 0.6481900215148926, 0.6606335043907166, 0.679864227771759, 0.6730769276618958, 0.6866515874862671, 0.6730769276618958, 0.6730769276618958, 0.692307710647583, 0.7160633206367493, 0.6957013607025146, 0.7126696705818176, 0.7149321436882019, 0.7138009071350098, 0.7002262473106384, 0.6572397947311401, 0.668552041053772, 0.6787330508232117, 0.6640271544456482, 0.7047511339187622, 0.7171945571899414, 0.7160633206367493, 0.679864227771759, 0.7126696705818176, 0.6990950107574463, 0.6809954643249512, 0.6979637742042542, 0.6730769276618958, 0.6877828240394592, 0.6877828240394592, 0.7013574838638306, 0.7058823704719543, 0.6674208045005798, 0.7047511339187622, 0.679864227771759, 0.7002262473106384, 0.6900452375411987, 0.685520350933075, 0.7002262473106384, 0.7104072570800781, 0.6900452375411987, 0.685520350933075, 0.692307710647583, 0.679864227771759, 0.6753393411636353, 0.6843891143798828, 0.6809954643249512, 0.6730769276618958, 0.679864227771759, 0.6651583909988403, 0.6719456911087036, 0.6821267008781433, 0.6764705777168274, 0.7002262473106384, 0.6957013607025146, 0.6843891143798828, 0.6764705777168274, 0.679864227771759, 0.6583710312843323, 0.6957013607025146, 0.6764705777168274, 0.6832579374313354, 0.6719456911087036, 0.6617646813392639, 0.6527149081230164, 0.6561086177825928, 0.6787330508232117, 0.6651583909988403, 0.6651583909988403, 0.6776018142700195, 0.6595022678375244, 0.662895917892456, 0.6730769276618958, 0.6719456911087036, 0.662895917892456, 0.6719456911087036, 0.6651583909988403, 0.6527149081230164, 0.6776018142700195, 0.6606335043907166, 0.6674208045005798]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8253"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 72ms/step - loss: 0.3920 - accuracy: 0.8251 - val_loss: 0.7513 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2616 - accuracy: 0.8946 - val_loss: 0.8129 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2242 - accuracy: 0.9111 - val_loss: 0.8508 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1919 - accuracy: 0.9199 - val_loss: 0.9401 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1788 - accuracy: 0.9245 - val_loss: 1.0348 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1851 - accuracy: 0.9256 - val_loss: 1.1331 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1467 - accuracy: 0.9447 - val_loss: 1.3398 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1095 - accuracy: 0.9589 - val_loss: 1.5723 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1364 - accuracy: 0.9432 - val_loss: 1.5590 - val_accuracy: 0.4855\n","Epoch 10/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1337 - accuracy: 0.9468 - val_loss: 1.5050 - val_accuracy: 0.4845\n","Epoch 11/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1048 - accuracy: 0.9633 - val_loss: 1.8871 - val_accuracy: 0.4855\n","Epoch 12/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0994 - accuracy: 0.9633 - val_loss: 1.6159 - val_accuracy: 0.4897\n","Epoch 13/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0907 - accuracy: 0.9682 - val_loss: 1.7033 - val_accuracy: 0.4897\n","Epoch 14/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0902 - accuracy: 0.9672 - val_loss: 1.7815 - val_accuracy: 0.4959\n","Epoch 15/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.1305 - accuracy: 0.9496 - val_loss: 1.2636 - val_accuracy: 0.5279\n","Epoch 16/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.1119 - accuracy: 0.9584 - val_loss: 1.1420 - val_accuracy: 0.5754\n","Epoch 17/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0868 - accuracy: 0.9700 - val_loss: 1.4324 - val_accuracy: 0.5496\n","Epoch 18/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0623 - accuracy: 0.9796 - val_loss: 1.1326 - val_accuracy: 0.6333\n","Epoch 19/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0704 - accuracy: 0.9770 - val_loss: 0.9529 - val_accuracy: 0.6601\n","Epoch 20/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0751 - accuracy: 0.9731 - val_loss: 1.0703 - val_accuracy: 0.6291\n","Epoch 21/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.0845 - accuracy: 0.9693 - val_loss: 1.1130 - val_accuracy: 0.6674\n","Epoch 22/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1437 - accuracy: 0.9501 - val_loss: 0.9432 - val_accuracy: 0.6622\n","Epoch 23/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.0825 - accuracy: 0.9708 - val_loss: 1.0808 - val_accuracy: 0.6870\n","Epoch 24/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0823 - accuracy: 0.9698 - val_loss: 1.1531 - val_accuracy: 0.6736\n","Epoch 25/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0632 - accuracy: 0.9755 - val_loss: 1.1672 - val_accuracy: 0.6901\n","Epoch 26/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0661 - accuracy: 0.9778 - val_loss: 1.2191 - val_accuracy: 0.6839\n","Epoch 27/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0838 - accuracy: 0.9698 - val_loss: 1.3259 - val_accuracy: 0.6767\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0810 - accuracy: 0.9726 - val_loss: 1.2922 - val_accuracy: 0.6674\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0854 - accuracy: 0.9703 - val_loss: 1.2781 - val_accuracy: 0.6581\n","Epoch 30/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1647 - accuracy: 0.9437 - val_loss: 1.1119 - val_accuracy: 0.6777\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0863 - accuracy: 0.9680 - val_loss: 1.2574 - val_accuracy: 0.6880\n","Epoch 32/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0511 - accuracy: 0.9845 - val_loss: 1.5693 - val_accuracy: 0.6612\n","Epoch 33/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0471 - accuracy: 0.9868 - val_loss: 1.4338 - val_accuracy: 0.6715\n","Epoch 34/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0530 - accuracy: 0.9824 - val_loss: 1.3792 - val_accuracy: 0.6839\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0640 - accuracy: 0.9798 - val_loss: 1.4015 - val_accuracy: 0.6570\n","Epoch 36/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0998 - accuracy: 0.9654 - val_loss: 1.2355 - val_accuracy: 0.6829\n","Epoch 37/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0765 - accuracy: 0.9742 - val_loss: 1.3573 - val_accuracy: 0.6488\n","Epoch 38/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0599 - accuracy: 0.9780 - val_loss: 1.4738 - val_accuracy: 0.6694\n","Epoch 39/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0332 - accuracy: 0.9915 - val_loss: 1.4335 - val_accuracy: 0.6973\n","Epoch 40/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0350 - accuracy: 0.9891 - val_loss: 1.6426 - val_accuracy: 0.6591\n","Epoch 41/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1136 - accuracy: 0.9623 - val_loss: 1.1491 - val_accuracy: 0.6674\n","Epoch 42/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0907 - accuracy: 0.9669 - val_loss: 1.3300 - val_accuracy: 0.6787\n","Epoch 43/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0981 - accuracy: 0.9677 - val_loss: 1.3420 - val_accuracy: 0.6674\n","Epoch 44/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0445 - accuracy: 0.9889 - val_loss: 1.4621 - val_accuracy: 0.6705\n","Epoch 45/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0337 - accuracy: 0.9897 - val_loss: 1.5180 - val_accuracy: 0.6705\n","Epoch 46/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0402 - accuracy: 0.9876 - val_loss: 1.5875 - val_accuracy: 0.6622\n","Epoch 47/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0332 - accuracy: 0.9922 - val_loss: 1.9369 - val_accuracy: 0.6457\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0401 - accuracy: 0.9879 - val_loss: 1.5549 - val_accuracy: 0.6849\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0368 - accuracy: 0.9894 - val_loss: 1.5420 - val_accuracy: 0.6818\n","Epoch 50/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0452 - accuracy: 0.9858 - val_loss: 1.7052 - val_accuracy: 0.6570\n","Epoch 51/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0603 - accuracy: 0.9806 - val_loss: 1.5398 - val_accuracy: 0.6550\n","Epoch 52/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0797 - accuracy: 0.9736 - val_loss: 1.4599 - val_accuracy: 0.6457\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0710 - accuracy: 0.9773 - val_loss: 1.5021 - val_accuracy: 0.6612\n","Epoch 54/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0502 - accuracy: 0.9832 - val_loss: 1.4851 - val_accuracy: 0.6539\n","Epoch 55/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0430 - accuracy: 0.9871 - val_loss: 1.5612 - val_accuracy: 0.6601\n","Epoch 56/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0682 - accuracy: 0.9786 - val_loss: 1.4482 - val_accuracy: 0.6477\n","Epoch 57/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0888 - accuracy: 0.9667 - val_loss: 1.3461 - val_accuracy: 0.6715\n","Epoch 58/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0802 - accuracy: 0.9742 - val_loss: 1.4059 - val_accuracy: 0.6591\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0607 - accuracy: 0.9814 - val_loss: 1.4285 - val_accuracy: 0.6715\n","Epoch 60/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0442 - accuracy: 0.9871 - val_loss: 1.6499 - val_accuracy: 0.6508\n","Epoch 61/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0509 - accuracy: 0.9855 - val_loss: 1.5107 - val_accuracy: 0.6643\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0592 - accuracy: 0.9819 - val_loss: 1.5793 - val_accuracy: 0.6488\n","Epoch 63/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0526 - accuracy: 0.9840 - val_loss: 1.5296 - val_accuracy: 0.6426\n","Epoch 64/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0419 - accuracy: 0.9873 - val_loss: 1.6718 - val_accuracy: 0.6219\n","Epoch 65/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0629 - accuracy: 0.9780 - val_loss: 1.5010 - val_accuracy: 0.6684\n","Epoch 66/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0430 - accuracy: 0.9873 - val_loss: 1.7697 - val_accuracy: 0.6457\n","Epoch 67/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0916 - accuracy: 0.9661 - val_loss: 1.3745 - val_accuracy: 0.6353\n","Epoch 68/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0529 - accuracy: 0.9840 - val_loss: 1.5725 - val_accuracy: 0.6674\n","Epoch 69/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0311 - accuracy: 0.9935 - val_loss: 1.7047 - val_accuracy: 0.6643\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0268 - accuracy: 0.9925 - val_loss: 1.7838 - val_accuracy: 0.6581\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0267 - accuracy: 0.9941 - val_loss: 1.7396 - val_accuracy: 0.6436\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0567 - accuracy: 0.9796 - val_loss: 1.5816 - val_accuracy: 0.6374\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0498 - accuracy: 0.9832 - val_loss: 1.7278 - val_accuracy: 0.6374\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0445 - accuracy: 0.9858 - val_loss: 1.6329 - val_accuracy: 0.6477\n","Epoch 75/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0280 - accuracy: 0.9928 - val_loss: 1.7649 - val_accuracy: 0.6591\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0360 - accuracy: 0.9884 - val_loss: 1.8632 - val_accuracy: 0.6415\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0506 - accuracy: 0.9858 - val_loss: 1.8232 - val_accuracy: 0.6374\n","Epoch 78/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0496 - accuracy: 0.9811 - val_loss: 1.7357 - val_accuracy: 0.6374\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0414 - accuracy: 0.9881 - val_loss: 1.5909 - val_accuracy: 0.6663\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 1.6571 - val_accuracy: 0.6529\n","Epoch 81/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0393 - accuracy: 0.9897 - val_loss: 1.6748 - val_accuracy: 0.6322\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0321 - accuracy: 0.9907 - val_loss: 1.7086 - val_accuracy: 0.6446\n","Epoch 83/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0306 - accuracy: 0.9925 - val_loss: 1.8937 - val_accuracy: 0.6539\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0368 - accuracy: 0.9897 - val_loss: 1.7339 - val_accuracy: 0.6498\n","Epoch 85/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0535 - accuracy: 0.9840 - val_loss: 1.6467 - val_accuracy: 0.6457\n","Epoch 86/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0483 - accuracy: 0.9855 - val_loss: 1.6631 - val_accuracy: 0.6570\n","Epoch 87/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0374 - accuracy: 0.9881 - val_loss: 1.8665 - val_accuracy: 0.6498\n","Epoch 88/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0780 - accuracy: 0.9760 - val_loss: 1.4680 - val_accuracy: 0.6333\n","Epoch 89/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0576 - accuracy: 0.9793 - val_loss: 1.5211 - val_accuracy: 0.6219\n","Epoch 90/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0336 - accuracy: 0.9894 - val_loss: 1.7820 - val_accuracy: 0.6405\n","Epoch 91/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0346 - accuracy: 0.9899 - val_loss: 1.7604 - val_accuracy: 0.6477\n","Epoch 92/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0312 - accuracy: 0.9910 - val_loss: 1.9281 - val_accuracy: 0.6508\n","Epoch 93/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1550 - accuracy: 0.9463 - val_loss: 1.2054 - val_accuracy: 0.6281\n","Epoch 94/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0501 - accuracy: 0.9832 - val_loss: 1.5989 - val_accuracy: 0.6643\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0358 - accuracy: 0.9884 - val_loss: 1.7486 - val_accuracy: 0.6612\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0486 - accuracy: 0.9840 - val_loss: 1.6831 - val_accuracy: 0.6312\n","Epoch 97/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0511 - accuracy: 0.9817 - val_loss: 1.5973 - val_accuracy: 0.6467\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1011 - accuracy: 0.9646 - val_loss: 1.3525 - val_accuracy: 0.6229\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0557 - accuracy: 0.9827 - val_loss: 1.5244 - val_accuracy: 0.6302\n","Epoch 100/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0318 - accuracy: 0.9915 - val_loss: 1.6178 - val_accuracy: 0.6384\n","{'loss': [0.3920094966888428, 0.2615991234779358, 0.22424514591693878, 0.1919076144695282, 0.17879937589168549, 0.18508028984069824, 0.1466672718524933, 0.10953256487846375, 0.13637295365333557, 0.13373777270317078, 0.1048012301325798, 0.09942343086004257, 0.0906623974442482, 0.0901750698685646, 0.13045179843902588, 0.11189563572406769, 0.08679358661174774, 0.062273621559143066, 0.07038935273885727, 0.07512504607439041, 0.08449597656726837, 0.1436946541070938, 0.08250456303358078, 0.08234935253858566, 0.06317761540412903, 0.06606036424636841, 0.08382061868906021, 0.08097384124994278, 0.08539342135190964, 0.16472230851650238, 0.08632417768239975, 0.051104649901390076, 0.047061070799827576, 0.052987005561590195, 0.06400950253009796, 0.09980075806379318, 0.07653746753931046, 0.05994560196995735, 0.03319403901696205, 0.03499528020620346, 0.11363912373781204, 0.09071444720029831, 0.0981311947107315, 0.044484879821538925, 0.03374899551272392, 0.04021882265806198, 0.03315949812531471, 0.04007938504219055, 0.036812346428632736, 0.045242611318826675, 0.06027045100927353, 0.07966634631156921, 0.07103665173053741, 0.05020080506801605, 0.0429997481405735, 0.06821969896554947, 0.08880074322223663, 0.08021338284015656, 0.060704294592142105, 0.04418021813035011, 0.05094598978757858, 0.05915068835020065, 0.05264660343527794, 0.04192017763853073, 0.06292396038770676, 0.04302490875124931, 0.09158296883106232, 0.05286868289113045, 0.031059706583619118, 0.02681061625480652, 0.026741711422801018, 0.05674629285931587, 0.0498470701277256, 0.04449864849448204, 0.027976948767900467, 0.035969078540802, 0.05058875307440758, 0.04955955967307091, 0.0413973331451416, 0.060141440480947495, 0.03930320218205452, 0.03205922618508339, 0.030605968087911606, 0.03678448870778084, 0.053475335240364075, 0.048331648111343384, 0.0374407023191452, 0.07799243927001953, 0.05764231085777283, 0.03360829874873161, 0.03462089225649834, 0.03121102787554264, 0.15501375496387482, 0.0501263327896595, 0.03575579822063446, 0.0486360639333725, 0.051053598523139954, 0.10112889111042023, 0.055688630789518356, 0.03181053325533867], 'accuracy': [0.8250645995140076, 0.8945736289024353, 0.9111111164093018, 0.91989666223526, 0.9245477914810181, 0.9255813956260681, 0.9447028636932373, 0.9589147567749023, 0.9431524276733398, 0.9467700123786926, 0.9633074998855591, 0.9633074998855591, 0.9682170748710632, 0.9671834707260132, 0.9496123790740967, 0.9583979249000549, 0.9700258374214172, 0.9795865416526794, 0.9770025610923767, 0.9731265902519226, 0.9692506194114685, 0.9501292109489441, 0.970801055431366, 0.9697674512863159, 0.975452184677124, 0.9777777791023254, 0.9697674512863159, 0.97260981798172, 0.9702842235565186, 0.9436692595481873, 0.9679586291313171, 0.9844961166381836, 0.986821711063385, 0.9824289679527283, 0.9798449873924255, 0.9653746485710144, 0.9741601943969727, 0.9780361652374268, 0.9914728403091431, 0.9891473054885864, 0.962273895740509, 0.9669250845909119, 0.9677002429962158, 0.9888888597488403, 0.9896640777587891, 0.987596869468689, 0.9922480583190918, 0.9878553152084351, 0.9894056916236877, 0.985788106918335, 0.9806201457977295, 0.97364342212677, 0.9772610068321228, 0.9832041263580322, 0.9870800971984863, 0.9785529971122742, 0.9666666388511658, 0.9741601943969727, 0.9813953638076782, 0.9870800971984863, 0.9855297207832336, 0.9819121360778809, 0.983979344367981, 0.9873384833335876, 0.9780361652374268, 0.9873384833335876, 0.9661498665809631, 0.983979344367981, 0.9935400485992432, 0.9925064444541931, 0.9940568208694458, 0.9795865416526794, 0.9832041263580322, 0.985788106918335, 0.9927648305892944, 0.9883720874786377, 0.985788106918335, 0.9811369776725769, 0.9881137013435364, 0.9788113832473755, 0.9896640777587891, 0.9906976819038391, 0.9925064444541931, 0.9896640777587891, 0.983979344367981, 0.9855297207832336, 0.9881137013435364, 0.9759690165519714, 0.9793281555175781, 0.9894056916236877, 0.9899224638938904, 0.9909560680389404, 0.94625324010849, 0.9832041263580322, 0.9883720874786377, 0.983979344367981, 0.9816537499427795, 0.9645994901657104, 0.9826873540878296, 0.9914728403091431], 'val_loss': [0.7512805461883545, 0.812903881072998, 0.8508288860321045, 0.9400966167449951, 1.0348341464996338, 1.133124828338623, 1.339787483215332, 1.5722564458847046, 1.5589689016342163, 1.5050264596939087, 1.8870806694030762, 1.6158819198608398, 1.7032603025436401, 1.7814528942108154, 1.2635889053344727, 1.141978144645691, 1.4323704242706299, 1.1326359510421753, 0.9528647065162659, 1.0703108310699463, 1.1129919290542603, 0.9432398676872253, 1.0808132886886597, 1.153062105178833, 1.1671648025512695, 1.2190560102462769, 1.3259037733078003, 1.2922202348709106, 1.278078317642212, 1.1119394302368164, 1.257379174232483, 1.5692837238311768, 1.433797836303711, 1.3791680335998535, 1.4014891386032104, 1.23548424243927, 1.357272982597351, 1.4738489389419556, 1.4335492849349976, 1.6426030397415161, 1.1490534543991089, 1.3300238847732544, 1.3419631719589233, 1.4621251821517944, 1.5179671049118042, 1.5874512195587158, 1.9369391202926636, 1.5549466609954834, 1.5419747829437256, 1.7052327394485474, 1.5397708415985107, 1.459946632385254, 1.5021414756774902, 1.4851350784301758, 1.5611885786056519, 1.448195219039917, 1.3461238145828247, 1.4058873653411865, 1.42854905128479, 1.6499154567718506, 1.510667324066162, 1.579313039779663, 1.5295908451080322, 1.6718498468399048, 1.5009719133377075, 1.7696763277053833, 1.3744813203811646, 1.572501301765442, 1.7047104835510254, 1.7837941646575928, 1.739633560180664, 1.5815520286560059, 1.7278319597244263, 1.6329206228256226, 1.7649157047271729, 1.8632079362869263, 1.8232005834579468, 1.7357401847839355, 1.5909442901611328, 1.6571043729782104, 1.6748217344284058, 1.7085801362991333, 1.893663763999939, 1.7339121103286743, 1.6467082500457764, 1.6631358861923218, 1.8665446043014526, 1.467965841293335, 1.5210663080215454, 1.7819700241088867, 1.7603518962860107, 1.9281073808670044, 1.2054128646850586, 1.5989000797271729, 1.7486085891723633, 1.6830812692642212, 1.5972893238067627, 1.352523684501648, 1.5243765115737915, 1.617764949798584], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4845041334629059, 0.48553720116615295, 0.48966941237449646, 0.48966941237449646, 0.4958677589893341, 0.5278925895690918, 0.5754132270812988, 0.5495867729187012, 0.6332644820213318, 0.6601239442825317, 0.6291322112083435, 0.6673553586006165, 0.6621900796890259, 0.6869834661483765, 0.6735537052154541, 0.6900826692581177, 0.68388432264328, 0.6766529083251953, 0.6673553586006165, 0.6580578684806824, 0.6776859760284424, 0.6880165338516235, 0.6611570119857788, 0.6714876294136047, 0.68388432264328, 0.6570248007774353, 0.682851254940033, 0.6487603187561035, 0.6694214940071106, 0.6973140239715576, 0.6590909361839294, 0.6673553586006165, 0.6787189841270447, 0.6673553586006165, 0.6704545617103577, 0.6704545617103577, 0.6621900796890259, 0.6456611752510071, 0.6849173307418823, 0.6818181872367859, 0.6570248007774353, 0.6549586653709412, 0.6456611752510071, 0.6611570119857788, 0.6539255976676941, 0.6601239442825317, 0.6477272510528564, 0.6714876294136047, 0.6590909361839294, 0.6714876294136047, 0.6508264541625977, 0.66425621509552, 0.6487603187561035, 0.6425619721412659, 0.6219007968902588, 0.6683884263038635, 0.6456611752510071, 0.6353305578231812, 0.6673553586006165, 0.66425621509552, 0.6580578684806824, 0.6435950398445129, 0.6373966932296753, 0.6373966932296753, 0.6477272510528564, 0.6590909361839294, 0.6415289044380188, 0.6373966932296753, 0.6373966932296753, 0.6663222908973694, 0.6528925895690918, 0.6322314143180847, 0.64462810754776, 0.6539255976676941, 0.6497933864593506, 0.6456611752510071, 0.6570248007774353, 0.6497933864593506, 0.6332644820213318, 0.6219007968902588, 0.6404958963394165, 0.6477272510528564, 0.6508264541625977, 0.6280992031097412, 0.66425621509552, 0.6611570119857788, 0.6311983466148376, 0.6466942429542542, 0.6229338645935059, 0.6301652789115906, 0.6384297609329224]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.1373 - accuracy: 0.9567"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 62ms/step - loss: 0.1336 - accuracy: 0.9580 - val_loss: 0.8668 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0712 - accuracy: 0.9752 - val_loss: 1.0190 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0568 - accuracy: 0.9817 - val_loss: 1.0965 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0774 - accuracy: 0.9709 - val_loss: 1.0707 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0751 - accuracy: 0.9723 - val_loss: 1.2203 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0460 - accuracy: 0.9857 - val_loss: 1.4414 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0339 - accuracy: 0.9890 - val_loss: 1.7011 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0629 - accuracy: 0.9790 - val_loss: 1.6748 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0694 - accuracy: 0.9752 - val_loss: 1.6890 - val_accuracy: 0.4849\n","Epoch 10/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0456 - accuracy: 0.9852 - val_loss: 1.6936 - val_accuracy: 0.4903\n","Epoch 11/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0675 - accuracy: 0.9758 - val_loss: 1.7298 - val_accuracy: 0.4871\n","Epoch 12/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0488 - accuracy: 0.9828 - val_loss: 2.0487 - val_accuracy: 0.4860\n","Epoch 13/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0335 - accuracy: 0.9895 - val_loss: 2.0090 - val_accuracy: 0.4849\n","Epoch 14/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0360 - accuracy: 0.9892 - val_loss: 1.6054 - val_accuracy: 0.5162\n","Epoch 15/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0557 - accuracy: 0.9806 - val_loss: 1.2257 - val_accuracy: 0.5399\n","Epoch 16/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0648 - accuracy: 0.9787 - val_loss: 1.1032 - val_accuracy: 0.5657\n","Epoch 17/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0410 - accuracy: 0.9865 - val_loss: 1.3334 - val_accuracy: 0.5560\n","Epoch 18/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0307 - accuracy: 0.9916 - val_loss: 1.1410 - val_accuracy: 0.6228\n","Epoch 19/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0341 - accuracy: 0.9884 - val_loss: 1.1051 - val_accuracy: 0.6444\n","Epoch 20/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0416 - accuracy: 0.9871 - val_loss: 0.9283 - val_accuracy: 0.7015\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0475 - accuracy: 0.9836 - val_loss: 0.9573 - val_accuracy: 0.6832\n","Epoch 22/100\n","29/29 [==============================] - 1s 45ms/step - loss: 0.0458 - accuracy: 0.9873 - val_loss: 0.9813 - val_accuracy: 0.7101\n","Epoch 23/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0662 - accuracy: 0.9768 - val_loss: 0.8751 - val_accuracy: 0.7198\n","Epoch 24/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0544 - accuracy: 0.9811 - val_loss: 0.9266 - val_accuracy: 0.7295\n","Epoch 25/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0351 - accuracy: 0.9895 - val_loss: 0.9165 - val_accuracy: 0.7586\n","Epoch 26/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.0267 - accuracy: 0.9933 - val_loss: 0.9127 - val_accuracy: 0.7780\n","Epoch 27/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0349 - accuracy: 0.9884 - val_loss: 0.9016 - val_accuracy: 0.7651\n","Epoch 28/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0586 - accuracy: 0.9803 - val_loss: 0.8899 - val_accuracy: 0.7619\n","Epoch 29/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0501 - accuracy: 0.9852 - val_loss: 0.8408 - val_accuracy: 0.7769\n","Epoch 30/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0534 - accuracy: 0.9825 - val_loss: 0.8608 - val_accuracy: 0.7705\n","Epoch 31/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0387 - accuracy: 0.9895 - val_loss: 0.9332 - val_accuracy: 0.7726\n","Epoch 32/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0316 - accuracy: 0.9903 - val_loss: 1.0200 - val_accuracy: 0.7565\n","Epoch 33/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0401 - accuracy: 0.9865 - val_loss: 0.9378 - val_accuracy: 0.7759\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0398 - accuracy: 0.9873 - val_loss: 0.9407 - val_accuracy: 0.7716\n","Epoch 35/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0379 - accuracy: 0.9892 - val_loss: 0.8270 - val_accuracy: 0.7716\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0223 - accuracy: 0.9946 - val_loss: 1.0045 - val_accuracy: 0.7619\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0289 - accuracy: 0.9922 - val_loss: 1.1398 - val_accuracy: 0.7651\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0329 - accuracy: 0.9895 - val_loss: 0.9890 - val_accuracy: 0.7532\n","Epoch 39/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0529 - accuracy: 0.9806 - val_loss: 1.2395 - val_accuracy: 0.7263\n","Epoch 40/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0657 - accuracy: 0.9801 - val_loss: 0.8447 - val_accuracy: 0.7672\n","Epoch 41/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0277 - accuracy: 0.9927 - val_loss: 0.9565 - val_accuracy: 0.7737\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0212 - accuracy: 0.9946 - val_loss: 1.0836 - val_accuracy: 0.7651\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0178 - accuracy: 0.9957 - val_loss: 1.0183 - val_accuracy: 0.7780\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0163 - accuracy: 0.9960 - val_loss: 1.0701 - val_accuracy: 0.7769\n","Epoch 45/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0145 - accuracy: 0.9973 - val_loss: 1.0608 - val_accuracy: 0.7780\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0166 - accuracy: 0.9962 - val_loss: 1.0652 - val_accuracy: 0.7737\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0159 - accuracy: 0.9952 - val_loss: 1.0882 - val_accuracy: 0.7629\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0243 - accuracy: 0.9927 - val_loss: 0.9736 - val_accuracy: 0.7716\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0219 - accuracy: 0.9952 - val_loss: 1.0931 - val_accuracy: 0.7748\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0238 - accuracy: 0.9935 - val_loss: 1.0890 - val_accuracy: 0.7662\n","Epoch 51/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0303 - accuracy: 0.9906 - val_loss: 1.1086 - val_accuracy: 0.7468\n","Epoch 52/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0455 - accuracy: 0.9863 - val_loss: 1.1148 - val_accuracy: 0.7575\n","Epoch 53/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0504 - accuracy: 0.9849 - val_loss: 1.1233 - val_accuracy: 0.7306\n","Epoch 54/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0566 - accuracy: 0.9825 - val_loss: 1.0497 - val_accuracy: 0.7381\n","Epoch 55/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0774 - accuracy: 0.9733 - val_loss: 0.9403 - val_accuracy: 0.7565\n","Epoch 56/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0519 - accuracy: 0.9833 - val_loss: 0.9156 - val_accuracy: 0.7651\n","Epoch 57/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0313 - accuracy: 0.9898 - val_loss: 1.0224 - val_accuracy: 0.7608\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0305 - accuracy: 0.9908 - val_loss: 1.1173 - val_accuracy: 0.7619\n","Epoch 59/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0417 - accuracy: 0.9855 - val_loss: 1.1921 - val_accuracy: 0.7198\n","Epoch 60/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0528 - accuracy: 0.9836 - val_loss: 0.9998 - val_accuracy: 0.7446\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0333 - accuracy: 0.9903 - val_loss: 1.1654 - val_accuracy: 0.7317\n","Epoch 62/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0328 - accuracy: 0.9930 - val_loss: 1.0276 - val_accuracy: 0.7360\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 1.2288 - val_accuracy: 0.7446\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0305 - accuracy: 0.9906 - val_loss: 1.2635 - val_accuracy: 0.7284\n","Epoch 65/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0326 - accuracy: 0.9890 - val_loss: 1.1354 - val_accuracy: 0.7349\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0339 - accuracy: 0.9895 - val_loss: 1.1481 - val_accuracy: 0.7231\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0252 - accuracy: 0.9952 - val_loss: 1.2146 - val_accuracy: 0.7241\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0198 - accuracy: 0.9946 - val_loss: 1.1152 - val_accuracy: 0.7392\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0248 - accuracy: 0.9927 - val_loss: 1.1525 - val_accuracy: 0.7425\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0265 - accuracy: 0.9927 - val_loss: 1.1967 - val_accuracy: 0.7144\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0348 - accuracy: 0.9884 - val_loss: 1.0962 - val_accuracy: 0.7522\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0260 - accuracy: 0.9930 - val_loss: 1.0736 - val_accuracy: 0.7532\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0247 - accuracy: 0.9935 - val_loss: 1.2323 - val_accuracy: 0.7403\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0355 - accuracy: 0.9895 - val_loss: 1.2729 - val_accuracy: 0.7112\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0620 - accuracy: 0.9782 - val_loss: 1.0110 - val_accuracy: 0.7371\n","Epoch 76/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0433 - accuracy: 0.9876 - val_loss: 1.0529 - val_accuracy: 0.7414\n","Epoch 77/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0316 - accuracy: 0.9906 - val_loss: 1.1148 - val_accuracy: 0.7338\n","Epoch 78/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0470 - accuracy: 0.9841 - val_loss: 0.9888 - val_accuracy: 0.7263\n","Epoch 79/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0357 - accuracy: 0.9884 - val_loss: 1.1055 - val_accuracy: 0.7425\n","Epoch 80/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0335 - accuracy: 0.9898 - val_loss: 1.1982 - val_accuracy: 0.7177\n","Epoch 81/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0381 - accuracy: 0.9881 - val_loss: 1.0736 - val_accuracy: 0.7295\n","Epoch 82/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0281 - accuracy: 0.9927 - val_loss: 1.3331 - val_accuracy: 0.7403\n","Epoch 83/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0288 - accuracy: 0.9911 - val_loss: 1.1721 - val_accuracy: 0.7414\n","Epoch 84/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0369 - accuracy: 0.9890 - val_loss: 1.2073 - val_accuracy: 0.7231\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0335 - accuracy: 0.9884 - val_loss: 1.1083 - val_accuracy: 0.7360\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0292 - accuracy: 0.9919 - val_loss: 1.2616 - val_accuracy: 0.7231\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0309 - accuracy: 0.9906 - val_loss: 1.2969 - val_accuracy: 0.7328\n","Epoch 88/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0285 - accuracy: 0.9927 - val_loss: 1.2155 - val_accuracy: 0.7435\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 1.1975 - val_accuracy: 0.7392\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0213 - accuracy: 0.9954 - val_loss: 1.1698 - val_accuracy: 0.7619\n","Epoch 91/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0226 - accuracy: 0.9935 - val_loss: 1.3863 - val_accuracy: 0.7166\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0487 - accuracy: 0.9844 - val_loss: 1.0969 - val_accuracy: 0.7188\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0247 - accuracy: 0.9946 - val_loss: 1.1664 - val_accuracy: 0.7284\n","Epoch 94/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0176 - accuracy: 0.9960 - val_loss: 1.3030 - val_accuracy: 0.7263\n","Epoch 95/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0178 - accuracy: 0.9957 - val_loss: 1.3299 - val_accuracy: 0.7188\n","Epoch 96/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0183 - accuracy: 0.9957 - val_loss: 1.2285 - val_accuracy: 0.7392\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0155 - accuracy: 0.9965 - val_loss: 1.2055 - val_accuracy: 0.7231\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0146 - accuracy: 0.9976 - val_loss: 1.2610 - val_accuracy: 0.7414\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0127 - accuracy: 0.9981 - val_loss: 1.2829 - val_accuracy: 0.7284\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 1.1950 - val_accuracy: 0.7457\n","{'loss': [0.13356709480285645, 0.07120773941278458, 0.056833766400814056, 0.07739469408988953, 0.0750775933265686, 0.0460108183324337, 0.03387733921408653, 0.0628594383597374, 0.06943579018115997, 0.045615244656801224, 0.06750475615262985, 0.04878953471779823, 0.03348798304796219, 0.03601986542344093, 0.0557052306830883, 0.06479485332965851, 0.04100655019283295, 0.03074399009346962, 0.034112703055143356, 0.04157339036464691, 0.04751889035105705, 0.04583168774843216, 0.06620682775974274, 0.05441693216562271, 0.035106826573610306, 0.026709940284490585, 0.034881576895713806, 0.058614857494831085, 0.050148870795965195, 0.05343622341752052, 0.03865395486354828, 0.03164159134030342, 0.040091656148433685, 0.039801690727472305, 0.037904754281044006, 0.022329648956656456, 0.02888796478509903, 0.03287006914615631, 0.052892256528139114, 0.06574656069278717, 0.027688516303896904, 0.021201230585575104, 0.01784752495586872, 0.016256319358944893, 0.014531255699694157, 0.016578806564211845, 0.01591678149998188, 0.024284426122903824, 0.021921781823039055, 0.023754311725497246, 0.030329089611768723, 0.045532628893852234, 0.050428614020347595, 0.0565900094807148, 0.07739536464214325, 0.05192234367132187, 0.03128526359796524, 0.03052542544901371, 0.041671160608530045, 0.05277935042977333, 0.03333434462547302, 0.03282881900668144, 0.024313723668456078, 0.03047766163945198, 0.0325816348195076, 0.03394361212849617, 0.0251570213586092, 0.019840439781546593, 0.02481766603887081, 0.02646614797413349, 0.034816499799489975, 0.025957705453038216, 0.02472805418074131, 0.035543035715818405, 0.062040064483881, 0.0433071106672287, 0.031555913388729095, 0.04700462520122528, 0.03565162792801857, 0.03353077918291092, 0.038138262927532196, 0.028129620477557182, 0.028812861070036888, 0.03690517321228981, 0.03352314978837967, 0.029168637469410896, 0.030904170125722885, 0.028465883806347847, 0.021281210705637932, 0.021276820451021194, 0.022593947127461433, 0.048657242208719254, 0.0246985275298357, 0.017590558156371117, 0.017775461077690125, 0.018309373408555984, 0.015484432689845562, 0.01460384950041771, 0.012686917558312416, 0.012274026870727539], 'accuracy': [0.9579741358757019, 0.975215494632721, 0.9816810488700867, 0.9709051847457886, 0.9722521305084229, 0.985722005367279, 0.9889547228813171, 0.9789870977401733, 0.975215494632721, 0.9851831793785095, 0.9757543206214905, 0.982758641242981, 0.9894935488700867, 0.9892241358757019, 0.9806034564971924, 0.9787176847457886, 0.9865301847457886, 0.9916487336158752, 0.9884159564971924, 0.9870689511299133, 0.9835668206214905, 0.9873383641242981, 0.9768319129943848, 0.9811422228813171, 0.9894935488700867, 0.9932650923728943, 0.9884159564971924, 0.9803340435028076, 0.9851831793785095, 0.9824892282485962, 0.9894935488700867, 0.9903017282485962, 0.9865301847457886, 0.9873383641242981, 0.9892241358757019, 0.9946120977401733, 0.9921875, 0.9894935488700867, 0.9806034564971924, 0.9800646305084229, 0.9927262663841248, 0.9946120977401733, 0.9956896305084229, 0.9959590435028076, 0.9973060488700867, 0.9962284564971924, 0.9951508641242981, 0.9927262663841248, 0.9951508641242981, 0.993534505367279, 0.990571141242981, 0.9862607717514038, 0.9849137663841248, 0.9824892282485962, 0.9733297228813171, 0.9832974076271057, 0.9897629022598267, 0.990840494632721, 0.9854525923728943, 0.9835668206214905, 0.9903017282485962, 0.9929956793785095, 0.9919180870056152, 0.990571141242981, 0.9889547228813171, 0.9894935488700867, 0.9951508641242981, 0.9946120977401733, 0.9927262663841248, 0.9927262663841248, 0.9884159564971924, 0.9929956793785095, 0.993534505367279, 0.9894935488700867, 0.978178858757019, 0.9876077771186829, 0.990571141242981, 0.9841055870056152, 0.9884159564971924, 0.9897629022598267, 0.9881465435028076, 0.9927262663841248, 0.9911099076271057, 0.9889547228813171, 0.9884159564971924, 0.9919180870056152, 0.990571141242981, 0.9927262663841248, 0.993803858757019, 0.9954202771186829, 0.993534505367279, 0.984375, 0.9946120977401733, 0.9959590435028076, 0.9956896305084229, 0.9956896305084229, 0.9964978694915771, 0.9975754022598267, 0.9981142282485962, 0.9973060488700867], 'val_loss': [0.8667868971824646, 1.0190447568893433, 1.0965152978897095, 1.0707335472106934, 1.220299482345581, 1.4414324760437012, 1.7011005878448486, 1.6748287677764893, 1.6889523267745972, 1.6935831308364868, 1.729792833328247, 2.048689126968384, 2.009021282196045, 1.6054469347000122, 1.2257053852081299, 1.1031733751296997, 1.3333529233932495, 1.1410362720489502, 1.105073094367981, 0.9282546043395996, 0.9572774767875671, 0.9813034534454346, 0.8750851154327393, 0.9265653491020203, 0.916467547416687, 0.9126694202423096, 0.9016197919845581, 0.8898853659629822, 0.8407751321792603, 0.8608017563819885, 0.9332093000411987, 1.0199897289276123, 0.9377926588058472, 0.9406549334526062, 0.8269505500793457, 1.0044989585876465, 1.1398104429244995, 0.988968014717102, 1.2394678592681885, 0.84466153383255, 0.956467866897583, 1.0836261510849, 1.0182621479034424, 1.0700840950012207, 1.0607649087905884, 1.0651969909667969, 1.0882461071014404, 0.9736228585243225, 1.0931003093719482, 1.0890077352523804, 1.1085913181304932, 1.1148024797439575, 1.1233388185501099, 1.049660086631775, 0.9403072595596313, 0.9156094193458557, 1.0223965644836426, 1.1173125505447388, 1.192070722579956, 0.9997859597206116, 1.165377140045166, 1.0275524854660034, 1.2287653684616089, 1.2634879350662231, 1.135433554649353, 1.1481208801269531, 1.2145916223526, 1.1152212619781494, 1.152548909187317, 1.196669101715088, 1.0962252616882324, 1.073562502861023, 1.2322564125061035, 1.272891879081726, 1.0109617710113525, 1.0528806447982788, 1.1147865056991577, 0.9888085126876831, 1.1054811477661133, 1.1981827020645142, 1.0735516548156738, 1.333052158355713, 1.1720902919769287, 1.2073209285736084, 1.108296513557434, 1.2616219520568848, 1.296879768371582, 1.2154574394226074, 1.1974878311157227, 1.1698018312454224, 1.3862873315811157, 1.0968855619430542, 1.1664323806762695, 1.3030208349227905, 1.3299262523651123, 1.2285432815551758, 1.2054942846298218, 1.2609738111495972, 1.2828857898712158, 1.1949516534805298], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.4903017282485962, 0.48706895112991333, 0.48599138855934143, 0.48491379618644714, 0.5161637663841248, 0.5398706793785095, 0.5657327771186829, 0.556034505367279, 0.6228448152542114, 0.6443965435028076, 0.701508641242981, 0.6831896305084229, 0.7101293206214905, 0.7198275923728943, 0.7295258641242981, 0.7586206793785095, 0.7780172228813171, 0.7650862336158752, 0.7618534564971924, 0.7769396305084229, 0.7704741358757019, 0.7726293206214905, 0.756465494632721, 0.7758620977401733, 0.7715517282485962, 0.7715517282485962, 0.7618534564971924, 0.7650862336158752, 0.7532327771186829, 0.7262930870056152, 0.767241358757019, 0.7737069129943848, 0.7650862336158752, 0.7780172228813171, 0.7769396305084229, 0.7780172228813171, 0.7737069129943848, 0.7629310488700867, 0.7715517282485962, 0.774784505367279, 0.7661637663841248, 0.7467672228813171, 0.7575430870056152, 0.7306034564971924, 0.7381465435028076, 0.756465494632721, 0.7650862336158752, 0.7607758641242981, 0.7618534564971924, 0.7198275923728943, 0.7446120977401733, 0.7316810488700867, 0.735991358757019, 0.7446120977401733, 0.7284482717514038, 0.7349137663841248, 0.7230603694915771, 0.7241379022598267, 0.7392241358757019, 0.7424569129943848, 0.7144396305084229, 0.7521551847457886, 0.7532327771186829, 0.7403017282485962, 0.7112069129943848, 0.7370689511299133, 0.7413793206214905, 0.7338362336158752, 0.7262930870056152, 0.7424569129943848, 0.7176724076271057, 0.7295258641242981, 0.7403017282485962, 0.7413793206214905, 0.7230603694915771, 0.735991358757019, 0.7230603694915771, 0.732758641242981, 0.743534505367279, 0.7392241358757019, 0.7618534564971924, 0.7165948152542114, 0.71875, 0.7284482717514038, 0.7262930870056152, 0.71875, 0.7392241358757019, 0.7230603694915771, 0.7413793206214905, 0.7284482717514038, 0.7456896305084229]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.1160 - accuracy: 0.9670"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 9s 92ms/step - loss: 0.1164 - accuracy: 0.9666 - val_loss: 0.8513 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0813 - accuracy: 0.9743 - val_loss: 0.9943 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0536 - accuracy: 0.9822 - val_loss: 1.0568 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0622 - accuracy: 0.9808 - val_loss: 1.1701 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0703 - accuracy: 0.9771 - val_loss: 1.3129 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0616 - accuracy: 0.9808 - val_loss: 1.3355 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0455 - accuracy: 0.9853 - val_loss: 1.6721 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0386 - accuracy: 0.9881 - val_loss: 1.8335 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0429 - accuracy: 0.9878 - val_loss: 1.8454 - val_accuracy: 0.4955\n","Epoch 10/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0540 - accuracy: 0.9816 - val_loss: 1.8775 - val_accuracy: 0.4955\n","Epoch 11/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0438 - accuracy: 0.9867 - val_loss: 2.0536 - val_accuracy: 0.4955\n","Epoch 12/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0341 - accuracy: 0.9901 - val_loss: 2.1641 - val_accuracy: 0.4955\n","Epoch 13/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.0666 - accuracy: 0.9757 - val_loss: 1.7232 - val_accuracy: 0.4966\n","Epoch 14/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.0713 - accuracy: 0.9788 - val_loss: 1.5812 - val_accuracy: 0.5045\n","Epoch 15/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.0645 - accuracy: 0.9805 - val_loss: 1.5572 - val_accuracy: 0.5136\n","Epoch 16/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0312 - accuracy: 0.9915 - val_loss: 1.9750 - val_accuracy: 0.5090\n","Epoch 17/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0246 - accuracy: 0.9932 - val_loss: 1.7001 - val_accuracy: 0.5396\n","Epoch 18/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0269 - accuracy: 0.9932 - val_loss: 1.2796 - val_accuracy: 0.6075\n","Epoch 19/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0267 - accuracy: 0.9935 - val_loss: 1.7692 - val_accuracy: 0.5758\n","Epoch 20/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0753 - accuracy: 0.9743 - val_loss: 0.9039 - val_accuracy: 0.6414\n","Epoch 21/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0678 - accuracy: 0.9791 - val_loss: 0.8137 - val_accuracy: 0.7059\n","Epoch 22/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0363 - accuracy: 0.9887 - val_loss: 0.8579 - val_accuracy: 0.7421\n","Epoch 23/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0360 - accuracy: 0.9884 - val_loss: 0.9466 - val_accuracy: 0.7410\n","Epoch 24/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0466 - accuracy: 0.9847 - val_loss: 1.0332 - val_accuracy: 0.7217\n","Epoch 25/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0617 - accuracy: 0.9805 - val_loss: 0.7818 - val_accuracy: 0.7579\n","Epoch 26/100\n","28/28 [==============================] - 1s 43ms/step - loss: 0.0374 - accuracy: 0.9881 - val_loss: 0.7731 - val_accuracy: 0.7658\n","Epoch 27/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0178 - accuracy: 0.9955 - val_loss: 0.7689 - val_accuracy: 0.7839\n","Epoch 28/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0234 - accuracy: 0.9938 - val_loss: 0.7994 - val_accuracy: 0.7851\n","Epoch 29/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0283 - accuracy: 0.9924 - val_loss: 0.7104 - val_accuracy: 0.7941\n","Epoch 30/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0264 - accuracy: 0.9915 - val_loss: 0.7217 - val_accuracy: 0.7941\n","Epoch 31/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.0299 - accuracy: 0.9918 - val_loss: 0.8909 - val_accuracy: 0.7964\n","Epoch 32/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0387 - accuracy: 0.9895 - val_loss: 0.8457 - val_accuracy: 0.7862\n","Epoch 33/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0522 - accuracy: 0.9827 - val_loss: 0.9643 - val_accuracy: 0.7477\n","Epoch 34/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0400 - accuracy: 0.9881 - val_loss: 0.7671 - val_accuracy: 0.7896\n","Epoch 35/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0321 - accuracy: 0.9909 - val_loss: 0.8753 - val_accuracy: 0.7828\n","Epoch 36/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0728 - accuracy: 0.9754 - val_loss: 0.8100 - val_accuracy: 0.7726\n","Epoch 37/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0453 - accuracy: 0.9859 - val_loss: 0.9295 - val_accuracy: 0.7658\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0409 - accuracy: 0.9861 - val_loss: 0.8917 - val_accuracy: 0.7704\n","Epoch 39/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0291 - accuracy: 0.9921 - val_loss: 0.8808 - val_accuracy: 0.7907\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0196 - accuracy: 0.9955 - val_loss: 0.9029 - val_accuracy: 0.7907\n","Epoch 41/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.9111 - val_accuracy: 0.8043\n","Epoch 42/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0433 - accuracy: 0.9875 - val_loss: 0.9686 - val_accuracy: 0.7749\n","Epoch 43/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0369 - accuracy: 0.9907 - val_loss: 0.8473 - val_accuracy: 0.7851\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0347 - accuracy: 0.9909 - val_loss: 0.8161 - val_accuracy: 0.7771\n","Epoch 45/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0377 - accuracy: 0.9878 - val_loss: 1.1291 - val_accuracy: 0.7489\n","Epoch 46/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0333 - accuracy: 0.9892 - val_loss: 0.9908 - val_accuracy: 0.7557\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0380 - accuracy: 0.9895 - val_loss: 0.8759 - val_accuracy: 0.7658\n","Epoch 48/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0403 - accuracy: 0.9875 - val_loss: 1.0161 - val_accuracy: 0.7624\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0356 - accuracy: 0.9881 - val_loss: 1.0704 - val_accuracy: 0.7523\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0302 - accuracy: 0.9912 - val_loss: 0.9652 - val_accuracy: 0.7704\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0318 - accuracy: 0.9909 - val_loss: 1.0039 - val_accuracy: 0.7738\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0252 - accuracy: 0.9924 - val_loss: 0.9650 - val_accuracy: 0.7726\n","Epoch 53/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0420 - accuracy: 0.9864 - val_loss: 0.9313 - val_accuracy: 0.7658\n","Epoch 54/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0555 - accuracy: 0.9816 - val_loss: 0.8181 - val_accuracy: 0.7624\n","Epoch 55/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0332 - accuracy: 0.9904 - val_loss: 0.9354 - val_accuracy: 0.7749\n","Epoch 56/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0220 - accuracy: 0.9943 - val_loss: 1.0348 - val_accuracy: 0.7613\n","Epoch 57/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0231 - accuracy: 0.9946 - val_loss: 0.9862 - val_accuracy: 0.7670\n","Epoch 58/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0307 - accuracy: 0.9912 - val_loss: 1.0186 - val_accuracy: 0.7557\n","Epoch 59/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0252 - accuracy: 0.9946 - val_loss: 1.0682 - val_accuracy: 0.7613\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0362 - accuracy: 0.9887 - val_loss: 1.1674 - val_accuracy: 0.7421\n","Epoch 61/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0691 - accuracy: 0.9768 - val_loss: 0.8749 - val_accuracy: 0.7590\n","Epoch 62/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 0.9464 - val_accuracy: 0.7477\n","Epoch 63/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0300 - accuracy: 0.9926 - val_loss: 0.9921 - val_accuracy: 0.7602\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0287 - accuracy: 0.9935 - val_loss: 0.9114 - val_accuracy: 0.7681\n","Epoch 65/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0356 - accuracy: 0.9895 - val_loss: 0.9764 - val_accuracy: 0.7455\n","Epoch 66/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0272 - accuracy: 0.9926 - val_loss: 0.9241 - val_accuracy: 0.7760\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0192 - accuracy: 0.9958 - val_loss: 0.9614 - val_accuracy: 0.7828\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.9800 - val_accuracy: 0.7919\n","Epoch 69/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0298 - accuracy: 0.9912 - val_loss: 1.1251 - val_accuracy: 0.7376\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0318 - accuracy: 0.9915 - val_loss: 0.9163 - val_accuracy: 0.7828\n","Epoch 71/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0258 - accuracy: 0.9946 - val_loss: 0.8701 - val_accuracy: 0.7749\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0187 - accuracy: 0.9952 - val_loss: 0.9934 - val_accuracy: 0.7986\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0220 - accuracy: 0.9949 - val_loss: 1.1029 - val_accuracy: 0.7602\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0380 - accuracy: 0.9861 - val_loss: 0.9333 - val_accuracy: 0.7692\n","Epoch 75/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0501 - accuracy: 0.9859 - val_loss: 1.0152 - val_accuracy: 0.7296\n","Epoch 76/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0387 - accuracy: 0.9892 - val_loss: 0.9313 - val_accuracy: 0.7613\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0272 - accuracy: 0.9924 - val_loss: 1.2056 - val_accuracy: 0.7500\n","Epoch 78/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0327 - accuracy: 0.9890 - val_loss: 0.9974 - val_accuracy: 0.7557\n","Epoch 79/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0281 - accuracy: 0.9921 - val_loss: 0.9059 - val_accuracy: 0.7523\n","Epoch 80/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0178 - accuracy: 0.9969 - val_loss: 1.0454 - val_accuracy: 0.7624\n","Epoch 81/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0157 - accuracy: 0.9980 - val_loss: 0.9580 - val_accuracy: 0.7760\n","Epoch 82/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 1.0030 - val_accuracy: 0.7873\n","Epoch 83/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0129 - accuracy: 0.9977 - val_loss: 0.9841 - val_accuracy: 0.7636\n","Epoch 84/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0131 - accuracy: 0.9972 - val_loss: 0.9917 - val_accuracy: 0.7545\n","Epoch 85/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0174 - accuracy: 0.9966 - val_loss: 1.1768 - val_accuracy: 0.7364\n","Epoch 86/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0174 - accuracy: 0.9969 - val_loss: 1.3807 - val_accuracy: 0.7262\n","Epoch 87/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0454 - accuracy: 0.9878 - val_loss: 0.9236 - val_accuracy: 0.7568\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0332 - accuracy: 0.9926 - val_loss: 1.0347 - val_accuracy: 0.7364\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0224 - accuracy: 0.9941 - val_loss: 1.0978 - val_accuracy: 0.7534\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0273 - accuracy: 0.9924 - val_loss: 1.1315 - val_accuracy: 0.7274\n","Epoch 91/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0647 - accuracy: 0.9788 - val_loss: 0.9196 - val_accuracy: 0.7319\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0406 - accuracy: 0.9873 - val_loss: 0.9914 - val_accuracy: 0.7579\n","Epoch 93/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0321 - accuracy: 0.9875 - val_loss: 1.2126 - val_accuracy: 0.7240\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0603 - accuracy: 0.9776 - val_loss: 1.0177 - val_accuracy: 0.7296\n","Epoch 95/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0489 - accuracy: 0.9853 - val_loss: 0.9669 - val_accuracy: 0.7568\n","Epoch 96/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0269 - accuracy: 0.9938 - val_loss: 1.1380 - val_accuracy: 0.7229\n","Epoch 97/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0250 - accuracy: 0.9932 - val_loss: 1.1077 - val_accuracy: 0.7489\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0204 - accuracy: 0.9941 - val_loss: 1.1576 - val_accuracy: 0.7523\n","Epoch 99/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0205 - accuracy: 0.9946 - val_loss: 1.1911 - val_accuracy: 0.7398\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 1.0985 - val_accuracy: 0.7658\n","{'loss': [0.11636605858802795, 0.08130224794149399, 0.05364559590816498, 0.06220538914203644, 0.07031549513339996, 0.06156466156244278, 0.045490335673093796, 0.03863634541630745, 0.04288797825574875, 0.053952064365148544, 0.04375457391142845, 0.03414812684059143, 0.06660421937704086, 0.07131227850914001, 0.06446021795272827, 0.03116503544151783, 0.024624278768897057, 0.026853293180465698, 0.02673090063035488, 0.07530107349157333, 0.06782843917608261, 0.036342181265354156, 0.03603529557585716, 0.04661887511610985, 0.06171390414237976, 0.03741725906729698, 0.017826268449425697, 0.02338099107146263, 0.028267454355955124, 0.026388462632894516, 0.029894258826971054, 0.03872999921441078, 0.05222950875759125, 0.039967428892850876, 0.032130807638168335, 0.07278847694396973, 0.04533762484788895, 0.040863119065761566, 0.029056334868073463, 0.01957537792623043, 0.019527267664670944, 0.043337978422641754, 0.036949269473552704, 0.03465829789638519, 0.037663284689188004, 0.033261340111494064, 0.03796372190117836, 0.040311068296432495, 0.0355866365134716, 0.030224325135350227, 0.031765952706336975, 0.025230517610907555, 0.04195725545287132, 0.05554983764886856, 0.03320496529340744, 0.02204032801091671, 0.023077167570590973, 0.030687080696225166, 0.025216398760676384, 0.036165643483400345, 0.06911883503198624, 0.05310438200831413, 0.030003055930137634, 0.028663575649261475, 0.0356452576816082, 0.02718563936650753, 0.019203050062060356, 0.021525602787733078, 0.02979435585439205, 0.03179234266281128, 0.025824451819062233, 0.01865883357822895, 0.022046232596039772, 0.03804539516568184, 0.05013026297092438, 0.03874801844358444, 0.027248164638876915, 0.03268840163946152, 0.02808266133069992, 0.017771488055586815, 0.015693308785557747, 0.014348805882036686, 0.012919553555548191, 0.013053522445261478, 0.0174186322838068, 0.01739894226193428, 0.04537874087691307, 0.0332023948431015, 0.022391922771930695, 0.027331452816724777, 0.06473889201879501, 0.04062259942293167, 0.03207995742559433, 0.06034165993332863, 0.04890751466155052, 0.026874369010329247, 0.025020040571689606, 0.020441221073269844, 0.020486855879426003, 0.015537559986114502], 'accuracy': [0.9666100740432739, 0.9742501378059387, 0.9821732044219971, 0.9807583689689636, 0.9770798087120056, 0.9807583689689636, 0.9852858185768127, 0.9881154298782349, 0.9878324866294861, 0.9816072583198547, 0.9867005944252014, 0.9900962114334106, 0.9756649732589722, 0.9787775874137878, 0.9804753661155701, 0.9915110468864441, 0.9932088255882263, 0.9932088255882263, 0.9934917688369751, 0.9742501378059387, 0.9790605306625366, 0.9886813759803772, 0.9883984327316284, 0.9847198724746704, 0.9804753661155701, 0.9881154298782349, 0.9954725503921509, 0.9937747716903687, 0.9923599362373352, 0.9915110468864441, 0.9917939901351929, 0.9895302653312683, 0.9827390909194946, 0.9881154298782349, 0.9909451007843018, 0.9753820300102234, 0.9858517050743103, 0.9861347079277039, 0.9920769929885864, 0.9954725503921509, 0.994340717792511, 0.9875495433807373, 0.990662157535553, 0.9909451007843018, 0.9878324866294861, 0.9892473220825195, 0.9895302653312683, 0.9875495433807373, 0.9881154298782349, 0.9912280440330505, 0.9909451007843018, 0.9923599362373352, 0.9864176511764526, 0.9816072583198547, 0.9903791546821594, 0.994340717792511, 0.9946236610412598, 0.9912280440330505, 0.9946236610412598, 0.9886813759803772, 0.9767968058586121, 0.9810413122177124, 0.992642879486084, 0.9934917688369751, 0.9895302653312683, 0.992642879486084, 0.9957554936408997, 0.9932088255882263, 0.9912280440330505, 0.9915110468864441, 0.9946236610412598, 0.9951896071434021, 0.9949066042900085, 0.9861347079277039, 0.9858517050743103, 0.9892473220825195, 0.9923599362373352, 0.988964319229126, 0.9920769929885864, 0.9968873858451843, 0.9980192184448242, 0.9968873858451843, 0.9977362751960754, 0.9971703290939331, 0.9966044425964355, 0.9968873858451843, 0.9878324866294861, 0.992642879486084, 0.9940577149391174, 0.9923599362373352, 0.9787775874137878, 0.9872665405273438, 0.9875495433807373, 0.977645754814148, 0.9852858185768127, 0.9937747716903687, 0.9932088255882263, 0.9940577149391174, 0.9946236610412598, 0.996321439743042], 'val_loss': [0.8513092398643494, 0.9943156242370605, 1.0568047761917114, 1.1701401472091675, 1.3129103183746338, 1.335513710975647, 1.6721346378326416, 1.8335283994674683, 1.8454067707061768, 1.877495288848877, 2.053605079650879, 2.164071798324585, 1.7231769561767578, 1.5812016725540161, 1.5571887493133545, 1.9750380516052246, 1.7000682353973389, 1.279550552368164, 1.769182562828064, 0.9039355516433716, 0.8137129545211792, 0.8578975200653076, 0.9465794563293457, 1.0331701040267944, 0.7817531824111938, 0.7731476426124573, 0.7689304351806641, 0.7993940711021423, 0.7104078531265259, 0.721696674823761, 0.8908900618553162, 0.8457484841346741, 0.9642949104309082, 0.7670679688453674, 0.8753073215484619, 0.8099954128265381, 0.9295408725738525, 0.8916977643966675, 0.8808339834213257, 0.9028917551040649, 0.9111014604568481, 0.9685558080673218, 0.8473332524299622, 0.8160640597343445, 1.1291157007217407, 0.9907971024513245, 0.8759185075759888, 1.0161314010620117, 1.0703630447387695, 0.9651732444763184, 1.0039334297180176, 0.9649732708930969, 0.9312800765037537, 0.8181212544441223, 0.935367226600647, 1.0348312854766846, 0.9862191677093506, 1.018584132194519, 1.0682013034820557, 1.1674288511276245, 0.8748857378959656, 0.946386456489563, 0.9921309351921082, 0.9114499092102051, 0.976427435874939, 0.924119234085083, 0.96144700050354, 0.9800372123718262, 1.1251389980316162, 0.9163126349449158, 0.8700863122940063, 0.9934372901916504, 1.1029459238052368, 0.9332640171051025, 1.0151903629302979, 0.9313445687294006, 1.2056214809417725, 0.9974116683006287, 0.9059234261512756, 1.0454002618789673, 0.9579800963401794, 1.0030015707015991, 0.9841347932815552, 0.9916949272155762, 1.176771640777588, 1.3807066679000854, 0.923607587814331, 1.0347192287445068, 1.0977777242660522, 1.1315300464630127, 0.9195557236671448, 0.9913590550422668, 1.2126137018203735, 1.0177490711212158, 0.9669033885002136, 1.1380234956741333, 1.10767662525177, 1.1575590372085571, 1.191145420074463, 1.0984673500061035], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.5045248866081238, 0.5135746598243713, 0.5090497732162476, 0.5395927429199219, 0.6074660420417786, 0.5757918357849121, 0.6414027214050293, 0.7058823704719543, 0.7420814633369446, 0.7409502267837524, 0.7217194437980652, 0.7579185366630554, 0.7658371329307556, 0.7839366793632507, 0.7850678563117981, 0.7941176295280457, 0.7941176295280457, 0.7963801026344299, 0.7861990928649902, 0.7477375268936157, 0.7895927429199219, 0.7828054428100586, 0.7726244330406189, 0.7658371329307556, 0.7703620195388794, 0.790723979473114, 0.790723979473114, 0.8042986392974854, 0.7748869061470032, 0.7850678563117981, 0.7771493196487427, 0.7488687634468079, 0.7556561231613159, 0.7658371329307556, 0.7624434232711792, 0.7522624731063843, 0.7703620195388794, 0.773755669593811, 0.7726244330406189, 0.7658371329307556, 0.7624434232711792, 0.7748869061470032, 0.7613122463226318, 0.766968309879303, 0.7556561231613159, 0.7613122463226318, 0.7420814633369446, 0.7590497732162476, 0.7477375268936157, 0.7601810097694397, 0.7680995464324951, 0.7454751133918762, 0.7760180830955505, 0.7828054428100586, 0.7918552160263062, 0.7375565767288208, 0.7828054428100586, 0.7748869061470032, 0.7986425161361694, 0.7601810097694397, 0.7692307829856873, 0.7296379804611206, 0.7613122463226318, 0.75, 0.7556561231613159, 0.7522624731063843, 0.7624434232711792, 0.7760180830955505, 0.7873303294181824, 0.7635746598243713, 0.7545248866081238, 0.7364253401756287, 0.726244330406189, 0.7567873597145081, 0.7364253401756287, 0.7533936500549316, 0.7273755669593811, 0.7319004535675049, 0.7579185366630554, 0.7239819169044495, 0.7296379804611206, 0.7567873597145081, 0.7228506803512573, 0.7488687634468079, 0.7522624731063843, 0.7398189902305603, 0.7658371329307556]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.1304 - accuracy: 0.9505"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 65ms/step - loss: 0.1312 - accuracy: 0.9506 - val_loss: 0.8820 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0812 - accuracy: 0.9731 - val_loss: 1.0027 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0757 - accuracy: 0.9734 - val_loss: 1.0548 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0633 - accuracy: 0.9762 - val_loss: 1.1635 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0448 - accuracy: 0.9858 - val_loss: 1.4931 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0680 - accuracy: 0.9780 - val_loss: 1.4685 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1098 - accuracy: 0.9618 - val_loss: 1.4269 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0607 - accuracy: 0.9801 - val_loss: 1.6845 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0818 - accuracy: 0.9700 - val_loss: 1.6712 - val_accuracy: 0.4866\n","Epoch 10/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0595 - accuracy: 0.9804 - val_loss: 1.8057 - val_accuracy: 0.4866\n","Epoch 11/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0588 - accuracy: 0.9822 - val_loss: 1.9377 - val_accuracy: 0.4876\n","Epoch 12/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0490 - accuracy: 0.9840 - val_loss: 1.6933 - val_accuracy: 0.4969\n","Epoch 13/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0684 - accuracy: 0.9773 - val_loss: 1.3374 - val_accuracy: 0.5248\n","Epoch 14/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0673 - accuracy: 0.9767 - val_loss: 1.2175 - val_accuracy: 0.5341\n","Epoch 15/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.0562 - accuracy: 0.9817 - val_loss: 1.1306 - val_accuracy: 0.5795\n","Epoch 16/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.0674 - accuracy: 0.9765 - val_loss: 1.1934 - val_accuracy: 0.5837\n","Epoch 17/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0842 - accuracy: 0.9713 - val_loss: 1.1736 - val_accuracy: 0.5806\n","Epoch 18/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.0522 - accuracy: 0.9819 - val_loss: 0.7888 - val_accuracy: 0.6952\n","Epoch 19/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0528 - accuracy: 0.9809 - val_loss: 0.8685 - val_accuracy: 0.7004\n","Epoch 20/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0588 - accuracy: 0.9809 - val_loss: 0.9629 - val_accuracy: 0.7004\n","Epoch 21/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.1171 - accuracy: 0.9612 - val_loss: 0.7592 - val_accuracy: 0.7376\n","Epoch 22/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0431 - accuracy: 0.9860 - val_loss: 0.8744 - val_accuracy: 0.7459\n","Epoch 23/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0318 - accuracy: 0.9912 - val_loss: 0.9095 - val_accuracy: 0.7583\n","Epoch 24/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0771 - accuracy: 0.9731 - val_loss: 0.9145 - val_accuracy: 0.7428\n","Epoch 25/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0691 - accuracy: 0.9721 - val_loss: 0.8767 - val_accuracy: 0.7376\n","Epoch 26/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0653 - accuracy: 0.9783 - val_loss: 1.0136 - val_accuracy: 0.7459\n","Epoch 27/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0417 - accuracy: 0.9842 - val_loss: 0.9664 - val_accuracy: 0.7531\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0423 - accuracy: 0.9873 - val_loss: 1.0257 - val_accuracy: 0.7510\n","Epoch 29/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0295 - accuracy: 0.9928 - val_loss: 0.9189 - val_accuracy: 0.7800\n","Epoch 30/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0215 - accuracy: 0.9935 - val_loss: 0.9777 - val_accuracy: 0.7841\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0207 - accuracy: 0.9959 - val_loss: 0.9749 - val_accuracy: 0.7820\n","Epoch 32/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0178 - accuracy: 0.9964 - val_loss: 1.1076 - val_accuracy: 0.7541\n","Epoch 33/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0209 - accuracy: 0.9943 - val_loss: 1.0007 - val_accuracy: 0.7779\n","Epoch 34/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0180 - accuracy: 0.9956 - val_loss: 1.0954 - val_accuracy: 0.7572\n","Epoch 35/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0246 - accuracy: 0.9930 - val_loss: 1.0288 - val_accuracy: 0.7686\n","Epoch 36/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0265 - accuracy: 0.9920 - val_loss: 1.1860 - val_accuracy: 0.7603\n","Epoch 37/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0500 - accuracy: 0.9832 - val_loss: 1.1591 - val_accuracy: 0.7252\n","Epoch 38/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0964 - accuracy: 0.9656 - val_loss: 0.9082 - val_accuracy: 0.7293\n","Epoch 39/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0924 - accuracy: 0.9659 - val_loss: 0.9714 - val_accuracy: 0.7283\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0517 - accuracy: 0.9806 - val_loss: 0.9761 - val_accuracy: 0.7397\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0409 - accuracy: 0.9855 - val_loss: 1.2277 - val_accuracy: 0.7273\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0404 - accuracy: 0.9873 - val_loss: 1.2194 - val_accuracy: 0.7283\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0361 - accuracy: 0.9899 - val_loss: 1.1615 - val_accuracy: 0.7376\n","Epoch 44/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0282 - accuracy: 0.9917 - val_loss: 1.1352 - val_accuracy: 0.7521\n","Epoch 45/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0255 - accuracy: 0.9925 - val_loss: 1.1753 - val_accuracy: 0.7603\n","Epoch 46/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0392 - accuracy: 0.9881 - val_loss: 1.1146 - val_accuracy: 0.7562\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0422 - accuracy: 0.9868 - val_loss: 1.1186 - val_accuracy: 0.7459\n","Epoch 48/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0488 - accuracy: 0.9853 - val_loss: 1.0969 - val_accuracy: 0.7293\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0354 - accuracy: 0.9879 - val_loss: 1.2338 - val_accuracy: 0.7355\n","Epoch 50/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0945 - accuracy: 0.9672 - val_loss: 0.8896 - val_accuracy: 0.7407\n","Epoch 51/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0643 - accuracy: 0.9755 - val_loss: 1.0940 - val_accuracy: 0.7335\n","Epoch 52/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0384 - accuracy: 0.9886 - val_loss: 1.1038 - val_accuracy: 0.7376\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0995 - accuracy: 0.9649 - val_loss: 0.8805 - val_accuracy: 0.7355\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0406 - accuracy: 0.9879 - val_loss: 1.0969 - val_accuracy: 0.7448\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0277 - accuracy: 0.9925 - val_loss: 1.2190 - val_accuracy: 0.7293\n","Epoch 56/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0320 - accuracy: 0.9899 - val_loss: 1.1843 - val_accuracy: 0.7531\n","Epoch 57/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0265 - accuracy: 0.9920 - val_loss: 1.1662 - val_accuracy: 0.7490\n","Epoch 58/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0510 - accuracy: 0.9817 - val_loss: 1.1516 - val_accuracy: 0.7118\n","Epoch 59/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0367 - accuracy: 0.9886 - val_loss: 1.0698 - val_accuracy: 0.7490\n","Epoch 60/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0311 - accuracy: 0.9902 - val_loss: 1.0665 - val_accuracy: 0.7469\n","Epoch 61/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0197 - accuracy: 0.9953 - val_loss: 1.1083 - val_accuracy: 0.7572\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0192 - accuracy: 0.9966 - val_loss: 1.0998 - val_accuracy: 0.7634\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0194 - accuracy: 0.9948 - val_loss: 1.1455 - val_accuracy: 0.7583\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0205 - accuracy: 0.9943 - val_loss: 1.2014 - val_accuracy: 0.7541\n","Epoch 65/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 1.1479 - val_accuracy: 0.7603\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0247 - accuracy: 0.9935 - val_loss: 1.1883 - val_accuracy: 0.7386\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0267 - accuracy: 0.9928 - val_loss: 1.2894 - val_accuracy: 0.7335\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0250 - accuracy: 0.9925 - val_loss: 1.2228 - val_accuracy: 0.7376\n","Epoch 69/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0225 - accuracy: 0.9951 - val_loss: 1.2327 - val_accuracy: 0.7438\n","Epoch 70/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0267 - accuracy: 0.9933 - val_loss: 1.2944 - val_accuracy: 0.7262\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0326 - accuracy: 0.9907 - val_loss: 1.2182 - val_accuracy: 0.7366\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0424 - accuracy: 0.9881 - val_loss: 1.1909 - val_accuracy: 0.7335\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0418 - accuracy: 0.9858 - val_loss: 1.2045 - val_accuracy: 0.7221\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0740 - accuracy: 0.9747 - val_loss: 1.0251 - val_accuracy: 0.7169\n","Epoch 75/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0764 - accuracy: 0.9742 - val_loss: 0.9679 - val_accuracy: 0.7087\n","Epoch 76/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1623 - accuracy: 0.9419 - val_loss: 1.0106 - val_accuracy: 0.7025\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0522 - accuracy: 0.9824 - val_loss: 1.2625 - val_accuracy: 0.7076\n","Epoch 78/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0665 - accuracy: 0.9822 - val_loss: 1.1374 - val_accuracy: 0.7056\n","Epoch 79/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0377 - accuracy: 0.9889 - val_loss: 1.1579 - val_accuracy: 0.7097\n","Epoch 80/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0766 - accuracy: 0.9731 - val_loss: 1.1028 - val_accuracy: 0.7035\n","Epoch 81/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0630 - accuracy: 0.9778 - val_loss: 1.1452 - val_accuracy: 0.7231\n","Epoch 82/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0394 - accuracy: 0.9889 - val_loss: 1.1533 - val_accuracy: 0.7407\n","Epoch 83/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0367 - accuracy: 0.9876 - val_loss: 1.1263 - val_accuracy: 0.7097\n","Epoch 84/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0288 - accuracy: 0.9912 - val_loss: 1.2693 - val_accuracy: 0.7314\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0227 - accuracy: 0.9943 - val_loss: 1.2797 - val_accuracy: 0.7190\n","Epoch 86/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 1.3446 - val_accuracy: 0.7076\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0275 - accuracy: 0.9922 - val_loss: 1.1689 - val_accuracy: 0.7180\n","Epoch 88/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0217 - accuracy: 0.9941 - val_loss: 1.3013 - val_accuracy: 0.7149\n","Epoch 89/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0209 - accuracy: 0.9948 - val_loss: 1.2994 - val_accuracy: 0.7273\n","Epoch 90/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0297 - accuracy: 0.9910 - val_loss: 1.2976 - val_accuracy: 0.7180\n","Epoch 91/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1305 - accuracy: 0.9574 - val_loss: 0.9263 - val_accuracy: 0.7056\n","Epoch 92/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0420 - accuracy: 0.9858 - val_loss: 1.3135 - val_accuracy: 0.6983\n","Epoch 93/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0321 - accuracy: 0.9904 - val_loss: 1.3483 - val_accuracy: 0.6983\n","Epoch 94/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0452 - accuracy: 0.9819 - val_loss: 1.2013 - val_accuracy: 0.7190\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0337 - accuracy: 0.9891 - val_loss: 1.3087 - val_accuracy: 0.7273\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0353 - accuracy: 0.9897 - val_loss: 1.2857 - val_accuracy: 0.7076\n","Epoch 97/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0625 - accuracy: 0.9796 - val_loss: 1.1220 - val_accuracy: 0.7128\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0338 - accuracy: 0.9891 - val_loss: 1.1912 - val_accuracy: 0.7128\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0168 - accuracy: 0.9961 - val_loss: 1.2668 - val_accuracy: 0.7293\n","Epoch 100/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 1.2237 - val_accuracy: 0.7366\n","{'loss': [0.13118384778499603, 0.08121979981660843, 0.07571414113044739, 0.06326501071453094, 0.044845279306173325, 0.06798291951417923, 0.10976341366767883, 0.06071453541517258, 0.08175721019506454, 0.05954864248633385, 0.05881420522928238, 0.0489853210747242, 0.0684310793876648, 0.06731265038251877, 0.0561646893620491, 0.06743095815181732, 0.08421787619590759, 0.052220992743968964, 0.05277477577328682, 0.058801520615816116, 0.11706289649009705, 0.04305144399404526, 0.031794413924217224, 0.07710187882184982, 0.06909812241792679, 0.0652606412768364, 0.04166117683053017, 0.04234059900045395, 0.02947448007762432, 0.021506553515791893, 0.02071010321378708, 0.017804430797696114, 0.02087313123047352, 0.01804916374385357, 0.024571260437369347, 0.02646087482571602, 0.04995841905474663, 0.09644155204296112, 0.09241235256195068, 0.05168165639042854, 0.040933459997177124, 0.04039840027689934, 0.036065828055143356, 0.02823089435696602, 0.0255301371216774, 0.03924297168850899, 0.04223395138978958, 0.04875357449054718, 0.035434190183877945, 0.0944897010922432, 0.06425420939922333, 0.03839901089668274, 0.09950266778469086, 0.04060349985957146, 0.027742957696318626, 0.031995777040719986, 0.0264739952981472, 0.05099010840058327, 0.03668948635458946, 0.031089812517166138, 0.019710689783096313, 0.01915845461189747, 0.019379829987883568, 0.020500261336565018, 0.017297614365816116, 0.02465110644698143, 0.026651760563254356, 0.025033308193087578, 0.022515127435326576, 0.02672271616756916, 0.032571613788604736, 0.0423634797334671, 0.04182800278067589, 0.07398754358291626, 0.07639463990926743, 0.16231101751327515, 0.05218613147735596, 0.06648008525371552, 0.03771574795246124, 0.07660812139511108, 0.06302951276302338, 0.03935869038105011, 0.03667721897363663, 0.028849001973867416, 0.0226746853441, 0.023510966449975967, 0.027540408074855804, 0.021695194765925407, 0.020887020975351334, 0.02970336563885212, 0.13049831986427307, 0.04195209965109825, 0.03208959475159645, 0.04521632194519043, 0.033740755170583725, 0.03533109277486801, 0.06249808520078659, 0.033796876668930054, 0.016795875504612923, 0.015537942759692669], 'accuracy': [0.9506459832191467, 0.9731265902519226, 0.9733850359916687, 0.9762274026870728, 0.985788106918335, 0.9780361652374268, 0.9617571234703064, 0.9801033735275269, 0.9700258374214172, 0.9803617596626282, 0.9821705222129822, 0.983979344367981, 0.9772610068321228, 0.9767441749572754, 0.9816537499427795, 0.9764857888221741, 0.9713178277015686, 0.9819121360778809, 0.9808785319328308, 0.9808785319328308, 0.961240291595459, 0.9860464930534363, 0.9912144541740417, 0.9731265902519226, 0.9720930457115173, 0.9782945513725281, 0.9842377305030823, 0.9873384833335876, 0.9927648305892944, 0.9935400485992432, 0.9958656430244446, 0.9963824152946472, 0.9943152666091919, 0.9956072568893433, 0.9930232763290405, 0.9919896721839905, 0.9832041263580322, 0.9656330943107605, 0.9658914804458618, 0.9806201457977295, 0.9855297207832336, 0.9873384833335876, 0.9899224638938904, 0.9917312860488892, 0.9925064444541931, 0.9881137013435364, 0.986821711063385, 0.9852713346481323, 0.9878553152084351, 0.9671834707260132, 0.975452184677124, 0.988630473613739, 0.9648578763008118, 0.9878553152084351, 0.9925064444541931, 0.9899224638938904, 0.9919896721839905, 0.9816537499427795, 0.988630473613739, 0.9901808500289917, 0.9953488111495972, 0.9966408014297485, 0.9948320388793945, 0.9943152666091919, 0.9950904250144958, 0.9935400485992432, 0.9927648305892944, 0.9925064444541931, 0.9950904250144958, 0.9932816624641418, 0.9906976819038391, 0.9881137013435364, 0.985788106918335, 0.9746770262718201, 0.9741601943969727, 0.9418604373931885, 0.9824289679527283, 0.9821705222129822, 0.9888888597488403, 0.9731265902519226, 0.9777777791023254, 0.9888888597488403, 0.987596869468689, 0.9912144541740417, 0.9943152666091919, 0.9932816624641418, 0.9922480583190918, 0.9940568208694458, 0.9948320388793945, 0.9909560680389404, 0.9573643207550049, 0.985788106918335, 0.9904392957687378, 0.9819121360778809, 0.9891473054885864, 0.9896640777587891, 0.9795865416526794, 0.9891473054885864, 0.9961240291595459, 0.9958656430244446], 'val_loss': [0.8820485472679138, 1.0026884078979492, 1.0547853708267212, 1.1635260581970215, 1.4931222200393677, 1.4684886932373047, 1.4268620014190674, 1.6845204830169678, 1.6711734533309937, 1.8057341575622559, 1.9377267360687256, 1.6932737827301025, 1.3373697996139526, 1.2174830436706543, 1.1306363344192505, 1.193390130996704, 1.173622965812683, 0.7887802124023438, 0.8684729337692261, 0.962892472743988, 0.7592445611953735, 0.8743653297424316, 0.9094535112380981, 0.9145433306694031, 0.8766912817955017, 1.013649344444275, 0.9664020538330078, 1.0257296562194824, 0.9188905954360962, 0.9777098298072815, 0.974881649017334, 1.1075873374938965, 1.0006580352783203, 1.095375657081604, 1.0288217067718506, 1.1860090494155884, 1.1590989828109741, 0.9082344770431519, 0.9714375734329224, 0.9761252403259277, 1.2277449369430542, 1.2194347381591797, 1.1614954471588135, 1.1352417469024658, 1.175342321395874, 1.1146483421325684, 1.1186155080795288, 1.096919298171997, 1.2338111400604248, 0.8895644545555115, 1.0940450429916382, 1.1038140058517456, 0.8804580569267273, 1.0969184637069702, 1.218996524810791, 1.1843314170837402, 1.1662498712539673, 1.1516066789627075, 1.0698338747024536, 1.0664576292037964, 1.1083024740219116, 1.099802017211914, 1.145464539527893, 1.2013828754425049, 1.147944688796997, 1.188254714012146, 1.2893794775009155, 1.2228022813796997, 1.232664704322815, 1.294425129890442, 1.2182426452636719, 1.1909422874450684, 1.2045109272003174, 1.0250787734985352, 0.9678703546524048, 1.0105541944503784, 1.2624993324279785, 1.1373990774154663, 1.1578651666641235, 1.102798342704773, 1.1452394723892212, 1.1533255577087402, 1.1262860298156738, 1.2692595720291138, 1.2796893119812012, 1.344605803489685, 1.168891429901123, 1.3012832403182983, 1.2993673086166382, 1.2976168394088745, 0.9262978434562683, 1.3135058879852295, 1.3483402729034424, 1.20134699344635, 1.308712363243103, 1.2857059240341187, 1.1220146417617798, 1.191223382949829, 1.2667829990386963, 1.2236518859863281], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.48657023906707764, 0.4876033067703247, 0.4969008266925812, 0.5247933864593506, 0.5340909361839294, 0.5795454382896423, 0.5836777091026306, 0.5805785059928894, 0.6952479481697083, 0.7004132270812988, 0.7004132270812988, 0.7376033067703247, 0.7458677887916565, 0.7582644820213318, 0.7427685856819153, 0.7376033067703247, 0.7458677887916565, 0.7530992031097412, 0.7510330677032471, 0.7799586653709412, 0.7840909361839294, 0.7820248007774353, 0.7541322112083435, 0.7778925895690918, 0.7572314143180847, 0.7685950398445129, 0.7603305578231812, 0.7252066135406494, 0.7293388247489929, 0.7283057570457458, 0.7396694421768188, 0.7272727489471436, 0.7283057570457458, 0.7376033067703247, 0.7520661354064941, 0.7603305578231812, 0.7561983466148376, 0.7458677887916565, 0.7293388247489929, 0.7355371713638306, 0.7407024502754211, 0.7334710955619812, 0.7376033067703247, 0.7355371713638306, 0.7448347210884094, 0.7293388247489929, 0.7530992031097412, 0.7489669322967529, 0.711776852607727, 0.7489669322967529, 0.7469007968902588, 0.7572314143180847, 0.7634297609329224, 0.7582644820213318, 0.7541322112083435, 0.7603305578231812, 0.7386363744735718, 0.7334710955619812, 0.7376033067703247, 0.7438016533851624, 0.7262396812438965, 0.7365702390670776, 0.7334710955619812, 0.7221074104309082, 0.7169421315193176, 0.7086777091026306, 0.702479362487793, 0.7076446413993835, 0.7055785059928894, 0.7097107172012329, 0.7035123705863953, 0.7231404781341553, 0.7407024502754211, 0.7097107172012329, 0.7314049601554871, 0.7190082669258118, 0.7076446413993835, 0.7179751992225647, 0.7148760557174683, 0.7272727489471436, 0.7179751992225647, 0.7055785059928894, 0.6983470916748047, 0.6983470916748047, 0.7190082669258118, 0.7272727489471436, 0.7076446413993835, 0.7128099203109741, 0.7128099203109741, 0.7293388247489929, 0.7365702390670776]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.0806 - accuracy: 0.9778"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 64ms/step - loss: 0.0778 - accuracy: 0.9779 - val_loss: 1.0348 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0385 - accuracy: 0.9881 - val_loss: 1.2852 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0279 - accuracy: 0.9935 - val_loss: 1.3976 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0402 - accuracy: 0.9871 - val_loss: 1.4598 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0432 - accuracy: 0.9855 - val_loss: 1.5880 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0347 - accuracy: 0.9895 - val_loss: 1.6175 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0369 - accuracy: 0.9865 - val_loss: 1.8336 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0558 - accuracy: 0.9811 - val_loss: 1.9383 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0400 - accuracy: 0.9881 - val_loss: 1.9609 - val_accuracy: 0.4849\n","Epoch 10/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0397 - accuracy: 0.9876 - val_loss: 2.0949 - val_accuracy: 0.4860\n","Epoch 11/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0440 - accuracy: 0.9857 - val_loss: 1.8276 - val_accuracy: 0.4892\n","Epoch 12/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0451 - accuracy: 0.9860 - val_loss: 1.7011 - val_accuracy: 0.4881\n","Epoch 13/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.0352 - accuracy: 0.9887 - val_loss: 1.6716 - val_accuracy: 0.5065\n","Epoch 14/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0343 - accuracy: 0.9890 - val_loss: 1.5473 - val_accuracy: 0.5474\n","Epoch 15/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0325 - accuracy: 0.9900 - val_loss: 1.3453 - val_accuracy: 0.5711\n","Epoch 16/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0288 - accuracy: 0.9908 - val_loss: 1.1463 - val_accuracy: 0.5873\n","Epoch 17/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.0240 - accuracy: 0.9919 - val_loss: 1.0707 - val_accuracy: 0.6541\n","Epoch 18/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0550 - accuracy: 0.9811 - val_loss: 0.8920 - val_accuracy: 0.6530\n","Epoch 19/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0810 - accuracy: 0.9714 - val_loss: 0.7019 - val_accuracy: 0.7037\n","Epoch 20/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0390 - accuracy: 0.9884 - val_loss: 0.8260 - val_accuracy: 0.7349\n","Epoch 21/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0293 - accuracy: 0.9919 - val_loss: 0.9148 - val_accuracy: 0.7284\n","Epoch 22/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0207 - accuracy: 0.9943 - val_loss: 0.6917 - val_accuracy: 0.7963\n","Epoch 23/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0272 - accuracy: 0.9919 - val_loss: 0.7951 - val_accuracy: 0.7888\n","Epoch 24/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0236 - accuracy: 0.9946 - val_loss: 0.7792 - val_accuracy: 0.7877\n","Epoch 25/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.0227 - accuracy: 0.9943 - val_loss: 0.6905 - val_accuracy: 0.8125\n","Epoch 26/100\n","29/29 [==============================] - 1s 39ms/step - loss: 0.0215 - accuracy: 0.9952 - val_loss: 0.6890 - val_accuracy: 0.8265\n","Epoch 27/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0262 - accuracy: 0.9930 - val_loss: 0.6087 - val_accuracy: 0.8491\n","Epoch 28/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0290 - accuracy: 0.9914 - val_loss: 0.6525 - val_accuracy: 0.8308\n","Epoch 29/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0188 - accuracy: 0.9946 - val_loss: 0.6693 - val_accuracy: 0.8384\n","Epoch 30/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0158 - accuracy: 0.9965 - val_loss: 0.6765 - val_accuracy: 0.8448\n","Epoch 31/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0175 - accuracy: 0.9960 - val_loss: 0.7417 - val_accuracy: 0.8287\n","Epoch 32/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.6949 - val_accuracy: 0.8534\n","Epoch 33/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0126 - accuracy: 0.9978 - val_loss: 0.6884 - val_accuracy: 0.8405\n","Epoch 34/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0120 - accuracy: 0.9984 - val_loss: 0.6276 - val_accuracy: 0.8642\n","Epoch 35/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0128 - accuracy: 0.9976 - val_loss: 0.6832 - val_accuracy: 0.8545\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0174 - accuracy: 0.9965 - val_loss: 0.7132 - val_accuracy: 0.8362\n","Epoch 37/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0123 - accuracy: 0.9981 - val_loss: 0.7021 - val_accuracy: 0.8448\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0149 - accuracy: 0.9968 - val_loss: 0.6377 - val_accuracy: 0.8448\n","Epoch 39/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0117 - accuracy: 0.9976 - val_loss: 0.6505 - val_accuracy: 0.8448\n","Epoch 40/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0117 - accuracy: 0.9973 - val_loss: 0.7414 - val_accuracy: 0.8459\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.7350 - val_accuracy: 0.8394\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0199 - accuracy: 0.9957 - val_loss: 0.7549 - val_accuracy: 0.8222\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0455 - accuracy: 0.9852 - val_loss: 0.8123 - val_accuracy: 0.7942\n","Epoch 44/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0554 - accuracy: 0.9806 - val_loss: 0.8708 - val_accuracy: 0.7802\n","Epoch 45/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0745 - accuracy: 0.9736 - val_loss: 0.6671 - val_accuracy: 0.7963\n","Epoch 46/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0492 - accuracy: 0.9857 - val_loss: 0.9471 - val_accuracy: 0.7759\n","Epoch 47/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0493 - accuracy: 0.9844 - val_loss: 0.8005 - val_accuracy: 0.7974\n","Epoch 48/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0566 - accuracy: 0.9820 - val_loss: 0.7960 - val_accuracy: 0.7845\n","Epoch 49/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0382 - accuracy: 0.9892 - val_loss: 0.7177 - val_accuracy: 0.8082\n","Epoch 50/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0320 - accuracy: 0.9903 - val_loss: 0.8411 - val_accuracy: 0.8039\n","Epoch 51/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0376 - accuracy: 0.9890 - val_loss: 0.9260 - val_accuracy: 0.7672\n","Epoch 52/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0353 - accuracy: 0.9903 - val_loss: 0.9071 - val_accuracy: 0.7931\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.8206 - val_accuracy: 0.8136\n","Epoch 54/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0353 - accuracy: 0.9898 - val_loss: 0.8681 - val_accuracy: 0.8039\n","Epoch 55/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0542 - accuracy: 0.9841 - val_loss: 0.7367 - val_accuracy: 0.7694\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0376 - accuracy: 0.9881 - val_loss: 0.8287 - val_accuracy: 0.7974\n","Epoch 57/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0383 - accuracy: 0.9868 - val_loss: 0.8324 - val_accuracy: 0.7985\n","Epoch 58/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0461 - accuracy: 0.9857 - val_loss: 0.7701 - val_accuracy: 0.7942\n","Epoch 59/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0323 - accuracy: 0.9908 - val_loss: 0.6807 - val_accuracy: 0.8211\n","Epoch 60/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0193 - accuracy: 0.9954 - val_loss: 0.8377 - val_accuracy: 0.8222\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0177 - accuracy: 0.9962 - val_loss: 0.8068 - val_accuracy: 0.8114\n","Epoch 62/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.8111 - val_accuracy: 0.8222\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0120 - accuracy: 0.9981 - val_loss: 0.7709 - val_accuracy: 0.8211\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0121 - accuracy: 0.9976 - val_loss: 0.7210 - val_accuracy: 0.8427\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0118 - accuracy: 0.9978 - val_loss: 0.7736 - val_accuracy: 0.8276\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0154 - accuracy: 0.9970 - val_loss: 0.7089 - val_accuracy: 0.8287\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.7038 - val_accuracy: 0.8373\n","Epoch 68/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0114 - accuracy: 0.9978 - val_loss: 0.7063 - val_accuracy: 0.8287\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0120 - accuracy: 0.9976 - val_loss: 0.7264 - val_accuracy: 0.8297\n","Epoch 70/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.7197 - val_accuracy: 0.8448\n","Epoch 71/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0166 - accuracy: 0.9954 - val_loss: 0.7636 - val_accuracy: 0.8190\n","Epoch 72/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0127 - accuracy: 0.9973 - val_loss: 0.7164 - val_accuracy: 0.8459\n","Epoch 73/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0127 - accuracy: 0.9976 - val_loss: 0.7214 - val_accuracy: 0.8330\n","Epoch 74/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.7073 - val_accuracy: 0.8297\n","Epoch 75/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.6903 - val_accuracy: 0.8373\n","Epoch 76/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0151 - accuracy: 0.9960 - val_loss: 0.7951 - val_accuracy: 0.8071\n","Epoch 77/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0171 - accuracy: 0.9960 - val_loss: 0.9152 - val_accuracy: 0.7942\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0368 - accuracy: 0.9887 - val_loss: 0.8598 - val_accuracy: 0.7899\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0672 - accuracy: 0.9763 - val_loss: 0.8263 - val_accuracy: 0.7716\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0383 - accuracy: 0.9868 - val_loss: 0.9636 - val_accuracy: 0.7726\n","Epoch 81/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0529 - accuracy: 0.9828 - val_loss: 0.9198 - val_accuracy: 0.7478\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0520 - accuracy: 0.9822 - val_loss: 0.8140 - val_accuracy: 0.7716\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0450 - accuracy: 0.9857 - val_loss: 0.8325 - val_accuracy: 0.7705\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0516 - accuracy: 0.9825 - val_loss: 0.9240 - val_accuracy: 0.7597\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0457 - accuracy: 0.9846 - val_loss: 0.9548 - val_accuracy: 0.7619\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0334 - accuracy: 0.9890 - val_loss: 0.9831 - val_accuracy: 0.7726\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0355 - accuracy: 0.9895 - val_loss: 1.0665 - val_accuracy: 0.7478\n","Epoch 88/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0356 - accuracy: 0.9892 - val_loss: 0.9465 - val_accuracy: 0.7780\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0260 - accuracy: 0.9933 - val_loss: 1.0487 - val_accuracy: 0.7748\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0452 - accuracy: 0.9871 - val_loss: 0.9007 - val_accuracy: 0.7683\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0324 - accuracy: 0.9900 - val_loss: 0.9063 - val_accuracy: 0.7856\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0370 - accuracy: 0.9873 - val_loss: 1.0336 - val_accuracy: 0.7608\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0526 - accuracy: 0.9863 - val_loss: 0.7720 - val_accuracy: 0.7662\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0253 - accuracy: 0.9933 - val_loss: 0.8653 - val_accuracy: 0.7877\n","Epoch 95/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0157 - accuracy: 0.9965 - val_loss: 0.8748 - val_accuracy: 0.7942\n","Epoch 96/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0151 - accuracy: 0.9965 - val_loss: 0.8892 - val_accuracy: 0.7974\n","Epoch 97/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0115 - accuracy: 0.9978 - val_loss: 0.8547 - val_accuracy: 0.8039\n","Epoch 98/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0118 - accuracy: 0.9978 - val_loss: 0.9038 - val_accuracy: 0.7909\n","Epoch 99/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0116 - accuracy: 0.9978 - val_loss: 0.8750 - val_accuracy: 0.7953\n","Epoch 100/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.8825 - val_accuracy: 0.8006\n","{'loss': [0.0778222531080246, 0.03853141516447067, 0.027873482555150986, 0.04017379879951477, 0.043208055198192596, 0.03473494201898575, 0.03690684586763382, 0.05578436702489853, 0.03999023512005806, 0.03965166211128235, 0.043987102806568146, 0.04510080814361572, 0.03520504757761955, 0.034266259521245956, 0.03245265409350395, 0.02880517579615116, 0.02396586164832115, 0.05496475100517273, 0.08095460385084152, 0.03895926848053932, 0.02931196056306362, 0.020719263702630997, 0.02716917358338833, 0.023628368973731995, 0.02272249571979046, 0.021535364910960197, 0.02620604820549488, 0.0290004201233387, 0.018810641020536423, 0.015837498009204865, 0.01750257797539234, 0.014196707867085934, 0.012640465050935745, 0.011979668401181698, 0.012812339700758457, 0.017440252006053925, 0.012327803298830986, 0.014856922440230846, 0.011683023534715176, 0.011717086657881737, 0.0131234684959054, 0.01986757107079029, 0.04553123563528061, 0.05540113523602486, 0.07449498772621155, 0.04922929033637047, 0.04927457123994827, 0.056635595858097076, 0.0381840355694294, 0.03202268108725548, 0.03760943561792374, 0.03529658168554306, 0.02463999204337597, 0.03525868430733681, 0.054237913340330124, 0.03756653517484665, 0.038298916071653366, 0.04606325551867485, 0.032343413680791855, 0.019311686977744102, 0.017723899334669113, 0.01446858886629343, 0.011968244798481464, 0.012100566178560257, 0.011786751449108124, 0.015362800098955631, 0.013048198074102402, 0.01141923014074564, 0.01199885830283165, 0.013980912044644356, 0.016579117625951767, 0.012712555006146431, 0.012725574895739555, 0.013242068700492382, 0.010758917778730392, 0.01511756144464016, 0.017054755240678787, 0.03675726056098938, 0.06721323728561401, 0.038322366774082184, 0.052880220115184784, 0.05197160318493843, 0.04495834931731224, 0.05160961300134659, 0.04565201699733734, 0.03337843716144562, 0.03545624762773514, 0.03560421243309975, 0.02604980766773224, 0.04515768587589264, 0.03237331658601761, 0.037042733281850815, 0.05262642353773117, 0.025338945910334587, 0.015745827928185463, 0.015062624588608742, 0.011523842811584473, 0.01182575337588787, 0.011578829027712345, 0.011422484181821346], 'accuracy': [0.977909505367279, 0.9881465435028076, 0.993534505367279, 0.9870689511299133, 0.9854525923728943, 0.9894935488700867, 0.9865301847457886, 0.9811422228813171, 0.9881465435028076, 0.9876077771186829, 0.985722005367279, 0.985991358757019, 0.9886853694915771, 0.9889547228813171, 0.9900323152542114, 0.990840494632721, 0.9919180870056152, 0.9811422228813171, 0.9714439511299133, 0.9884159564971924, 0.9919180870056152, 0.9943426847457886, 0.9919180870056152, 0.9946120977401733, 0.9943426847457886, 0.9951508641242981, 0.9929956793785095, 0.9913793206214905, 0.9946120977401733, 0.9964978694915771, 0.9959590435028076, 0.9973060488700867, 0.9978448152542114, 0.998383641242981, 0.9975754022598267, 0.9964978694915771, 0.9981142282485962, 0.9967672228813171, 0.9975754022598267, 0.9973060488700867, 0.9970366358757019, 0.9956896305084229, 0.9851831793785095, 0.9806034564971924, 0.9735991358757019, 0.985722005367279, 0.984375, 0.9819504022598267, 0.9892241358757019, 0.9903017282485962, 0.9889547228813171, 0.9903017282485962, 0.9919180870056152, 0.9897629022598267, 0.9841055870056152, 0.9881465435028076, 0.9867995977401733, 0.985722005367279, 0.990840494632721, 0.9954202771186829, 0.9962284564971924, 0.9962284564971924, 0.9981142282485962, 0.9975754022598267, 0.9978448152542114, 0.9970366358757019, 0.9970366358757019, 0.9978448152542114, 0.9975754022598267, 0.9967672228813171, 0.9954202771186829, 0.9973060488700867, 0.9975754022598267, 0.9962284564971924, 0.9975754022598267, 0.9959590435028076, 0.9959590435028076, 0.9886853694915771, 0.9762930870056152, 0.9867995977401733, 0.982758641242981, 0.9822198152542114, 0.985722005367279, 0.9824892282485962, 0.9846444129943848, 0.9889547228813171, 0.9894935488700867, 0.9892241358757019, 0.9932650923728943, 0.9870689511299133, 0.9900323152542114, 0.9873383641242981, 0.9862607717514038, 0.9932650923728943, 0.9964978694915771, 0.9964978694915771, 0.9978448152542114, 0.9978448152542114, 0.9978448152542114, 0.9967672228813171], 'val_loss': [1.034778118133545, 1.285240888595581, 1.397580623626709, 1.4598276615142822, 1.5880100727081299, 1.6174753904342651, 1.8335753679275513, 1.938326120376587, 1.9609183073043823, 2.094851016998291, 1.8275716304779053, 1.7010613679885864, 1.6715567111968994, 1.5473244190216064, 1.3452706336975098, 1.1462501287460327, 1.0706865787506104, 0.8920196890830994, 0.7019171118736267, 0.825971782207489, 0.9148215651512146, 0.691729724407196, 0.7951220273971558, 0.7791815996170044, 0.6904889345169067, 0.6889992356300354, 0.6086762547492981, 0.6525397300720215, 0.6693183183670044, 0.6765460968017578, 0.7416714429855347, 0.6948567032814026, 0.6883578896522522, 0.6275816559791565, 0.683174192905426, 0.7132331728935242, 0.7021066546440125, 0.63768070936203, 0.6505290269851685, 0.7414315938949585, 0.7349600195884705, 0.7548902630805969, 0.8122985363006592, 0.8707894682884216, 0.6671233773231506, 0.9470716714859009, 0.8004837036132812, 0.7960038185119629, 0.7176723480224609, 0.8411362767219543, 0.9259896278381348, 0.9071336388587952, 0.8205941319465637, 0.8681117296218872, 0.736690878868103, 0.8287067413330078, 0.8323656916618347, 0.7700605988502502, 0.6807442307472229, 0.8377394080162048, 0.806830883026123, 0.8110992908477783, 0.7708602547645569, 0.7210131883621216, 0.7736142873764038, 0.7089313864707947, 0.7037708163261414, 0.7063148021697998, 0.7264367938041687, 0.7196609377861023, 0.7636000514030457, 0.7163684964179993, 0.7213817238807678, 0.7073042392730713, 0.6903186440467834, 0.7950592041015625, 0.9151791334152222, 0.859789252281189, 0.826299250125885, 0.9635564684867859, 0.9198200702667236, 0.8139983415603638, 0.8325074911117554, 0.9240195751190186, 0.9547919034957886, 0.9831255078315735, 1.0664961338043213, 0.9465417265892029, 1.0486763715744019, 0.9007142782211304, 0.9063398241996765, 1.0335899591445923, 0.7719969749450684, 0.8653365969657898, 0.8748491406440735, 0.8892423510551453, 0.8547026515007019, 0.9037553071975708, 0.8749712705612183, 0.8824595212936401], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.4892241358757019, 0.4881465435028076, 0.506465494632721, 0.5474137663841248, 0.5711206793785095, 0.587284505367279, 0.6540948152542114, 0.6530172228813171, 0.7036637663841248, 0.7349137663841248, 0.7284482717514038, 0.7963362336158752, 0.7887930870056152, 0.787715494632721, 0.8125, 0.826508641242981, 0.8491379022598267, 0.8308189511299133, 0.8383620977401733, 0.8448275923728943, 0.8286637663841248, 0.8534482717514038, 0.8405172228813171, 0.8642241358757019, 0.8545258641242981, 0.8362069129943848, 0.8448275923728943, 0.8448275923728943, 0.8448275923728943, 0.8459051847457886, 0.8394396305084229, 0.8221982717514038, 0.7941810488700867, 0.7801724076271057, 0.7963362336158752, 0.7758620977401733, 0.7974137663841248, 0.7844827771186829, 0.8081896305084229, 0.8038793206214905, 0.767241358757019, 0.7931034564971924, 0.8135775923728943, 0.8038793206214905, 0.7693965435028076, 0.7974137663841248, 0.798491358757019, 0.7941810488700867, 0.8211206793785095, 0.8221982717514038, 0.8114224076271057, 0.8221982717514038, 0.8211206793785095, 0.8426724076271057, 0.8275862336158752, 0.8286637663841248, 0.837284505367279, 0.8286637663841248, 0.829741358757019, 0.8448275923728943, 0.818965494632721, 0.8459051847457886, 0.8329741358757019, 0.829741358757019, 0.837284505367279, 0.8071120977401733, 0.7941810488700867, 0.7898706793785095, 0.7715517282485962, 0.7726293206214905, 0.7478448152542114, 0.7715517282485962, 0.7704741358757019, 0.7596982717514038, 0.7618534564971924, 0.7726293206214905, 0.7478448152542114, 0.7780172228813171, 0.774784505367279, 0.7683189511299133, 0.7855603694915771, 0.7607758641242981, 0.7661637663841248, 0.787715494632721, 0.7941810488700867, 0.7974137663841248, 0.8038793206214905, 0.7909482717514038, 0.795258641242981, 0.8006465435028076]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9737"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 81ms/step - loss: 0.0771 - accuracy: 0.9737 - val_loss: 0.9939 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0422 - accuracy: 0.9856 - val_loss: 1.3494 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0448 - accuracy: 0.9864 - val_loss: 1.2918 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0389 - accuracy: 0.9884 - val_loss: 1.3871 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0195 - accuracy: 0.9946 - val_loss: 1.8510 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0377 - accuracy: 0.9892 - val_loss: 1.8455 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0396 - accuracy: 0.9870 - val_loss: 1.8670 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0339 - accuracy: 0.9909 - val_loss: 2.0929 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0342 - accuracy: 0.9909 - val_loss: 2.2108 - val_accuracy: 0.4955\n","Epoch 10/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0294 - accuracy: 0.9909 - val_loss: 2.1908 - val_accuracy: 0.4955\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0212 - accuracy: 0.9952 - val_loss: 2.3081 - val_accuracy: 0.4943\n","Epoch 12/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0200 - accuracy: 0.9955 - val_loss: 2.2039 - val_accuracy: 0.5000\n","Epoch 13/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0269 - accuracy: 0.9932 - val_loss: 2.0194 - val_accuracy: 0.5023\n","Epoch 14/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0521 - accuracy: 0.9842 - val_loss: 1.9358 - val_accuracy: 0.5045\n","Epoch 15/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0505 - accuracy: 0.9847 - val_loss: 1.3259 - val_accuracy: 0.5498\n","Epoch 16/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0364 - accuracy: 0.9892 - val_loss: 1.0696 - val_accuracy: 0.5882\n","Epoch 17/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0314 - accuracy: 0.9901 - val_loss: 1.0718 - val_accuracy: 0.6052\n","Epoch 18/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0219 - accuracy: 0.9943 - val_loss: 1.0600 - val_accuracy: 0.6561\n","Epoch 19/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0174 - accuracy: 0.9958 - val_loss: 0.9190 - val_accuracy: 0.6934\n","Epoch 20/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 0.7147 - val_accuracy: 0.7545\n","Epoch 21/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0768 - accuracy: 0.9743 - val_loss: 0.6395 - val_accuracy: 0.7172\n","Epoch 22/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.0412 - accuracy: 0.9878 - val_loss: 0.5997 - val_accuracy: 0.7930\n","Epoch 23/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.0185 - accuracy: 0.9966 - val_loss: 0.6067 - val_accuracy: 0.8156\n","Epoch 24/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0203 - accuracy: 0.9952 - val_loss: 0.6609 - val_accuracy: 0.8133\n","Epoch 25/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0205 - accuracy: 0.9952 - val_loss: 0.5013 - val_accuracy: 0.8337\n","Epoch 26/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0219 - accuracy: 0.9946 - val_loss: 0.5337 - val_accuracy: 0.8439\n","Epoch 27/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0413 - accuracy: 0.9878 - val_loss: 0.5293 - val_accuracy: 0.8439\n","Epoch 28/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0433 - accuracy: 0.9864 - val_loss: 0.4814 - val_accuracy: 0.8303\n","Epoch 29/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0334 - accuracy: 0.9901 - val_loss: 0.5429 - val_accuracy: 0.8495\n","Epoch 30/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0228 - accuracy: 0.9949 - val_loss: 0.6164 - val_accuracy: 0.8473\n","Epoch 31/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0267 - accuracy: 0.9929 - val_loss: 0.6139 - val_accuracy: 0.8405\n","Epoch 32/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0248 - accuracy: 0.9932 - val_loss: 0.7437 - val_accuracy: 0.8224\n","Epoch 33/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0747 - accuracy: 0.9754 - val_loss: 0.5253 - val_accuracy: 0.8122\n","Epoch 34/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0337 - accuracy: 0.9898 - val_loss: 0.6932 - val_accuracy: 0.8281\n","Epoch 35/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0157 - accuracy: 0.9972 - val_loss: 0.6391 - val_accuracy: 0.8484\n","Epoch 36/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0160 - accuracy: 0.9963 - val_loss: 0.7254 - val_accuracy: 0.8394\n","Epoch 37/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0161 - accuracy: 0.9966 - val_loss: 0.7279 - val_accuracy: 0.8292\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0241 - accuracy: 0.9941 - val_loss: 0.7091 - val_accuracy: 0.8326\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0339 - accuracy: 0.9907 - val_loss: 0.6502 - val_accuracy: 0.8303\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0660 - accuracy: 0.9776 - val_loss: 0.5171 - val_accuracy: 0.8314\n","Epoch 41/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0340 - accuracy: 0.9884 - val_loss: 0.5402 - val_accuracy: 0.8518\n","Epoch 42/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0194 - accuracy: 0.9969 - val_loss: 0.5870 - val_accuracy: 0.8450\n","Epoch 43/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0182 - accuracy: 0.9960 - val_loss: 0.6549 - val_accuracy: 0.8439\n","Epoch 44/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0235 - accuracy: 0.9935 - val_loss: 0.6450 - val_accuracy: 0.8462\n","Epoch 45/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0328 - accuracy: 0.9912 - val_loss: 0.7267 - val_accuracy: 0.8247\n","Epoch 46/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0272 - accuracy: 0.9932 - val_loss: 0.7503 - val_accuracy: 0.8111\n","Epoch 47/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0327 - accuracy: 0.9890 - val_loss: 0.8448 - val_accuracy: 0.7986\n","Epoch 48/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0495 - accuracy: 0.9827 - val_loss: 0.7059 - val_accuracy: 0.8190\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0477 - accuracy: 0.9847 - val_loss: 0.6539 - val_accuracy: 0.8077\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0270 - accuracy: 0.9932 - val_loss: 0.6393 - val_accuracy: 0.8281\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0135 - accuracy: 0.9986 - val_loss: 0.7909 - val_accuracy: 0.8303\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0159 - accuracy: 0.9966 - val_loss: 0.7332 - val_accuracy: 0.8382\n","Epoch 53/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0203 - accuracy: 0.9963 - val_loss: 0.7033 - val_accuracy: 0.8360\n","Epoch 54/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0251 - accuracy: 0.9938 - val_loss: 0.9173 - val_accuracy: 0.7896\n","Epoch 55/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0380 - accuracy: 0.9887 - val_loss: 0.7415 - val_accuracy: 0.8066\n","Epoch 56/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0297 - accuracy: 0.9921 - val_loss: 0.7617 - val_accuracy: 0.8077\n","Epoch 57/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0368 - accuracy: 0.9892 - val_loss: 0.7029 - val_accuracy: 0.8066\n","Epoch 58/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0290 - accuracy: 0.9912 - val_loss: 0.7367 - val_accuracy: 0.8043\n","Epoch 59/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0289 - accuracy: 0.9924 - val_loss: 0.6296 - val_accuracy: 0.8269\n","Epoch 60/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 0.6232 - val_accuracy: 0.8326\n","Epoch 61/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0184 - accuracy: 0.9963 - val_loss: 0.8311 - val_accuracy: 0.7896\n","Epoch 62/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0189 - accuracy: 0.9952 - val_loss: 0.6967 - val_accuracy: 0.8281\n","Epoch 63/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0113 - accuracy: 0.9986 - val_loss: 0.6729 - val_accuracy: 0.8495\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0137 - accuracy: 0.9966 - val_loss: 0.7198 - val_accuracy: 0.8269\n","Epoch 65/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0117 - accuracy: 0.9977 - val_loss: 0.6597 - val_accuracy: 0.8450\n","Epoch 66/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0138 - accuracy: 0.9983 - val_loss: 0.6809 - val_accuracy: 0.8382\n","Epoch 67/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0121 - accuracy: 0.9977 - val_loss: 0.7236 - val_accuracy: 0.8450\n","Epoch 68/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.0087 - accuracy: 0.9992 - val_loss: 0.6498 - val_accuracy: 0.8552\n","Epoch 69/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0094 - accuracy: 0.9992 - val_loss: 0.6471 - val_accuracy: 0.8473\n","Epoch 70/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0089 - accuracy: 0.9992 - val_loss: 0.6946 - val_accuracy: 0.8450\n","Epoch 71/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.6786 - val_accuracy: 0.8303\n","Epoch 72/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0092 - accuracy: 0.9989 - val_loss: 0.6969 - val_accuracy: 0.8382\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0088 - accuracy: 0.9994 - val_loss: 0.6843 - val_accuracy: 0.8348\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0090 - accuracy: 0.9986 - val_loss: 0.6691 - val_accuracy: 0.8450\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0120 - accuracy: 0.9980 - val_loss: 0.6475 - val_accuracy: 0.8428\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0095 - accuracy: 0.9989 - val_loss: 0.7483 - val_accuracy: 0.8314\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0110 - accuracy: 0.9986 - val_loss: 0.7734 - val_accuracy: 0.8281\n","Epoch 78/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0120 - accuracy: 0.9972 - val_loss: 0.7583 - val_accuracy: 0.8281\n","Epoch 79/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0240 - accuracy: 0.9932 - val_loss: 0.7189 - val_accuracy: 0.8156\n","Epoch 80/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0536 - accuracy: 0.9830 - val_loss: 0.7336 - val_accuracy: 0.7952\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0597 - accuracy: 0.9799 - val_loss: 0.7232 - val_accuracy: 0.7783\n","Epoch 82/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0668 - accuracy: 0.9774 - val_loss: 0.7543 - val_accuracy: 0.7885\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0448 - accuracy: 0.9867 - val_loss: 0.8108 - val_accuracy: 0.7975\n","Epoch 84/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0434 - accuracy: 0.9873 - val_loss: 0.8147 - val_accuracy: 0.8020\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0319 - accuracy: 0.9907 - val_loss: 0.8596 - val_accuracy: 0.7941\n","Epoch 86/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0248 - accuracy: 0.9924 - val_loss: 0.9106 - val_accuracy: 0.7885\n","Epoch 87/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0407 - accuracy: 0.9861 - val_loss: 0.8107 - val_accuracy: 0.7998\n","Epoch 88/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0255 - accuracy: 0.9949 - val_loss: 0.7745 - val_accuracy: 0.7975\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0199 - accuracy: 0.9946 - val_loss: 0.7529 - val_accuracy: 0.8179\n","Epoch 90/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0275 - accuracy: 0.9918 - val_loss: 0.8417 - val_accuracy: 0.7919\n","Epoch 91/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0428 - accuracy: 0.9847 - val_loss: 0.8072 - val_accuracy: 0.7828\n","Epoch 92/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0433 - accuracy: 0.9873 - val_loss: 0.6938 - val_accuracy: 0.7919\n","Epoch 93/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0217 - accuracy: 0.9952 - val_loss: 0.7380 - val_accuracy: 0.8020\n","Epoch 94/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0124 - accuracy: 0.9972 - val_loss: 0.9103 - val_accuracy: 0.8077\n","Epoch 95/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0115 - accuracy: 0.9986 - val_loss: 0.8154 - val_accuracy: 0.8122\n","Epoch 96/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0111 - accuracy: 0.9986 - val_loss: 0.8187 - val_accuracy: 0.8145\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0084 - accuracy: 0.9997 - val_loss: 0.7806 - val_accuracy: 0.8360\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0087 - accuracy: 0.9989 - val_loss: 0.8655 - val_accuracy: 0.8167\n","Epoch 99/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0129 - accuracy: 0.9972 - val_loss: 0.8566 - val_accuracy: 0.8100\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0138 - accuracy: 0.9975 - val_loss: 0.8078 - val_accuracy: 0.8100\n","{'loss': [0.0771038755774498, 0.042224444448947906, 0.044773709028959274, 0.038886554539203644, 0.019522100687026978, 0.03769189119338989, 0.03956768661737442, 0.033918313682079315, 0.034207783639431, 0.029351258650422096, 0.02123899944126606, 0.019974395632743835, 0.026906948536634445, 0.05214116349816322, 0.05054579675197601, 0.03641071170568466, 0.03141512721776962, 0.02193903550505638, 0.017383847385644913, 0.028134169057011604, 0.07680610567331314, 0.04117249324917793, 0.018542148172855377, 0.020255038514733315, 0.02049660123884678, 0.02186690643429756, 0.0412597581744194, 0.04326436296105385, 0.03336617723107338, 0.022776169702410698, 0.02673608623445034, 0.02479860559105873, 0.07467374205589294, 0.03365352377295494, 0.01566374860703945, 0.015952030196785927, 0.016077937558293343, 0.02405828796327114, 0.03388074040412903, 0.0660000592470169, 0.034029338508844376, 0.019405845552682877, 0.018165847286581993, 0.02349925972521305, 0.032794635742902756, 0.02716575376689434, 0.03271549940109253, 0.04947413131594658, 0.04766486585140228, 0.026958642527461052, 0.013512270525097847, 0.015882477164268494, 0.02033073455095291, 0.025062713772058487, 0.03801250457763672, 0.029737094417214394, 0.036757562309503555, 0.02901463955640793, 0.02892266772687435, 0.022933419793844223, 0.018370412290096283, 0.01889735460281372, 0.011273170821368694, 0.013682780787348747, 0.011683797463774681, 0.013786637224256992, 0.012102674692869186, 0.008715222589671612, 0.009382002055644989, 0.00893333088606596, 0.014829459600150585, 0.0092270877212286, 0.008809381164610386, 0.009019658900797367, 0.011975567787885666, 0.00948255229741335, 0.011016499251127243, 0.012040115892887115, 0.02401929907500744, 0.053618401288986206, 0.05972087010741234, 0.0668276771903038, 0.044834915548563004, 0.04341188073158264, 0.03186575323343277, 0.024813348427414894, 0.04068056121468544, 0.025537755340337753, 0.01985515095293522, 0.027530578896403313, 0.042800091207027435, 0.04332345351576805, 0.021686295047402382, 0.012422661297023296, 0.011451687663793564, 0.011054378934204578, 0.008371088653802872, 0.008665583096444607, 0.012914055027067661, 0.013785574585199356], 'accuracy': [0.9736841917037964, 0.9855687618255615, 0.9864176511764526, 0.9883984327316284, 0.9946236610412598, 0.9892473220825195, 0.986983597278595, 0.9909451007843018, 0.9909451007843018, 0.9909451007843018, 0.9951896071434021, 0.9954725503921509, 0.9932088255882263, 0.9841539263725281, 0.9847198724746704, 0.9892473220825195, 0.9900962114334106, 0.994340717792511, 0.9957554936408997, 0.9909451007843018, 0.9742501378059387, 0.9878324866294861, 0.9966044425964355, 0.9951896071434021, 0.9951896071434021, 0.9946236610412598, 0.9878324866294861, 0.9864176511764526, 0.9900962114334106, 0.9949066042900085, 0.9929258823394775, 0.9932088255882263, 0.9753820300102234, 0.9898132681846619, 0.9971703290939331, 0.996321439743042, 0.9966044425964355, 0.9940577149391174, 0.990662157535553, 0.977645754814148, 0.9883984327316284, 0.9968873858451843, 0.9960384964942932, 0.9934917688369751, 0.9912280440330505, 0.9932088255882263, 0.988964319229126, 0.9827390909194946, 0.9847198724746704, 0.9932088255882263, 0.9985851645469666, 0.9966044425964355, 0.996321439743042, 0.9937747716903687, 0.9886813759803772, 0.9920769929885864, 0.9892473220825195, 0.9912280440330505, 0.9923599362373352, 0.992642879486084, 0.996321439743042, 0.9951896071434021, 0.9985851645469666, 0.9966044425964355, 0.9977362751960754, 0.9983022212982178, 0.9977362751960754, 0.9991511106491089, 0.9991511106491089, 0.9991511106491089, 0.9968873858451843, 0.9988681674003601, 0.9994340538978577, 0.9985851645469666, 0.9980192184448242, 0.9988681674003601, 0.9985851645469666, 0.9971703290939331, 0.9932088255882263, 0.9830220937728882, 0.9799094796180725, 0.9773627519607544, 0.9867005944252014, 0.9872665405273438, 0.990662157535553, 0.9923599362373352, 0.9861347079277039, 0.9949066042900085, 0.9946236610412598, 0.9917939901351929, 0.9847198724746704, 0.9872665405273438, 0.9951896071434021, 0.9971703290939331, 0.9985851645469666, 0.9985851645469666, 0.9997170567512512, 0.9988681674003601, 0.9971703290939331, 0.9974533319473267], 'val_loss': [0.9939133524894714, 1.3493789434432983, 1.2917888164520264, 1.3871221542358398, 1.8510159254074097, 1.8455016613006592, 1.866950511932373, 2.092850685119629, 2.21077036857605, 2.1908483505249023, 2.3081095218658447, 2.203909397125244, 2.0193727016448975, 1.9358305931091309, 1.32588791847229, 1.0696138143539429, 1.0717991590499878, 1.0600183010101318, 0.9189794659614563, 0.714691698551178, 0.639539897441864, 0.5997295379638672, 0.6067261099815369, 0.6609340310096741, 0.5012622475624084, 0.5337492823600769, 0.5292821526527405, 0.4813506603240967, 0.5428626537322998, 0.6163884401321411, 0.6139278411865234, 0.7436850070953369, 0.5252757668495178, 0.6931802034378052, 0.6390520334243774, 0.7253538370132446, 0.7278913855552673, 0.7091244459152222, 0.6502063870429993, 0.5171012282371521, 0.5402103662490845, 0.5869556069374084, 0.6548960208892822, 0.645018994808197, 0.7266814112663269, 0.7503139972686768, 0.8448310494422913, 0.7058813571929932, 0.6539271473884583, 0.6392578482627869, 0.7908614277839661, 0.733161985874176, 0.703281044960022, 0.9172585010528564, 0.7415376305580139, 0.7617268562316895, 0.7028899192810059, 0.7367293834686279, 0.629615843296051, 0.623244047164917, 0.831145703792572, 0.6966631412506104, 0.6728938221931458, 0.7198272347450256, 0.6597430109977722, 0.6808927655220032, 0.7236232161521912, 0.6497702598571777, 0.6471391320228577, 0.6945677995681763, 0.6785615682601929, 0.6969249844551086, 0.68428635597229, 0.6690998077392578, 0.6475344300270081, 0.7482555508613586, 0.7734174132347107, 0.7582741379737854, 0.7188595533370972, 0.7336391806602478, 0.7232031226158142, 0.7543457746505737, 0.8107993602752686, 0.8146786093711853, 0.8595591187477112, 0.9105516076087952, 0.8106527924537659, 0.7745073437690735, 0.7529457211494446, 0.841730535030365, 0.8072217106819153, 0.69375079870224, 0.7380361557006836, 0.9102757573127747, 0.8153561353683472, 0.8187007308006287, 0.7806244492530823, 0.8654754161834717, 0.8566021919250488, 0.8077911734580994], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4943438768386841, 0.5, 0.5022624731063843, 0.5045248866081238, 0.5497737526893616, 0.5882353186607361, 0.6052036285400391, 0.6561086177825928, 0.6934388875961304, 0.7545248866081238, 0.7171945571899414, 0.7929864525794983, 0.8156108856201172, 0.8133484125137329, 0.8337104320526123, 0.8438913822174072, 0.8438913822174072, 0.8303167223930359, 0.8495475053787231, 0.8472850918769836, 0.8404977321624756, 0.8223981857299805, 0.8122171759605408, 0.8280543088912964, 0.848416268825531, 0.8393664956092834, 0.8291855454444885, 0.8325791954994202, 0.8303167223930359, 0.831447958946228, 0.8518099784851074, 0.8450226187705994, 0.8438913822174072, 0.8461538553237915, 0.8246606588363647, 0.8110859990119934, 0.7986425161361694, 0.8190045356750488, 0.807692289352417, 0.8280543088912964, 0.8303167223930359, 0.8382353186607361, 0.8359728455543518, 0.7895927429199219, 0.8065611124038696, 0.807692289352417, 0.8065611124038696, 0.8042986392974854, 0.8269230723381042, 0.8325791954994202, 0.7895927429199219, 0.8280543088912964, 0.8495475053787231, 0.8269230723381042, 0.8450226187705994, 0.8382353186607361, 0.8450226187705994, 0.8552036285400391, 0.8472850918769836, 0.8450226187705994, 0.8303167223930359, 0.8382353186607361, 0.8348416090011597, 0.8450226187705994, 0.8427602052688599, 0.831447958946228, 0.8280543088912964, 0.8280543088912964, 0.8156108856201172, 0.7952488660812378, 0.7782805562019348, 0.7884615659713745, 0.7975113391876221, 0.8020362257957458, 0.7941176295280457, 0.7884615659713745, 0.7997737526893616, 0.7975113391876221, 0.8178732991218567, 0.7918552160263062, 0.7828054428100586, 0.7918552160263062, 0.8020362257957458, 0.807692289352417, 0.8122171759605408, 0.814479649066925, 0.8359728455543518, 0.8167420625686646, 0.8099547624588013, 0.8099547624588013]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.0941 - accuracy: 0.9685"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 57ms/step - loss: 0.0936 - accuracy: 0.9687 - val_loss: 0.9925 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0403 - accuracy: 0.9879 - val_loss: 1.2870 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0431 - accuracy: 0.9863 - val_loss: 1.5374 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0513 - accuracy: 0.9819 - val_loss: 1.4942 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0448 - accuracy: 0.9848 - val_loss: 1.6489 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0443 - accuracy: 0.9863 - val_loss: 1.8212 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0398 - accuracy: 0.9884 - val_loss: 1.7925 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0365 - accuracy: 0.9871 - val_loss: 2.0025 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0399 - accuracy: 0.9860 - val_loss: 2.0060 - val_accuracy: 0.4876\n","Epoch 10/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0842 - accuracy: 0.9718 - val_loss: 1.6221 - val_accuracy: 0.4907\n","Epoch 11/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.0552 - accuracy: 0.9814 - val_loss: 1.7781 - val_accuracy: 0.4928\n","Epoch 12/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.0328 - accuracy: 0.9884 - val_loss: 1.9967 - val_accuracy: 0.4959\n","Epoch 13/100\n","31/31 [==============================] - 1s 35ms/step - loss: 0.0403 - accuracy: 0.9866 - val_loss: 1.8353 - val_accuracy: 0.5052\n","Epoch 14/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.0311 - accuracy: 0.9904 - val_loss: 1.5824 - val_accuracy: 0.5537\n","Epoch 15/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0286 - accuracy: 0.9910 - val_loss: 1.2869 - val_accuracy: 0.6085\n","Epoch 16/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0383 - accuracy: 0.9873 - val_loss: 1.1424 - val_accuracy: 0.6395\n","Epoch 17/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0503 - accuracy: 0.9827 - val_loss: 1.0127 - val_accuracy: 0.6622\n","Epoch 18/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0319 - accuracy: 0.9907 - val_loss: 0.8434 - val_accuracy: 0.7211\n","Epoch 19/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0273 - accuracy: 0.9930 - val_loss: 0.9008 - val_accuracy: 0.7283\n","Epoch 20/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.8985 - val_accuracy: 0.7376\n","Epoch 21/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0239 - accuracy: 0.9941 - val_loss: 0.8614 - val_accuracy: 0.7655\n","Epoch 22/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0326 - accuracy: 0.9897 - val_loss: 0.8299 - val_accuracy: 0.7769\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0570 - accuracy: 0.9796 - val_loss: 0.9102 - val_accuracy: 0.7438\n","Epoch 24/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0598 - accuracy: 0.9793 - val_loss: 0.6572 - val_accuracy: 0.8006\n","Epoch 25/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0362 - accuracy: 0.9902 - val_loss: 0.7855 - val_accuracy: 0.8110\n","Epoch 26/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0635 - accuracy: 0.9786 - val_loss: 0.7360 - val_accuracy: 0.7893\n","Epoch 27/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0502 - accuracy: 0.9829 - val_loss: 0.7701 - val_accuracy: 0.8017\n","Epoch 28/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.0624 - accuracy: 0.9796 - val_loss: 0.6326 - val_accuracy: 0.8130\n","Epoch 29/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0535 - accuracy: 0.9829 - val_loss: 0.7449 - val_accuracy: 0.8048\n","Epoch 30/100\n","31/31 [==============================] - 1s 37ms/step - loss: 0.0336 - accuracy: 0.9904 - val_loss: 0.8120 - val_accuracy: 0.8140\n","Epoch 31/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0202 - accuracy: 0.9943 - val_loss: 0.8015 - val_accuracy: 0.8213\n","Epoch 32/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0214 - accuracy: 0.9951 - val_loss: 0.7768 - val_accuracy: 0.8202\n","Epoch 33/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0167 - accuracy: 0.9961 - val_loss: 0.7702 - val_accuracy: 0.8450\n","Epoch 34/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 0.7705 - val_accuracy: 0.8461\n","Epoch 35/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0161 - accuracy: 0.9964 - val_loss: 0.7300 - val_accuracy: 0.8471\n","Epoch 36/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 0.7722 - val_accuracy: 0.8326\n","Epoch 37/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.7431 - val_accuracy: 0.8533\n","Epoch 38/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 0.7705 - val_accuracy: 0.8388\n","Epoch 39/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0143 - accuracy: 0.9972 - val_loss: 0.7356 - val_accuracy: 0.8481\n","Epoch 40/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0254 - accuracy: 0.9917 - val_loss: 0.7464 - val_accuracy: 0.8213\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.9181 - val_accuracy: 0.8006\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0227 - accuracy: 0.9938 - val_loss: 0.9795 - val_accuracy: 0.7841\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0416 - accuracy: 0.9884 - val_loss: 0.8624 - val_accuracy: 0.7986\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0742 - accuracy: 0.9755 - val_loss: 0.9285 - val_accuracy: 0.7624\n","Epoch 45/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0970 - accuracy: 0.9643 - val_loss: 0.8187 - val_accuracy: 0.7676\n","Epoch 46/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0479 - accuracy: 0.9853 - val_loss: 0.9866 - val_accuracy: 0.7748\n","Epoch 47/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0298 - accuracy: 0.9894 - val_loss: 0.9806 - val_accuracy: 0.7841\n","Epoch 48/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0395 - accuracy: 0.9850 - val_loss: 0.8602 - val_accuracy: 0.7903\n","Epoch 49/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0424 - accuracy: 0.9871 - val_loss: 0.8975 - val_accuracy: 0.7882\n","Epoch 50/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0459 - accuracy: 0.9848 - val_loss: 0.8825 - val_accuracy: 0.7841\n","Epoch 51/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0559 - accuracy: 0.9806 - val_loss: 0.8303 - val_accuracy: 0.7944\n","Epoch 52/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0277 - accuracy: 0.9917 - val_loss: 1.0059 - val_accuracy: 0.7748\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0299 - accuracy: 0.9894 - val_loss: 1.0190 - val_accuracy: 0.7924\n","Epoch 54/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0365 - accuracy: 0.9876 - val_loss: 1.0701 - val_accuracy: 0.7707\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0512 - accuracy: 0.9850 - val_loss: 0.9620 - val_accuracy: 0.7727\n","Epoch 56/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0497 - accuracy: 0.9832 - val_loss: 0.8707 - val_accuracy: 0.7624\n","Epoch 57/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0308 - accuracy: 0.9902 - val_loss: 0.9395 - val_accuracy: 0.7810\n","Epoch 58/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0393 - accuracy: 0.9876 - val_loss: 0.9527 - val_accuracy: 0.7696\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0284 - accuracy: 0.9920 - val_loss: 0.9365 - val_accuracy: 0.7903\n","Epoch 60/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0290 - accuracy: 0.9907 - val_loss: 1.0073 - val_accuracy: 0.7727\n","Epoch 61/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0371 - accuracy: 0.9891 - val_loss: 1.0080 - val_accuracy: 0.7521\n","Epoch 62/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0350 - accuracy: 0.9902 - val_loss: 0.9507 - val_accuracy: 0.7779\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 0.9202 - val_accuracy: 0.7882\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 1.0336 - val_accuracy: 0.7831\n","Epoch 65/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 0.9413 - val_accuracy: 0.8006\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0225 - accuracy: 0.9935 - val_loss: 1.1316 - val_accuracy: 0.7686\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0334 - accuracy: 0.9894 - val_loss: 0.9518 - val_accuracy: 0.7769\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0278 - accuracy: 0.9922 - val_loss: 0.9567 - val_accuracy: 0.8006\n","Epoch 69/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0213 - accuracy: 0.9948 - val_loss: 0.9626 - val_accuracy: 0.7903\n","Epoch 70/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0176 - accuracy: 0.9969 - val_loss: 1.0558 - val_accuracy: 0.7934\n","Epoch 71/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0196 - accuracy: 0.9943 - val_loss: 1.0046 - val_accuracy: 0.7893\n","Epoch 72/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0402 - accuracy: 0.9876 - val_loss: 1.0383 - val_accuracy: 0.7624\n","Epoch 73/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0655 - accuracy: 0.9773 - val_loss: 0.8709 - val_accuracy: 0.7562\n","Epoch 74/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0412 - accuracy: 0.9881 - val_loss: 0.8987 - val_accuracy: 0.7748\n","Epoch 75/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 1.0291 - val_accuracy: 0.7789\n","Epoch 76/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 1.1036 - val_accuracy: 0.7758\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0541 - accuracy: 0.9817 - val_loss: 0.9610 - val_accuracy: 0.7583\n","Epoch 78/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0885 - accuracy: 0.9713 - val_loss: 0.8001 - val_accuracy: 0.7583\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0361 - accuracy: 0.9894 - val_loss: 0.9614 - val_accuracy: 0.7645\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0367 - accuracy: 0.9886 - val_loss: 0.9791 - val_accuracy: 0.7665\n","Epoch 81/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0375 - accuracy: 0.9879 - val_loss: 0.9971 - val_accuracy: 0.7593\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0365 - accuracy: 0.9873 - val_loss: 1.0270 - val_accuracy: 0.7469\n","Epoch 83/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0248 - accuracy: 0.9922 - val_loss: 1.1177 - val_accuracy: 0.7572\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0222 - accuracy: 0.9946 - val_loss: 1.0439 - val_accuracy: 0.7738\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 1.0877 - val_accuracy: 0.7727\n","Epoch 86/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0211 - accuracy: 0.9935 - val_loss: 1.1001 - val_accuracy: 0.7634\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0269 - accuracy: 0.9922 - val_loss: 1.0189 - val_accuracy: 0.7758\n","Epoch 88/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0253 - accuracy: 0.9933 - val_loss: 1.0971 - val_accuracy: 0.7552\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0160 - accuracy: 0.9964 - val_loss: 1.0253 - val_accuracy: 0.7686\n","Epoch 90/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0155 - accuracy: 0.9972 - val_loss: 1.0210 - val_accuracy: 0.7614\n","Epoch 91/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0140 - accuracy: 0.9974 - val_loss: 0.9500 - val_accuracy: 0.7831\n","Epoch 92/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0126 - accuracy: 0.9974 - val_loss: 0.9601 - val_accuracy: 0.7903\n","Epoch 93/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.9766 - val_accuracy: 0.7841\n","Epoch 94/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.9631 - val_accuracy: 0.7851\n","Epoch 95/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0138 - accuracy: 0.9972 - val_loss: 0.9399 - val_accuracy: 0.7913\n","Epoch 96/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0135 - accuracy: 0.9974 - val_loss: 0.9544 - val_accuracy: 0.7851\n","Epoch 97/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 0.9213 - val_accuracy: 0.7831\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0130 - accuracy: 0.9974 - val_loss: 0.9228 - val_accuracy: 0.7975\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.8924 - val_accuracy: 0.7924\n","Epoch 100/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0137 - accuracy: 0.9969 - val_loss: 0.9142 - val_accuracy: 0.8017\n","{'loss': [0.09356771409511566, 0.040332406759262085, 0.04306446388363838, 0.051316745579242706, 0.04475859925150871, 0.044315971434116364, 0.03978390246629715, 0.03650656342506409, 0.039909638464450836, 0.08418384939432144, 0.05523189902305603, 0.032760895788669586, 0.0402904637157917, 0.031083039939403534, 0.0285786222666502, 0.03825848549604416, 0.05028894171118736, 0.03185787424445152, 0.027299532666802406, 0.02933252602815628, 0.02390001341700554, 0.032558269798755646, 0.057013314217329025, 0.05979578197002411, 0.036179330199956894, 0.06352992355823517, 0.05021164193749428, 0.06236995384097099, 0.05346985533833504, 0.033561546355485916, 0.02018812485039234, 0.021355537697672844, 0.016702596098184586, 0.018255194649100304, 0.016147559508681297, 0.015126146376132965, 0.014623385854065418, 0.013974134810268879, 0.01428996678441763, 0.025443963706493378, 0.018440373241901398, 0.022680258378386497, 0.04158373549580574, 0.07417111098766327, 0.09701143950223923, 0.04787520691752434, 0.029819337651133537, 0.039549052715301514, 0.04241525009274483, 0.04588678479194641, 0.05588975548744202, 0.02769521251320839, 0.02990727312862873, 0.03651770204305649, 0.05121661350131035, 0.049745719879865646, 0.030849864706397057, 0.03933818265795708, 0.02841673605144024, 0.028970398008823395, 0.03709559515118599, 0.03502138331532478, 0.021121319383382797, 0.0172251109033823, 0.015897395089268684, 0.02252146415412426, 0.03335948288440704, 0.027775943279266357, 0.02129463106393814, 0.017568806186318398, 0.019625360146164894, 0.04015493020415306, 0.06548183411359787, 0.04124510660767555, 0.023863205686211586, 0.02178024873137474, 0.05413656309247017, 0.08845795691013336, 0.03609171137213707, 0.03674658387899399, 0.0374545119702816, 0.036493778228759766, 0.024822091683745384, 0.022220946848392487, 0.017940407618880272, 0.021108360961079597, 0.026882942765951157, 0.02525043860077858, 0.015962300822138786, 0.015512988902628422, 0.014017049223184586, 0.012641056440770626, 0.014503736980259418, 0.012135552242398262, 0.013848495669662952, 0.013519314117729664, 0.011941786855459213, 0.013028658926486969, 0.014418547041714191, 0.013718495145440102], 'accuracy': [0.9687338471412659, 0.9878553152084351, 0.9863049387931824, 0.9819121360778809, 0.9847545027732849, 0.9863049387931824, 0.9883720874786377, 0.9870800971984863, 0.9860464930534363, 0.9718345999717712, 0.9813953638076782, 0.9883720874786377, 0.9865633249282837, 0.9904392957687378, 0.9909560680389404, 0.9873384833335876, 0.9826873540878296, 0.9906976819038391, 0.9930232763290405, 0.9912144541740417, 0.9940568208694458, 0.9896640777587891, 0.9795865416526794, 0.9793281555175781, 0.9901808500289917, 0.9785529971122742, 0.9829457402229309, 0.9795865416526794, 0.9829457402229309, 0.9904392957687378, 0.9943152666091919, 0.9950904250144958, 0.9961240291595459, 0.9950904250144958, 0.9963824152946472, 0.9958656430244446, 0.9968992471694946, 0.9963824152946472, 0.997157633304596, 0.9917312860488892, 0.9937984347343445, 0.9937984347343445, 0.9883720874786377, 0.975452184677124, 0.9643411040306091, 0.9852713346481323, 0.9894056916236877, 0.985012948513031, 0.9870800971984863, 0.9847545027732849, 0.9806201457977295, 0.9917312860488892, 0.9894056916236877, 0.987596869468689, 0.985012948513031, 0.9832041263580322, 0.9901808500289917, 0.987596869468689, 0.9919896721839905, 0.9906976819038391, 0.9891473054885864, 0.9901808500289917, 0.9937984347343445, 0.9945736527442932, 0.9953488111495972, 0.9935400485992432, 0.9894056916236877, 0.9922480583190918, 0.9948320388793945, 0.9968992471694946, 0.9943152666091919, 0.987596869468689, 0.9772610068321228, 0.9881137013435364, 0.9927648305892944, 0.9925064444541931, 0.9816537499427795, 0.9713178277015686, 0.9894056916236877, 0.988630473613739, 0.9878553152084351, 0.9873384833335876, 0.9922480583190918, 0.9945736527442932, 0.9950904250144958, 0.9935400485992432, 0.9922480583190918, 0.9932816624641418, 0.9963824152946472, 0.997157633304596, 0.9974160194396973, 0.9974160194396973, 0.9958656430244446, 0.9966408014297485, 0.997157633304596, 0.9974160194396973, 0.9974160194396973, 0.9974160194396973, 0.9968992471694946, 0.9968992471694946], 'val_loss': [0.9925481677055359, 1.286961555480957, 1.537434458732605, 1.4942054748535156, 1.6488797664642334, 1.8211817741394043, 1.7925007343292236, 2.00248122215271, 2.0060038566589355, 1.6221107244491577, 1.778141736984253, 1.996731162071228, 1.8352640867233276, 1.582412838935852, 1.2868785858154297, 1.142382264137268, 1.0127204656600952, 0.8434150815010071, 0.9007710814476013, 0.8984731435775757, 0.8613942265510559, 0.829893946647644, 0.9102065563201904, 0.6571979522705078, 0.7854570150375366, 0.7359638214111328, 0.7700798511505127, 0.6325644254684448, 0.7448794841766357, 0.8120454549789429, 0.801504909992218, 0.7767671942710876, 0.7701969146728516, 0.7704906463623047, 0.729996383190155, 0.7721706032752991, 0.7430692911148071, 0.7704958319664001, 0.7356200814247131, 0.7463858127593994, 0.9181060791015625, 0.9795029163360596, 0.8624324798583984, 0.9284685850143433, 0.818727970123291, 0.9865512847900391, 0.9806373715400696, 0.8602458238601685, 0.8975092768669128, 0.8824520111083984, 0.8303186893463135, 1.005881428718567, 1.0189578533172607, 1.070103406906128, 0.9620220065116882, 0.8707370162010193, 0.9395348429679871, 0.9526966214179993, 0.9364786148071289, 1.0072619915008545, 1.0080363750457764, 0.9507081508636475, 0.9202377200126648, 1.0336438417434692, 0.9413254857063293, 1.1316213607788086, 0.951812744140625, 0.956739068031311, 0.962612509727478, 1.0558061599731445, 1.004583477973938, 1.038263201713562, 0.8708819150924683, 0.8987300395965576, 1.0290716886520386, 1.1035997867584229, 0.9609774947166443, 0.8000892996788025, 0.961356520652771, 0.9791136384010315, 0.9971030354499817, 1.0269927978515625, 1.117687463760376, 1.043918251991272, 1.0877363681793213, 1.1000863313674927, 1.018879771232605, 1.097090244293213, 1.025270700454712, 1.0209767818450928, 0.9499679207801819, 0.9600751996040344, 0.9765942096710205, 0.9630672931671143, 0.9399320483207703, 0.9543540477752686, 0.9213126301765442, 0.9228354692459106, 0.8924142718315125, 0.9142426252365112], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4876033067703247, 0.49070248007774353, 0.4927685856819153, 0.4958677589893341, 0.5051652789115906, 0.5537189841270447, 0.6084710955619812, 0.6394628286361694, 0.6621900796890259, 0.7210744023323059, 0.7283057570457458, 0.7376033067703247, 0.7654958963394165, 0.7768595218658447, 0.7438016533851624, 0.8006198406219482, 0.8109503984451294, 0.78925621509552, 0.8016529083251953, 0.8130165338516235, 0.8047520518302917, 0.8140496015548706, 0.8212810158729553, 0.8202479481697083, 0.8450413346290588, 0.8460744023323059, 0.8471074104309082, 0.8326446413993835, 0.8533057570457458, 0.8388429880142212, 0.8481404781341553, 0.8212810158729553, 0.8006198406219482, 0.7840909361839294, 0.7985537052154541, 0.7623966932296753, 0.7675619721412659, 0.7747933864593506, 0.7840909361839294, 0.7902892827987671, 0.788223147392273, 0.7840909361839294, 0.7944214940071106, 0.7747933864593506, 0.7923553586006165, 0.7706611752510071, 0.7727272510528564, 0.7623966932296753, 0.7809917330741882, 0.76962810754776, 0.7902892827987671, 0.7727272510528564, 0.7520661354064941, 0.7778925895690918, 0.788223147392273, 0.7830578684806824, 0.8006198406219482, 0.7685950398445129, 0.7768595218658447, 0.8006198406219482, 0.7902892827987671, 0.7933884263038635, 0.78925621509552, 0.7623966932296753, 0.7561983466148376, 0.7747933864593506, 0.7789255976676941, 0.7758264541625977, 0.7582644820213318, 0.7582644820213318, 0.7644628286361694, 0.7665289044380188, 0.7592975497245789, 0.7469007968902588, 0.7572314143180847, 0.7737603187561035, 0.7727272510528564, 0.7634297609329224, 0.7758264541625977, 0.7551652789115906, 0.7685950398445129, 0.7613636255264282, 0.7830578684806824, 0.7902892827987671, 0.7840909361839294, 0.7851239442825317, 0.7913222908973694, 0.7851239442825317, 0.7830578684806824, 0.797520637512207, 0.7923553586006165, 0.8016529083251953]}\n","32/32 [==============================] - 1s 5ms/step\n"]}]},{"cell_type":"code","source":["\n","metrics_df.round(3)"],"metadata":{"id":"Ik5JoVP2NPvY","colab":{"base_uri":"https://localhost:8080/","height":519},"executionInfo":{"status":"ok","timestamp":1717528603142,"user_tz":-360,"elapsed":79,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"outputId":"62187627-b179-492c-f229-66936df7a0b9"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.533      0.545   0.397  0.459        0.397        0.668   \n","1        1     0.556      0.557   0.547  0.552        0.547        0.565   \n","2        2     0.581      0.647   0.357  0.461        0.357        0.805   \n","3        0     0.581      0.587   0.549  0.567        0.549        0.613   \n","4        1     0.559      0.557   0.575  0.566        0.575        0.542   \n","5        2     0.592      0.615   0.494  0.548        0.494        0.691   \n","6        0     0.651      0.656   0.633  0.645        0.633        0.668   \n","7        1     0.658      0.649   0.691  0.669        0.691        0.626   \n","8        2     0.699      0.688   0.729  0.708        0.729        0.669   \n","9        0     0.748      0.762   0.720  0.741        0.720        0.776   \n","10       1     0.752      0.744   0.768  0.756        0.768        0.736   \n","11       2     0.801      0.804   0.797  0.800        0.797        0.805   \n","12       0     0.822      0.821   0.822  0.822        0.822        0.821   \n","13       1     0.809      0.798   0.826  0.812        0.826        0.791   \n","14       2     0.850      0.841   0.863  0.852        0.863        0.837   \n","\n","    Kappa  \n","0   0.065  \n","1   0.112  \n","2   0.163  \n","3   0.162  \n","4   0.117  \n","5   0.185  \n","6   0.302  \n","7   0.316  \n","8   0.398  \n","9   0.496  \n","10  0.504  \n","11  0.602  \n","12  0.643  \n","13  0.617  \n","14  0.701  "],"text/html":["\n","  <div id=\"df-55df8130-a067-47cd-8276-6bfb066d4aea\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.533</td>\n","      <td>0.545</td>\n","      <td>0.397</td>\n","      <td>0.459</td>\n","      <td>0.397</td>\n","      <td>0.668</td>\n","      <td>0.065</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.556</td>\n","      <td>0.557</td>\n","      <td>0.547</td>\n","      <td>0.552</td>\n","      <td>0.547</td>\n","      <td>0.565</td>\n","      <td>0.112</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.581</td>\n","      <td>0.647</td>\n","      <td>0.357</td>\n","      <td>0.461</td>\n","      <td>0.357</td>\n","      <td>0.805</td>\n","      <td>0.163</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.581</td>\n","      <td>0.587</td>\n","      <td>0.549</td>\n","      <td>0.567</td>\n","      <td>0.549</td>\n","      <td>0.613</td>\n","      <td>0.162</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.559</td>\n","      <td>0.557</td>\n","      <td>0.575</td>\n","      <td>0.566</td>\n","      <td>0.575</td>\n","      <td>0.542</td>\n","      <td>0.117</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.592</td>\n","      <td>0.615</td>\n","      <td>0.494</td>\n","      <td>0.548</td>\n","      <td>0.494</td>\n","      <td>0.691</td>\n","      <td>0.185</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.651</td>\n","      <td>0.656</td>\n","      <td>0.633</td>\n","      <td>0.645</td>\n","      <td>0.633</td>\n","      <td>0.668</td>\n","      <td>0.302</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.658</td>\n","      <td>0.649</td>\n","      <td>0.691</td>\n","      <td>0.669</td>\n","      <td>0.691</td>\n","      <td>0.626</td>\n","      <td>0.316</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.699</td>\n","      <td>0.688</td>\n","      <td>0.729</td>\n","      <td>0.708</td>\n","      <td>0.729</td>\n","      <td>0.669</td>\n","      <td>0.398</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.748</td>\n","      <td>0.762</td>\n","      <td>0.720</td>\n","      <td>0.741</td>\n","      <td>0.720</td>\n","      <td>0.776</td>\n","      <td>0.496</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.752</td>\n","      <td>0.744</td>\n","      <td>0.768</td>\n","      <td>0.756</td>\n","      <td>0.768</td>\n","      <td>0.736</td>\n","      <td>0.504</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.801</td>\n","      <td>0.804</td>\n","      <td>0.797</td>\n","      <td>0.800</td>\n","      <td>0.797</td>\n","      <td>0.805</td>\n","      <td>0.602</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.822</td>\n","      <td>0.821</td>\n","      <td>0.822</td>\n","      <td>0.822</td>\n","      <td>0.822</td>\n","      <td>0.821</td>\n","      <td>0.643</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.809</td>\n","      <td>0.798</td>\n","      <td>0.826</td>\n","      <td>0.812</td>\n","      <td>0.826</td>\n","      <td>0.791</td>\n","      <td>0.617</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.850</td>\n","      <td>0.841</td>\n","      <td>0.863</td>\n","      <td>0.852</td>\n","      <td>0.863</td>\n","      <td>0.837</td>\n","      <td>0.701</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55df8130-a067-47cd-8276-6bfb066d4aea')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-55df8130-a067-47cd-8276-6bfb066d4aea button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-55df8130-a067-47cd-8276-6bfb066d4aea');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-38816467-042d-4225-a9c4-7aa38081eb5d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38816467-042d-4225-a9c4-7aa38081eb5d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-38816467-042d-4225-a9c4-7aa38081eb5d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11045611065465043,\n        \"min\": 0.533,\n        \"max\": 0.85,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.752,\n          0.822,\n          0.533\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10338310629240478,\n        \"min\": 0.545,\n        \"max\": 0.841,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.744,\n          0.821,\n          0.545\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15927971801654023,\n        \"min\": 0.357,\n        \"max\": 0.863,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.72,\n          0.797,\n          0.397\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13246825315991032,\n        \"min\": 0.459,\n        \"max\": 0.852,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.741,\n          0.8,\n          0.459\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15927971801654023,\n        \"min\": 0.357,\n        \"max\": 0.863,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.72,\n          0.797,\n          0.397\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09609732170094668,\n        \"min\": 0.542,\n        \"max\": 0.837,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.791,\n          0.736,\n          0.668\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22090006359265288,\n        \"min\": 0.065,\n        \"max\": 0.701,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.496,\n          0.602,\n          0.065\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["metrics_df.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/DWT/CNN_LSTM/Alpha_DWT_CNN_LSTM.csv', index = False)"],"metadata":{"id":"Ncf_cMAQF6g4","executionInfo":{"status":"ok","timestamp":1717528603142,"user_tz":-360,"elapsed":69,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# CNN-LSTM Graph"],"metadata":{"id":"ZUR_QwblhNjJ"}},{"cell_type":"code","source":["import wandb\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import re\n","import seaborn as sns\n","\n","# Initialize the API\n","api = wandb.Api()\n","\n","# Specify the entity and project\n","entity = \"raihanrabby\"\n","project = \"Beta_time_domain_CNN_Lstm\"\n","\n","# Fetch all runs from the project\n","runs = api.runs(f\"{entity}/{project}\")\n","\n","# List to store the dataframes\n","dataframes = []\n","\n","# Iterate over each run and fetch the history\n","for run in runs:\n","    # Fetch the history for each run\n","    history = run.history()\n","\n","    # Add columns to identify the run, model name, epoch, and client\n","    history['run_id'] = run.id\n","    history['model_name'] = run.name\n","\n","    # Extract epoch and client from model name\n","    match = re.match(r'epoch_(\\d+)_client_(\\d+)', run.name)\n","    if match:\n","        history['epoch_number'] = int(match.group(1))\n","        history['client_number'] = int(match.group(2))\n","    else:\n","        history['epoch_number'] = None\n","        history['client_number'] = None\n","\n","    # Append to the list of dataframes\n","    dataframes.append(history)\n","\n","# Concatenate all dataframes into a single dataframe\n","all_metrics_df = pd.concat(dataframes)\n","\n","# Filter out rows with None epoch_number\n","all_metrics_df = all_metrics_df.dropna(subset=['epoch_number'])\n","\n","# Get the unique epochs\n","unique_epochs = sorted(all_metrics_df['epoch_number'].unique())\n","\n","# Set the Seaborn style\n","sns.set(style=\"whitegrid\")\n","\n","# Create subplots for each epoch\n","fig, axes = plt.subplots(2, len(unique_epochs), figsize=(len(unique_epochs) * 3, 4.5), sharex=True)\n","\n","# Set the color palette\n","palette = sns.color_palette(\"Set1\", n_colors=all_metrics_df['client_number'].nunique())\n","\n","# Store the lines and labels for the legend\n","lines = []\n","labels = []\n","\n","# Iterate through each epoch and plot the training and validation accuracy\n","for i, epoch in enumerate(unique_epochs):\n","    epoch_df = all_metrics_df[all_metrics_df['epoch_number'] == epoch]\n","    for j, client in enumerate(epoch_df['client_number'].unique()):\n","        client_df = epoch_df[epoch_df['client_number'] == client]\n","        line, = axes[0, i].plot(client_df['accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","        axes[1, i].plot(client_df['val_accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","\n","        if i == 0:\n","            lines.append(line)\n","            labels.append(f'Client {client}')\n","\n","    axes[0, i].set_title(f'Epoch {epoch}', fontsize=12, fontweight='bold')\n","    axes[0, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","    axes[1, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","    # axes[0, i].set_ylim(0.5)  # Ensure y-axis covers full range of accuracy\n","    axes[1, i].set_ylim(0.5, 1.0)  # Ensure y-axis covers full range of accuracy\n","    axes[1, i].set_xlabel('Steps', fontsize=10, fontweight='bold')\n","    axes[0, i].grid(True)\n","    axes[1, i].grid(True)\n","    axes[0, i].tick_params(axis='both', which='major', labelsize=10)\n","    axes[1, i].tick_params(axis='both', which='major', labelsize=10)\n","\n","# Add a single legend for the entire figure\n","fig.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 1.0), ncol=len(labels), fontsize=10, frameon=True)\n","\n","# Add row labels\n","fig.text(0.04, 0.75, 'Training Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","fig.text(0.04, 0.25, 'Validation Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","\n","plt.tight_layout(rect=[0.05, 0, 1, 0.95])\n","plt.subplots_adjust(hspace=0.2, top=0.88)  # Add some space between the rows and reduce space between the legend and plot\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":462},"id":"zdihdEQAk8x9","executionInfo":{"status":"ok","timestamp":1716740043376,"user_tz":-360,"elapsed":15427,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"6f210444-99b7-4a2d-e54d-c63ffe64373a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x450 with 10 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"F0IzJ6S5k8vk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_metrics_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"dF-KSdKdhsqv","executionInfo":{"status":"ok","timestamp":1716636800286,"user_tz":-360,"elapsed":373,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"468ed3c0-e85c-4f92-da49-0afecd4c142c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      _runtime  accuracy  val_loss    _timestamp  val_accuracy      loss  \\\n","0    13.310213  0.894723  0.860759  1.716588e+09      0.504283  0.247455   \n","1    22.364346  0.917493  0.848398  1.716588e+09      0.504283  0.195490   \n","2    33.860330  0.914814  0.825522  1.716588e+09      0.504283  0.204736   \n","3    43.363837  0.909992  0.825889  1.716588e+09      0.504283  0.208303   \n","4    44.307076  0.922047  0.801610  1.716588e+09      0.504283  0.188477   \n","..         ...       ...       ...           ...           ...       ...   \n","95  416.614793  0.788910  0.553507  1.716585e+09      0.730193  0.455315   \n","96  417.041695  0.782213  0.548009  1.716585e+09      0.732334  0.458011   \n","97  417.444440  0.778998  0.550679  1.716585e+09      0.729122  0.459626   \n","98  417.884801  0.792660  0.559028  1.716585e+09      0.722698  0.451855   \n","99  418.304440  0.782748  0.551085  1.716585e+09      0.729122  0.454946   \n","\n","    _step  epoch    run_id  \n","0       0      0  2nsbmzjb  \n","1       1      1  2nsbmzjb  \n","2       2      2  2nsbmzjb  \n","3       3      3  2nsbmzjb  \n","4       4      4  2nsbmzjb  \n","..    ...    ...       ...  \n","95     95     95  u6ki5wej  \n","96     96     96  u6ki5wej  \n","97     97     97  u6ki5wej  \n","98     98     98  u6ki5wej  \n","99     99     99  u6ki5wej  \n","\n","[1500 rows x 9 columns]"],"text/html":["\n","  <div id=\"df-c54c6cd2-19dd-4a84-90fb-57f868070b89\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>_runtime</th>\n","      <th>accuracy</th>\n","      <th>val_loss</th>\n","      <th>_timestamp</th>\n","      <th>val_accuracy</th>\n","      <th>loss</th>\n","      <th>_step</th>\n","      <th>epoch</th>\n","      <th>run_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>13.310213</td>\n","      <td>0.894723</td>\n","      <td>0.860759</td>\n","      <td>1.716588e+09</td>\n","      <td>0.504283</td>\n","      <td>0.247455</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2nsbmzjb</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>22.364346</td>\n","      <td>0.917493</td>\n","      <td>0.848398</td>\n","      <td>1.716588e+09</td>\n","      <td>0.504283</td>\n","      <td>0.195490</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2nsbmzjb</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>33.860330</td>\n","      <td>0.914814</td>\n","      <td>0.825522</td>\n","      <td>1.716588e+09</td>\n","      <td>0.504283</td>\n","      <td>0.204736</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2nsbmzjb</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>43.363837</td>\n","      <td>0.909992</td>\n","      <td>0.825889</td>\n","      <td>1.716588e+09</td>\n","      <td>0.504283</td>\n","      <td>0.208303</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2nsbmzjb</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>44.307076</td>\n","      <td>0.922047</td>\n","      <td>0.801610</td>\n","      <td>1.716588e+09</td>\n","      <td>0.504283</td>\n","      <td>0.188477</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>2nsbmzjb</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>416.614793</td>\n","      <td>0.788910</td>\n","      <td>0.553507</td>\n","      <td>1.716585e+09</td>\n","      <td>0.730193</td>\n","      <td>0.455315</td>\n","      <td>95</td>\n","      <td>95</td>\n","      <td>u6ki5wej</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>417.041695</td>\n","      <td>0.782213</td>\n","      <td>0.548009</td>\n","      <td>1.716585e+09</td>\n","      <td>0.732334</td>\n","      <td>0.458011</td>\n","      <td>96</td>\n","      <td>96</td>\n","      <td>u6ki5wej</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>417.444440</td>\n","      <td>0.778998</td>\n","      <td>0.550679</td>\n","      <td>1.716585e+09</td>\n","      <td>0.729122</td>\n","      <td>0.459626</td>\n","      <td>97</td>\n","      <td>97</td>\n","      <td>u6ki5wej</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>417.884801</td>\n","      <td>0.792660</td>\n","      <td>0.559028</td>\n","      <td>1.716585e+09</td>\n","      <td>0.722698</td>\n","      <td>0.451855</td>\n","      <td>98</td>\n","      <td>98</td>\n","      <td>u6ki5wej</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>418.304440</td>\n","      <td>0.782748</td>\n","      <td>0.551085</td>\n","      <td>1.716585e+09</td>\n","      <td>0.729122</td>\n","      <td>0.454946</td>\n","      <td>99</td>\n","      <td>99</td>\n","      <td>u6ki5wej</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1500 rows × 9 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c54c6cd2-19dd-4a84-90fb-57f868070b89')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c54c6cd2-19dd-4a84-90fb-57f868070b89 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c54c6cd2-19dd-4a84-90fb-57f868070b89');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d2db8c50-ed3f-4d64-8b19-fc6d9c84f4c6\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2db8c50-ed3f-4d64-8b19-fc6d9c84f4c6')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d2db8c50-ed3f-4d64-8b19-fc6d9c84f4c6 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_af67ca15-c1be-45e1-84f8-5c85a974368d\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('all_metrics_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_af67ca15-c1be-45e1-84f8-5c85a974368d button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('all_metrics_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"all_metrics_df","summary":"{\n  \"name\": \"all_metrics_df\",\n  \"rows\": 1500,\n  \"fields\": [\n    {\n      \"column\": \"_runtime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 88.45497529136644,\n        \"min\": 10.388507843017578,\n        \"max\": 525.9502971172333,\n        \"num_unique_values\": 1499,\n        \"samples\": [\n          171.23451471328735,\n          514.5650720596313,\n          154.19228529930115\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08458249714165784,\n        \"min\": 0.5001339316368103,\n        \"max\": 0.9694615602493286,\n        \"num_unique_values\": 773,\n        \"samples\": [\n          0.8494508266448975,\n          0.7013126015663147,\n          0.7811411619186401\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07423729060194581,\n        \"min\": 0.42367106676101685,\n        \"max\": 0.898168683052063,\n        \"num_unique_values\": 1498,\n        \"samples\": [\n          0.49998635053634644,\n          0.6923187971115112,\n          0.5667726397514343\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_timestamp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1152.2215388098273,\n        \"min\": 1716584329.3731794,\n        \"max\": 1716588576.7424233,\n        \"num_unique_values\": 1500,\n        \"samples\": [\n          1716585811.4945405,\n          1716585200.7616174,\n          1716587598.5155294\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08631999854487923,\n        \"min\": 0.4860813617706299,\n        \"max\": 0.835117757320404,\n        \"num_unique_values\": 240,\n        \"samples\": [\n          0.7644539475440979,\n          0.5920770764350891,\n          0.5224839448928833\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1503027321511436,\n        \"min\": 0.08336261659860611,\n        \"max\": 0.6930587291717529,\n        \"num_unique_values\": 1500,\n        \"samples\": [\n          0.46639472246170044,\n          0.4926566481590271,\n          0.23360194265842438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_step\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          83,\n          53,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          83,\n          53,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"run_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"0ebggn8j\",\n          \"tsl17cy8\",\n          \"2nsbmzjb\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["# CNN"],"metadata":{"id":"QUuWzfMHSNmi"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    # model.add(Dropout(0.5))\n","    # model.add(LSTM(256, return_sequences=True))\n","    # model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Alpha/CNN/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Alpha/CNN/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"8xrx_fxBSWGd","executionInfo":{"status":"ok","timestamp":1717528603143,"user_tz":-360,"elapsed":67,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["global_model_CNN, metrics_df_CNN = federated_learning(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1TaNdIbSfkq","outputId":"eb6d3957-62f7-4a69-d33e-e44953eb54a4","executionInfo":{"status":"ok","timestamp":1717529742302,"user_tz":-360,"elapsed":1139225,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"collapsed":true},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 2.0124 - accuracy: 0.5260"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 76ms/step - loss: 2.0116 - accuracy: 0.5232 - val_loss: 2.0026 - val_accuracy: 0.5744\n","Epoch 2/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.9892 - accuracy: 0.5506 - val_loss: 1.9822 - val_accuracy: 0.5140\n","Epoch 3/100\n","29/29 [==============================] - 1s 48ms/step - loss: 1.9677 - accuracy: 0.5695 - val_loss: 1.9621 - val_accuracy: 0.5927\n","Epoch 4/100\n","29/29 [==============================] - 1s 35ms/step - loss: 1.9490 - accuracy: 0.5277 - val_loss: 1.9427 - val_accuracy: 0.5485\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.9278 - accuracy: 0.5493 - val_loss: 1.9234 - val_accuracy: 0.5172\n","Epoch 6/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.9074 - accuracy: 0.5652 - val_loss: 1.9045 - val_accuracy: 0.5312\n","Epoch 7/100\n","29/29 [==============================] - 1s 34ms/step - loss: 1.8881 - accuracy: 0.5784 - val_loss: 1.8863 - val_accuracy: 0.6056\n","Epoch 8/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.8689 - accuracy: 0.5784 - val_loss: 1.8680 - val_accuracy: 0.5830\n","Epoch 9/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.8511 - accuracy: 0.5717 - val_loss: 1.8499 - val_accuracy: 0.5614\n","Epoch 10/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.8348 - accuracy: 0.5434 - val_loss: 1.8328 - val_accuracy: 0.5787\n","Epoch 11/100\n","29/29 [==============================] - 1s 41ms/step - loss: 1.8141 - accuracy: 0.5843 - val_loss: 1.8151 - val_accuracy: 0.6099\n","Epoch 12/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.7972 - accuracy: 0.5814 - val_loss: 1.7978 - val_accuracy: 0.5970\n","Epoch 13/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.7788 - accuracy: 0.5876 - val_loss: 1.7806 - val_accuracy: 0.5938\n","Epoch 14/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.7627 - accuracy: 0.5827 - val_loss: 1.7638 - val_accuracy: 0.5668\n","Epoch 15/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.7500 - accuracy: 0.5625 - val_loss: 1.7468 - val_accuracy: 0.5744\n","Epoch 16/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.7301 - accuracy: 0.5727 - val_loss: 1.7316 - val_accuracy: 0.5938\n","Epoch 17/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.7143 - accuracy: 0.5832 - val_loss: 1.7144 - val_accuracy: 0.6056\n","Epoch 18/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.6989 - accuracy: 0.5886 - val_loss: 1.6987 - val_accuracy: 0.5679\n","Epoch 19/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.6835 - accuracy: 0.5857 - val_loss: 1.6827 - val_accuracy: 0.6034\n","Epoch 20/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.6700 - accuracy: 0.5913 - val_loss: 1.6678 - val_accuracy: 0.5927\n","Epoch 21/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.6555 - accuracy: 0.5803 - val_loss: 1.6526 - val_accuracy: 0.5841\n","Epoch 22/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.6428 - accuracy: 0.5851 - val_loss: 1.6378 - val_accuracy: 0.5959\n","Epoch 23/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.6278 - accuracy: 0.5832 - val_loss: 1.6246 - val_accuracy: 0.5873\n","Epoch 24/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.6131 - accuracy: 0.5913 - val_loss: 1.6097 - val_accuracy: 0.5981\n","Epoch 25/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.6040 - accuracy: 0.5854 - val_loss: 1.5970 - val_accuracy: 0.5862\n","Epoch 26/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.5906 - accuracy: 0.5776 - val_loss: 1.5900 - val_accuracy: 0.5711\n","Epoch 27/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.5760 - accuracy: 0.5878 - val_loss: 1.5710 - val_accuracy: 0.5981\n","Epoch 28/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.5636 - accuracy: 0.5911 - val_loss: 1.5586 - val_accuracy: 0.5959\n","Epoch 29/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.5521 - accuracy: 0.5946 - val_loss: 1.5475 - val_accuracy: 0.5884\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5389 - accuracy: 0.5878 - val_loss: 1.5351 - val_accuracy: 0.5981\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5268 - accuracy: 0.5867 - val_loss: 1.5228 - val_accuracy: 0.5948\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5148 - accuracy: 0.5929 - val_loss: 1.5111 - val_accuracy: 0.6056\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5028 - accuracy: 0.5913 - val_loss: 1.5001 - val_accuracy: 0.5905\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4951 - accuracy: 0.5859 - val_loss: 1.4994 - val_accuracy: 0.5690\n","Epoch 35/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4886 - accuracy: 0.5857 - val_loss: 1.4914 - val_accuracy: 0.5625\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4741 - accuracy: 0.5854 - val_loss: 1.4698 - val_accuracy: 0.5948\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4632 - accuracy: 0.5959 - val_loss: 1.4589 - val_accuracy: 0.6013\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4511 - accuracy: 0.5946 - val_loss: 1.4581 - val_accuracy: 0.5700\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4399 - accuracy: 0.5989 - val_loss: 1.4388 - val_accuracy: 0.5959\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4309 - accuracy: 0.5902 - val_loss: 1.4315 - val_accuracy: 0.5873\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4207 - accuracy: 0.5946 - val_loss: 1.4197 - val_accuracy: 0.5991\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4099 - accuracy: 0.5940 - val_loss: 1.4154 - val_accuracy: 0.5808\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4038 - accuracy: 0.5889 - val_loss: 1.4019 - val_accuracy: 0.5970\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3951 - accuracy: 0.5973 - val_loss: 1.3922 - val_accuracy: 0.5981\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3869 - accuracy: 0.5967 - val_loss: 1.3888 - val_accuracy: 0.5797\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3763 - accuracy: 0.6002 - val_loss: 1.3772 - val_accuracy: 0.5873\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3657 - accuracy: 0.5964 - val_loss: 1.3676 - val_accuracy: 0.6045\n","Epoch 48/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3559 - accuracy: 0.6024 - val_loss: 1.3680 - val_accuracy: 0.5744\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3497 - accuracy: 0.5911 - val_loss: 1.3505 - val_accuracy: 0.6002\n","Epoch 50/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3402 - accuracy: 0.5973 - val_loss: 1.3418 - val_accuracy: 0.6002\n","Epoch 51/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3317 - accuracy: 0.5981 - val_loss: 1.3378 - val_accuracy: 0.5787\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3234 - accuracy: 0.6016 - val_loss: 1.3271 - val_accuracy: 0.6002\n","Epoch 53/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3179 - accuracy: 0.6018 - val_loss: 1.3245 - val_accuracy: 0.5722\n","Epoch 54/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3137 - accuracy: 0.5886 - val_loss: 1.3130 - val_accuracy: 0.5948\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3022 - accuracy: 0.6037 - val_loss: 1.3087 - val_accuracy: 0.5819\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2931 - accuracy: 0.5959 - val_loss: 1.2978 - val_accuracy: 0.5991\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2851 - accuracy: 0.6034 - val_loss: 1.2895 - val_accuracy: 0.5970\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2826 - accuracy: 0.5948 - val_loss: 1.2883 - val_accuracy: 0.5754\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2747 - accuracy: 0.5973 - val_loss: 1.2779 - val_accuracy: 0.5851\n","Epoch 60/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2688 - accuracy: 0.5975 - val_loss: 1.2707 - val_accuracy: 0.5916\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2570 - accuracy: 0.5975 - val_loss: 1.2689 - val_accuracy: 0.5787\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2531 - accuracy: 0.6002 - val_loss: 1.2562 - val_accuracy: 0.5981\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2493 - accuracy: 0.5913 - val_loss: 1.2499 - val_accuracy: 0.5981\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2399 - accuracy: 0.5970 - val_loss: 1.2441 - val_accuracy: 0.5948\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2321 - accuracy: 0.6053 - val_loss: 1.2401 - val_accuracy: 0.5873\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2243 - accuracy: 0.6043 - val_loss: 1.2403 - val_accuracy: 0.5754\n","Epoch 67/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.2190 - accuracy: 0.6043 - val_loss: 1.2251 - val_accuracy: 0.5970\n","Epoch 68/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2115 - accuracy: 0.6099 - val_loss: 1.2192 - val_accuracy: 0.5970\n","Epoch 69/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.2059 - accuracy: 0.6040 - val_loss: 1.2134 - val_accuracy: 0.6002\n","Epoch 70/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2007 - accuracy: 0.6045 - val_loss: 1.2186 - val_accuracy: 0.5733\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1941 - accuracy: 0.6121 - val_loss: 1.2026 - val_accuracy: 0.5841\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1898 - accuracy: 0.6026 - val_loss: 1.1967 - val_accuracy: 0.5851\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1836 - accuracy: 0.6096 - val_loss: 1.1997 - val_accuracy: 0.5722\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1794 - accuracy: 0.6056 - val_loss: 1.1872 - val_accuracy: 0.5927\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1739 - accuracy: 0.5951 - val_loss: 1.1844 - val_accuracy: 0.5830\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1685 - accuracy: 0.6083 - val_loss: 1.1890 - val_accuracy: 0.5657\n","Epoch 77/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1629 - accuracy: 0.6131 - val_loss: 1.1793 - val_accuracy: 0.5690\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1563 - accuracy: 0.6140 - val_loss: 1.1688 - val_accuracy: 0.5884\n","Epoch 79/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1511 - accuracy: 0.6096 - val_loss: 1.1610 - val_accuracy: 0.5970\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1484 - accuracy: 0.6053 - val_loss: 1.1573 - val_accuracy: 0.5873\n","Epoch 81/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1428 - accuracy: 0.6088 - val_loss: 1.1517 - val_accuracy: 0.5862\n","Epoch 82/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1368 - accuracy: 0.6091 - val_loss: 1.1513 - val_accuracy: 0.5862\n","Epoch 83/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1309 - accuracy: 0.6172 - val_loss: 1.1435 - val_accuracy: 0.5787\n","Epoch 84/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1299 - accuracy: 0.6140 - val_loss: 1.1385 - val_accuracy: 0.5862\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1215 - accuracy: 0.6142 - val_loss: 1.1364 - val_accuracy: 0.5894\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1169 - accuracy: 0.6140 - val_loss: 1.1298 - val_accuracy: 0.5981\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1121 - accuracy: 0.6140 - val_loss: 1.1253 - val_accuracy: 0.5927\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1082 - accuracy: 0.6118 - val_loss: 1.1344 - val_accuracy: 0.5700\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1065 - accuracy: 0.6110 - val_loss: 1.1295 - val_accuracy: 0.5722\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1011 - accuracy: 0.6121 - val_loss: 1.1211 - val_accuracy: 0.5733\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0962 - accuracy: 0.6078 - val_loss: 1.1130 - val_accuracy: 0.5797\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0914 - accuracy: 0.6091 - val_loss: 1.1065 - val_accuracy: 0.5948\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0877 - accuracy: 0.6096 - val_loss: 1.1118 - val_accuracy: 0.5711\n","Epoch 94/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0862 - accuracy: 0.6099 - val_loss: 1.0992 - val_accuracy: 0.5927\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0805 - accuracy: 0.6180 - val_loss: 1.0950 - val_accuracy: 0.5894\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0764 - accuracy: 0.6134 - val_loss: 1.0939 - val_accuracy: 0.5851\n","Epoch 97/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0714 - accuracy: 0.6175 - val_loss: 1.0952 - val_accuracy: 0.5690\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0732 - accuracy: 0.6032 - val_loss: 1.0975 - val_accuracy: 0.5733\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0666 - accuracy: 0.6172 - val_loss: 1.0835 - val_accuracy: 0.5873\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0616 - accuracy: 0.6164 - val_loss: 1.0915 - val_accuracy: 0.5722\n","{'loss': [2.011603355407715, 1.9891709089279175, 1.9676543474197388, 1.9490270614624023, 1.9278194904327393, 1.9074190855026245, 1.8881006240844727, 1.86885404586792, 1.8510617017745972, 1.8347502946853638, 1.814103603363037, 1.7971560955047607, 1.7788419723510742, 1.7627321481704712, 1.7500180006027222, 1.730129599571228, 1.7143065929412842, 1.6989049911499023, 1.6835248470306396, 1.6699981689453125, 1.6554890871047974, 1.642796277999878, 1.6278069019317627, 1.6130566596984863, 1.60397207736969, 1.5905706882476807, 1.575955867767334, 1.5636286735534668, 1.5521103143692017, 1.5388656854629517, 1.5267921686172485, 1.5148377418518066, 1.502822756767273, 1.495107889175415, 1.4886418581008911, 1.4740880727767944, 1.4632489681243896, 1.4511349201202393, 1.4399337768554688, 1.430925965309143, 1.42073392868042, 1.4098902940750122, 1.403784990310669, 1.395147442817688, 1.386945366859436, 1.3762985467910767, 1.3656824827194214, 1.3558791875839233, 1.3497258424758911, 1.3401520252227783, 1.3317155838012695, 1.323391079902649, 1.3178516626358032, 1.3136998414993286, 1.3022401332855225, 1.2930513620376587, 1.2850664854049683, 1.2825841903686523, 1.2746670246124268, 1.2688137292861938, 1.2570106983184814, 1.2530847787857056, 1.2492893934249878, 1.239880084991455, 1.2320584058761597, 1.2242512702941895, 1.2190295457839966, 1.2114861011505127, 1.2059067487716675, 1.200735330581665, 1.1941275596618652, 1.1897737979888916, 1.1836374998092651, 1.1793813705444336, 1.1738789081573486, 1.168455719947815, 1.1628824472427368, 1.1562830209732056, 1.1510916948318481, 1.1484367847442627, 1.1427661180496216, 1.1367571353912354, 1.1308590173721313, 1.1299136877059937, 1.1215041875839233, 1.116888403892517, 1.1121137142181396, 1.1081992387771606, 1.106492519378662, 1.1010760068893433, 1.0961710214614868, 1.0913689136505127, 1.0876959562301636, 1.086227297782898, 1.0805299282073975, 1.076388955116272, 1.0714354515075684, 1.0732166767120361, 1.066572904586792, 1.061640977859497], 'accuracy': [0.5231680870056152, 0.5506465435028076, 0.5695043206214905, 0.5277478694915771, 0.5492995977401733, 0.5651939511299133, 0.5783944129943848, 0.5783944129943848, 0.571659505367279, 0.5433728694915771, 0.584321141242981, 0.5813577771186829, 0.587553858757019, 0.5827047228813171, 0.5625, 0.5727370977401733, 0.5832435488700867, 0.5886314511299133, 0.5856680870056152, 0.5913254022598267, 0.5802801847457886, 0.5851293206214905, 0.5832435488700867, 0.5913254022598267, 0.5853987336158752, 0.5775862336158752, 0.5878232717514038, 0.5910560488700867, 0.5945581793785095, 0.5878232717514038, 0.5867456793785095, 0.5929418206214905, 0.5913254022598267, 0.5859375, 0.5856680870056152, 0.5853987336158752, 0.5959051847457886, 0.5945581793785095, 0.5988685488700867, 0.5902478694915771, 0.5945581793785095, 0.5940194129943848, 0.5889008641242981, 0.5972521305084229, 0.5967133641242981, 0.600215494632721, 0.5964439511299133, 0.6023706793785095, 0.5910560488700867, 0.5972521305084229, 0.5980603694915771, 0.6015625, 0.6018319129943848, 0.5886314511299133, 0.6037176847457886, 0.5959051847457886, 0.6034482717514038, 0.5948275923728943, 0.5972521305084229, 0.5975215435028076, 0.5975215435028076, 0.600215494632721, 0.5913254022598267, 0.5969827771186829, 0.6053340435028076, 0.6042564511299133, 0.6042564511299133, 0.6099137663841248, 0.6039870977401733, 0.6045258641242981, 0.6120689511299133, 0.6026400923728943, 0.6096444129943848, 0.6056034564971924, 0.595097005367279, 0.6082974076271057, 0.6131465435028076, 0.6139547228813171, 0.6096444129943848, 0.6053340435028076, 0.6088362336158752, 0.6091055870056152, 0.6171875, 0.6139547228813171, 0.6142241358757019, 0.6139547228813171, 0.6139547228813171, 0.6117995977401733, 0.610991358757019, 0.6120689511299133, 0.607758641242981, 0.6091055870056152, 0.6096444129943848, 0.6099137663841248, 0.6179956793785095, 0.6134159564971924, 0.6174569129943848, 0.603178858757019, 0.6171875, 0.6163793206214905], 'val_loss': [2.0025522708892822, 1.9822111129760742, 1.9621402025222778, 1.9427402019500732, 1.9234306812286377, 1.9045348167419434, 1.8863093852996826, 1.8679890632629395, 1.8499374389648438, 1.8327916860580444, 1.8151417970657349, 1.7978169918060303, 1.780572772026062, 1.763820767402649, 1.746808648109436, 1.7316054105758667, 1.7143961191177368, 1.6987454891204834, 1.682674527168274, 1.6678133010864258, 1.6526035070419312, 1.6377724409103394, 1.6245977878570557, 1.6097170114517212, 1.5970245599746704, 1.5900027751922607, 1.5709503889083862, 1.5586334466934204, 1.5475326776504517, 1.5350923538208008, 1.5228416919708252, 1.5111018419265747, 1.5000675916671753, 1.499436855316162, 1.4913541078567505, 1.4698054790496826, 1.4588595628738403, 1.4580931663513184, 1.4388264417648315, 1.431515097618103, 1.4196679592132568, 1.4153534173965454, 1.4019051790237427, 1.3921583890914917, 1.3887994289398193, 1.377211570739746, 1.3675767183303833, 1.3680285215377808, 1.350477695465088, 1.341791033744812, 1.3377838134765625, 1.3270671367645264, 1.3245494365692139, 1.3129606246948242, 1.3086527585983276, 1.297836422920227, 1.2894630432128906, 1.2882602214813232, 1.277942180633545, 1.2707054615020752, 1.268945574760437, 1.2562100887298584, 1.2499295473098755, 1.2440645694732666, 1.2400686740875244, 1.2403167486190796, 1.2250561714172363, 1.219173789024353, 1.213422179222107, 1.218566656112671, 1.2025701999664307, 1.1967072486877441, 1.1996519565582275, 1.1872484683990479, 1.1843912601470947, 1.1890106201171875, 1.1793367862701416, 1.168769359588623, 1.1609506607055664, 1.1573147773742676, 1.151696801185608, 1.1513484716415405, 1.1434578895568848, 1.1385276317596436, 1.1364136934280396, 1.1297756433486938, 1.1252520084381104, 1.134393572807312, 1.1295342445373535, 1.1210845708847046, 1.1129505634307861, 1.1064735651016235, 1.111814260482788, 1.0992109775543213, 1.0949903726577759, 1.0939035415649414, 1.0952109098434448, 1.0974876880645752, 1.0834507942199707, 1.091509222984314], 'val_accuracy': [0.5743534564971924, 0.514008641242981, 0.5926724076271057, 0.548491358757019, 0.517241358757019, 0.53125, 0.6056034564971924, 0.5829741358757019, 0.5614224076271057, 0.5786637663841248, 0.6099137663841248, 0.5969827771186829, 0.59375, 0.5668103694915771, 0.5743534564971924, 0.59375, 0.6056034564971924, 0.5678879022598267, 0.6034482717514038, 0.5926724076271057, 0.5840517282485962, 0.5959051847457886, 0.587284505367279, 0.5980603694915771, 0.5862069129943848, 0.5711206793785095, 0.5980603694915771, 0.5959051847457886, 0.5883620977401733, 0.5980603694915771, 0.5948275923728943, 0.6056034564971924, 0.5905172228813171, 0.568965494632721, 0.5625, 0.5948275923728943, 0.6012930870056152, 0.5700430870056152, 0.5959051847457886, 0.587284505367279, 0.5991379022598267, 0.5808189511299133, 0.5969827771186829, 0.5980603694915771, 0.579741358757019, 0.587284505367279, 0.6045258641242981, 0.5743534564971924, 0.600215494632721, 0.600215494632721, 0.5786637663841248, 0.600215494632721, 0.5721982717514038, 0.5948275923728943, 0.5818965435028076, 0.5991379022598267, 0.5969827771186829, 0.5754310488700867, 0.5851293206214905, 0.5915948152542114, 0.5786637663841248, 0.5980603694915771, 0.5980603694915771, 0.5948275923728943, 0.587284505367279, 0.5754310488700867, 0.5969827771186829, 0.5969827771186829, 0.600215494632721, 0.5732758641242981, 0.5840517282485962, 0.5851293206214905, 0.5721982717514038, 0.5926724076271057, 0.5829741358757019, 0.5657327771186829, 0.568965494632721, 0.5883620977401733, 0.5969827771186829, 0.587284505367279, 0.5862069129943848, 0.5862069129943848, 0.5786637663841248, 0.5862069129943848, 0.5894396305084229, 0.5980603694915771, 0.5926724076271057, 0.5700430870056152, 0.5721982717514038, 0.5732758641242981, 0.579741358757019, 0.5948275923728943, 0.5711206793785095, 0.5926724076271057, 0.5894396305084229, 0.5851293206214905, 0.568965494632721, 0.5732758641242981, 0.587284505367279, 0.5721982717514038]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 2.0141 - accuracy: 0.5003"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 4s 46ms/step - loss: 2.0141 - accuracy: 0.5003 - val_loss: 2.0036 - val_accuracy: 0.5068\n","Epoch 2/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.9926 - accuracy: 0.5198 - val_loss: 1.9842 - val_accuracy: 0.5475\n","Epoch 3/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.9707 - accuracy: 0.5379 - val_loss: 1.9650 - val_accuracy: 0.5023\n","Epoch 4/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.9521 - accuracy: 0.5215 - val_loss: 1.9462 - val_accuracy: 0.5045\n","Epoch 5/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.9343 - accuracy: 0.5453 - val_loss: 1.9279 - val_accuracy: 0.5204\n","Epoch 6/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.9131 - accuracy: 0.5512 - val_loss: 1.9096 - val_accuracy: 0.5373\n","Epoch 7/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.8949 - accuracy: 0.5611 - val_loss: 1.8917 - val_accuracy: 0.5600\n","Epoch 8/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.8758 - accuracy: 0.5764 - val_loss: 1.8741 - val_accuracy: 0.5690\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.8593 - accuracy: 0.5478 - val_loss: 1.8568 - val_accuracy: 0.5622\n","Epoch 10/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.8404 - accuracy: 0.5555 - val_loss: 1.8396 - val_accuracy: 0.5520\n","Epoch 11/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.8229 - accuracy: 0.5764 - val_loss: 1.8229 - val_accuracy: 0.5667\n","Epoch 12/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.8071 - accuracy: 0.5634 - val_loss: 1.8064 - val_accuracy: 0.5566\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.7884 - accuracy: 0.5784 - val_loss: 1.7902 - val_accuracy: 0.5419\n","Epoch 14/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.7723 - accuracy: 0.5874 - val_loss: 1.7739 - val_accuracy: 0.5871\n","Epoch 15/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.7577 - accuracy: 0.5699 - val_loss: 1.7604 - val_accuracy: 0.5079\n","Epoch 16/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.7408 - accuracy: 0.5812 - val_loss: 1.7423 - val_accuracy: 0.5826\n","Epoch 17/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.7249 - accuracy: 0.5886 - val_loss: 1.7286 - val_accuracy: 0.5136\n","Epoch 18/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.7094 - accuracy: 0.5869 - val_loss: 1.7154 - val_accuracy: 0.5102\n","Epoch 19/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.6984 - accuracy: 0.5702 - val_loss: 1.6992 - val_accuracy: 0.5170\n","Epoch 20/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6789 - accuracy: 0.5869 - val_loss: 1.6828 - val_accuracy: 0.5520\n","Epoch 21/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.6671 - accuracy: 0.5869 - val_loss: 1.6758 - val_accuracy: 0.5068\n","Epoch 22/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6542 - accuracy: 0.5662 - val_loss: 1.6562 - val_accuracy: 0.5441\n","Epoch 23/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.6408 - accuracy: 0.5750 - val_loss: 1.6482 - val_accuracy: 0.5136\n","Epoch 24/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.6360 - accuracy: 0.5555 - val_loss: 1.6270 - val_accuracy: 0.5962\n","Epoch 25/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.6132 - accuracy: 0.5891 - val_loss: 1.6131 - val_accuracy: 0.5713\n","Epoch 26/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.5997 - accuracy: 0.5852 - val_loss: 1.6004 - val_accuracy: 0.5713\n","Epoch 27/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.5873 - accuracy: 0.5894 - val_loss: 1.5871 - val_accuracy: 0.5826\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5745 - accuracy: 0.5872 - val_loss: 1.5759 - val_accuracy: 0.5848\n","Epoch 29/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.5613 - accuracy: 0.5976 - val_loss: 1.5679 - val_accuracy: 0.5600\n","Epoch 30/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.5513 - accuracy: 0.5900 - val_loss: 1.5538 - val_accuracy: 0.5701\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5374 - accuracy: 0.5956 - val_loss: 1.5438 - val_accuracy: 0.5554\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.5280 - accuracy: 0.5917 - val_loss: 1.5281 - val_accuracy: 0.5905\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5158 - accuracy: 0.5908 - val_loss: 1.5257 - val_accuracy: 0.5464\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5053 - accuracy: 0.5934 - val_loss: 1.5061 - val_accuracy: 0.5894\n","Epoch 35/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4945 - accuracy: 0.5914 - val_loss: 1.4958 - val_accuracy: 0.5848\n","Epoch 36/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4818 - accuracy: 0.5942 - val_loss: 1.4878 - val_accuracy: 0.5735\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4727 - accuracy: 0.5968 - val_loss: 1.4825 - val_accuracy: 0.5611\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4689 - accuracy: 0.5685 - val_loss: 1.4687 - val_accuracy: 0.5656\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4543 - accuracy: 0.5852 - val_loss: 1.4560 - val_accuracy: 0.5916\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4428 - accuracy: 0.5934 - val_loss: 1.4451 - val_accuracy: 0.5905\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4325 - accuracy: 0.5934 - val_loss: 1.4366 - val_accuracy: 0.5758\n","Epoch 42/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4234 - accuracy: 0.5914 - val_loss: 1.4263 - val_accuracy: 0.5848\n","Epoch 43/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4120 - accuracy: 0.5999 - val_loss: 1.4182 - val_accuracy: 0.5781\n","Epoch 44/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4026 - accuracy: 0.5985 - val_loss: 1.4088 - val_accuracy: 0.5962\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3931 - accuracy: 0.5982 - val_loss: 1.3992 - val_accuracy: 0.5837\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3851 - accuracy: 0.6016 - val_loss: 1.3931 - val_accuracy: 0.5781\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3766 - accuracy: 0.5965 - val_loss: 1.3824 - val_accuracy: 0.5860\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3672 - accuracy: 0.5999 - val_loss: 1.3745 - val_accuracy: 0.5803\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3645 - accuracy: 0.5840 - val_loss: 1.3654 - val_accuracy: 0.5826\n","Epoch 50/100\n","28/28 [==============================] - 1s 48ms/step - loss: 1.3530 - accuracy: 0.6030 - val_loss: 1.3569 - val_accuracy: 0.6007\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3458 - accuracy: 0.5894 - val_loss: 1.3524 - val_accuracy: 0.5713\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3349 - accuracy: 0.5988 - val_loss: 1.3435 - val_accuracy: 0.5860\n","Epoch 53/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3261 - accuracy: 0.5939 - val_loss: 1.3365 - val_accuracy: 0.5758\n","Epoch 54/100\n","28/28 [==============================] - 1s 38ms/step - loss: 1.3180 - accuracy: 0.6064 - val_loss: 1.3253 - val_accuracy: 0.5905\n","Epoch 55/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.3107 - accuracy: 0.6024 - val_loss: 1.3271 - val_accuracy: 0.5656\n","Epoch 56/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3064 - accuracy: 0.5922 - val_loss: 1.3105 - val_accuracy: 0.5860\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2945 - accuracy: 0.6058 - val_loss: 1.3049 - val_accuracy: 0.5860\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2891 - accuracy: 0.5982 - val_loss: 1.3046 - val_accuracy: 0.5566\n","Epoch 59/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2822 - accuracy: 0.5973 - val_loss: 1.2906 - val_accuracy: 0.5848\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2733 - accuracy: 0.6050 - val_loss: 1.2821 - val_accuracy: 0.5905\n","Epoch 61/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2680 - accuracy: 0.6005 - val_loss: 1.2771 - val_accuracy: 0.5826\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2583 - accuracy: 0.6047 - val_loss: 1.2684 - val_accuracy: 0.5894\n","Epoch 63/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2530 - accuracy: 0.6041 - val_loss: 1.2619 - val_accuracy: 0.5916\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2456 - accuracy: 0.6016 - val_loss: 1.2587 - val_accuracy: 0.5882\n","Epoch 65/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2387 - accuracy: 0.6007 - val_loss: 1.2495 - val_accuracy: 0.5916\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2336 - accuracy: 0.6030 - val_loss: 1.2461 - val_accuracy: 0.5690\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2248 - accuracy: 0.6118 - val_loss: 1.2369 - val_accuracy: 0.5928\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2201 - accuracy: 0.6092 - val_loss: 1.2310 - val_accuracy: 0.5894\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2134 - accuracy: 0.6053 - val_loss: 1.2266 - val_accuracy: 0.5950\n","Epoch 70/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2077 - accuracy: 0.6089 - val_loss: 1.2190 - val_accuracy: 0.5950\n","Epoch 71/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2006 - accuracy: 0.6022 - val_loss: 1.2132 - val_accuracy: 0.5962\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1960 - accuracy: 0.6095 - val_loss: 1.2084 - val_accuracy: 0.5882\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1901 - accuracy: 0.6041 - val_loss: 1.2025 - val_accuracy: 0.5928\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1897 - accuracy: 0.5985 - val_loss: 1.1972 - val_accuracy: 0.5973\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1771 - accuracy: 0.6101 - val_loss: 1.1912 - val_accuracy: 0.5950\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1732 - accuracy: 0.6095 - val_loss: 1.1899 - val_accuracy: 0.5894\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1691 - accuracy: 0.6121 - val_loss: 1.1808 - val_accuracy: 0.5950\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1617 - accuracy: 0.6078 - val_loss: 1.1763 - val_accuracy: 0.5928\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1585 - accuracy: 0.6109 - val_loss: 1.1754 - val_accuracy: 0.5871\n","Epoch 80/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1529 - accuracy: 0.6013 - val_loss: 1.1677 - val_accuracy: 0.5860\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1468 - accuracy: 0.6053 - val_loss: 1.1641 - val_accuracy: 0.5679\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1428 - accuracy: 0.6050 - val_loss: 1.1574 - val_accuracy: 0.5939\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1401 - accuracy: 0.6058 - val_loss: 1.1547 - val_accuracy: 0.5894\n","Epoch 84/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1346 - accuracy: 0.6067 - val_loss: 1.1510 - val_accuracy: 0.5916\n","Epoch 85/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1304 - accuracy: 0.6027 - val_loss: 1.1452 - val_accuracy: 0.5747\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1221 - accuracy: 0.6104 - val_loss: 1.1384 - val_accuracy: 0.5973\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1155 - accuracy: 0.6135 - val_loss: 1.1469 - val_accuracy: 0.5475\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1148 - accuracy: 0.6058 - val_loss: 1.1323 - val_accuracy: 0.5871\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1087 - accuracy: 0.6169 - val_loss: 1.1262 - val_accuracy: 0.5962\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1054 - accuracy: 0.6126 - val_loss: 1.1304 - val_accuracy: 0.5758\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1029 - accuracy: 0.6064 - val_loss: 1.1209 - val_accuracy: 0.5724\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0947 - accuracy: 0.6180 - val_loss: 1.1186 - val_accuracy: 0.5848\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0912 - accuracy: 0.6169 - val_loss: 1.1102 - val_accuracy: 0.5984\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0879 - accuracy: 0.6121 - val_loss: 1.1063 - val_accuracy: 0.5905\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0834 - accuracy: 0.6152 - val_loss: 1.1030 - val_accuracy: 0.5848\n","Epoch 96/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0794 - accuracy: 0.6132 - val_loss: 1.0984 - val_accuracy: 0.5939\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0783 - accuracy: 0.6126 - val_loss: 1.0941 - val_accuracy: 0.5995\n","Epoch 98/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0772 - accuracy: 0.5985 - val_loss: 1.0926 - val_accuracy: 0.5837\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0704 - accuracy: 0.6121 - val_loss: 1.0884 - val_accuracy: 0.5928\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0639 - accuracy: 0.6203 - val_loss: 1.0850 - val_accuracy: 0.5882\n","{'loss': [2.0141468048095703, 1.9925636053085327, 1.9706556797027588, 1.9520939588546753, 1.9343016147613525, 1.913104772567749, 1.8949440717697144, 1.8758256435394287, 1.859324336051941, 1.8403658866882324, 1.8229396343231201, 1.8070545196533203, 1.7883551120758057, 1.772273063659668, 1.7576955556869507, 1.7407703399658203, 1.724867343902588, 1.709446907043457, 1.6984474658966064, 1.6788966655731201, 1.6671010255813599, 1.6542123556137085, 1.6407885551452637, 1.6360429525375366, 1.6131993532180786, 1.599711298942566, 1.5873451232910156, 1.5744845867156982, 1.5613315105438232, 1.551347017288208, 1.5374196767807007, 1.5280355215072632, 1.5158379077911377, 1.5053125619888306, 1.4944795370101929, 1.4818027019500732, 1.4727234840393066, 1.4689313173294067, 1.4542973041534424, 1.4428036212921143, 1.4324532747268677, 1.4233766794204712, 1.4119752645492554, 1.402595043182373, 1.3930730819702148, 1.3851425647735596, 1.3766288757324219, 1.3672353029251099, 1.3645062446594238, 1.353016972541809, 1.3458149433135986, 1.3348983526229858, 1.32606840133667, 1.3179612159729004, 1.3106653690338135, 1.3063921928405762, 1.2945209741592407, 1.2890512943267822, 1.2822211980819702, 1.2733099460601807, 1.2679986953735352, 1.2582675218582153, 1.2529983520507812, 1.2455840110778809, 1.238734483718872, 1.2336387634277344, 1.2247568368911743, 1.2200759649276733, 1.213385820388794, 1.2076817750930786, 1.2005811929702759, 1.1960477828979492, 1.1901276111602783, 1.1896675825119019, 1.177132248878479, 1.173214077949524, 1.1690822839736938, 1.1616655588150024, 1.158528208732605, 1.1528743505477905, 1.146763801574707, 1.142845869064331, 1.140114665031433, 1.1346211433410645, 1.1304043531417847, 1.1220790147781372, 1.1155074834823608, 1.1148449182510376, 1.108690619468689, 1.1053876876831055, 1.102944254875183, 1.0946507453918457, 1.091160535812378, 1.0878769159317017, 1.083394169807434, 1.0793529748916626, 1.0783021450042725, 1.0771540403366089, 1.0704439878463745, 1.0639216899871826], 'accuracy': [0.5002829432487488, 0.5198075771331787, 0.5379173755645752, 0.5215053558349609, 0.5452744960784912, 0.5512167811393738, 0.5611205697059631, 0.5764006972312927, 0.5478211641311646, 0.5554612278938293, 0.5764006972312927, 0.5633842945098877, 0.5783814191818237, 0.587436318397522, 0.5698924660682678, 0.5812110900878906, 0.5885682106018066, 0.5868703722953796, 0.5701754093170166, 0.5868703722953796, 0.5868703722953796, 0.5662139058113098, 0.5749858617782593, 0.5554612278938293, 0.5891340970993042, 0.5851725935935974, 0.5894170999526978, 0.5871533751487732, 0.5976231098175049, 0.5899830460548401, 0.5956423282623291, 0.5916808247566223, 0.5908319354057312, 0.5933786034584045, 0.5913978219032288, 0.5942274928092957, 0.5967742204666138, 0.5684776306152344, 0.5851725935935974, 0.5933786034584045, 0.5933786034584045, 0.5913978219032288, 0.5998868346214294, 0.598471999168396, 0.5981889963150024, 0.6015846133232117, 0.5964912176132202, 0.5998868346214294, 0.5840407609939575, 0.6029994487762451, 0.5894170999526978, 0.5987549424171448, 0.5939445495605469, 0.6063950061798096, 0.6024335026741028, 0.5922467708587646, 0.6058290600776672, 0.5981889963150024, 0.5973401069641113, 0.6049801707267761, 0.600452721118927, 0.6046972274780273, 0.604131281375885, 0.6015846133232117, 0.6007357239723206, 0.6029994487762451, 0.6117713451385498, 0.6092246770858765, 0.6052631735801697, 0.6089417338371277, 0.602150559425354, 0.6095076203346252, 0.604131281375885, 0.598471999168396, 0.6100735664367676, 0.6095076203346252, 0.6120543479919434, 0.607809841632843, 0.6109224557876587, 0.6013016700744629, 0.6052631735801697, 0.6049801707267761, 0.6058290600776672, 0.6066780090332031, 0.6027164459228516, 0.6103565096855164, 0.6134691834449768, 0.6058290600776672, 0.6168647408485413, 0.6126202344894409, 0.6063950061798096, 0.6179966330528259, 0.6168647408485413, 0.6120543479919434, 0.615166962146759, 0.6131861805915833, 0.6126202344894409, 0.598471999168396, 0.6120543479919434, 0.6202603578567505], 'val_loss': [2.0036120414733887, 1.9841581583023071, 1.9650145769119263, 1.94624662399292, 1.9278517961502075, 1.9095649719238281, 1.8916678428649902, 1.8740925788879395, 1.8568037748336792, 1.8396482467651367, 1.822926640510559, 1.8063877820968628, 1.7901875972747803, 1.7738945484161377, 1.7604167461395264, 1.742261528968811, 1.728551983833313, 1.715382695198059, 1.6991612911224365, 1.6828097105026245, 1.6757891178131104, 1.6562367677688599, 1.6482466459274292, 1.626994013786316, 1.6131036281585693, 1.600416898727417, 1.5871442556381226, 1.575853705406189, 1.567942500114441, 1.5537762641906738, 1.543750524520874, 1.5280877351760864, 1.5256516933441162, 1.5061413049697876, 1.495846152305603, 1.487789273262024, 1.4825284481048584, 1.4687122106552124, 1.455997347831726, 1.4450703859329224, 1.436553716659546, 1.4262889623641968, 1.4181619882583618, 1.4088290929794312, 1.3992087841033936, 1.3930667638778687, 1.3824471235275269, 1.374454140663147, 1.3653932809829712, 1.3569005727767944, 1.3524315357208252, 1.3435410261154175, 1.3364648818969727, 1.3252880573272705, 1.3270978927612305, 1.3105254173278809, 1.3048906326293945, 1.3046029806137085, 1.2906233072280884, 1.282092809677124, 1.277123212814331, 1.268418788909912, 1.2619167566299438, 1.2587494850158691, 1.2494601011276245, 1.2461292743682861, 1.2369444370269775, 1.2309619188308716, 1.2265933752059937, 1.2190418243408203, 1.213245153427124, 1.2083513736724854, 1.202532172203064, 1.1972334384918213, 1.1911641359329224, 1.1898845434188843, 1.1808347702026367, 1.1762768030166626, 1.1753815412521362, 1.167673945426941, 1.1641247272491455, 1.1573845148086548, 1.154740333557129, 1.1510292291641235, 1.145174503326416, 1.138382077217102, 1.14690363407135, 1.1322637796401978, 1.1261701583862305, 1.1303977966308594, 1.120931625366211, 1.118577241897583, 1.1102296113967896, 1.10626220703125, 1.103037714958191, 1.0983874797821045, 1.0941017866134644, 1.0925782918930054, 1.0883599519729614, 1.084993839263916], 'val_accuracy': [0.5067873597145081, 0.5475113391876221, 0.5022624731063843, 0.5045248866081238, 0.5203620195388794, 0.5373303294181824, 0.5599547624588013, 0.5690045356750488, 0.5622171759605408, 0.5520362257957458, 0.5667420625686646, 0.5565611124038696, 0.5418552160263062, 0.587104082107544, 0.5079185366630554, 0.5825791954994202, 0.5135746598243713, 0.5101810097694397, 0.516968309879303, 0.5520362257957458, 0.5067873597145081, 0.5441176295280457, 0.5135746598243713, 0.5961538553237915, 0.5712669491767883, 0.5712669491767883, 0.5825791954994202, 0.5848416090011597, 0.5599547624588013, 0.570135772228241, 0.5554298758506775, 0.5904977321624756, 0.5463801026344299, 0.5893664956092834, 0.5848416090011597, 0.5735294222831726, 0.5610859990119934, 0.5656108856201172, 0.5916289687156677, 0.5904977321624756, 0.5757918357849121, 0.5848416090011597, 0.5780543088912964, 0.5961538553237915, 0.5837104320526123, 0.5780543088912964, 0.5859728455543518, 0.5803167223930359, 0.5825791954994202, 0.6006787419319153, 0.5712669491767883, 0.5859728455543518, 0.5757918357849121, 0.5904977321624756, 0.5656108856201172, 0.5859728455543518, 0.5859728455543518, 0.5565611124038696, 0.5848416090011597, 0.5904977321624756, 0.5825791954994202, 0.5893664956092834, 0.5916289687156677, 0.5882353186607361, 0.5916289687156677, 0.5690045356750488, 0.5927602052688599, 0.5893664956092834, 0.5950226187705994, 0.5950226187705994, 0.5961538553237915, 0.5882353186607361, 0.5927602052688599, 0.5972850918769836, 0.5950226187705994, 0.5893664956092834, 0.5950226187705994, 0.5927602052688599, 0.587104082107544, 0.5859728455543518, 0.5678732991218567, 0.5938913822174072, 0.5893664956092834, 0.5916289687156677, 0.5746606588363647, 0.5972850918769836, 0.5475113391876221, 0.587104082107544, 0.5961538553237915, 0.5757918357849121, 0.5723981857299805, 0.5848416090011597, 0.598416268825531, 0.5904977321624756, 0.5848416090011597, 0.5938913822174072, 0.5995475053787231, 0.5837104320526123, 0.5927602052688599, 0.5882353186607361]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 2.0131 - accuracy: 0.5153"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 6s 36ms/step - loss: 2.0125 - accuracy: 0.5147 - val_loss: 2.0015 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.9913 - accuracy: 0.4997 - val_loss: 1.9797 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.9691 - accuracy: 0.5176 - val_loss: 1.9582 - val_accuracy: 0.5155\n","Epoch 4/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.9475 - accuracy: 0.5080 - val_loss: 1.9376 - val_accuracy: 0.4835\n","Epoch 5/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.9261 - accuracy: 0.5220 - val_loss: 1.9173 - val_accuracy: 0.4804\n","Epoch 6/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.9058 - accuracy: 0.5266 - val_loss: 1.8971 - val_accuracy: 0.5506\n","Epoch 7/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.8865 - accuracy: 0.5196 - val_loss: 1.8773 - val_accuracy: 0.5145\n","Epoch 8/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.8657 - accuracy: 0.5243 - val_loss: 1.8583 - val_accuracy: 0.5702\n","Epoch 9/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.8476 - accuracy: 0.5178 - val_loss: 1.8393 - val_accuracy: 0.5300\n","Epoch 10/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.8263 - accuracy: 0.5561 - val_loss: 1.8216 - val_accuracy: 0.4866\n","Epoch 11/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.8095 - accuracy: 0.5235 - val_loss: 1.8036 - val_accuracy: 0.4855\n","Epoch 12/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.7904 - accuracy: 0.5375 - val_loss: 1.7859 - val_accuracy: 0.4866\n","Epoch 13/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.7726 - accuracy: 0.5362 - val_loss: 1.7666 - val_accuracy: 0.5444\n","Epoch 14/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.7552 - accuracy: 0.5519 - val_loss: 1.7492 - val_accuracy: 0.5837\n","Epoch 15/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.7366 - accuracy: 0.5447 - val_loss: 1.7317 - val_accuracy: 0.5919\n","Epoch 16/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.7236 - accuracy: 0.5282 - val_loss: 1.7166 - val_accuracy: 0.5486\n","Epoch 17/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.7045 - accuracy: 0.5664 - val_loss: 1.6986 - val_accuracy: 0.5764\n","Epoch 18/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.6885 - accuracy: 0.5602 - val_loss: 1.6837 - val_accuracy: 0.5196\n","Epoch 19/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.6730 - accuracy: 0.5512 - val_loss: 1.6663 - val_accuracy: 0.5919\n","Epoch 20/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.6562 - accuracy: 0.5618 - val_loss: 1.6499 - val_accuracy: 0.5878\n","Epoch 21/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.6418 - accuracy: 0.5625 - val_loss: 1.6353 - val_accuracy: 0.5692\n","Epoch 22/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.6259 - accuracy: 0.5623 - val_loss: 1.6188 - val_accuracy: 0.5868\n","Epoch 23/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.6124 - accuracy: 0.5473 - val_loss: 1.6040 - val_accuracy: 0.5806\n","Epoch 24/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5978 - accuracy: 0.5561 - val_loss: 1.5921 - val_accuracy: 0.5341\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5860 - accuracy: 0.5501 - val_loss: 1.5770 - val_accuracy: 0.5527\n","Epoch 26/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.5689 - accuracy: 0.5661 - val_loss: 1.5632 - val_accuracy: 0.5465\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5574 - accuracy: 0.5584 - val_loss: 1.5474 - val_accuracy: 0.5754\n","Epoch 28/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.5420 - accuracy: 0.5638 - val_loss: 1.5336 - val_accuracy: 0.5878\n","Epoch 29/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.5297 - accuracy: 0.5506 - val_loss: 1.5263 - val_accuracy: 0.5289\n","Epoch 30/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.5169 - accuracy: 0.5638 - val_loss: 1.5077 - val_accuracy: 0.5888\n","Epoch 31/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5036 - accuracy: 0.5659 - val_loss: 1.4953 - val_accuracy: 0.5888\n","Epoch 32/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4935 - accuracy: 0.5605 - val_loss: 1.4853 - val_accuracy: 0.5837\n","Epoch 33/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.4804 - accuracy: 0.5705 - val_loss: 1.4718 - val_accuracy: 0.5878\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.4675 - accuracy: 0.5716 - val_loss: 1.4612 - val_accuracy: 0.5826\n","Epoch 35/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.4573 - accuracy: 0.5649 - val_loss: 1.4508 - val_accuracy: 0.5671\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.4502 - accuracy: 0.5483 - val_loss: 1.4407 - val_accuracy: 0.5816\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.4363 - accuracy: 0.5643 - val_loss: 1.4414 - val_accuracy: 0.5145\n","Epoch 38/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4252 - accuracy: 0.5643 - val_loss: 1.4162 - val_accuracy: 0.5847\n","Epoch 39/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.4132 - accuracy: 0.5700 - val_loss: 1.4113 - val_accuracy: 0.5444\n","Epoch 40/100\n","31/31 [==============================] - 1s 41ms/step - loss: 1.4020 - accuracy: 0.5716 - val_loss: 1.3950 - val_accuracy: 0.5930\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3904 - accuracy: 0.5791 - val_loss: 1.3994 - val_accuracy: 0.5186\n","Epoch 42/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3813 - accuracy: 0.5731 - val_loss: 1.3745 - val_accuracy: 0.5868\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3710 - accuracy: 0.5716 - val_loss: 1.3659 - val_accuracy: 0.5857\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3626 - accuracy: 0.5685 - val_loss: 1.3607 - val_accuracy: 0.5548\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3524 - accuracy: 0.5690 - val_loss: 1.3467 - val_accuracy: 0.5919\n","Epoch 46/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3433 - accuracy: 0.5726 - val_loss: 1.3402 - val_accuracy: 0.5692\n","Epoch 47/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3329 - accuracy: 0.5783 - val_loss: 1.3361 - val_accuracy: 0.5362\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3250 - accuracy: 0.5703 - val_loss: 1.3229 - val_accuracy: 0.5702\n","Epoch 49/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.3147 - accuracy: 0.5829 - val_loss: 1.3111 - val_accuracy: 0.5816\n","Epoch 50/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3063 - accuracy: 0.5824 - val_loss: 1.3025 - val_accuracy: 0.5837\n","Epoch 51/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2975 - accuracy: 0.5734 - val_loss: 1.2945 - val_accuracy: 0.5868\n","Epoch 52/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2892 - accuracy: 0.5806 - val_loss: 1.2863 - val_accuracy: 0.5837\n","Epoch 53/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2846 - accuracy: 0.5680 - val_loss: 1.2791 - val_accuracy: 0.5919\n","Epoch 54/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2777 - accuracy: 0.5687 - val_loss: 1.2715 - val_accuracy: 0.5930\n","Epoch 55/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2681 - accuracy: 0.5716 - val_loss: 1.2673 - val_accuracy: 0.5651\n","Epoch 56/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2577 - accuracy: 0.5840 - val_loss: 1.2550 - val_accuracy: 0.5899\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2514 - accuracy: 0.5765 - val_loss: 1.2511 - val_accuracy: 0.5826\n","Epoch 58/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2432 - accuracy: 0.5780 - val_loss: 1.2406 - val_accuracy: 0.5744\n","Epoch 59/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2351 - accuracy: 0.5848 - val_loss: 1.2359 - val_accuracy: 0.5764\n","Epoch 60/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2286 - accuracy: 0.5822 - val_loss: 1.2292 - val_accuracy: 0.5764\n","Epoch 61/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2233 - accuracy: 0.5765 - val_loss: 1.2293 - val_accuracy: 0.5475\n","Epoch 62/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2134 - accuracy: 0.5925 - val_loss: 1.2141 - val_accuracy: 0.5847\n","Epoch 63/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2060 - accuracy: 0.5884 - val_loss: 1.2094 - val_accuracy: 0.5723\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2022 - accuracy: 0.5879 - val_loss: 1.1997 - val_accuracy: 0.5816\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1956 - accuracy: 0.5796 - val_loss: 1.1938 - val_accuracy: 0.5847\n","Epoch 66/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1877 - accuracy: 0.5868 - val_loss: 1.1889 - val_accuracy: 0.5837\n","Epoch 67/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1833 - accuracy: 0.5848 - val_loss: 1.1851 - val_accuracy: 0.5764\n","Epoch 68/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1748 - accuracy: 0.5824 - val_loss: 1.1769 - val_accuracy: 0.5785\n","Epoch 69/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1673 - accuracy: 0.5899 - val_loss: 1.1707 - val_accuracy: 0.5837\n","Epoch 70/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1636 - accuracy: 0.5832 - val_loss: 1.1662 - val_accuracy: 0.5692\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1561 - accuracy: 0.5938 - val_loss: 1.1580 - val_accuracy: 0.5826\n","Epoch 72/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1533 - accuracy: 0.5866 - val_loss: 1.1612 - val_accuracy: 0.5620\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1491 - accuracy: 0.5871 - val_loss: 1.1476 - val_accuracy: 0.5868\n","Epoch 74/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1394 - accuracy: 0.5860 - val_loss: 1.1431 - val_accuracy: 0.5888\n","Epoch 75/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1340 - accuracy: 0.5912 - val_loss: 1.1375 - val_accuracy: 0.5899\n","Epoch 76/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1272 - accuracy: 0.5920 - val_loss: 1.1321 - val_accuracy: 0.5888\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1249 - accuracy: 0.5928 - val_loss: 1.1366 - val_accuracy: 0.5620\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1164 - accuracy: 0.5977 - val_loss: 1.1216 - val_accuracy: 0.5806\n","Epoch 79/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1127 - accuracy: 0.5922 - val_loss: 1.1216 - val_accuracy: 0.5744\n","Epoch 80/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1072 - accuracy: 0.5920 - val_loss: 1.1121 - val_accuracy: 0.5785\n","Epoch 81/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1008 - accuracy: 0.5935 - val_loss: 1.1104 - val_accuracy: 0.5795\n","Epoch 82/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0968 - accuracy: 0.5953 - val_loss: 1.1110 - val_accuracy: 0.5620\n","Epoch 83/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0937 - accuracy: 0.5873 - val_loss: 1.0991 - val_accuracy: 0.5837\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0885 - accuracy: 0.5907 - val_loss: 1.0965 - val_accuracy: 0.5744\n","Epoch 85/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0831 - accuracy: 0.5946 - val_loss: 1.0965 - val_accuracy: 0.5713\n","Epoch 86/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0799 - accuracy: 0.5904 - val_loss: 1.0915 - val_accuracy: 0.5640\n","Epoch 87/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0744 - accuracy: 0.5938 - val_loss: 1.0868 - val_accuracy: 0.5640\n","Epoch 88/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0756 - accuracy: 0.5835 - val_loss: 1.0790 - val_accuracy: 0.5744\n","Epoch 89/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0657 - accuracy: 0.5977 - val_loss: 1.0739 - val_accuracy: 0.5888\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0607 - accuracy: 0.5938 - val_loss: 1.0740 - val_accuracy: 0.5713\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0570 - accuracy: 0.6008 - val_loss: 1.0678 - val_accuracy: 0.5785\n","Epoch 92/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0517 - accuracy: 0.6072 - val_loss: 1.0635 - val_accuracy: 0.5857\n","Epoch 93/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0478 - accuracy: 0.6000 - val_loss: 1.0615 - val_accuracy: 0.5713\n","Epoch 94/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0453 - accuracy: 0.5858 - val_loss: 1.0560 - val_accuracy: 0.5692\n","Epoch 95/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0408 - accuracy: 0.5995 - val_loss: 1.0520 - val_accuracy: 0.5713\n","Epoch 96/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0355 - accuracy: 0.6078 - val_loss: 1.0497 - val_accuracy: 0.5878\n","Epoch 97/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0324 - accuracy: 0.6070 - val_loss: 1.0469 - val_accuracy: 0.5775\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0284 - accuracy: 0.6010 - val_loss: 1.0427 - val_accuracy: 0.5868\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0273 - accuracy: 0.6003 - val_loss: 1.0401 - val_accuracy: 0.5826\n","Epoch 100/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0234 - accuracy: 0.5984 - val_loss: 1.0355 - val_accuracy: 0.5692\n","{'loss': [2.012451648712158, 1.9912936687469482, 1.9690958261489868, 1.9475433826446533, 1.9261140823364258, 1.905834436416626, 1.8864811658859253, 1.8656847476959229, 1.8476426601409912, 1.826282262802124, 1.8095414638519287, 1.7903987169265747, 1.7726303339004517, 1.7551672458648682, 1.7366065979003906, 1.7236124277114868, 1.7044767141342163, 1.6884925365447998, 1.6729992628097534, 1.656174659729004, 1.641757607460022, 1.6258625984191895, 1.6123876571655273, 1.597844123840332, 1.5860058069229126, 1.5689055919647217, 1.5573879480361938, 1.5420048236846924, 1.529740333557129, 1.5169200897216797, 1.5036259889602661, 1.493518590927124, 1.4803980588912964, 1.4675426483154297, 1.4572813510894775, 1.45023512840271, 1.4362597465515137, 1.4251588582992554, 1.4131920337677002, 1.4019695520401, 1.3904221057891846, 1.3812743425369263, 1.370965838432312, 1.3626255989074707, 1.3523931503295898, 1.3433012962341309, 1.3329063653945923, 1.3250433206558228, 1.3146966695785522, 1.3062524795532227, 1.2975499629974365, 1.2892181873321533, 1.2846336364746094, 1.2776830196380615, 1.268123745918274, 1.2577171325683594, 1.2514142990112305, 1.243190884590149, 1.235113501548767, 1.2285701036453247, 1.2233036756515503, 1.2133816480636597, 1.2060410976409912, 1.2022072076797485, 1.1955591440200806, 1.1877491474151611, 1.183250904083252, 1.174842119216919, 1.1673203706741333, 1.1635816097259521, 1.1561272144317627, 1.153285026550293, 1.1490907669067383, 1.1394026279449463, 1.1339718103408813, 1.12723970413208, 1.1249152421951294, 1.116359829902649, 1.1127482652664185, 1.107205867767334, 1.1007874011993408, 1.0968201160430908, 1.0937086343765259, 1.0885056257247925, 1.0830901861190796, 1.0798527002334595, 1.074446439743042, 1.0755629539489746, 1.065740942955017, 1.0607484579086304, 1.0569645166397095, 1.0516607761383057, 1.0477733612060547, 1.0453040599822998, 1.0408408641815186, 1.0355077981948853, 1.0324339866638184, 1.0284373760223389, 1.0272953510284424, 1.0233780145645142], 'accuracy': [0.5147286653518677, 0.4997416138648987, 0.5175710320472717, 0.5080103278160095, 0.5219638347625732, 0.5266149640083313, 0.5196382403373718, 0.5242894291877747, 0.5178294777870178, 0.5560723543167114, 0.5235142111778259, 0.5374677181243896, 0.5361757278442383, 0.551937997341156, 0.5447028279304504, 0.5281654000282288, 0.5664082765579224, 0.5602067112922668, 0.5511627793312073, 0.5617570877075195, 0.5625323057174683, 0.5622739195823669, 0.5472868084907532, 0.5560723543167114, 0.5501291751861572, 0.566149890422821, 0.5583979487419128, 0.5638242959976196, 0.5506460070610046, 0.5638242959976196, 0.565891444683075, 0.5604650974273682, 0.5705426335334778, 0.5715762376785278, 0.5648579001426697, 0.5483204126358032, 0.5643410682678223, 0.5643410682678223, 0.5700258612632751, 0.5715762376785278, 0.5790697932243347, 0.5731266140937805, 0.5715762376785278, 0.5684754252433777, 0.5689922571182251, 0.5726098418235779, 0.578294575214386, 0.5702842473983765, 0.5829457640647888, 0.5824289321899414, 0.5733850002288818, 0.5806201696395874, 0.567958652973175, 0.5687338709831238, 0.5715762376785278, 0.5839793086051941, 0.576485812664032, 0.5780361890792847, 0.5847545266151428, 0.5821705460548401, 0.576485812664032, 0.592506468296051, 0.5883721113204956, 0.5878552794456482, 0.5795865654945374, 0.5868217349052429, 0.5847545266151428, 0.5824289321899414, 0.5899224877357483, 0.5832041501998901, 0.5937984585762024, 0.5865632891654968, 0.5870801210403442, 0.5860465168952942, 0.5912144780158997, 0.5919896364212036, 0.5927648544311523, 0.5976744294166565, 0.5922480821609497, 0.5919896364212036, 0.5935400724411011, 0.5953488349914551, 0.5873385071754456, 0.5906976461410522, 0.5945736169815063, 0.5904392600059509, 0.5937984585762024, 0.5834625363349915, 0.5976744294166565, 0.5937984585762024, 0.6007751822471619, 0.6072351336479187, 0.6000000238418579, 0.5857881307601929, 0.5994831919670105, 0.6077519655227661, 0.6069767475128174, 0.6010335683822632, 0.6002584099769592, 0.5984495878219604], 'val_loss': [2.0014994144439697, 1.9797048568725586, 1.958185076713562, 1.937577247619629, 1.9172645807266235, 1.8970932960510254, 1.877333641052246, 1.8582653999328613, 1.839264154434204, 1.8215761184692383, 1.8035866022109985, 1.7859305143356323, 1.7666391134262085, 1.7491519451141357, 1.7316691875457764, 1.7166019678115845, 1.6985727548599243, 1.6837373971939087, 1.6663422584533691, 1.6499465703964233, 1.6353484392166138, 1.6188465356826782, 1.6040046215057373, 1.5921204090118408, 1.5769542455673218, 1.5631842613220215, 1.5474328994750977, 1.5336062908172607, 1.526301383972168, 1.5077265501022339, 1.4952549934387207, 1.4852759838104248, 1.4718499183654785, 1.4611793756484985, 1.4507876634597778, 1.4407151937484741, 1.4414243698120117, 1.4162131547927856, 1.411270260810852, 1.3950116634368896, 1.3994466066360474, 1.3744956254959106, 1.365880012512207, 1.3607228994369507, 1.346666932106018, 1.3401786088943481, 1.3360626697540283, 1.322920322418213, 1.3110684156417847, 1.3025037050247192, 1.2945111989974976, 1.2863467931747437, 1.2791337966918945, 1.271540880203247, 1.2672947645187378, 1.2550442218780518, 1.251110315322876, 1.2406421899795532, 1.2358624935150146, 1.2292189598083496, 1.2293227910995483, 1.2140908241271973, 1.2094058990478516, 1.1997499465942383, 1.1937947273254395, 1.1888647079467773, 1.185068964958191, 1.1768742799758911, 1.170682668685913, 1.1661529541015625, 1.1579748392105103, 1.161242127418518, 1.1476444005966187, 1.143066167831421, 1.137508749961853, 1.1320977210998535, 1.1366186141967773, 1.1216106414794922, 1.1216068267822266, 1.1121227741241455, 1.110430359840393, 1.1109813451766968, 1.0990729331970215, 1.0965301990509033, 1.096498966217041, 1.0914961099624634, 1.086822509765625, 1.0789638757705688, 1.0738791227340698, 1.0739957094192505, 1.0677508115768433, 1.063485026359558, 1.061488151550293, 1.0559587478637695, 1.05197274684906, 1.0496567487716675, 1.0469086170196533, 1.0426959991455078, 1.04007089138031, 1.0354667901992798], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.5154958963394165, 0.4834710657596588, 0.48037189245224, 0.5506198406219482, 0.5144628286361694, 0.5702479481697083, 0.5299586653709412, 0.48657023906707764, 0.48553720116615295, 0.48657023906707764, 0.5444214940071106, 0.5836777091026306, 0.5919421315193176, 0.5485537052154541, 0.5764462947845459, 0.51962810754776, 0.5919421315193176, 0.5878099203109741, 0.5692148804664612, 0.586776852607727, 0.5805785059928894, 0.5340909361839294, 0.5526859760284424, 0.5464876294136047, 0.5754132270812988, 0.5878099203109741, 0.5289255976676941, 0.5888429880142212, 0.5888429880142212, 0.5836777091026306, 0.5878099203109741, 0.5826446413993835, 0.567148745059967, 0.5816115736961365, 0.5144628286361694, 0.5847107172012329, 0.5444214940071106, 0.5929751992225647, 0.5185950398445129, 0.586776852607727, 0.58574378490448, 0.5547520518302917, 0.5919421315193176, 0.5692148804664612, 0.5361570119857788, 0.5702479481697083, 0.5816115736961365, 0.5836777091026306, 0.586776852607727, 0.5836777091026306, 0.5919421315193176, 0.5929751992225647, 0.5650826692581177, 0.5898760557174683, 0.5826446413993835, 0.5743801593780518, 0.5764462947845459, 0.5764462947845459, 0.547520637512207, 0.5847107172012329, 0.5723140239715576, 0.5816115736961365, 0.5847107172012329, 0.5836777091026306, 0.5764462947845459, 0.5785123705863953, 0.5836777091026306, 0.5692148804664612, 0.5826446413993835, 0.5619834661483765, 0.586776852607727, 0.5888429880142212, 0.5898760557174683, 0.5888429880142212, 0.5619834661483765, 0.5805785059928894, 0.5743801593780518, 0.5785123705863953, 0.5795454382896423, 0.5619834661483765, 0.5836777091026306, 0.5743801593780518, 0.5712810158729553, 0.5640496015548706, 0.5640496015548706, 0.5743801593780518, 0.5888429880142212, 0.5712810158729553, 0.5785123705863953, 0.58574378490448, 0.5712810158729553, 0.5692148804664612, 0.5712810158729553, 0.5878099203109741, 0.577479362487793, 0.586776852607727, 0.5826446413993835, 0.5692148804664612]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 1.0592 - accuracy: 0.5784"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 4s 35ms/step - loss: 1.0586 - accuracy: 0.5803 - val_loss: 1.0772 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0487 - accuracy: 0.5946 - val_loss: 1.0720 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.0423 - accuracy: 0.5978 - val_loss: 1.0679 - val_accuracy: 0.4860\n","Epoch 4/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0352 - accuracy: 0.6032 - val_loss: 1.0635 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0307 - accuracy: 0.6040 - val_loss: 1.0599 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0262 - accuracy: 0.6040 - val_loss: 1.0561 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0231 - accuracy: 0.6026 - val_loss: 1.0540 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0183 - accuracy: 0.6053 - val_loss: 1.0487 - val_accuracy: 0.4828\n","Epoch 9/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.0176 - accuracy: 0.5989 - val_loss: 1.0444 - val_accuracy: 0.4903\n","Epoch 10/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.0112 - accuracy: 0.6107 - val_loss: 1.0418 - val_accuracy: 0.4881\n","Epoch 11/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0097 - accuracy: 0.5999 - val_loss: 1.0397 - val_accuracy: 0.4871\n","Epoch 12/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0030 - accuracy: 0.6102 - val_loss: 1.0376 - val_accuracy: 0.4892\n","Epoch 13/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.0007 - accuracy: 0.6061 - val_loss: 1.0284 - val_accuracy: 0.5108\n","Epoch 14/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.9981 - accuracy: 0.6053 - val_loss: 1.0233 - val_accuracy: 0.5420\n","Epoch 15/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9924 - accuracy: 0.6067 - val_loss: 1.0202 - val_accuracy: 0.5377\n","Epoch 16/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.9921 - accuracy: 0.6048 - val_loss: 1.0136 - val_accuracy: 0.5668\n","Epoch 17/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9913 - accuracy: 0.6043 - val_loss: 1.0203 - val_accuracy: 0.5075\n","Epoch 18/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9847 - accuracy: 0.6123 - val_loss: 1.0084 - val_accuracy: 0.5560\n","Epoch 19/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.9808 - accuracy: 0.6118 - val_loss: 0.9995 - val_accuracy: 0.6024\n","Epoch 20/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9778 - accuracy: 0.6199 - val_loss: 0.9941 - val_accuracy: 0.5916\n","Epoch 21/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9771 - accuracy: 0.6064 - val_loss: 0.9906 - val_accuracy: 0.5959\n","Epoch 22/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9757 - accuracy: 0.6161 - val_loss: 0.9925 - val_accuracy: 0.5819\n","Epoch 23/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9725 - accuracy: 0.6059 - val_loss: 0.9837 - val_accuracy: 0.5970\n","Epoch 24/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9677 - accuracy: 0.6212 - val_loss: 0.9800 - val_accuracy: 0.5981\n","Epoch 25/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9698 - accuracy: 0.6199 - val_loss: 0.9926 - val_accuracy: 0.5647\n","Epoch 26/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9633 - accuracy: 0.6156 - val_loss: 0.9890 - val_accuracy: 0.5711\n","Epoch 27/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9653 - accuracy: 0.6110 - val_loss: 0.9927 - val_accuracy: 0.5603\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9616 - accuracy: 0.6140 - val_loss: 0.9726 - val_accuracy: 0.5884\n","Epoch 29/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9583 - accuracy: 0.6207 - val_loss: 0.9687 - val_accuracy: 0.6013\n","Epoch 30/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9543 - accuracy: 0.6183 - val_loss: 0.9685 - val_accuracy: 0.5884\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9533 - accuracy: 0.6153 - val_loss: 0.9690 - val_accuracy: 0.5851\n","Epoch 32/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9508 - accuracy: 0.6188 - val_loss: 0.9625 - val_accuracy: 0.5991\n","Epoch 33/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9472 - accuracy: 0.6223 - val_loss: 0.9625 - val_accuracy: 0.5916\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9446 - accuracy: 0.6282 - val_loss: 0.9610 - val_accuracy: 0.5884\n","Epoch 35/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9462 - accuracy: 0.6164 - val_loss: 0.9607 - val_accuracy: 0.5862\n","Epoch 36/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9418 - accuracy: 0.6202 - val_loss: 0.9617 - val_accuracy: 0.5841\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9390 - accuracy: 0.6193 - val_loss: 0.9776 - val_accuracy: 0.5560\n","Epoch 38/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9423 - accuracy: 0.6177 - val_loss: 0.9604 - val_accuracy: 0.5862\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9344 - accuracy: 0.6258 - val_loss: 0.9498 - val_accuracy: 0.5927\n","Epoch 40/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9347 - accuracy: 0.6242 - val_loss: 0.9485 - val_accuracy: 0.6024\n","Epoch 41/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9313 - accuracy: 0.6220 - val_loss: 0.9483 - val_accuracy: 0.6013\n","Epoch 42/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9311 - accuracy: 0.6228 - val_loss: 0.9468 - val_accuracy: 0.5970\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9308 - accuracy: 0.6196 - val_loss: 0.9477 - val_accuracy: 0.5948\n","Epoch 44/100\n","29/29 [==============================] - 1s 44ms/step - loss: 0.9250 - accuracy: 0.6288 - val_loss: 0.9442 - val_accuracy: 0.6045\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9261 - accuracy: 0.6231 - val_loss: 0.9447 - val_accuracy: 0.5948\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9220 - accuracy: 0.6307 - val_loss: 0.9511 - val_accuracy: 0.5765\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9212 - accuracy: 0.6293 - val_loss: 0.9430 - val_accuracy: 0.5905\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9211 - accuracy: 0.6245 - val_loss: 0.9433 - val_accuracy: 0.5894\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9170 - accuracy: 0.6317 - val_loss: 0.9642 - val_accuracy: 0.5517\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9171 - accuracy: 0.6207 - val_loss: 0.9340 - val_accuracy: 0.5991\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9133 - accuracy: 0.6317 - val_loss: 0.9347 - val_accuracy: 0.6013\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9134 - accuracy: 0.6350 - val_loss: 0.9324 - val_accuracy: 0.6002\n","Epoch 53/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9075 - accuracy: 0.6369 - val_loss: 0.9398 - val_accuracy: 0.5776\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9073 - accuracy: 0.6307 - val_loss: 0.9293 - val_accuracy: 0.6002\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9056 - accuracy: 0.6369 - val_loss: 0.9286 - val_accuracy: 0.5991\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9040 - accuracy: 0.6363 - val_loss: 0.9418 - val_accuracy: 0.5754\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9010 - accuracy: 0.6323 - val_loss: 0.9304 - val_accuracy: 0.5894\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8993 - accuracy: 0.6350 - val_loss: 0.9262 - val_accuracy: 0.5981\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9005 - accuracy: 0.6298 - val_loss: 0.9240 - val_accuracy: 0.5991\n","Epoch 60/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8966 - accuracy: 0.6414 - val_loss: 0.9323 - val_accuracy: 0.5787\n","Epoch 61/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8966 - accuracy: 0.6371 - val_loss: 0.9226 - val_accuracy: 0.5959\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8942 - accuracy: 0.6393 - val_loss: 0.9293 - val_accuracy: 0.5830\n","Epoch 63/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8953 - accuracy: 0.6377 - val_loss: 0.9206 - val_accuracy: 0.5970\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8932 - accuracy: 0.6339 - val_loss: 0.9179 - val_accuracy: 0.5991\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8902 - accuracy: 0.6377 - val_loss: 0.9194 - val_accuracy: 0.5981\n","Epoch 66/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8857 - accuracy: 0.6449 - val_loss: 0.9174 - val_accuracy: 0.5981\n","Epoch 67/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8862 - accuracy: 0.6447 - val_loss: 0.9132 - val_accuracy: 0.5970\n","Epoch 68/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8835 - accuracy: 0.6463 - val_loss: 0.9130 - val_accuracy: 0.5938\n","Epoch 69/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8809 - accuracy: 0.6466 - val_loss: 0.9122 - val_accuracy: 0.5948\n","Epoch 70/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8793 - accuracy: 0.6490 - val_loss: 0.9130 - val_accuracy: 0.5948\n","Epoch 71/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8820 - accuracy: 0.6352 - val_loss: 0.9322 - val_accuracy: 0.5657\n","Epoch 72/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8786 - accuracy: 0.6401 - val_loss: 0.9296 - val_accuracy: 0.5614\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8783 - accuracy: 0.6428 - val_loss: 0.9099 - val_accuracy: 0.5970\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8732 - accuracy: 0.6519 - val_loss: 0.9104 - val_accuracy: 0.5991\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8709 - accuracy: 0.6463 - val_loss: 0.9264 - val_accuracy: 0.5528\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8694 - accuracy: 0.6519 - val_loss: 0.9055 - val_accuracy: 0.5948\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8678 - accuracy: 0.6492 - val_loss: 0.9075 - val_accuracy: 0.5830\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8639 - accuracy: 0.6565 - val_loss: 0.9105 - val_accuracy: 0.5787\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8616 - accuracy: 0.6614 - val_loss: 0.9063 - val_accuracy: 0.5862\n","Epoch 80/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8609 - accuracy: 0.6587 - val_loss: 0.9041 - val_accuracy: 0.5959\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8607 - accuracy: 0.6624 - val_loss: 0.9019 - val_accuracy: 0.5991\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8598 - accuracy: 0.6598 - val_loss: 0.9105 - val_accuracy: 0.5754\n","Epoch 83/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8582 - accuracy: 0.6554 - val_loss: 0.9247 - val_accuracy: 0.5582\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8578 - accuracy: 0.6616 - val_loss: 0.9003 - val_accuracy: 0.5927\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8519 - accuracy: 0.6697 - val_loss: 0.9129 - val_accuracy: 0.5647\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8512 - accuracy: 0.6598 - val_loss: 0.9028 - val_accuracy: 0.5797\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8513 - accuracy: 0.6614 - val_loss: 0.8982 - val_accuracy: 0.5916\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8512 - accuracy: 0.6530 - val_loss: 0.9193 - val_accuracy: 0.5517\n","Epoch 89/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8496 - accuracy: 0.6638 - val_loss: 0.8956 - val_accuracy: 0.5916\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8426 - accuracy: 0.6692 - val_loss: 0.8949 - val_accuracy: 0.6002\n","Epoch 91/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8443 - accuracy: 0.6649 - val_loss: 0.8976 - val_accuracy: 0.5905\n","Epoch 92/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8414 - accuracy: 0.6724 - val_loss: 0.8935 - val_accuracy: 0.5927\n","Epoch 93/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8420 - accuracy: 0.6678 - val_loss: 0.8989 - val_accuracy: 0.5916\n","Epoch 94/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8458 - accuracy: 0.6576 - val_loss: 0.8910 - val_accuracy: 0.6002\n","Epoch 95/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8341 - accuracy: 0.6716 - val_loss: 0.8951 - val_accuracy: 0.5894\n","Epoch 96/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8315 - accuracy: 0.6754 - val_loss: 0.8920 - val_accuracy: 0.5991\n","Epoch 97/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8325 - accuracy: 0.6678 - val_loss: 0.8938 - val_accuracy: 0.5841\n","Epoch 98/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8284 - accuracy: 0.6797 - val_loss: 0.8939 - val_accuracy: 0.5927\n","Epoch 99/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8326 - accuracy: 0.6767 - val_loss: 0.9063 - val_accuracy: 0.5991\n","Epoch 100/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8295 - accuracy: 0.6646 - val_loss: 0.8910 - val_accuracy: 0.5905\n","{'loss': [1.058641791343689, 1.0487278699874878, 1.0422909259796143, 1.0351916551589966, 1.0307046175003052, 1.0262491703033447, 1.0230576992034912, 1.018291711807251, 1.0175623893737793, 1.011247992515564, 1.0097248554229736, 1.00297212600708, 1.0006937980651855, 0.9981021285057068, 0.9923816323280334, 0.9920556545257568, 0.9912680983543396, 0.9846723675727844, 0.9808393716812134, 0.9778144955635071, 0.9770589470863342, 0.9756554365158081, 0.9725332856178284, 0.9677494764328003, 0.9697895646095276, 0.9632941484451294, 0.9652754664421082, 0.9616098999977112, 0.9582610130310059, 0.9543175101280212, 0.9533424377441406, 0.9508363008499146, 0.9471684694290161, 0.9445838928222656, 0.9462423920631409, 0.9417972564697266, 0.9390231966972351, 0.942322313785553, 0.9343788027763367, 0.9346972107887268, 0.9313404560089111, 0.9310558438301086, 0.9308117032051086, 0.9249904155731201, 0.9260938167572021, 0.9220148324966431, 0.921241283416748, 0.9211151003837585, 0.916954517364502, 0.9170600175857544, 0.9133079648017883, 0.9133579730987549, 0.9074863791465759, 0.9072593450546265, 0.9056341052055359, 0.9040285348892212, 0.9009873867034912, 0.8992733359336853, 0.9004584550857544, 0.896640419960022, 0.8966206312179565, 0.8941890001296997, 0.8953219056129456, 0.8932042121887207, 0.8902401924133301, 0.885740339756012, 0.8861972689628601, 0.8834754824638367, 0.8809148669242859, 0.8792687058448792, 0.8819557428359985, 0.8786255121231079, 0.8782842755317688, 0.8731518983840942, 0.8708767890930176, 0.8693795800209045, 0.8677971959114075, 0.8639419674873352, 0.8615618944168091, 0.8609358072280884, 0.8606827259063721, 0.8598287105560303, 0.8581720590591431, 0.8578258156776428, 0.8518505096435547, 0.8512441515922546, 0.8512942790985107, 0.8511719107627869, 0.8495749831199646, 0.8425704836845398, 0.8443041443824768, 0.8414306640625, 0.841976523399353, 0.8458247780799866, 0.8340747356414795, 0.8314800262451172, 0.8325367569923401, 0.8283963799476624, 0.8325539231300354, 0.8294664025306702], 'accuracy': [0.5802801847457886, 0.5945581793785095, 0.5977909564971924, 0.603178858757019, 0.6039870977401733, 0.6039870977401733, 0.6026400923728943, 0.6053340435028076, 0.5988685488700867, 0.610722005367279, 0.599946141242981, 0.6101831793785095, 0.6061422228813171, 0.6053340435028076, 0.6066810488700867, 0.6047952771186829, 0.6042564511299133, 0.6123383641242981, 0.6117995977401733, 0.6198814511299133, 0.6064116358757019, 0.6161099076271057, 0.6058728694915771, 0.6212284564971924, 0.6198814511299133, 0.615571141242981, 0.610991358757019, 0.6139547228813171, 0.6206896305084229, 0.6182650923728943, 0.6153017282485962, 0.618803858757019, 0.6223060488700867, 0.6282327771186829, 0.6163793206214905, 0.6201508641242981, 0.6193426847457886, 0.6177262663841248, 0.6258081793785095, 0.6241918206214905, 0.6220366358757019, 0.6228448152542114, 0.6196120977401733, 0.6287715435028076, 0.6231142282485962, 0.6306573152542114, 0.6293103694915771, 0.6244612336158752, 0.6317349076271057, 0.6206896305084229, 0.6317349076271057, 0.6349676847457886, 0.6368534564971924, 0.6306573152542114, 0.6368534564971924, 0.6363146305084229, 0.6322737336158752, 0.6349676847457886, 0.6298491358757019, 0.6414331793785095, 0.6371228694915771, 0.639277994632721, 0.6376616358757019, 0.6338900923728943, 0.6376616358757019, 0.6449353694915771, 0.6446659564971924, 0.6462823152542114, 0.6465517282485962, 0.6489762663841248, 0.6352370977401733, 0.6400862336158752, 0.6427801847457886, 0.6519396305084229, 0.6462823152542114, 0.6519396305084229, 0.6492456793785095, 0.6565194129943848, 0.6613685488700867, 0.6586745977401733, 0.662446141242981, 0.6597521305084229, 0.6554418206214905, 0.6616379022598267, 0.6697198152542114, 0.6597521305084229, 0.6613685488700867, 0.6530172228813171, 0.6637930870056152, 0.6691810488700867, 0.6648706793785095, 0.6724137663841248, 0.6678340435028076, 0.657597005367279, 0.6716055870056152, 0.6753771305084229, 0.6678340435028076, 0.6796875, 0.6767241358757019, 0.6646012663841248], 'val_loss': [1.0771616697311401, 1.0719789266586304, 1.0679227113723755, 1.063537836074829, 1.0598845481872559, 1.0560575723648071, 1.0540342330932617, 1.048742413520813, 1.0444096326828003, 1.041764259338379, 1.039741039276123, 1.0376005172729492, 1.0283870697021484, 1.0232857465744019, 1.0202080011367798, 1.0136393308639526, 1.0203359127044678, 1.0083673000335693, 0.9994589686393738, 0.9940896034240723, 0.9906450510025024, 0.9925220012664795, 0.9836585521697998, 0.9799994230270386, 0.9925863146781921, 0.9889941215515137, 0.9926599860191345, 0.9725530743598938, 0.968748927116394, 0.9685074090957642, 0.9690219163894653, 0.9625468850135803, 0.9625324010848999, 0.9609946012496948, 0.9607238173484802, 0.961713433265686, 0.9776417016983032, 0.9604083895683289, 0.9497588872909546, 0.9484550952911377, 0.9482805728912354, 0.946790874004364, 0.9476805925369263, 0.944193959236145, 0.9447377324104309, 0.9511297941207886, 0.9430148005485535, 0.94334477186203, 0.9641619324684143, 0.9339738488197327, 0.9347360730171204, 0.9323799014091492, 0.9398254156112671, 0.929347574710846, 0.9285846948623657, 0.9417629837989807, 0.9303783774375916, 0.9262029528617859, 0.9240374565124512, 0.9323235750198364, 0.9226300716400146, 0.9293333888053894, 0.9205864667892456, 0.917876124382019, 0.9193896651268005, 0.9173911809921265, 0.9132422804832458, 0.9130210876464844, 0.9121938943862915, 0.9130208492279053, 0.9321672320365906, 0.9295931458473206, 0.9099138975143433, 0.9103883504867554, 0.9264287352561951, 0.9054870009422302, 0.9074817299842834, 0.9104961156845093, 0.9063320159912109, 0.9041141867637634, 0.9018784761428833, 0.9105097651481628, 0.924710214138031, 0.900313138961792, 0.9129461646080017, 0.9027895927429199, 0.8982442617416382, 0.919317901134491, 0.8956316709518433, 0.8949313163757324, 0.8975893259048462, 0.8935360312461853, 0.8988547921180725, 0.8910496234893799, 0.895058274269104, 0.8919994235038757, 0.8938248157501221, 0.8938567042350769, 0.9062589406967163, 0.8910307288169861], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48275861144065857, 0.4903017282485962, 0.4881465435028076, 0.48706895112991333, 0.4892241358757019, 0.5107758641242981, 0.5420258641242981, 0.537715494632721, 0.5668103694915771, 0.5075430870056152, 0.556034505367279, 0.6023706793785095, 0.5915948152542114, 0.5959051847457886, 0.5818965435028076, 0.5969827771186829, 0.5980603694915771, 0.5646551847457886, 0.5711206793785095, 0.5603448152542114, 0.5883620977401733, 0.6012930870056152, 0.5883620977401733, 0.5851293206214905, 0.5991379022598267, 0.5915948152542114, 0.5883620977401733, 0.5862069129943848, 0.5840517282485962, 0.556034505367279, 0.5862069129943848, 0.5926724076271057, 0.6023706793785095, 0.6012930870056152, 0.5969827771186829, 0.5948275923728943, 0.6045258641242981, 0.5948275923728943, 0.576508641242981, 0.5905172228813171, 0.5894396305084229, 0.5517241358757019, 0.5991379022598267, 0.6012930870056152, 0.600215494632721, 0.5775862336158752, 0.600215494632721, 0.5991379022598267, 0.5754310488700867, 0.5894396305084229, 0.5980603694915771, 0.5991379022598267, 0.5786637663841248, 0.5959051847457886, 0.5829741358757019, 0.5969827771186829, 0.5991379022598267, 0.5980603694915771, 0.5980603694915771, 0.5969827771186829, 0.59375, 0.5948275923728943, 0.5948275923728943, 0.5657327771186829, 0.5614224076271057, 0.5969827771186829, 0.5991379022598267, 0.5528017282485962, 0.5948275923728943, 0.5829741358757019, 0.5786637663841248, 0.5862069129943848, 0.5959051847457886, 0.5991379022598267, 0.5754310488700867, 0.5581896305084229, 0.5926724076271057, 0.5646551847457886, 0.579741358757019, 0.5915948152542114, 0.5517241358757019, 0.5915948152542114, 0.600215494632721, 0.5905172228813171, 0.5926724076271057, 0.5915948152542114, 0.600215494632721, 0.5894396305084229, 0.5991379022598267, 0.5840517282485962, 0.5926724076271057, 0.5991379022598267, 0.5905172228813171]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 1.0555 - accuracy: 0.5971"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 5s 41ms/step - loss: 1.0553 - accuracy: 0.5979 - val_loss: 1.0771 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0479 - accuracy: 0.5948 - val_loss: 1.0721 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0422 - accuracy: 0.6095 - val_loss: 1.0683 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0371 - accuracy: 0.5996 - val_loss: 1.0643 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0323 - accuracy: 0.6050 - val_loss: 1.0603 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0301 - accuracy: 0.6002 - val_loss: 1.0566 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.0238 - accuracy: 0.6078 - val_loss: 1.0532 - val_accuracy: 0.4966\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0197 - accuracy: 0.6084 - val_loss: 1.0505 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.0165 - accuracy: 0.6087 - val_loss: 1.0452 - val_accuracy: 0.4977\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0132 - accuracy: 0.6007 - val_loss: 1.0438 - val_accuracy: 0.4966\n","Epoch 11/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0087 - accuracy: 0.6112 - val_loss: 1.0396 - val_accuracy: 0.4977\n","Epoch 12/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.0069 - accuracy: 0.6041 - val_loss: 1.0360 - val_accuracy: 0.5000\n","Epoch 13/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0018 - accuracy: 0.6089 - val_loss: 1.0355 - val_accuracy: 0.4977\n","Epoch 14/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0059 - accuracy: 0.5968 - val_loss: 1.0370 - val_accuracy: 0.4966\n","Epoch 15/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.0014 - accuracy: 0.5962 - val_loss: 1.0215 - val_accuracy: 0.5656\n","Epoch 16/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9936 - accuracy: 0.6047 - val_loss: 1.0192 - val_accuracy: 0.5328\n","Epoch 17/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.9892 - accuracy: 0.6075 - val_loss: 1.0136 - val_accuracy: 0.5905\n","Epoch 18/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9880 - accuracy: 0.6129 - val_loss: 1.0102 - val_accuracy: 0.5848\n","Epoch 19/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.9839 - accuracy: 0.6186 - val_loss: 1.0059 - val_accuracy: 0.5973\n","Epoch 20/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9814 - accuracy: 0.6171 - val_loss: 1.0014 - val_accuracy: 0.5939\n","Epoch 21/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9837 - accuracy: 0.6123 - val_loss: 1.0010 - val_accuracy: 0.5713\n","Epoch 22/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.9773 - accuracy: 0.6177 - val_loss: 0.9940 - val_accuracy: 0.6018\n","Epoch 23/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9756 - accuracy: 0.6138 - val_loss: 0.9957 - val_accuracy: 0.5803\n","Epoch 24/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9723 - accuracy: 0.6160 - val_loss: 0.9889 - val_accuracy: 0.5826\n","Epoch 25/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9702 - accuracy: 0.6106 - val_loss: 0.9856 - val_accuracy: 0.6007\n","Epoch 26/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9681 - accuracy: 0.6132 - val_loss: 0.9834 - val_accuracy: 0.5950\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9661 - accuracy: 0.6064 - val_loss: 0.9820 - val_accuracy: 0.5916\n","Epoch 28/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9621 - accuracy: 0.6188 - val_loss: 0.9791 - val_accuracy: 0.6063\n","Epoch 29/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9595 - accuracy: 0.6166 - val_loss: 0.9773 - val_accuracy: 0.6052\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9574 - accuracy: 0.6200 - val_loss: 0.9751 - val_accuracy: 0.6018\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9552 - accuracy: 0.6217 - val_loss: 0.9740 - val_accuracy: 0.6041\n","Epoch 32/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9537 - accuracy: 0.6177 - val_loss: 0.9807 - val_accuracy: 0.5814\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9500 - accuracy: 0.6231 - val_loss: 0.9714 - val_accuracy: 0.5984\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9505 - accuracy: 0.6106 - val_loss: 0.9689 - val_accuracy: 0.5995\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9475 - accuracy: 0.6186 - val_loss: 0.9667 - val_accuracy: 0.6052\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9452 - accuracy: 0.6231 - val_loss: 0.9651 - val_accuracy: 0.6052\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9451 - accuracy: 0.6208 - val_loss: 0.9699 - val_accuracy: 0.5848\n","Epoch 38/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9445 - accuracy: 0.6214 - val_loss: 0.9622 - val_accuracy: 0.6063\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9387 - accuracy: 0.6231 - val_loss: 0.9614 - val_accuracy: 0.6007\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9386 - accuracy: 0.6194 - val_loss: 0.9585 - val_accuracy: 0.6063\n","Epoch 41/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9339 - accuracy: 0.6262 - val_loss: 0.9611 - val_accuracy: 0.5905\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9350 - accuracy: 0.6228 - val_loss: 0.9556 - val_accuracy: 0.6063\n","Epoch 43/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.9376 - accuracy: 0.6126 - val_loss: 0.9542 - val_accuracy: 0.6097\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9313 - accuracy: 0.6276 - val_loss: 0.9529 - val_accuracy: 0.6052\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9278 - accuracy: 0.6307 - val_loss: 0.9524 - val_accuracy: 0.6052\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9277 - accuracy: 0.6242 - val_loss: 0.9526 - val_accuracy: 0.5950\n","Epoch 47/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9233 - accuracy: 0.6276 - val_loss: 0.9584 - val_accuracy: 0.5747\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9240 - accuracy: 0.6259 - val_loss: 0.9538 - val_accuracy: 0.5837\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9206 - accuracy: 0.6302 - val_loss: 0.9501 - val_accuracy: 0.5894\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9212 - accuracy: 0.6225 - val_loss: 0.9447 - val_accuracy: 0.6041\n","Epoch 51/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9153 - accuracy: 0.6333 - val_loss: 0.9482 - val_accuracy: 0.5894\n","Epoch 52/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9160 - accuracy: 0.6296 - val_loss: 0.9419 - val_accuracy: 0.6018\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9143 - accuracy: 0.6290 - val_loss: 0.9478 - val_accuracy: 0.5792\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9218 - accuracy: 0.6174 - val_loss: 0.9436 - val_accuracy: 0.5916\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9141 - accuracy: 0.6290 - val_loss: 0.9493 - val_accuracy: 0.5735\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9109 - accuracy: 0.6316 - val_loss: 0.9558 - val_accuracy: 0.5611\n","Epoch 57/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9164 - accuracy: 0.6276 - val_loss: 0.9499 - val_accuracy: 0.5713\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9062 - accuracy: 0.6367 - val_loss: 0.9498 - val_accuracy: 0.5803\n","Epoch 59/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9081 - accuracy: 0.6307 - val_loss: 0.9346 - val_accuracy: 0.6063\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9016 - accuracy: 0.6415 - val_loss: 0.9325 - val_accuracy: 0.6041\n","Epoch 61/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9001 - accuracy: 0.6415 - val_loss: 0.9318 - val_accuracy: 0.6086\n","Epoch 62/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9008 - accuracy: 0.6389 - val_loss: 0.9306 - val_accuracy: 0.6086\n","Epoch 63/100\n","28/28 [==============================] - 1s 49ms/step - loss: 0.8968 - accuracy: 0.6398 - val_loss: 0.9295 - val_accuracy: 0.6109\n","Epoch 64/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8957 - accuracy: 0.6437 - val_loss: 0.9284 - val_accuracy: 0.6041\n","Epoch 65/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8935 - accuracy: 0.6426 - val_loss: 0.9280 - val_accuracy: 0.6052\n","Epoch 66/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8927 - accuracy: 0.6437 - val_loss: 0.9266 - val_accuracy: 0.6097\n","Epoch 67/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8899 - accuracy: 0.6486 - val_loss: 0.9252 - val_accuracy: 0.6086\n","Epoch 68/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8875 - accuracy: 0.6460 - val_loss: 0.9252 - val_accuracy: 0.6052\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8856 - accuracy: 0.6432 - val_loss: 0.9236 - val_accuracy: 0.6086\n","Epoch 70/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.8855 - accuracy: 0.6463 - val_loss: 0.9210 - val_accuracy: 0.6143\n","Epoch 71/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8831 - accuracy: 0.6466 - val_loss: 0.9217 - val_accuracy: 0.6063\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8830 - accuracy: 0.6395 - val_loss: 0.9190 - val_accuracy: 0.6131\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8780 - accuracy: 0.6508 - val_loss: 0.9225 - val_accuracy: 0.6041\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8781 - accuracy: 0.6443 - val_loss: 0.9267 - val_accuracy: 0.5928\n","Epoch 75/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.8828 - accuracy: 0.6415 - val_loss: 0.9225 - val_accuracy: 0.5916\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8865 - accuracy: 0.6406 - val_loss: 0.9154 - val_accuracy: 0.6120\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8743 - accuracy: 0.6497 - val_loss: 0.9162 - val_accuracy: 0.6143\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8741 - accuracy: 0.6517 - val_loss: 0.9239 - val_accuracy: 0.5894\n","Epoch 79/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8712 - accuracy: 0.6483 - val_loss: 0.9135 - val_accuracy: 0.6097\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8678 - accuracy: 0.6576 - val_loss: 0.9157 - val_accuracy: 0.6086\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8683 - accuracy: 0.6570 - val_loss: 0.9114 - val_accuracy: 0.6097\n","Epoch 82/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.8669 - accuracy: 0.6539 - val_loss: 0.9112 - val_accuracy: 0.6165\n","Epoch 83/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.8633 - accuracy: 0.6644 - val_loss: 0.9134 - val_accuracy: 0.6176\n","Epoch 84/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8636 - accuracy: 0.6548 - val_loss: 0.9096 - val_accuracy: 0.6143\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8616 - accuracy: 0.6539 - val_loss: 0.9182 - val_accuracy: 0.5826\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8612 - accuracy: 0.6525 - val_loss: 0.9101 - val_accuracy: 0.6041\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8563 - accuracy: 0.6658 - val_loss: 0.9073 - val_accuracy: 0.6109\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8545 - accuracy: 0.6675 - val_loss: 0.9083 - val_accuracy: 0.6097\n","Epoch 89/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8570 - accuracy: 0.6585 - val_loss: 0.9095 - val_accuracy: 0.6143\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8521 - accuracy: 0.6658 - val_loss: 0.9117 - val_accuracy: 0.5837\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8576 - accuracy: 0.6494 - val_loss: 0.9189 - val_accuracy: 0.5894\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8495 - accuracy: 0.6585 - val_loss: 0.9120 - val_accuracy: 0.5803\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8502 - accuracy: 0.6638 - val_loss: 0.9080 - val_accuracy: 0.5962\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8447 - accuracy: 0.6706 - val_loss: 0.9005 - val_accuracy: 0.6109\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8499 - accuracy: 0.6559 - val_loss: 0.9443 - val_accuracy: 0.5396\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8564 - accuracy: 0.6426 - val_loss: 0.9039 - val_accuracy: 0.6029\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8419 - accuracy: 0.6669 - val_loss: 0.9019 - val_accuracy: 0.6097\n","Epoch 98/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8397 - accuracy: 0.6718 - val_loss: 0.9071 - val_accuracy: 0.6018\n","Epoch 99/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8358 - accuracy: 0.6743 - val_loss: 0.8971 - val_accuracy: 0.6063\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8335 - accuracy: 0.6808 - val_loss: 0.9010 - val_accuracy: 0.5939\n","{'loss': [1.0553102493286133, 1.0478992462158203, 1.0421925783157349, 1.037134051322937, 1.0322601795196533, 1.0301482677459717, 1.023760437965393, 1.0196512937545776, 1.016486406326294, 1.0131648778915405, 1.0087498426437378, 1.0068655014038086, 1.0018339157104492, 1.0059460401535034, 1.0014089345932007, 0.9935544729232788, 0.9891901612281799, 0.9879651069641113, 0.9839333295822144, 0.9813550114631653, 0.9837448000907898, 0.97732013463974, 0.9755938649177551, 0.972318172454834, 0.9702472686767578, 0.9681163430213928, 0.9660714268684387, 0.9620784521102905, 0.9595202803611755, 0.9574487209320068, 0.9551874399185181, 0.9537457823753357, 0.9499715566635132, 0.9504916071891785, 0.9474663138389587, 0.9452037811279297, 0.945068359375, 0.9445475339889526, 0.938709557056427, 0.9386373162269592, 0.9339129328727722, 0.9349684119224548, 0.9375705122947693, 0.9312995672225952, 0.9278018474578857, 0.9277021288871765, 0.9232786893844604, 0.9239607453346252, 0.9206368923187256, 0.9212178587913513, 0.9152956604957581, 0.916006863117218, 0.9143253564834595, 0.9218387603759766, 0.9140976071357727, 0.9109169840812683, 0.916373610496521, 0.9062130451202393, 0.908061683177948, 0.9015882015228271, 0.9000951647758484, 0.9008499383926392, 0.8968083262443542, 0.8957236409187317, 0.8935202956199646, 0.8927367925643921, 0.8898852467536926, 0.8874637484550476, 0.8856284022331238, 0.8855322599411011, 0.8831377625465393, 0.8830339908599854, 0.8779634237289429, 0.8781378269195557, 0.8828160762786865, 0.8864537477493286, 0.8742720484733582, 0.874072253704071, 0.8711838126182556, 0.8678386211395264, 0.8683333992958069, 0.8669043183326721, 0.8632639050483704, 0.8635984659194946, 0.8615707755088806, 0.8612415790557861, 0.85626620054245, 0.8545294404029846, 0.8570470213890076, 0.852112889289856, 0.8576087951660156, 0.8494870066642761, 0.8501941561698914, 0.8447192311286926, 0.8498765230178833, 0.856377899646759, 0.8418907523155212, 0.8397031426429749, 0.8357890248298645, 0.8335402607917786], 'accuracy': [0.5979060530662537, 0.594793438911438, 0.6095076203346252, 0.5996038317680359, 0.6049801707267761, 0.6001697778701782, 0.607809841632843, 0.6083757877349854, 0.6086587309837341, 0.6007357239723206, 0.6112054586410522, 0.604131281375885, 0.6089417338371277, 0.5967742204666138, 0.5962082743644714, 0.6046972274780273, 0.6075268983840942, 0.6129032373428345, 0.6185625195503235, 0.61714768409729, 0.6123372912406921, 0.6177136301994324, 0.6137521266937256, 0.6160158514976501, 0.6106395125389099, 0.6131861805915833, 0.6063950061798096, 0.618845522403717, 0.6165817975997925, 0.6199773550033569, 0.6216751337051392, 0.6177136301994324, 0.6230899691581726, 0.6106395125389099, 0.6185625195503235, 0.6230899691581726, 0.620826244354248, 0.6213921904563904, 0.6230899691581726, 0.6194114089012146, 0.6262025833129883, 0.6228070259094238, 0.6126202344894409, 0.6276174187660217, 0.6307300329208374, 0.6242218613624573, 0.6276174187660217, 0.6259196400642395, 0.6301641464233398, 0.6225240230560303, 0.6332767605781555, 0.6295982003211975, 0.6290322542190552, 0.6174306869506836, 0.6290322542190552, 0.6315789222717285, 0.6276174187660217, 0.63667231798172, 0.6307300329208374, 0.6414827108383179, 0.6414827108383179, 0.6389360427856445, 0.6397849321365356, 0.6437464356422424, 0.6426146030426025, 0.6437464356422424, 0.6485568881034851, 0.646010160446167, 0.6431805491447449, 0.6462931632995605, 0.6465761065483093, 0.6395019888877869, 0.6508206129074097, 0.6443123817443848, 0.6414827108383179, 0.6406338214874268, 0.649688720703125, 0.6516695022583008, 0.6482738852500916, 0.6576117873191833, 0.657045841217041, 0.6539332270622253, 0.664402961730957, 0.6547821164131165, 0.6539332270622253, 0.6525183916091919, 0.6658177971839905, 0.6675155758857727, 0.6584606766700745, 0.6658177971839905, 0.6494057774543762, 0.6584606766700745, 0.6638370156288147, 0.6706281900405884, 0.6559139490127563, 0.6426146030426025, 0.6669496297836304, 0.6717600226402283, 0.6743067502975464, 0.6808149218559265], 'val_loss': [1.0770691633224487, 1.0721218585968018, 1.0683141946792603, 1.0642504692077637, 1.060340166091919, 1.056557059288025, 1.0531736612319946, 1.050493597984314, 1.0451905727386475, 1.0438225269317627, 1.0396190881729126, 1.0360121726989746, 1.035477876663208, 1.0370475053787231, 1.021528720855713, 1.0191714763641357, 1.0135810375213623, 1.0101721286773682, 1.005900263786316, 1.0014115571975708, 1.0009615421295166, 0.9940280318260193, 0.9957224130630493, 0.9889270067214966, 0.9855943322181702, 0.9834176898002625, 0.9819714426994324, 0.9791057705879211, 0.9772992134094238, 0.9750745296478271, 0.9739962220191956, 0.9806699156761169, 0.9714342355728149, 0.9689159989356995, 0.9667184352874756, 0.9650610089302063, 0.9699283242225647, 0.9621657133102417, 0.96138596534729, 0.9584881067276001, 0.9611167311668396, 0.955637514591217, 0.9542165994644165, 0.9528506994247437, 0.9524431228637695, 0.9526256322860718, 0.9583929181098938, 0.9538438320159912, 0.9501160383224487, 0.9446831345558167, 0.9481658339500427, 0.9419098496437073, 0.9478129148483276, 0.9435691237449646, 0.949314296245575, 0.9557631015777588, 0.949883222579956, 0.9497552514076233, 0.934596598148346, 0.9324946999549866, 0.931814432144165, 0.9306297898292542, 0.929483950138092, 0.9283869862556458, 0.9280237555503845, 0.9266124963760376, 0.9251962304115295, 0.925229012966156, 0.9235511422157288, 0.9210165739059448, 0.9217336773872375, 0.9189717769622803, 0.9225472211837769, 0.9266663789749146, 0.9225286245346069, 0.9154470562934875, 0.9161720275878906, 0.9238788485527039, 0.9135149121284485, 0.9156659841537476, 0.9113721251487732, 0.9112124443054199, 0.9133592247962952, 0.9095686078071594, 0.9182146787643433, 0.9101112484931946, 0.907250702381134, 0.9083131551742554, 0.9095167517662048, 0.91167813539505, 0.9188955426216125, 0.9120104312896729, 0.9080455899238586, 0.9005217552185059, 0.9442693591117859, 0.9039435982704163, 0.9018898010253906, 0.9071056246757507, 0.8970533013343811, 0.9010462164878845], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.4954751133918762, 0.4977375566959381, 0.49660632014274597, 0.4977375566959381, 0.5, 0.4977375566959381, 0.49660632014274597, 0.5656108856201172, 0.5328054428100586, 0.5904977321624756, 0.5848416090011597, 0.5972850918769836, 0.5938913822174072, 0.5712669491767883, 0.6018099784851074, 0.5803167223930359, 0.5825791954994202, 0.6006787419319153, 0.5950226187705994, 0.5916289687156677, 0.6063348650932312, 0.6052036285400391, 0.6018099784851074, 0.6040723919868469, 0.581447958946228, 0.598416268825531, 0.5995475053787231, 0.6052036285400391, 0.6052036285400391, 0.5848416090011597, 0.6063348650932312, 0.6006787419319153, 0.6063348650932312, 0.5904977321624756, 0.6063348650932312, 0.6097285151481628, 0.6052036285400391, 0.6052036285400391, 0.5950226187705994, 0.5746606588363647, 0.5837104320526123, 0.5893664956092834, 0.6040723919868469, 0.5893664956092834, 0.6018099784851074, 0.5791855454444885, 0.5916289687156677, 0.5735294222831726, 0.5610859990119934, 0.5712669491767883, 0.5803167223930359, 0.6063348650932312, 0.6040723919868469, 0.6085972785949707, 0.6085972785949707, 0.610859751701355, 0.6040723919868469, 0.6052036285400391, 0.6097285151481628, 0.6085972785949707, 0.6052036285400391, 0.6085972785949707, 0.6142534017562866, 0.6063348650932312, 0.6131221652030945, 0.6040723919868469, 0.5927602052688599, 0.5916289687156677, 0.6119909286499023, 0.6142534017562866, 0.5893664956092834, 0.6097285151481628, 0.6085972785949707, 0.6097285151481628, 0.6165158152580261, 0.6176470518112183, 0.6142534017562866, 0.5825791954994202, 0.6040723919868469, 0.610859751701355, 0.6097285151481628, 0.6142534017562866, 0.5837104320526123, 0.5893664956092834, 0.5803167223930359, 0.5961538553237915, 0.610859751701355, 0.5395927429199219, 0.6029411554336548, 0.6097285151481628, 0.6018099784851074, 0.6063348650932312, 0.5938913822174072]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/31 [=========================>....] - ETA: 0s - loss: 1.0655 - accuracy: 0.5715"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 4s 34ms/step - loss: 1.0641 - accuracy: 0.5729 - val_loss: 1.0775 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0543 - accuracy: 0.5811 - val_loss: 1.0730 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0524 - accuracy: 0.5773 - val_loss: 1.0684 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0447 - accuracy: 0.5814 - val_loss: 1.0636 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0402 - accuracy: 0.5871 - val_loss: 1.0613 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0348 - accuracy: 0.5850 - val_loss: 1.0575 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0310 - accuracy: 0.5845 - val_loss: 1.0531 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0271 - accuracy: 0.5853 - val_loss: 1.0502 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0223 - accuracy: 0.5910 - val_loss: 1.0481 - val_accuracy: 0.4855\n","Epoch 10/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0188 - accuracy: 0.5866 - val_loss: 1.0421 - val_accuracy: 0.4855\n","Epoch 11/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0185 - accuracy: 0.5757 - val_loss: 1.0426 - val_accuracy: 0.4855\n","Epoch 12/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0098 - accuracy: 0.5925 - val_loss: 1.0422 - val_accuracy: 0.4855\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0110 - accuracy: 0.5775 - val_loss: 1.0302 - val_accuracy: 0.4938\n","Epoch 14/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0036 - accuracy: 0.5990 - val_loss: 1.0406 - val_accuracy: 0.4855\n","Epoch 15/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0033 - accuracy: 0.5837 - val_loss: 1.0236 - val_accuracy: 0.4959\n","Epoch 16/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9981 - accuracy: 0.5922 - val_loss: 1.0184 - val_accuracy: 0.5103\n","Epoch 17/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.9938 - accuracy: 0.5956 - val_loss: 1.0113 - val_accuracy: 0.5341\n","Epoch 18/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9934 - accuracy: 0.5866 - val_loss: 1.0146 - val_accuracy: 0.5093\n","Epoch 19/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9893 - accuracy: 0.5948 - val_loss: 1.0010 - val_accuracy: 0.5816\n","Epoch 20/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9901 - accuracy: 0.5902 - val_loss: 0.9950 - val_accuracy: 0.5868\n","Epoch 21/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9824 - accuracy: 0.6000 - val_loss: 0.9919 - val_accuracy: 0.5868\n","Epoch 22/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9794 - accuracy: 0.5969 - val_loss: 0.9876 - val_accuracy: 0.5888\n","Epoch 23/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9769 - accuracy: 0.5974 - val_loss: 0.9882 - val_accuracy: 0.5795\n","Epoch 24/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9756 - accuracy: 0.5894 - val_loss: 0.9820 - val_accuracy: 0.5837\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9718 - accuracy: 0.6003 - val_loss: 0.9780 - val_accuracy: 0.5878\n","Epoch 26/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9692 - accuracy: 0.6072 - val_loss: 0.9760 - val_accuracy: 0.5940\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9680 - accuracy: 0.6013 - val_loss: 0.9798 - val_accuracy: 0.5733\n","Epoch 28/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9637 - accuracy: 0.6054 - val_loss: 0.9721 - val_accuracy: 0.5950\n","Epoch 29/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9624 - accuracy: 0.6003 - val_loss: 0.9701 - val_accuracy: 0.5909\n","Epoch 30/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9594 - accuracy: 0.6036 - val_loss: 0.9677 - val_accuracy: 0.5816\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9612 - accuracy: 0.5946 - val_loss: 0.9655 - val_accuracy: 0.5899\n","Epoch 32/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9552 - accuracy: 0.6041 - val_loss: 0.9627 - val_accuracy: 0.5950\n","Epoch 33/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9523 - accuracy: 0.6065 - val_loss: 0.9620 - val_accuracy: 0.5837\n","Epoch 34/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9530 - accuracy: 0.5951 - val_loss: 0.9590 - val_accuracy: 0.5847\n","Epoch 35/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9551 - accuracy: 0.5987 - val_loss: 0.9604 - val_accuracy: 0.5950\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9490 - accuracy: 0.5961 - val_loss: 0.9582 - val_accuracy: 0.5723\n","Epoch 37/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9465 - accuracy: 0.6080 - val_loss: 0.9620 - val_accuracy: 0.5713\n","Epoch 38/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9423 - accuracy: 0.6078 - val_loss: 0.9520 - val_accuracy: 0.5888\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9395 - accuracy: 0.6075 - val_loss: 0.9612 - val_accuracy: 0.5640\n","Epoch 40/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9400 - accuracy: 0.6098 - val_loss: 0.9497 - val_accuracy: 0.5909\n","Epoch 41/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9368 - accuracy: 0.6090 - val_loss: 0.9484 - val_accuracy: 0.5940\n","Epoch 42/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9378 - accuracy: 0.6103 - val_loss: 0.9507 - val_accuracy: 0.5909\n","Epoch 43/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9357 - accuracy: 0.6000 - val_loss: 0.9478 - val_accuracy: 0.5733\n","Epoch 44/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9296 - accuracy: 0.6165 - val_loss: 0.9505 - val_accuracy: 0.5671\n","Epoch 45/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9324 - accuracy: 0.6008 - val_loss: 0.9565 - val_accuracy: 0.5640\n","Epoch 46/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9276 - accuracy: 0.6067 - val_loss: 0.9406 - val_accuracy: 0.5971\n","Epoch 47/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9247 - accuracy: 0.6111 - val_loss: 0.9416 - val_accuracy: 0.5847\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9222 - accuracy: 0.6129 - val_loss: 0.9392 - val_accuracy: 0.5785\n","Epoch 49/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9196 - accuracy: 0.6199 - val_loss: 0.9468 - val_accuracy: 0.5579\n","Epoch 50/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9198 - accuracy: 0.6078 - val_loss: 0.9372 - val_accuracy: 0.5713\n","Epoch 51/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9150 - accuracy: 0.6186 - val_loss: 0.9347 - val_accuracy: 0.5816\n","Epoch 52/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9153 - accuracy: 0.6129 - val_loss: 0.9368 - val_accuracy: 0.5868\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9161 - accuracy: 0.6176 - val_loss: 0.9342 - val_accuracy: 0.5909\n","Epoch 54/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9115 - accuracy: 0.6134 - val_loss: 0.9464 - val_accuracy: 0.5630\n","Epoch 55/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9092 - accuracy: 0.6163 - val_loss: 0.9294 - val_accuracy: 0.5899\n","Epoch 56/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9123 - accuracy: 0.6217 - val_loss: 0.9360 - val_accuracy: 0.5785\n","Epoch 57/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9118 - accuracy: 0.6137 - val_loss: 0.9267 - val_accuracy: 0.5899\n","Epoch 58/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9024 - accuracy: 0.6271 - val_loss: 0.9265 - val_accuracy: 0.5899\n","Epoch 59/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9027 - accuracy: 0.6204 - val_loss: 0.9255 - val_accuracy: 0.5785\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8983 - accuracy: 0.6279 - val_loss: 0.9303 - val_accuracy: 0.5795\n","Epoch 61/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9034 - accuracy: 0.6171 - val_loss: 0.9224 - val_accuracy: 0.5878\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8970 - accuracy: 0.6256 - val_loss: 0.9209 - val_accuracy: 0.5899\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8932 - accuracy: 0.6331 - val_loss: 0.9202 - val_accuracy: 0.5888\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8914 - accuracy: 0.6339 - val_loss: 0.9246 - val_accuracy: 0.5671\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8912 - accuracy: 0.6320 - val_loss: 0.9180 - val_accuracy: 0.5888\n","Epoch 66/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8874 - accuracy: 0.6305 - val_loss: 0.9184 - val_accuracy: 0.5878\n","Epoch 67/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8942 - accuracy: 0.6214 - val_loss: 0.9319 - val_accuracy: 0.5527\n","Epoch 68/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8870 - accuracy: 0.6320 - val_loss: 0.9143 - val_accuracy: 0.5857\n","Epoch 69/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8830 - accuracy: 0.6323 - val_loss: 0.9298 - val_accuracy: 0.5620\n","Epoch 70/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8822 - accuracy: 0.6349 - val_loss: 0.9150 - val_accuracy: 0.5847\n","Epoch 71/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8820 - accuracy: 0.6344 - val_loss: 0.9189 - val_accuracy: 0.5671\n","Epoch 72/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8782 - accuracy: 0.6326 - val_loss: 0.9092 - val_accuracy: 0.5909\n","Epoch 73/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8755 - accuracy: 0.6380 - val_loss: 0.9106 - val_accuracy: 0.5826\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8754 - accuracy: 0.6362 - val_loss: 0.9116 - val_accuracy: 0.5795\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8763 - accuracy: 0.6305 - val_loss: 0.9162 - val_accuracy: 0.5713\n","Epoch 76/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8699 - accuracy: 0.6481 - val_loss: 0.9057 - val_accuracy: 0.5857\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8698 - accuracy: 0.6416 - val_loss: 0.9165 - val_accuracy: 0.5630\n","Epoch 78/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8692 - accuracy: 0.6403 - val_loss: 0.9044 - val_accuracy: 0.5878\n","Epoch 79/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8650 - accuracy: 0.6450 - val_loss: 0.9118 - val_accuracy: 0.5775\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8654 - accuracy: 0.6478 - val_loss: 0.9175 - val_accuracy: 0.5682\n","Epoch 81/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8624 - accuracy: 0.6494 - val_loss: 0.9084 - val_accuracy: 0.5754\n","Epoch 82/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8646 - accuracy: 0.6364 - val_loss: 0.9057 - val_accuracy: 0.5888\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8597 - accuracy: 0.6444 - val_loss: 0.9020 - val_accuracy: 0.5899\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8554 - accuracy: 0.6553 - val_loss: 0.9034 - val_accuracy: 0.5795\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8533 - accuracy: 0.6584 - val_loss: 0.9100 - val_accuracy: 0.5733\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8524 - accuracy: 0.6553 - val_loss: 0.9012 - val_accuracy: 0.5723\n","Epoch 87/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8486 - accuracy: 0.6636 - val_loss: 0.8994 - val_accuracy: 0.5868\n","Epoch 88/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8470 - accuracy: 0.6556 - val_loss: 0.8974 - val_accuracy: 0.5919\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8493 - accuracy: 0.6491 - val_loss: 0.9027 - val_accuracy: 0.5702\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8443 - accuracy: 0.6574 - val_loss: 0.8960 - val_accuracy: 0.5816\n","Epoch 91/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8440 - accuracy: 0.6592 - val_loss: 0.8941 - val_accuracy: 0.5950\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8425 - accuracy: 0.6625 - val_loss: 0.8959 - val_accuracy: 0.5806\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8404 - accuracy: 0.6594 - val_loss: 0.8940 - val_accuracy: 0.5888\n","Epoch 94/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8385 - accuracy: 0.6618 - val_loss: 0.8950 - val_accuracy: 0.5785\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8390 - accuracy: 0.6677 - val_loss: 0.8940 - val_accuracy: 0.5857\n","Epoch 96/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8319 - accuracy: 0.6687 - val_loss: 0.8962 - val_accuracy: 0.5878\n","Epoch 97/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8350 - accuracy: 0.6571 - val_loss: 0.9038 - val_accuracy: 0.5806\n","Epoch 98/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8338 - accuracy: 0.6667 - val_loss: 0.8924 - val_accuracy: 0.5888\n","Epoch 99/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8278 - accuracy: 0.6716 - val_loss: 0.9005 - val_accuracy: 0.5888\n","Epoch 100/100\n","31/31 [==============================] - 1s 45ms/step - loss: 0.8295 - accuracy: 0.6623 - val_loss: 0.8893 - val_accuracy: 0.5981\n","{'loss': [1.0641101598739624, 1.0542659759521484, 1.0523754358291626, 1.0446913242340088, 1.04019033908844, 1.0347850322723389, 1.0310031175613403, 1.0270822048187256, 1.022347331047058, 1.0187721252441406, 1.0184543132781982, 1.009844422340393, 1.0110104084014893, 1.0036290884017944, 1.0032554864883423, 0.998143196105957, 0.9937591552734375, 0.993388295173645, 0.9892546534538269, 0.990104079246521, 0.9824110269546509, 0.9794014096260071, 0.9768663644790649, 0.9756118655204773, 0.9718332886695862, 0.9691512584686279, 0.9680317044258118, 0.9637086987495422, 0.9623574018478394, 0.9593949913978577, 0.9611776471138, 0.9552327990531921, 0.9522942304611206, 0.9530285596847534, 0.9550992250442505, 0.9489992260932922, 0.9465172290802002, 0.9423011541366577, 0.9394650459289551, 0.9400131106376648, 0.9367747902870178, 0.9378499388694763, 0.9356825947761536, 0.929600179195404, 0.93240886926651, 0.9276434779167175, 0.9246771335601807, 0.9222461581230164, 0.9195995330810547, 0.9198442697525024, 0.914993941783905, 0.9152976870536804, 0.9160785675048828, 0.9114851951599121, 0.9091922044754028, 0.9122902154922485, 0.9117898941040039, 0.9023986458778381, 0.9026703834533691, 0.8983394503593445, 0.9033574461936951, 0.8970236778259277, 0.8931780457496643, 0.8913929462432861, 0.8911649584770203, 0.8874140977859497, 0.894196629524231, 0.8870232701301575, 0.8830409049987793, 0.8822312951087952, 0.8820048570632935, 0.8781703114509583, 0.8754921555519104, 0.8753917217254639, 0.8763447999954224, 0.8698763847351074, 0.8698086142539978, 0.8691834211349487, 0.864992082118988, 0.865379273891449, 0.8624430894851685, 0.8646149635314941, 0.8597031831741333, 0.8554331660270691, 0.8533409833908081, 0.852425217628479, 0.8486205339431763, 0.8470050692558289, 0.84931480884552, 0.8443362712860107, 0.8439502716064453, 0.8424853086471558, 0.8404030799865723, 0.8384876847267151, 0.8389980792999268, 0.8318997025489807, 0.8349718451499939, 0.8337651491165161, 0.8278222680091858, 0.8295189142227173], 'accuracy': [0.5728682279586792, 0.58113694190979, 0.5772609710693359, 0.5813953280448914, 0.5870801210403442, 0.5850129127502441, 0.5844961404800415, 0.5852712988853455, 0.5909560918807983, 0.5865632891654968, 0.5757105946540833, 0.592506468296051, 0.5775193572044373, 0.5989664196968079, 0.5837209224700928, 0.5922480821609497, 0.5956072211265564, 0.5865632891654968, 0.5948320627212524, 0.5901808738708496, 0.6000000238418579, 0.5968992114067078, 0.5974160432815552, 0.5894056558609009, 0.6002584099769592, 0.6072351336479187, 0.6012920141220093, 0.6054263710975647, 0.6002584099769592, 0.6036175489425659, 0.5945736169815063, 0.6041343808174133, 0.6064599752426147, 0.5950904488563538, 0.5987080335617065, 0.5961240530014038, 0.6080103516578674, 0.6077519655227661, 0.60749351978302, 0.6098191142082214, 0.6090439558029175, 0.6103359460830688, 0.6000000238418579, 0.6165374517440796, 0.6007751822471619, 0.6067183613777161, 0.6111111044883728, 0.6129198670387268, 0.619896650314331, 0.6077519655227661, 0.6186046600341797, 0.6129198670387268, 0.6175710558891296, 0.6134366989135742, 0.6162790656089783, 0.6217054128646851, 0.6136950850486755, 0.6271317601203918, 0.6204134225845337, 0.6279069781303406, 0.617054283618927, 0.6255813837051392, 0.633074939250946, 0.6338501572608948, 0.632041335105896, 0.6304909586906433, 0.6214470267295837, 0.632041335105896, 0.6322997212409973, 0.6348837018013, 0.6343669295310974, 0.6325581669807434, 0.6379845142364502, 0.6361756920814514, 0.6304909586906433, 0.648061990737915, 0.6416020393371582, 0.6403100490570068, 0.6449612379074097, 0.6478036046028137, 0.6493539810180664, 0.6364341378211975, 0.644444465637207, 0.6552971601486206, 0.658397912979126, 0.6552971601486206, 0.6635658740997314, 0.6555555462837219, 0.6490955948829651, 0.6573643684387207, 0.6591731309890747, 0.6625322699546814, 0.659431517124176, 0.6617571115493774, 0.6677002310752869, 0.6687338352203369, 0.6571059226989746, 0.6666666865348816, 0.671576201915741, 0.6622738838195801], 'val_loss': [1.0775325298309326, 1.072995901107788, 1.0684401988983154, 1.063632845878601, 1.0613254308700562, 1.0575037002563477, 1.0530952215194702, 1.0501891374588013, 1.0480784177780151, 1.042081594467163, 1.042630672454834, 1.0421767234802246, 1.0301567316055298, 1.0405853986740112, 1.0235786437988281, 1.0184179544448853, 1.0112905502319336, 1.0146067142486572, 1.0010037422180176, 0.9949904680252075, 0.9918559193611145, 0.9876006841659546, 0.9882218837738037, 0.9820353388786316, 0.9779841899871826, 0.9760259389877319, 0.9798422455787659, 0.972072184085846, 0.9701158404350281, 0.9676530361175537, 0.9654700756072998, 0.9627441763877869, 0.961953341960907, 0.9589946866035461, 0.9603589773178101, 0.9582010507583618, 0.9619666337966919, 0.9519856572151184, 0.9612382650375366, 0.9497232437133789, 0.9484025835990906, 0.9506646394729614, 0.9478381872177124, 0.9504795074462891, 0.9564952254295349, 0.9405708909034729, 0.9415871500968933, 0.9392449259757996, 0.9468196630477905, 0.9372035264968872, 0.9346674084663391, 0.9368031620979309, 0.9342053532600403, 0.9464257955551147, 0.9293502569198608, 0.9359744787216187, 0.9267396330833435, 0.9264517426490784, 0.9254614114761353, 0.9302805066108704, 0.9223576784133911, 0.92086261510849, 0.9201709628105164, 0.9245686531066895, 0.9180211424827576, 0.918353259563446, 0.9319176077842712, 0.914309024810791, 0.9298413395881653, 0.9149537086486816, 0.9188621044158936, 0.9091938138008118, 0.9105873703956604, 0.9115676283836365, 0.9162418842315674, 0.905689001083374, 0.9165431261062622, 0.9043664336204529, 0.9117876887321472, 0.9175495505332947, 0.9084019660949707, 0.9056515097618103, 0.9019710421562195, 0.9034320712089539, 0.9099571704864502, 0.9011529684066772, 0.899383544921875, 0.8974175453186035, 0.9027182459831238, 0.8960167765617371, 0.8941431641578674, 0.8959212899208069, 0.8939762115478516, 0.8950369358062744, 0.8940045833587646, 0.8961786031723022, 0.9037603735923767, 0.8924381732940674, 0.9004825353622437, 0.8893005847930908], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.49380165338516235, 0.48553720116615295, 0.4958677589893341, 0.5103305578231812, 0.5340909361839294, 0.5092975497245789, 0.5816115736961365, 0.586776852607727, 0.586776852607727, 0.5888429880142212, 0.5795454382896423, 0.5836777091026306, 0.5878099203109741, 0.5940082669258118, 0.5733470916748047, 0.5950413346290588, 0.5909090638160706, 0.5816115736961365, 0.5898760557174683, 0.5950413346290588, 0.5836777091026306, 0.5847107172012329, 0.5950413346290588, 0.5723140239715576, 0.5712810158729553, 0.5888429880142212, 0.5640496015548706, 0.5909090638160706, 0.5940082669258118, 0.5909090638160706, 0.5733470916748047, 0.567148745059967, 0.5640496015548706, 0.5971074104309082, 0.5847107172012329, 0.5785123705863953, 0.557851254940033, 0.5712810158729553, 0.5816115736961365, 0.586776852607727, 0.5909090638160706, 0.5630165338516235, 0.5898760557174683, 0.5785123705863953, 0.5898760557174683, 0.5898760557174683, 0.5785123705863953, 0.5795454382896423, 0.5878099203109741, 0.5898760557174683, 0.5888429880142212, 0.567148745059967, 0.5888429880142212, 0.5878099203109741, 0.5526859760284424, 0.58574378490448, 0.5619834661483765, 0.5847107172012329, 0.567148745059967, 0.5909090638160706, 0.5826446413993835, 0.5795454382896423, 0.5712810158729553, 0.58574378490448, 0.5630165338516235, 0.5878099203109741, 0.577479362487793, 0.5681818127632141, 0.5754132270812988, 0.5888429880142212, 0.5898760557174683, 0.5795454382896423, 0.5733470916748047, 0.5723140239715576, 0.586776852607727, 0.5919421315193176, 0.5702479481697083, 0.5816115736961365, 0.5950413346290588, 0.5805785059928894, 0.5888429880142212, 0.5785123705863953, 0.58574378490448, 0.5878099203109741, 0.5805785059928894, 0.5888429880142212, 0.5888429880142212, 0.5981404781341553]}\n","32/32 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.8540 - accuracy: 0.6474"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 5s 35ms/step - loss: 0.8540 - accuracy: 0.6474 - val_loss: 0.9211 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8445 - accuracy: 0.6584 - val_loss: 0.9182 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8479 - accuracy: 0.6509 - val_loss: 0.9201 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8440 - accuracy: 0.6527 - val_loss: 0.9161 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8376 - accuracy: 0.6654 - val_loss: 0.9186 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8369 - accuracy: 0.6600 - val_loss: 0.9181 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8318 - accuracy: 0.6748 - val_loss: 0.9204 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8325 - accuracy: 0.6606 - val_loss: 0.9169 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.8292 - accuracy: 0.6643 - val_loss: 0.9169 - val_accuracy: 0.4860\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8312 - accuracy: 0.6659 - val_loss: 0.9260 - val_accuracy: 0.4849\n","Epoch 11/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8288 - accuracy: 0.6689 - val_loss: 0.9248 - val_accuracy: 0.4849\n","Epoch 12/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.8243 - accuracy: 0.6708 - val_loss: 0.9158 - val_accuracy: 0.4892\n","Epoch 13/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8290 - accuracy: 0.6665 - val_loss: 0.9345 - val_accuracy: 0.4849\n","Epoch 14/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.8237 - accuracy: 0.6727 - val_loss: 0.9138 - val_accuracy: 0.4978\n","Epoch 15/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.8199 - accuracy: 0.6781 - val_loss: 0.9112 - val_accuracy: 0.5043\n","Epoch 16/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.8207 - accuracy: 0.6713 - val_loss: 0.9019 - val_accuracy: 0.5248\n","Epoch 17/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8138 - accuracy: 0.6856 - val_loss: 0.9251 - val_accuracy: 0.5000\n","Epoch 18/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.8164 - accuracy: 0.6732 - val_loss: 0.8853 - val_accuracy: 0.5722\n","Epoch 19/100\n","29/29 [==============================] - 4s 127ms/step - loss: 0.8152 - accuracy: 0.6759 - val_loss: 0.8819 - val_accuracy: 0.5797\n","Epoch 20/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8142 - accuracy: 0.6708 - val_loss: 0.8831 - val_accuracy: 0.5668\n","Epoch 21/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.8100 - accuracy: 0.6824 - val_loss: 0.8701 - val_accuracy: 0.6013\n","Epoch 22/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.8080 - accuracy: 0.6829 - val_loss: 0.8660 - val_accuracy: 0.6067\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8042 - accuracy: 0.6891 - val_loss: 0.8638 - val_accuracy: 0.6034\n","Epoch 24/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8035 - accuracy: 0.6867 - val_loss: 0.8620 - val_accuracy: 0.6013\n","Epoch 25/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.8014 - accuracy: 0.6856 - val_loss: 0.8619 - val_accuracy: 0.6207\n","Epoch 26/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8019 - accuracy: 0.6867 - val_loss: 0.8612 - val_accuracy: 0.6153\n","Epoch 27/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.8058 - accuracy: 0.6783 - val_loss: 0.8560 - val_accuracy: 0.6218\n","Epoch 28/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7981 - accuracy: 0.6851 - val_loss: 0.8845 - val_accuracy: 0.5657\n","Epoch 29/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8090 - accuracy: 0.6719 - val_loss: 0.8801 - val_accuracy: 0.6110\n","Epoch 30/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7992 - accuracy: 0.6886 - val_loss: 0.8587 - val_accuracy: 0.6078\n","Epoch 31/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.7940 - accuracy: 0.6862 - val_loss: 0.8512 - val_accuracy: 0.6250\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7993 - accuracy: 0.6886 - val_loss: 0.8545 - val_accuracy: 0.6131\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7910 - accuracy: 0.6934 - val_loss: 0.8543 - val_accuracy: 0.6078\n","Epoch 34/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.7874 - accuracy: 0.6967 - val_loss: 0.8565 - val_accuracy: 0.6336\n","Epoch 35/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7841 - accuracy: 0.7015 - val_loss: 0.8547 - val_accuracy: 0.6207\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7855 - accuracy: 0.6994 - val_loss: 0.8823 - val_accuracy: 0.5668\n","Epoch 37/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7942 - accuracy: 0.6791 - val_loss: 0.8637 - val_accuracy: 0.5873\n","Epoch 38/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.7828 - accuracy: 0.6961 - val_loss: 0.8534 - val_accuracy: 0.6358\n","Epoch 39/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7884 - accuracy: 0.6921 - val_loss: 0.8502 - val_accuracy: 0.6185\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7885 - accuracy: 0.6888 - val_loss: 0.8581 - val_accuracy: 0.6024\n","Epoch 41/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7798 - accuracy: 0.6972 - val_loss: 0.8632 - val_accuracy: 0.6013\n","Epoch 42/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7758 - accuracy: 0.7055 - val_loss: 0.8525 - val_accuracy: 0.6121\n","Epoch 43/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7725 - accuracy: 0.7109 - val_loss: 0.8543 - val_accuracy: 0.6121\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7736 - accuracy: 0.7045 - val_loss: 0.8510 - val_accuracy: 0.6315\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7703 - accuracy: 0.7091 - val_loss: 0.8516 - val_accuracy: 0.6228\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7697 - accuracy: 0.7029 - val_loss: 0.8741 - val_accuracy: 0.5830\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7706 - accuracy: 0.6991 - val_loss: 0.8822 - val_accuracy: 0.5700\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7655 - accuracy: 0.7112 - val_loss: 0.8502 - val_accuracy: 0.6239\n","Epoch 49/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.7640 - accuracy: 0.7123 - val_loss: 0.8566 - val_accuracy: 0.6379\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7693 - accuracy: 0.7026 - val_loss: 0.8622 - val_accuracy: 0.6304\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7646 - accuracy: 0.7109 - val_loss: 0.8494 - val_accuracy: 0.6336\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7569 - accuracy: 0.7198 - val_loss: 0.8482 - val_accuracy: 0.6336\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7601 - accuracy: 0.7023 - val_loss: 0.8509 - val_accuracy: 0.6164\n","Epoch 54/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.7643 - accuracy: 0.7042 - val_loss: 0.8617 - val_accuracy: 0.6390\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7773 - accuracy: 0.6843 - val_loss: 0.8525 - val_accuracy: 0.6196\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7579 - accuracy: 0.7117 - val_loss: 0.8490 - val_accuracy: 0.6369\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7618 - accuracy: 0.6975 - val_loss: 0.8497 - val_accuracy: 0.6078\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7553 - accuracy: 0.7088 - val_loss: 0.8488 - val_accuracy: 0.6261\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7461 - accuracy: 0.7217 - val_loss: 0.8515 - val_accuracy: 0.6175\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7521 - accuracy: 0.7112 - val_loss: 0.8692 - val_accuracy: 0.5754\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7534 - accuracy: 0.7101 - val_loss: 0.8575 - val_accuracy: 0.5959\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7547 - accuracy: 0.7123 - val_loss: 0.8769 - val_accuracy: 0.5722\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7538 - accuracy: 0.7091 - val_loss: 0.8510 - val_accuracy: 0.6218\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7398 - accuracy: 0.7279 - val_loss: 0.8506 - val_accuracy: 0.6207\n","Epoch 65/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7355 - accuracy: 0.7322 - val_loss: 0.8805 - val_accuracy: 0.5733\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7452 - accuracy: 0.7161 - val_loss: 0.8762 - val_accuracy: 0.5841\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7472 - accuracy: 0.7107 - val_loss: 0.8572 - val_accuracy: 0.6056\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7316 - accuracy: 0.7266 - val_loss: 0.8496 - val_accuracy: 0.6282\n","Epoch 69/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7329 - accuracy: 0.7333 - val_loss: 0.8490 - val_accuracy: 0.6347\n","Epoch 70/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7357 - accuracy: 0.7252 - val_loss: 0.8611 - val_accuracy: 0.6379\n","Epoch 71/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7360 - accuracy: 0.7196 - val_loss: 0.8520 - val_accuracy: 0.6293\n","Epoch 72/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7291 - accuracy: 0.7293 - val_loss: 0.8722 - val_accuracy: 0.5873\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7330 - accuracy: 0.7258 - val_loss: 0.8576 - val_accuracy: 0.6024\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7229 - accuracy: 0.7387 - val_loss: 0.8533 - val_accuracy: 0.6239\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7223 - accuracy: 0.7325 - val_loss: 0.8701 - val_accuracy: 0.5905\n","Epoch 76/100\n","29/29 [==============================] - 1s 51ms/step - loss: 0.7272 - accuracy: 0.7311 - val_loss: 0.8623 - val_accuracy: 0.6412\n","Epoch 77/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7188 - accuracy: 0.7355 - val_loss: 0.8528 - val_accuracy: 0.6293\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7184 - accuracy: 0.7414 - val_loss: 0.8956 - val_accuracy: 0.5700\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7153 - accuracy: 0.7473 - val_loss: 0.8599 - val_accuracy: 0.6067\n","Epoch 80/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7123 - accuracy: 0.7422 - val_loss: 0.8575 - val_accuracy: 0.6142\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7156 - accuracy: 0.7303 - val_loss: 0.8537 - val_accuracy: 0.6401\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7102 - accuracy: 0.7406 - val_loss: 0.8722 - val_accuracy: 0.5873\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7183 - accuracy: 0.7233 - val_loss: 0.8673 - val_accuracy: 0.5991\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7112 - accuracy: 0.7435 - val_loss: 0.8553 - val_accuracy: 0.6336\n","Epoch 85/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7098 - accuracy: 0.7392 - val_loss: 0.8651 - val_accuracy: 0.6121\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7019 - accuracy: 0.7468 - val_loss: 0.8541 - val_accuracy: 0.6228\n","Epoch 87/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7160 - accuracy: 0.7306 - val_loss: 0.8577 - val_accuracy: 0.6261\n","Epoch 88/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7022 - accuracy: 0.7454 - val_loss: 0.8554 - val_accuracy: 0.6272\n","Epoch 89/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7027 - accuracy: 0.7460 - val_loss: 0.8637 - val_accuracy: 0.6369\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6992 - accuracy: 0.7457 - val_loss: 0.8626 - val_accuracy: 0.6315\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7237 - accuracy: 0.7158 - val_loss: 0.8620 - val_accuracy: 0.6131\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6982 - accuracy: 0.7476 - val_loss: 0.8901 - val_accuracy: 0.5787\n","Epoch 93/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6980 - accuracy: 0.7460 - val_loss: 0.8770 - val_accuracy: 0.5884\n","Epoch 94/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6912 - accuracy: 0.7570 - val_loss: 0.8668 - val_accuracy: 0.6164\n","Epoch 95/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6883 - accuracy: 0.7554 - val_loss: 0.8807 - val_accuracy: 0.5916\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6851 - accuracy: 0.7600 - val_loss: 0.8736 - val_accuracy: 0.6002\n","Epoch 97/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6888 - accuracy: 0.7543 - val_loss: 0.8818 - val_accuracy: 0.5938\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7093 - accuracy: 0.7373 - val_loss: 0.8746 - val_accuracy: 0.6379\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6818 - accuracy: 0.7645 - val_loss: 0.8592 - val_accuracy: 0.6239\n","Epoch 100/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6852 - accuracy: 0.7559 - val_loss: 0.8886 - val_accuracy: 0.5841\n","{'loss': [0.8540395498275757, 0.8444904088973999, 0.8478561639785767, 0.8439531922340393, 0.8376431465148926, 0.8369149565696716, 0.8317882418632507, 0.8324765563011169, 0.8292105197906494, 0.8312060832977295, 0.8287825584411621, 0.824332594871521, 0.8289642930030823, 0.8237274289131165, 0.8198840618133545, 0.820716142654419, 0.8138489723205566, 0.8164443373680115, 0.8151825070381165, 0.8141611218452454, 0.8100384473800659, 0.8079771995544434, 0.8041847348213196, 0.8034772276878357, 0.8013540506362915, 0.8019357919692993, 0.8057891726493835, 0.7980749011039734, 0.8089568614959717, 0.7992388010025024, 0.7939953207969666, 0.7992745637893677, 0.7910186052322388, 0.7873595952987671, 0.7841324210166931, 0.7855308651924133, 0.7941949367523193, 0.7828059792518616, 0.7883593440055847, 0.7884547114372253, 0.7797731757164001, 0.775785505771637, 0.7725246548652649, 0.7736408710479736, 0.7702624797821045, 0.7697004675865173, 0.770552396774292, 0.7654730677604675, 0.7639868259429932, 0.769318163394928, 0.7646228075027466, 0.7569282650947571, 0.7600542306900024, 0.7642965912818909, 0.7773085236549377, 0.7578600645065308, 0.7617536783218384, 0.7552655339241028, 0.7460964322090149, 0.7520816922187805, 0.7534279823303223, 0.7546666860580444, 0.7538430690765381, 0.7397734522819519, 0.7355053424835205, 0.7451876997947693, 0.7471790909767151, 0.7316336631774902, 0.7329354882240295, 0.7357490658760071, 0.7359840869903564, 0.7290741205215454, 0.7329944968223572, 0.7229078412055969, 0.7223430275917053, 0.7271990776062012, 0.7188189029693604, 0.7184010744094849, 0.7152646780014038, 0.7122638821601868, 0.7156497836112976, 0.7102461457252502, 0.7183326482772827, 0.7112471461296082, 0.7098233699798584, 0.7018986344337463, 0.7159942388534546, 0.702185332775116, 0.7027134895324707, 0.6992267370223999, 0.7236780524253845, 0.6981697082519531, 0.6979973912239075, 0.6911927461624146, 0.6882657408714294, 0.6851441860198975, 0.6888346672058105, 0.7092629075050354, 0.6818084120750427, 0.685240626335144], 'accuracy': [0.6473599076271057, 0.6584051847457886, 0.6508620977401733, 0.6527478694915771, 0.665409505367279, 0.6600215435028076, 0.6748383641242981, 0.6605603694915771, 0.6643319129943848, 0.6659482717514038, 0.6689116358757019, 0.6707974076271057, 0.6664870977401733, 0.6726831793785095, 0.678071141242981, 0.6713362336158752, 0.6856142282485962, 0.673222005367279, 0.6759159564971924, 0.6707974076271057, 0.6823814511299133, 0.6829202771186829, 0.689116358757019, 0.6866918206214905, 0.6856142282485962, 0.6866918206214905, 0.678340494632721, 0.6850754022598267, 0.671875, 0.6885775923728943, 0.686152994632721, 0.6885775923728943, 0.6934267282485962, 0.696659505367279, 0.701508641242981, 0.6993534564971924, 0.6791487336158752, 0.6961206793785095, 0.6920797228813171, 0.688847005367279, 0.6971982717514038, 0.7055495977401733, 0.7109375, 0.704472005367279, 0.7090517282485962, 0.7028555870056152, 0.6990840435028076, 0.7112069129943848, 0.712284505367279, 0.7025862336158752, 0.7109375, 0.7198275923728943, 0.7023168206214905, 0.7042025923728943, 0.6842672228813171, 0.7117456793785095, 0.6974676847457886, 0.7087823152542114, 0.7217133641242981, 0.7112069129943848, 0.7101293206214905, 0.712284505367279, 0.7090517282485962, 0.727909505367279, 0.7322198152542114, 0.7160560488700867, 0.7106680870056152, 0.7265625, 0.7332974076271057, 0.725215494632721, 0.7195581793785095, 0.7292564511299133, 0.7257543206214905, 0.7386853694915771, 0.7324892282485962, 0.7311422228813171, 0.7354525923728943, 0.7413793206214905, 0.7473060488700867, 0.7421875, 0.7303340435028076, 0.740571141242981, 0.7233297228813171, 0.743534505367279, 0.7392241358757019, 0.7467672228813171, 0.7306034564971924, 0.7454202771186829, 0.7459590435028076, 0.7456896305084229, 0.7157866358757019, 0.7475754022598267, 0.7459590435028076, 0.7570043206214905, 0.7553879022598267, 0.7599676847457886, 0.7543103694915771, 0.7373383641242981, 0.7645474076271057, 0.7559267282485962], 'val_loss': [0.9211012721061707, 0.9182365536689758, 0.9201303124427795, 0.9160533547401428, 0.9185554385185242, 0.9180521368980408, 0.9203796982765198, 0.9169389605522156, 0.9169224500656128, 0.9260026216506958, 0.9247665405273438, 0.9157716035842896, 0.9345328211784363, 0.9138299226760864, 0.911165714263916, 0.9019413590431213, 0.925144612789154, 0.8853119611740112, 0.8819141983985901, 0.883082926273346, 0.8701461553573608, 0.8659986853599548, 0.8637592196464539, 0.8619935512542725, 0.861892580986023, 0.8611958622932434, 0.8559771776199341, 0.8845496773719788, 0.8800604343414307, 0.8587009310722351, 0.8512064814567566, 0.8545154929161072, 0.8543182611465454, 0.8564556837081909, 0.8546993136405945, 0.8823248147964478, 0.863674521446228, 0.853387713432312, 0.8502342104911804, 0.8580525517463684, 0.8632115125656128, 0.8524749279022217, 0.8543215990066528, 0.8509936928749084, 0.8515651822090149, 0.8741331696510315, 0.8821915984153748, 0.8501956462860107, 0.8565908670425415, 0.8621909618377686, 0.8494032025337219, 0.848230242729187, 0.8508917093276978, 0.861707329750061, 0.8525473475456238, 0.8489852547645569, 0.8497125506401062, 0.848835825920105, 0.8515361547470093, 0.8692402243614197, 0.8574699759483337, 0.8769470453262329, 0.8509924411773682, 0.8506362438201904, 0.8805164098739624, 0.8762370944023132, 0.8572262525558472, 0.8495848178863525, 0.8489640355110168, 0.8610873222351074, 0.8520034551620483, 0.8722314238548279, 0.8575785160064697, 0.8532959222793579, 0.870147705078125, 0.8622640371322632, 0.8528475761413574, 0.8955862522125244, 0.8599153161048889, 0.8575477600097656, 0.8537098169326782, 0.8722267746925354, 0.867326021194458, 0.8553357720375061, 0.8650857210159302, 0.8540592193603516, 0.8577120304107666, 0.8553831577301025, 0.8636881113052368, 0.8626402020454407, 0.861980676651001, 0.8900662660598755, 0.8769784569740295, 0.8668210506439209, 0.8806911706924438, 0.8735519051551819, 0.881811797618866, 0.8746304512023926, 0.8592285513877869, 0.8886156678199768], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.48491379618644714, 0.48491379618644714, 0.4892241358757019, 0.48491379618644714, 0.4978448152542114, 0.5043103694915771, 0.524784505367279, 0.5, 0.5721982717514038, 0.579741358757019, 0.5668103694915771, 0.6012930870056152, 0.6066810488700867, 0.6034482717514038, 0.6012930870056152, 0.6206896305084229, 0.6153017282485962, 0.6217672228813171, 0.5657327771186829, 0.610991358757019, 0.607758641242981, 0.625, 0.6131465435028076, 0.607758641242981, 0.6336206793785095, 0.6206896305084229, 0.5668103694915771, 0.587284505367279, 0.6357758641242981, 0.618534505367279, 0.6023706793785095, 0.6012930870056152, 0.6120689511299133, 0.6120689511299133, 0.631465494632721, 0.6228448152542114, 0.5829741358757019, 0.5700430870056152, 0.6239224076271057, 0.6379310488700867, 0.6303879022598267, 0.6336206793785095, 0.6336206793785095, 0.6163793206214905, 0.639008641242981, 0.6196120977401733, 0.6368534564971924, 0.607758641242981, 0.6260775923728943, 0.6174569129943848, 0.5754310488700867, 0.5959051847457886, 0.5721982717514038, 0.6217672228813171, 0.6206896305084229, 0.5732758641242981, 0.5840517282485962, 0.6056034564971924, 0.6282327771186829, 0.6346982717514038, 0.6379310488700867, 0.6293103694915771, 0.587284505367279, 0.6023706793785095, 0.6239224076271057, 0.5905172228813171, 0.6411637663841248, 0.6293103694915771, 0.5700430870056152, 0.6066810488700867, 0.6142241358757019, 0.6400862336158752, 0.587284505367279, 0.5991379022598267, 0.6336206793785095, 0.6120689511299133, 0.6228448152542114, 0.6260775923728943, 0.6271551847457886, 0.6368534564971924, 0.631465494632721, 0.6131465435028076, 0.5786637663841248, 0.5883620977401733, 0.6163793206214905, 0.5915948152542114, 0.600215494632721, 0.59375, 0.6379310488700867, 0.6239224076271057, 0.5840517282485962]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.8534 - accuracy: 0.6460"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 4s 37ms/step - loss: 0.8534 - accuracy: 0.6460 - val_loss: 0.9189 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8459 - accuracy: 0.6565 - val_loss: 0.9175 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8427 - accuracy: 0.6570 - val_loss: 0.9175 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8418 - accuracy: 0.6545 - val_loss: 0.9151 - val_accuracy: 0.4966\n","Epoch 5/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8457 - accuracy: 0.6471 - val_loss: 0.9150 - val_accuracy: 0.4966\n","Epoch 6/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8432 - accuracy: 0.6582 - val_loss: 0.9202 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8352 - accuracy: 0.6636 - val_loss: 0.9184 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8333 - accuracy: 0.6582 - val_loss: 0.9174 - val_accuracy: 0.4966\n","Epoch 9/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8351 - accuracy: 0.6604 - val_loss: 0.9139 - val_accuracy: 0.4966\n","Epoch 10/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8337 - accuracy: 0.6633 - val_loss: 0.9231 - val_accuracy: 0.4966\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8295 - accuracy: 0.6616 - val_loss: 0.9195 - val_accuracy: 0.4966\n","Epoch 12/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8262 - accuracy: 0.6723 - val_loss: 0.9255 - val_accuracy: 0.4966\n","Epoch 13/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.8267 - accuracy: 0.6754 - val_loss: 0.9235 - val_accuracy: 0.4977\n","Epoch 14/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8247 - accuracy: 0.6689 - val_loss: 0.9209 - val_accuracy: 0.4966\n","Epoch 15/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.8207 - accuracy: 0.6800 - val_loss: 0.9109 - val_accuracy: 0.5068\n","Epoch 16/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.8230 - accuracy: 0.6715 - val_loss: 0.9062 - val_accuracy: 0.5136\n","Epoch 17/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8190 - accuracy: 0.6780 - val_loss: 0.9092 - val_accuracy: 0.5102\n","Epoch 18/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.8176 - accuracy: 0.6800 - val_loss: 0.8911 - val_accuracy: 0.5543\n","Epoch 19/100\n","28/28 [==============================] - 1s 47ms/step - loss: 0.8150 - accuracy: 0.6797 - val_loss: 0.8815 - val_accuracy: 0.5848\n","Epoch 20/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8169 - accuracy: 0.6757 - val_loss: 0.8863 - val_accuracy: 0.5622\n","Epoch 21/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.8141 - accuracy: 0.6828 - val_loss: 0.8741 - val_accuracy: 0.6018\n","Epoch 22/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8124 - accuracy: 0.6735 - val_loss: 0.8827 - val_accuracy: 0.5611\n","Epoch 23/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.8140 - accuracy: 0.6698 - val_loss: 0.8684 - val_accuracy: 0.6109\n","Epoch 24/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8072 - accuracy: 0.6842 - val_loss: 0.8696 - val_accuracy: 0.6063\n","Epoch 25/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.8061 - accuracy: 0.6825 - val_loss: 0.8646 - val_accuracy: 0.6131\n","Epoch 26/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.8057 - accuracy: 0.6893 - val_loss: 0.8607 - val_accuracy: 0.6256\n","Epoch 27/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.8021 - accuracy: 0.6919 - val_loss: 0.8585 - val_accuracy: 0.6312\n","Epoch 28/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8078 - accuracy: 0.6794 - val_loss: 0.8576 - val_accuracy: 0.6278\n","Epoch 29/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8012 - accuracy: 0.6910 - val_loss: 0.8725 - val_accuracy: 0.6029\n","Epoch 30/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7998 - accuracy: 0.6853 - val_loss: 0.8782 - val_accuracy: 0.5962\n","Epoch 31/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8001 - accuracy: 0.6853 - val_loss: 0.8688 - val_accuracy: 0.6131\n","Epoch 32/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7957 - accuracy: 0.6927 - val_loss: 0.8753 - val_accuracy: 0.5995\n","Epoch 33/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7997 - accuracy: 0.6808 - val_loss: 0.8573 - val_accuracy: 0.6290\n","Epoch 34/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.7981 - accuracy: 0.6839 - val_loss: 0.8540 - val_accuracy: 0.6335\n","Epoch 35/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7923 - accuracy: 0.6958 - val_loss: 0.8530 - val_accuracy: 0.6324\n","Epoch 36/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7920 - accuracy: 0.6907 - val_loss: 0.8627 - val_accuracy: 0.6176\n","Epoch 37/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7940 - accuracy: 0.6842 - val_loss: 0.8562 - val_accuracy: 0.6267\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7962 - accuracy: 0.6780 - val_loss: 0.8542 - val_accuracy: 0.6335\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7932 - accuracy: 0.6845 - val_loss: 0.8785 - val_accuracy: 0.5826\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7866 - accuracy: 0.6952 - val_loss: 0.8520 - val_accuracy: 0.6233\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7846 - accuracy: 0.6916 - val_loss: 0.8766 - val_accuracy: 0.5995\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7909 - accuracy: 0.6870 - val_loss: 0.8547 - val_accuracy: 0.6222\n","Epoch 43/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7876 - accuracy: 0.6967 - val_loss: 0.8507 - val_accuracy: 0.6346\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7856 - accuracy: 0.6938 - val_loss: 0.8578 - val_accuracy: 0.6256\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7732 - accuracy: 0.7117 - val_loss: 0.8555 - val_accuracy: 0.6244\n","Epoch 46/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7762 - accuracy: 0.7077 - val_loss: 0.8538 - val_accuracy: 0.6188\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7741 - accuracy: 0.7015 - val_loss: 0.8523 - val_accuracy: 0.6312\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7776 - accuracy: 0.6995 - val_loss: 0.8626 - val_accuracy: 0.6109\n","Epoch 49/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7753 - accuracy: 0.7057 - val_loss: 0.8654 - val_accuracy: 0.6176\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7776 - accuracy: 0.6930 - val_loss: 0.8506 - val_accuracy: 0.6267\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7724 - accuracy: 0.7032 - val_loss: 0.8506 - val_accuracy: 0.6199\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7641 - accuracy: 0.7153 - val_loss: 0.8552 - val_accuracy: 0.6312\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7735 - accuracy: 0.6941 - val_loss: 0.8543 - val_accuracy: 0.6222\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7725 - accuracy: 0.6992 - val_loss: 0.8498 - val_accuracy: 0.6290\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7633 - accuracy: 0.7179 - val_loss: 0.8579 - val_accuracy: 0.6143\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7600 - accuracy: 0.7136 - val_loss: 0.8550 - val_accuracy: 0.6290\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7583 - accuracy: 0.7176 - val_loss: 0.8539 - val_accuracy: 0.6109\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7631 - accuracy: 0.7068 - val_loss: 0.8473 - val_accuracy: 0.6278\n","Epoch 59/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7510 - accuracy: 0.7292 - val_loss: 0.8521 - val_accuracy: 0.6222\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7503 - accuracy: 0.7312 - val_loss: 0.8508 - val_accuracy: 0.6199\n","Epoch 61/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7510 - accuracy: 0.7264 - val_loss: 0.8497 - val_accuracy: 0.6256\n","Epoch 62/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7472 - accuracy: 0.7221 - val_loss: 0.8508 - val_accuracy: 0.6267\n","Epoch 63/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7536 - accuracy: 0.7213 - val_loss: 0.8825 - val_accuracy: 0.5939\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7515 - accuracy: 0.7187 - val_loss: 0.8507 - val_accuracy: 0.6120\n","Epoch 65/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7514 - accuracy: 0.7204 - val_loss: 0.8495 - val_accuracy: 0.6244\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7421 - accuracy: 0.7309 - val_loss: 0.8705 - val_accuracy: 0.6120\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7431 - accuracy: 0.7312 - val_loss: 0.8558 - val_accuracy: 0.6154\n","Epoch 68/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7392 - accuracy: 0.7323 - val_loss: 0.8589 - val_accuracy: 0.6210\n","Epoch 69/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7423 - accuracy: 0.7252 - val_loss: 0.8999 - val_accuracy: 0.5781\n","Epoch 70/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7445 - accuracy: 0.7125 - val_loss: 0.8510 - val_accuracy: 0.6301\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7368 - accuracy: 0.7275 - val_loss: 0.8496 - val_accuracy: 0.6210\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7329 - accuracy: 0.7394 - val_loss: 0.8517 - val_accuracy: 0.6143\n","Epoch 73/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7285 - accuracy: 0.7357 - val_loss: 0.8533 - val_accuracy: 0.6267\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7313 - accuracy: 0.7388 - val_loss: 0.8628 - val_accuracy: 0.6188\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7355 - accuracy: 0.7244 - val_loss: 0.8871 - val_accuracy: 0.5973\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7295 - accuracy: 0.7388 - val_loss: 0.8536 - val_accuracy: 0.6165\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7291 - accuracy: 0.7326 - val_loss: 0.8557 - val_accuracy: 0.6097\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7320 - accuracy: 0.7207 - val_loss: 0.8956 - val_accuracy: 0.5837\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7302 - accuracy: 0.7320 - val_loss: 0.8538 - val_accuracy: 0.6176\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7175 - accuracy: 0.7419 - val_loss: 0.8631 - val_accuracy: 0.6143\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7229 - accuracy: 0.7286 - val_loss: 0.8630 - val_accuracy: 0.6131\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7173 - accuracy: 0.7385 - val_loss: 0.8527 - val_accuracy: 0.6244\n","Epoch 83/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7200 - accuracy: 0.7351 - val_loss: 0.8683 - val_accuracy: 0.5962\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7115 - accuracy: 0.7487 - val_loss: 0.8532 - val_accuracy: 0.6222\n","Epoch 85/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7082 - accuracy: 0.7533 - val_loss: 0.8562 - val_accuracy: 0.6109\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7091 - accuracy: 0.7552 - val_loss: 0.8630 - val_accuracy: 0.6109\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7393 - accuracy: 0.7117 - val_loss: 0.8965 - val_accuracy: 0.5837\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7193 - accuracy: 0.7303 - val_loss: 0.8516 - val_accuracy: 0.6244\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7096 - accuracy: 0.7442 - val_loss: 0.8606 - val_accuracy: 0.6075\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7037 - accuracy: 0.7535 - val_loss: 0.8853 - val_accuracy: 0.5939\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7022 - accuracy: 0.7547 - val_loss: 0.8676 - val_accuracy: 0.5962\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7137 - accuracy: 0.7377 - val_loss: 0.8919 - val_accuracy: 0.5894\n","Epoch 93/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7115 - accuracy: 0.7385 - val_loss: 0.8644 - val_accuracy: 0.6143\n","Epoch 94/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6995 - accuracy: 0.7493 - val_loss: 0.8605 - val_accuracy: 0.6131\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7022 - accuracy: 0.7450 - val_loss: 0.8619 - val_accuracy: 0.6109\n","Epoch 96/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7021 - accuracy: 0.7484 - val_loss: 0.8936 - val_accuracy: 0.5995\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7005 - accuracy: 0.7442 - val_loss: 0.8793 - val_accuracy: 0.5962\n","Epoch 98/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6926 - accuracy: 0.7609 - val_loss: 0.8640 - val_accuracy: 0.6154\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6881 - accuracy: 0.7651 - val_loss: 0.8611 - val_accuracy: 0.6086\n","Epoch 100/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6859 - accuracy: 0.7702 - val_loss: 0.9077 - val_accuracy: 0.5950\n","{'loss': [0.8533643484115601, 0.8458989858627319, 0.8426517248153687, 0.8417643308639526, 0.8456832766532898, 0.8431885838508606, 0.8352437019348145, 0.8333094120025635, 0.8350577354431152, 0.8337395191192627, 0.8294541239738464, 0.8262485861778259, 0.8266623616218567, 0.8247190713882446, 0.820686399936676, 0.8229880332946777, 0.8189584612846375, 0.8176417946815491, 0.8150084018707275, 0.816919207572937, 0.8141245245933533, 0.8124236464500427, 0.813981831073761, 0.807155430316925, 0.8061350584030151, 0.8057103753089905, 0.802117645740509, 0.807826042175293, 0.8011630177497864, 0.7998449206352234, 0.8001423478126526, 0.7956812381744385, 0.7996633648872375, 0.7981077432632446, 0.7922934889793396, 0.7920324206352234, 0.7939649820327759, 0.7962456941604614, 0.7931827306747437, 0.7865898609161377, 0.784588634967804, 0.7909272909164429, 0.7876086831092834, 0.7856091856956482, 0.7732140421867371, 0.7762029767036438, 0.7741063237190247, 0.7776495218276978, 0.7753242254257202, 0.777608335018158, 0.7724049091339111, 0.7640691995620728, 0.7735308408737183, 0.7725392580032349, 0.7632946968078613, 0.7599936723709106, 0.7583037614822388, 0.7631487250328064, 0.7509662508964539, 0.7502530813217163, 0.7510197162628174, 0.7472236156463623, 0.7535539865493774, 0.7515308856964111, 0.7513654828071594, 0.7421332597732544, 0.743086576461792, 0.7391930818557739, 0.7423288226127625, 0.744465172290802, 0.7368050813674927, 0.7328540682792664, 0.7285459637641907, 0.7313014268875122, 0.7355278134346008, 0.7294901609420776, 0.7291393280029297, 0.7320249080657959, 0.7302155494689941, 0.7175015211105347, 0.7228893637657166, 0.7172970175743103, 0.719959557056427, 0.711519718170166, 0.7081665396690369, 0.7091253995895386, 0.7393437027931213, 0.7192791700363159, 0.7096055746078491, 0.7036502361297607, 0.7021774649620056, 0.7137061953544617, 0.711531400680542, 0.6994599103927612, 0.702160120010376, 0.7020840048789978, 0.7005401849746704, 0.6925795674324036, 0.6881473660469055, 0.6858705878257751], 'accuracy': [0.646010160446167, 0.6564798951148987, 0.657045841217041, 0.6544991731643677, 0.6471420526504517, 0.6581776738166809, 0.6635540723800659, 0.6581776738166809, 0.6604413986206055, 0.6632710695266724, 0.6615732908248901, 0.6723259687423706, 0.6754385828971863, 0.6689304113388062, 0.6799660325050354, 0.6714770793914795, 0.6779853105545044, 0.6799660325050354, 0.6796830892562866, 0.6757215857505798, 0.6827957034111023, 0.6734578609466553, 0.6697793006896973, 0.6842105388641357, 0.6825127601623535, 0.6893039345741272, 0.6918506026268005, 0.6794000864028931, 0.6910017132759094, 0.6853423714637756, 0.6853423714637756, 0.6926994919776917, 0.6808149218559265, 0.6839275360107422, 0.6958121061325073, 0.6907187104225159, 0.6842105388641357, 0.6779853105545044, 0.6844934821128845, 0.695246160030365, 0.691567599773407, 0.6870402097702026, 0.6966609954833984, 0.6938313245773315, 0.7116581797599792, 0.7076966762542725, 0.7014714479446411, 0.6994906663894653, 0.7057158946990967, 0.6929824352264404, 0.7031692266464233, 0.7153367400169373, 0.6941143274307251, 0.6992077231407166, 0.7178834080696106, 0.713638961315155, 0.7176004648208618, 0.7068477869033813, 0.7292020320892334, 0.7311828136444092, 0.7263723611831665, 0.7221279144287109, 0.7212790250778198, 0.7187322974205017, 0.7204301357269287, 0.7308998107910156, 0.7311828136444092, 0.7323146462440491, 0.7252405285835266, 0.7125070691108704, 0.7275042533874512, 0.7393888235092163, 0.7357102632522583, 0.738822877407074, 0.7243916392326355, 0.738822877407074, 0.7325976490974426, 0.7207130789756775, 0.7320317029953003, 0.7419354915618896, 0.7286360859870911, 0.7385398745536804, 0.735144317150116, 0.7487266659736633, 0.7532541155815125, 0.7552348375320435, 0.7116581797599792, 0.7303339242935181, 0.7441992163658142, 0.7535370588302612, 0.7546689510345459, 0.7376909852027893, 0.7385398745536804, 0.7492926120758057, 0.7450481057167053, 0.7484436631202698, 0.7441992163658142, 0.7608941793441772, 0.7651386260986328, 0.7702320218086243], 'val_loss': [0.9188655018806458, 0.9174589514732361, 0.9175302386283875, 0.9150834679603577, 0.9149622917175293, 0.9201673269271851, 0.9183781743049622, 0.9174317121505737, 0.9139323234558105, 0.9230675101280212, 0.9194953441619873, 0.9255406260490417, 0.9235211610794067, 0.920864999294281, 0.9108744263648987, 0.906189501285553, 0.9092429280281067, 0.8911201357841492, 0.8815445899963379, 0.8862650394439697, 0.8740713000297546, 0.8827484250068665, 0.8683673143386841, 0.8695510029792786, 0.8646334409713745, 0.8607133626937866, 0.8584523797035217, 0.8575733304023743, 0.8724996447563171, 0.8782030344009399, 0.8687984347343445, 0.8752697110176086, 0.8572666049003601, 0.8539556860923767, 0.8530159592628479, 0.8626756072044373, 0.8561939001083374, 0.8542479872703552, 0.8785041570663452, 0.8519935607910156, 0.8766262531280518, 0.8546634316444397, 0.850650429725647, 0.8577747344970703, 0.8554766774177551, 0.8537868857383728, 0.8523257970809937, 0.8626186847686768, 0.8654263615608215, 0.8505671620368958, 0.8505715727806091, 0.8551504611968994, 0.8543335795402527, 0.8498391509056091, 0.8578928112983704, 0.8550232648849487, 0.8538805246353149, 0.8473419547080994, 0.8521332144737244, 0.8507881760597229, 0.8497226238250732, 0.8507512807846069, 0.882476270198822, 0.8507277369499207, 0.8495141863822937, 0.8704572319984436, 0.8557937145233154, 0.8588758111000061, 0.8999433517456055, 0.8509839177131653, 0.8496180772781372, 0.8517016768455505, 0.8533014059066772, 0.8628082275390625, 0.8871482610702515, 0.8536089062690735, 0.8556672930717468, 0.8956317901611328, 0.8538355827331543, 0.8630998134613037, 0.8630440831184387, 0.852721631526947, 0.8682573437690735, 0.8531637787818909, 0.8561641573905945, 0.8629630208015442, 0.8965282440185547, 0.8515716791152954, 0.8605840802192688, 0.8853400945663452, 0.8676300048828125, 0.8918967247009277, 0.8643519878387451, 0.8604577779769897, 0.8618695735931396, 0.8935548067092896, 0.8792924284934998, 0.8640049695968628, 0.8611167073249817, 0.9076979756355286], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.49660632014274597, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.49660632014274597, 0.49660632014274597, 0.49660632014274597, 0.49660632014274597, 0.4977375566959381, 0.49660632014274597, 0.5067873597145081, 0.5135746598243713, 0.5101810097694397, 0.5542986392974854, 0.5848416090011597, 0.5622171759605408, 0.6018099784851074, 0.5610859990119934, 0.610859751701355, 0.6063348650932312, 0.6131221652030945, 0.6255655884742737, 0.6312217116355896, 0.627828061580658, 0.6029411554336548, 0.5961538553237915, 0.6131221652030945, 0.5995475053787231, 0.6289592981338501, 0.6334841847419739, 0.6323529481887817, 0.6176470518112183, 0.6266968250274658, 0.6334841847419739, 0.5825791954994202, 0.6233031749725342, 0.5995475053787231, 0.622171938419342, 0.6346153616905212, 0.6255655884742737, 0.6244344115257263, 0.6187782883644104, 0.6312217116355896, 0.610859751701355, 0.6176470518112183, 0.6266968250274658, 0.6199095249176025, 0.6312217116355896, 0.622171938419342, 0.6289592981338501, 0.6142534017562866, 0.6289592981338501, 0.610859751701355, 0.627828061580658, 0.622171938419342, 0.6199095249176025, 0.6255655884742737, 0.6266968250274658, 0.5938913822174072, 0.6119909286499023, 0.6244344115257263, 0.6119909286499023, 0.6153846383094788, 0.6210407018661499, 0.5780543088912964, 0.6300904750823975, 0.6210407018661499, 0.6142534017562866, 0.6266968250274658, 0.6187782883644104, 0.5972850918769836, 0.6165158152580261, 0.6097285151481628, 0.5837104320526123, 0.6176470518112183, 0.6142534017562866, 0.6131221652030945, 0.6244344115257263, 0.5961538553237915, 0.622171938419342, 0.610859751701355, 0.610859751701355, 0.5837104320526123, 0.6244344115257263, 0.6074660420417786, 0.5938913822174072, 0.5961538553237915, 0.5893664956092834, 0.6142534017562866, 0.6131221652030945, 0.610859751701355, 0.5995475053787231, 0.5961538553237915, 0.6153846383094788, 0.6085972785949707, 0.5950226187705994]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.8699 - accuracy: 0.6145"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 4s 36ms/step - loss: 0.8699 - accuracy: 0.6145 - val_loss: 0.9201 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8550 - accuracy: 0.6473 - val_loss: 0.9218 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8526 - accuracy: 0.6419 - val_loss: 0.9218 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8496 - accuracy: 0.6419 - val_loss: 0.9218 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8503 - accuracy: 0.6372 - val_loss: 0.9255 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8513 - accuracy: 0.6339 - val_loss: 0.9259 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8417 - accuracy: 0.6628 - val_loss: 0.9272 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8411 - accuracy: 0.6649 - val_loss: 0.9290 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8379 - accuracy: 0.6563 - val_loss: 0.9370 - val_accuracy: 0.4855\n","Epoch 10/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8380 - accuracy: 0.6576 - val_loss: 0.9453 - val_accuracy: 0.4855\n","Epoch 11/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8401 - accuracy: 0.6434 - val_loss: 0.9354 - val_accuracy: 0.4855\n","Epoch 12/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8363 - accuracy: 0.6561 - val_loss: 0.9291 - val_accuracy: 0.4855\n","Epoch 13/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.8358 - accuracy: 0.6589 - val_loss: 0.9306 - val_accuracy: 0.4866\n","Epoch 14/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8316 - accuracy: 0.6628 - val_loss: 0.9410 - val_accuracy: 0.4855\n","Epoch 15/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8345 - accuracy: 0.6509 - val_loss: 0.9086 - val_accuracy: 0.5041\n","Epoch 16/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.8254 - accuracy: 0.6718 - val_loss: 0.9047 - val_accuracy: 0.5227\n","Epoch 17/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8246 - accuracy: 0.6693 - val_loss: 0.8969 - val_accuracy: 0.5279\n","Epoch 18/100\n","31/31 [==============================] - 3s 107ms/step - loss: 0.8224 - accuracy: 0.6739 - val_loss: 0.8903 - val_accuracy: 0.5537\n","Epoch 19/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8251 - accuracy: 0.6656 - val_loss: 0.9042 - val_accuracy: 0.5186\n","Epoch 20/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8380 - accuracy: 0.6344 - val_loss: 0.8799 - val_accuracy: 0.5775\n","Epoch 21/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.8284 - accuracy: 0.6548 - val_loss: 0.8751 - val_accuracy: 0.5868\n","Epoch 22/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8175 - accuracy: 0.6788 - val_loss: 0.8728 - val_accuracy: 0.5837\n","Epoch 23/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8163 - accuracy: 0.6767 - val_loss: 0.8700 - val_accuracy: 0.5899\n","Epoch 24/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.8181 - accuracy: 0.6711 - val_loss: 0.8665 - val_accuracy: 0.6043\n","Epoch 25/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8125 - accuracy: 0.6739 - val_loss: 0.8647 - val_accuracy: 0.5992\n","Epoch 26/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8138 - accuracy: 0.6713 - val_loss: 0.8649 - val_accuracy: 0.5899\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8078 - accuracy: 0.6767 - val_loss: 0.8616 - val_accuracy: 0.6043\n","Epoch 28/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8114 - accuracy: 0.6742 - val_loss: 0.8614 - val_accuracy: 0.6023\n","Epoch 29/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8112 - accuracy: 0.6711 - val_loss: 0.8721 - val_accuracy: 0.5950\n","Epoch 30/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.8102 - accuracy: 0.6747 - val_loss: 0.8599 - val_accuracy: 0.6074\n","Epoch 31/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.8105 - accuracy: 0.6736 - val_loss: 0.8577 - val_accuracy: 0.6178\n","Epoch 32/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8006 - accuracy: 0.6884 - val_loss: 0.8661 - val_accuracy: 0.6054\n","Epoch 33/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8008 - accuracy: 0.6858 - val_loss: 0.8628 - val_accuracy: 0.6126\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7954 - accuracy: 0.6902 - val_loss: 0.8613 - val_accuracy: 0.6136\n","Epoch 35/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7962 - accuracy: 0.6863 - val_loss: 0.8624 - val_accuracy: 0.6105\n","Epoch 36/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7980 - accuracy: 0.6871 - val_loss: 0.8953 - val_accuracy: 0.5775\n","Epoch 37/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7949 - accuracy: 0.6822 - val_loss: 0.8596 - val_accuracy: 0.6074\n","Epoch 38/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7923 - accuracy: 0.6876 - val_loss: 0.8638 - val_accuracy: 0.6126\n","Epoch 39/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8001 - accuracy: 0.6780 - val_loss: 0.9117 - val_accuracy: 0.5651\n","Epoch 40/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7974 - accuracy: 0.6677 - val_loss: 0.8547 - val_accuracy: 0.6054\n","Epoch 41/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7862 - accuracy: 0.6928 - val_loss: 0.8562 - val_accuracy: 0.6002\n","Epoch 42/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7891 - accuracy: 0.6899 - val_loss: 0.8528 - val_accuracy: 0.6167\n","Epoch 43/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7856 - accuracy: 0.6897 - val_loss: 0.8590 - val_accuracy: 0.5981\n","Epoch 44/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7831 - accuracy: 0.6938 - val_loss: 0.8836 - val_accuracy: 0.5940\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7859 - accuracy: 0.6879 - val_loss: 0.8759 - val_accuracy: 0.6033\n","Epoch 46/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7863 - accuracy: 0.6879 - val_loss: 0.8791 - val_accuracy: 0.5857\n","Epoch 47/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7876 - accuracy: 0.6840 - val_loss: 0.8657 - val_accuracy: 0.6095\n","Epoch 48/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.7812 - accuracy: 0.6904 - val_loss: 0.8550 - val_accuracy: 0.6043\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7775 - accuracy: 0.7010 - val_loss: 0.8608 - val_accuracy: 0.5961\n","Epoch 50/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7790 - accuracy: 0.6915 - val_loss: 0.8738 - val_accuracy: 0.5981\n","Epoch 51/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7812 - accuracy: 0.6943 - val_loss: 0.8692 - val_accuracy: 0.5961\n","Epoch 52/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7750 - accuracy: 0.6946 - val_loss: 0.8653 - val_accuracy: 0.6116\n","Epoch 53/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7685 - accuracy: 0.7072 - val_loss: 0.8781 - val_accuracy: 0.6023\n","Epoch 54/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7683 - accuracy: 0.6995 - val_loss: 0.8558 - val_accuracy: 0.6178\n","Epoch 55/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7674 - accuracy: 0.7034 - val_loss: 0.8695 - val_accuracy: 0.6167\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7621 - accuracy: 0.7080 - val_loss: 0.8576 - val_accuracy: 0.6105\n","Epoch 57/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7607 - accuracy: 0.7150 - val_loss: 0.8576 - val_accuracy: 0.6043\n","Epoch 58/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7617 - accuracy: 0.7065 - val_loss: 0.8577 - val_accuracy: 0.6012\n","Epoch 59/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7743 - accuracy: 0.6946 - val_loss: 0.8615 - val_accuracy: 0.5950\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7624 - accuracy: 0.7005 - val_loss: 0.8545 - val_accuracy: 0.6095\n","Epoch 61/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7591 - accuracy: 0.7047 - val_loss: 0.8646 - val_accuracy: 0.5899\n","Epoch 62/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7591 - accuracy: 0.7096 - val_loss: 0.8767 - val_accuracy: 0.5981\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7547 - accuracy: 0.7137 - val_loss: 0.8615 - val_accuracy: 0.6157\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7597 - accuracy: 0.7028 - val_loss: 0.8661 - val_accuracy: 0.6012\n","Epoch 65/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7524 - accuracy: 0.7158 - val_loss: 0.8707 - val_accuracy: 0.6147\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7549 - accuracy: 0.7075 - val_loss: 0.8909 - val_accuracy: 0.5919\n","Epoch 67/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7546 - accuracy: 0.6987 - val_loss: 0.8631 - val_accuracy: 0.6116\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7424 - accuracy: 0.7212 - val_loss: 0.8655 - val_accuracy: 0.6136\n","Epoch 69/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7455 - accuracy: 0.7160 - val_loss: 0.8582 - val_accuracy: 0.6054\n","Epoch 70/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7444 - accuracy: 0.7150 - val_loss: 0.8741 - val_accuracy: 0.6033\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7618 - accuracy: 0.6910 - val_loss: 0.9174 - val_accuracy: 0.5764\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7382 - accuracy: 0.7292 - val_loss: 0.8625 - val_accuracy: 0.5930\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7490 - accuracy: 0.7052 - val_loss: 0.9256 - val_accuracy: 0.5744\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7439 - accuracy: 0.7127 - val_loss: 0.8611 - val_accuracy: 0.5971\n","Epoch 75/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7339 - accuracy: 0.7233 - val_loss: 0.9124 - val_accuracy: 0.5723\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7405 - accuracy: 0.7072 - val_loss: 0.8624 - val_accuracy: 0.5981\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7369 - accuracy: 0.7145 - val_loss: 0.8619 - val_accuracy: 0.6023\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7282 - accuracy: 0.7313 - val_loss: 0.8829 - val_accuracy: 0.6116\n","Epoch 79/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7277 - accuracy: 0.7318 - val_loss: 0.8652 - val_accuracy: 0.6064\n","Epoch 80/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7233 - accuracy: 0.7359 - val_loss: 0.8680 - val_accuracy: 0.6023\n","Epoch 81/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7326 - accuracy: 0.7225 - val_loss: 0.8624 - val_accuracy: 0.5992\n","Epoch 82/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7235 - accuracy: 0.7320 - val_loss: 0.8652 - val_accuracy: 0.5992\n","Epoch 83/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7315 - accuracy: 0.7181 - val_loss: 0.8697 - val_accuracy: 0.6095\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7206 - accuracy: 0.7380 - val_loss: 0.8653 - val_accuracy: 0.6074\n","Epoch 85/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7185 - accuracy: 0.7388 - val_loss: 0.8677 - val_accuracy: 0.5961\n","Epoch 86/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7167 - accuracy: 0.7419 - val_loss: 0.8643 - val_accuracy: 0.6012\n","Epoch 87/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7298 - accuracy: 0.7220 - val_loss: 0.8645 - val_accuracy: 0.5981\n","Epoch 88/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7208 - accuracy: 0.7326 - val_loss: 0.8754 - val_accuracy: 0.5992\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7287 - accuracy: 0.7207 - val_loss: 0.8735 - val_accuracy: 0.5981\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7093 - accuracy: 0.7434 - val_loss: 0.8693 - val_accuracy: 0.5961\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7106 - accuracy: 0.7375 - val_loss: 0.8670 - val_accuracy: 0.5992\n","Epoch 92/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7116 - accuracy: 0.7439 - val_loss: 0.8746 - val_accuracy: 0.5971\n","Epoch 93/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7036 - accuracy: 0.7532 - val_loss: 0.8691 - val_accuracy: 0.6064\n","Epoch 94/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7082 - accuracy: 0.7408 - val_loss: 0.8694 - val_accuracy: 0.5930\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7016 - accuracy: 0.7481 - val_loss: 0.8744 - val_accuracy: 0.5940\n","Epoch 96/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6994 - accuracy: 0.7512 - val_loss: 0.8713 - val_accuracy: 0.6043\n","Epoch 97/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7009 - accuracy: 0.7530 - val_loss: 0.8780 - val_accuracy: 0.6012\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7020 - accuracy: 0.7437 - val_loss: 0.8778 - val_accuracy: 0.5992\n","Epoch 99/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6961 - accuracy: 0.7488 - val_loss: 0.9425 - val_accuracy: 0.5733\n","Epoch 100/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7084 - accuracy: 0.7354 - val_loss: 0.8697 - val_accuracy: 0.6012\n","{'loss': [0.8698598742485046, 0.8549624085426331, 0.8525962233543396, 0.8496395945549011, 0.8502976298332214, 0.8513336777687073, 0.8417412042617798, 0.8410735726356506, 0.8379395604133606, 0.8380349278450012, 0.8401186466217041, 0.8363473415374756, 0.8357834219932556, 0.8316221833229065, 0.8345147371292114, 0.8253777027130127, 0.8245521187782288, 0.8224270939826965, 0.8251309394836426, 0.838001012802124, 0.8284110426902771, 0.8174818754196167, 0.8163434863090515, 0.8181462287902832, 0.8124718070030212, 0.8137692809104919, 0.8078005313873291, 0.8113725185394287, 0.8111613392829895, 0.8101781010627747, 0.8105242252349854, 0.8006357550621033, 0.8007965683937073, 0.7953609228134155, 0.7961573004722595, 0.7979632616043091, 0.7949269413948059, 0.7922880053520203, 0.8000986576080322, 0.7973995208740234, 0.7862178087234497, 0.7890788912773132, 0.785554051399231, 0.7831456661224365, 0.7858691811561584, 0.7862545847892761, 0.7875642776489258, 0.7811876535415649, 0.7774561047554016, 0.7790210247039795, 0.7811970710754395, 0.7749505043029785, 0.7684791088104248, 0.7683169841766357, 0.7674409747123718, 0.7620651721954346, 0.7607162594795227, 0.7616767287254333, 0.7742538452148438, 0.7624450325965881, 0.7590767741203308, 0.7590562105178833, 0.7546851634979248, 0.7597235441207886, 0.7523519396781921, 0.7548767328262329, 0.7545802593231201, 0.7423574328422546, 0.7454774975776672, 0.7443533539772034, 0.7617653012275696, 0.7382199764251709, 0.7489521503448486, 0.7438639998435974, 0.733911395072937, 0.74054354429245, 0.7369138598442078, 0.7281796932220459, 0.7277461886405945, 0.7232608795166016, 0.7326316833496094, 0.7235234975814819, 0.7314644455909729, 0.7205906510353088, 0.718476414680481, 0.7166860699653625, 0.7297539710998535, 0.7207515239715576, 0.7286644577980042, 0.7093397974967957, 0.7105602025985718, 0.7116221785545349, 0.7036008238792419, 0.7081536650657654, 0.701649010181427, 0.6994078755378723, 0.7008737921714783, 0.7019719481468201, 0.6961039900779724, 0.7083768844604492], 'accuracy': [0.6144703030586243, 0.6472868323326111, 0.6418604850769043, 0.6418604850769043, 0.6372092962265015, 0.6338501572608948, 0.6627907156944275, 0.6648578643798828, 0.6563307642936707, 0.657622754573822, 0.643410861492157, 0.6560723781585693, 0.6589147448539734, 0.6627907156944275, 0.6509044170379639, 0.6718346476554871, 0.6692506670951843, 0.6739017963409424, 0.6656330823898315, 0.6343669295310974, 0.654780387878418, 0.6788113713264465, 0.6767441630363464, 0.6710594296455383, 0.6739017963409424, 0.6713178157806396, 0.6767441630363464, 0.6741601824760437, 0.6710594296455383, 0.6746770143508911, 0.6736434102058411, 0.6883720755577087, 0.685788094997406, 0.6901808977127075, 0.6863049268722534, 0.6870800852775574, 0.682170569896698, 0.6875969171524048, 0.6780361533164978, 0.6677002310752869, 0.6927648782730103, 0.6899224519729614, 0.6896640658378601, 0.6937984228134155, 0.6878553032875061, 0.6878553032875061, 0.683979332447052, 0.6904392838478088, 0.7010335922241211, 0.6914728879928589, 0.6943152546882629, 0.6945736408233643, 0.7072351574897766, 0.6994832158088684, 0.7033591866493225, 0.7080103158950806, 0.7149870991706848, 0.7064599394798279, 0.6945736408233643, 0.7005168199539185, 0.7046511769294739, 0.709560751914978, 0.7136951088905334, 0.7028423547744751, 0.7157622575759888, 0.7074935436248779, 0.6987079977989197, 0.7211886048316956, 0.7160206437110901, 0.7149870991706848, 0.6909560561180115, 0.7291989922523499, 0.7051679491996765, 0.7126615047454834, 0.7232558131217957, 0.7072351574897766, 0.7144702672958374, 0.7312661409378052, 0.7317829728126526, 0.735917329788208, 0.7224805951118469, 0.7320413589477539, 0.7180878520011902, 0.7379844784736633, 0.7387596964836121, 0.7418604493141174, 0.7219638228416443, 0.7325581312179565, 0.7206718325614929, 0.7434108257293701, 0.7374677062034607, 0.7439276576042175, 0.7532299757003784, 0.7408268451690674, 0.748062014579773, 0.7511627674102783, 0.7529715895652771, 0.7436692714691162, 0.7488372325897217, 0.7354004979133606], 'val_loss': [0.9201323390007019, 0.9218054413795471, 0.9217668175697327, 0.9218380451202393, 0.9254619479179382, 0.9258912801742554, 0.9272497892379761, 0.9289964437484741, 0.93697190284729, 0.9452613592147827, 0.9354473948478699, 0.9290528893470764, 0.9306247234344482, 0.9409671425819397, 0.9085792303085327, 0.9046894907951355, 0.8969370126724243, 0.8902611136436462, 0.9042335152626038, 0.8798590898513794, 0.8751060366630554, 0.8728373050689697, 0.869958758354187, 0.8664831519126892, 0.8647271990776062, 0.8648856282234192, 0.8616244792938232, 0.8614022731781006, 0.8721427321434021, 0.8599449992179871, 0.8577037453651428, 0.8660747408866882, 0.862798810005188, 0.8613285422325134, 0.8624494671821594, 0.8953434228897095, 0.8596399426460266, 0.8638058304786682, 0.9117494225502014, 0.8546881079673767, 0.8562302589416504, 0.8527569770812988, 0.8589702248573303, 0.8835995197296143, 0.8759192228317261, 0.8791048526763916, 0.8657498955726624, 0.8549708127975464, 0.8608198165893555, 0.8737739324569702, 0.8691794872283936, 0.8653081655502319, 0.8780813217163086, 0.8558005094528198, 0.8694891333580017, 0.8575680255889893, 0.8576463460922241, 0.857720673084259, 0.8614864945411682, 0.8544681668281555, 0.8645619750022888, 0.8766860961914062, 0.8615382313728333, 0.8660508990287781, 0.8707477450370789, 0.8908675909042358, 0.8630657196044922, 0.8654735088348389, 0.8581844568252563, 0.8740655779838562, 0.9173876643180847, 0.8625202775001526, 0.9255882501602173, 0.8610762357711792, 0.9123930335044861, 0.8623995780944824, 0.861871063709259, 0.8828659057617188, 0.8652418255805969, 0.8679630756378174, 0.862374484539032, 0.8652420043945312, 0.8697115182876587, 0.8652958869934082, 0.8677170276641846, 0.8642612099647522, 0.8645211458206177, 0.8754398226737976, 0.8735285401344299, 0.8693245649337769, 0.8669766783714294, 0.8746013641357422, 0.8691089153289795, 0.869422435760498, 0.8743686079978943, 0.8712769746780396, 0.878048837184906, 0.877774178981781, 0.9425337314605713, 0.869698166847229], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.48553720116615295, 0.5041322112083435, 0.5227272510528564, 0.5278925895690918, 0.5537189841270447, 0.5185950398445129, 0.577479362487793, 0.586776852607727, 0.5836777091026306, 0.5898760557174683, 0.6043388247489929, 0.5991735458374023, 0.5898760557174683, 0.6043388247489929, 0.6022727489471436, 0.5950413346290588, 0.6074380278587341, 0.6177685856819153, 0.60537189245224, 0.6126033067703247, 0.6136363744735718, 0.6105371713638306, 0.577479362487793, 0.6074380278587341, 0.6126033067703247, 0.5650826692581177, 0.60537189245224, 0.6002066135406494, 0.6167355179786682, 0.5981404781341553, 0.5940082669258118, 0.6033057570457458, 0.58574378490448, 0.6095041036605835, 0.6043388247489929, 0.5960744023323059, 0.5981404781341553, 0.5960744023323059, 0.6115702390670776, 0.6022727489471436, 0.6177685856819153, 0.6167355179786682, 0.6105371713638306, 0.6043388247489929, 0.6012396812438965, 0.5950413346290588, 0.6095041036605835, 0.5898760557174683, 0.5981404781341553, 0.6157024502754211, 0.6012396812438965, 0.6146694421768188, 0.5919421315193176, 0.6115702390670776, 0.6136363744735718, 0.60537189245224, 0.6033057570457458, 0.5764462947845459, 0.5929751992225647, 0.5743801593780518, 0.5971074104309082, 0.5723140239715576, 0.5981404781341553, 0.6022727489471436, 0.6115702390670776, 0.6064049601554871, 0.6022727489471436, 0.5991735458374023, 0.5991735458374023, 0.6095041036605835, 0.6074380278587341, 0.5960744023323059, 0.6012396812438965, 0.5981404781341553, 0.5991735458374023, 0.5981404781341553, 0.5960744023323059, 0.5991735458374023, 0.5971074104309082, 0.6064049601554871, 0.5929751992225647, 0.5940082669258118, 0.6043388247489929, 0.6012396812438965, 0.5991735458374023, 0.5733470916748047, 0.6012396812438965]}\n","32/32 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.7395 - accuracy: 0.7150"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 5s 35ms/step - loss: 0.7395 - accuracy: 0.7150 - val_loss: 0.8901 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7371 - accuracy: 0.7093 - val_loss: 0.8906 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7222 - accuracy: 0.7260 - val_loss: 0.8919 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7167 - accuracy: 0.7368 - val_loss: 0.8925 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7149 - accuracy: 0.7360 - val_loss: 0.8988 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7113 - accuracy: 0.7355 - val_loss: 0.9020 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.7092 - accuracy: 0.7357 - val_loss: 0.8979 - val_accuracy: 0.4871\n","Epoch 8/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7062 - accuracy: 0.7387 - val_loss: 0.9081 - val_accuracy: 0.4860\n","Epoch 9/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7032 - accuracy: 0.7422 - val_loss: 0.9109 - val_accuracy: 0.4871\n","Epoch 10/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7011 - accuracy: 0.7452 - val_loss: 0.9177 - val_accuracy: 0.4860\n","Epoch 11/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7020 - accuracy: 0.7371 - val_loss: 0.9349 - val_accuracy: 0.4871\n","Epoch 12/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6995 - accuracy: 0.7452 - val_loss: 0.9475 - val_accuracy: 0.4881\n","Epoch 13/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7204 - accuracy: 0.7255 - val_loss: 0.9884 - val_accuracy: 0.4860\n","Epoch 14/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.7125 - accuracy: 0.7196 - val_loss: 0.9568 - val_accuracy: 0.4946\n","Epoch 15/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.6945 - accuracy: 0.7495 - val_loss: 0.8862 - val_accuracy: 0.5302\n","Epoch 16/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.6926 - accuracy: 0.7465 - val_loss: 0.8715 - val_accuracy: 0.5528\n","Epoch 17/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6920 - accuracy: 0.7481 - val_loss: 0.8615 - val_accuracy: 0.5614\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6966 - accuracy: 0.7454 - val_loss: 0.8720 - val_accuracy: 0.5603\n","Epoch 19/100\n","29/29 [==============================] - 2s 63ms/step - loss: 0.7011 - accuracy: 0.7422 - val_loss: 0.8421 - val_accuracy: 0.5830\n","Epoch 20/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6949 - accuracy: 0.7462 - val_loss: 0.8364 - val_accuracy: 0.6024\n","Epoch 21/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6838 - accuracy: 0.7519 - val_loss: 0.8317 - val_accuracy: 0.6067\n","Epoch 22/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6872 - accuracy: 0.7538 - val_loss: 0.8409 - val_accuracy: 0.6228\n","Epoch 23/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6802 - accuracy: 0.7573 - val_loss: 0.8221 - val_accuracy: 0.6325\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6857 - accuracy: 0.7457 - val_loss: 0.8269 - val_accuracy: 0.6088\n","Epoch 25/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6865 - accuracy: 0.7470 - val_loss: 0.8759 - val_accuracy: 0.6185\n","Epoch 26/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6837 - accuracy: 0.7505 - val_loss: 0.8153 - val_accuracy: 0.6369\n","Epoch 27/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6761 - accuracy: 0.7562 - val_loss: 0.8276 - val_accuracy: 0.6466\n","Epoch 28/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6821 - accuracy: 0.7478 - val_loss: 0.8318 - val_accuracy: 0.6164\n","Epoch 29/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6931 - accuracy: 0.7400 - val_loss: 0.8160 - val_accuracy: 0.6584\n","Epoch 30/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6873 - accuracy: 0.7470 - val_loss: 0.8157 - val_accuracy: 0.6616\n","Epoch 31/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6757 - accuracy: 0.7651 - val_loss: 0.8163 - val_accuracy: 0.6541\n","Epoch 32/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6877 - accuracy: 0.7473 - val_loss: 0.8231 - val_accuracy: 0.6325\n","Epoch 33/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6685 - accuracy: 0.7651 - val_loss: 0.8139 - val_accuracy: 0.6444\n","Epoch 34/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6660 - accuracy: 0.7656 - val_loss: 0.8415 - val_accuracy: 0.6121\n","Epoch 35/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6671 - accuracy: 0.7627 - val_loss: 0.8608 - val_accuracy: 0.6422\n","Epoch 36/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6863 - accuracy: 0.7460 - val_loss: 0.8136 - val_accuracy: 0.6573\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6713 - accuracy: 0.7610 - val_loss: 0.8620 - val_accuracy: 0.5991\n","Epoch 38/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6836 - accuracy: 0.7470 - val_loss: 0.8684 - val_accuracy: 0.5938\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6786 - accuracy: 0.7505 - val_loss: 0.8269 - val_accuracy: 0.6282\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6553 - accuracy: 0.7759 - val_loss: 0.8155 - val_accuracy: 0.6552\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6547 - accuracy: 0.7737 - val_loss: 0.8336 - val_accuracy: 0.6325\n","Epoch 42/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6544 - accuracy: 0.7775 - val_loss: 0.8162 - val_accuracy: 0.6638\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6596 - accuracy: 0.7678 - val_loss: 0.8325 - val_accuracy: 0.6562\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6610 - accuracy: 0.7689 - val_loss: 0.8480 - val_accuracy: 0.6131\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6496 - accuracy: 0.7767 - val_loss: 0.8243 - val_accuracy: 0.6487\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6461 - accuracy: 0.7788 - val_loss: 0.8299 - val_accuracy: 0.6444\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6487 - accuracy: 0.7777 - val_loss: 0.8166 - val_accuracy: 0.6606\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6503 - accuracy: 0.7702 - val_loss: 0.8518 - val_accuracy: 0.6175\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6486 - accuracy: 0.7729 - val_loss: 0.8343 - val_accuracy: 0.6519\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6475 - accuracy: 0.7756 - val_loss: 0.8405 - val_accuracy: 0.6369\n","Epoch 51/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6471 - accuracy: 0.7726 - val_loss: 0.8223 - val_accuracy: 0.6509\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6423 - accuracy: 0.7788 - val_loss: 0.8223 - val_accuracy: 0.6466\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6390 - accuracy: 0.7893 - val_loss: 0.8619 - val_accuracy: 0.6196\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6364 - accuracy: 0.7831 - val_loss: 0.8426 - val_accuracy: 0.6185\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6417 - accuracy: 0.7796 - val_loss: 0.8205 - val_accuracy: 0.6530\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6353 - accuracy: 0.7794 - val_loss: 0.8411 - val_accuracy: 0.6239\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6291 - accuracy: 0.7864 - val_loss: 0.8551 - val_accuracy: 0.6185\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6302 - accuracy: 0.7950 - val_loss: 0.8413 - val_accuracy: 0.6412\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6304 - accuracy: 0.7829 - val_loss: 0.8367 - val_accuracy: 0.6336\n","Epoch 60/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6269 - accuracy: 0.7888 - val_loss: 0.8283 - val_accuracy: 0.6509\n","Epoch 61/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6341 - accuracy: 0.7877 - val_loss: 0.8385 - val_accuracy: 0.6498\n","Epoch 62/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6209 - accuracy: 0.7947 - val_loss: 0.8424 - val_accuracy: 0.6282\n","Epoch 63/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6238 - accuracy: 0.7918 - val_loss: 0.8368 - val_accuracy: 0.6412\n","Epoch 64/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6321 - accuracy: 0.7834 - val_loss: 0.8308 - val_accuracy: 0.6584\n","Epoch 65/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6172 - accuracy: 0.7966 - val_loss: 0.8355 - val_accuracy: 0.6466\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6131 - accuracy: 0.7980 - val_loss: 0.8318 - val_accuracy: 0.6584\n","Epoch 67/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6182 - accuracy: 0.7982 - val_loss: 0.8886 - val_accuracy: 0.6067\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6158 - accuracy: 0.7923 - val_loss: 0.8366 - val_accuracy: 0.6627\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6154 - accuracy: 0.7891 - val_loss: 0.8295 - val_accuracy: 0.6541\n","Epoch 70/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6102 - accuracy: 0.8001 - val_loss: 0.8352 - val_accuracy: 0.6541\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6186 - accuracy: 0.7934 - val_loss: 0.8643 - val_accuracy: 0.6509\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6223 - accuracy: 0.7861 - val_loss: 0.8346 - val_accuracy: 0.6530\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6043 - accuracy: 0.8015 - val_loss: 0.8464 - val_accuracy: 0.6412\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6023 - accuracy: 0.8068 - val_loss: 0.8365 - val_accuracy: 0.6487\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6177 - accuracy: 0.7901 - val_loss: 0.8457 - val_accuracy: 0.6466\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6006 - accuracy: 0.8055 - val_loss: 0.8403 - val_accuracy: 0.6466\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5959 - accuracy: 0.8090 - val_loss: 0.8413 - val_accuracy: 0.6466\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5992 - accuracy: 0.8041 - val_loss: 0.8716 - val_accuracy: 0.6562\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6071 - accuracy: 0.8012 - val_loss: 0.8786 - val_accuracy: 0.6509\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6025 - accuracy: 0.7966 - val_loss: 0.8733 - val_accuracy: 0.6476\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5917 - accuracy: 0.8147 - val_loss: 0.8614 - val_accuracy: 0.6358\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5883 - accuracy: 0.8144 - val_loss: 0.8500 - val_accuracy: 0.6519\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5870 - accuracy: 0.8120 - val_loss: 0.8772 - val_accuracy: 0.6218\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5891 - accuracy: 0.8120 - val_loss: 0.8790 - val_accuracy: 0.6196\n","Epoch 85/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5866 - accuracy: 0.8085 - val_loss: 0.8601 - val_accuracy: 0.6412\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5780 - accuracy: 0.8235 - val_loss: 0.8670 - val_accuracy: 0.6272\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5837 - accuracy: 0.8133 - val_loss: 0.8811 - val_accuracy: 0.6498\n","Epoch 88/100\n","29/29 [==============================] - 1s 45ms/step - loss: 0.5865 - accuracy: 0.8152 - val_loss: 0.8616 - val_accuracy: 0.6649\n","Epoch 89/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5916 - accuracy: 0.8047 - val_loss: 0.8966 - val_accuracy: 0.6519\n","Epoch 90/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5876 - accuracy: 0.8136 - val_loss: 0.8635 - val_accuracy: 0.6336\n","Epoch 91/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5745 - accuracy: 0.8230 - val_loss: 0.8999 - val_accuracy: 0.6272\n","Epoch 92/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5749 - accuracy: 0.8233 - val_loss: 0.8553 - val_accuracy: 0.6541\n","Epoch 93/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5735 - accuracy: 0.8287 - val_loss: 0.8567 - val_accuracy: 0.6606\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5649 - accuracy: 0.8314 - val_loss: 0.8746 - val_accuracy: 0.6401\n","Epoch 95/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5938 - accuracy: 0.8033 - val_loss: 0.9244 - val_accuracy: 0.6142\n","Epoch 96/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5837 - accuracy: 0.8165 - val_loss: 0.8603 - val_accuracy: 0.6616\n","Epoch 97/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5658 - accuracy: 0.8254 - val_loss: 0.8558 - val_accuracy: 0.6476\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5649 - accuracy: 0.8297 - val_loss: 0.8785 - val_accuracy: 0.6293\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5672 - accuracy: 0.8254 - val_loss: 0.8605 - val_accuracy: 0.6412\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5591 - accuracy: 0.8303 - val_loss: 0.8673 - val_accuracy: 0.6498\n","{'loss': [0.7394958734512329, 0.7371186017990112, 0.7221835851669312, 0.7167074680328369, 0.7149267792701721, 0.7113479971885681, 0.7092050909996033, 0.7061988115310669, 0.7031856775283813, 0.7011078596115112, 0.7019910216331482, 0.6995473504066467, 0.7203968167304993, 0.7125083804130554, 0.6944982409477234, 0.6926324963569641, 0.6919596195220947, 0.6966358423233032, 0.7010822892189026, 0.6948651075363159, 0.6838259100914001, 0.6871993541717529, 0.6801563501358032, 0.6856697797775269, 0.6864930391311646, 0.6836629509925842, 0.6760671138763428, 0.6820997595787048, 0.6931386590003967, 0.6873431205749512, 0.675701916217804, 0.6876985430717468, 0.6684938669204712, 0.6659507751464844, 0.6671338677406311, 0.6863430142402649, 0.6712988018989563, 0.6835850477218628, 0.6786122918128967, 0.6552983522415161, 0.6546736359596252, 0.6544212102890015, 0.6595550179481506, 0.6610394716262817, 0.6495817303657532, 0.6460914611816406, 0.6486801505088806, 0.650260865688324, 0.6485555768013, 0.6474939584732056, 0.647143542766571, 0.6422536373138428, 0.6389884352684021, 0.6363967657089233, 0.6416666507720947, 0.6352607011795044, 0.6290714740753174, 0.6301581859588623, 0.6303507089614868, 0.6269174814224243, 0.634054958820343, 0.6208567023277283, 0.6238006353378296, 0.6320745944976807, 0.6172041296958923, 0.6130830645561218, 0.6181522607803345, 0.6157787442207336, 0.6154144406318665, 0.6102398037910461, 0.6186487078666687, 0.6223062872886658, 0.6042569279670715, 0.6022557020187378, 0.6177194714546204, 0.6006208062171936, 0.5959324836730957, 0.5991585850715637, 0.6071069836616516, 0.6024930477142334, 0.5917420983314514, 0.5882508754730225, 0.587048351764679, 0.5890832543373108, 0.586551308631897, 0.5780327916145325, 0.5837468504905701, 0.586527943611145, 0.5915566086769104, 0.587611734867096, 0.5744999647140503, 0.5749487280845642, 0.5735005736351013, 0.564919650554657, 0.5938014388084412, 0.5837035775184631, 0.5657573938369751, 0.5648725032806396, 0.5672174692153931, 0.5590790510177612], 'accuracy': [0.7149784564971924, 0.709321141242981, 0.7260237336158752, 0.7367995977401733, 0.735991358757019, 0.7354525923728943, 0.735722005367279, 0.7386853694915771, 0.7421875, 0.7451508641242981, 0.7370689511299133, 0.7451508641242981, 0.7254849076271057, 0.7195581793785095, 0.7494612336158752, 0.7464978694915771, 0.7481142282485962, 0.7454202771186829, 0.7421875, 0.7462284564971924, 0.7518857717514038, 0.7537715435028076, 0.7572737336158752, 0.7456896305084229, 0.7470366358757019, 0.7505387663841248, 0.756196141242981, 0.7478448152542114, 0.7400323152542114, 0.7470366358757019, 0.7650862336158752, 0.7473060488700867, 0.7650862336158752, 0.765625, 0.7626616358757019, 0.7459590435028076, 0.7610452771186829, 0.7470366358757019, 0.7505387663841248, 0.7758620977401733, 0.7737069129943848, 0.7774784564971924, 0.7677801847457886, 0.7688577771186829, 0.7766702771186829, 0.7788254022598267, 0.7777478694915771, 0.7702047228813171, 0.7728987336158752, 0.7755926847457886, 0.7726293206214905, 0.7788254022598267, 0.7893319129943848, 0.7831357717514038, 0.779633641242981, 0.7793642282485962, 0.7863685488700867, 0.7949892282485962, 0.782866358757019, 0.7887930870056152, 0.787715494632721, 0.7947198152542114, 0.7917564511299133, 0.7834051847457886, 0.7966055870056152, 0.7979525923728943, 0.798222005367279, 0.7922952771186829, 0.7890625, 0.8001077771186829, 0.7933728694915771, 0.7860991358757019, 0.8014547228813171, 0.8068426847457886, 0.7901400923728943, 0.8054956793785095, 0.8089978694915771, 0.8041487336158752, 0.8011853694915771, 0.7966055870056152, 0.8146551847457886, 0.8143857717514038, 0.8119612336158752, 0.8119612336158752, 0.8084590435028076, 0.8235452771186829, 0.8133081793785095, 0.8151939511299133, 0.8046875, 0.8135775923728943, 0.8230064511299133, 0.8232758641242981, 0.8286637663841248, 0.8313577771186829, 0.803340494632721, 0.8165409564971924, 0.8254310488700867, 0.829741358757019, 0.8254310488700867, 0.8302801847457886], 'val_loss': [0.8900858163833618, 0.8905577659606934, 0.8919479846954346, 0.8924795389175415, 0.8988381028175354, 0.9020081162452698, 0.8979016542434692, 0.9080784320831299, 0.9108541011810303, 0.9176639914512634, 0.9348737597465515, 0.9475468993186951, 0.9884408116340637, 0.9567543268203735, 0.886188268661499, 0.8714786171913147, 0.8614563345909119, 0.872044026851654, 0.8421469926834106, 0.8364198803901672, 0.8316524028778076, 0.8408604860305786, 0.8220962285995483, 0.826897382736206, 0.8758772611618042, 0.8152775168418884, 0.8275965452194214, 0.8317936658859253, 0.8160368204116821, 0.8156997561454773, 0.8162878751754761, 0.823050856590271, 0.813870906829834, 0.841453492641449, 0.8607996702194214, 0.8136328458786011, 0.8619944453239441, 0.8684244751930237, 0.826896071434021, 0.8154857158660889, 0.8336417078971863, 0.8161934018135071, 0.8325029611587524, 0.8480433225631714, 0.824262797832489, 0.8298963904380798, 0.8165987730026245, 0.8517792820930481, 0.8342996835708618, 0.840531587600708, 0.8223466277122498, 0.822297990322113, 0.8618707060813904, 0.8426384925842285, 0.8204874396324158, 0.8410916328430176, 0.8551321625709534, 0.8412547707557678, 0.8366965651512146, 0.8282711505889893, 0.8385137319564819, 0.8423848748207092, 0.836834728717804, 0.8308151364326477, 0.8354653716087341, 0.8318060636520386, 0.8886046409606934, 0.8366497755050659, 0.82951819896698, 0.8351643681526184, 0.8643006086349487, 0.8345692157745361, 0.8463636040687561, 0.8364642858505249, 0.8457488417625427, 0.84028559923172, 0.841347873210907, 0.8715821504592896, 0.8785914778709412, 0.8733150362968445, 0.8613982200622559, 0.8499958515167236, 0.8772379755973816, 0.8790081143379211, 0.8601375818252563, 0.8669702410697937, 0.8810636401176453, 0.8616194725036621, 0.8965599536895752, 0.8635024428367615, 0.8998671770095825, 0.8553305268287659, 0.8567360043525696, 0.8746173977851868, 0.9244185090065002, 0.8602676391601562, 0.8557958006858826, 0.8784738183021545, 0.8604933023452759, 0.8672538995742798], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48706895112991333, 0.48599138855934143, 0.48706895112991333, 0.48599138855934143, 0.48706895112991333, 0.4881465435028076, 0.48599138855934143, 0.49461206793785095, 0.5301724076271057, 0.5528017282485962, 0.5614224076271057, 0.5603448152542114, 0.5829741358757019, 0.6023706793785095, 0.6066810488700867, 0.6228448152542114, 0.6325430870056152, 0.6088362336158752, 0.618534505367279, 0.6368534564971924, 0.6465517282485962, 0.6163793206214905, 0.6584051847457886, 0.6616379022598267, 0.6540948152542114, 0.6325430870056152, 0.6443965435028076, 0.6120689511299133, 0.642241358757019, 0.6573275923728943, 0.5991379022598267, 0.59375, 0.6282327771186829, 0.6551724076271057, 0.6325430870056152, 0.6637930870056152, 0.65625, 0.6131465435028076, 0.6487069129943848, 0.6443965435028076, 0.6605603694915771, 0.6174569129943848, 0.6519396305084229, 0.6368534564971924, 0.6508620977401733, 0.6465517282485962, 0.6196120977401733, 0.618534505367279, 0.6530172228813171, 0.6239224076271057, 0.618534505367279, 0.6411637663841248, 0.6336206793785095, 0.6508620977401733, 0.649784505367279, 0.6282327771186829, 0.6411637663841248, 0.6584051847457886, 0.6465517282485962, 0.6584051847457886, 0.6066810488700867, 0.662715494632721, 0.6540948152542114, 0.6540948152542114, 0.6508620977401733, 0.6530172228813171, 0.6411637663841248, 0.6487069129943848, 0.6465517282485962, 0.6465517282485962, 0.6465517282485962, 0.65625, 0.6508620977401733, 0.6476293206214905, 0.6357758641242981, 0.6519396305084229, 0.6217672228813171, 0.6196120977401733, 0.6411637663841248, 0.6271551847457886, 0.649784505367279, 0.6648706793785095, 0.6519396305084229, 0.6336206793785095, 0.6271551847457886, 0.6540948152542114, 0.6605603694915771, 0.6400862336158752, 0.6142241358757019, 0.6616379022598267, 0.6476293206214905, 0.6293103694915771, 0.6411637663841248, 0.649784505367279]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.7534 - accuracy: 0.7098"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 4s 47ms/step - loss: 0.7525 - accuracy: 0.7100 - val_loss: 0.8854 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7280 - accuracy: 0.7224 - val_loss: 0.8863 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7270 - accuracy: 0.7230 - val_loss: 0.8866 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.7214 - accuracy: 0.7405 - val_loss: 0.8866 - val_accuracy: 0.4966\n","Epoch 5/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7160 - accuracy: 0.7425 - val_loss: 0.8912 - val_accuracy: 0.4966\n","Epoch 6/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7120 - accuracy: 0.7431 - val_loss: 0.8945 - val_accuracy: 0.4966\n","Epoch 7/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7124 - accuracy: 0.7388 - val_loss: 0.8967 - val_accuracy: 0.4966\n","Epoch 8/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7077 - accuracy: 0.7496 - val_loss: 0.9110 - val_accuracy: 0.4966\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7092 - accuracy: 0.7411 - val_loss: 0.9041 - val_accuracy: 0.4966\n","Epoch 10/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7179 - accuracy: 0.7286 - val_loss: 0.9146 - val_accuracy: 0.4966\n","Epoch 11/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7061 - accuracy: 0.7465 - val_loss: 0.9091 - val_accuracy: 0.4977\n","Epoch 12/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.7120 - accuracy: 0.7332 - val_loss: 0.9086 - val_accuracy: 0.5023\n","Epoch 13/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7197 - accuracy: 0.7281 - val_loss: 0.9397 - val_accuracy: 0.4977\n","Epoch 14/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7001 - accuracy: 0.7470 - val_loss: 0.9452 - val_accuracy: 0.4989\n","Epoch 15/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6960 - accuracy: 0.7566 - val_loss: 0.9347 - val_accuracy: 0.5102\n","Epoch 16/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6959 - accuracy: 0.7586 - val_loss: 0.9054 - val_accuracy: 0.5181\n","Epoch 17/100\n","28/28 [==============================] - 2s 67ms/step - loss: 0.6951 - accuracy: 0.7501 - val_loss: 0.9034 - val_accuracy: 0.5204\n","Epoch 18/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6942 - accuracy: 0.7535 - val_loss: 0.8589 - val_accuracy: 0.5679\n","Epoch 19/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6997 - accuracy: 0.7385 - val_loss: 0.8481 - val_accuracy: 0.5769\n","Epoch 20/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6912 - accuracy: 0.7555 - val_loss: 0.8645 - val_accuracy: 0.5690\n","Epoch 21/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6887 - accuracy: 0.7550 - val_loss: 0.8544 - val_accuracy: 0.5894\n","Epoch 22/100\n","28/28 [==============================] - 1s 39ms/step - loss: 0.6861 - accuracy: 0.7581 - val_loss: 0.8383 - val_accuracy: 0.6018\n","Epoch 23/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.6850 - accuracy: 0.7600 - val_loss: 0.8378 - val_accuracy: 0.6165\n","Epoch 24/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.6821 - accuracy: 0.7589 - val_loss: 0.8341 - val_accuracy: 0.6233\n","Epoch 25/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6811 - accuracy: 0.7603 - val_loss: 0.8375 - val_accuracy: 0.6244\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6900 - accuracy: 0.7538 - val_loss: 0.8338 - val_accuracy: 0.6188\n","Epoch 27/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6785 - accuracy: 0.7643 - val_loss: 0.8580 - val_accuracy: 0.6052\n","Epoch 28/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6751 - accuracy: 0.7646 - val_loss: 0.8556 - val_accuracy: 0.6131\n","Epoch 29/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6866 - accuracy: 0.7521 - val_loss: 0.8207 - val_accuracy: 0.6380\n","Epoch 30/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6869 - accuracy: 0.7558 - val_loss: 0.8946 - val_accuracy: 0.6041\n","Epoch 31/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6765 - accuracy: 0.7660 - val_loss: 0.8197 - val_accuracy: 0.6380\n","Epoch 32/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6690 - accuracy: 0.7756 - val_loss: 0.8200 - val_accuracy: 0.6471\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6748 - accuracy: 0.7615 - val_loss: 0.8355 - val_accuracy: 0.6312\n","Epoch 34/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6714 - accuracy: 0.7714 - val_loss: 0.8272 - val_accuracy: 0.6290\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6656 - accuracy: 0.7725 - val_loss: 0.8285 - val_accuracy: 0.6459\n","Epoch 36/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6612 - accuracy: 0.7793 - val_loss: 0.8256 - val_accuracy: 0.6448\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6654 - accuracy: 0.7736 - val_loss: 0.8242 - val_accuracy: 0.6425\n","Epoch 38/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6598 - accuracy: 0.7773 - val_loss: 0.8499 - val_accuracy: 0.6369\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6756 - accuracy: 0.7617 - val_loss: 0.8233 - val_accuracy: 0.6403\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6650 - accuracy: 0.7742 - val_loss: 0.8390 - val_accuracy: 0.6369\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6644 - accuracy: 0.7654 - val_loss: 0.8276 - val_accuracy: 0.6346\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6560 - accuracy: 0.7810 - val_loss: 0.8465 - val_accuracy: 0.6312\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6569 - accuracy: 0.7753 - val_loss: 0.8319 - val_accuracy: 0.6459\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6592 - accuracy: 0.7657 - val_loss: 0.8559 - val_accuracy: 0.6233\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6517 - accuracy: 0.7799 - val_loss: 0.8282 - val_accuracy: 0.6403\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6584 - accuracy: 0.7702 - val_loss: 0.8352 - val_accuracy: 0.6448\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6444 - accuracy: 0.7838 - val_loss: 0.8416 - val_accuracy: 0.6301\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6696 - accuracy: 0.7629 - val_loss: 0.8395 - val_accuracy: 0.6335\n","Epoch 49/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6466 - accuracy: 0.7835 - val_loss: 0.8399 - val_accuracy: 0.6425\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6486 - accuracy: 0.7759 - val_loss: 0.8308 - val_accuracy: 0.6437\n","Epoch 51/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6417 - accuracy: 0.7869 - val_loss: 0.8307 - val_accuracy: 0.6335\n","Epoch 52/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6514 - accuracy: 0.7711 - val_loss: 0.8344 - val_accuracy: 0.6437\n","Epoch 53/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6329 - accuracy: 0.7915 - val_loss: 0.8323 - val_accuracy: 0.6380\n","Epoch 54/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6383 - accuracy: 0.7892 - val_loss: 0.8581 - val_accuracy: 0.6335\n","Epoch 55/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6365 - accuracy: 0.7810 - val_loss: 0.8326 - val_accuracy: 0.6324\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6345 - accuracy: 0.7895 - val_loss: 0.8339 - val_accuracy: 0.6459\n","Epoch 57/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6232 - accuracy: 0.7977 - val_loss: 0.8390 - val_accuracy: 0.6369\n","Epoch 58/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6271 - accuracy: 0.8019 - val_loss: 0.8693 - val_accuracy: 0.6244\n","Epoch 59/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6336 - accuracy: 0.7886 - val_loss: 0.8355 - val_accuracy: 0.6403\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6390 - accuracy: 0.7773 - val_loss: 0.8783 - val_accuracy: 0.6210\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6285 - accuracy: 0.7963 - val_loss: 0.8506 - val_accuracy: 0.6425\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6215 - accuracy: 0.7991 - val_loss: 0.8500 - val_accuracy: 0.6290\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6235 - accuracy: 0.7991 - val_loss: 0.8410 - val_accuracy: 0.6335\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6157 - accuracy: 0.8062 - val_loss: 0.8890 - val_accuracy: 0.6154\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6229 - accuracy: 0.7892 - val_loss: 0.8499 - val_accuracy: 0.6391\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6252 - accuracy: 0.7977 - val_loss: 0.8378 - val_accuracy: 0.6437\n","Epoch 67/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6255 - accuracy: 0.7909 - val_loss: 0.8692 - val_accuracy: 0.6380\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6176 - accuracy: 0.7980 - val_loss: 0.8718 - val_accuracy: 0.6244\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6170 - accuracy: 0.7900 - val_loss: 0.8518 - val_accuracy: 0.6357\n","Epoch 70/100\n","28/28 [==============================] - 1s 50ms/step - loss: 0.6073 - accuracy: 0.8101 - val_loss: 0.8501 - val_accuracy: 0.6482\n","Epoch 71/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6046 - accuracy: 0.8079 - val_loss: 0.8568 - val_accuracy: 0.6312\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6080 - accuracy: 0.8039 - val_loss: 0.8520 - val_accuracy: 0.6369\n","Epoch 73/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6203 - accuracy: 0.7963 - val_loss: 0.8789 - val_accuracy: 0.6391\n","Epoch 74/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6130 - accuracy: 0.7994 - val_loss: 0.8615 - val_accuracy: 0.6403\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6039 - accuracy: 0.8056 - val_loss: 0.8476 - val_accuracy: 0.6301\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6068 - accuracy: 0.8062 - val_loss: 0.8473 - val_accuracy: 0.6312\n","Epoch 77/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5946 - accuracy: 0.8127 - val_loss: 0.8452 - val_accuracy: 0.6290\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6045 - accuracy: 0.8079 - val_loss: 0.8476 - val_accuracy: 0.6244\n","Epoch 79/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6050 - accuracy: 0.8008 - val_loss: 0.9027 - val_accuracy: 0.6222\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6028 - accuracy: 0.8053 - val_loss: 0.8521 - val_accuracy: 0.6369\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6067 - accuracy: 0.7985 - val_loss: 0.9025 - val_accuracy: 0.6165\n","Epoch 82/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5901 - accuracy: 0.8166 - val_loss: 0.8521 - val_accuracy: 0.6278\n","Epoch 83/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5824 - accuracy: 0.8206 - val_loss: 0.8541 - val_accuracy: 0.6312\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5803 - accuracy: 0.8316 - val_loss: 0.8566 - val_accuracy: 0.6324\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5873 - accuracy: 0.8161 - val_loss: 0.8603 - val_accuracy: 0.6290\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5748 - accuracy: 0.8316 - val_loss: 0.8585 - val_accuracy: 0.6267\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5987 - accuracy: 0.8036 - val_loss: 0.8874 - val_accuracy: 0.6233\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6074 - accuracy: 0.7949 - val_loss: 0.8874 - val_accuracy: 0.6222\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5849 - accuracy: 0.8231 - val_loss: 0.8587 - val_accuracy: 0.6290\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5845 - accuracy: 0.8175 - val_loss: 0.8923 - val_accuracy: 0.6290\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5837 - accuracy: 0.8195 - val_loss: 0.8625 - val_accuracy: 0.6471\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5675 - accuracy: 0.8331 - val_loss: 0.8641 - val_accuracy: 0.6210\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5716 - accuracy: 0.8257 - val_loss: 0.8713 - val_accuracy: 0.6165\n","Epoch 94/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5768 - accuracy: 0.8229 - val_loss: 0.8580 - val_accuracy: 0.6278\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5702 - accuracy: 0.8246 - val_loss: 0.8691 - val_accuracy: 0.6176\n","Epoch 96/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5733 - accuracy: 0.8186 - val_loss: 0.8854 - val_accuracy: 0.6324\n","Epoch 97/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5594 - accuracy: 0.8381 - val_loss: 0.8801 - val_accuracy: 0.6210\n","Epoch 98/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5622 - accuracy: 0.8322 - val_loss: 0.8807 - val_accuracy: 0.6278\n","Epoch 99/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5603 - accuracy: 0.8339 - val_loss: 0.8902 - val_accuracy: 0.6335\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5752 - accuracy: 0.8132 - val_loss: 0.8857 - val_accuracy: 0.6165\n","{'loss': [0.7524669170379639, 0.7280189394950867, 0.7269842028617859, 0.7213969826698303, 0.7159767746925354, 0.712040364742279, 0.7123516201972961, 0.7076560854911804, 0.7091599106788635, 0.7179000377655029, 0.7061364054679871, 0.7120020985603333, 0.7197458148002625, 0.700069785118103, 0.6960114240646362, 0.6958788633346558, 0.6951013803482056, 0.6941630244255066, 0.6997300386428833, 0.6912367939949036, 0.6886993050575256, 0.6860852837562561, 0.6849756240844727, 0.6820811033248901, 0.6810905933380127, 0.6899521946907043, 0.6784594058990479, 0.6750876307487488, 0.6866180896759033, 0.6868659257888794, 0.6765155792236328, 0.6690201759338379, 0.6747605204582214, 0.6714149713516235, 0.6656072735786438, 0.6612066030502319, 0.6654345393180847, 0.6598203182220459, 0.6755584478378296, 0.6649783253669739, 0.664357602596283, 0.655990719795227, 0.6568806171417236, 0.6592126488685608, 0.6516615748405457, 0.6583836674690247, 0.6444381475448608, 0.6695796251296997, 0.6465536952018738, 0.6486451029777527, 0.6417111158370972, 0.651427149772644, 0.6328528523445129, 0.6383399963378906, 0.6364547610282898, 0.6345171928405762, 0.6232219934463501, 0.6270694136619568, 0.6335766315460205, 0.6389994621276855, 0.6284969449043274, 0.6214586496353149, 0.6234856843948364, 0.6157400608062744, 0.6229369640350342, 0.6251575350761414, 0.6254668235778809, 0.6176163554191589, 0.6169816255569458, 0.607333242893219, 0.6046416163444519, 0.6080066561698914, 0.6203012466430664, 0.6130385398864746, 0.6039016842842102, 0.6068317890167236, 0.5946270823478699, 0.6044816970825195, 0.6049575209617615, 0.6028144359588623, 0.6067155599594116, 0.5901355147361755, 0.5823655724525452, 0.5802834630012512, 0.5872766971588135, 0.5748000741004944, 0.5987167954444885, 0.6073875427246094, 0.5849435329437256, 0.5844720602035522, 0.5837164521217346, 0.5674623250961304, 0.5715814828872681, 0.5767683386802673, 0.5701826214790344, 0.5732898712158203, 0.5594250559806824, 0.5622368454933167, 0.5603450536727905, 0.5751917958259583], 'accuracy': [0.709960401058197, 0.7224108576774597, 0.722976803779602, 0.7405206561088562, 0.742501437664032, 0.7430673241615295, 0.738822877407074, 0.7495755553245544, 0.7410866022109985, 0.7286360859870911, 0.7464629411697388, 0.7331635355949402, 0.7280701994895935, 0.7470288872718811, 0.7566496729850769, 0.7586304545402527, 0.7501415014266968, 0.7535370588302612, 0.7385398745536804, 0.755517840385437, 0.7549518942832947, 0.7580645084381104, 0.7600452899932861, 0.7589133977890015, 0.7603282332420349, 0.7538200616836548, 0.7642897367477417, 0.7645727396011353, 0.7521222233772278, 0.7558007836341858, 0.7659875750541687, 0.7756083607673645, 0.7614601254463196, 0.7713639140129089, 0.7724957466125488, 0.7792869210243225, 0.7736276388168335, 0.7773061394691467, 0.7617430686950684, 0.774193525314331, 0.7654216289520264, 0.7809846997261047, 0.7753254175186157, 0.7657045722007751, 0.7798528671264648, 0.7702320218086243, 0.7838143706321716, 0.7628749012947083, 0.7835314273834229, 0.7758913636207581, 0.7869269847869873, 0.7710809111595154, 0.7914544343948364, 0.7891907095909119, 0.7809846997261047, 0.7894737124443054, 0.7976796627044678, 0.8019241690635681, 0.7886247634887695, 0.7773061394691467, 0.7962648272514343, 0.7990944981575012, 0.7990944981575012, 0.8061686754226685, 0.7891907095909119, 0.7976796627044678, 0.7908884882926941, 0.7979626655578613, 0.790039598941803, 0.8101301789283752, 0.8078664541244507, 0.8039049506187439, 0.7962648272514343, 0.7993775010108948, 0.8056027293205261, 0.8061686754226685, 0.8126768469810486, 0.8078664541244507, 0.8007922768592834, 0.8053197264671326, 0.7985285520553589, 0.8166383504867554, 0.8205999135971069, 0.8316355347633362, 0.8160724639892578, 0.8316355347633362, 0.8036219477653503, 0.7948500514030457, 0.8231465816497803, 0.8174872398376465, 0.8194680213928223, 0.8330503702163696, 0.8256932497024536, 0.8228636384010315, 0.8245614171028137, 0.8186191320419312, 0.8381437659263611, 0.8322014808654785, 0.8338992595672607, 0.8132427930831909], 'val_loss': [0.8853689432144165, 0.8863347768783569, 0.8865893483161926, 0.8866495490074158, 0.8911925554275513, 0.8944776058197021, 0.896722674369812, 0.9109542369842529, 0.90410315990448, 0.9145545363426208, 0.9091410636901855, 0.9085876941680908, 0.9396683573722839, 0.9452463388442993, 0.9346624612808228, 0.9053945541381836, 0.9034451246261597, 0.858882486820221, 0.8481431007385254, 0.8644745349884033, 0.8543919920921326, 0.8382721543312073, 0.8378405570983887, 0.834130585193634, 0.8374820947647095, 0.8338184356689453, 0.8579798340797424, 0.8556499481201172, 0.8207219243049622, 0.8945858478546143, 0.8197422623634338, 0.8200057148933411, 0.8354746103286743, 0.8272175788879395, 0.8285059332847595, 0.8256129622459412, 0.8241987824440002, 0.849865734577179, 0.8233024477958679, 0.8389766216278076, 0.827629804611206, 0.8465016484260559, 0.8318683505058289, 0.8558875322341919, 0.8281643390655518, 0.8351711630821228, 0.8416294455528259, 0.8394989371299744, 0.83992600440979, 0.8308023810386658, 0.8306849598884583, 0.8344064354896545, 0.8322895169258118, 0.8580779433250427, 0.8325902819633484, 0.833926260471344, 0.83896803855896, 0.8693047165870667, 0.835476815700531, 0.8783499002456665, 0.8505867719650269, 0.8499820828437805, 0.8410438299179077, 0.8889850378036499, 0.8499132990837097, 0.8377673029899597, 0.8691794872283936, 0.871809720993042, 0.851847231388092, 0.8501173257827759, 0.8568036556243896, 0.8519613146781921, 0.8788841366767883, 0.8615120649337769, 0.8475767970085144, 0.8473252058029175, 0.845206081867218, 0.8475637435913086, 0.9027018547058105, 0.8521227836608887, 0.9025371670722961, 0.8521186113357544, 0.8540597558021545, 0.8566389083862305, 0.8603261709213257, 0.858506977558136, 0.8874271512031555, 0.8874136805534363, 0.8586885333061218, 0.8922738432884216, 0.862521767616272, 0.8641142249107361, 0.8713412284851074, 0.8579962253570557, 0.8690534234046936, 0.8853874802589417, 0.8801467418670654, 0.8806515336036682, 0.890160322189331, 0.8857329487800598], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.49660632014274597, 0.49660632014274597, 0.49660632014274597, 0.49660632014274597, 0.49660632014274597, 0.49660632014274597, 0.4977375566959381, 0.5022624731063843, 0.4977375566959381, 0.49886876344680786, 0.5101810097694397, 0.5180995464324951, 0.5203620195388794, 0.5678732991218567, 0.5769230723381042, 0.5690045356750488, 0.5893664956092834, 0.6018099784851074, 0.6165158152580261, 0.6233031749725342, 0.6244344115257263, 0.6187782883644104, 0.6052036285400391, 0.6131221652030945, 0.6380090713500977, 0.6040723919868469, 0.6380090713500977, 0.6470588445663452, 0.6312217116355896, 0.6289592981338501, 0.6459276080131531, 0.6447963714599609, 0.6425339579582214, 0.6368778347969055, 0.6402714848518372, 0.6368778347969055, 0.6346153616905212, 0.6312217116355896, 0.6459276080131531, 0.6233031749725342, 0.6402714848518372, 0.6447963714599609, 0.6300904750823975, 0.6334841847419739, 0.6425339579582214, 0.6436651349067688, 0.6334841847419739, 0.6436651349067688, 0.6380090713500977, 0.6334841847419739, 0.6323529481887817, 0.6459276080131531, 0.6368778347969055, 0.6244344115257263, 0.6402714848518372, 0.6210407018661499, 0.6425339579582214, 0.6289592981338501, 0.6334841847419739, 0.6153846383094788, 0.639140248298645, 0.6436651349067688, 0.6380090713500977, 0.6244344115257263, 0.6357465982437134, 0.6481900215148926, 0.6312217116355896, 0.6368778347969055, 0.639140248298645, 0.6402714848518372, 0.6300904750823975, 0.6312217116355896, 0.6289592981338501, 0.6244344115257263, 0.622171938419342, 0.6368778347969055, 0.6165158152580261, 0.627828061580658, 0.6312217116355896, 0.6323529481887817, 0.6289592981338501, 0.6266968250274658, 0.6233031749725342, 0.622171938419342, 0.6289592981338501, 0.6289592981338501, 0.6470588445663452, 0.6210407018661499, 0.6165158152580261, 0.627828061580658, 0.6176470518112183, 0.6323529481887817, 0.6210407018661499, 0.627828061580658, 0.6334841847419739, 0.6165158152580261]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 35ms/step - loss: 0.7586 - accuracy: 0.6992 - val_loss: 0.8894 - val_accuracy: 0.4855\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7380 - accuracy: 0.7132 - val_loss: 0.8917 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7320 - accuracy: 0.7235 - val_loss: 0.8950 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7298 - accuracy: 0.7183 - val_loss: 0.8969 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7287 - accuracy: 0.7243 - val_loss: 0.9068 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7284 - accuracy: 0.7178 - val_loss: 0.9021 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7311 - accuracy: 0.7165 - val_loss: 0.9148 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7192 - accuracy: 0.7307 - val_loss: 0.9259 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7215 - accuracy: 0.7336 - val_loss: 0.9351 - val_accuracy: 0.4855\n","Epoch 10/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7160 - accuracy: 0.7359 - val_loss: 0.9439 - val_accuracy: 0.4866\n","Epoch 11/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7152 - accuracy: 0.7370 - val_loss: 0.9833 - val_accuracy: 0.4855\n","Epoch 12/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7226 - accuracy: 0.7199 - val_loss: 0.9508 - val_accuracy: 0.4897\n","Epoch 13/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.7340 - accuracy: 0.7026 - val_loss: 0.9384 - val_accuracy: 0.4969\n","Epoch 14/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.7131 - accuracy: 0.7364 - val_loss: 0.9211 - val_accuracy: 0.5031\n","Epoch 15/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7103 - accuracy: 0.7411 - val_loss: 0.9277 - val_accuracy: 0.5031\n","Epoch 16/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7042 - accuracy: 0.7481 - val_loss: 0.9364 - val_accuracy: 0.5083\n","Epoch 17/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.7068 - accuracy: 0.7421 - val_loss: 0.8710 - val_accuracy: 0.5320\n","Epoch 18/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.7064 - accuracy: 0.7406 - val_loss: 0.8633 - val_accuracy: 0.5444\n","Epoch 19/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.7200 - accuracy: 0.7147 - val_loss: 0.8636 - val_accuracy: 0.5589\n","Epoch 20/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7068 - accuracy: 0.7313 - val_loss: 0.8787 - val_accuracy: 0.5413\n","Epoch 21/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6987 - accuracy: 0.7457 - val_loss: 0.8686 - val_accuracy: 0.5548\n","Epoch 22/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.7109 - accuracy: 0.7282 - val_loss: 0.8520 - val_accuracy: 0.5961\n","Epoch 23/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6979 - accuracy: 0.7506 - val_loss: 0.8537 - val_accuracy: 0.5961\n","Epoch 24/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6958 - accuracy: 0.7509 - val_loss: 0.8657 - val_accuracy: 0.5930\n","Epoch 25/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6966 - accuracy: 0.7470 - val_loss: 0.8483 - val_accuracy: 0.6074\n","Epoch 26/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6919 - accuracy: 0.7543 - val_loss: 0.8641 - val_accuracy: 0.5981\n","Epoch 27/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6929 - accuracy: 0.7506 - val_loss: 0.8334 - val_accuracy: 0.6229\n","Epoch 28/100\n","31/31 [==============================] - 1s 38ms/step - loss: 0.6943 - accuracy: 0.7481 - val_loss: 0.8347 - val_accuracy: 0.6250\n","Epoch 29/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6862 - accuracy: 0.7506 - val_loss: 0.8459 - val_accuracy: 0.6281\n","Epoch 30/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7014 - accuracy: 0.7346 - val_loss: 0.8337 - val_accuracy: 0.6219\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6902 - accuracy: 0.7478 - val_loss: 0.8340 - val_accuracy: 0.6271\n","Epoch 32/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6822 - accuracy: 0.7574 - val_loss: 0.8519 - val_accuracy: 0.6240\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6925 - accuracy: 0.7491 - val_loss: 0.8553 - val_accuracy: 0.6240\n","Epoch 34/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6819 - accuracy: 0.7568 - val_loss: 0.8341 - val_accuracy: 0.6281\n","Epoch 35/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6892 - accuracy: 0.7561 - val_loss: 0.8741 - val_accuracy: 0.6105\n","Epoch 36/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6886 - accuracy: 0.7444 - val_loss: 0.8426 - val_accuracy: 0.6291\n","Epoch 37/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6748 - accuracy: 0.7656 - val_loss: 0.8470 - val_accuracy: 0.6312\n","Epoch 38/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6746 - accuracy: 0.7607 - val_loss: 0.8369 - val_accuracy: 0.6219\n","Epoch 39/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6732 - accuracy: 0.7651 - val_loss: 0.8577 - val_accuracy: 0.6229\n","Epoch 40/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6746 - accuracy: 0.7579 - val_loss: 0.8471 - val_accuracy: 0.6209\n","Epoch 41/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6752 - accuracy: 0.7610 - val_loss: 0.8406 - val_accuracy: 0.6281\n","Epoch 42/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7059 - accuracy: 0.7256 - val_loss: 0.8897 - val_accuracy: 0.6012\n","Epoch 43/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6890 - accuracy: 0.7426 - val_loss: 0.8783 - val_accuracy: 0.6333\n","Epoch 44/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6649 - accuracy: 0.7721 - val_loss: 0.8517 - val_accuracy: 0.6250\n","Epoch 45/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6703 - accuracy: 0.7643 - val_loss: 0.8590 - val_accuracy: 0.6095\n","Epoch 46/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6680 - accuracy: 0.7661 - val_loss: 0.8763 - val_accuracy: 0.6147\n","Epoch 47/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6619 - accuracy: 0.7654 - val_loss: 0.8495 - val_accuracy: 0.6343\n","Epoch 48/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6626 - accuracy: 0.7659 - val_loss: 0.8762 - val_accuracy: 0.6353\n","Epoch 49/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6699 - accuracy: 0.7618 - val_loss: 0.8600 - val_accuracy: 0.6260\n","Epoch 50/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6704 - accuracy: 0.7599 - val_loss: 0.8663 - val_accuracy: 0.6157\n","Epoch 51/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6660 - accuracy: 0.7568 - val_loss: 0.8480 - val_accuracy: 0.6240\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6572 - accuracy: 0.7775 - val_loss: 0.8545 - val_accuracy: 0.6147\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6537 - accuracy: 0.7765 - val_loss: 0.8507 - val_accuracy: 0.6343\n","Epoch 54/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6515 - accuracy: 0.7791 - val_loss: 0.8573 - val_accuracy: 0.6219\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6480 - accuracy: 0.7783 - val_loss: 0.8788 - val_accuracy: 0.6188\n","Epoch 56/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6565 - accuracy: 0.7677 - val_loss: 0.8530 - val_accuracy: 0.6364\n","Epoch 57/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6493 - accuracy: 0.7791 - val_loss: 0.8603 - val_accuracy: 0.6291\n","Epoch 58/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6471 - accuracy: 0.7801 - val_loss: 0.8589 - val_accuracy: 0.6333\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6473 - accuracy: 0.7824 - val_loss: 0.8956 - val_accuracy: 0.6054\n","Epoch 60/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6617 - accuracy: 0.7589 - val_loss: 0.8607 - val_accuracy: 0.6343\n","Epoch 61/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6413 - accuracy: 0.7855 - val_loss: 0.8500 - val_accuracy: 0.6302\n","Epoch 62/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6391 - accuracy: 0.7860 - val_loss: 0.9001 - val_accuracy: 0.5930\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6631 - accuracy: 0.7579 - val_loss: 0.9009 - val_accuracy: 0.6126\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6451 - accuracy: 0.7736 - val_loss: 0.8602 - val_accuracy: 0.6260\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6469 - accuracy: 0.7780 - val_loss: 0.8897 - val_accuracy: 0.6147\n","Epoch 66/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6366 - accuracy: 0.7868 - val_loss: 0.8644 - val_accuracy: 0.6291\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6323 - accuracy: 0.7894 - val_loss: 0.9057 - val_accuracy: 0.6033\n","Epoch 68/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6354 - accuracy: 0.7876 - val_loss: 0.9036 - val_accuracy: 0.5992\n","Epoch 69/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6416 - accuracy: 0.7788 - val_loss: 0.8611 - val_accuracy: 0.6302\n","Epoch 70/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6364 - accuracy: 0.7814 - val_loss: 0.8785 - val_accuracy: 0.6188\n","Epoch 71/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6304 - accuracy: 0.7853 - val_loss: 0.8715 - val_accuracy: 0.6229\n","Epoch 72/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6259 - accuracy: 0.7912 - val_loss: 0.8668 - val_accuracy: 0.6302\n","Epoch 73/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6238 - accuracy: 0.7917 - val_loss: 0.8709 - val_accuracy: 0.6260\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6267 - accuracy: 0.7855 - val_loss: 0.9389 - val_accuracy: 0.6043\n","Epoch 75/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6418 - accuracy: 0.7729 - val_loss: 0.9389 - val_accuracy: 0.6012\n","Epoch 76/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6415 - accuracy: 0.7713 - val_loss: 0.8811 - val_accuracy: 0.6302\n","Epoch 77/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6273 - accuracy: 0.7871 - val_loss: 0.8725 - val_accuracy: 0.6322\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6236 - accuracy: 0.7884 - val_loss: 0.8794 - val_accuracy: 0.6291\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6156 - accuracy: 0.7969 - val_loss: 0.8708 - val_accuracy: 0.6322\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6117 - accuracy: 0.8026 - val_loss: 0.9210 - val_accuracy: 0.6033\n","Epoch 81/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6132 - accuracy: 0.7969 - val_loss: 0.8890 - val_accuracy: 0.6136\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6180 - accuracy: 0.7961 - val_loss: 0.9168 - val_accuracy: 0.6126\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6125 - accuracy: 0.7974 - val_loss: 0.8947 - val_accuracy: 0.6229\n","Epoch 84/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6065 - accuracy: 0.7995 - val_loss: 1.0160 - val_accuracy: 0.5599\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6194 - accuracy: 0.7922 - val_loss: 0.9184 - val_accuracy: 0.6105\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6098 - accuracy: 0.7943 - val_loss: 0.9115 - val_accuracy: 0.6147\n","Epoch 87/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6090 - accuracy: 0.8013 - val_loss: 0.8867 - val_accuracy: 0.6229\n","Epoch 88/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6128 - accuracy: 0.7956 - val_loss: 0.9023 - val_accuracy: 0.6105\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6060 - accuracy: 0.8008 - val_loss: 0.8920 - val_accuracy: 0.6229\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5950 - accuracy: 0.8140 - val_loss: 0.8862 - val_accuracy: 0.6260\n","Epoch 91/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5932 - accuracy: 0.8119 - val_loss: 0.8916 - val_accuracy: 0.6250\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6032 - accuracy: 0.8031 - val_loss: 0.9134 - val_accuracy: 0.6209\n","Epoch 93/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5973 - accuracy: 0.8047 - val_loss: 0.9436 - val_accuracy: 0.6002\n","Epoch 94/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6084 - accuracy: 0.7966 - val_loss: 1.0143 - val_accuracy: 0.5775\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6047 - accuracy: 0.8003 - val_loss: 0.9367 - val_accuracy: 0.5919\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5969 - accuracy: 0.8018 - val_loss: 0.9273 - val_accuracy: 0.6043\n","Epoch 97/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5834 - accuracy: 0.8173 - val_loss: 0.8921 - val_accuracy: 0.6219\n","Epoch 98/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5872 - accuracy: 0.8145 - val_loss: 0.8957 - val_accuracy: 0.6188\n","Epoch 99/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5896 - accuracy: 0.8109 - val_loss: 0.8923 - val_accuracy: 0.6302\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5814 - accuracy: 0.8238 - val_loss: 0.9018 - val_accuracy: 0.6333\n","{'loss': [0.7585701942443848, 0.7380115389823914, 0.7320258617401123, 0.7298397421836853, 0.7286691069602966, 0.7283869981765747, 0.7311432361602783, 0.7192168831825256, 0.7214730978012085, 0.7159934043884277, 0.7151657938957214, 0.7226076722145081, 0.7340237498283386, 0.7131222486495972, 0.7103105783462524, 0.7041592597961426, 0.7067762017250061, 0.7064287066459656, 0.7200309634208679, 0.706838071346283, 0.6987167596817017, 0.7109025120735168, 0.6979064345359802, 0.6958273649215698, 0.6966153979301453, 0.6918854117393494, 0.6928509473800659, 0.6942722201347351, 0.6862305998802185, 0.7013871073722839, 0.6902042627334595, 0.6822423338890076, 0.6924746036529541, 0.6818732023239136, 0.6892245411872864, 0.6886410713195801, 0.6748214960098267, 0.6745620369911194, 0.673234760761261, 0.6745635271072388, 0.675158679485321, 0.705938994884491, 0.6889527440071106, 0.6649206280708313, 0.6703053712844849, 0.6680279970169067, 0.6618993878364563, 0.6626291275024414, 0.6699291467666626, 0.6704379916191101, 0.6660336852073669, 0.6571769714355469, 0.6536909937858582, 0.6514555811882019, 0.6479626893997192, 0.6565474271774292, 0.6493470072746277, 0.647055983543396, 0.64731764793396, 0.6617028713226318, 0.6413205862045288, 0.6390593647956848, 0.6631150245666504, 0.6451489925384521, 0.6468807458877563, 0.6366033554077148, 0.6323198080062866, 0.6353944540023804, 0.64157634973526, 0.6363669633865356, 0.6303929090499878, 0.6258646845817566, 0.6238061785697937, 0.6266838312149048, 0.6417811512947083, 0.6414955258369446, 0.6273245811462402, 0.6235560178756714, 0.6156206727027893, 0.6117249727249146, 0.6131530404090881, 0.6179640889167786, 0.6124587655067444, 0.6065146923065186, 0.6194168925285339, 0.6098061203956604, 0.6089746356010437, 0.6127783060073853, 0.6059549450874329, 0.5949651598930359, 0.5932407975196838, 0.6032332181930542, 0.5973442792892456, 0.6083905696868896, 0.6046869158744812, 0.596919059753418, 0.5833931565284729, 0.587235689163208, 0.5896236896514893, 0.5814152956008911], 'accuracy': [0.6992248296737671, 0.713178277015686, 0.723514199256897, 0.7183462381362915, 0.7242894172668457, 0.7178294658660889, 0.7165374755859375, 0.7307493686676025, 0.7335917353630066, 0.735917329788208, 0.7369509339332581, 0.7198966145515442, 0.7025839686393738, 0.7364341020584106, 0.7410852909088135, 0.748062014579773, 0.7421188354492188, 0.7405684590339661, 0.7147286534309387, 0.7312661409378052, 0.7457364201545715, 0.7281653881072998, 0.7506459951400757, 0.750904381275177, 0.7470284104347229, 0.7542635798454285, 0.7506459951400757, 0.748062014579773, 0.7506459951400757, 0.7346253395080566, 0.7478036284446716, 0.7573643326759338, 0.749095618724823, 0.7568475604057312, 0.7560723423957825, 0.7444444298744202, 0.7656330466270447, 0.7607235312461853, 0.765116274356842, 0.7578811645507812, 0.7609819173812866, 0.7255814075469971, 0.7426356673240662, 0.7720929980278015, 0.7643410563468933, 0.7661498785018921, 0.7653746604919434, 0.7658914923667908, 0.7617571353912354, 0.7599483132362366, 0.7568475604057312, 0.7775194048881531, 0.776485800743103, 0.7790697813034058, 0.778294563293457, 0.7677002549171448, 0.7790697813034058, 0.7801033854484558, 0.7824289202690125, 0.7589147090911865, 0.7855297327041626, 0.7860465049743652, 0.7578811645507812, 0.773643434047699, 0.7780361771583557, 0.786821722984314, 0.7894057035446167, 0.7875968813896179, 0.7788113951683044, 0.7813953757286072, 0.7852713465690613, 0.7912144660949707, 0.7917312383651733, 0.7855297327041626, 0.7728682160377502, 0.7713178396224976, 0.7870801091194153, 0.7883720993995667, 0.7968991994857788, 0.8025839924812317, 0.7968991994857788, 0.7961240410804749, 0.7974160313606262, 0.7994831800460815, 0.7922480702400208, 0.7943152189254761, 0.8012920022010803, 0.7956072092056274, 0.8007751703262329, 0.8139534592628479, 0.8118863105773926, 0.8031007647514343, 0.804651141166687, 0.7966408133506775, 0.8002583980560303, 0.801808774471283, 0.8173126578330994, 0.8144702911376953, 0.8108527064323425, 0.8237726092338562], 'val_loss': [0.8894352912902832, 0.8916692137718201, 0.8950108885765076, 0.8968618512153625, 0.9067773818969727, 0.9020610451698303, 0.9147700667381287, 0.9259488582611084, 0.9350515604019165, 0.9439337849617004, 0.9833251237869263, 0.9507681131362915, 0.9384477734565735, 0.9211369752883911, 0.9277245998382568, 0.9363527297973633, 0.8710074424743652, 0.8632550835609436, 0.8635942339897156, 0.8786841630935669, 0.8685706853866577, 0.8519734740257263, 0.8537269830703735, 0.8656811714172363, 0.8483113646507263, 0.8640772104263306, 0.8334376215934753, 0.8346919417381287, 0.8459455370903015, 0.8336776494979858, 0.8339836001396179, 0.8518604040145874, 0.855273425579071, 0.8341172933578491, 0.8741017580032349, 0.8425922393798828, 0.8470346927642822, 0.8369206190109253, 0.8576804995536804, 0.8471047282218933, 0.8406264781951904, 0.8897230625152588, 0.8782683610916138, 0.8517292141914368, 0.8590055108070374, 0.8762779831886292, 0.8494586944580078, 0.876213550567627, 0.8600125908851624, 0.8662950992584229, 0.8479717373847961, 0.8545432090759277, 0.850688636302948, 0.8572577834129333, 0.8788415789604187, 0.8530254364013672, 0.8603196740150452, 0.8589348196983337, 0.8955917954444885, 0.860743522644043, 0.8500313758850098, 0.9001487493515015, 0.900871217250824, 0.8601823449134827, 0.889723002910614, 0.8643994927406311, 0.9056661128997803, 0.9035513401031494, 0.8610745072364807, 0.8784890174865723, 0.8715277314186096, 0.8667966723442078, 0.8709453344345093, 0.9389162063598633, 0.9388566613197327, 0.8810750842094421, 0.872545599937439, 0.8793826699256897, 0.8707944750785828, 0.920992374420166, 0.8889538645744324, 0.9168321490287781, 0.8947024345397949, 1.0159518718719482, 0.9184315800666809, 0.9114604592323303, 0.8867254853248596, 0.9022707343101501, 0.8919818997383118, 0.8861639499664307, 0.8916077017784119, 0.9133636951446533, 0.9435673356056213, 1.014261245727539, 0.936697781085968, 0.9272983074188232, 0.892125129699707, 0.895738422870636, 0.8923162817955017, 0.9017836451530457], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.48553720116615295, 0.48966941237449646, 0.4969008266925812, 0.5030992031097412, 0.5030992031097412, 0.5082644820213318, 0.5320248007774353, 0.5444214940071106, 0.55888432264328, 0.5413222908973694, 0.5547520518302917, 0.5960744023323059, 0.5960744023323059, 0.5929751992225647, 0.6074380278587341, 0.5981404781341553, 0.6229338645935059, 0.625, 0.6280992031097412, 0.6219007968902588, 0.6270661354064941, 0.6239669322967529, 0.6239669322967529, 0.6280992031097412, 0.6105371713638306, 0.6291322112083435, 0.6311983466148376, 0.6219007968902588, 0.6229338645935059, 0.6208677887916565, 0.6280992031097412, 0.6012396812438965, 0.6332644820213318, 0.625, 0.6095041036605835, 0.6146694421768188, 0.6342975497245789, 0.6353305578231812, 0.6260330677032471, 0.6157024502754211, 0.6239669322967529, 0.6146694421768188, 0.6342975497245789, 0.6219007968902588, 0.6188016533851624, 0.6363636255264282, 0.6291322112083435, 0.6332644820213318, 0.60537189245224, 0.6342975497245789, 0.6301652789115906, 0.5929751992225647, 0.6126033067703247, 0.6260330677032471, 0.6146694421768188, 0.6291322112083435, 0.6033057570457458, 0.5991735458374023, 0.6301652789115906, 0.6188016533851624, 0.6229338645935059, 0.6301652789115906, 0.6260330677032471, 0.6043388247489929, 0.6012396812438965, 0.6301652789115906, 0.6322314143180847, 0.6291322112083435, 0.6322314143180847, 0.6033057570457458, 0.6136363744735718, 0.6126033067703247, 0.6229338645935059, 0.5599173307418823, 0.6105371713638306, 0.6146694421768188, 0.6229338645935059, 0.6105371713638306, 0.6229338645935059, 0.6260330677032471, 0.625, 0.6208677887916565, 0.6002066135406494, 0.577479362487793, 0.5919421315193176, 0.6043388247489929, 0.6219007968902588, 0.6188016533851624, 0.6301652789115906, 0.6332644820213318]}\n","32/32 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.6691 - accuracy: 0.7557"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 4s 34ms/step - loss: 0.6619 - accuracy: 0.7597 - val_loss: 0.8966 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6173 - accuracy: 0.7945 - val_loss: 0.9003 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6145 - accuracy: 0.8001 - val_loss: 0.9033 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6093 - accuracy: 0.8006 - val_loss: 0.9100 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6048 - accuracy: 0.8031 - val_loss: 0.9254 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6053 - accuracy: 0.7996 - val_loss: 0.9360 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5999 - accuracy: 0.7982 - val_loss: 0.9533 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6043 - accuracy: 0.8001 - val_loss: 0.9538 - val_accuracy: 0.4860\n","Epoch 9/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.6013 - accuracy: 0.7977 - val_loss: 0.9507 - val_accuracy: 0.4871\n","Epoch 10/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5969 - accuracy: 0.8060 - val_loss: 0.9943 - val_accuracy: 0.4849\n","Epoch 11/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5854 - accuracy: 0.8195 - val_loss: 1.0138 - val_accuracy: 0.4849\n","Epoch 12/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5930 - accuracy: 0.8050 - val_loss: 1.0364 - val_accuracy: 0.4881\n","Epoch 13/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5876 - accuracy: 0.8082 - val_loss: 1.0088 - val_accuracy: 0.4978\n","Epoch 14/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5855 - accuracy: 0.8122 - val_loss: 1.0030 - val_accuracy: 0.5054\n","Epoch 15/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.5873 - accuracy: 0.8103 - val_loss: 1.0126 - val_accuracy: 0.5097\n","Epoch 16/100\n","29/29 [==============================] - 1s 40ms/step - loss: 0.5864 - accuracy: 0.8122 - val_loss: 0.9601 - val_accuracy: 0.5248\n","Epoch 17/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.5859 - accuracy: 0.8163 - val_loss: 0.8968 - val_accuracy: 0.5463\n","Epoch 18/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.5767 - accuracy: 0.8219 - val_loss: 0.8649 - val_accuracy: 0.5690\n","Epoch 19/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.5943 - accuracy: 0.7955 - val_loss: 0.8544 - val_accuracy: 0.6013\n","Epoch 20/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5745 - accuracy: 0.8254 - val_loss: 0.8559 - val_accuracy: 0.5927\n","Epoch 21/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5726 - accuracy: 0.8225 - val_loss: 0.8383 - val_accuracy: 0.6228\n","Epoch 22/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5691 - accuracy: 0.8214 - val_loss: 0.8422 - val_accuracy: 0.6185\n","Epoch 23/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5672 - accuracy: 0.8249 - val_loss: 0.8298 - val_accuracy: 0.6455\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5709 - accuracy: 0.8152 - val_loss: 0.8485 - val_accuracy: 0.6390\n","Epoch 25/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.5842 - accuracy: 0.8033 - val_loss: 0.8531 - val_accuracy: 0.6509\n","Epoch 26/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5703 - accuracy: 0.8227 - val_loss: 0.7970 - val_accuracy: 0.6778\n","Epoch 27/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5620 - accuracy: 0.8308 - val_loss: 0.8003 - val_accuracy: 0.6713\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5684 - accuracy: 0.8214 - val_loss: 0.8156 - val_accuracy: 0.6573\n","Epoch 29/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5643 - accuracy: 0.8246 - val_loss: 0.7851 - val_accuracy: 0.6875\n","Epoch 30/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5695 - accuracy: 0.8260 - val_loss: 0.8503 - val_accuracy: 0.6433\n","Epoch 31/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5603 - accuracy: 0.8287 - val_loss: 0.7907 - val_accuracy: 0.6886\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5512 - accuracy: 0.8394 - val_loss: 0.7982 - val_accuracy: 0.6843\n","Epoch 33/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5471 - accuracy: 0.8429 - val_loss: 0.7967 - val_accuracy: 0.6897\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5481 - accuracy: 0.8392 - val_loss: 0.8029 - val_accuracy: 0.6681\n","Epoch 35/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5486 - accuracy: 0.8381 - val_loss: 0.7982 - val_accuracy: 0.6821\n","Epoch 36/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5422 - accuracy: 0.8416 - val_loss: 0.8268 - val_accuracy: 0.6950\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5711 - accuracy: 0.8144 - val_loss: 0.7963 - val_accuracy: 0.6778\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5565 - accuracy: 0.8292 - val_loss: 0.8594 - val_accuracy: 0.6778\n","Epoch 39/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5588 - accuracy: 0.8230 - val_loss: 0.8004 - val_accuracy: 0.6789\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5405 - accuracy: 0.8424 - val_loss: 0.8011 - val_accuracy: 0.6810\n","Epoch 41/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5457 - accuracy: 0.8338 - val_loss: 0.8144 - val_accuracy: 0.6638\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5346 - accuracy: 0.8475 - val_loss: 0.8493 - val_accuracy: 0.6498\n","Epoch 43/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5509 - accuracy: 0.8292 - val_loss: 0.8137 - val_accuracy: 0.6767\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5270 - accuracy: 0.8518 - val_loss: 0.8106 - val_accuracy: 0.6703\n","Epoch 45/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5316 - accuracy: 0.8497 - val_loss: 0.8651 - val_accuracy: 0.6519\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5452 - accuracy: 0.8376 - val_loss: 0.8130 - val_accuracy: 0.6843\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5237 - accuracy: 0.8491 - val_loss: 0.8092 - val_accuracy: 0.6756\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5262 - accuracy: 0.8502 - val_loss: 0.8103 - val_accuracy: 0.6843\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5244 - accuracy: 0.8545 - val_loss: 0.8066 - val_accuracy: 0.6843\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5193 - accuracy: 0.8540 - val_loss: 0.8129 - val_accuracy: 0.6821\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5167 - accuracy: 0.8532 - val_loss: 0.8090 - val_accuracy: 0.6810\n","Epoch 52/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5324 - accuracy: 0.8481 - val_loss: 0.8154 - val_accuracy: 0.6832\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5204 - accuracy: 0.8518 - val_loss: 0.8190 - val_accuracy: 0.6778\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5097 - accuracy: 0.8623 - val_loss: 0.8206 - val_accuracy: 0.6789\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5200 - accuracy: 0.8537 - val_loss: 0.8351 - val_accuracy: 0.6735\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5171 - accuracy: 0.8537 - val_loss: 0.8153 - val_accuracy: 0.6821\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5067 - accuracy: 0.8626 - val_loss: 0.8762 - val_accuracy: 0.6487\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5083 - accuracy: 0.8580 - val_loss: 0.8293 - val_accuracy: 0.6713\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5071 - accuracy: 0.8580 - val_loss: 0.8344 - val_accuracy: 0.6724\n","Epoch 60/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4980 - accuracy: 0.8675 - val_loss: 0.8270 - val_accuracy: 0.6735\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4986 - accuracy: 0.8621 - val_loss: 0.8210 - val_accuracy: 0.6767\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4950 - accuracy: 0.8685 - val_loss: 0.8335 - val_accuracy: 0.6810\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5014 - accuracy: 0.8629 - val_loss: 0.8350 - val_accuracy: 0.6724\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4923 - accuracy: 0.8707 - val_loss: 0.8451 - val_accuracy: 0.6789\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4969 - accuracy: 0.8710 - val_loss: 0.8329 - val_accuracy: 0.6767\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4942 - accuracy: 0.8658 - val_loss: 0.8340 - val_accuracy: 0.6821\n","Epoch 67/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5038 - accuracy: 0.8623 - val_loss: 0.8466 - val_accuracy: 0.6756\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4952 - accuracy: 0.8653 - val_loss: 0.8346 - val_accuracy: 0.6746\n","Epoch 69/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4886 - accuracy: 0.8745 - val_loss: 0.8506 - val_accuracy: 0.6843\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5247 - accuracy: 0.8454 - val_loss: 0.8369 - val_accuracy: 0.6778\n","Epoch 71/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4988 - accuracy: 0.8645 - val_loss: 0.8741 - val_accuracy: 0.6756\n","Epoch 72/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4971 - accuracy: 0.8623 - val_loss: 0.8454 - val_accuracy: 0.6864\n","Epoch 73/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4809 - accuracy: 0.8745 - val_loss: 0.8463 - val_accuracy: 0.6800\n","Epoch 74/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4750 - accuracy: 0.8866 - val_loss: 0.8426 - val_accuracy: 0.6875\n","Epoch 75/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4725 - accuracy: 0.8863 - val_loss: 0.8661 - val_accuracy: 0.6627\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4746 - accuracy: 0.8777 - val_loss: 0.8514 - val_accuracy: 0.6789\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4912 - accuracy: 0.8669 - val_loss: 0.8594 - val_accuracy: 0.6778\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4746 - accuracy: 0.8812 - val_loss: 0.8678 - val_accuracy: 0.6853\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4798 - accuracy: 0.8742 - val_loss: 0.8748 - val_accuracy: 0.6735\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4769 - accuracy: 0.8785 - val_loss: 0.8622 - val_accuracy: 0.6821\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4643 - accuracy: 0.8831 - val_loss: 0.8536 - val_accuracy: 0.6897\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4677 - accuracy: 0.8817 - val_loss: 0.8731 - val_accuracy: 0.6703\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4694 - accuracy: 0.8788 - val_loss: 0.8617 - val_accuracy: 0.6724\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4574 - accuracy: 0.8906 - val_loss: 0.8611 - val_accuracy: 0.6659\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4533 - accuracy: 0.8939 - val_loss: 0.8570 - val_accuracy: 0.6746\n","Epoch 86/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4603 - accuracy: 0.8820 - val_loss: 0.8989 - val_accuracy: 0.6692\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4644 - accuracy: 0.8793 - val_loss: 0.9013 - val_accuracy: 0.6541\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4781 - accuracy: 0.8702 - val_loss: 0.8633 - val_accuracy: 0.6767\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4579 - accuracy: 0.8847 - val_loss: 0.8708 - val_accuracy: 0.6692\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4502 - accuracy: 0.8906 - val_loss: 0.8719 - val_accuracy: 0.6843\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4511 - accuracy: 0.8936 - val_loss: 0.8734 - val_accuracy: 0.6767\n","Epoch 92/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4538 - accuracy: 0.8925 - val_loss: 0.8739 - val_accuracy: 0.6767\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4674 - accuracy: 0.8825 - val_loss: 0.8712 - val_accuracy: 0.6735\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4463 - accuracy: 0.8925 - val_loss: 0.8765 - val_accuracy: 0.6897\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4397 - accuracy: 0.8990 - val_loss: 0.8893 - val_accuracy: 0.6692\n","Epoch 96/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4514 - accuracy: 0.8877 - val_loss: 0.8748 - val_accuracy: 0.6789\n","Epoch 97/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4392 - accuracy: 0.9057 - val_loss: 0.8875 - val_accuracy: 0.6659\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4555 - accuracy: 0.8858 - val_loss: 0.9169 - val_accuracy: 0.6681\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4386 - accuracy: 0.9001 - val_loss: 0.8782 - val_accuracy: 0.6767\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4353 - accuracy: 0.9022 - val_loss: 0.8914 - val_accuracy: 0.6778\n","{'loss': [0.6618635654449463, 0.6173174381256104, 0.6144992113113403, 0.6092968583106995, 0.6048163175582886, 0.605294406414032, 0.5999392867088318, 0.6043441891670227, 0.6012702584266663, 0.5968877077102661, 0.5853723287582397, 0.5929958820343018, 0.5876490473747253, 0.5855411291122437, 0.5872668623924255, 0.586357831954956, 0.5859057903289795, 0.5766681432723999, 0.594289243221283, 0.5744548439979553, 0.5726228952407837, 0.5691272616386414, 0.5671597719192505, 0.5708870887756348, 0.5841542482376099, 0.5703383088111877, 0.5619520545005798, 0.5684424042701721, 0.5642800331115723, 0.5695095658302307, 0.5602864623069763, 0.5511749982833862, 0.5471304059028625, 0.5480829477310181, 0.5486043691635132, 0.5422179698944092, 0.5710734128952026, 0.5564501285552979, 0.5588392615318298, 0.5405195951461792, 0.5456989407539368, 0.5345780849456787, 0.5509033799171448, 0.5270386934280396, 0.531568706035614, 0.545211672782898, 0.5236502885818481, 0.5261844396591187, 0.5244425535202026, 0.5193336606025696, 0.5167063474655151, 0.5324183106422424, 0.5203689336776733, 0.5096683502197266, 0.5200321078300476, 0.5171236395835876, 0.506713330745697, 0.5083016753196716, 0.5071300864219666, 0.49800392985343933, 0.4985993802547455, 0.49496543407440186, 0.5013546347618103, 0.4922938048839569, 0.4968779385089874, 0.4941863715648651, 0.5038371086120605, 0.49516505002975464, 0.4885680675506592, 0.5247161388397217, 0.4987602233886719, 0.4971045255661011, 0.48090797662734985, 0.4749845266342163, 0.4724840223789215, 0.4746335446834564, 0.4911626875400543, 0.4746030569076538, 0.4798071086406708, 0.4768674671649933, 0.4643295109272003, 0.4677296578884125, 0.4694298803806305, 0.45737749338150024, 0.4533345699310303, 0.46029531955718994, 0.4644138813018799, 0.47809040546417236, 0.45793119072914124, 0.4502335786819458, 0.45110124349594116, 0.4538218677043915, 0.46741941571235657, 0.4462967813014984, 0.4396757483482361, 0.45144349336624146, 0.4391830563545227, 0.45551884174346924, 0.43861833214759827, 0.43534383177757263], 'accuracy': [0.7596982717514038, 0.7944504022598267, 0.8001077771186829, 0.8006465435028076, 0.803071141242981, 0.7995689511299133, 0.798222005367279, 0.8001077771186829, 0.7976831793785095, 0.806034505367279, 0.8195043206214905, 0.8049569129943848, 0.8081896305084229, 0.8122305870056152, 0.8103448152542114, 0.8122305870056152, 0.8162715435028076, 0.821928858757019, 0.795527994632721, 0.8254310488700867, 0.8224676847457886, 0.8213900923728943, 0.8248922228813171, 0.8151939511299133, 0.803340494632721, 0.8227370977401733, 0.8308189511299133, 0.8213900923728943, 0.8246228694915771, 0.8259698152542114, 0.8286637663841248, 0.8394396305084229, 0.8429418206214905, 0.8391702771186829, 0.8380926847457886, 0.8415948152542114, 0.8143857717514038, 0.8292025923728943, 0.8230064511299133, 0.842402994632721, 0.8337823152542114, 0.8475215435028076, 0.8292025923728943, 0.8518319129943848, 0.8496767282485962, 0.837553858757019, 0.8491379022598267, 0.850215494632721, 0.8545258641242981, 0.8539870977401733, 0.853178858757019, 0.8480603694915771, 0.8518319129943848, 0.8623383641242981, 0.8537176847457886, 0.8537176847457886, 0.8626077771186829, 0.858027994632721, 0.858027994632721, 0.8674569129943848, 0.8620689511299133, 0.868534505367279, 0.8628771305084229, 0.8706896305084229, 0.8709590435028076, 0.865840494632721, 0.8623383641242981, 0.8653017282485962, 0.8744612336158752, 0.845366358757019, 0.8644935488700867, 0.8623383641242981, 0.8744612336158752, 0.8865840435028076, 0.8863146305084229, 0.8776939511299133, 0.8669180870056152, 0.881196141242981, 0.8741918206214905, 0.8785021305084229, 0.8830819129943848, 0.8817349076271057, 0.8787715435028076, 0.890625, 0.8938577771186829, 0.8820043206214905, 0.8793103694915771, 0.8701508641242981, 0.8846982717514038, 0.890625, 0.8935883641242981, 0.8925107717514038, 0.8825430870056152, 0.8925107717514038, 0.8989762663841248, 0.8876616358757019, 0.9057112336158752, 0.8857758641242981, 0.900053858757019, 0.9022090435028076], 'val_loss': [0.8966476917266846, 0.9002988934516907, 0.9033337235450745, 0.910019040107727, 0.9254475831985474, 0.9360135197639465, 0.9533200263977051, 0.953765869140625, 0.9506633281707764, 0.9942895174026489, 1.0138046741485596, 1.0364168882369995, 1.0087862014770508, 1.0029606819152832, 1.0126453638076782, 0.9601388573646545, 0.8967627882957458, 0.8649095892906189, 0.8544147610664368, 0.8558769822120667, 0.8382790088653564, 0.8421794772148132, 0.8298324942588806, 0.8484939336776733, 0.8531189560890198, 0.7970132231712341, 0.8002669215202332, 0.8155816197395325, 0.7850673794746399, 0.8502666354179382, 0.7906671762466431, 0.7982298135757446, 0.7967391610145569, 0.8028927445411682, 0.7982262969017029, 0.8268015384674072, 0.7962708473205566, 0.8594270944595337, 0.8003800511360168, 0.8010650277137756, 0.8143920302391052, 0.8492982983589172, 0.8137050867080688, 0.8106259107589722, 0.8651297092437744, 0.8129627108573914, 0.8092005252838135, 0.8102792501449585, 0.8065592050552368, 0.8129463195800781, 0.8090316653251648, 0.8153722882270813, 0.8189847469329834, 0.820611298084259, 0.8351142406463623, 0.8152793645858765, 0.8761681318283081, 0.8292514085769653, 0.8344092965126038, 0.8270151615142822, 0.8210117220878601, 0.833513081073761, 0.8350347280502319, 0.8450679779052734, 0.8329325318336487, 0.834046483039856, 0.846572995185852, 0.8346006274223328, 0.8505738377571106, 0.8368892669677734, 0.8741105198860168, 0.8453860282897949, 0.8463460803031921, 0.8426455855369568, 0.8661085367202759, 0.8514331579208374, 0.859416127204895, 0.8678078651428223, 0.8747926950454712, 0.8622428774833679, 0.8535628318786621, 0.8730570077896118, 0.8617389798164368, 0.8611213564872742, 0.8569653034210205, 0.8989355564117432, 0.9013264775276184, 0.8632887005805969, 0.8707576394081116, 0.8719220757484436, 0.8733726739883423, 0.8739138841629028, 0.8712296485900879, 0.8765047192573547, 0.8892790675163269, 0.8747600317001343, 0.8875120878219604, 0.9169419407844543, 0.8782200217247009, 0.8914231061935425], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.48706895112991333, 0.48491379618644714, 0.48491379618644714, 0.4881465435028076, 0.4978448152542114, 0.5053879022598267, 0.5096982717514038, 0.524784505367279, 0.5463362336158752, 0.568965494632721, 0.6012930870056152, 0.5926724076271057, 0.6228448152542114, 0.618534505367279, 0.6454741358757019, 0.639008641242981, 0.6508620977401733, 0.6778017282485962, 0.6713362336158752, 0.6573275923728943, 0.6875, 0.6433189511299133, 0.6885775923728943, 0.6842672228813171, 0.6896551847457886, 0.6681034564971924, 0.6821120977401733, 0.6950430870056152, 0.6778017282485962, 0.6778017282485962, 0.6788793206214905, 0.681034505367279, 0.6637930870056152, 0.649784505367279, 0.6767241358757019, 0.670258641242981, 0.6519396305084229, 0.6842672228813171, 0.6756465435028076, 0.6842672228813171, 0.6842672228813171, 0.6821120977401733, 0.681034505367279, 0.6831896305084229, 0.6778017282485962, 0.6788793206214905, 0.673491358757019, 0.6821120977401733, 0.6487069129943848, 0.6713362336158752, 0.6724137663841248, 0.673491358757019, 0.6767241358757019, 0.681034505367279, 0.6724137663841248, 0.6788793206214905, 0.6767241358757019, 0.6821120977401733, 0.6756465435028076, 0.6745689511299133, 0.6842672228813171, 0.6778017282485962, 0.6756465435028076, 0.6864224076271057, 0.6799569129943848, 0.6875, 0.662715494632721, 0.6788793206214905, 0.6778017282485962, 0.6853448152542114, 0.673491358757019, 0.6821120977401733, 0.6896551847457886, 0.670258641242981, 0.6724137663841248, 0.6659482717514038, 0.6745689511299133, 0.6691810488700867, 0.6540948152542114, 0.6767241358757019, 0.6691810488700867, 0.6842672228813171, 0.6767241358757019, 0.6767241358757019, 0.673491358757019, 0.6896551847457886, 0.6691810488700867, 0.6788793206214905, 0.6659482717514038, 0.6681034564971924, 0.6767241358757019, 0.6778017282485962]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.6865 - accuracy: 0.7450"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 4s 38ms/step - loss: 0.6771 - accuracy: 0.7513 - val_loss: 0.8913 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6158 - accuracy: 0.8011 - val_loss: 0.8944 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6159 - accuracy: 0.7932 - val_loss: 0.8966 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6135 - accuracy: 0.7943 - val_loss: 0.9066 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6056 - accuracy: 0.8033 - val_loss: 0.9102 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6059 - accuracy: 0.7982 - val_loss: 0.9293 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6005 - accuracy: 0.8036 - val_loss: 0.9255 - val_accuracy: 0.4966\n","Epoch 8/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5995 - accuracy: 0.8081 - val_loss: 0.9612 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5904 - accuracy: 0.8175 - val_loss: 0.9571 - val_accuracy: 0.4966\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5944 - accuracy: 0.8098 - val_loss: 0.9882 - val_accuracy: 0.4966\n","Epoch 11/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5859 - accuracy: 0.8101 - val_loss: 0.9988 - val_accuracy: 0.4966\n","Epoch 12/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5887 - accuracy: 0.8149 - val_loss: 1.0738 - val_accuracy: 0.4966\n","Epoch 13/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5973 - accuracy: 0.8121 - val_loss: 1.0571 - val_accuracy: 0.4989\n","Epoch 14/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5822 - accuracy: 0.8212 - val_loss: 1.0707 - val_accuracy: 0.4977\n","Epoch 15/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.5804 - accuracy: 0.8203 - val_loss: 1.0778 - val_accuracy: 0.5011\n","Epoch 16/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5928 - accuracy: 0.8132 - val_loss: 1.0335 - val_accuracy: 0.5136\n","Epoch 17/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5778 - accuracy: 0.8220 - val_loss: 1.0594 - val_accuracy: 0.5136\n","Epoch 18/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5842 - accuracy: 0.8110 - val_loss: 1.0162 - val_accuracy: 0.5294\n","Epoch 19/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5737 - accuracy: 0.8203 - val_loss: 0.9127 - val_accuracy: 0.5486\n","Epoch 20/100\n","28/28 [==============================] - 2s 83ms/step - loss: 0.5735 - accuracy: 0.8263 - val_loss: 0.8683 - val_accuracy: 0.5781\n","Epoch 21/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5820 - accuracy: 0.8087 - val_loss: 0.9249 - val_accuracy: 0.5577\n","Epoch 22/100\n","28/28 [==============================] - 2s 65ms/step - loss: 0.5765 - accuracy: 0.8200 - val_loss: 0.8608 - val_accuracy: 0.6018\n","Epoch 23/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.5656 - accuracy: 0.8285 - val_loss: 0.8595 - val_accuracy: 0.6063\n","Epoch 24/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.5659 - accuracy: 0.8260 - val_loss: 0.8449 - val_accuracy: 0.6143\n","Epoch 25/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.5607 - accuracy: 0.8345 - val_loss: 0.8427 - val_accuracy: 0.6233\n","Epoch 26/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5649 - accuracy: 0.8265 - val_loss: 0.8370 - val_accuracy: 0.6369\n","Epoch 27/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5772 - accuracy: 0.8127 - val_loss: 0.8207 - val_accuracy: 0.6425\n","Epoch 28/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5604 - accuracy: 0.8370 - val_loss: 0.8268 - val_accuracy: 0.6357\n","Epoch 29/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5570 - accuracy: 0.8345 - val_loss: 0.8213 - val_accuracy: 0.6584\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5683 - accuracy: 0.8217 - val_loss: 0.8615 - val_accuracy: 0.6403\n","Epoch 31/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5694 - accuracy: 0.8214 - val_loss: 0.8271 - val_accuracy: 0.6482\n","Epoch 32/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5828 - accuracy: 0.8087 - val_loss: 0.8152 - val_accuracy: 0.6686\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5486 - accuracy: 0.8447 - val_loss: 0.8605 - val_accuracy: 0.6493\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5570 - accuracy: 0.8331 - val_loss: 0.8168 - val_accuracy: 0.6640\n","Epoch 35/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5433 - accuracy: 0.8415 - val_loss: 0.8193 - val_accuracy: 0.6606\n","Epoch 36/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5442 - accuracy: 0.8430 - val_loss: 0.8154 - val_accuracy: 0.6731\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5534 - accuracy: 0.8342 - val_loss: 0.8596 - val_accuracy: 0.6493\n","Epoch 38/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5390 - accuracy: 0.8458 - val_loss: 0.8259 - val_accuracy: 0.6629\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5357 - accuracy: 0.8534 - val_loss: 0.8338 - val_accuracy: 0.6550\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5366 - accuracy: 0.8463 - val_loss: 0.8211 - val_accuracy: 0.6686\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5277 - accuracy: 0.8543 - val_loss: 0.8496 - val_accuracy: 0.6538\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5407 - accuracy: 0.8413 - val_loss: 0.8644 - val_accuracy: 0.6414\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5405 - accuracy: 0.8379 - val_loss: 0.8228 - val_accuracy: 0.6708\n","Epoch 44/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5291 - accuracy: 0.8517 - val_loss: 0.8599 - val_accuracy: 0.6505\n","Epoch 45/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5469 - accuracy: 0.8356 - val_loss: 0.8254 - val_accuracy: 0.6606\n","Epoch 46/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5311 - accuracy: 0.8492 - val_loss: 0.8445 - val_accuracy: 0.6640\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5226 - accuracy: 0.8551 - val_loss: 0.8454 - val_accuracy: 0.6629\n","Epoch 48/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5210 - accuracy: 0.8613 - val_loss: 0.8349 - val_accuracy: 0.6606\n","Epoch 49/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5206 - accuracy: 0.8568 - val_loss: 0.8257 - val_accuracy: 0.6618\n","Epoch 50/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5211 - accuracy: 0.8548 - val_loss: 0.8483 - val_accuracy: 0.6572\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5256 - accuracy: 0.8529 - val_loss: 0.8427 - val_accuracy: 0.6652\n","Epoch 52/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5290 - accuracy: 0.8418 - val_loss: 0.9563 - val_accuracy: 0.6357\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5247 - accuracy: 0.8509 - val_loss: 0.8555 - val_accuracy: 0.6482\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5094 - accuracy: 0.8645 - val_loss: 0.8545 - val_accuracy: 0.6618\n","Epoch 55/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5163 - accuracy: 0.8585 - val_loss: 0.8619 - val_accuracy: 0.6595\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5234 - accuracy: 0.8537 - val_loss: 0.8437 - val_accuracy: 0.6414\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5177 - accuracy: 0.8551 - val_loss: 0.8700 - val_accuracy: 0.6527\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5039 - accuracy: 0.8622 - val_loss: 0.8589 - val_accuracy: 0.6437\n","Epoch 59/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5066 - accuracy: 0.8608 - val_loss: 0.8680 - val_accuracy: 0.6584\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5288 - accuracy: 0.8447 - val_loss: 0.8441 - val_accuracy: 0.6471\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4976 - accuracy: 0.8698 - val_loss: 0.8410 - val_accuracy: 0.6618\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4975 - accuracy: 0.8673 - val_loss: 0.8678 - val_accuracy: 0.6482\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5003 - accuracy: 0.8633 - val_loss: 0.8732 - val_accuracy: 0.6527\n","Epoch 64/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5045 - accuracy: 0.8582 - val_loss: 0.8797 - val_accuracy: 0.6471\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4937 - accuracy: 0.8684 - val_loss: 0.8455 - val_accuracy: 0.6505\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4986 - accuracy: 0.8673 - val_loss: 0.8542 - val_accuracy: 0.6618\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5110 - accuracy: 0.8546 - val_loss: 0.8550 - val_accuracy: 0.6482\n","Epoch 68/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4946 - accuracy: 0.8639 - val_loss: 0.9075 - val_accuracy: 0.6459\n","Epoch 69/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4966 - accuracy: 0.8681 - val_loss: 0.8526 - val_accuracy: 0.6584\n","Epoch 70/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4843 - accuracy: 0.8758 - val_loss: 0.8587 - val_accuracy: 0.6606\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5012 - accuracy: 0.8580 - val_loss: 0.9079 - val_accuracy: 0.6459\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4914 - accuracy: 0.8746 - val_loss: 0.8949 - val_accuracy: 0.6414\n","Epoch 73/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4857 - accuracy: 0.8729 - val_loss: 0.9084 - val_accuracy: 0.6516\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4897 - accuracy: 0.8715 - val_loss: 0.9001 - val_accuracy: 0.6437\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4763 - accuracy: 0.8837 - val_loss: 0.8638 - val_accuracy: 0.6527\n","Epoch 76/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4751 - accuracy: 0.8831 - val_loss: 0.8625 - val_accuracy: 0.6527\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4853 - accuracy: 0.8696 - val_loss: 0.9145 - val_accuracy: 0.6437\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4685 - accuracy: 0.8891 - val_loss: 0.8736 - val_accuracy: 0.6606\n","Epoch 79/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4664 - accuracy: 0.8905 - val_loss: 0.8644 - val_accuracy: 0.6561\n","Epoch 80/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4602 - accuracy: 0.8942 - val_loss: 0.8719 - val_accuracy: 0.6584\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4736 - accuracy: 0.8854 - val_loss: 0.8699 - val_accuracy: 0.6595\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4710 - accuracy: 0.8834 - val_loss: 0.8735 - val_accuracy: 0.6527\n","Epoch 83/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4632 - accuracy: 0.8896 - val_loss: 0.8957 - val_accuracy: 0.6516\n","Epoch 84/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4700 - accuracy: 0.8806 - val_loss: 0.8790 - val_accuracy: 0.6572\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4551 - accuracy: 0.8984 - val_loss: 0.8994 - val_accuracy: 0.6414\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4534 - accuracy: 0.8959 - val_loss: 0.9368 - val_accuracy: 0.6538\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4628 - accuracy: 0.8871 - val_loss: 0.8834 - val_accuracy: 0.6403\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4582 - accuracy: 0.8933 - val_loss: 0.8817 - val_accuracy: 0.6538\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4627 - accuracy: 0.8868 - val_loss: 0.9578 - val_accuracy: 0.6437\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4677 - accuracy: 0.8792 - val_loss: 0.9127 - val_accuracy: 0.6527\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4642 - accuracy: 0.8885 - val_loss: 0.8810 - val_accuracy: 0.6674\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4630 - accuracy: 0.8848 - val_loss: 0.8917 - val_accuracy: 0.6437\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4445 - accuracy: 0.8995 - val_loss: 0.9320 - val_accuracy: 0.6527\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4580 - accuracy: 0.8879 - val_loss: 0.8851 - val_accuracy: 0.6516\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4405 - accuracy: 0.9012 - val_loss: 0.9124 - val_accuracy: 0.6550\n","Epoch 96/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4496 - accuracy: 0.8945 - val_loss: 0.9022 - val_accuracy: 0.6403\n","Epoch 97/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4359 - accuracy: 0.9058 - val_loss: 0.8997 - val_accuracy: 0.6471\n","Epoch 98/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4732 - accuracy: 0.8679 - val_loss: 0.9415 - val_accuracy: 0.6550\n","Epoch 99/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4415 - accuracy: 0.9038 - val_loss: 0.8978 - val_accuracy: 0.6640\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4376 - accuracy: 0.8964 - val_loss: 0.9744 - val_accuracy: 0.6448\n","{'loss': [0.6771431565284729, 0.6158022880554199, 0.6159375905990601, 0.6135444641113281, 0.6055500507354736, 0.6059335470199585, 0.6004768013954163, 0.5995244979858398, 0.5903815031051636, 0.5943806767463684, 0.5858532190322876, 0.5887178778648376, 0.5973005294799805, 0.5821854472160339, 0.5804265141487122, 0.5927973985671997, 0.5777809023857117, 0.5842303037643433, 0.5736647248268127, 0.573519766330719, 0.5820040106773376, 0.576457142829895, 0.5656118392944336, 0.5658665299415588, 0.5607228875160217, 0.5648695826530457, 0.5772156119346619, 0.5603659749031067, 0.556990921497345, 0.5683088302612305, 0.5694087743759155, 0.5827993154525757, 0.5485786199569702, 0.5569835901260376, 0.5433223843574524, 0.544238805770874, 0.5534192323684692, 0.539021909236908, 0.5356881022453308, 0.5365839004516602, 0.527739405632019, 0.5406778454780579, 0.5404752492904663, 0.5291057229042053, 0.5468646883964539, 0.5310598611831665, 0.5225662589073181, 0.5209682583808899, 0.5205807089805603, 0.5210962891578674, 0.5256395936012268, 0.52900230884552, 0.52471524477005, 0.5094366669654846, 0.5163412094116211, 0.5234298706054688, 0.5176884531974792, 0.5039334893226624, 0.5066310167312622, 0.5288112759590149, 0.4976193308830261, 0.4975438117980957, 0.500345766544342, 0.5045017004013062, 0.49370276927948, 0.4986322224140167, 0.5110154151916504, 0.49463367462158203, 0.49655821919441223, 0.4843203127384186, 0.5011927485466003, 0.49140772223472595, 0.4857257306575775, 0.4896930456161499, 0.4763246476650238, 0.4751009941101074, 0.4853112995624542, 0.4684630334377289, 0.466367244720459, 0.4601961076259613, 0.4736085534095764, 0.4709773659706116, 0.4632420539855957, 0.46996161341667175, 0.45505475997924805, 0.4534456133842468, 0.4627821743488312, 0.45824629068374634, 0.46265938878059387, 0.46769246459007263, 0.46422508358955383, 0.46301648020744324, 0.44451549649238586, 0.458046555519104, 0.4404756426811218, 0.4496323764324188, 0.4359411597251892, 0.4732452630996704, 0.4415304362773895, 0.4375608265399933], 'accuracy': [0.7512733340263367, 0.801075279712677, 0.7931522130966187, 0.7942841053009033, 0.8033390045166016, 0.7982456088066101, 0.8036219477653503, 0.8081493973731995, 0.8174872398376465, 0.8098471760749817, 0.8101301789283752, 0.8149405717849731, 0.8121109008789062, 0.8211658000946045, 0.8203169107437134, 0.8132427930831909, 0.8220146894454956, 0.8109790682792664, 0.8203169107437134, 0.826259195804596, 0.8087153434753418, 0.8200339674949646, 0.8285229206085205, 0.8259762525558472, 0.8344652056694031, 0.8265421390533447, 0.8126768469810486, 0.8370118737220764, 0.8344652056694031, 0.8217317461967468, 0.821448802947998, 0.8087153434753418, 0.8446519374847412, 0.8330503702163696, 0.8415393233299255, 0.842954158782959, 0.8341822028160095, 0.8457838296890259, 0.8534238934516907, 0.8463497161865234, 0.8542727828025818, 0.8412563800811768, 0.8378607630729675, 0.8517261147499084, 0.835597038269043, 0.8491793870925903, 0.8551216721534729, 0.8613469004631042, 0.8568194508552551, 0.8548387289047241, 0.8528579473495483, 0.8418223261833191, 0.8508771657943726, 0.8644595146179199, 0.8585172891616821, 0.8537068367004395, 0.8551216721534729, 0.8621957898139954, 0.8607810139656067, 0.8446519374847412, 0.8698358535766602, 0.8672891855239868, 0.86332768201828, 0.8582342863082886, 0.8684210777282715, 0.8672891855239868, 0.8545557260513306, 0.8638936281204224, 0.8681380748748779, 0.8757781386375427, 0.8579513430595398, 0.8746463060379028, 0.8729485273361206, 0.8715336918830872, 0.8837012052536011, 0.8831352591514587, 0.8695529103279114, 0.8890775442123413, 0.8904923796653748, 0.8941709399223328, 0.8853989839553833, 0.8834182024002075, 0.8896434903144836, 0.8805885910987854, 0.8984153866767883, 0.895868718624115, 0.8870967626571655, 0.8933219909667969, 0.8868138194084167, 0.879173755645752, 0.888511598110199, 0.884833037853241, 0.899547278881073, 0.8879456520080566, 0.9012450575828552, 0.8944538831710815, 0.9057725071907043, 0.8678551316261292, 0.9037917256355286, 0.8964346647262573], 'val_loss': [0.8913256525993347, 0.8944457769393921, 0.8966026306152344, 0.9065704941749573, 0.9101651310920715, 0.929347038269043, 0.9254556894302368, 0.9612041711807251, 0.9570830464363098, 0.9882398247718811, 0.9988206624984741, 1.0738499164581299, 1.057105302810669, 1.0707491636276245, 1.0777926445007324, 1.0335475206375122, 1.0594161748886108, 1.016162633895874, 0.9127442836761475, 0.8682568669319153, 0.9248791933059692, 0.8607683777809143, 0.8595027923583984, 0.8448760509490967, 0.8426509499549866, 0.8370034098625183, 0.8206517696380615, 0.8267661929130554, 0.8212566375732422, 0.861494779586792, 0.8271034955978394, 0.8151706457138062, 0.8605097532272339, 0.8168329000473022, 0.8193145394325256, 0.8154231905937195, 0.8596364855766296, 0.8258972764015198, 0.8337728381156921, 0.8211290836334229, 0.8496090173721313, 0.8644281625747681, 0.8227841258049011, 0.859883189201355, 0.8253511190414429, 0.8444620370864868, 0.8453993797302246, 0.8349462747573853, 0.8256529569625854, 0.8482766151428223, 0.8427159786224365, 0.9562991261482239, 0.8555047512054443, 0.854455292224884, 0.8619101643562317, 0.843695878982544, 0.8699541091918945, 0.8588998913764954, 0.868034303188324, 0.8441001176834106, 0.8409616947174072, 0.8677843809127808, 0.8731693625450134, 0.8797274827957153, 0.8455213308334351, 0.8541885018348694, 0.854988157749176, 0.9075143337249756, 0.8525838255882263, 0.85866379737854, 0.9079089760780334, 0.8948577642440796, 0.9084451794624329, 0.9000819325447083, 0.863811731338501, 0.8625037670135498, 0.9145056009292603, 0.8736172914505005, 0.8643861413002014, 0.8719011545181274, 0.8698632717132568, 0.8735146522521973, 0.8956813812255859, 0.8790274858474731, 0.8994187712669373, 0.9367685914039612, 0.8833875060081482, 0.881703794002533, 0.9577770233154297, 0.912651777267456, 0.8809650540351868, 0.8916566371917725, 0.9320219159126282, 0.8850843906402588, 0.9123654365539551, 0.9021922945976257, 0.8997151851654053, 0.9415284395217896, 0.8978416323661804, 0.9744383692741394], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.4954751133918762, 0.49660632014274597, 0.49660632014274597, 0.49660632014274597, 0.49660632014274597, 0.49886876344680786, 0.4977375566959381, 0.5011312365531921, 0.5135746598243713, 0.5135746598243713, 0.529411792755127, 0.5486425161361694, 0.5780543088912964, 0.557692289352417, 0.6018099784851074, 0.6063348650932312, 0.6142534017562866, 0.6233031749725342, 0.6368778347969055, 0.6425339579582214, 0.6357465982437134, 0.6583710312843323, 0.6402714848518372, 0.6481900215148926, 0.668552041053772, 0.6493212580680847, 0.6640271544456482, 0.6606335043907166, 0.6730769276618958, 0.6493212580680847, 0.662895917892456, 0.6549773812294006, 0.668552041053772, 0.6538461446762085, 0.6414027214050293, 0.6708144545555115, 0.6504524946212769, 0.6606335043907166, 0.6640271544456482, 0.662895917892456, 0.6606335043907166, 0.6617646813392639, 0.6572397947311401, 0.6651583909988403, 0.6357465982437134, 0.6481900215148926, 0.6617646813392639, 0.6595022678375244, 0.6414027214050293, 0.6527149081230164, 0.6436651349067688, 0.6583710312843323, 0.6470588445663452, 0.6617646813392639, 0.6481900215148926, 0.6527149081230164, 0.6470588445663452, 0.6504524946212769, 0.6617646813392639, 0.6481900215148926, 0.6459276080131531, 0.6583710312843323, 0.6606335043907166, 0.6459276080131531, 0.6414027214050293, 0.651583731174469, 0.6436651349067688, 0.6527149081230164, 0.6527149081230164, 0.6436651349067688, 0.6606335043907166, 0.6561086177825928, 0.6583710312843323, 0.6595022678375244, 0.6527149081230164, 0.651583731174469, 0.6572397947311401, 0.6414027214050293, 0.6538461446762085, 0.6402714848518372, 0.6538461446762085, 0.6436651349067688, 0.6527149081230164, 0.6674208045005798, 0.6436651349067688, 0.6527149081230164, 0.651583731174469, 0.6549773812294006, 0.6402714848518372, 0.6470588445663452, 0.6549773812294006, 0.6640271544456482, 0.6447963714599609]}\n","45/45 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.7028 - accuracy: 0.7411"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 4s 36ms/step - loss: 0.6991 - accuracy: 0.7437 - val_loss: 0.8992 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6376 - accuracy: 0.7842 - val_loss: 0.9025 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6353 - accuracy: 0.7829 - val_loss: 0.9068 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6267 - accuracy: 0.7951 - val_loss: 0.9178 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6237 - accuracy: 0.7912 - val_loss: 0.9360 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6327 - accuracy: 0.7827 - val_loss: 0.9417 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6280 - accuracy: 0.7891 - val_loss: 0.9449 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6284 - accuracy: 0.7811 - val_loss: 0.9890 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6207 - accuracy: 0.7959 - val_loss: 0.9953 - val_accuracy: 0.4855\n","Epoch 10/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6158 - accuracy: 0.7972 - val_loss: 1.0418 - val_accuracy: 0.4866\n","Epoch 11/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6159 - accuracy: 0.7907 - val_loss: 1.0553 - val_accuracy: 0.4866\n","Epoch 12/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6144 - accuracy: 0.7977 - val_loss: 1.0700 - val_accuracy: 0.4886\n","Epoch 13/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6156 - accuracy: 0.7910 - val_loss: 1.0990 - val_accuracy: 0.4917\n","Epoch 14/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6047 - accuracy: 0.8062 - val_loss: 1.0822 - val_accuracy: 0.4948\n","Epoch 15/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.6032 - accuracy: 0.8150 - val_loss: 1.0704 - val_accuracy: 0.5031\n","Epoch 16/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.6100 - accuracy: 0.8005 - val_loss: 1.0284 - val_accuracy: 0.5093\n","Epoch 17/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6048 - accuracy: 0.8031 - val_loss: 0.9730 - val_accuracy: 0.5093\n","Epoch 18/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6049 - accuracy: 0.8044 - val_loss: 0.8962 - val_accuracy: 0.5517\n","Epoch 19/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6388 - accuracy: 0.7762 - val_loss: 0.9055 - val_accuracy: 0.5496\n","Epoch 20/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5989 - accuracy: 0.8034 - val_loss: 0.8730 - val_accuracy: 0.5919\n","Epoch 21/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5930 - accuracy: 0.8075 - val_loss: 0.8936 - val_accuracy: 0.5610\n","Epoch 22/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5972 - accuracy: 0.8111 - val_loss: 0.8609 - val_accuracy: 0.6178\n","Epoch 23/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6141 - accuracy: 0.7922 - val_loss: 0.8615 - val_accuracy: 0.6074\n","Epoch 24/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6029 - accuracy: 0.8000 - val_loss: 0.8575 - val_accuracy: 0.6147\n","Epoch 25/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6050 - accuracy: 0.7966 - val_loss: 0.8436 - val_accuracy: 0.6384\n","Epoch 26/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6047 - accuracy: 0.7933 - val_loss: 0.8365 - val_accuracy: 0.6457\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6041 - accuracy: 0.8003 - val_loss: 0.8729 - val_accuracy: 0.6333\n","Epoch 28/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5895 - accuracy: 0.8114 - val_loss: 0.8348 - val_accuracy: 0.6426\n","Epoch 29/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5946 - accuracy: 0.8075 - val_loss: 0.8280 - val_accuracy: 0.6622\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5889 - accuracy: 0.8137 - val_loss: 0.9718 - val_accuracy: 0.5826\n","Epoch 31/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6121 - accuracy: 0.7884 - val_loss: 0.8378 - val_accuracy: 0.6508\n","Epoch 32/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5907 - accuracy: 0.8093 - val_loss: 0.8307 - val_accuracy: 0.6632\n","Epoch 33/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5805 - accuracy: 0.8181 - val_loss: 0.8377 - val_accuracy: 0.6601\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5767 - accuracy: 0.8240 - val_loss: 0.8329 - val_accuracy: 0.6550\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5767 - accuracy: 0.8163 - val_loss: 0.8341 - val_accuracy: 0.6612\n","Epoch 36/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5697 - accuracy: 0.8287 - val_loss: 0.8581 - val_accuracy: 0.6488\n","Epoch 37/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5750 - accuracy: 0.8214 - val_loss: 0.8673 - val_accuracy: 0.6415\n","Epoch 38/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6362 - accuracy: 0.7718 - val_loss: 0.8517 - val_accuracy: 0.6519\n","Epoch 39/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5869 - accuracy: 0.8070 - val_loss: 0.8500 - val_accuracy: 0.6539\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5665 - accuracy: 0.8297 - val_loss: 0.8870 - val_accuracy: 0.6281\n","Epoch 41/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5720 - accuracy: 0.8233 - val_loss: 0.8451 - val_accuracy: 0.6612\n","Epoch 42/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5684 - accuracy: 0.8261 - val_loss: 0.8614 - val_accuracy: 0.6591\n","Epoch 43/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5715 - accuracy: 0.8191 - val_loss: 0.8530 - val_accuracy: 0.6601\n","Epoch 44/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5628 - accuracy: 0.8279 - val_loss: 0.8889 - val_accuracy: 0.6426\n","Epoch 45/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5648 - accuracy: 0.8295 - val_loss: 0.8674 - val_accuracy: 0.6519\n","Epoch 46/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5590 - accuracy: 0.8297 - val_loss: 0.8484 - val_accuracy: 0.6612\n","Epoch 47/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5605 - accuracy: 0.8264 - val_loss: 0.8489 - val_accuracy: 0.6653\n","Epoch 48/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5563 - accuracy: 0.8302 - val_loss: 0.8576 - val_accuracy: 0.6591\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5578 - accuracy: 0.8326 - val_loss: 0.8534 - val_accuracy: 0.6519\n","Epoch 50/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5499 - accuracy: 0.8372 - val_loss: 0.8593 - val_accuracy: 0.6632\n","Epoch 51/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5569 - accuracy: 0.8344 - val_loss: 0.8566 - val_accuracy: 0.6643\n","Epoch 52/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5535 - accuracy: 0.8341 - val_loss: 0.8604 - val_accuracy: 0.6519\n","Epoch 53/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5573 - accuracy: 0.8261 - val_loss: 0.8632 - val_accuracy: 0.6663\n","Epoch 54/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5449 - accuracy: 0.8380 - val_loss: 0.8621 - val_accuracy: 0.6674\n","Epoch 55/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5439 - accuracy: 0.8372 - val_loss: 0.8559 - val_accuracy: 0.6550\n","Epoch 56/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5496 - accuracy: 0.8372 - val_loss: 0.9060 - val_accuracy: 0.6312\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5457 - accuracy: 0.8406 - val_loss: 0.8711 - val_accuracy: 0.6519\n","Epoch 58/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5640 - accuracy: 0.8173 - val_loss: 0.8594 - val_accuracy: 0.6694\n","Epoch 59/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5413 - accuracy: 0.8393 - val_loss: 0.8625 - val_accuracy: 0.6529\n","Epoch 60/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5362 - accuracy: 0.8450 - val_loss: 0.8968 - val_accuracy: 0.6343\n","Epoch 61/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5476 - accuracy: 0.8320 - val_loss: 0.8995 - val_accuracy: 0.6436\n","Epoch 62/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5366 - accuracy: 0.8465 - val_loss: 0.8920 - val_accuracy: 0.6426\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5340 - accuracy: 0.8444 - val_loss: 0.9056 - val_accuracy: 0.6374\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5400 - accuracy: 0.8390 - val_loss: 0.8668 - val_accuracy: 0.6653\n","Epoch 65/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5384 - accuracy: 0.8429 - val_loss: 0.9415 - val_accuracy: 0.6147\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5254 - accuracy: 0.8512 - val_loss: 0.9135 - val_accuracy: 0.6364\n","Epoch 67/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5290 - accuracy: 0.8439 - val_loss: 0.8780 - val_accuracy: 0.6581\n","Epoch 68/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5190 - accuracy: 0.8563 - val_loss: 0.9022 - val_accuracy: 0.6446\n","Epoch 69/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5469 - accuracy: 0.8336 - val_loss: 0.8993 - val_accuracy: 0.6415\n","Epoch 70/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5231 - accuracy: 0.8499 - val_loss: 0.8724 - val_accuracy: 0.6684\n","Epoch 71/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5248 - accuracy: 0.8478 - val_loss: 0.9008 - val_accuracy: 0.6446\n","Epoch 72/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5298 - accuracy: 0.8475 - val_loss: 0.8903 - val_accuracy: 0.6560\n","Epoch 73/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5206 - accuracy: 0.8517 - val_loss: 0.8990 - val_accuracy: 0.6457\n","Epoch 74/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5146 - accuracy: 0.8589 - val_loss: 0.8980 - val_accuracy: 0.6539\n","Epoch 75/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5271 - accuracy: 0.8450 - val_loss: 0.9658 - val_accuracy: 0.6085\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5630 - accuracy: 0.8199 - val_loss: 0.8924 - val_accuracy: 0.6550\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5121 - accuracy: 0.8630 - val_loss: 0.9230 - val_accuracy: 0.6343\n","Epoch 78/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5177 - accuracy: 0.8501 - val_loss: 0.8849 - val_accuracy: 0.6581\n","Epoch 79/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5074 - accuracy: 0.8620 - val_loss: 0.9118 - val_accuracy: 0.6488\n","Epoch 80/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5140 - accuracy: 0.8499 - val_loss: 0.8886 - val_accuracy: 0.6694\n","Epoch 81/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5025 - accuracy: 0.8625 - val_loss: 0.9405 - val_accuracy: 0.6436\n","Epoch 82/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5227 - accuracy: 0.8439 - val_loss: 0.8955 - val_accuracy: 0.6405\n","Epoch 83/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5033 - accuracy: 0.8610 - val_loss: 0.8980 - val_accuracy: 0.6643\n","Epoch 84/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5139 - accuracy: 0.8537 - val_loss: 0.8969 - val_accuracy: 0.6570\n","Epoch 85/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4970 - accuracy: 0.8693 - val_loss: 1.0030 - val_accuracy: 0.6095\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5553 - accuracy: 0.8171 - val_loss: 0.8901 - val_accuracy: 0.6550\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4954 - accuracy: 0.8731 - val_loss: 0.9471 - val_accuracy: 0.6271\n","Epoch 88/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5030 - accuracy: 0.8594 - val_loss: 0.9088 - val_accuracy: 0.6415\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5120 - accuracy: 0.8501 - val_loss: 0.9789 - val_accuracy: 0.6054\n","Epoch 90/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5016 - accuracy: 0.8651 - val_loss: 0.9064 - val_accuracy: 0.6570\n","Epoch 91/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4916 - accuracy: 0.8690 - val_loss: 0.9160 - val_accuracy: 0.6570\n","Epoch 92/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4846 - accuracy: 0.8765 - val_loss: 0.9198 - val_accuracy: 0.6498\n","Epoch 93/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4983 - accuracy: 0.8638 - val_loss: 0.9342 - val_accuracy: 0.6405\n","Epoch 94/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5024 - accuracy: 0.8589 - val_loss: 0.9265 - val_accuracy: 0.6467\n","Epoch 95/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4797 - accuracy: 0.8757 - val_loss: 0.9345 - val_accuracy: 0.6415\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4975 - accuracy: 0.8607 - val_loss: 0.9126 - val_accuracy: 0.6519\n","Epoch 97/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4740 - accuracy: 0.8819 - val_loss: 0.9120 - val_accuracy: 0.6622\n","Epoch 98/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4828 - accuracy: 0.8762 - val_loss: 0.9106 - val_accuracy: 0.6570\n","Epoch 99/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4693 - accuracy: 0.8842 - val_loss: 0.9127 - val_accuracy: 0.6539\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4735 - accuracy: 0.8811 - val_loss: 0.9311 - val_accuracy: 0.6384\n","{'loss': [0.6990690231323242, 0.6375849843025208, 0.6352804899215698, 0.626720666885376, 0.623689591884613, 0.6327143311500549, 0.6279917359352112, 0.628373920917511, 0.6207245588302612, 0.6158332228660583, 0.6158779263496399, 0.6143698692321777, 0.615575909614563, 0.6046661138534546, 0.6031566262245178, 0.6099855303764343, 0.6048181056976318, 0.6048501133918762, 0.6388111710548401, 0.5988736152648926, 0.592978835105896, 0.5972221493721008, 0.6141356229782104, 0.6028513312339783, 0.6049743294715881, 0.604732096195221, 0.6041123270988464, 0.5895035862922668, 0.5945864319801331, 0.5889065265655518, 0.612092137336731, 0.5907303094863892, 0.5805191397666931, 0.5767371654510498, 0.576683759689331, 0.5696716904640198, 0.5750375390052795, 0.6362233757972717, 0.5868767499923706, 0.566469132900238, 0.5719988346099854, 0.5683993697166443, 0.5715193748474121, 0.5628145337104797, 0.5648229718208313, 0.5590053200721741, 0.5605013370513916, 0.5562705993652344, 0.5577598214149475, 0.5499454736709595, 0.556909441947937, 0.5535342693328857, 0.557287871837616, 0.5449233651161194, 0.5438752174377441, 0.5496206283569336, 0.545663595199585, 0.5639915466308594, 0.5413283109664917, 0.5361797213554382, 0.5476109385490417, 0.5365514755249023, 0.5340332388877869, 0.5399539470672607, 0.5384396910667419, 0.5254318118095398, 0.5290265083312988, 0.518977701663971, 0.5468592643737793, 0.5231001973152161, 0.524836540222168, 0.529772937297821, 0.5206234455108643, 0.5145690441131592, 0.5271080136299133, 0.5629740953445435, 0.5120794773101807, 0.5177492499351501, 0.5073694586753845, 0.514011800289154, 0.5025190711021423, 0.5227183103561401, 0.5033047795295715, 0.513938307762146, 0.4969761073589325, 0.5552951097488403, 0.4953587055206299, 0.5029831528663635, 0.5119523406028748, 0.5015679597854614, 0.4915776550769806, 0.48457854986190796, 0.49825042486190796, 0.5023790001869202, 0.47968071699142456, 0.497472882270813, 0.4740130603313446, 0.4827920198440552, 0.4693254232406616, 0.47345608472824097], 'accuracy': [0.7436692714691162, 0.7842377424240112, 0.7829457521438599, 0.7950904369354248, 0.7912144660949707, 0.7826873660087585, 0.7891472578048706, 0.7811369299888611, 0.7958656549453735, 0.7971576452255249, 0.7906976938247681, 0.7976744174957275, 0.7909560799598694, 0.8062015771865845, 0.814987063407898, 0.8005167841911316, 0.8031007647514343, 0.8043927550315857, 0.7762274146080017, 0.8033591508865356, 0.8074935674667358, 0.8111110925674438, 0.7922480702400208, 0.800000011920929, 0.7966408133506775, 0.7932816743850708, 0.8002583980560303, 0.8113695383071899, 0.8074935674667358, 0.8136950731277466, 0.7883720993995667, 0.8093023300170898, 0.8180878758430481, 0.8240309953689575, 0.8162790536880493, 0.8286821842193604, 0.8214470148086548, 0.7718346118927002, 0.8069767355918884, 0.8297157883644104, 0.8232558369636536, 0.8260982036590576, 0.8191214203834534, 0.8279069662094116, 0.8294573426246643, 0.8297157883644104, 0.8263565897941589, 0.830232560634613, 0.8325581550598145, 0.8372092843055725, 0.8343669176101685, 0.8341085314750671, 0.8260982036590576, 0.8379845023155212, 0.8372092843055725, 0.8372092843055725, 0.840568482875824, 0.8173126578330994, 0.8392764925956726, 0.8449612259864807, 0.832041323184967, 0.8465116024017334, 0.8444444537162781, 0.8390181064605713, 0.8428940773010254, 0.8511627912521362, 0.8439276218414307, 0.8563307523727417, 0.8335917592048645, 0.8498708009719849, 0.8478035926818848, 0.8475452065467834, 0.8516795635223389, 0.8589147329330444, 0.8449612259864807, 0.8198966383934021, 0.8630490899085999, 0.8501291871070862, 0.8620154857635498, 0.8498708009719849, 0.8625323176383972, 0.8439276218414307, 0.8609819412231445, 0.853746771812439, 0.8692506551742554, 0.817054271697998, 0.8731266260147095, 0.8594315052032471, 0.8501291871070862, 0.8651162981987, 0.868992269039154, 0.8764857649803162, 0.8638243079185486, 0.8589147329330444, 0.8757106065750122, 0.8607234954833984, 0.8819121718406677, 0.8762273788452148, 0.8842377066612244, 0.881136953830719], 'val_loss': [0.8991977572441101, 0.9024710059165955, 0.9067798852920532, 0.9177573919296265, 0.9360170960426331, 0.9417210817337036, 0.9448911547660828, 0.9890329241752625, 0.9952940344810486, 1.0417649745941162, 1.055260419845581, 1.070038080215454, 1.098994493484497, 1.0822268724441528, 1.0704439878463745, 1.028436541557312, 0.973045289516449, 0.8962186574935913, 0.905476987361908, 0.8729611039161682, 0.8936484456062317, 0.8608986735343933, 0.8615170121192932, 0.8574663400650024, 0.8436005115509033, 0.8365373015403748, 0.8729287981987, 0.8347996473312378, 0.8279921412467957, 0.971818745136261, 0.8378270864486694, 0.83069908618927, 0.8377326130867004, 0.8328613638877869, 0.8341376781463623, 0.8581058979034424, 0.8673104643821716, 0.8517061471939087, 0.8500327467918396, 0.8869768977165222, 0.845133364200592, 0.8614497780799866, 0.8529573678970337, 0.8889127969741821, 0.867435097694397, 0.8483679294586182, 0.8488682508468628, 0.857647716999054, 0.8534350395202637, 0.8593260049819946, 0.8566434383392334, 0.8603776097297668, 0.8631577491760254, 0.8620508313179016, 0.855878472328186, 0.905999481678009, 0.8711338639259338, 0.8593938946723938, 0.8625192642211914, 0.8968122005462646, 0.8995081186294556, 0.8919580578804016, 0.905561089515686, 0.8668056130409241, 0.9414823651313782, 0.9135121703147888, 0.8780315518379211, 0.902222752571106, 0.8993338942527771, 0.8723843693733215, 0.9007586240768433, 0.89033043384552, 0.8989576101303101, 0.8980178833007812, 0.9657931923866272, 0.892401933670044, 0.9229679107666016, 0.884861171245575, 0.9118180274963379, 0.8885735273361206, 0.9404982924461365, 0.8954532146453857, 0.8980013132095337, 0.8968518972396851, 1.0029748678207397, 0.8901152014732361, 0.9471226930618286, 0.9088438153266907, 0.9788755774497986, 0.9064248204231262, 0.9159882664680481, 0.9198157787322998, 0.934229850769043, 0.9265103936195374, 0.9345040917396545, 0.9125985503196716, 0.9120317101478577, 0.9106346964836121, 0.9127330183982849, 0.9311093688011169], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.48657023906707764, 0.4886363744735718, 0.4917355477809906, 0.4948347210884094, 0.5030992031097412, 0.5092975497245789, 0.5092975497245789, 0.5516529083251953, 0.5495867729187012, 0.5919421315193176, 0.5609503984451294, 0.6177685856819153, 0.6074380278587341, 0.6146694421768188, 0.6384297609329224, 0.6456611752510071, 0.6332644820213318, 0.6425619721412659, 0.6621900796890259, 0.5826446413993835, 0.6508264541625977, 0.663223147392273, 0.6601239442825317, 0.6549586653709412, 0.6611570119857788, 0.6487603187561035, 0.6415289044380188, 0.6518595218658447, 0.6539255976676941, 0.6280992031097412, 0.6611570119857788, 0.6590909361839294, 0.6601239442825317, 0.6425619721412659, 0.6518595218658447, 0.6611570119857788, 0.6652892827987671, 0.6590909361839294, 0.6518595218658447, 0.663223147392273, 0.66425621509552, 0.6518595218658447, 0.6663222908973694, 0.6673553586006165, 0.6549586653709412, 0.6311983466148376, 0.6518595218658447, 0.6694214940071106, 0.6528925895690918, 0.6342975497245789, 0.6435950398445129, 0.6425619721412659, 0.6373966932296753, 0.6652892827987671, 0.6146694421768188, 0.6363636255264282, 0.6580578684806824, 0.64462810754776, 0.6415289044380188, 0.6683884263038635, 0.64462810754776, 0.6559917330741882, 0.6456611752510071, 0.6539255976676941, 0.6084710955619812, 0.6549586653709412, 0.6342975497245789, 0.6580578684806824, 0.6487603187561035, 0.6694214940071106, 0.6435950398445129, 0.6404958963394165, 0.66425621509552, 0.6570248007774353, 0.6095041036605835, 0.6549586653709412, 0.6270661354064941, 0.6415289044380188, 0.60537189245224, 0.6570248007774353, 0.6570248007774353, 0.6497933864593506, 0.6404958963394165, 0.6466942429542542, 0.6415289044380188, 0.6518595218658447, 0.6621900796890259, 0.6570248007774353, 0.6539255976676941, 0.6384297609329224]}\n","32/32 [==============================] - 0s 3ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_CNN.round(3)"],"metadata":{"id":"y3RXIk-qZ7ts","colab":{"base_uri":"https://localhost:8080/","height":519},"executionInfo":{"status":"ok","timestamp":1717529742303,"user_tz":-360,"elapsed":29,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"outputId":"36eb50d6-9c18-4ad3-8add-803da389d10a","collapsed":true},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.504      0.505   0.456  0.479        0.456        0.553   \n","1        1     0.554      0.544   0.662  0.597        0.662        0.445   \n","2        2     0.588      0.641   0.402  0.494        0.402        0.775   \n","3        0     0.540      0.539   0.551  0.545        0.551        0.529   \n","4        1     0.576      0.596   0.468  0.524        0.468        0.684   \n","5        2     0.607      0.644   0.480  0.550        0.480        0.735   \n","6        0     0.570      0.618   0.369  0.462        0.369        0.772   \n","7        1     0.591      0.591   0.590  0.591        0.590        0.592   \n","8        2     0.612      0.626   0.558  0.590        0.558        0.667   \n","9        0     0.595      0.633   0.454  0.529        0.454        0.737   \n","10       1     0.631      0.663   0.534  0.592        0.534        0.729   \n","11       2     0.628      0.630   0.618  0.624        0.618        0.637   \n","12       0     0.624      0.688   0.454  0.547        0.454        0.794   \n","13       1     0.665      0.678   0.627  0.652        0.627        0.702   \n","14       2     0.653      0.670   0.602  0.634        0.602        0.703   \n","\n","    Kappa  \n","0   0.008  \n","1   0.107  \n","2   0.177  \n","3   0.080  \n","4   0.151  \n","5   0.215  \n","6   0.141  \n","7   0.182  \n","8   0.225  \n","9   0.191  \n","10  0.263  \n","11  0.255  \n","12  0.248  \n","13  0.329  \n","14  0.305  "],"text/html":["\n","  <div id=\"df-20f1b036-911b-4e4c-aabe-cf7cfc5a872c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.504</td>\n","      <td>0.505</td>\n","      <td>0.456</td>\n","      <td>0.479</td>\n","      <td>0.456</td>\n","      <td>0.553</td>\n","      <td>0.008</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.554</td>\n","      <td>0.544</td>\n","      <td>0.662</td>\n","      <td>0.597</td>\n","      <td>0.662</td>\n","      <td>0.445</td>\n","      <td>0.107</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.588</td>\n","      <td>0.641</td>\n","      <td>0.402</td>\n","      <td>0.494</td>\n","      <td>0.402</td>\n","      <td>0.775</td>\n","      <td>0.177</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.540</td>\n","      <td>0.539</td>\n","      <td>0.551</td>\n","      <td>0.545</td>\n","      <td>0.551</td>\n","      <td>0.529</td>\n","      <td>0.080</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.576</td>\n","      <td>0.596</td>\n","      <td>0.468</td>\n","      <td>0.524</td>\n","      <td>0.468</td>\n","      <td>0.684</td>\n","      <td>0.151</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.607</td>\n","      <td>0.644</td>\n","      <td>0.480</td>\n","      <td>0.550</td>\n","      <td>0.480</td>\n","      <td>0.735</td>\n","      <td>0.215</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.570</td>\n","      <td>0.618</td>\n","      <td>0.369</td>\n","      <td>0.462</td>\n","      <td>0.369</td>\n","      <td>0.772</td>\n","      <td>0.141</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.591</td>\n","      <td>0.591</td>\n","      <td>0.590</td>\n","      <td>0.591</td>\n","      <td>0.590</td>\n","      <td>0.592</td>\n","      <td>0.182</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.612</td>\n","      <td>0.626</td>\n","      <td>0.558</td>\n","      <td>0.590</td>\n","      <td>0.558</td>\n","      <td>0.667</td>\n","      <td>0.225</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.595</td>\n","      <td>0.633</td>\n","      <td>0.454</td>\n","      <td>0.529</td>\n","      <td>0.454</td>\n","      <td>0.737</td>\n","      <td>0.191</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.631</td>\n","      <td>0.663</td>\n","      <td>0.534</td>\n","      <td>0.592</td>\n","      <td>0.534</td>\n","      <td>0.729</td>\n","      <td>0.263</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.628</td>\n","      <td>0.630</td>\n","      <td>0.618</td>\n","      <td>0.624</td>\n","      <td>0.618</td>\n","      <td>0.637</td>\n","      <td>0.255</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.624</td>\n","      <td>0.688</td>\n","      <td>0.454</td>\n","      <td>0.547</td>\n","      <td>0.454</td>\n","      <td>0.794</td>\n","      <td>0.248</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.665</td>\n","      <td>0.678</td>\n","      <td>0.627</td>\n","      <td>0.652</td>\n","      <td>0.627</td>\n","      <td>0.702</td>\n","      <td>0.329</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.653</td>\n","      <td>0.670</td>\n","      <td>0.602</td>\n","      <td>0.634</td>\n","      <td>0.602</td>\n","      <td>0.703</td>\n","      <td>0.305</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20f1b036-911b-4e4c-aabe-cf7cfc5a872c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-20f1b036-911b-4e4c-aabe-cf7cfc5a872c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-20f1b036-911b-4e4c-aabe-cf7cfc5a872c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ba6fb4ea-3cd6-4482-87f5-5f4264346131\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ba6fb4ea-3cd6-4482-87f5-5f4264346131')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ba6fb4ea-3cd6-4482-87f5-5f4264346131 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df_CNN\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04305290211997771,\n        \"min\": 0.504,\n        \"max\": 0.665,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.595,\n          0.628,\n          0.504\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05382838691708342,\n        \"min\": 0.505,\n        \"max\": 0.688,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.633,\n          0.63,\n          0.505\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08833270440027671,\n        \"min\": 0.369,\n        \"max\": 0.662,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.454,\n          0.618,\n          0.456\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05704342539638008,\n        \"min\": 0.462,\n        \"max\": 0.652,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.529,\n          0.624,\n          0.479\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08833270440027671,\n        \"min\": 0.369,\n        \"max\": 0.662,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.454,\n          0.618,\n          0.456\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10095435083432983,\n        \"min\": 0.445,\n        \"max\": 0.794,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.737,\n          0.637,\n          0.553\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08599601319662609,\n        \"min\": 0.008,\n        \"max\": 0.329,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.191,\n          0.255,\n          0.008\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["metrics_df_CNN.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/DWT/CNN/Alpha_DWT_CNN.csv', index = False)"],"metadata":{"id":"_iOLsKpkfzdG","executionInfo":{"status":"ok","timestamp":1717529742304,"user_tz":-360,"elapsed":12,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# GRU"],"metadata":{"id":"GPlWZUcV48bB"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model_gru(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(GRU(256, return_sequences=True))\n","    model.add(GRU(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning_gru(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model_gru(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model_gru(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Alpha/CNN_GRU/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Alpha/CNN_GRU/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n","\n"],"metadata":{"id":"ieXSN-9PI4Dx","executionInfo":{"status":"ok","timestamp":1717529742304,"user_tz":-360,"elapsed":11,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["global_model_gru, metrics_df_gru = federated_learning_gru(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"lD5S-Pvy5B-r","executionInfo":{"status":"ok","timestamp":1717530984336,"user_tz":-360,"elapsed":1143861,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"outputId":"bfa0de19-a427-4e70-a8d5-190ab962c07e"},"execution_count":17,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 1.8194 - accuracy: 0.5043"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 7s 58ms/step - loss: 1.8191 - accuracy: 0.5040 - val_loss: 1.8139 - val_accuracy: 0.5151\n","Epoch 2/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.8090 - accuracy: 0.5030 - val_loss: 1.8040 - val_accuracy: 0.5151\n","Epoch 3/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.7995 - accuracy: 0.4962 - val_loss: 1.7942 - val_accuracy: 0.5151\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.7892 - accuracy: 0.5170 - val_loss: 1.7845 - val_accuracy: 0.5151\n","Epoch 5/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.7799 - accuracy: 0.5108 - val_loss: 1.7750 - val_accuracy: 0.5506\n","Epoch 6/100\n","29/29 [==============================] - 1s 32ms/step - loss: 1.7703 - accuracy: 0.5092 - val_loss: 1.7655 - val_accuracy: 0.5700\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.7608 - accuracy: 0.5170 - val_loss: 1.7562 - val_accuracy: 0.4860\n","Epoch 8/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.7513 - accuracy: 0.5040 - val_loss: 1.7469 - val_accuracy: 0.5841\n","Epoch 9/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.7421 - accuracy: 0.5145 - val_loss: 1.7376 - val_accuracy: 0.5711\n","Epoch 10/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.7326 - accuracy: 0.5248 - val_loss: 1.7284 - val_accuracy: 0.5625\n","Epoch 11/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.7236 - accuracy: 0.5070 - val_loss: 1.7192 - val_accuracy: 0.5151\n","Epoch 12/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.7145 - accuracy: 0.5207 - val_loss: 1.7102 - val_accuracy: 0.5474\n","Epoch 13/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.7054 - accuracy: 0.5221 - val_loss: 1.7010 - val_accuracy: 0.5151\n","Epoch 14/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.6968 - accuracy: 0.5216 - val_loss: 1.6922 - val_accuracy: 0.5593\n","Epoch 15/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.6879 - accuracy: 0.5197 - val_loss: 1.6833 - val_accuracy: 0.5485\n","Epoch 16/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.6781 - accuracy: 0.5364 - val_loss: 1.6745 - val_accuracy: 0.5593\n","Epoch 17/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.6699 - accuracy: 0.5463 - val_loss: 1.6660 - val_accuracy: 0.5765\n","Epoch 18/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.6610 - accuracy: 0.5269 - val_loss: 1.6568 - val_accuracy: 0.5151\n","Epoch 19/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.6545 - accuracy: 0.5127 - val_loss: 1.6488 - val_accuracy: 0.5884\n","Epoch 20/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.6436 - accuracy: 0.5474 - val_loss: 1.6396 - val_accuracy: 0.5722\n","Epoch 21/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.6362 - accuracy: 0.5256 - val_loss: 1.6311 - val_accuracy: 0.6002\n","Epoch 22/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.6279 - accuracy: 0.5369 - val_loss: 1.6221 - val_accuracy: 0.5431\n","Epoch 23/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.6192 - accuracy: 0.5401 - val_loss: 1.6135 - val_accuracy: 0.5560\n","Epoch 24/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.6110 - accuracy: 0.5396 - val_loss: 1.6059 - val_accuracy: 0.5657\n","Epoch 25/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.6020 - accuracy: 0.5590 - val_loss: 1.5966 - val_accuracy: 0.5506\n","Epoch 26/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.5950 - accuracy: 0.5493 - val_loss: 1.5884 - val_accuracy: 0.5453\n","Epoch 27/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.5859 - accuracy: 0.5506 - val_loss: 1.5803 - val_accuracy: 0.5948\n","Epoch 28/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.5774 - accuracy: 0.5682 - val_loss: 1.5710 - val_accuracy: 0.5571\n","Epoch 29/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.5704 - accuracy: 0.5574 - val_loss: 1.5633 - val_accuracy: 0.6013\n","Epoch 30/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.5614 - accuracy: 0.5660 - val_loss: 1.5555 - val_accuracy: 0.5970\n","Epoch 31/100\n","29/29 [==============================] - 1s 35ms/step - loss: 1.5547 - accuracy: 0.5531 - val_loss: 1.5461 - val_accuracy: 0.6034\n","Epoch 32/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.5460 - accuracy: 0.5620 - val_loss: 1.5389 - val_accuracy: 0.5959\n","Epoch 33/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.5377 - accuracy: 0.5695 - val_loss: 1.5297 - val_accuracy: 0.5819\n","Epoch 34/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.5298 - accuracy: 0.5687 - val_loss: 1.5240 - val_accuracy: 0.5841\n","Epoch 35/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.5235 - accuracy: 0.5644 - val_loss: 1.5140 - val_accuracy: 0.5862\n","Epoch 36/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.5129 - accuracy: 0.5744 - val_loss: 1.5064 - val_accuracy: 0.6045\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.5075 - accuracy: 0.5695 - val_loss: 1.4987 - val_accuracy: 0.6045\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4998 - accuracy: 0.5741 - val_loss: 1.5036 - val_accuracy: 0.5280\n","Epoch 39/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4921 - accuracy: 0.5735 - val_loss: 1.4846 - val_accuracy: 0.6034\n","Epoch 40/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.4844 - accuracy: 0.5746 - val_loss: 1.4766 - val_accuracy: 0.6034\n","Epoch 41/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4783 - accuracy: 0.5719 - val_loss: 1.4764 - val_accuracy: 0.5765\n","Epoch 42/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4700 - accuracy: 0.5773 - val_loss: 1.4643 - val_accuracy: 0.5657\n","Epoch 43/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4624 - accuracy: 0.5792 - val_loss: 1.4583 - val_accuracy: 0.6013\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4568 - accuracy: 0.5789 - val_loss: 1.4509 - val_accuracy: 0.5679\n","Epoch 45/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4502 - accuracy: 0.5811 - val_loss: 1.4518 - val_accuracy: 0.5765\n","Epoch 46/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.4454 - accuracy: 0.5773 - val_loss: 1.4370 - val_accuracy: 0.5873\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4374 - accuracy: 0.5797 - val_loss: 1.4306 - val_accuracy: 0.5873\n","Epoch 48/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4314 - accuracy: 0.5800 - val_loss: 1.4283 - val_accuracy: 0.5614\n","Epoch 49/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4249 - accuracy: 0.5841 - val_loss: 1.4187 - val_accuracy: 0.5991\n","Epoch 50/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4181 - accuracy: 0.5822 - val_loss: 1.4159 - val_accuracy: 0.5981\n","Epoch 51/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.4127 - accuracy: 0.5830 - val_loss: 1.4067 - val_accuracy: 0.5916\n","Epoch 52/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.4049 - accuracy: 0.5824 - val_loss: 1.4021 - val_accuracy: 0.5787\n","Epoch 53/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.4006 - accuracy: 0.5797 - val_loss: 1.3955 - val_accuracy: 0.6078\n","Epoch 54/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3933 - accuracy: 0.5832 - val_loss: 1.4051 - val_accuracy: 0.5700\n","Epoch 55/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3887 - accuracy: 0.5929 - val_loss: 1.3842 - val_accuracy: 0.5873\n","Epoch 56/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3854 - accuracy: 0.5773 - val_loss: 1.3819 - val_accuracy: 0.5603\n","Epoch 57/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3783 - accuracy: 0.5814 - val_loss: 1.3891 - val_accuracy: 0.5679\n","Epoch 58/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3711 - accuracy: 0.5854 - val_loss: 1.3670 - val_accuracy: 0.5991\n","Epoch 59/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3656 - accuracy: 0.5908 - val_loss: 1.3754 - val_accuracy: 0.5700\n","Epoch 60/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3616 - accuracy: 0.5814 - val_loss: 1.3601 - val_accuracy: 0.5991\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3533 - accuracy: 0.5916 - val_loss: 1.3520 - val_accuracy: 0.5819\n","Epoch 62/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3505 - accuracy: 0.5841 - val_loss: 1.3457 - val_accuracy: 0.5959\n","Epoch 63/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3443 - accuracy: 0.5878 - val_loss: 1.3401 - val_accuracy: 0.6056\n","Epoch 64/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3382 - accuracy: 0.5824 - val_loss: 1.3347 - val_accuracy: 0.6002\n","Epoch 65/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3339 - accuracy: 0.5902 - val_loss: 1.3304 - val_accuracy: 0.5938\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3296 - accuracy: 0.5908 - val_loss: 1.3247 - val_accuracy: 0.5991\n","Epoch 67/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3241 - accuracy: 0.5854 - val_loss: 1.3263 - val_accuracy: 0.5916\n","Epoch 68/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3187 - accuracy: 0.5881 - val_loss: 1.3191 - val_accuracy: 0.6024\n","Epoch 69/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3135 - accuracy: 0.5908 - val_loss: 1.3095 - val_accuracy: 0.5981\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3080 - accuracy: 0.6005 - val_loss: 1.3183 - val_accuracy: 0.5668\n","Epoch 71/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3026 - accuracy: 0.5870 - val_loss: 1.2995 - val_accuracy: 0.5948\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2953 - accuracy: 0.5938 - val_loss: 1.2947 - val_accuracy: 0.5970\n","Epoch 73/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2906 - accuracy: 0.5991 - val_loss: 1.2937 - val_accuracy: 0.6067\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2869 - accuracy: 0.5948 - val_loss: 1.2852 - val_accuracy: 0.6013\n","Epoch 75/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.2860 - accuracy: 0.5841 - val_loss: 1.2839 - val_accuracy: 0.5722\n","Epoch 76/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.2776 - accuracy: 0.5951 - val_loss: 1.2769 - val_accuracy: 0.6056\n","Epoch 77/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2738 - accuracy: 0.5865 - val_loss: 1.2706 - val_accuracy: 0.6034\n","Epoch 78/100\n","29/29 [==============================] - 1s 50ms/step - loss: 1.2691 - accuracy: 0.5889 - val_loss: 1.2683 - val_accuracy: 0.6088\n","Epoch 79/100\n","29/29 [==============================] - 1s 31ms/step - loss: 1.2632 - accuracy: 0.5929 - val_loss: 1.2630 - val_accuracy: 0.6099\n","Epoch 80/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2589 - accuracy: 0.5956 - val_loss: 1.2576 - val_accuracy: 0.5970\n","Epoch 81/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2549 - accuracy: 0.5908 - val_loss: 1.2525 - val_accuracy: 0.6002\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2502 - accuracy: 0.5911 - val_loss: 1.2504 - val_accuracy: 0.5744\n","Epoch 83/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.2459 - accuracy: 0.5956 - val_loss: 1.2436 - val_accuracy: 0.5970\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2396 - accuracy: 0.5913 - val_loss: 1.2393 - val_accuracy: 0.5991\n","Epoch 85/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.2389 - accuracy: 0.5927 - val_loss: 1.2361 - val_accuracy: 0.6067\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2333 - accuracy: 0.5986 - val_loss: 1.2485 - val_accuracy: 0.5657\n","Epoch 87/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.2291 - accuracy: 0.5892 - val_loss: 1.2317 - val_accuracy: 0.5991\n","Epoch 88/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2231 - accuracy: 0.5970 - val_loss: 1.2312 - val_accuracy: 0.5830\n","Epoch 89/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.2173 - accuracy: 0.5973 - val_loss: 1.2179 - val_accuracy: 0.5981\n","Epoch 90/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.2140 - accuracy: 0.5981 - val_loss: 1.2154 - val_accuracy: 0.6056\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2103 - accuracy: 0.5943 - val_loss: 1.2114 - val_accuracy: 0.5819\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2095 - accuracy: 0.5892 - val_loss: 1.2073 - val_accuracy: 0.5765\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2034 - accuracy: 0.5946 - val_loss: 1.2027 - val_accuracy: 0.5873\n","Epoch 94/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1993 - accuracy: 0.5959 - val_loss: 1.1969 - val_accuracy: 0.5981\n","Epoch 95/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1920 - accuracy: 0.6024 - val_loss: 1.1974 - val_accuracy: 0.6099\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1896 - accuracy: 0.6029 - val_loss: 1.1898 - val_accuracy: 0.6002\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1822 - accuracy: 0.5991 - val_loss: 1.1946 - val_accuracy: 0.5808\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1814 - accuracy: 0.5948 - val_loss: 1.1879 - val_accuracy: 0.5991\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1767 - accuracy: 0.5997 - val_loss: 1.1774 - val_accuracy: 0.5981\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1716 - accuracy: 0.6013 - val_loss: 1.1752 - val_accuracy: 0.6099\n","{'loss': [1.8190677165985107, 1.80897855758667, 1.7995009422302246, 1.7891634702682495, 1.7799090147018433, 1.7703338861465454, 1.7607645988464355, 1.751279592514038, 1.742082953453064, 1.7325587272644043, 1.723585605621338, 1.7144646644592285, 1.705445408821106, 1.6967824697494507, 1.6879000663757324, 1.6781471967697144, 1.669944405555725, 1.6609753370285034, 1.6545088291168213, 1.643630862236023, 1.6361706256866455, 1.6279420852661133, 1.6192190647125244, 1.610964059829712, 1.6019772291183472, 1.5949591398239136, 1.5859099626541138, 1.577446460723877, 1.5703712701797485, 1.561400055885315, 1.5547096729278564, 1.5460268259048462, 1.5376585721969604, 1.5298447608947754, 1.5234981775283813, 1.5128703117370605, 1.5074944496154785, 1.499769926071167, 1.492067575454712, 1.4843701124191284, 1.4782741069793701, 1.4699504375457764, 1.4623544216156006, 1.4568192958831787, 1.4502372741699219, 1.4453628063201904, 1.4373527765274048, 1.431435465812683, 1.4248757362365723, 1.4181100130081177, 1.4126678705215454, 1.4049370288848877, 1.4005695581436157, 1.39325749874115, 1.388675332069397, 1.3854165077209473, 1.3782881498336792, 1.3711010217666626, 1.3656479120254517, 1.3615859746932983, 1.3532707691192627, 1.3505189418792725, 1.3443374633789062, 1.338226079940796, 1.3339279890060425, 1.3296486139297485, 1.3240598440170288, 1.3186795711517334, 1.3134543895721436, 1.308046579360962, 1.302567481994629, 1.2953011989593506, 1.2905982732772827, 1.2869000434875488, 1.2860132455825806, 1.2776497602462769, 1.273759365081787, 1.2690850496292114, 1.2631661891937256, 1.2589465379714966, 1.2549041509628296, 1.2501899003982544, 1.245877981185913, 1.2395926713943481, 1.2389487028121948, 1.2333083152770996, 1.2290714979171753, 1.2230788469314575, 1.2172529697418213, 1.2140283584594727, 1.2103040218353271, 1.2094842195510864, 1.203444480895996, 1.1993472576141357, 1.1920382976531982, 1.1896029710769653, 1.182152509689331, 1.1814080476760864, 1.1766775846481323, 1.1716071367263794], 'accuracy': [0.5040409564971924, 0.5029633641242981, 0.4962284564971924, 0.516972005367279, 0.5107758641242981, 0.509159505367279, 0.516972005367279, 0.5040409564971924, 0.5145474076271057, 0.524784505367279, 0.5070043206214905, 0.5207435488700867, 0.522090494632721, 0.5215517282485962, 0.5196659564971924, 0.5363685488700867, 0.5463362336158752, 0.5269396305084229, 0.5126616358757019, 0.5474137663841248, 0.5255926847457886, 0.5369073152542114, 0.5401400923728943, 0.5396012663841248, 0.5589978694915771, 0.5492995977401733, 0.5506465435028076, 0.5681573152542114, 0.5573814511299133, 0.5660021305084229, 0.553071141242981, 0.5619612336158752, 0.5695043206214905, 0.568696141242981, 0.5643857717514038, 0.5743534564971924, 0.5695043206214905, 0.5740840435028076, 0.5735452771186829, 0.5746228694915771, 0.571928858757019, 0.5773168206214905, 0.5792025923728943, 0.5789331793785095, 0.5810883641242981, 0.5773168206214905, 0.579741358757019, 0.5800107717514038, 0.5840517282485962, 0.5821659564971924, 0.5829741358757019, 0.5824353694915771, 0.579741358757019, 0.5832435488700867, 0.5929418206214905, 0.5773168206214905, 0.5813577771186829, 0.5853987336158752, 0.5907866358757019, 0.5813577771186829, 0.5915948152542114, 0.5840517282485962, 0.5878232717514038, 0.5824353694915771, 0.5902478694915771, 0.5907866358757019, 0.5853987336158752, 0.5880926847457886, 0.5907866358757019, 0.6004849076271057, 0.5870150923728943, 0.59375, 0.5991379022598267, 0.5948275923728943, 0.5840517282485962, 0.595097005367279, 0.5864762663841248, 0.5889008641242981, 0.5929418206214905, 0.5956357717514038, 0.5907866358757019, 0.5910560488700867, 0.5956357717514038, 0.5913254022598267, 0.5926724076271057, 0.5985991358757019, 0.5891702771186829, 0.5969827771186829, 0.5972521305084229, 0.5980603694915771, 0.5942887663841248, 0.5891702771186829, 0.5945581793785095, 0.5959051847457886, 0.6023706793785095, 0.602909505367279, 0.5991379022598267, 0.5948275923728943, 0.5996767282485962, 0.6012930870056152], 'val_loss': [1.8138514757156372, 1.8040287494659424, 1.794194221496582, 1.784520149230957, 1.7750293016433716, 1.765549659729004, 1.7562260627746582, 1.7468602657318115, 1.7376463413238525, 1.728442668914795, 1.719248652458191, 1.7102493047714233, 1.7010496854782104, 1.6922489404678345, 1.6832998991012573, 1.6744601726531982, 1.666000485420227, 1.6568286418914795, 1.6488138437271118, 1.6395751237869263, 1.631080150604248, 1.6220999956130981, 1.6135271787643433, 1.6058892011642456, 1.5965766906738281, 1.5883785486221313, 1.5803215503692627, 1.5710093975067139, 1.5633455514907837, 1.5554801225662231, 1.5461037158966064, 1.5389138460159302, 1.5297157764434814, 1.523998498916626, 1.5140479803085327, 1.5063564777374268, 1.4986597299575806, 1.503649115562439, 1.4846391677856445, 1.4766384363174438, 1.4764227867126465, 1.4643464088439941, 1.4582953453063965, 1.4508801698684692, 1.4518442153930664, 1.4370298385620117, 1.4306364059448242, 1.4282599687576294, 1.4186769723892212, 1.4158927202224731, 1.406665325164795, 1.4020559787750244, 1.395498514175415, 1.4050707817077637, 1.3841519355773926, 1.3818769454956055, 1.3890538215637207, 1.3669530153274536, 1.37538743019104, 1.3600976467132568, 1.3520383834838867, 1.3457087278366089, 1.340057611465454, 1.3346623182296753, 1.3303630352020264, 1.3247206211090088, 1.3262721300125122, 1.319111943244934, 1.3095020055770874, 1.3182579278945923, 1.2994757890701294, 1.294675588607788, 1.2936875820159912, 1.2852360010147095, 1.283859372138977, 1.2768710851669312, 1.2706396579742432, 1.268256425857544, 1.2629643678665161, 1.2575504779815674, 1.2524583339691162, 1.2504310607910156, 1.2436482906341553, 1.239277958869934, 1.2361103296279907, 1.2484694719314575, 1.231654167175293, 1.2311770915985107, 1.2178595066070557, 1.2154144048690796, 1.2113618850708008, 1.2072639465332031, 1.2027337551116943, 1.196946620941162, 1.197434902191162, 1.1897879838943481, 1.1946321725845337, 1.1879498958587646, 1.1774041652679443, 1.1751731634140015], 'val_accuracy': [0.5150862336158752, 0.5150862336158752, 0.5150862336158752, 0.5150862336158752, 0.5506465435028076, 0.5700430870056152, 0.48599138855934143, 0.5840517282485962, 0.5711206793785095, 0.5625, 0.5150862336158752, 0.5474137663841248, 0.5150862336158752, 0.5592672228813171, 0.548491358757019, 0.5592672228813171, 0.576508641242981, 0.5150862336158752, 0.5883620977401733, 0.5721982717514038, 0.600215494632721, 0.5431034564971924, 0.556034505367279, 0.5657327771186829, 0.5506465435028076, 0.545258641242981, 0.5948275923728943, 0.5571120977401733, 0.6012930870056152, 0.5969827771186829, 0.6034482717514038, 0.5959051847457886, 0.5818965435028076, 0.5840517282485962, 0.5862069129943848, 0.6045258641242981, 0.6045258641242981, 0.5280172228813171, 0.6034482717514038, 0.6034482717514038, 0.576508641242981, 0.5657327771186829, 0.6012930870056152, 0.5678879022598267, 0.576508641242981, 0.587284505367279, 0.587284505367279, 0.5614224076271057, 0.5991379022598267, 0.5980603694915771, 0.5915948152542114, 0.5786637663841248, 0.607758641242981, 0.5700430870056152, 0.587284505367279, 0.5603448152542114, 0.5678879022598267, 0.5991379022598267, 0.5700430870056152, 0.5991379022598267, 0.5818965435028076, 0.5959051847457886, 0.6056034564971924, 0.600215494632721, 0.59375, 0.5991379022598267, 0.5915948152542114, 0.6023706793785095, 0.5980603694915771, 0.5668103694915771, 0.5948275923728943, 0.5969827771186829, 0.6066810488700867, 0.6012930870056152, 0.5721982717514038, 0.6056034564971924, 0.6034482717514038, 0.6088362336158752, 0.6099137663841248, 0.5969827771186829, 0.600215494632721, 0.5743534564971924, 0.5969827771186829, 0.5991379022598267, 0.6066810488700867, 0.5657327771186829, 0.5991379022598267, 0.5829741358757019, 0.5980603694915771, 0.6056034564971924, 0.5818965435028076, 0.576508641242981, 0.587284505367279, 0.5980603694915771, 0.6099137663841248, 0.600215494632721, 0.5808189511299133, 0.5991379022598267, 0.5980603694915771, 0.6099137663841248]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 1.8195 - accuracy: 0.4910"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 61ms/step - loss: 1.8194 - accuracy: 0.4918 - val_loss: 1.8140 - val_accuracy: 0.5045\n","Epoch 2/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.8093 - accuracy: 0.5020 - val_loss: 1.8045 - val_accuracy: 0.5045\n","Epoch 3/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.8000 - accuracy: 0.5031 - val_loss: 1.7950 - val_accuracy: 0.5045\n","Epoch 4/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.7910 - accuracy: 0.4994 - val_loss: 1.7856 - val_accuracy: 0.5045\n","Epoch 5/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.7813 - accuracy: 0.4975 - val_loss: 1.7764 - val_accuracy: 0.5045\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.7722 - accuracy: 0.5076 - val_loss: 1.7673 - val_accuracy: 0.5045\n","Epoch 7/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.7627 - accuracy: 0.5187 - val_loss: 1.7582 - val_accuracy: 0.5045\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.7539 - accuracy: 0.5082 - val_loss: 1.7492 - val_accuracy: 0.5045\n","Epoch 9/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.7446 - accuracy: 0.5156 - val_loss: 1.7402 - val_accuracy: 0.5045\n","Epoch 10/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.7360 - accuracy: 0.5051 - val_loss: 1.7313 - val_accuracy: 0.5045\n","Epoch 11/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.7267 - accuracy: 0.5246 - val_loss: 1.7224 - val_accuracy: 0.5045\n","Epoch 12/100\n","28/28 [==============================] - 1s 30ms/step - loss: 1.7175 - accuracy: 0.5328 - val_loss: 1.7136 - val_accuracy: 0.5057\n","Epoch 13/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.7090 - accuracy: 0.5099 - val_loss: 1.7048 - val_accuracy: 0.5034\n","Epoch 14/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.7008 - accuracy: 0.5119 - val_loss: 1.6961 - val_accuracy: 0.5645\n","Epoch 15/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.6915 - accuracy: 0.5306 - val_loss: 1.6875 - val_accuracy: 0.5034\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.6832 - accuracy: 0.5297 - val_loss: 1.6789 - val_accuracy: 0.5215\n","Epoch 17/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.6748 - accuracy: 0.5283 - val_loss: 1.6705 - val_accuracy: 0.5192\n","Epoch 18/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.6663 - accuracy: 0.5274 - val_loss: 1.6620 - val_accuracy: 0.5475\n","Epoch 19/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.6572 - accuracy: 0.5371 - val_loss: 1.6536 - val_accuracy: 0.5735\n","Epoch 20/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.6494 - accuracy: 0.5340 - val_loss: 1.6453 - val_accuracy: 0.5498\n","Epoch 21/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.6411 - accuracy: 0.5269 - val_loss: 1.6368 - val_accuracy: 0.5860\n","Epoch 22/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.6324 - accuracy: 0.5492 - val_loss: 1.6285 - val_accuracy: 0.5803\n","Epoch 23/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.6250 - accuracy: 0.5405 - val_loss: 1.6205 - val_accuracy: 0.5543\n","Epoch 24/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.6170 - accuracy: 0.5325 - val_loss: 1.6121 - val_accuracy: 0.5656\n","Epoch 25/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.6087 - accuracy: 0.5464 - val_loss: 1.6040 - val_accuracy: 0.5226\n","Epoch 26/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.6007 - accuracy: 0.5461 - val_loss: 1.5959 - val_accuracy: 0.5260\n","Epoch 27/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5931 - accuracy: 0.5413 - val_loss: 1.5881 - val_accuracy: 0.5249\n","Epoch 28/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.5853 - accuracy: 0.5354 - val_loss: 1.5808 - val_accuracy: 0.5124\n","Epoch 29/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.5762 - accuracy: 0.5594 - val_loss: 1.5721 - val_accuracy: 0.5882\n","Epoch 30/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.5694 - accuracy: 0.5478 - val_loss: 1.5650 - val_accuracy: 0.5271\n","Epoch 31/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.5617 - accuracy: 0.5376 - val_loss: 1.5564 - val_accuracy: 0.5803\n","Epoch 32/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.5527 - accuracy: 0.5671 - val_loss: 1.5514 - val_accuracy: 0.5057\n","Epoch 33/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.5452 - accuracy: 0.5498 - val_loss: 1.5424 - val_accuracy: 0.5577\n","Epoch 34/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.5382 - accuracy: 0.5535 - val_loss: 1.5335 - val_accuracy: 0.5837\n","Epoch 35/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.5296 - accuracy: 0.5611 - val_loss: 1.5259 - val_accuracy: 0.5860\n","Epoch 36/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.5227 - accuracy: 0.5671 - val_loss: 1.5185 - val_accuracy: 0.5769\n","Epoch 37/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.5142 - accuracy: 0.5823 - val_loss: 1.5110 - val_accuracy: 0.5848\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5072 - accuracy: 0.5784 - val_loss: 1.5038 - val_accuracy: 0.5860\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4994 - accuracy: 0.5784 - val_loss: 1.4966 - val_accuracy: 0.5871\n","Epoch 40/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.4919 - accuracy: 0.5727 - val_loss: 1.4896 - val_accuracy: 0.5871\n","Epoch 41/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4850 - accuracy: 0.5719 - val_loss: 1.4836 - val_accuracy: 0.5600\n","Epoch 42/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.4779 - accuracy: 0.5781 - val_loss: 1.4760 - val_accuracy: 0.5860\n","Epoch 43/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4735 - accuracy: 0.5707 - val_loss: 1.4695 - val_accuracy: 0.5758\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4646 - accuracy: 0.5671 - val_loss: 1.4660 - val_accuracy: 0.5837\n","Epoch 45/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4592 - accuracy: 0.5730 - val_loss: 1.4583 - val_accuracy: 0.5588\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4508 - accuracy: 0.5874 - val_loss: 1.4518 - val_accuracy: 0.5633\n","Epoch 47/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4428 - accuracy: 0.5880 - val_loss: 1.4530 - val_accuracy: 0.5328\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4369 - accuracy: 0.5872 - val_loss: 1.4419 - val_accuracy: 0.5814\n","Epoch 49/100\n","28/28 [==============================] - 2s 58ms/step - loss: 1.4314 - accuracy: 0.5835 - val_loss: 1.4327 - val_accuracy: 0.5916\n","Epoch 50/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4284 - accuracy: 0.5758 - val_loss: 1.4300 - val_accuracy: 0.5803\n","Epoch 51/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4198 - accuracy: 0.5829 - val_loss: 1.4202 - val_accuracy: 0.5713\n","Epoch 52/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.4148 - accuracy: 0.5775 - val_loss: 1.4182 - val_accuracy: 0.5837\n","Epoch 53/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.4082 - accuracy: 0.5804 - val_loss: 1.4164 - val_accuracy: 0.5701\n","Epoch 54/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.4022 - accuracy: 0.5770 - val_loss: 1.4085 - val_accuracy: 0.5475\n","Epoch 55/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.3954 - accuracy: 0.5869 - val_loss: 1.3998 - val_accuracy: 0.5645\n","Epoch 56/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.3888 - accuracy: 0.5781 - val_loss: 1.3920 - val_accuracy: 0.5871\n","Epoch 57/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.3805 - accuracy: 0.5979 - val_loss: 1.3871 - val_accuracy: 0.5814\n","Epoch 58/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.3780 - accuracy: 0.5880 - val_loss: 1.3809 - val_accuracy: 0.5814\n","Epoch 59/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3705 - accuracy: 0.5886 - val_loss: 1.3764 - val_accuracy: 0.5747\n","Epoch 60/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3655 - accuracy: 0.5903 - val_loss: 1.3709 - val_accuracy: 0.5837\n","Epoch 61/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.3595 - accuracy: 0.5925 - val_loss: 1.3684 - val_accuracy: 0.5611\n","Epoch 62/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.3515 - accuracy: 0.5934 - val_loss: 1.3596 - val_accuracy: 0.5848\n","Epoch 63/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3510 - accuracy: 0.5789 - val_loss: 1.3552 - val_accuracy: 0.5792\n","Epoch 64/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.3426 - accuracy: 0.5857 - val_loss: 1.3523 - val_accuracy: 0.5905\n","Epoch 65/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3374 - accuracy: 0.5931 - val_loss: 1.3440 - val_accuracy: 0.5826\n","Epoch 66/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3317 - accuracy: 0.5931 - val_loss: 1.3444 - val_accuracy: 0.5554\n","Epoch 67/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3265 - accuracy: 0.5925 - val_loss: 1.3346 - val_accuracy: 0.5792\n","Epoch 68/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3231 - accuracy: 0.5894 - val_loss: 1.3299 - val_accuracy: 0.5701\n","Epoch 69/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3137 - accuracy: 0.6010 - val_loss: 1.3240 - val_accuracy: 0.5837\n","Epoch 70/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3100 - accuracy: 0.5971 - val_loss: 1.3215 - val_accuracy: 0.5916\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3095 - accuracy: 0.5787 - val_loss: 1.3152 - val_accuracy: 0.5781\n","Epoch 72/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3029 - accuracy: 0.5874 - val_loss: 1.3244 - val_accuracy: 0.5351\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2959 - accuracy: 0.5860 - val_loss: 1.3042 - val_accuracy: 0.5781\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2893 - accuracy: 0.5982 - val_loss: 1.3075 - val_accuracy: 0.5498\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2865 - accuracy: 0.5945 - val_loss: 1.2947 - val_accuracy: 0.5826\n","Epoch 76/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.2817 - accuracy: 0.5857 - val_loss: 1.2896 - val_accuracy: 0.5826\n","Epoch 77/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.2771 - accuracy: 0.5979 - val_loss: 1.2866 - val_accuracy: 0.5781\n","Epoch 78/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2714 - accuracy: 0.6007 - val_loss: 1.2805 - val_accuracy: 0.5769\n","Epoch 79/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.2680 - accuracy: 0.5920 - val_loss: 1.2819 - val_accuracy: 0.5543\n","Epoch 80/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.2624 - accuracy: 0.5985 - val_loss: 1.2710 - val_accuracy: 0.5837\n","Epoch 81/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.2609 - accuracy: 0.5877 - val_loss: 1.2668 - val_accuracy: 0.5814\n","Epoch 82/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.2524 - accuracy: 0.6010 - val_loss: 1.2622 - val_accuracy: 0.5803\n","Epoch 83/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2487 - accuracy: 0.5925 - val_loss: 1.2579 - val_accuracy: 0.5792\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2442 - accuracy: 0.5942 - val_loss: 1.2538 - val_accuracy: 0.5781\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2374 - accuracy: 0.5954 - val_loss: 1.2493 - val_accuracy: 0.5837\n","Epoch 86/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2344 - accuracy: 0.5968 - val_loss: 1.2450 - val_accuracy: 0.5814\n","Epoch 87/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2288 - accuracy: 0.6010 - val_loss: 1.2420 - val_accuracy: 0.5769\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2254 - accuracy: 0.6072 - val_loss: 1.2394 - val_accuracy: 0.5667\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2208 - accuracy: 0.6036 - val_loss: 1.2321 - val_accuracy: 0.5837\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2165 - accuracy: 0.6019 - val_loss: 1.2308 - val_accuracy: 0.5724\n","Epoch 91/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2155 - accuracy: 0.5945 - val_loss: 1.2250 - val_accuracy: 0.5758\n","Epoch 92/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2067 - accuracy: 0.6047 - val_loss: 1.2225 - val_accuracy: 0.5667\n","Epoch 93/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2047 - accuracy: 0.6038 - val_loss: 1.2156 - val_accuracy: 0.5792\n","Epoch 94/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1994 - accuracy: 0.6041 - val_loss: 1.2147 - val_accuracy: 0.5735\n","Epoch 95/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1956 - accuracy: 0.6036 - val_loss: 1.2077 - val_accuracy: 0.5803\n","Epoch 96/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1926 - accuracy: 0.5954 - val_loss: 1.2071 - val_accuracy: 0.5679\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1883 - accuracy: 0.6072 - val_loss: 1.2045 - val_accuracy: 0.5837\n","Epoch 98/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1859 - accuracy: 0.5917 - val_loss: 1.1964 - val_accuracy: 0.5826\n","Epoch 99/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.1793 - accuracy: 0.6022 - val_loss: 1.1978 - val_accuracy: 0.5532\n","Epoch 100/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1734 - accuracy: 0.6084 - val_loss: 1.1902 - val_accuracy: 0.5713\n","{'loss': [1.8194352388381958, 1.809282898902893, 1.8000010251998901, 1.7910184860229492, 1.78129243850708, 1.772231936454773, 1.7626584768295288, 1.7538530826568604, 1.7445833683013916, 1.7359545230865479, 1.7266910076141357, 1.717477798461914, 1.7089542150497437, 1.7008075714111328, 1.691525936126709, 1.6831586360931396, 1.6748031377792358, 1.6662921905517578, 1.6571823358535767, 1.6493808031082153, 1.6410512924194336, 1.6323922872543335, 1.6249854564666748, 1.617013692855835, 1.6087487936019897, 1.6006587743759155, 1.5931012630462646, 1.5853313207626343, 1.5761783123016357, 1.5693663358688354, 1.5617443323135376, 1.55272376537323, 1.5452308654785156, 1.5382484197616577, 1.5296061038970947, 1.5226770639419556, 1.5141677856445312, 1.507190227508545, 1.4993586540222168, 1.491854190826416, 1.4849776029586792, 1.477905511856079, 1.4734731912612915, 1.4646376371383667, 1.4591617584228516, 1.450835943222046, 1.4427677392959595, 1.4368761777877808, 1.4314193725585938, 1.4283530712127686, 1.4197990894317627, 1.414845585823059, 1.408210039138794, 1.402154564857483, 1.3954391479492188, 1.3887780904769897, 1.3805118799209595, 1.3780304193496704, 1.3705188035964966, 1.3654916286468506, 1.3594703674316406, 1.3514666557312012, 1.3510026931762695, 1.3426445722579956, 1.3373830318450928, 1.3316943645477295, 1.3264915943145752, 1.3230996131896973, 1.31368887424469, 1.3100481033325195, 1.30945885181427, 1.3029457330703735, 1.295854091644287, 1.28925621509552, 1.2865163087844849, 1.2816985845565796, 1.277075171470642, 1.271440863609314, 1.268039584159851, 1.262359857559204, 1.2608639001846313, 1.2524182796478271, 1.2486628293991089, 1.244209885597229, 1.2374457120895386, 1.2344387769699097, 1.2287665605545044, 1.22544527053833, 1.2207812070846558, 1.2165031433105469, 1.2155144214630127, 1.2067322731018066, 1.2047035694122314, 1.1994357109069824, 1.1955950260162354, 1.1926487684249878, 1.1882848739624023, 1.185936450958252, 1.1793400049209595, 1.1733683347702026], 'accuracy': [0.49179399013519287, 0.5019807815551758, 0.5031126141548157, 0.49943408370018005, 0.4974533021450043, 0.5076400637626648, 0.5186757445335388, 0.5082060098648071, 0.5155631303787231, 0.5050933957099915, 0.5246179699897766, 0.5328239798545837, 0.5099037885665894, 0.5118845701217651, 0.5305602550506592, 0.5297113656997681, 0.5282965302467346, 0.5274476408958435, 0.5370684862136841, 0.5339558720588684, 0.5268816947937012, 0.549235999584198, 0.5404640436172485, 0.532541036605835, 0.5464063286781311, 0.5461233854293823, 0.5413129329681396, 0.5353707075119019, 0.5594227313995361, 0.5478211641311646, 0.5376344323158264, 0.5670627951622009, 0.5498019456863403, 0.5534804463386536, 0.5611205697059631, 0.5670627951622009, 0.5823429822921753, 0.5783814191818237, 0.5783814191818237, 0.5727221369743347, 0.5718732476234436, 0.578098475933075, 0.5707413554191589, 0.5670627951622009, 0.5730050802230835, 0.587436318397522, 0.5880022644996643, 0.5871533751487732, 0.5834748148918152, 0.5758347511291504, 0.5829088687896729, 0.5775325298309326, 0.5803622007369995, 0.5769665837287903, 0.5868703722953796, 0.578098475933075, 0.5979060530662537, 0.5880022644996643, 0.5885682106018066, 0.5902659893035889, 0.5925297141075134, 0.5933786034584045, 0.5789473652839661, 0.5857385396957397, 0.5930956602096558, 0.5930956602096558, 0.5925297141075134, 0.5894170999526978, 0.6010186672210693, 0.5970571637153625, 0.5786644220352173, 0.587436318397522, 0.5860214829444885, 0.5981889963150024, 0.5945104956626892, 0.5857385396957397, 0.5979060530662537, 0.6007357239723206, 0.5919637680053711, 0.598471999168396, 0.5877193212509155, 0.6010186672210693, 0.5925297141075134, 0.5942274928092957, 0.5953593850135803, 0.5967742204666138, 0.6010186672210693, 0.6072438955307007, 0.6035653352737427, 0.6018675565719604, 0.5945104956626892, 0.6046972274780273, 0.6038483381271362, 0.604131281375885, 0.6035653352737427, 0.5953593850135803, 0.6072438955307007, 0.5916808247566223, 0.602150559425354, 0.6083757877349854], 'val_loss': [1.8140267133712769, 1.8044675588607788, 1.7949864864349365, 1.7856448888778687, 1.7764179706573486, 1.7672721147537231, 1.75818932056427, 1.7491661310195923, 1.740211844444275, 1.7312736511230469, 1.7224005460739136, 1.7135976552963257, 1.7048040628433228, 1.696122646331787, 1.6874661445617676, 1.6789488792419434, 1.6704583168029785, 1.6619980335235596, 1.6536431312561035, 1.6452932357788086, 1.636755108833313, 1.628476619720459, 1.6205127239227295, 1.612134575843811, 1.604010820388794, 1.5958995819091797, 1.5881478786468506, 1.5807609558105469, 1.5720571279525757, 1.5649954080581665, 1.5563942193984985, 1.5513888597488403, 1.5423593521118164, 1.533517599105835, 1.5258512496948242, 1.51853609085083, 1.5109716653823853, 1.5038049221038818, 1.496636152267456, 1.4896228313446045, 1.4835551977157593, 1.4759702682495117, 1.4694857597351074, 1.4660238027572632, 1.4582661390304565, 1.4517987966537476, 1.4530457258224487, 1.4419467449188232, 1.4326683282852173, 1.4300225973129272, 1.4202195405960083, 1.4182391166687012, 1.4163751602172852, 1.408462405204773, 1.3997629880905151, 1.3920094966888428, 1.3870511054992676, 1.3808587789535522, 1.3764430284500122, 1.3708549737930298, 1.3683557510375977, 1.359649896621704, 1.3552144765853882, 1.352272391319275, 1.344005823135376, 1.3444325923919678, 1.3345844745635986, 1.3299212455749512, 1.323962688446045, 1.3214921951293945, 1.3151675462722778, 1.3244465589523315, 1.3041670322418213, 1.3075242042541504, 1.294698715209961, 1.289611577987671, 1.2865970134735107, 1.2805474996566772, 1.2819359302520752, 1.271007776260376, 1.2667664289474487, 1.262195348739624, 1.2579047679901123, 1.2538018226623535, 1.2492544651031494, 1.2449852228164673, 1.2419660091400146, 1.2393649816513062, 1.232058048248291, 1.2308238744735718, 1.2249720096588135, 1.2224583625793457, 1.215596318244934, 1.2146694660186768, 1.2077404260635376, 1.2070958614349365, 1.2044771909713745, 1.1963796615600586, 1.197788119316101, 1.190230369567871], 'val_accuracy': [0.5045248866081238, 0.5045248866081238, 0.5045248866081238, 0.5045248866081238, 0.5045248866081238, 0.5045248866081238, 0.5045248866081238, 0.5045248866081238, 0.5045248866081238, 0.5045248866081238, 0.5045248866081238, 0.5056561231613159, 0.5033936500549316, 0.564479649066925, 0.5033936500549316, 0.5214931964874268, 0.5192307829856873, 0.5475113391876221, 0.5735294222831726, 0.5497737526893616, 0.5859728455543518, 0.5803167223930359, 0.5542986392974854, 0.5656108856201172, 0.5226244330406189, 0.5260180830955505, 0.5248869061470032, 0.5124434232711792, 0.5882353186607361, 0.5271493196487427, 0.5803167223930359, 0.5056561231613159, 0.557692289352417, 0.5837104320526123, 0.5859728455543518, 0.5769230723381042, 0.5848416090011597, 0.5859728455543518, 0.587104082107544, 0.587104082107544, 0.5599547624588013, 0.5859728455543518, 0.5757918357849121, 0.5837104320526123, 0.5588235259056091, 0.5633484125137329, 0.5328054428100586, 0.581447958946228, 0.5916289687156677, 0.5803167223930359, 0.5712669491767883, 0.5837104320526123, 0.570135772228241, 0.5475113391876221, 0.564479649066925, 0.587104082107544, 0.581447958946228, 0.581447958946228, 0.5746606588363647, 0.5837104320526123, 0.5610859990119934, 0.5848416090011597, 0.5791855454444885, 0.5904977321624756, 0.5825791954994202, 0.5554298758506775, 0.5791855454444885, 0.570135772228241, 0.5837104320526123, 0.5916289687156677, 0.5780543088912964, 0.5350678563117981, 0.5780543088912964, 0.5497737526893616, 0.5825791954994202, 0.5825791954994202, 0.5780543088912964, 0.5769230723381042, 0.5542986392974854, 0.5837104320526123, 0.581447958946228, 0.5803167223930359, 0.5791855454444885, 0.5780543088912964, 0.5837104320526123, 0.581447958946228, 0.5769230723381042, 0.5667420625686646, 0.5837104320526123, 0.5723981857299805, 0.5757918357849121, 0.5667420625686646, 0.5791855454444885, 0.5735294222831726, 0.5803167223930359, 0.5678732991218567, 0.5837104320526123, 0.5825791954994202, 0.5531674027442932, 0.5712669491767883]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 1.8188 - accuracy: 0.5052"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 54ms/step - loss: 1.8188 - accuracy: 0.5039 - val_loss: 1.8130 - val_accuracy: 0.5145\n","Epoch 2/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.8083 - accuracy: 0.5049 - val_loss: 1.8023 - val_accuracy: 0.5145\n","Epoch 3/100\n","31/31 [==============================] - 1s 30ms/step - loss: 1.7973 - accuracy: 0.5036 - val_loss: 1.7918 - val_accuracy: 0.5548\n","Epoch 4/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.7869 - accuracy: 0.5005 - val_loss: 1.7814 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 31ms/step - loss: 1.7766 - accuracy: 0.5008 - val_loss: 1.7710 - val_accuracy: 0.5847\n","Epoch 6/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.7666 - accuracy: 0.4982 - val_loss: 1.7607 - val_accuracy: 0.5145\n","Epoch 7/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.7559 - accuracy: 0.5067 - val_loss: 1.7507 - val_accuracy: 0.5145\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.7456 - accuracy: 0.5207 - val_loss: 1.7407 - val_accuracy: 0.5165\n","Epoch 9/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.7358 - accuracy: 0.5090 - val_loss: 1.7308 - val_accuracy: 0.4835\n","Epoch 10/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.7258 - accuracy: 0.5083 - val_loss: 1.7209 - val_accuracy: 0.5517\n","Epoch 11/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.7164 - accuracy: 0.5021 - val_loss: 1.7111 - val_accuracy: 0.5165\n","Epoch 12/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.7064 - accuracy: 0.5096 - val_loss: 1.7016 - val_accuracy: 0.5723\n","Epoch 13/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.6971 - accuracy: 0.5036 - val_loss: 1.6920 - val_accuracy: 0.5744\n","Epoch 14/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.6878 - accuracy: 0.5041 - val_loss: 1.6824 - val_accuracy: 0.5145\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.6787 - accuracy: 0.4897 - val_loss: 1.6731 - val_accuracy: 0.5155\n","Epoch 16/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.6694 - accuracy: 0.4977 - val_loss: 1.6640 - val_accuracy: 0.5816\n","Epoch 17/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.6598 - accuracy: 0.5085 - val_loss: 1.6550 - val_accuracy: 0.4845\n","Epoch 18/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.6505 - accuracy: 0.5070 - val_loss: 1.6453 - val_accuracy: 0.5899\n","Epoch 19/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.6416 - accuracy: 0.5111 - val_loss: 1.6361 - val_accuracy: 0.5176\n","Epoch 20/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.6327 - accuracy: 0.5121 - val_loss: 1.6278 - val_accuracy: 0.4907\n","Epoch 21/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.6238 - accuracy: 0.5049 - val_loss: 1.6181 - val_accuracy: 0.5145\n","Epoch 22/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.6147 - accuracy: 0.5271 - val_loss: 1.6096 - val_accuracy: 0.5868\n","Epoch 23/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.6066 - accuracy: 0.5070 - val_loss: 1.6005 - val_accuracy: 0.5279\n","Epoch 24/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.5978 - accuracy: 0.5145 - val_loss: 1.5920 - val_accuracy: 0.5795\n","Epoch 25/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.5888 - accuracy: 0.5199 - val_loss: 1.5834 - val_accuracy: 0.5899\n","Epoch 26/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.5802 - accuracy: 0.5235 - val_loss: 1.5749 - val_accuracy: 0.5899\n","Epoch 27/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.5711 - accuracy: 0.5344 - val_loss: 1.5664 - val_accuracy: 0.5279\n","Epoch 28/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.5636 - accuracy: 0.5202 - val_loss: 1.5577 - val_accuracy: 0.5444\n","Epoch 29/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.5548 - accuracy: 0.5227 - val_loss: 1.5487 - val_accuracy: 0.5610\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5464 - accuracy: 0.5287 - val_loss: 1.5402 - val_accuracy: 0.5382\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.5378 - accuracy: 0.5382 - val_loss: 1.5338 - val_accuracy: 0.4886\n","Epoch 32/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.5303 - accuracy: 0.5150 - val_loss: 1.5249 - val_accuracy: 0.5186\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5222 - accuracy: 0.5227 - val_loss: 1.5155 - val_accuracy: 0.5816\n","Epoch 34/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.5137 - accuracy: 0.5375 - val_loss: 1.5071 - val_accuracy: 0.5692\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.5062 - accuracy: 0.5305 - val_loss: 1.4990 - val_accuracy: 0.5702\n","Epoch 36/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4987 - accuracy: 0.5289 - val_loss: 1.4925 - val_accuracy: 0.5362\n","Epoch 37/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4925 - accuracy: 0.5207 - val_loss: 1.4884 - val_accuracy: 0.4835\n","Epoch 38/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4834 - accuracy: 0.5351 - val_loss: 1.4768 - val_accuracy: 0.5434\n","Epoch 39/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4755 - accuracy: 0.5305 - val_loss: 1.4684 - val_accuracy: 0.5620\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4679 - accuracy: 0.5395 - val_loss: 1.4608 - val_accuracy: 0.5599\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4597 - accuracy: 0.5426 - val_loss: 1.4524 - val_accuracy: 0.5682\n","Epoch 42/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4526 - accuracy: 0.5509 - val_loss: 1.4447 - val_accuracy: 0.5816\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4441 - accuracy: 0.5499 - val_loss: 1.4369 - val_accuracy: 0.5837\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4368 - accuracy: 0.5579 - val_loss: 1.4297 - val_accuracy: 0.5671\n","Epoch 45/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4318 - accuracy: 0.5289 - val_loss: 1.4246 - val_accuracy: 0.5568\n","Epoch 46/100\n","31/31 [==============================] - 1s 48ms/step - loss: 1.4229 - accuracy: 0.5525 - val_loss: 1.4151 - val_accuracy: 0.5981\n","Epoch 47/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.4154 - accuracy: 0.5589 - val_loss: 1.4078 - val_accuracy: 0.5981\n","Epoch 48/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.4087 - accuracy: 0.5514 - val_loss: 1.4001 - val_accuracy: 0.5919\n","Epoch 49/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.4016 - accuracy: 0.5512 - val_loss: 1.3927 - val_accuracy: 0.5868\n","Epoch 50/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.3944 - accuracy: 0.5553 - val_loss: 1.3884 - val_accuracy: 0.5610\n","Epoch 51/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3871 - accuracy: 0.5576 - val_loss: 1.3786 - val_accuracy: 0.5888\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3794 - accuracy: 0.5641 - val_loss: 1.3721 - val_accuracy: 0.5909\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3744 - accuracy: 0.5589 - val_loss: 1.3658 - val_accuracy: 0.5661\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3666 - accuracy: 0.5656 - val_loss: 1.3604 - val_accuracy: 0.5671\n","Epoch 55/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3613 - accuracy: 0.5620 - val_loss: 1.3572 - val_accuracy: 0.5424\n","Epoch 56/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3564 - accuracy: 0.5452 - val_loss: 1.3458 - val_accuracy: 0.5919\n","Epoch 57/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3469 - accuracy: 0.5636 - val_loss: 1.3417 - val_accuracy: 0.5568\n","Epoch 58/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3398 - accuracy: 0.5605 - val_loss: 1.3316 - val_accuracy: 0.5837\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3342 - accuracy: 0.5630 - val_loss: 1.3261 - val_accuracy: 0.5888\n","Epoch 60/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3287 - accuracy: 0.5661 - val_loss: 1.3213 - val_accuracy: 0.5723\n","Epoch 61/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3225 - accuracy: 0.5618 - val_loss: 1.3138 - val_accuracy: 0.5899\n","Epoch 62/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3166 - accuracy: 0.5711 - val_loss: 1.3076 - val_accuracy: 0.5775\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3104 - accuracy: 0.5724 - val_loss: 1.3028 - val_accuracy: 0.5899\n","Epoch 64/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3043 - accuracy: 0.5693 - val_loss: 1.3016 - val_accuracy: 0.5527\n","Epoch 65/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2994 - accuracy: 0.5667 - val_loss: 1.2910 - val_accuracy: 0.5775\n","Epoch 66/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2927 - accuracy: 0.5685 - val_loss: 1.2851 - val_accuracy: 0.5919\n","Epoch 67/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2891 - accuracy: 0.5718 - val_loss: 1.2791 - val_accuracy: 0.5899\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2804 - accuracy: 0.5731 - val_loss: 1.2729 - val_accuracy: 0.5868\n","Epoch 69/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.2764 - accuracy: 0.5682 - val_loss: 1.2685 - val_accuracy: 0.5775\n","Epoch 70/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.2715 - accuracy: 0.5667 - val_loss: 1.2624 - val_accuracy: 0.5847\n","Epoch 71/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.2651 - accuracy: 0.5633 - val_loss: 1.2622 - val_accuracy: 0.5702\n","Epoch 72/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.2624 - accuracy: 0.5625 - val_loss: 1.2542 - val_accuracy: 0.5702\n","Epoch 73/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.2577 - accuracy: 0.5649 - val_loss: 1.2503 - val_accuracy: 0.5754\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2502 - accuracy: 0.5698 - val_loss: 1.2461 - val_accuracy: 0.5733\n","Epoch 75/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2452 - accuracy: 0.5734 - val_loss: 1.2364 - val_accuracy: 0.5857\n","Epoch 76/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2409 - accuracy: 0.5667 - val_loss: 1.2313 - val_accuracy: 0.5857\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2344 - accuracy: 0.5729 - val_loss: 1.2279 - val_accuracy: 0.5857\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2280 - accuracy: 0.5711 - val_loss: 1.2255 - val_accuracy: 0.5764\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2229 - accuracy: 0.5770 - val_loss: 1.2167 - val_accuracy: 0.5888\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2196 - accuracy: 0.5698 - val_loss: 1.2147 - val_accuracy: 0.5775\n","Epoch 81/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2131 - accuracy: 0.5798 - val_loss: 1.2068 - val_accuracy: 0.5868\n","Epoch 82/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2097 - accuracy: 0.5677 - val_loss: 1.2029 - val_accuracy: 0.5868\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2031 - accuracy: 0.5690 - val_loss: 1.2009 - val_accuracy: 0.5754\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1983 - accuracy: 0.5739 - val_loss: 1.1937 - val_accuracy: 0.5847\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1962 - accuracy: 0.5669 - val_loss: 1.1883 - val_accuracy: 0.5888\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1888 - accuracy: 0.5786 - val_loss: 1.1845 - val_accuracy: 0.5857\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1885 - accuracy: 0.5724 - val_loss: 1.1786 - val_accuracy: 0.5826\n","Epoch 88/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1807 - accuracy: 0.5760 - val_loss: 1.1747 - val_accuracy: 0.5826\n","Epoch 89/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1751 - accuracy: 0.5855 - val_loss: 1.1713 - val_accuracy: 0.5888\n","Epoch 90/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1723 - accuracy: 0.5752 - val_loss: 1.1653 - val_accuracy: 0.5816\n","Epoch 91/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.1686 - accuracy: 0.5713 - val_loss: 1.1615 - val_accuracy: 0.5857\n","Epoch 92/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.1635 - accuracy: 0.5767 - val_loss: 1.1594 - val_accuracy: 0.5868\n","Epoch 93/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.1584 - accuracy: 0.5798 - val_loss: 1.1527 - val_accuracy: 0.5857\n","Epoch 94/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.1547 - accuracy: 0.5778 - val_loss: 1.1490 - val_accuracy: 0.5806\n","Epoch 95/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.1478 - accuracy: 0.5793 - val_loss: 1.1477 - val_accuracy: 0.5785\n","Epoch 96/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1453 - accuracy: 0.5819 - val_loss: 1.1403 - val_accuracy: 0.5847\n","Epoch 97/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1436 - accuracy: 0.5762 - val_loss: 1.1363 - val_accuracy: 0.5826\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1355 - accuracy: 0.5881 - val_loss: 1.1325 - val_accuracy: 0.5837\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1338 - accuracy: 0.5659 - val_loss: 1.1289 - val_accuracy: 0.5857\n","Epoch 100/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1293 - accuracy: 0.5804 - val_loss: 1.1247 - val_accuracy: 0.5816\n","{'loss': [1.818798542022705, 1.8082637786865234, 1.7973320484161377, 1.786935806274414, 1.7766138315200806, 1.7666021585464478, 1.755865454673767, 1.7456331253051758, 1.7358064651489258, 1.725836157798767, 1.7163995504379272, 1.7064024209976196, 1.69706130027771, 1.6877800226211548, 1.6787338256835938, 1.6694499254226685, 1.65977942943573, 1.6505014896392822, 1.641600251197815, 1.6326993703842163, 1.6237550973892212, 1.6147186756134033, 1.6066197156906128, 1.5977593660354614, 1.5887521505355835, 1.5801665782928467, 1.5711133480072021, 1.5635699033737183, 1.5547617673873901, 1.5463626384735107, 1.5378278493881226, 1.5302886962890625, 1.522239089012146, 1.5137284994125366, 1.5061782598495483, 1.4986848831176758, 1.4925261735916138, 1.4834043979644775, 1.4754725694656372, 1.4678702354431152, 1.4597097635269165, 1.4526095390319824, 1.4441219568252563, 1.4368152618408203, 1.4318076372146606, 1.4229151010513306, 1.415436029434204, 1.4087142944335938, 1.401638150215149, 1.3943896293640137, 1.387131929397583, 1.3794164657592773, 1.374408483505249, 1.366553544998169, 1.361250638961792, 1.3564300537109375, 1.3469289541244507, 1.3397750854492188, 1.334159255027771, 1.3286629915237427, 1.3225406408309937, 1.3166061639785767, 1.3103770017623901, 1.3043221235275269, 1.29938805103302, 1.2927218675613403, 1.2890568971633911, 1.2804182767868042, 1.2764134407043457, 1.2715286016464233, 1.2651170492172241, 1.2624459266662598, 1.2577160596847534, 1.2502226829528809, 1.2451772689819336, 1.2409005165100098, 1.2344428300857544, 1.2280000448226929, 1.2229191064834595, 1.2195594310760498, 1.213133454322815, 1.2097229957580566, 1.2031034231185913, 1.1982887983322144, 1.1961677074432373, 1.1888433694839478, 1.1884528398513794, 1.1807188987731934, 1.1751177310943604, 1.1723222732543945, 1.1686310768127441, 1.1634947061538696, 1.1583919525146484, 1.1547160148620605, 1.1477642059326172, 1.1452653408050537, 1.1436046361923218, 1.1355047225952148, 1.1337916851043701, 1.1293240785598755], 'accuracy': [0.5038759708404541, 0.5049095749855042, 0.5036175847053528, 0.5005167722702026, 0.5007752180099487, 0.4981912076473236, 0.5067183375358582, 0.5206718444824219, 0.5090439319610596, 0.5082687139511108, 0.5020672082901001, 0.5095607042312622, 0.5036175847053528, 0.5041343569755554, 0.48966407775878906, 0.4976744055747986, 0.5085271596908569, 0.5069767236709595, 0.5111111402511597, 0.5121446847915649, 0.5049095749855042, 0.5271317958831787, 0.5069767236709595, 0.5144702792167664, 0.5198966264724731, 0.5235142111778259, 0.5343669056892395, 0.5201550126075745, 0.5227389931678772, 0.5286821722984314, 0.5382428765296936, 0.514987051486969, 0.5227389931678772, 0.5374677181243896, 0.5304909348487854, 0.5289405584335327, 0.5206718444824219, 0.5351421236991882, 0.5304909348487854, 0.539534866809845, 0.5426356792449951, 0.550904393196106, 0.5498707890510559, 0.5578811168670654, 0.5289405584335327, 0.5524547696113586, 0.5589147210121155, 0.5514211654663086, 0.5511627793312073, 0.5552971363067627, 0.5576227307319641, 0.564082682132721, 0.5589147210121155, 0.5656330585479736, 0.5620155334472656, 0.5452196598052979, 0.5635659098625183, 0.5604650974273682, 0.5630490779876709, 0.566149890422821, 0.5617570877075195, 0.5710594058036804, 0.5723513960838318, 0.5692506432533264, 0.5666666626930237, 0.5684754252433777, 0.5718346238136292, 0.5731266140937805, 0.5682170391082764, 0.5666666626930237, 0.5633074641227722, 0.5625323057174683, 0.5648579001426697, 0.569767415523529, 0.5733850002288818, 0.5666666626930237, 0.5728682279586792, 0.5710594058036804, 0.5770025849342346, 0.569767415523529, 0.5798449516296387, 0.5677002668380737, 0.5689922571182251, 0.5739018321037292, 0.566925048828125, 0.5785529613494873, 0.5723513960838318, 0.5759689807891846, 0.5855297446250916, 0.5751938223838806, 0.5713178515434265, 0.5767441987991333, 0.5798449516296387, 0.5777778029441833, 0.579328179359436, 0.5819121599197388, 0.5762273669242859, 0.5881136655807495, 0.565891444683075, 0.5803617835044861], 'val_loss': [1.8129849433898926, 1.802331566810608, 1.7918131351470947, 1.7814092636108398, 1.7710405588150024, 1.76073157787323, 1.7506847381591797, 1.7406749725341797, 1.7308119535446167, 1.7209092378616333, 1.7111378908157349, 1.7015869617462158, 1.6920337677001953, 1.6823877096176147, 1.67313814163208, 1.6640334129333496, 1.6549928188323975, 1.6453466415405273, 1.6360677480697632, 1.62776780128479, 1.618098258972168, 1.6096330881118774, 1.6005244255065918, 1.591998815536499, 1.583382487297058, 1.5748546123504639, 1.5664373636245728, 1.5577335357666016, 1.5486730337142944, 1.5402039289474487, 1.533832311630249, 1.5248732566833496, 1.515519380569458, 1.507146954536438, 1.4990015029907227, 1.4924851655960083, 1.4883759021759033, 1.4767721891403198, 1.4683780670166016, 1.4607912302017212, 1.4524139165878296, 1.4447400569915771, 1.4369257688522339, 1.4296760559082031, 1.4245916604995728, 1.4151312112808228, 1.4077712297439575, 1.400102138519287, 1.3926879167556763, 1.388393521308899, 1.3786245584487915, 1.3720911741256714, 1.3658300638198853, 1.3604249954223633, 1.3572471141815186, 1.3457942008972168, 1.34173583984375, 1.3315846920013428, 1.3260812759399414, 1.3212581872940063, 1.3137673139572144, 1.307598352432251, 1.302768588066101, 1.301611304283142, 1.2909873723983765, 1.2851008176803589, 1.2790600061416626, 1.272943139076233, 1.2684950828552246, 1.2624129056930542, 1.2622491121292114, 1.2542400360107422, 1.2503094673156738, 1.246082067489624, 1.236396074295044, 1.2313123941421509, 1.2279077768325806, 1.225544810295105, 1.2167187929153442, 1.2147003412246704, 1.2068463563919067, 1.2028560638427734, 1.2009292840957642, 1.1936506032943726, 1.1883140802383423, 1.1844770908355713, 1.1785699129104614, 1.1747159957885742, 1.171275019645691, 1.1653071641921997, 1.1615337133407593, 1.1594107151031494, 1.1526525020599365, 1.1489824056625366, 1.147664189338684, 1.1403218507766724, 1.136338233947754, 1.132548451423645, 1.128925085067749, 1.1246623992919922], 'val_accuracy': [0.5144628286361694, 0.5144628286361694, 0.5547520518302917, 0.48553720116615295, 0.5847107172012329, 0.5144628286361694, 0.5144628286361694, 0.5165289044380188, 0.4834710657596588, 0.5516529083251953, 0.5165289044380188, 0.5723140239715576, 0.5743801593780518, 0.5144628286361694, 0.5154958963394165, 0.5816115736961365, 0.4845041334629059, 0.5898760557174683, 0.5175619721412659, 0.49070248007774353, 0.5144628286361694, 0.586776852607727, 0.5278925895690918, 0.5795454382896423, 0.5898760557174683, 0.5898760557174683, 0.5278925895690918, 0.5444214940071106, 0.5609503984451294, 0.538223147392273, 0.4886363744735718, 0.5185950398445129, 0.5816115736961365, 0.5692148804664612, 0.5702479481697083, 0.5361570119857788, 0.4834710657596588, 0.5433884263038635, 0.5619834661483765, 0.5599173307418823, 0.5681818127632141, 0.5816115736961365, 0.5836777091026306, 0.567148745059967, 0.5568181872367859, 0.5981404781341553, 0.5981404781341553, 0.5919421315193176, 0.586776852607727, 0.5609503984451294, 0.5888429880142212, 0.5909090638160706, 0.56611567735672, 0.567148745059967, 0.5423553586006165, 0.5919421315193176, 0.5568181872367859, 0.5836777091026306, 0.5888429880142212, 0.5723140239715576, 0.5898760557174683, 0.577479362487793, 0.5898760557174683, 0.5526859760284424, 0.577479362487793, 0.5919421315193176, 0.5898760557174683, 0.586776852607727, 0.577479362487793, 0.5847107172012329, 0.5702479481697083, 0.5702479481697083, 0.5754132270812988, 0.5733470916748047, 0.58574378490448, 0.58574378490448, 0.58574378490448, 0.5764462947845459, 0.5888429880142212, 0.577479362487793, 0.586776852607727, 0.586776852607727, 0.5754132270812988, 0.5847107172012329, 0.5888429880142212, 0.58574378490448, 0.5826446413993835, 0.5826446413993835, 0.5888429880142212, 0.5816115736961365, 0.58574378490448, 0.586776852607727, 0.58574378490448, 0.5805785059928894, 0.5785123705863953, 0.5847107172012329, 0.5826446413993835, 0.5836777091026306, 0.58574378490448, 0.5816115736961365]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 1.1616 - accuracy: 0.5845"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 54ms/step - loss: 1.1611 - accuracy: 0.5870 - val_loss: 1.1749 - val_accuracy: 0.5851\n","Epoch 2/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.1544 - accuracy: 0.5865 - val_loss: 1.1700 - val_accuracy: 0.6067\n","Epoch 3/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.1493 - accuracy: 0.5881 - val_loss: 1.1651 - val_accuracy: 0.5819\n","Epoch 4/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.1447 - accuracy: 0.5884 - val_loss: 1.1605 - val_accuracy: 0.6218\n","Epoch 5/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1377 - accuracy: 0.5983 - val_loss: 1.1562 - val_accuracy: 0.5399\n","Epoch 6/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1330 - accuracy: 0.5967 - val_loss: 1.1513 - val_accuracy: 0.5647\n","Epoch 7/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1271 - accuracy: 0.5900 - val_loss: 1.1462 - val_accuracy: 0.5970\n","Epoch 8/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1244 - accuracy: 0.5927 - val_loss: 1.1416 - val_accuracy: 0.5797\n","Epoch 9/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1191 - accuracy: 0.5975 - val_loss: 1.1362 - val_accuracy: 0.6175\n","Epoch 10/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1142 - accuracy: 0.5970 - val_loss: 1.1314 - val_accuracy: 0.6024\n","Epoch 11/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1103 - accuracy: 0.5964 - val_loss: 1.1260 - val_accuracy: 0.6110\n","Epoch 12/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1066 - accuracy: 0.5924 - val_loss: 1.1211 - val_accuracy: 0.6153\n","Epoch 13/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1013 - accuracy: 0.5983 - val_loss: 1.1174 - val_accuracy: 0.5787\n","Epoch 14/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0978 - accuracy: 0.5938 - val_loss: 1.1112 - val_accuracy: 0.6024\n","Epoch 15/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0964 - accuracy: 0.5913 - val_loss: 1.1049 - val_accuracy: 0.6121\n","Epoch 16/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0922 - accuracy: 0.5911 - val_loss: 1.1021 - val_accuracy: 0.5916\n","Epoch 17/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0886 - accuracy: 0.5989 - val_loss: 1.0948 - val_accuracy: 0.6131\n","Epoch 18/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0840 - accuracy: 0.6010 - val_loss: 1.0903 - val_accuracy: 0.5873\n","Epoch 19/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.0816 - accuracy: 0.5975 - val_loss: 1.0841 - val_accuracy: 0.6121\n","Epoch 20/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.0770 - accuracy: 0.5946 - val_loss: 1.0792 - val_accuracy: 0.6045\n","Epoch 21/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0732 - accuracy: 0.6016 - val_loss: 1.0745 - val_accuracy: 0.6121\n","Epoch 22/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0697 - accuracy: 0.6021 - val_loss: 1.0704 - val_accuracy: 0.6088\n","Epoch 23/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0636 - accuracy: 0.5954 - val_loss: 1.0665 - val_accuracy: 0.5970\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0606 - accuracy: 0.6034 - val_loss: 1.0621 - val_accuracy: 0.6121\n","Epoch 25/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0578 - accuracy: 0.6075 - val_loss: 1.0582 - val_accuracy: 0.6024\n","Epoch 26/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.0562 - accuracy: 0.5935 - val_loss: 1.0552 - val_accuracy: 0.6013\n","Epoch 27/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0501 - accuracy: 0.6086 - val_loss: 1.0525 - val_accuracy: 0.6088\n","Epoch 28/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.0498 - accuracy: 0.5959 - val_loss: 1.0496 - val_accuracy: 0.5959\n","Epoch 29/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0470 - accuracy: 0.5997 - val_loss: 1.0465 - val_accuracy: 0.6078\n","Epoch 30/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0430 - accuracy: 0.6053 - val_loss: 1.0551 - val_accuracy: 0.5797\n","Epoch 31/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0418 - accuracy: 0.6051 - val_loss: 1.0404 - val_accuracy: 0.6110\n","Epoch 32/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0364 - accuracy: 0.6040 - val_loss: 1.0366 - val_accuracy: 0.6067\n","Epoch 33/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0319 - accuracy: 0.6026 - val_loss: 1.0339 - val_accuracy: 0.6013\n","Epoch 34/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0305 - accuracy: 0.6034 - val_loss: 1.0314 - val_accuracy: 0.6153\n","Epoch 35/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0305 - accuracy: 0.5932 - val_loss: 1.0383 - val_accuracy: 0.5884\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0234 - accuracy: 0.6061 - val_loss: 1.0253 - val_accuracy: 0.6099\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0207 - accuracy: 0.6148 - val_loss: 1.0230 - val_accuracy: 0.6110\n","Epoch 38/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.0167 - accuracy: 0.6059 - val_loss: 1.0193 - val_accuracy: 0.6013\n","Epoch 39/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0156 - accuracy: 0.6051 - val_loss: 1.0178 - val_accuracy: 0.6002\n","Epoch 40/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0142 - accuracy: 0.6016 - val_loss: 1.0253 - val_accuracy: 0.5916\n","Epoch 41/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0151 - accuracy: 0.5911 - val_loss: 1.0115 - val_accuracy: 0.6056\n","Epoch 42/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.0070 - accuracy: 0.6005 - val_loss: 1.0245 - val_accuracy: 0.5808\n","Epoch 43/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0069 - accuracy: 0.6018 - val_loss: 1.0066 - val_accuracy: 0.6142\n","Epoch 44/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0019 - accuracy: 0.6053 - val_loss: 1.0037 - val_accuracy: 0.6034\n","Epoch 45/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9978 - accuracy: 0.6102 - val_loss: 1.0190 - val_accuracy: 0.5787\n","Epoch 46/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9989 - accuracy: 0.6026 - val_loss: 1.0007 - val_accuracy: 0.6045\n","Epoch 47/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9932 - accuracy: 0.6118 - val_loss: 1.0023 - val_accuracy: 0.6002\n","Epoch 48/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9947 - accuracy: 0.6088 - val_loss: 0.9965 - val_accuracy: 0.6034\n","Epoch 49/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9895 - accuracy: 0.6083 - val_loss: 0.9980 - val_accuracy: 0.6002\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9869 - accuracy: 0.6094 - val_loss: 0.9903 - val_accuracy: 0.6099\n","Epoch 51/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9878 - accuracy: 0.6072 - val_loss: 0.9881 - val_accuracy: 0.6088\n","Epoch 52/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9821 - accuracy: 0.6091 - val_loss: 0.9849 - val_accuracy: 0.6099\n","Epoch 53/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9792 - accuracy: 0.6096 - val_loss: 0.9825 - val_accuracy: 0.6099\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9759 - accuracy: 0.6061 - val_loss: 0.9800 - val_accuracy: 0.6067\n","Epoch 55/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9734 - accuracy: 0.6126 - val_loss: 0.9787 - val_accuracy: 0.6078\n","Epoch 56/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9714 - accuracy: 0.6075 - val_loss: 0.9774 - val_accuracy: 0.6088\n","Epoch 57/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9701 - accuracy: 0.6113 - val_loss: 0.9737 - val_accuracy: 0.6088\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9682 - accuracy: 0.6034 - val_loss: 0.9711 - val_accuracy: 0.6121\n","Epoch 59/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9654 - accuracy: 0.6094 - val_loss: 0.9707 - val_accuracy: 0.6142\n","Epoch 60/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9623 - accuracy: 0.6096 - val_loss: 0.9669 - val_accuracy: 0.5991\n","Epoch 61/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9606 - accuracy: 0.6080 - val_loss: 0.9684 - val_accuracy: 0.6034\n","Epoch 62/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9577 - accuracy: 0.6134 - val_loss: 0.9646 - val_accuracy: 0.5927\n","Epoch 63/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9568 - accuracy: 0.6145 - val_loss: 0.9636 - val_accuracy: 0.6067\n","Epoch 64/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9537 - accuracy: 0.6105 - val_loss: 0.9588 - val_accuracy: 0.5970\n","Epoch 65/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9531 - accuracy: 0.6156 - val_loss: 0.9642 - val_accuracy: 0.6045\n","Epoch 66/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9509 - accuracy: 0.6029 - val_loss: 0.9557 - val_accuracy: 0.6088\n","Epoch 67/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9461 - accuracy: 0.6180 - val_loss: 0.9534 - val_accuracy: 0.6110\n","Epoch 68/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9433 - accuracy: 0.6153 - val_loss: 0.9557 - val_accuracy: 0.6002\n","Epoch 69/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9447 - accuracy: 0.6096 - val_loss: 0.9495 - val_accuracy: 0.6099\n","Epoch 70/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9395 - accuracy: 0.6169 - val_loss: 0.9482 - val_accuracy: 0.5981\n","Epoch 71/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9420 - accuracy: 0.6140 - val_loss: 0.9613 - val_accuracy: 0.5819\n","Epoch 72/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9384 - accuracy: 0.6088 - val_loss: 0.9440 - val_accuracy: 0.6131\n","Epoch 73/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9346 - accuracy: 0.6185 - val_loss: 0.9491 - val_accuracy: 0.6024\n","Epoch 74/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.9325 - accuracy: 0.6118 - val_loss: 0.9394 - val_accuracy: 0.6002\n","Epoch 75/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9333 - accuracy: 0.6150 - val_loss: 0.9376 - val_accuracy: 0.6002\n","Epoch 76/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9304 - accuracy: 0.6153 - val_loss: 0.9422 - val_accuracy: 0.6024\n","Epoch 77/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9270 - accuracy: 0.6091 - val_loss: 0.9342 - val_accuracy: 0.6067\n","Epoch 78/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9262 - accuracy: 0.6110 - val_loss: 0.9337 - val_accuracy: 0.6013\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9246 - accuracy: 0.6115 - val_loss: 0.9343 - val_accuracy: 0.6067\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9198 - accuracy: 0.6177 - val_loss: 0.9288 - val_accuracy: 0.5991\n","Epoch 81/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9192 - accuracy: 0.6088 - val_loss: 0.9390 - val_accuracy: 0.5894\n","Epoch 82/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9177 - accuracy: 0.6166 - val_loss: 0.9262 - val_accuracy: 0.6131\n","Epoch 83/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9151 - accuracy: 0.6158 - val_loss: 0.9274 - val_accuracy: 0.6056\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9151 - accuracy: 0.6161 - val_loss: 0.9221 - val_accuracy: 0.6067\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9145 - accuracy: 0.6169 - val_loss: 0.9209 - val_accuracy: 0.6024\n","Epoch 86/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9126 - accuracy: 0.6180 - val_loss: 0.9350 - val_accuracy: 0.5787\n","Epoch 87/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9112 - accuracy: 0.6096 - val_loss: 0.9170 - val_accuracy: 0.5991\n","Epoch 88/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9075 - accuracy: 0.6161 - val_loss: 0.9165 - val_accuracy: 0.6110\n","Epoch 89/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9034 - accuracy: 0.6215 - val_loss: 0.9143 - val_accuracy: 0.6034\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9028 - accuracy: 0.6169 - val_loss: 0.9131 - val_accuracy: 0.6002\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9038 - accuracy: 0.6156 - val_loss: 0.9314 - val_accuracy: 0.5711\n","Epoch 92/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9023 - accuracy: 0.6091 - val_loss: 0.9175 - val_accuracy: 0.5991\n","Epoch 93/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8970 - accuracy: 0.6274 - val_loss: 0.9108 - val_accuracy: 0.6078\n","Epoch 94/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8960 - accuracy: 0.6199 - val_loss: 0.9095 - val_accuracy: 0.6045\n","Epoch 95/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8939 - accuracy: 0.6223 - val_loss: 0.9062 - val_accuracy: 0.6034\n","Epoch 96/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8945 - accuracy: 0.6129 - val_loss: 0.9059 - val_accuracy: 0.6110\n","Epoch 97/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8884 - accuracy: 0.6228 - val_loss: 0.9022 - val_accuracy: 0.6024\n","Epoch 98/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8877 - accuracy: 0.6185 - val_loss: 0.9080 - val_accuracy: 0.5916\n","Epoch 99/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8900 - accuracy: 0.6223 - val_loss: 0.9034 - val_accuracy: 0.6088\n","Epoch 100/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.8864 - accuracy: 0.6274 - val_loss: 0.9019 - val_accuracy: 0.6034\n","{'loss': [1.1611400842666626, 1.1543859243392944, 1.1492643356323242, 1.1446784734725952, 1.1377414464950562, 1.1329736709594727, 1.1271214485168457, 1.12436842918396, 1.119107723236084, 1.1141701936721802, 1.1102724075317383, 1.1066253185272217, 1.101317286491394, 1.0977600812911987, 1.0963858366012573, 1.0922058820724487, 1.088629126548767, 1.0840462446212769, 1.0815874338150024, 1.077006459236145, 1.0731571912765503, 1.06972336769104, 1.0636398792266846, 1.0605847835540771, 1.0578300952911377, 1.0561895370483398, 1.0501025915145874, 1.0497820377349854, 1.0470058917999268, 1.04301118850708, 1.04183828830719, 1.0363762378692627, 1.03190279006958, 1.0304845571517944, 1.0305148363113403, 1.023416519165039, 1.0207403898239136, 1.0166969299316406, 1.0156149864196777, 1.0142366886138916, 1.0150505304336548, 1.0070252418518066, 1.0068721771240234, 1.0018513202667236, 0.9977855682373047, 0.9988999962806702, 0.993226945400238, 0.9947332143783569, 0.9894983768463135, 0.9869140386581421, 0.987848699092865, 0.9821383357048035, 0.97915118932724, 0.9759001135826111, 0.9733766317367554, 0.9713910818099976, 0.970069408416748, 0.9681529402732849, 0.9654172658920288, 0.9623121619224548, 0.9606161713600159, 0.9577497243881226, 0.9568313360214233, 0.9537134766578674, 0.953055202960968, 0.9509264826774597, 0.9460877180099487, 0.9432658553123474, 0.944658100605011, 0.9394545555114746, 0.941979169845581, 0.9383775591850281, 0.9346490502357483, 0.9325085878372192, 0.9332557320594788, 0.9304006099700928, 0.9270114898681641, 0.9262198209762573, 0.9246100187301636, 0.9197991490364075, 0.9191502928733826, 0.9177078008651733, 0.9151361584663391, 0.91510409116745, 0.9145100116729736, 0.9126238822937012, 0.9111785888671875, 0.9075166583061218, 0.9033948183059692, 0.9028353095054626, 0.9037728309631348, 0.902302622795105, 0.8970343470573425, 0.8960113525390625, 0.893898606300354, 0.8945295810699463, 0.8884409070014954, 0.887728750705719, 0.8899660706520081, 0.886406421661377], 'accuracy': [0.5870150923728943, 0.5864762663841248, 0.5880926847457886, 0.5883620977401733, 0.5983297228813171, 0.5967133641242981, 0.5899784564971924, 0.5926724076271057, 0.5975215435028076, 0.5969827771186829, 0.5964439511299133, 0.592402994632721, 0.5983297228813171, 0.59375, 0.5913254022598267, 0.5910560488700867, 0.5988685488700867, 0.6010237336158752, 0.5975215435028076, 0.5945581793785095, 0.6015625, 0.6021012663841248, 0.595366358757019, 0.6034482717514038, 0.6074892282485962, 0.5934805870056152, 0.6085668206214905, 0.5959051847457886, 0.5996767282485962, 0.6053340435028076, 0.6050646305084229, 0.6039870977401733, 0.6026400923728943, 0.6034482717514038, 0.5932112336158752, 0.6061422228813171, 0.6147629022598267, 0.6058728694915771, 0.6050646305084229, 0.6015625, 0.5910560488700867, 0.6004849076271057, 0.6018319129943848, 0.6053340435028076, 0.6101831793785095, 0.6026400923728943, 0.6117995977401733, 0.6088362336158752, 0.6082974076271057, 0.609375, 0.6072198152542114, 0.6091055870056152, 0.6096444129943848, 0.6061422228813171, 0.6126077771186829, 0.6074892282485962, 0.6112607717514038, 0.6034482717514038, 0.609375, 0.6096444129943848, 0.608027994632721, 0.6134159564971924, 0.6144935488700867, 0.6104525923728943, 0.615571141242981, 0.602909505367279, 0.6179956793785095, 0.6153017282485962, 0.6096444129943848, 0.6169180870056152, 0.6139547228813171, 0.6088362336158752, 0.618534505367279, 0.6117995977401733, 0.6150323152542114, 0.6153017282485962, 0.6091055870056152, 0.610991358757019, 0.6115301847457886, 0.6177262663841248, 0.6088362336158752, 0.6166487336158752, 0.615840494632721, 0.6161099076271057, 0.6169180870056152, 0.6179956793785095, 0.6096444129943848, 0.6161099076271057, 0.6214978694915771, 0.6169180870056152, 0.615571141242981, 0.6091055870056152, 0.6274245977401733, 0.6198814511299133, 0.6223060488700867, 0.6128771305084229, 0.6228448152542114, 0.618534505367279, 0.6223060488700867, 0.6274245977401733], 'val_loss': [1.174869179725647, 1.1700135469436646, 1.1650716066360474, 1.160491943359375, 1.1561871767044067, 1.1513172388076782, 1.1461775302886963, 1.14156174659729, 1.1362286806106567, 1.131392240524292, 1.1260462999343872, 1.1211309432983398, 1.1173856258392334, 1.1112133264541626, 1.1049048900604248, 1.1021170616149902, 1.0948415994644165, 1.0902916193008423, 1.0840764045715332, 1.0791943073272705, 1.0744839906692505, 1.070389986038208, 1.0665100812911987, 1.0620867013931274, 1.0581560134887695, 1.0552420616149902, 1.0524688959121704, 1.049619436264038, 1.046491026878357, 1.0551122426986694, 1.0403714179992676, 1.0365805625915527, 1.0339152812957764, 1.0313881635665894, 1.0383007526397705, 1.025264024734497, 1.022979497909546, 1.0193486213684082, 1.0178148746490479, 1.0253236293792725, 1.0115374326705933, 1.0244622230529785, 1.0066249370574951, 1.0037158727645874, 1.0189926624298096, 1.000731348991394, 1.0022501945495605, 0.9964540004730225, 0.9979650974273682, 0.9902744293212891, 0.9880954623222351, 0.9848569631576538, 0.9825167655944824, 0.9799937605857849, 0.9786731600761414, 0.9774402976036072, 0.9736523032188416, 0.9711390733718872, 0.9707213640213013, 0.966937780380249, 0.9684051275253296, 0.9646189212799072, 0.9635614156723022, 0.9587531685829163, 0.9641640186309814, 0.9556535482406616, 0.95343017578125, 0.9556571841239929, 0.9495304226875305, 0.9482470154762268, 0.9613298177719116, 0.9439674019813538, 0.9491012096405029, 0.9394251108169556, 0.9375903010368347, 0.9421945214271545, 0.9341908693313599, 0.9336675405502319, 0.934329092502594, 0.9287909865379333, 0.9389795064926147, 0.9261529445648193, 0.9273988008499146, 0.9221177697181702, 0.920924961566925, 0.9349539279937744, 0.9169766902923584, 0.9164862632751465, 0.9143182635307312, 0.9130954146385193, 0.9314287304878235, 0.9174652099609375, 0.9107669591903687, 0.9094935655593872, 0.9062093496322632, 0.9058906435966492, 0.9022477269172668, 0.9080325961112976, 0.9033570289611816, 0.9019011855125427], 'val_accuracy': [0.5851293206214905, 0.6066810488700867, 0.5818965435028076, 0.6217672228813171, 0.5398706793785095, 0.5646551847457886, 0.5969827771186829, 0.579741358757019, 0.6174569129943848, 0.6023706793785095, 0.610991358757019, 0.6153017282485962, 0.5786637663841248, 0.6023706793785095, 0.6120689511299133, 0.5915948152542114, 0.6131465435028076, 0.587284505367279, 0.6120689511299133, 0.6045258641242981, 0.6120689511299133, 0.6088362336158752, 0.5969827771186829, 0.6120689511299133, 0.6023706793785095, 0.6012930870056152, 0.6088362336158752, 0.5959051847457886, 0.607758641242981, 0.579741358757019, 0.610991358757019, 0.6066810488700867, 0.6012930870056152, 0.6153017282485962, 0.5883620977401733, 0.6099137663841248, 0.610991358757019, 0.6012930870056152, 0.600215494632721, 0.5915948152542114, 0.6056034564971924, 0.5808189511299133, 0.6142241358757019, 0.6034482717514038, 0.5786637663841248, 0.6045258641242981, 0.600215494632721, 0.6034482717514038, 0.600215494632721, 0.6099137663841248, 0.6088362336158752, 0.6099137663841248, 0.6099137663841248, 0.6066810488700867, 0.607758641242981, 0.6088362336158752, 0.6088362336158752, 0.6120689511299133, 0.6142241358757019, 0.5991379022598267, 0.6034482717514038, 0.5926724076271057, 0.6066810488700867, 0.5969827771186829, 0.6045258641242981, 0.6088362336158752, 0.610991358757019, 0.600215494632721, 0.6099137663841248, 0.5980603694915771, 0.5818965435028076, 0.6131465435028076, 0.6023706793785095, 0.600215494632721, 0.600215494632721, 0.6023706793785095, 0.6066810488700867, 0.6012930870056152, 0.6066810488700867, 0.5991379022598267, 0.5894396305084229, 0.6131465435028076, 0.6056034564971924, 0.6066810488700867, 0.6023706793785095, 0.5786637663841248, 0.5991379022598267, 0.610991358757019, 0.6034482717514038, 0.600215494632721, 0.5711206793785095, 0.5991379022598267, 0.607758641242981, 0.6045258641242981, 0.6034482717514038, 0.610991358757019, 0.6023706793785095, 0.5915948152542114, 0.6088362336158752, 0.6034482717514038]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 1.1613 - accuracy: 0.5847"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 76ms/step - loss: 1.1612 - accuracy: 0.5849 - val_loss: 1.1754 - val_accuracy: 0.5871\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.1552 - accuracy: 0.5883 - val_loss: 1.1707 - val_accuracy: 0.5814\n","Epoch 3/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.1491 - accuracy: 0.5914 - val_loss: 1.1661 - val_accuracy: 0.5826\n","Epoch 4/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1453 - accuracy: 0.5914 - val_loss: 1.1618 - val_accuracy: 0.5124\n","Epoch 5/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1400 - accuracy: 0.5846 - val_loss: 1.1573 - val_accuracy: 0.5283\n","Epoch 6/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1410 - accuracy: 0.5764 - val_loss: 1.1530 - val_accuracy: 0.5147\n","Epoch 7/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1302 - accuracy: 0.5965 - val_loss: 1.1482 - val_accuracy: 0.5860\n","Epoch 8/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.1260 - accuracy: 0.5965 - val_loss: 1.1440 - val_accuracy: 0.5328\n","Epoch 9/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1209 - accuracy: 0.5985 - val_loss: 1.1392 - val_accuracy: 0.5860\n","Epoch 10/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1187 - accuracy: 0.5920 - val_loss: 1.1347 - val_accuracy: 0.5747\n","Epoch 11/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.1124 - accuracy: 0.5959 - val_loss: 1.1304 - val_accuracy: 0.5701\n","Epoch 12/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.1095 - accuracy: 0.5951 - val_loss: 1.1257 - val_accuracy: 0.5882\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1035 - accuracy: 0.6005 - val_loss: 1.1213 - val_accuracy: 0.5814\n","Epoch 14/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1017 - accuracy: 0.5962 - val_loss: 1.1162 - val_accuracy: 0.5860\n","Epoch 15/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.0971 - accuracy: 0.5985 - val_loss: 1.1122 - val_accuracy: 0.5894\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0955 - accuracy: 0.5897 - val_loss: 1.1079 - val_accuracy: 0.5679\n","Epoch 17/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0908 - accuracy: 0.5965 - val_loss: 1.1024 - val_accuracy: 0.5894\n","Epoch 18/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.0854 - accuracy: 0.6013 - val_loss: 1.0981 - val_accuracy: 0.5848\n","Epoch 19/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0869 - accuracy: 0.5877 - val_loss: 1.1042 - val_accuracy: 0.5226\n","Epoch 20/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0828 - accuracy: 0.5880 - val_loss: 1.0899 - val_accuracy: 0.5871\n","Epoch 21/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0744 - accuracy: 0.6022 - val_loss: 1.0853 - val_accuracy: 0.5894\n","Epoch 22/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0724 - accuracy: 0.6132 - val_loss: 1.0821 - val_accuracy: 0.5792\n","Epoch 23/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.0680 - accuracy: 0.6092 - val_loss: 1.0776 - val_accuracy: 0.5848\n","Epoch 24/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.0657 - accuracy: 0.5999 - val_loss: 1.0756 - val_accuracy: 0.5747\n","Epoch 25/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.0626 - accuracy: 0.5920 - val_loss: 1.0779 - val_accuracy: 0.5520\n","Epoch 26/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.0580 - accuracy: 0.6075 - val_loss: 1.0694 - val_accuracy: 0.5747\n","Epoch 27/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.0570 - accuracy: 0.6002 - val_loss: 1.0642 - val_accuracy: 0.5871\n","Epoch 28/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.0519 - accuracy: 0.6084 - val_loss: 1.0631 - val_accuracy: 0.5803\n","Epoch 29/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.0472 - accuracy: 0.6092 - val_loss: 1.0597 - val_accuracy: 0.5962\n","Epoch 30/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0475 - accuracy: 0.6007 - val_loss: 1.0578 - val_accuracy: 0.5803\n","Epoch 31/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0449 - accuracy: 0.5934 - val_loss: 1.0617 - val_accuracy: 0.5588\n","Epoch 32/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.0412 - accuracy: 0.5993 - val_loss: 1.0507 - val_accuracy: 0.5973\n","Epoch 33/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0377 - accuracy: 0.5993 - val_loss: 1.0474 - val_accuracy: 0.5894\n","Epoch 34/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0324 - accuracy: 0.6053 - val_loss: 1.0450 - val_accuracy: 0.5882\n","Epoch 35/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.0303 - accuracy: 0.6075 - val_loss: 1.0448 - val_accuracy: 0.5713\n","Epoch 36/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0266 - accuracy: 0.6109 - val_loss: 1.0402 - val_accuracy: 0.5973\n","Epoch 37/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0299 - accuracy: 0.5945 - val_loss: 1.0485 - val_accuracy: 0.5520\n","Epoch 38/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0261 - accuracy: 0.5973 - val_loss: 1.0389 - val_accuracy: 0.5656\n","Epoch 39/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0231 - accuracy: 0.5976 - val_loss: 1.0310 - val_accuracy: 0.5848\n","Epoch 40/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0223 - accuracy: 0.5911 - val_loss: 1.0285 - val_accuracy: 0.5882\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0151 - accuracy: 0.6075 - val_loss: 1.0267 - val_accuracy: 0.5950\n","Epoch 42/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.0107 - accuracy: 0.6106 - val_loss: 1.0241 - val_accuracy: 0.5995\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0103 - accuracy: 0.6078 - val_loss: 1.0208 - val_accuracy: 0.5894\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0063 - accuracy: 0.6075 - val_loss: 1.0198 - val_accuracy: 0.5894\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0040 - accuracy: 0.6047 - val_loss: 1.0157 - val_accuracy: 0.5803\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0008 - accuracy: 0.6101 - val_loss: 1.0142 - val_accuracy: 0.5950\n","Epoch 47/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9993 - accuracy: 0.6053 - val_loss: 1.0170 - val_accuracy: 0.5701\n","Epoch 48/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9958 - accuracy: 0.6061 - val_loss: 1.0085 - val_accuracy: 0.5792\n","Epoch 49/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9919 - accuracy: 0.6123 - val_loss: 1.0067 - val_accuracy: 0.5871\n","Epoch 50/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9942 - accuracy: 0.6002 - val_loss: 1.0094 - val_accuracy: 0.5690\n","Epoch 51/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9895 - accuracy: 0.5999 - val_loss: 1.0050 - val_accuracy: 0.5667\n","Epoch 52/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9862 - accuracy: 0.6075 - val_loss: 0.9998 - val_accuracy: 0.5962\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9849 - accuracy: 0.6070 - val_loss: 0.9972 - val_accuracy: 0.5826\n","Epoch 54/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.9802 - accuracy: 0.6123 - val_loss: 0.9954 - val_accuracy: 0.6007\n","Epoch 55/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9784 - accuracy: 0.6129 - val_loss: 0.9949 - val_accuracy: 0.5803\n","Epoch 56/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9755 - accuracy: 0.6044 - val_loss: 0.9905 - val_accuracy: 0.5848\n","Epoch 57/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.9769 - accuracy: 0.6081 - val_loss: 0.9901 - val_accuracy: 0.5837\n","Epoch 58/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9713 - accuracy: 0.6112 - val_loss: 0.9915 - val_accuracy: 0.5735\n","Epoch 59/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9688 - accuracy: 0.6132 - val_loss: 0.9850 - val_accuracy: 0.5928\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9653 - accuracy: 0.6180 - val_loss: 0.9830 - val_accuracy: 0.5973\n","Epoch 61/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9653 - accuracy: 0.6072 - val_loss: 0.9843 - val_accuracy: 0.5848\n","Epoch 62/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9657 - accuracy: 0.6092 - val_loss: 0.9778 - val_accuracy: 0.5962\n","Epoch 63/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9602 - accuracy: 0.6132 - val_loss: 0.9758 - val_accuracy: 0.5950\n","Epoch 64/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9597 - accuracy: 0.6098 - val_loss: 0.9736 - val_accuracy: 0.5792\n","Epoch 65/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9542 - accuracy: 0.6183 - val_loss: 0.9733 - val_accuracy: 0.5826\n","Epoch 66/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9518 - accuracy: 0.6197 - val_loss: 0.9721 - val_accuracy: 0.5792\n","Epoch 67/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9511 - accuracy: 0.6146 - val_loss: 0.9695 - val_accuracy: 0.5939\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9490 - accuracy: 0.6214 - val_loss: 0.9665 - val_accuracy: 0.5939\n","Epoch 69/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9448 - accuracy: 0.6118 - val_loss: 0.9648 - val_accuracy: 0.5928\n","Epoch 70/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9423 - accuracy: 0.6217 - val_loss: 0.9663 - val_accuracy: 0.5769\n","Epoch 71/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9423 - accuracy: 0.6157 - val_loss: 0.9641 - val_accuracy: 0.5894\n","Epoch 72/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.9426 - accuracy: 0.6115 - val_loss: 0.9614 - val_accuracy: 0.5724\n","Epoch 73/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9400 - accuracy: 0.6160 - val_loss: 0.9587 - val_accuracy: 0.5882\n","Epoch 74/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9364 - accuracy: 0.6225 - val_loss: 0.9565 - val_accuracy: 0.5814\n","Epoch 75/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9321 - accuracy: 0.6220 - val_loss: 0.9644 - val_accuracy: 0.5622\n","Epoch 76/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9327 - accuracy: 0.6188 - val_loss: 0.9522 - val_accuracy: 0.5905\n","Epoch 77/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9299 - accuracy: 0.6183 - val_loss: 0.9511 - val_accuracy: 0.5781\n","Epoch 78/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9262 - accuracy: 0.6316 - val_loss: 0.9494 - val_accuracy: 0.5814\n","Epoch 79/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9259 - accuracy: 0.6129 - val_loss: 0.9463 - val_accuracy: 0.5950\n","Epoch 80/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9251 - accuracy: 0.6256 - val_loss: 0.9448 - val_accuracy: 0.5860\n","Epoch 81/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9213 - accuracy: 0.6203 - val_loss: 0.9497 - val_accuracy: 0.5713\n","Epoch 82/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9189 - accuracy: 0.6205 - val_loss: 0.9467 - val_accuracy: 0.5781\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9168 - accuracy: 0.6279 - val_loss: 0.9405 - val_accuracy: 0.5905\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9145 - accuracy: 0.6205 - val_loss: 0.9404 - val_accuracy: 0.5724\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9143 - accuracy: 0.6231 - val_loss: 0.9373 - val_accuracy: 0.5860\n","Epoch 86/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9123 - accuracy: 0.6174 - val_loss: 0.9345 - val_accuracy: 0.5928\n","Epoch 87/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9128 - accuracy: 0.6214 - val_loss: 0.9358 - val_accuracy: 0.5747\n","Epoch 88/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9086 - accuracy: 0.6225 - val_loss: 0.9314 - val_accuracy: 0.5916\n","Epoch 89/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9124 - accuracy: 0.6098 - val_loss: 0.9455 - val_accuracy: 0.5486\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9085 - accuracy: 0.6149 - val_loss: 0.9286 - val_accuracy: 0.5826\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9044 - accuracy: 0.6205 - val_loss: 0.9258 - val_accuracy: 0.5894\n","Epoch 92/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.9017 - accuracy: 0.6188 - val_loss: 0.9249 - val_accuracy: 0.5950\n","Epoch 93/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8976 - accuracy: 0.6313 - val_loss: 0.9245 - val_accuracy: 0.5882\n","Epoch 94/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8998 - accuracy: 0.6203 - val_loss: 0.9220 - val_accuracy: 0.5939\n","Epoch 95/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8945 - accuracy: 0.6285 - val_loss: 0.9234 - val_accuracy: 0.5781\n","Epoch 96/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8945 - accuracy: 0.6242 - val_loss: 0.9209 - val_accuracy: 0.5826\n","Epoch 97/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8930 - accuracy: 0.6251 - val_loss: 0.9175 - val_accuracy: 0.5939\n","Epoch 98/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8923 - accuracy: 0.6262 - val_loss: 0.9180 - val_accuracy: 0.5803\n","Epoch 99/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8897 - accuracy: 0.6273 - val_loss: 0.9183 - val_accuracy: 0.5781\n","Epoch 100/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8894 - accuracy: 0.6239 - val_loss: 0.9144 - val_accuracy: 0.5848\n","{'loss': [1.161208152770996, 1.1551637649536133, 1.1491433382034302, 1.1453475952148438, 1.139965534210205, 1.1409523487091064, 1.1302211284637451, 1.1260205507278442, 1.120936393737793, 1.118665337562561, 1.1123969554901123, 1.109521508216858, 1.1034581661224365, 1.1017347574234009, 1.09709632396698, 1.0954560041427612, 1.0908483266830444, 1.0853880643844604, 1.0869356393814087, 1.082837700843811, 1.0744030475616455, 1.0723508596420288, 1.0680266618728638, 1.0656663179397583, 1.0626466274261475, 1.0579748153686523, 1.0569548606872559, 1.0518757104873657, 1.0471607446670532, 1.0474860668182373, 1.0448552370071411, 1.0412092208862305, 1.0376569032669067, 1.0323528051376343, 1.030327320098877, 1.0266470909118652, 1.029924750328064, 1.0261116027832031, 1.023088812828064, 1.0222975015640259, 1.0151127576828003, 1.0106656551361084, 1.0103400945663452, 1.0062943696975708, 1.004025936126709, 1.0008141994476318, 0.9993465542793274, 0.9957517385482788, 0.9919155240058899, 0.994201123714447, 0.989507257938385, 0.9861866235733032, 0.9849257469177246, 0.9802192449569702, 0.9784034490585327, 0.975479006767273, 0.9769068956375122, 0.9713114500045776, 0.9687772393226624, 0.9653306603431702, 0.9653181433677673, 0.9657399654388428, 0.9601889252662659, 0.9597049951553345, 0.9541748762130737, 0.951789915561676, 0.9511204957962036, 0.9490305185317993, 0.9448434710502625, 0.94228595495224, 0.9423402547836304, 0.9426035284996033, 0.9399709105491638, 0.9363587498664856, 0.9320788979530334, 0.9327128529548645, 0.9298924207687378, 0.9262150526046753, 0.9259155988693237, 0.9250761866569519, 0.9212941527366638, 0.9188805818557739, 0.916752278804779, 0.9144638776779175, 0.914251983165741, 0.9122878313064575, 0.9128105044364929, 0.9086067080497742, 0.912390410900116, 0.9084616899490356, 0.9043785333633423, 0.9017472863197327, 0.8976441621780396, 0.8997951149940491, 0.8945380449295044, 0.8944864869117737, 0.8929912447929382, 0.8922634720802307, 0.8897063732147217, 0.8894164562225342], 'accuracy': [0.5848896503448486, 0.5882852077484131, 0.5913978219032288, 0.5913978219032288, 0.5846067070960999, 0.5764006972312927, 0.5964912176132202, 0.5964912176132202, 0.598471999168396, 0.5919637680053711, 0.5959252715110779, 0.5950763821601868, 0.600452721118927, 0.5962082743644714, 0.598471999168396, 0.5897000432014465, 0.5964912176132202, 0.6013016700744629, 0.5877193212509155, 0.5880022644996643, 0.602150559425354, 0.6131861805915833, 0.6092246770858765, 0.5998868346214294, 0.5919637680053711, 0.6075268983840942, 0.6001697778701782, 0.6083757877349854, 0.6092246770858765, 0.6007357239723206, 0.5933786034584045, 0.5993208885192871, 0.5993208885192871, 0.6052631735801697, 0.6075268983840942, 0.6109224557876587, 0.5945104956626892, 0.5973401069641113, 0.5976231098175049, 0.59111487865448, 0.6075268983840942, 0.6106395125389099, 0.607809841632843, 0.6075268983840942, 0.6046972274780273, 0.6100735664367676, 0.6052631735801697, 0.6061120629310608, 0.6123372912406921, 0.6001697778701782, 0.5998868346214294, 0.6075268983840942, 0.6069609522819519, 0.6123372912406921, 0.6129032373428345, 0.6044142842292786, 0.6080927848815918, 0.6112054586410522, 0.6131861805915833, 0.6179966330528259, 0.6072438955307007, 0.6092246770858765, 0.6131861805915833, 0.6097906231880188, 0.6182795763015747, 0.6196944117546082, 0.6146010160446167, 0.6213921904563904, 0.6117713451385498, 0.6216751337051392, 0.6157329082489014, 0.611488401889801, 0.6160158514976501, 0.6225240230560303, 0.6219581365585327, 0.618845522403717, 0.6182795763015747, 0.6315789222717285, 0.6129032373428345, 0.6256366968154907, 0.6202603578567505, 0.6205433011054993, 0.6279004216194153, 0.6205433011054993, 0.6230899691581726, 0.6174306869506836, 0.6213921904563904, 0.6225240230560303, 0.6097906231880188, 0.6148839592933655, 0.6205433011054993, 0.618845522403717, 0.6312959790229797, 0.6202603578567505, 0.6284663081169128, 0.6242218613624573, 0.6250707507133484, 0.6262025833129883, 0.627334475517273, 0.6239388585090637], 'val_loss': [1.1754074096679688, 1.1707274913787842, 1.1661293506622314, 1.1618080139160156, 1.157253623008728, 1.1529918909072876, 1.1481688022613525, 1.143953800201416, 1.139150619506836, 1.134738564491272, 1.1303709745407104, 1.1256709098815918, 1.1212642192840576, 1.116225242614746, 1.112196445465088, 1.1078935861587524, 1.1023508310317993, 1.0981217622756958, 1.104223370552063, 1.0898617506027222, 1.0853228569030762, 1.0820566415786743, 1.0775929689407349, 1.0756239891052246, 1.0779430866241455, 1.0694160461425781, 1.0642449855804443, 1.0631005764007568, 1.0596790313720703, 1.0577678680419922, 1.0616874694824219, 1.0507056713104248, 1.0474393367767334, 1.0449986457824707, 1.0447643995285034, 1.0402436256408691, 1.0484861135482788, 1.0388507843017578, 1.0309735536575317, 1.0285258293151855, 1.0266566276550293, 1.0241132974624634, 1.0207682847976685, 1.01976478099823, 1.015677571296692, 1.014184594154358, 1.0169707536697388, 1.0085400342941284, 1.0066996812820435, 1.0093944072723389, 1.0050016641616821, 0.9997540712356567, 0.9972118139266968, 0.9954445362091064, 0.9948604702949524, 0.990504801273346, 0.9901422262191772, 0.9914737939834595, 0.9850165843963623, 0.9829952716827393, 0.9842642545700073, 0.9778485894203186, 0.9757737517356873, 0.9736425280570984, 0.9732769131660461, 0.9720501899719238, 0.9695133566856384, 0.9664523601531982, 0.964799165725708, 0.9663133025169373, 0.9640582799911499, 0.9613956809043884, 0.9586770534515381, 0.9564776420593262, 0.9644464254379272, 0.9522011876106262, 0.9511048793792725, 0.9493682980537415, 0.9462680816650391, 0.9447620511054993, 0.9496639966964722, 0.9466522336006165, 0.940486490726471, 0.940359354019165, 0.9372646808624268, 0.9345207810401917, 0.9357950687408447, 0.9313672184944153, 0.9455404877662659, 0.9285754561424255, 0.92577064037323, 0.924939751625061, 0.924523651599884, 0.9220443367958069, 0.9233623743057251, 0.9209010004997253, 0.9175450205802917, 0.918034017086029, 0.9182548522949219, 0.9144033193588257], 'val_accuracy': [0.587104082107544, 0.581447958946228, 0.5825791954994202, 0.5124434232711792, 0.5282805562019348, 0.5147058963775635, 0.5859728455543518, 0.5328054428100586, 0.5859728455543518, 0.5746606588363647, 0.570135772228241, 0.5882353186607361, 0.581447958946228, 0.5859728455543518, 0.5893664956092834, 0.5678732991218567, 0.5893664956092834, 0.5848416090011597, 0.5226244330406189, 0.587104082107544, 0.5893664956092834, 0.5791855454444885, 0.5848416090011597, 0.5746606588363647, 0.5520362257957458, 0.5746606588363647, 0.587104082107544, 0.5803167223930359, 0.5961538553237915, 0.5803167223930359, 0.5588235259056091, 0.5972850918769836, 0.5893664956092834, 0.5882353186607361, 0.5712669491767883, 0.5972850918769836, 0.5520362257957458, 0.5656108856201172, 0.5848416090011597, 0.5882353186607361, 0.5950226187705994, 0.5995475053787231, 0.5893664956092834, 0.5893664956092834, 0.5803167223930359, 0.5950226187705994, 0.570135772228241, 0.5791855454444885, 0.587104082107544, 0.5690045356750488, 0.5667420625686646, 0.5961538553237915, 0.5825791954994202, 0.6006787419319153, 0.5803167223930359, 0.5848416090011597, 0.5837104320526123, 0.5735294222831726, 0.5927602052688599, 0.5972850918769836, 0.5848416090011597, 0.5961538553237915, 0.5950226187705994, 0.5791855454444885, 0.5825791954994202, 0.5791855454444885, 0.5938913822174072, 0.5938913822174072, 0.5927602052688599, 0.5769230723381042, 0.5893664956092834, 0.5723981857299805, 0.5882353186607361, 0.581447958946228, 0.5622171759605408, 0.5904977321624756, 0.5780543088912964, 0.581447958946228, 0.5950226187705994, 0.5859728455543518, 0.5712669491767883, 0.5780543088912964, 0.5904977321624756, 0.5723981857299805, 0.5859728455543518, 0.5927602052688599, 0.5746606588363647, 0.5916289687156677, 0.5486425161361694, 0.5825791954994202, 0.5893664956092834, 0.5950226187705994, 0.5882353186607361, 0.5938913822174072, 0.5780543088912964, 0.5825791954994202, 0.5938913822174072, 0.5803167223930359, 0.5780543088912964, 0.5848416090011597]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 1.1673 - accuracy: 0.5722"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 72ms/step - loss: 1.1677 - accuracy: 0.5685 - val_loss: 1.1750 - val_accuracy: 0.5682\n","Epoch 2/100\n","31/31 [==============================] - 1s 33ms/step - loss: 1.1604 - accuracy: 0.5788 - val_loss: 1.1699 - val_accuracy: 0.5795\n","Epoch 3/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.1561 - accuracy: 0.5685 - val_loss: 1.1648 - val_accuracy: 0.5682\n","Epoch 4/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1499 - accuracy: 0.5729 - val_loss: 1.1605 - val_accuracy: 0.5031\n","Epoch 5/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1453 - accuracy: 0.5736 - val_loss: 1.1555 - val_accuracy: 0.5145\n","Epoch 6/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1400 - accuracy: 0.5682 - val_loss: 1.1506 - val_accuracy: 0.5186\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1351 - accuracy: 0.5801 - val_loss: 1.1455 - val_accuracy: 0.5465\n","Epoch 8/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.1296 - accuracy: 0.5721 - val_loss: 1.1402 - val_accuracy: 0.5806\n","Epoch 9/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1262 - accuracy: 0.5752 - val_loss: 1.1351 - val_accuracy: 0.5826\n","Epoch 10/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1239 - accuracy: 0.5620 - val_loss: 1.1300 - val_accuracy: 0.5764\n","Epoch 11/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1176 - accuracy: 0.5734 - val_loss: 1.1256 - val_accuracy: 0.5630\n","Epoch 12/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1118 - accuracy: 0.5817 - val_loss: 1.1211 - val_accuracy: 0.5455\n","Epoch 13/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.1085 - accuracy: 0.5729 - val_loss: 1.1146 - val_accuracy: 0.5857\n","Epoch 14/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1073 - accuracy: 0.5667 - val_loss: 1.1119 - val_accuracy: 0.5289\n","Epoch 15/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1009 - accuracy: 0.5724 - val_loss: 1.1047 - val_accuracy: 0.5754\n","Epoch 16/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.0950 - accuracy: 0.5829 - val_loss: 1.0987 - val_accuracy: 0.5940\n","Epoch 17/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0912 - accuracy: 0.5793 - val_loss: 1.0939 - val_accuracy: 0.5816\n","Epoch 18/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0870 - accuracy: 0.5853 - val_loss: 1.0881 - val_accuracy: 0.5909\n","Epoch 19/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0832 - accuracy: 0.5858 - val_loss: 1.0834 - val_accuracy: 0.5826\n","Epoch 20/100\n","31/31 [==============================] - 1s 32ms/step - loss: 1.0803 - accuracy: 0.5798 - val_loss: 1.0776 - val_accuracy: 0.5971\n","Epoch 21/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0761 - accuracy: 0.5832 - val_loss: 1.0733 - val_accuracy: 0.5837\n","Epoch 22/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0719 - accuracy: 0.5835 - val_loss: 1.0691 - val_accuracy: 0.5837\n","Epoch 23/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.0672 - accuracy: 0.5824 - val_loss: 1.0660 - val_accuracy: 0.5744\n","Epoch 24/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0657 - accuracy: 0.5793 - val_loss: 1.0618 - val_accuracy: 0.5857\n","Epoch 25/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0634 - accuracy: 0.5734 - val_loss: 1.0610 - val_accuracy: 0.5837\n","Epoch 26/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0593 - accuracy: 0.5809 - val_loss: 1.0625 - val_accuracy: 0.5527\n","Epoch 27/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0590 - accuracy: 0.5713 - val_loss: 1.0493 - val_accuracy: 0.5888\n","Epoch 28/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0506 - accuracy: 0.5837 - val_loss: 1.0468 - val_accuracy: 0.5806\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0468 - accuracy: 0.5832 - val_loss: 1.0453 - val_accuracy: 0.5775\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0482 - accuracy: 0.5744 - val_loss: 1.0415 - val_accuracy: 0.5795\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0399 - accuracy: 0.5938 - val_loss: 1.0362 - val_accuracy: 0.5971\n","Epoch 32/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0359 - accuracy: 0.5827 - val_loss: 1.0369 - val_accuracy: 0.5775\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0323 - accuracy: 0.5855 - val_loss: 1.0305 - val_accuracy: 0.5795\n","Epoch 34/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0289 - accuracy: 0.5866 - val_loss: 1.0262 - val_accuracy: 0.5981\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0275 - accuracy: 0.5855 - val_loss: 1.0235 - val_accuracy: 0.5806\n","Epoch 36/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0256 - accuracy: 0.5855 - val_loss: 1.0226 - val_accuracy: 0.5961\n","Epoch 37/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0200 - accuracy: 0.5930 - val_loss: 1.0176 - val_accuracy: 0.5847\n","Epoch 38/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0181 - accuracy: 0.5881 - val_loss: 1.0180 - val_accuracy: 0.5733\n","Epoch 39/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0142 - accuracy: 0.5860 - val_loss: 1.0120 - val_accuracy: 0.5899\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0122 - accuracy: 0.5842 - val_loss: 1.0101 - val_accuracy: 0.5868\n","Epoch 41/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0105 - accuracy: 0.5871 - val_loss: 1.0063 - val_accuracy: 0.5857\n","Epoch 42/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.0077 - accuracy: 0.5879 - val_loss: 1.0057 - val_accuracy: 0.5795\n","Epoch 43/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0040 - accuracy: 0.5879 - val_loss: 1.0043 - val_accuracy: 0.5847\n","Epoch 44/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0006 - accuracy: 0.5798 - val_loss: 1.0010 - val_accuracy: 0.5826\n","Epoch 45/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9969 - accuracy: 0.5891 - val_loss: 0.9956 - val_accuracy: 0.5919\n","Epoch 46/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9937 - accuracy: 0.5907 - val_loss: 0.9944 - val_accuracy: 0.5723\n","Epoch 47/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9937 - accuracy: 0.5835 - val_loss: 0.9939 - val_accuracy: 0.5785\n","Epoch 48/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9903 - accuracy: 0.5873 - val_loss: 0.9880 - val_accuracy: 0.5795\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9856 - accuracy: 0.5925 - val_loss: 0.9863 - val_accuracy: 0.5899\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9821 - accuracy: 0.6010 - val_loss: 0.9884 - val_accuracy: 0.5702\n","Epoch 51/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9810 - accuracy: 0.5902 - val_loss: 0.9814 - val_accuracy: 0.5868\n","Epoch 52/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9790 - accuracy: 0.5925 - val_loss: 0.9789 - val_accuracy: 0.5919\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9739 - accuracy: 0.5922 - val_loss: 0.9773 - val_accuracy: 0.5754\n","Epoch 54/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9729 - accuracy: 0.5948 - val_loss: 0.9808 - val_accuracy: 0.5702\n","Epoch 55/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9720 - accuracy: 0.5925 - val_loss: 0.9708 - val_accuracy: 0.5878\n","Epoch 56/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9673 - accuracy: 0.5995 - val_loss: 0.9778 - val_accuracy: 0.5702\n","Epoch 57/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9663 - accuracy: 0.5876 - val_loss: 0.9684 - val_accuracy: 0.5837\n","Epoch 58/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9638 - accuracy: 0.5956 - val_loss: 0.9663 - val_accuracy: 0.5857\n","Epoch 59/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9618 - accuracy: 0.5876 - val_loss: 0.9631 - val_accuracy: 0.5857\n","Epoch 60/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9553 - accuracy: 0.6028 - val_loss: 0.9626 - val_accuracy: 0.5837\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9568 - accuracy: 0.5961 - val_loss: 0.9605 - val_accuracy: 0.5847\n","Epoch 62/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9542 - accuracy: 0.5956 - val_loss: 0.9557 - val_accuracy: 0.5837\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9534 - accuracy: 0.5915 - val_loss: 0.9539 - val_accuracy: 0.5837\n","Epoch 64/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9501 - accuracy: 0.5941 - val_loss: 0.9548 - val_accuracy: 0.5754\n","Epoch 65/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9465 - accuracy: 0.5961 - val_loss: 0.9494 - val_accuracy: 0.5816\n","Epoch 66/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9445 - accuracy: 0.5948 - val_loss: 0.9519 - val_accuracy: 0.5806\n","Epoch 67/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9423 - accuracy: 0.5948 - val_loss: 0.9474 - val_accuracy: 0.5888\n","Epoch 68/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9401 - accuracy: 0.5915 - val_loss: 0.9482 - val_accuracy: 0.5816\n","Epoch 69/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9373 - accuracy: 0.5987 - val_loss: 0.9422 - val_accuracy: 0.5826\n","Epoch 70/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9377 - accuracy: 0.5855 - val_loss: 0.9417 - val_accuracy: 0.5857\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9349 - accuracy: 0.5912 - val_loss: 0.9413 - val_accuracy: 0.5806\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9311 - accuracy: 0.5969 - val_loss: 0.9363 - val_accuracy: 0.5826\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9300 - accuracy: 0.5990 - val_loss: 0.9350 - val_accuracy: 0.5837\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9342 - accuracy: 0.5744 - val_loss: 0.9387 - val_accuracy: 0.5785\n","Epoch 75/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9246 - accuracy: 0.6021 - val_loss: 0.9346 - val_accuracy: 0.5785\n","Epoch 76/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9317 - accuracy: 0.5829 - val_loss: 0.9296 - val_accuracy: 0.5909\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9236 - accuracy: 0.5990 - val_loss: 0.9300 - val_accuracy: 0.5795\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9210 - accuracy: 0.5922 - val_loss: 0.9287 - val_accuracy: 0.5837\n","Epoch 79/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9173 - accuracy: 0.5959 - val_loss: 0.9252 - val_accuracy: 0.5816\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9136 - accuracy: 0.6018 - val_loss: 0.9227 - val_accuracy: 0.5847\n","Epoch 81/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9114 - accuracy: 0.6052 - val_loss: 0.9209 - val_accuracy: 0.5857\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9118 - accuracy: 0.6016 - val_loss: 0.9193 - val_accuracy: 0.5888\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9090 - accuracy: 0.5953 - val_loss: 0.9179 - val_accuracy: 0.5837\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9049 - accuracy: 0.6062 - val_loss: 0.9168 - val_accuracy: 0.5816\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9035 - accuracy: 0.6052 - val_loss: 0.9173 - val_accuracy: 0.5795\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9036 - accuracy: 0.6047 - val_loss: 0.9134 - val_accuracy: 0.5837\n","Epoch 87/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9019 - accuracy: 0.6026 - val_loss: 0.9168 - val_accuracy: 0.5775\n","Epoch 88/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8964 - accuracy: 0.6065 - val_loss: 0.9117 - val_accuracy: 0.5847\n","Epoch 89/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8952 - accuracy: 0.6026 - val_loss: 0.9102 - val_accuracy: 0.5723\n","Epoch 90/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8939 - accuracy: 0.6119 - val_loss: 0.9150 - val_accuracy: 0.5744\n","Epoch 91/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.8916 - accuracy: 0.6124 - val_loss: 0.9066 - val_accuracy: 0.5826\n","Epoch 92/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8938 - accuracy: 0.6018 - val_loss: 0.9048 - val_accuracy: 0.5826\n","Epoch 93/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8897 - accuracy: 0.6093 - val_loss: 0.9036 - val_accuracy: 0.5795\n","Epoch 94/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8895 - accuracy: 0.6078 - val_loss: 0.9022 - val_accuracy: 0.5806\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8846 - accuracy: 0.6098 - val_loss: 0.9001 - val_accuracy: 0.5785\n","Epoch 96/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8853 - accuracy: 0.6103 - val_loss: 0.9017 - val_accuracy: 0.5682\n","Epoch 97/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8835 - accuracy: 0.6028 - val_loss: 0.9030 - val_accuracy: 0.5744\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8806 - accuracy: 0.6158 - val_loss: 0.9020 - val_accuracy: 0.5733\n","Epoch 99/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8778 - accuracy: 0.6101 - val_loss: 0.8961 - val_accuracy: 0.5806\n","Epoch 100/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8770 - accuracy: 0.6129 - val_loss: 0.8957 - val_accuracy: 0.5754\n","{'loss': [1.1676808595657349, 1.1603872776031494, 1.1561152935028076, 1.149897813796997, 1.145341396331787, 1.140048861503601, 1.1350750923156738, 1.1296467781066895, 1.126173496246338, 1.1238596439361572, 1.1176438331604004, 1.1117914915084839, 1.1085432767868042, 1.107318639755249, 1.1009317636489868, 1.0949668884277344, 1.0912336111068726, 1.0870472192764282, 1.0832264423370361, 1.0803279876708984, 1.0761274099349976, 1.0718947649002075, 1.0672099590301514, 1.0656652450561523, 1.0634090900421143, 1.0592927932739258, 1.058957576751709, 1.0505716800689697, 1.0467925071716309, 1.0481624603271484, 1.0399359464645386, 1.035881757736206, 1.0322608947753906, 1.028930902481079, 1.0274931192398071, 1.0255578756332397, 1.0199893712997437, 1.0180792808532715, 1.0141842365264893, 1.0121656656265259, 1.0105186700820923, 1.0076831579208374, 1.0040215253829956, 1.0005522966384888, 0.9968503713607788, 0.9936772584915161, 0.9937355518341064, 0.990271806716919, 0.985621988773346, 0.9820675849914551, 0.981038510799408, 0.978986918926239, 0.9739198684692383, 0.9729151725769043, 0.9720075130462646, 0.9672595262527466, 0.9663012027740479, 0.9637637138366699, 0.9617554545402527, 0.9552505016326904, 0.9568275809288025, 0.9542344808578491, 0.9534280896186829, 0.9501317143440247, 0.9464868307113647, 0.9444605112075806, 0.9423075914382935, 0.9400545954704285, 0.9372695684432983, 0.9377243518829346, 0.9348846673965454, 0.9310715198516846, 0.9299739599227905, 0.9341716170310974, 0.9246076345443726, 0.9316830039024353, 0.9236359596252441, 0.9210419654846191, 0.9172911643981934, 0.9136199951171875, 0.9114189147949219, 0.9118385314941406, 0.9089594483375549, 0.9048532843589783, 0.9035021662712097, 0.9036152362823486, 0.9019136428833008, 0.8964220881462097, 0.8951882719993591, 0.8938917517662048, 0.8916283845901489, 0.8937512636184692, 0.8896535634994507, 0.8894528150558472, 0.8846147060394287, 0.8853061199188232, 0.8834982514381409, 0.8805878162384033, 0.8777875304222107, 0.8770444989204407], 'accuracy': [0.5684754252433777, 0.5788113474845886, 0.5684754252433777, 0.5728682279586792, 0.5736433863639832, 0.5682170391082764, 0.58010333776474, 0.5720930099487305, 0.5751938223838806, 0.5620155334472656, 0.5733850002288818, 0.5816537737846375, 0.5728682279586792, 0.5666666626930237, 0.5723513960838318, 0.5829457640647888, 0.579328179359436, 0.5852712988853455, 0.5857881307601929, 0.5798449516296387, 0.5832041501998901, 0.5834625363349915, 0.5824289321899414, 0.579328179359436, 0.5733850002288818, 0.5808785557746887, 0.5713178515434265, 0.5837209224700928, 0.5832041501998901, 0.5744186043739319, 0.5937984585762024, 0.5826873183250427, 0.5855297446250916, 0.5865632891654968, 0.5855297446250916, 0.5855297446250916, 0.5930232405662537, 0.5881136655807495, 0.5860465168952942, 0.5842377543449402, 0.5870801210403442, 0.5878552794456482, 0.5878552794456482, 0.5798449516296387, 0.5891472697257996, 0.5906976461410522, 0.5834625363349915, 0.5873385071754456, 0.592506468296051, 0.6010335683822632, 0.5901808738708496, 0.592506468296051, 0.5922480821609497, 0.5948320627212524, 0.592506468296051, 0.5994831919670105, 0.5875968933105469, 0.5956072211265564, 0.5875968933105469, 0.602842390537262, 0.5961240530014038, 0.5956072211265564, 0.591472864151001, 0.5940568447113037, 0.5961240530014038, 0.5948320627212524, 0.5948320627212524, 0.591472864151001, 0.5987080335617065, 0.5855297446250916, 0.5912144780158997, 0.5968992114067078, 0.5989664196968079, 0.5744186043739319, 0.6020671725273132, 0.5829457640647888, 0.5989664196968079, 0.5922480821609497, 0.5958656072616577, 0.6018087863922119, 0.6051679849624634, 0.6015504002571106, 0.5953488349914551, 0.6062015295028687, 0.6051679849624634, 0.604651153087616, 0.6025840044021606, 0.6064599752426147, 0.6025840044021606, 0.6118863224983215, 0.6124030947685242, 0.6018087863922119, 0.6093023419380188, 0.6077519655227661, 0.6098191142082214, 0.6103359460830688, 0.602842390537262, 0.6157622933387756, 0.6100775003433228, 0.6129198670387268], 'val_loss': [1.175022840499878, 1.1698691844940186, 1.1648242473602295, 1.1604838371276855, 1.1555283069610596, 1.1506085395812988, 1.145459771156311, 1.1402437686920166, 1.135061502456665, 1.1300410032272339, 1.1255978345870972, 1.1210836172103882, 1.1146048307418823, 1.111937165260315, 1.1046841144561768, 1.098672866821289, 1.0939359664916992, 1.0880520343780518, 1.083369255065918, 1.0776091814041138, 1.073317527770996, 1.069068193435669, 1.0659607648849487, 1.0617949962615967, 1.0609543323516846, 1.062548279762268, 1.0493179559707642, 1.046849012374878, 1.0452861785888672, 1.0415420532226562, 1.0362415313720703, 1.036877155303955, 1.0304611921310425, 1.026200532913208, 1.0235233306884766, 1.0225664377212524, 1.0176153182983398, 1.0179771184921265, 1.012016773223877, 1.010130524635315, 1.0063023567199707, 1.0057446956634521, 1.0043078660964966, 1.0010285377502441, 0.9955553412437439, 0.994390070438385, 0.9939248561859131, 0.9879899621009827, 0.9863446950912476, 0.9884033203125, 0.9813915491104126, 0.9789454936981201, 0.9772648811340332, 0.9807693958282471, 0.9708252549171448, 0.9777645468711853, 0.9684432744979858, 0.9662818312644958, 0.9630638360977173, 0.9625867605209351, 0.9604729413986206, 0.9556520581245422, 0.953937292098999, 0.9548108577728271, 0.9494178891181946, 0.9518813490867615, 0.9474431276321411, 0.9481539726257324, 0.9421696662902832, 0.9417204856872559, 0.9412932395935059, 0.9363157749176025, 0.9350492358207703, 0.9387214183807373, 0.9346041083335876, 0.9296430945396423, 0.930046796798706, 0.9286675453186035, 0.9251523017883301, 0.9226632118225098, 0.9208642840385437, 0.9192601442337036, 0.9178835153579712, 0.9168456792831421, 0.9172852039337158, 0.9134001731872559, 0.9167923331260681, 0.9116852879524231, 0.9101693034172058, 0.9150080680847168, 0.9065748453140259, 0.904808759689331, 0.9036180377006531, 0.9022180438041687, 0.9000779390335083, 0.9016520380973816, 0.9030099511146545, 0.9020099639892578, 0.8960883021354675, 0.8957458138465881], 'val_accuracy': [0.5681818127632141, 0.5795454382896423, 0.5681818127632141, 0.5030992031097412, 0.5144628286361694, 0.5185950398445129, 0.5464876294136047, 0.5805785059928894, 0.5826446413993835, 0.5764462947845459, 0.5630165338516235, 0.5454545617103577, 0.58574378490448, 0.5289255976676941, 0.5754132270812988, 0.5940082669258118, 0.5816115736961365, 0.5909090638160706, 0.5826446413993835, 0.5971074104309082, 0.5836777091026306, 0.5836777091026306, 0.5743801593780518, 0.58574378490448, 0.5836777091026306, 0.5526859760284424, 0.5888429880142212, 0.5805785059928894, 0.577479362487793, 0.5795454382896423, 0.5971074104309082, 0.577479362487793, 0.5795454382896423, 0.5981404781341553, 0.5805785059928894, 0.5960744023323059, 0.5847107172012329, 0.5733470916748047, 0.5898760557174683, 0.586776852607727, 0.58574378490448, 0.5795454382896423, 0.5847107172012329, 0.5826446413993835, 0.5919421315193176, 0.5723140239715576, 0.5785123705863953, 0.5795454382896423, 0.5898760557174683, 0.5702479481697083, 0.586776852607727, 0.5919421315193176, 0.5754132270812988, 0.5702479481697083, 0.5878099203109741, 0.5702479481697083, 0.5836777091026306, 0.58574378490448, 0.58574378490448, 0.5836777091026306, 0.5847107172012329, 0.5836777091026306, 0.5836777091026306, 0.5754132270812988, 0.5816115736961365, 0.5805785059928894, 0.5888429880142212, 0.5816115736961365, 0.5826446413993835, 0.58574378490448, 0.5805785059928894, 0.5826446413993835, 0.5836777091026306, 0.5785123705863953, 0.5785123705863953, 0.5909090638160706, 0.5795454382896423, 0.5836777091026306, 0.5816115736961365, 0.5847107172012329, 0.58574378490448, 0.5888429880142212, 0.5836777091026306, 0.5816115736961365, 0.5795454382896423, 0.5836777091026306, 0.577479362487793, 0.5847107172012329, 0.5723140239715576, 0.5743801593780518, 0.5826446413993835, 0.5826446413993835, 0.5795454382896423, 0.5805785059928894, 0.5785123705863953, 0.5681818127632141, 0.5743801593780518, 0.5733470916748047, 0.5805785059928894, 0.5754132270812988]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.8899 - accuracy: 0.6160"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 6s 57ms/step - loss: 0.8897 - accuracy: 0.6150 - val_loss: 0.9229 - val_accuracy: 0.5032\n","Epoch 2/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8864 - accuracy: 0.6166 - val_loss: 0.9213 - val_accuracy: 0.4914\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8828 - accuracy: 0.6172 - val_loss: 0.9197 - val_accuracy: 0.4871\n","Epoch 4/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8835 - accuracy: 0.6118 - val_loss: 0.9187 - val_accuracy: 0.4828\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8833 - accuracy: 0.6080 - val_loss: 0.9186 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8790 - accuracy: 0.6102 - val_loss: 0.9151 - val_accuracy: 0.4860\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8768 - accuracy: 0.6153 - val_loss: 0.9138 - val_accuracy: 0.4828\n","Epoch 8/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8754 - accuracy: 0.6175 - val_loss: 0.9119 - val_accuracy: 0.4881\n","Epoch 9/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.8752 - accuracy: 0.6196 - val_loss: 0.9074 - val_accuracy: 0.5377\n","Epoch 10/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8731 - accuracy: 0.6207 - val_loss: 0.9075 - val_accuracy: 0.4925\n","Epoch 11/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8681 - accuracy: 0.6204 - val_loss: 0.9040 - val_accuracy: 0.5151\n","Epoch 12/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8673 - accuracy: 0.6199 - val_loss: 0.9019 - val_accuracy: 0.5194\n","Epoch 13/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.8663 - accuracy: 0.6191 - val_loss: 0.8963 - val_accuracy: 0.5808\n","Epoch 14/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8641 - accuracy: 0.6193 - val_loss: 0.8985 - val_accuracy: 0.5183\n","Epoch 15/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8619 - accuracy: 0.6245 - val_loss: 0.8944 - val_accuracy: 0.5463\n","Epoch 16/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.8614 - accuracy: 0.6288 - val_loss: 0.8859 - val_accuracy: 0.5970\n","Epoch 17/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.8570 - accuracy: 0.6212 - val_loss: 0.8805 - val_accuracy: 0.6078\n","Epoch 18/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8581 - accuracy: 0.6290 - val_loss: 0.8772 - val_accuracy: 0.6034\n","Epoch 19/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.8566 - accuracy: 0.6258 - val_loss: 0.8735 - val_accuracy: 0.6121\n","Epoch 20/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8574 - accuracy: 0.6315 - val_loss: 0.8785 - val_accuracy: 0.5787\n","Epoch 21/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.8558 - accuracy: 0.6272 - val_loss: 0.8680 - val_accuracy: 0.6142\n","Epoch 22/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8526 - accuracy: 0.6218 - val_loss: 0.8667 - val_accuracy: 0.6121\n","Epoch 23/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8540 - accuracy: 0.6202 - val_loss: 0.8726 - val_accuracy: 0.5905\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8495 - accuracy: 0.6253 - val_loss: 0.8609 - val_accuracy: 0.6088\n","Epoch 25/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8466 - accuracy: 0.6296 - val_loss: 0.8604 - val_accuracy: 0.6110\n","Epoch 26/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.8467 - accuracy: 0.6320 - val_loss: 0.8627 - val_accuracy: 0.6175\n","Epoch 27/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8457 - accuracy: 0.6304 - val_loss: 0.8579 - val_accuracy: 0.6034\n","Epoch 28/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8461 - accuracy: 0.6226 - val_loss: 0.8548 - val_accuracy: 0.6131\n","Epoch 29/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8403 - accuracy: 0.6355 - val_loss: 0.8550 - val_accuracy: 0.6024\n","Epoch 30/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.8432 - accuracy: 0.6242 - val_loss: 0.8522 - val_accuracy: 0.6196\n","Epoch 31/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8413 - accuracy: 0.6323 - val_loss: 0.8550 - val_accuracy: 0.6164\n","Epoch 32/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8396 - accuracy: 0.6301 - val_loss: 0.8502 - val_accuracy: 0.6142\n","Epoch 33/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.8350 - accuracy: 0.6401 - val_loss: 0.8553 - val_accuracy: 0.6207\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8342 - accuracy: 0.6377 - val_loss: 0.8506 - val_accuracy: 0.6131\n","Epoch 35/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8328 - accuracy: 0.6433 - val_loss: 0.8474 - val_accuracy: 0.6056\n","Epoch 36/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8333 - accuracy: 0.6393 - val_loss: 0.8458 - val_accuracy: 0.6056\n","Epoch 37/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8342 - accuracy: 0.6272 - val_loss: 0.8517 - val_accuracy: 0.6078\n","Epoch 38/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8336 - accuracy: 0.6328 - val_loss: 0.8438 - val_accuracy: 0.6067\n","Epoch 39/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.8258 - accuracy: 0.6417 - val_loss: 0.8494 - val_accuracy: 0.6261\n","Epoch 40/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8260 - accuracy: 0.6406 - val_loss: 0.8520 - val_accuracy: 0.6153\n","Epoch 41/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8251 - accuracy: 0.6420 - val_loss: 0.8418 - val_accuracy: 0.6099\n","Epoch 42/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8239 - accuracy: 0.6420 - val_loss: 0.8403 - val_accuracy: 0.6056\n","Epoch 43/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8263 - accuracy: 0.6331 - val_loss: 0.8404 - val_accuracy: 0.6045\n","Epoch 44/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8222 - accuracy: 0.6377 - val_loss: 0.8422 - val_accuracy: 0.6218\n","Epoch 45/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8198 - accuracy: 0.6422 - val_loss: 0.8455 - val_accuracy: 0.6218\n","Epoch 46/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8172 - accuracy: 0.6444 - val_loss: 0.8382 - val_accuracy: 0.6056\n","Epoch 47/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.8221 - accuracy: 0.6363 - val_loss: 0.8435 - val_accuracy: 0.6282\n","Epoch 48/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8125 - accuracy: 0.6487 - val_loss: 0.8509 - val_accuracy: 0.5948\n","Epoch 49/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8145 - accuracy: 0.6433 - val_loss: 0.8364 - val_accuracy: 0.6099\n","Epoch 50/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8117 - accuracy: 0.6444 - val_loss: 0.8411 - val_accuracy: 0.6250\n","Epoch 51/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8133 - accuracy: 0.6476 - val_loss: 0.8450 - val_accuracy: 0.6142\n","Epoch 52/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8098 - accuracy: 0.6463 - val_loss: 0.8331 - val_accuracy: 0.6110\n","Epoch 53/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.8070 - accuracy: 0.6482 - val_loss: 0.8376 - val_accuracy: 0.6293\n","Epoch 54/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8059 - accuracy: 0.6565 - val_loss: 0.8334 - val_accuracy: 0.6272\n","Epoch 55/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8085 - accuracy: 0.6538 - val_loss: 0.8368 - val_accuracy: 0.6272\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8067 - accuracy: 0.6479 - val_loss: 0.8306 - val_accuracy: 0.6067\n","Epoch 57/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8037 - accuracy: 0.6517 - val_loss: 0.8306 - val_accuracy: 0.6250\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8069 - accuracy: 0.6444 - val_loss: 0.8295 - val_accuracy: 0.6067\n","Epoch 59/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8007 - accuracy: 0.6522 - val_loss: 0.8353 - val_accuracy: 0.6239\n","Epoch 60/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7982 - accuracy: 0.6544 - val_loss: 0.8291 - val_accuracy: 0.6067\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7984 - accuracy: 0.6549 - val_loss: 0.8447 - val_accuracy: 0.5916\n","Epoch 62/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8024 - accuracy: 0.6466 - val_loss: 0.8275 - val_accuracy: 0.6293\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7935 - accuracy: 0.6579 - val_loss: 0.8276 - val_accuracy: 0.6282\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7955 - accuracy: 0.6536 - val_loss: 0.8251 - val_accuracy: 0.6024\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7955 - accuracy: 0.6471 - val_loss: 0.8432 - val_accuracy: 0.5959\n","Epoch 66/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7931 - accuracy: 0.6562 - val_loss: 0.8240 - val_accuracy: 0.6067\n","Epoch 67/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7918 - accuracy: 0.6468 - val_loss: 0.8245 - val_accuracy: 0.6261\n","Epoch 68/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.7880 - accuracy: 0.6622 - val_loss: 0.8253 - val_accuracy: 0.6325\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7870 - accuracy: 0.6641 - val_loss: 0.8232 - val_accuracy: 0.6131\n","Epoch 70/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7852 - accuracy: 0.6635 - val_loss: 0.8241 - val_accuracy: 0.6325\n","Epoch 71/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7811 - accuracy: 0.6603 - val_loss: 0.8268 - val_accuracy: 0.6056\n","Epoch 72/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7830 - accuracy: 0.6633 - val_loss: 0.8370 - val_accuracy: 0.6056\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7933 - accuracy: 0.6460 - val_loss: 0.8215 - val_accuracy: 0.6272\n","Epoch 74/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7812 - accuracy: 0.6595 - val_loss: 0.8223 - val_accuracy: 0.6218\n","Epoch 75/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7811 - accuracy: 0.6606 - val_loss: 0.8202 - val_accuracy: 0.6088\n","Epoch 76/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7810 - accuracy: 0.6651 - val_loss: 0.8224 - val_accuracy: 0.6239\n","Epoch 77/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7748 - accuracy: 0.6700 - val_loss: 0.8276 - val_accuracy: 0.6175\n","Epoch 78/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7768 - accuracy: 0.6627 - val_loss: 0.8335 - val_accuracy: 0.6002\n","Epoch 79/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.7731 - accuracy: 0.6711 - val_loss: 0.8212 - val_accuracy: 0.6131\n","Epoch 80/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7722 - accuracy: 0.6751 - val_loss: 0.8301 - val_accuracy: 0.6099\n","Epoch 81/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7706 - accuracy: 0.6659 - val_loss: 0.8193 - val_accuracy: 0.6239\n","Epoch 82/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7656 - accuracy: 0.6743 - val_loss: 0.8204 - val_accuracy: 0.6261\n","Epoch 83/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7645 - accuracy: 0.6732 - val_loss: 0.8257 - val_accuracy: 0.6250\n","Epoch 84/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7672 - accuracy: 0.6716 - val_loss: 0.8176 - val_accuracy: 0.6175\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7616 - accuracy: 0.6765 - val_loss: 0.8188 - val_accuracy: 0.6272\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7646 - accuracy: 0.6746 - val_loss: 0.8168 - val_accuracy: 0.6315\n","Epoch 87/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7597 - accuracy: 0.6783 - val_loss: 0.8179 - val_accuracy: 0.6282\n","Epoch 88/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7606 - accuracy: 0.6770 - val_loss: 0.8157 - val_accuracy: 0.6228\n","Epoch 89/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7606 - accuracy: 0.6853 - val_loss: 0.8211 - val_accuracy: 0.6153\n","Epoch 90/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7648 - accuracy: 0.6689 - val_loss: 0.8215 - val_accuracy: 0.6218\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7567 - accuracy: 0.6783 - val_loss: 0.8151 - val_accuracy: 0.6272\n","Epoch 92/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7511 - accuracy: 0.6923 - val_loss: 0.8245 - val_accuracy: 0.6164\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7525 - accuracy: 0.6797 - val_loss: 0.8184 - val_accuracy: 0.6153\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7544 - accuracy: 0.6775 - val_loss: 0.8179 - val_accuracy: 0.6261\n","Epoch 95/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7576 - accuracy: 0.6797 - val_loss: 0.8507 - val_accuracy: 0.5808\n","Epoch 96/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7540 - accuracy: 0.6791 - val_loss: 0.8335 - val_accuracy: 0.6067\n","Epoch 97/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7512 - accuracy: 0.6808 - val_loss: 0.8254 - val_accuracy: 0.6088\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7513 - accuracy: 0.6786 - val_loss: 0.8295 - val_accuracy: 0.6185\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7419 - accuracy: 0.6937 - val_loss: 0.8274 - val_accuracy: 0.6153\n","Epoch 100/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7435 - accuracy: 0.6907 - val_loss: 0.8174 - val_accuracy: 0.6228\n","{'loss': [0.889729917049408, 0.8863972425460815, 0.8827999234199524, 0.883514404296875, 0.8832943439483643, 0.8790408372879028, 0.8767812848091125, 0.8754394054412842, 0.8752163052558899, 0.8731226325035095, 0.8680557012557983, 0.867264986038208, 0.866317868232727, 0.864087700843811, 0.8618839979171753, 0.8614174127578735, 0.8569628596305847, 0.8580516576766968, 0.8565521240234375, 0.8574206233024597, 0.8558408617973328, 0.8525964617729187, 0.8540403246879578, 0.8495399951934814, 0.846583902835846, 0.846653401851654, 0.8457258939743042, 0.8461081385612488, 0.8402726650238037, 0.8431819677352905, 0.8412584066390991, 0.8396143913269043, 0.8350080847740173, 0.8342118263244629, 0.8327826261520386, 0.8332957029342651, 0.8341744542121887, 0.8335978984832764, 0.8258329033851624, 0.8259535431861877, 0.8250928521156311, 0.8239390850067139, 0.8262814283370972, 0.822201132774353, 0.8198068141937256, 0.8171941041946411, 0.8221242427825928, 0.8125301003456116, 0.8144662380218506, 0.8117145299911499, 0.8133378624916077, 0.8097587823867798, 0.8069533109664917, 0.8059444427490234, 0.8084619641304016, 0.8066762089729309, 0.8036915063858032, 0.8069176077842712, 0.8006554841995239, 0.7981968522071838, 0.798382043838501, 0.8023790717124939, 0.7935265898704529, 0.7954919338226318, 0.7954872250556946, 0.793103039264679, 0.7918314933776855, 0.7880349159240723, 0.7869543433189392, 0.785168468952179, 0.7811350226402283, 0.7830479145050049, 0.7932670712471008, 0.7811585664749146, 0.7810668349266052, 0.7810261845588684, 0.7747715711593628, 0.7767961025238037, 0.7730880379676819, 0.7721570730209351, 0.7706420421600342, 0.7656148672103882, 0.7645406126976013, 0.7672275304794312, 0.761628270149231, 0.764644980430603, 0.7596870064735413, 0.7606432437896729, 0.7606249451637268, 0.7648090720176697, 0.7567138075828552, 0.7510560154914856, 0.7524704337120056, 0.7544068694114685, 0.7575560212135315, 0.7540393471717834, 0.7512456178665161, 0.7513127326965332, 0.7419232130050659, 0.7434624433517456], 'accuracy': [0.6150323152542114, 0.6166487336158752, 0.6171875, 0.6117995977401733, 0.608027994632721, 0.6101831793785095, 0.6153017282485962, 0.6174569129943848, 0.6196120977401733, 0.6206896305084229, 0.6204202771186829, 0.6198814511299133, 0.6190732717514038, 0.6193426847457886, 0.6244612336158752, 0.6287715435028076, 0.6212284564971924, 0.6290409564971924, 0.6258081793785095, 0.631465494632721, 0.6271551847457886, 0.6217672228813171, 0.6201508641242981, 0.6252694129943848, 0.6295797228813171, 0.6320043206214905, 0.6303879022598267, 0.6225754022598267, 0.6355064511299133, 0.6241918206214905, 0.6322737336158752, 0.6301185488700867, 0.6400862336158752, 0.6376616358757019, 0.6433189511299133, 0.639277994632721, 0.6271551847457886, 0.6328125, 0.6417025923728943, 0.640625, 0.641972005367279, 0.641972005367279, 0.6330819129943848, 0.6376616358757019, 0.642241358757019, 0.6443965435028076, 0.6363146305084229, 0.6487069129943848, 0.6433189511299133, 0.6443965435028076, 0.6476293206214905, 0.6462823152542114, 0.6481680870056152, 0.6565194129943848, 0.6538254022598267, 0.6478987336158752, 0.6516702771186829, 0.6443965435028076, 0.6522090435028076, 0.6543642282485962, 0.654902994632721, 0.6465517282485962, 0.657866358757019, 0.6535560488700867, 0.647090494632721, 0.65625, 0.646821141242981, 0.6621767282485962, 0.6640625, 0.6635237336158752, 0.6602909564971924, 0.6632543206214905, 0.6460129022598267, 0.6594827771186829, 0.6605603694915771, 0.6651400923728943, 0.6699892282485962, 0.662715494632721, 0.6710668206214905, 0.6751077771186829, 0.6659482717514038, 0.6742995977401733, 0.673222005367279, 0.6716055870056152, 0.6764547228813171, 0.6745689511299133, 0.678340494632721, 0.6769935488700867, 0.6853448152542114, 0.6689116358757019, 0.678340494632721, 0.6923491358757019, 0.6796875, 0.6775323152542114, 0.6796875, 0.6791487336158752, 0.6807650923728943, 0.6786099076271057, 0.693696141242981, 0.6907327771186829], 'val_loss': [0.9228964447975159, 0.9213381409645081, 0.9197285175323486, 0.9187210202217102, 0.9185569286346436, 0.9150756597518921, 0.9138109683990479, 0.9119036197662354, 0.9073630571365356, 0.907498300075531, 0.9040405750274658, 0.9019157290458679, 0.896347165107727, 0.8985447287559509, 0.894393801689148, 0.8859043121337891, 0.8805169463157654, 0.877189576625824, 0.8735321164131165, 0.8785310983657837, 0.8679525256156921, 0.8667207956314087, 0.8725789189338684, 0.8608670234680176, 0.8604007959365845, 0.8627066612243652, 0.8579419851303101, 0.8547686338424683, 0.8550167679786682, 0.8522377014160156, 0.8550118207931519, 0.8501848578453064, 0.85527503490448, 0.850555419921875, 0.8474358320236206, 0.8458254337310791, 0.8516904711723328, 0.8437995910644531, 0.8494077324867249, 0.8519941568374634, 0.8417710065841675, 0.8403258919715881, 0.8404229283332825, 0.8421680331230164, 0.8455193638801575, 0.8381794691085815, 0.843495786190033, 0.8508734703063965, 0.836368203163147, 0.8410655856132507, 0.845000147819519, 0.8330931067466736, 0.8376438617706299, 0.8334082961082458, 0.8367803692817688, 0.8305987119674683, 0.8306176662445068, 0.8294613361358643, 0.835258424282074, 0.8290825486183167, 0.8447442650794983, 0.8274552822113037, 0.8275730013847351, 0.8251134753227234, 0.8432192802429199, 0.8239752650260925, 0.8245276808738708, 0.8252580165863037, 0.8231912851333618, 0.8240969181060791, 0.826797366142273, 0.8370124697685242, 0.821494996547699, 0.8223125338554382, 0.820203959941864, 0.8224023580551147, 0.8275685906410217, 0.8334524035453796, 0.8211591839790344, 0.8301423192024231, 0.8192893862724304, 0.8203592896461487, 0.8257309198379517, 0.8175503015518188, 0.8188155889511108, 0.8167646527290344, 0.8179258108139038, 0.8157280087471008, 0.821063220500946, 0.8215351700782776, 0.8151170015335083, 0.8245241641998291, 0.8184078931808472, 0.8179329633712769, 0.8507238030433655, 0.8335340023040771, 0.8254169821739197, 0.829547107219696, 0.8273524045944214, 0.8173812627792358], 'val_accuracy': [0.5032327771186829, 0.4913793206214905, 0.48706895112991333, 0.48275861144065857, 0.48491379618644714, 0.48599138855934143, 0.48275861144065857, 0.4881465435028076, 0.537715494632721, 0.4924568831920624, 0.5150862336158752, 0.5193965435028076, 0.5808189511299133, 0.5183189511299133, 0.5463362336158752, 0.5969827771186829, 0.607758641242981, 0.6034482717514038, 0.6120689511299133, 0.5786637663841248, 0.6142241358757019, 0.6120689511299133, 0.5905172228813171, 0.6088362336158752, 0.610991358757019, 0.6174569129943848, 0.6034482717514038, 0.6131465435028076, 0.6023706793785095, 0.6196120977401733, 0.6163793206214905, 0.6142241358757019, 0.6206896305084229, 0.6131465435028076, 0.6056034564971924, 0.6056034564971924, 0.607758641242981, 0.6066810488700867, 0.6260775923728943, 0.6153017282485962, 0.6099137663841248, 0.6056034564971924, 0.6045258641242981, 0.6217672228813171, 0.6217672228813171, 0.6056034564971924, 0.6282327771186829, 0.5948275923728943, 0.6099137663841248, 0.625, 0.6142241358757019, 0.610991358757019, 0.6293103694915771, 0.6271551847457886, 0.6271551847457886, 0.6066810488700867, 0.625, 0.6066810488700867, 0.6239224076271057, 0.6066810488700867, 0.5915948152542114, 0.6293103694915771, 0.6282327771186829, 0.6023706793785095, 0.5959051847457886, 0.6066810488700867, 0.6260775923728943, 0.6325430870056152, 0.6131465435028076, 0.6325430870056152, 0.6056034564971924, 0.6056034564971924, 0.6271551847457886, 0.6217672228813171, 0.6088362336158752, 0.6239224076271057, 0.6174569129943848, 0.600215494632721, 0.6131465435028076, 0.6099137663841248, 0.6239224076271057, 0.6260775923728943, 0.625, 0.6174569129943848, 0.6271551847457886, 0.631465494632721, 0.6282327771186829, 0.6228448152542114, 0.6153017282485962, 0.6217672228813171, 0.6271551847457886, 0.6163793206214905, 0.6153017282485962, 0.6260775923728943, 0.5808189511299133, 0.6066810488700867, 0.6088362336158752, 0.618534505367279, 0.6153017282485962, 0.6228448152542114]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.8935 - accuracy: 0.6103"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 9s 77ms/step - loss: 0.8933 - accuracy: 0.6095 - val_loss: 0.9234 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.8871 - accuracy: 0.6132 - val_loss: 0.9216 - val_accuracy: 0.5090\n","Epoch 3/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.8833 - accuracy: 0.6183 - val_loss: 0.9197 - val_accuracy: 0.5136\n","Epoch 4/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8848 - accuracy: 0.6160 - val_loss: 0.9188 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.8855 - accuracy: 0.6146 - val_loss: 0.9159 - val_accuracy: 0.5498\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8809 - accuracy: 0.6146 - val_loss: 0.9150 - val_accuracy: 0.5045\n","Epoch 7/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8783 - accuracy: 0.6188 - val_loss: 0.9141 - val_accuracy: 0.4943\n","Epoch 8/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8776 - accuracy: 0.6132 - val_loss: 0.9119 - val_accuracy: 0.5090\n","Epoch 9/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8743 - accuracy: 0.6138 - val_loss: 0.9096 - val_accuracy: 0.5158\n","Epoch 10/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8715 - accuracy: 0.6234 - val_loss: 0.9077 - val_accuracy: 0.5181\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8706 - accuracy: 0.6251 - val_loss: 0.9078 - val_accuracy: 0.5102\n","Epoch 12/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8710 - accuracy: 0.6200 - val_loss: 0.9058 - val_accuracy: 0.5124\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8696 - accuracy: 0.6135 - val_loss: 0.9015 - val_accuracy: 0.5238\n","Epoch 14/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8687 - accuracy: 0.6138 - val_loss: 0.8990 - val_accuracy: 0.5441\n","Epoch 15/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8684 - accuracy: 0.6160 - val_loss: 0.8997 - val_accuracy: 0.5226\n","Epoch 16/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.8609 - accuracy: 0.6296 - val_loss: 0.8943 - val_accuracy: 0.5543\n","Epoch 17/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8613 - accuracy: 0.6251 - val_loss: 0.8961 - val_accuracy: 0.5215\n","Epoch 18/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.8606 - accuracy: 0.6208 - val_loss: 0.8857 - val_accuracy: 0.6075\n","Epoch 19/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8578 - accuracy: 0.6237 - val_loss: 0.8851 - val_accuracy: 0.5826\n","Epoch 20/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8600 - accuracy: 0.6228 - val_loss: 0.8812 - val_accuracy: 0.5781\n","Epoch 21/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8544 - accuracy: 0.6287 - val_loss: 0.8797 - val_accuracy: 0.5848\n","Epoch 22/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.8538 - accuracy: 0.6254 - val_loss: 0.8754 - val_accuracy: 0.6131\n","Epoch 23/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8513 - accuracy: 0.6239 - val_loss: 0.8765 - val_accuracy: 0.5916\n","Epoch 24/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8566 - accuracy: 0.6222 - val_loss: 0.8735 - val_accuracy: 0.5916\n","Epoch 25/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.8507 - accuracy: 0.6211 - val_loss: 0.8760 - val_accuracy: 0.5848\n","Epoch 26/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8475 - accuracy: 0.6256 - val_loss: 0.8699 - val_accuracy: 0.5950\n","Epoch 27/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8465 - accuracy: 0.6268 - val_loss: 0.8680 - val_accuracy: 0.6052\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8501 - accuracy: 0.6205 - val_loss: 0.8682 - val_accuracy: 0.5984\n","Epoch 29/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8443 - accuracy: 0.6271 - val_loss: 0.8656 - val_accuracy: 0.6075\n","Epoch 30/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8387 - accuracy: 0.6355 - val_loss: 0.8674 - val_accuracy: 0.5950\n","Epoch 31/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8398 - accuracy: 0.6336 - val_loss: 0.8652 - val_accuracy: 0.5950\n","Epoch 32/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8383 - accuracy: 0.6290 - val_loss: 0.8648 - val_accuracy: 0.5950\n","Epoch 33/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8382 - accuracy: 0.6296 - val_loss: 0.8623 - val_accuracy: 0.5995\n","Epoch 34/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8364 - accuracy: 0.6387 - val_loss: 0.8660 - val_accuracy: 0.6007\n","Epoch 35/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8354 - accuracy: 0.6341 - val_loss: 0.8654 - val_accuracy: 0.5950\n","Epoch 36/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8345 - accuracy: 0.6361 - val_loss: 0.8598 - val_accuracy: 0.6120\n","Epoch 37/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8327 - accuracy: 0.6304 - val_loss: 0.8645 - val_accuracy: 0.5984\n","Epoch 38/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8334 - accuracy: 0.6273 - val_loss: 0.8585 - val_accuracy: 0.6052\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8266 - accuracy: 0.6449 - val_loss: 0.8569 - val_accuracy: 0.6041\n","Epoch 40/100\n","28/28 [==============================] - 2s 55ms/step - loss: 0.8281 - accuracy: 0.6355 - val_loss: 0.8563 - val_accuracy: 0.6154\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8350 - accuracy: 0.6276 - val_loss: 0.8580 - val_accuracy: 0.5962\n","Epoch 42/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8243 - accuracy: 0.6347 - val_loss: 0.8549 - val_accuracy: 0.6018\n","Epoch 43/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8294 - accuracy: 0.6307 - val_loss: 0.8628 - val_accuracy: 0.5826\n","Epoch 44/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8269 - accuracy: 0.6333 - val_loss: 0.8526 - val_accuracy: 0.6029\n","Epoch 45/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8261 - accuracy: 0.6387 - val_loss: 0.8580 - val_accuracy: 0.5905\n","Epoch 46/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8211 - accuracy: 0.6395 - val_loss: 0.8569 - val_accuracy: 0.5962\n","Epoch 47/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8196 - accuracy: 0.6449 - val_loss: 0.8516 - val_accuracy: 0.6097\n","Epoch 48/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8160 - accuracy: 0.6531 - val_loss: 0.8532 - val_accuracy: 0.5950\n","Epoch 49/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8191 - accuracy: 0.6324 - val_loss: 0.8502 - val_accuracy: 0.6018\n","Epoch 50/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8195 - accuracy: 0.6350 - val_loss: 0.8492 - val_accuracy: 0.6063\n","Epoch 51/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8123 - accuracy: 0.6480 - val_loss: 0.8480 - val_accuracy: 0.6041\n","Epoch 52/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8131 - accuracy: 0.6423 - val_loss: 0.8476 - val_accuracy: 0.6120\n","Epoch 53/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8122 - accuracy: 0.6500 - val_loss: 0.8466 - val_accuracy: 0.5995\n","Epoch 54/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8127 - accuracy: 0.6426 - val_loss: 0.8483 - val_accuracy: 0.6007\n","Epoch 55/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8050 - accuracy: 0.6534 - val_loss: 0.8479 - val_accuracy: 0.6086\n","Epoch 56/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8065 - accuracy: 0.6469 - val_loss: 0.8464 - val_accuracy: 0.6063\n","Epoch 57/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8051 - accuracy: 0.6562 - val_loss: 0.8538 - val_accuracy: 0.5882\n","Epoch 58/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8149 - accuracy: 0.6375 - val_loss: 0.8438 - val_accuracy: 0.6029\n","Epoch 59/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8094 - accuracy: 0.6420 - val_loss: 0.8448 - val_accuracy: 0.6007\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8047 - accuracy: 0.6565 - val_loss: 0.8453 - val_accuracy: 0.5973\n","Epoch 61/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8034 - accuracy: 0.6559 - val_loss: 0.8438 - val_accuracy: 0.5995\n","Epoch 62/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8030 - accuracy: 0.6415 - val_loss: 0.8431 - val_accuracy: 0.6018\n","Epoch 63/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7946 - accuracy: 0.6556 - val_loss: 0.8415 - val_accuracy: 0.6041\n","Epoch 64/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7991 - accuracy: 0.6500 - val_loss: 0.8478 - val_accuracy: 0.5871\n","Epoch 65/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8027 - accuracy: 0.6449 - val_loss: 0.8476 - val_accuracy: 0.5894\n","Epoch 66/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8002 - accuracy: 0.6474 - val_loss: 0.8407 - val_accuracy: 0.5973\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7981 - accuracy: 0.6500 - val_loss: 0.8565 - val_accuracy: 0.5803\n","Epoch 68/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8093 - accuracy: 0.6370 - val_loss: 0.8382 - val_accuracy: 0.6063\n","Epoch 69/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7942 - accuracy: 0.6568 - val_loss: 0.8373 - val_accuracy: 0.6063\n","Epoch 70/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7910 - accuracy: 0.6568 - val_loss: 0.8404 - val_accuracy: 0.6018\n","Epoch 71/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7920 - accuracy: 0.6579 - val_loss: 0.8374 - val_accuracy: 0.6041\n","Epoch 72/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7869 - accuracy: 0.6653 - val_loss: 0.8386 - val_accuracy: 0.5950\n","Epoch 73/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7851 - accuracy: 0.6669 - val_loss: 0.8373 - val_accuracy: 0.5973\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7882 - accuracy: 0.6633 - val_loss: 0.8367 - val_accuracy: 0.6029\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7864 - accuracy: 0.6587 - val_loss: 0.8434 - val_accuracy: 0.5928\n","Epoch 76/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7849 - accuracy: 0.6638 - val_loss: 0.8347 - val_accuracy: 0.6097\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7847 - accuracy: 0.6565 - val_loss: 0.8336 - val_accuracy: 0.6109\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7849 - accuracy: 0.6624 - val_loss: 0.8347 - val_accuracy: 0.6120\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7805 - accuracy: 0.6672 - val_loss: 0.8338 - val_accuracy: 0.6018\n","Epoch 80/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7823 - accuracy: 0.6539 - val_loss: 0.8331 - val_accuracy: 0.6075\n","Epoch 81/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7826 - accuracy: 0.6582 - val_loss: 0.8316 - val_accuracy: 0.6018\n","Epoch 82/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7803 - accuracy: 0.6576 - val_loss: 0.8348 - val_accuracy: 0.5962\n","Epoch 83/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7759 - accuracy: 0.6698 - val_loss: 0.8321 - val_accuracy: 0.6029\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7710 - accuracy: 0.6771 - val_loss: 0.8360 - val_accuracy: 0.5984\n","Epoch 85/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7729 - accuracy: 0.6757 - val_loss: 0.8413 - val_accuracy: 0.5962\n","Epoch 86/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7693 - accuracy: 0.6732 - val_loss: 0.8423 - val_accuracy: 0.5962\n","Epoch 87/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7681 - accuracy: 0.6737 - val_loss: 0.8337 - val_accuracy: 0.6075\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7645 - accuracy: 0.6825 - val_loss: 0.8427 - val_accuracy: 0.5882\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7654 - accuracy: 0.6760 - val_loss: 0.8362 - val_accuracy: 0.5950\n","Epoch 90/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7705 - accuracy: 0.6650 - val_loss: 0.8340 - val_accuracy: 0.5984\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7647 - accuracy: 0.6757 - val_loss: 0.8299 - val_accuracy: 0.6041\n","Epoch 92/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7648 - accuracy: 0.6706 - val_loss: 0.8349 - val_accuracy: 0.5995\n","Epoch 93/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7619 - accuracy: 0.6800 - val_loss: 0.8293 - val_accuracy: 0.6029\n","Epoch 94/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7598 - accuracy: 0.6723 - val_loss: 0.8288 - val_accuracy: 0.6007\n","Epoch 95/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7586 - accuracy: 0.6797 - val_loss: 0.8306 - val_accuracy: 0.6063\n","Epoch 96/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7640 - accuracy: 0.6718 - val_loss: 0.8322 - val_accuracy: 0.6041\n","Epoch 97/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7622 - accuracy: 0.6777 - val_loss: 0.8356 - val_accuracy: 0.6007\n","Epoch 98/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7555 - accuracy: 0.6831 - val_loss: 0.8284 - val_accuracy: 0.6052\n","Epoch 99/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7570 - accuracy: 0.6885 - val_loss: 0.8278 - val_accuracy: 0.6097\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7514 - accuracy: 0.6868 - val_loss: 0.8297 - val_accuracy: 0.6007\n","{'loss': [0.8933164477348328, 0.8870643973350525, 0.8832709193229675, 0.8847507834434509, 0.8855366110801697, 0.8809135556221008, 0.8782902359962463, 0.8775815963745117, 0.8742746710777283, 0.8714994192123413, 0.8706027865409851, 0.8709835410118103, 0.8696297407150269, 0.8686866760253906, 0.868417501449585, 0.860909640789032, 0.8613300323486328, 0.8606287240982056, 0.8578479290008545, 0.8600401282310486, 0.8544425964355469, 0.8538245558738708, 0.8512722253799438, 0.8565678596496582, 0.8507072925567627, 0.8475245237350464, 0.846468448638916, 0.8501284718513489, 0.8443011045455933, 0.8386822938919067, 0.8397742509841919, 0.8382756114006042, 0.8381829857826233, 0.8363986611366272, 0.8353914022445679, 0.834543764591217, 0.8327019810676575, 0.8333895802497864, 0.8266387581825256, 0.8280578255653381, 0.8349595069885254, 0.8242797255516052, 0.8293634057044983, 0.8268680572509766, 0.8261260986328125, 0.8211396336555481, 0.8195843696594238, 0.8160400986671448, 0.8190788626670837, 0.8195241689682007, 0.8123089075088501, 0.8131003379821777, 0.8121928572654724, 0.8127153515815735, 0.8049941658973694, 0.806509792804718, 0.8051387667655945, 0.8148784041404724, 0.8093913793563843, 0.8046783208847046, 0.8033965826034546, 0.8029921650886536, 0.7946463227272034, 0.7990741729736328, 0.8026553392410278, 0.8001635074615479, 0.7981342077255249, 0.8093282580375671, 0.7941709160804749, 0.7909739017486572, 0.7919774651527405, 0.7868830561637878, 0.7850518226623535, 0.7881725430488586, 0.7864000797271729, 0.7849166393280029, 0.7846683263778687, 0.7849096655845642, 0.7804822325706482, 0.7823360562324524, 0.7826244235038757, 0.7802514433860779, 0.7758850455284119, 0.770992636680603, 0.7729249596595764, 0.769317626953125, 0.7680550813674927, 0.7644860744476318, 0.7653699517250061, 0.7704965472221375, 0.7646560072898865, 0.7647796273231506, 0.7618719935417175, 0.7597768306732178, 0.7585857510566711, 0.7640283703804016, 0.7622149586677551, 0.755532443523407, 0.7570071220397949, 0.7514060139656067], 'accuracy': [0.6095076203346252, 0.6131861805915833, 0.6182795763015747, 0.6160158514976501, 0.6146010160446167, 0.6146010160446167, 0.618845522403717, 0.6131861805915833, 0.6137521266937256, 0.6233729720115662, 0.6250707507133484, 0.6199773550033569, 0.6134691834449768, 0.6137521266937256, 0.6160158514976501, 0.6295982003211975, 0.6250707507133484, 0.620826244354248, 0.6236559152603149, 0.6228070259094238, 0.6287493109703064, 0.6253536939620972, 0.6239388585090637, 0.6222410798072815, 0.6211092472076416, 0.6256366968154907, 0.6267685294151306, 0.6205433011054993, 0.6270514726638794, 0.6355404853820801, 0.6335597038269043, 0.6290322542190552, 0.6295982003211975, 0.6386530995368958, 0.6341256499290466, 0.6361063718795776, 0.6304470896720886, 0.627334475517273, 0.6448783278465271, 0.6355404853820801, 0.6276174187660217, 0.634691596031189, 0.6307300329208374, 0.6332767605781555, 0.6386530995368958, 0.6395019888877869, 0.6448783278465271, 0.6530843377113342, 0.6324278712272644, 0.6349745392799377, 0.6479909420013428, 0.6423316597938538, 0.6499717235565186, 0.6426146030426025, 0.653367280960083, 0.6468591094017029, 0.6561969518661499, 0.6375212073326111, 0.6420486569404602, 0.6564798951148987, 0.6559139490127563, 0.6414827108383179, 0.6556310057640076, 0.6499717235565186, 0.6448783278465271, 0.6474249958992004, 0.6499717235565186, 0.6369553208351135, 0.6567628979682922, 0.6567628979682922, 0.6578947305679321, 0.6652518510818481, 0.6669496297836304, 0.6632710695266724, 0.6587436199188232, 0.6638370156288147, 0.6564798951148987, 0.6624221801757812, 0.6672325730323792, 0.6539332270622253, 0.6581776738166809, 0.6576117873191833, 0.6697793006896973, 0.6771363615989685, 0.6757215857505798, 0.6731748580932617, 0.673740804195404, 0.6825127601623535, 0.6760045289993286, 0.6649688482284546, 0.6757215857505798, 0.6706281900405884, 0.6799660325050354, 0.6723259687423706, 0.6796830892562866, 0.6717600226402283, 0.6777023077011108, 0.6830786466598511, 0.6884549856185913, 0.6867572069168091], 'val_loss': [0.9233847856521606, 0.9215720295906067, 0.9197213053703308, 0.9187946319580078, 0.9158504605293274, 0.9149628281593323, 0.9140722155570984, 0.9118642807006836, 0.9095732569694519, 0.9077465534210205, 0.9077661037445068, 0.905849277973175, 0.9015094637870789, 0.8990303874015808, 0.8996568918228149, 0.8942721486091614, 0.8961443901062012, 0.885718047618866, 0.8851345777511597, 0.8812283873558044, 0.8796950578689575, 0.8753898739814758, 0.8765323162078857, 0.8735235333442688, 0.8760380148887634, 0.8698821067810059, 0.8680210113525391, 0.8681998252868652, 0.8655516505241394, 0.8673600554466248, 0.865199863910675, 0.8647797703742981, 0.8622886538505554, 0.8659806251525879, 0.8654057383537292, 0.8598450422286987, 0.8645288348197937, 0.8585058450698853, 0.856926441192627, 0.8562763333320618, 0.8580013513565063, 0.8548662662506104, 0.8628286123275757, 0.8525582551956177, 0.8580191731452942, 0.8569357991218567, 0.8515928983688354, 0.8532060384750366, 0.850196123123169, 0.8491677045822144, 0.8480079770088196, 0.8475779294967651, 0.8465770483016968, 0.8482606410980225, 0.8479086756706238, 0.8463606238365173, 0.8538106083869934, 0.8437625765800476, 0.8448102474212646, 0.8453258872032166, 0.8438429832458496, 0.8431439995765686, 0.8414720892906189, 0.847771942615509, 0.8475820422172546, 0.8407304883003235, 0.856497049331665, 0.838228166103363, 0.8373366594314575, 0.8404488563537598, 0.8374066352844238, 0.8386355042457581, 0.837264895439148, 0.8366989493370056, 0.8433807492256165, 0.834723711013794, 0.8335861563682556, 0.83469158411026, 0.833828866481781, 0.8331188559532166, 0.8315547108650208, 0.8347893357276917, 0.8321229219436646, 0.835961639881134, 0.8413313627243042, 0.8422967791557312, 0.8337088823318481, 0.8427272439002991, 0.8361802101135254, 0.8340134620666504, 0.829868733882904, 0.8349390029907227, 0.8292677402496338, 0.8287600874900818, 0.8305965662002563, 0.8321533203125, 0.8355910181999207, 0.8284024000167847, 0.8278347849845886, 0.8296512961387634], 'val_accuracy': [0.4954751133918762, 0.5090497732162476, 0.5135746598243713, 0.4954751133918762, 0.5497737526893616, 0.5045248866081238, 0.4943438768386841, 0.5090497732162476, 0.5158371329307556, 0.5180995464324951, 0.5101810097694397, 0.5124434232711792, 0.523755669593811, 0.5441176295280457, 0.5226244330406189, 0.5542986392974854, 0.5214931964874268, 0.6074660420417786, 0.5825791954994202, 0.5780543088912964, 0.5848416090011597, 0.6131221652030945, 0.5916289687156677, 0.5916289687156677, 0.5848416090011597, 0.5950226187705994, 0.6052036285400391, 0.598416268825531, 0.6074660420417786, 0.5950226187705994, 0.5950226187705994, 0.5950226187705994, 0.5995475053787231, 0.6006787419319153, 0.5950226187705994, 0.6119909286499023, 0.598416268825531, 0.6052036285400391, 0.6040723919868469, 0.6153846383094788, 0.5961538553237915, 0.6018099784851074, 0.5825791954994202, 0.6029411554336548, 0.5904977321624756, 0.5961538553237915, 0.6097285151481628, 0.5950226187705994, 0.6018099784851074, 0.6063348650932312, 0.6040723919868469, 0.6119909286499023, 0.5995475053787231, 0.6006787419319153, 0.6085972785949707, 0.6063348650932312, 0.5882353186607361, 0.6029411554336548, 0.6006787419319153, 0.5972850918769836, 0.5995475053787231, 0.6018099784851074, 0.6040723919868469, 0.587104082107544, 0.5893664956092834, 0.5972850918769836, 0.5803167223930359, 0.6063348650932312, 0.6063348650932312, 0.6018099784851074, 0.6040723919868469, 0.5950226187705994, 0.5972850918769836, 0.6029411554336548, 0.5927602052688599, 0.6097285151481628, 0.610859751701355, 0.6119909286499023, 0.6018099784851074, 0.6074660420417786, 0.6018099784851074, 0.5961538553237915, 0.6029411554336548, 0.598416268825531, 0.5961538553237915, 0.5961538553237915, 0.6074660420417786, 0.5882353186607361, 0.5950226187705994, 0.598416268825531, 0.6040723919868469, 0.5995475053787231, 0.6029411554336548, 0.6006787419319153, 0.6063348650932312, 0.6040723919868469, 0.6006787419319153, 0.6052036285400391, 0.6097285151481628, 0.6006787419319153]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.9006 - accuracy: 0.5917"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 61ms/step - loss: 0.9006 - accuracy: 0.5917 - val_loss: 0.9237 - val_accuracy: 0.4866\n","Epoch 2/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8958 - accuracy: 0.5992 - val_loss: 0.9218 - val_accuracy: 0.4824\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8914 - accuracy: 0.6044 - val_loss: 0.9202 - val_accuracy: 0.4866\n","Epoch 4/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8891 - accuracy: 0.6052 - val_loss: 0.9188 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8879 - accuracy: 0.6039 - val_loss: 0.9163 - val_accuracy: 0.4835\n","Epoch 6/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8857 - accuracy: 0.6041 - val_loss: 0.9148 - val_accuracy: 0.4824\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8855 - accuracy: 0.6005 - val_loss: 0.9137 - val_accuracy: 0.4824\n","Epoch 8/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.8817 - accuracy: 0.6083 - val_loss: 0.9127 - val_accuracy: 0.4866\n","Epoch 9/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8826 - accuracy: 0.6036 - val_loss: 0.9136 - val_accuracy: 0.4855\n","Epoch 10/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8798 - accuracy: 0.6023 - val_loss: 0.9100 - val_accuracy: 0.4824\n","Epoch 11/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.8769 - accuracy: 0.6072 - val_loss: 0.9076 - val_accuracy: 0.4897\n","Epoch 12/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8742 - accuracy: 0.6080 - val_loss: 0.9059 - val_accuracy: 0.4907\n","Epoch 13/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8741 - accuracy: 0.6010 - val_loss: 0.9041 - val_accuracy: 0.5010\n","Epoch 14/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8699 - accuracy: 0.6124 - val_loss: 0.8984 - val_accuracy: 0.5248\n","Epoch 15/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8679 - accuracy: 0.6116 - val_loss: 0.8994 - val_accuracy: 0.5093\n","Epoch 16/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.8663 - accuracy: 0.6078 - val_loss: 0.8961 - val_accuracy: 0.5289\n","Epoch 17/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.8659 - accuracy: 0.6106 - val_loss: 0.8865 - val_accuracy: 0.5713\n","Epoch 18/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8639 - accuracy: 0.6080 - val_loss: 0.8823 - val_accuracy: 0.5702\n","Epoch 19/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8626 - accuracy: 0.6067 - val_loss: 0.8768 - val_accuracy: 0.5682\n","Epoch 20/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8616 - accuracy: 0.6109 - val_loss: 0.8745 - val_accuracy: 0.5713\n","Epoch 21/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8575 - accuracy: 0.6093 - val_loss: 0.8742 - val_accuracy: 0.5878\n","Epoch 22/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8583 - accuracy: 0.6080 - val_loss: 0.8707 - val_accuracy: 0.5764\n","Epoch 23/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8547 - accuracy: 0.6168 - val_loss: 0.8694 - val_accuracy: 0.5775\n","Epoch 24/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8550 - accuracy: 0.6132 - val_loss: 0.8756 - val_accuracy: 0.5754\n","Epoch 25/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8531 - accuracy: 0.6183 - val_loss: 0.8679 - val_accuracy: 0.5837\n","Epoch 26/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8516 - accuracy: 0.6109 - val_loss: 0.8677 - val_accuracy: 0.5878\n","Epoch 27/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8485 - accuracy: 0.6176 - val_loss: 0.8649 - val_accuracy: 0.5857\n","Epoch 28/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8485 - accuracy: 0.6093 - val_loss: 0.8639 - val_accuracy: 0.5806\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8488 - accuracy: 0.6124 - val_loss: 0.8648 - val_accuracy: 0.5795\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8446 - accuracy: 0.6137 - val_loss: 0.8621 - val_accuracy: 0.5816\n","Epoch 31/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8439 - accuracy: 0.6181 - val_loss: 0.8625 - val_accuracy: 0.5754\n","Epoch 32/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8392 - accuracy: 0.6266 - val_loss: 0.8605 - val_accuracy: 0.5816\n","Epoch 33/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8401 - accuracy: 0.6207 - val_loss: 0.8595 - val_accuracy: 0.5847\n","Epoch 34/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8457 - accuracy: 0.6070 - val_loss: 0.8632 - val_accuracy: 0.5775\n","Epoch 35/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8373 - accuracy: 0.6129 - val_loss: 0.8728 - val_accuracy: 0.5692\n","Epoch 36/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8409 - accuracy: 0.6155 - val_loss: 0.8561 - val_accuracy: 0.5826\n","Epoch 37/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8364 - accuracy: 0.6194 - val_loss: 0.8570 - val_accuracy: 0.5847\n","Epoch 38/100\n","31/31 [==============================] - 1s 44ms/step - loss: 0.8351 - accuracy: 0.6204 - val_loss: 0.8618 - val_accuracy: 0.5899\n","Epoch 39/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.8312 - accuracy: 0.6240 - val_loss: 0.8559 - val_accuracy: 0.5961\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8298 - accuracy: 0.6307 - val_loss: 0.8546 - val_accuracy: 0.5868\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8270 - accuracy: 0.6284 - val_loss: 0.8536 - val_accuracy: 0.5899\n","Epoch 42/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8303 - accuracy: 0.6150 - val_loss: 0.8521 - val_accuracy: 0.5775\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8297 - accuracy: 0.6261 - val_loss: 0.8515 - val_accuracy: 0.5806\n","Epoch 44/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8227 - accuracy: 0.6339 - val_loss: 0.8506 - val_accuracy: 0.5847\n","Epoch 45/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8270 - accuracy: 0.6264 - val_loss: 0.8523 - val_accuracy: 0.5950\n","Epoch 46/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8269 - accuracy: 0.6233 - val_loss: 0.8504 - val_accuracy: 0.5775\n","Epoch 47/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8214 - accuracy: 0.6282 - val_loss: 0.8483 - val_accuracy: 0.5795\n","Epoch 48/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.8193 - accuracy: 0.6302 - val_loss: 0.8534 - val_accuracy: 0.5795\n","Epoch 49/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8240 - accuracy: 0.6212 - val_loss: 0.8473 - val_accuracy: 0.5837\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8163 - accuracy: 0.6331 - val_loss: 0.8506 - val_accuracy: 0.5847\n","Epoch 51/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8138 - accuracy: 0.6339 - val_loss: 0.8483 - val_accuracy: 0.5981\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8187 - accuracy: 0.6253 - val_loss: 0.8470 - val_accuracy: 0.5899\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8135 - accuracy: 0.6313 - val_loss: 0.8562 - val_accuracy: 0.5847\n","Epoch 54/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8145 - accuracy: 0.6336 - val_loss: 0.8629 - val_accuracy: 0.5826\n","Epoch 55/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8098 - accuracy: 0.6403 - val_loss: 0.8440 - val_accuracy: 0.5826\n","Epoch 56/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8126 - accuracy: 0.6313 - val_loss: 0.8512 - val_accuracy: 0.5806\n","Epoch 57/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8084 - accuracy: 0.6362 - val_loss: 0.8495 - val_accuracy: 0.5857\n","Epoch 58/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8145 - accuracy: 0.6235 - val_loss: 0.8498 - val_accuracy: 0.5888\n","Epoch 59/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8049 - accuracy: 0.6413 - val_loss: 0.8440 - val_accuracy: 0.5878\n","Epoch 60/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8082 - accuracy: 0.6307 - val_loss: 0.8416 - val_accuracy: 0.5878\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8058 - accuracy: 0.6372 - val_loss: 0.8435 - val_accuracy: 0.5930\n","Epoch 62/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8025 - accuracy: 0.6380 - val_loss: 0.8440 - val_accuracy: 0.5806\n","Epoch 63/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8007 - accuracy: 0.6393 - val_loss: 0.8406 - val_accuracy: 0.5857\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7993 - accuracy: 0.6450 - val_loss: 0.8418 - val_accuracy: 0.5878\n","Epoch 65/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7954 - accuracy: 0.6406 - val_loss: 0.8460 - val_accuracy: 0.5775\n","Epoch 66/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7980 - accuracy: 0.6432 - val_loss: 0.8622 - val_accuracy: 0.5775\n","Epoch 67/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7963 - accuracy: 0.6457 - val_loss: 0.8454 - val_accuracy: 0.5795\n","Epoch 68/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7942 - accuracy: 0.6457 - val_loss: 0.8446 - val_accuracy: 0.5795\n","Epoch 69/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7890 - accuracy: 0.6517 - val_loss: 0.8386 - val_accuracy: 0.5909\n","Epoch 70/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.7869 - accuracy: 0.6512 - val_loss: 0.8403 - val_accuracy: 0.5899\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7899 - accuracy: 0.6543 - val_loss: 0.8390 - val_accuracy: 0.5950\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7940 - accuracy: 0.6457 - val_loss: 0.8413 - val_accuracy: 0.5888\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7957 - accuracy: 0.6328 - val_loss: 0.8550 - val_accuracy: 0.5868\n","Epoch 74/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7887 - accuracy: 0.6419 - val_loss: 0.8382 - val_accuracy: 0.5888\n","Epoch 75/100\n","31/31 [==============================] - 1s 44ms/step - loss: 0.7847 - accuracy: 0.6514 - val_loss: 0.8373 - val_accuracy: 0.6002\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7828 - accuracy: 0.6566 - val_loss: 0.8378 - val_accuracy: 0.5940\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7816 - accuracy: 0.6574 - val_loss: 0.8642 - val_accuracy: 0.5837\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7829 - accuracy: 0.6496 - val_loss: 0.8404 - val_accuracy: 0.5909\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7953 - accuracy: 0.6274 - val_loss: 0.8358 - val_accuracy: 0.5971\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7809 - accuracy: 0.6545 - val_loss: 0.8409 - val_accuracy: 0.5878\n","Epoch 81/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7779 - accuracy: 0.6522 - val_loss: 0.8347 - val_accuracy: 0.5888\n","Epoch 82/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7760 - accuracy: 0.6553 - val_loss: 0.8683 - val_accuracy: 0.5837\n","Epoch 83/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7867 - accuracy: 0.6401 - val_loss: 0.8354 - val_accuracy: 0.5971\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7732 - accuracy: 0.6615 - val_loss: 0.8408 - val_accuracy: 0.5940\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7703 - accuracy: 0.6669 - val_loss: 0.8461 - val_accuracy: 0.5847\n","Epoch 86/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7696 - accuracy: 0.6620 - val_loss: 0.8371 - val_accuracy: 0.5981\n","Epoch 87/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7666 - accuracy: 0.6724 - val_loss: 0.8379 - val_accuracy: 0.5909\n","Epoch 88/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7657 - accuracy: 0.6618 - val_loss: 0.8390 - val_accuracy: 0.5868\n","Epoch 89/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7715 - accuracy: 0.6594 - val_loss: 0.8442 - val_accuracy: 0.5909\n","Epoch 90/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7645 - accuracy: 0.6599 - val_loss: 0.8383 - val_accuracy: 0.5971\n","Epoch 91/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7607 - accuracy: 0.6687 - val_loss: 0.8385 - val_accuracy: 0.5919\n","Epoch 92/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7659 - accuracy: 0.6646 - val_loss: 0.8361 - val_accuracy: 0.5971\n","Epoch 93/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7627 - accuracy: 0.6664 - val_loss: 0.8400 - val_accuracy: 0.5816\n","Epoch 94/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7660 - accuracy: 0.6587 - val_loss: 0.8432 - val_accuracy: 0.5899\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7705 - accuracy: 0.6571 - val_loss: 0.8388 - val_accuracy: 0.5785\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7606 - accuracy: 0.6693 - val_loss: 0.8534 - val_accuracy: 0.5888\n","Epoch 97/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7541 - accuracy: 0.6736 - val_loss: 0.8369 - val_accuracy: 0.5888\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7614 - accuracy: 0.6672 - val_loss: 0.8387 - val_accuracy: 0.5971\n","Epoch 99/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7578 - accuracy: 0.6680 - val_loss: 0.8369 - val_accuracy: 0.5909\n","Epoch 100/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7528 - accuracy: 0.6729 - val_loss: 0.8425 - val_accuracy: 0.5919\n","{'loss': [0.9005641937255859, 0.8958480358123779, 0.8914037346839905, 0.8890842795372009, 0.8879013061523438, 0.8856638073921204, 0.8854584693908691, 0.8817113637924194, 0.8826102614402771, 0.8797805905342102, 0.8769176602363586, 0.8741905689239502, 0.8741233944892883, 0.8699384927749634, 0.8679049611091614, 0.8663370609283447, 0.8658900260925293, 0.8638784885406494, 0.8625847697257996, 0.8615884184837341, 0.8574504256248474, 0.8582667708396912, 0.8546829223632812, 0.8549606800079346, 0.8531113266944885, 0.8516427278518677, 0.8484508991241455, 0.8485140800476074, 0.848757266998291, 0.8445788621902466, 0.8439069390296936, 0.8392268419265747, 0.8401051163673401, 0.8457025289535522, 0.8372865319252014, 0.8409244418144226, 0.8363932371139526, 0.8351252675056458, 0.8312472701072693, 0.8298218846321106, 0.8270288705825806, 0.8302880525588989, 0.8297250866889954, 0.8227455615997314, 0.8270402550697327, 0.8269106149673462, 0.8213866949081421, 0.8192933797836304, 0.8239682912826538, 0.8162561058998108, 0.8138263821601868, 0.8187006115913391, 0.813512921333313, 0.8144620656967163, 0.8097949028015137, 0.8125539422035217, 0.8083553910255432, 0.8144687414169312, 0.8048896789550781, 0.8082343935966492, 0.8058494925498962, 0.8024669289588928, 0.8006661534309387, 0.7993364930152893, 0.7954328656196594, 0.7980379462242126, 0.7962542772293091, 0.7942211031913757, 0.7890235781669617, 0.7869162559509277, 0.7898741960525513, 0.7939961552619934, 0.7956802248954773, 0.7886865735054016, 0.7847213745117188, 0.7827602624893188, 0.7815595269203186, 0.7829257845878601, 0.7952974438667297, 0.7808883786201477, 0.7779090404510498, 0.7759996652603149, 0.7867467999458313, 0.7731640934944153, 0.770286500453949, 0.7695938944816589, 0.7666038274765015, 0.7656511068344116, 0.7715153098106384, 0.7644537091255188, 0.7606740593910217, 0.7659114599227905, 0.7627041339874268, 0.7660073041915894, 0.7705012559890747, 0.7606151700019836, 0.7541162371635437, 0.7613697052001953, 0.7578441500663757, 0.752842903137207], 'accuracy': [0.5917312502861023, 0.5992248058319092, 0.6043927669525146, 0.6051679849624634, 0.603875994682312, 0.6041343808174133, 0.6005167961120605, 0.6082687377929688, 0.6036175489425659, 0.6023255586624146, 0.6072351336479187, 0.6080103516578674, 0.6010335683822632, 0.6124030947685242, 0.6116279363632202, 0.6077519655227661, 0.6105943322181702, 0.6080103516578674, 0.6067183613777161, 0.6108527183532715, 0.6093023419380188, 0.6080103516578674, 0.6167958378791809, 0.6131783127784729, 0.6183462738990784, 0.6108527183532715, 0.6175710558891296, 0.6093023419380188, 0.6124030947685242, 0.6136950850486755, 0.6180878281593323, 0.6266149878501892, 0.620671808719635, 0.6069767475128174, 0.6129198670387268, 0.6155038475990295, 0.6193798184394836, 0.6204134225845337, 0.6240310072898865, 0.6307493448257446, 0.6284237504005432, 0.6149870753288269, 0.6260982155799866, 0.6338501572608948, 0.6263566017150879, 0.6232557892799377, 0.6281653642654419, 0.630232572555542, 0.6211886405944824, 0.633074939250946, 0.6338501572608948, 0.6253229975700378, 0.631266176700592, 0.6335917115211487, 0.6403100490570068, 0.631266176700592, 0.6361756920814514, 0.6235142350196838, 0.6413436532020569, 0.6307493448257446, 0.6372092962265015, 0.6379845142364502, 0.6392765045166016, 0.6449612379074097, 0.6405684947967529, 0.6431524753570557, 0.6457364559173584, 0.6457364559173584, 0.6516795754432678, 0.6511628031730652, 0.6542635560035706, 0.6457364559173584, 0.6328165531158447, 0.6418604850769043, 0.6514211893081665, 0.656589150428772, 0.6573643684387207, 0.6496124267578125, 0.6273902058601379, 0.6545219421386719, 0.6521964073181152, 0.6552971601486206, 0.6400516629219055, 0.6614987254142761, 0.6669250726699829, 0.6620154976844788, 0.6723514199256897, 0.6617571115493774, 0.659431517124176, 0.6599483489990234, 0.6687338352203369, 0.6645994782447815, 0.6664082407951355, 0.6586563587188721, 0.6571059226989746, 0.6692506670951843, 0.6736434102058411, 0.6671834588050842, 0.667958676815033, 0.6728681921958923], 'val_loss': [0.9236574172973633, 0.9217797517776489, 0.920154333114624, 0.9188306331634521, 0.9163150191307068, 0.9147752523422241, 0.9136626720428467, 0.9126998782157898, 0.9135525822639465, 0.909995973110199, 0.9075608849525452, 0.9058918952941895, 0.90411776304245, 0.8984277844429016, 0.8993676900863647, 0.8961038589477539, 0.8865073919296265, 0.8822993636131287, 0.8767508268356323, 0.8745357990264893, 0.8742201328277588, 0.8706662654876709, 0.8693577647209167, 0.8755900859832764, 0.8679417967796326, 0.8676774501800537, 0.8649475574493408, 0.8638665080070496, 0.8647745251655579, 0.8621267080307007, 0.8624950051307678, 0.8605445623397827, 0.8594777584075928, 0.8632432222366333, 0.8728406429290771, 0.8561357259750366, 0.857015073299408, 0.8617991805076599, 0.8558951020240784, 0.85460364818573, 0.8535670638084412, 0.8520568609237671, 0.8514752984046936, 0.8505986928939819, 0.852279782295227, 0.8503788113594055, 0.8483105301856995, 0.8533830642700195, 0.8472632765769958, 0.8505584001541138, 0.8483455181121826, 0.8470324873924255, 0.85624760389328, 0.8629021644592285, 0.844017505645752, 0.8511500358581543, 0.8495240807533264, 0.8497515320777893, 0.8439808487892151, 0.8415770530700684, 0.8434767127037048, 0.8439693450927734, 0.8406389355659485, 0.8417981863021851, 0.8459771871566772, 0.8622406125068665, 0.8454363346099854, 0.8445640802383423, 0.8385696411132812, 0.8402694463729858, 0.8390107750892639, 0.8412872552871704, 0.8550075888633728, 0.8381555676460266, 0.8372778296470642, 0.8377969264984131, 0.864195704460144, 0.8403531908988953, 0.8357877731323242, 0.840898334980011, 0.8346778154373169, 0.8683435320854187, 0.8354408144950867, 0.840789794921875, 0.8461215496063232, 0.8371149301528931, 0.8379257917404175, 0.8390107154846191, 0.8442195057868958, 0.8382967114448547, 0.8385289311408997, 0.836128294467926, 0.8400341868400574, 0.8431916236877441, 0.8388044238090515, 0.8533920645713806, 0.8369421362876892, 0.8387069702148438, 0.8369051814079285, 0.8425017595291138], 'val_accuracy': [0.48657023906707764, 0.48243802785873413, 0.48657023906707764, 0.48553720116615295, 0.4834710657596588, 0.48243802785873413, 0.48243802785873413, 0.48657023906707764, 0.48553720116615295, 0.48243802785873413, 0.48966941237449646, 0.49070248007774353, 0.5010330677032471, 0.5247933864593506, 0.5092975497245789, 0.5289255976676941, 0.5712810158729553, 0.5702479481697083, 0.5681818127632141, 0.5712810158729553, 0.5878099203109741, 0.5764462947845459, 0.577479362487793, 0.5754132270812988, 0.5836777091026306, 0.5878099203109741, 0.58574378490448, 0.5805785059928894, 0.5795454382896423, 0.5816115736961365, 0.5754132270812988, 0.5816115736961365, 0.5847107172012329, 0.577479362487793, 0.5692148804664612, 0.5826446413993835, 0.5847107172012329, 0.5898760557174683, 0.5960744023323059, 0.586776852607727, 0.5898760557174683, 0.577479362487793, 0.5805785059928894, 0.5847107172012329, 0.5950413346290588, 0.577479362487793, 0.5795454382896423, 0.5795454382896423, 0.5836777091026306, 0.5847107172012329, 0.5981404781341553, 0.5898760557174683, 0.5847107172012329, 0.5826446413993835, 0.5826446413993835, 0.5805785059928894, 0.58574378490448, 0.5888429880142212, 0.5878099203109741, 0.5878099203109741, 0.5929751992225647, 0.5805785059928894, 0.58574378490448, 0.5878099203109741, 0.577479362487793, 0.577479362487793, 0.5795454382896423, 0.5795454382896423, 0.5909090638160706, 0.5898760557174683, 0.5950413346290588, 0.5888429880142212, 0.586776852607727, 0.5888429880142212, 0.6002066135406494, 0.5940082669258118, 0.5836777091026306, 0.5909090638160706, 0.5971074104309082, 0.5878099203109741, 0.5888429880142212, 0.5836777091026306, 0.5971074104309082, 0.5940082669258118, 0.5847107172012329, 0.5981404781341553, 0.5909090638160706, 0.586776852607727, 0.5909090638160706, 0.5971074104309082, 0.5919421315193176, 0.5971074104309082, 0.5816115736961365, 0.5898760557174683, 0.5785123705863953, 0.5888429880142212, 0.5888429880142212, 0.5971074104309082, 0.5909090638160706, 0.5919421315193176]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.7776 - accuracy: 0.6479"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 6s 56ms/step - loss: 0.7773 - accuracy: 0.6492 - val_loss: 0.8467 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7726 - accuracy: 0.6592 - val_loss: 0.8464 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7655 - accuracy: 0.6689 - val_loss: 0.8468 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7612 - accuracy: 0.6705 - val_loss: 0.8463 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.7611 - accuracy: 0.6713 - val_loss: 0.8446 - val_accuracy: 0.4860\n","Epoch 6/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.7584 - accuracy: 0.6727 - val_loss: 0.8447 - val_accuracy: 0.4871\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7589 - accuracy: 0.6778 - val_loss: 0.8440 - val_accuracy: 0.4860\n","Epoch 8/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7573 - accuracy: 0.6773 - val_loss: 0.8459 - val_accuracy: 0.4871\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7529 - accuracy: 0.6794 - val_loss: 0.8493 - val_accuracy: 0.4860\n","Epoch 10/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7560 - accuracy: 0.6743 - val_loss: 0.8537 - val_accuracy: 0.4849\n","Epoch 11/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.7594 - accuracy: 0.6614 - val_loss: 0.8434 - val_accuracy: 0.4892\n","Epoch 12/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7553 - accuracy: 0.6711 - val_loss: 0.8534 - val_accuracy: 0.4871\n","Epoch 13/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.7531 - accuracy: 0.6735 - val_loss: 0.8344 - val_accuracy: 0.5205\n","Epoch 14/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7647 - accuracy: 0.6641 - val_loss: 0.8382 - val_accuracy: 0.5129\n","Epoch 15/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7506 - accuracy: 0.6746 - val_loss: 0.8410 - val_accuracy: 0.5119\n","Epoch 16/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.7470 - accuracy: 0.6870 - val_loss: 0.8258 - val_accuracy: 0.5539\n","Epoch 17/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.7467 - accuracy: 0.6848 - val_loss: 0.8189 - val_accuracy: 0.5905\n","Epoch 18/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7486 - accuracy: 0.6783 - val_loss: 0.8213 - val_accuracy: 0.5647\n","Epoch 19/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.7443 - accuracy: 0.6835 - val_loss: 0.8096 - val_accuracy: 0.6013\n","Epoch 20/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.7420 - accuracy: 0.6883 - val_loss: 0.8000 - val_accuracy: 0.6250\n","Epoch 21/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.7380 - accuracy: 0.6940 - val_loss: 0.7969 - val_accuracy: 0.6261\n","Epoch 22/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.7396 - accuracy: 0.6859 - val_loss: 0.7939 - val_accuracy: 0.6282\n","Epoch 23/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.7408 - accuracy: 0.6870 - val_loss: 0.7957 - val_accuracy: 0.6369\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7370 - accuracy: 0.6870 - val_loss: 0.7898 - val_accuracy: 0.6358\n","Epoch 25/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7352 - accuracy: 0.6910 - val_loss: 0.8021 - val_accuracy: 0.6142\n","Epoch 26/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.7388 - accuracy: 0.6829 - val_loss: 0.7879 - val_accuracy: 0.6530\n","Epoch 27/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7307 - accuracy: 0.6956 - val_loss: 0.7878 - val_accuracy: 0.6476\n","Epoch 28/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7291 - accuracy: 0.6985 - val_loss: 0.7859 - val_accuracy: 0.6519\n","Epoch 29/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7303 - accuracy: 0.6888 - val_loss: 0.7917 - val_accuracy: 0.6336\n","Epoch 30/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7294 - accuracy: 0.6932 - val_loss: 0.7897 - val_accuracy: 0.6412\n","Epoch 31/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7334 - accuracy: 0.6926 - val_loss: 0.8216 - val_accuracy: 0.6067\n","Epoch 32/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7294 - accuracy: 0.6940 - val_loss: 0.7863 - val_accuracy: 0.6509\n","Epoch 33/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7251 - accuracy: 0.6980 - val_loss: 0.7881 - val_accuracy: 0.6519\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7351 - accuracy: 0.6870 - val_loss: 0.8150 - val_accuracy: 0.6131\n","Epoch 35/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7368 - accuracy: 0.6835 - val_loss: 0.8238 - val_accuracy: 0.6121\n","Epoch 36/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.7276 - accuracy: 0.6870 - val_loss: 0.7857 - val_accuracy: 0.6541\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7183 - accuracy: 0.7010 - val_loss: 0.7940 - val_accuracy: 0.6433\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7197 - accuracy: 0.7031 - val_loss: 0.7895 - val_accuracy: 0.6422\n","Epoch 39/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7207 - accuracy: 0.7015 - val_loss: 0.7992 - val_accuracy: 0.6250\n","Epoch 40/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7139 - accuracy: 0.7015 - val_loss: 0.7867 - val_accuracy: 0.6487\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7136 - accuracy: 0.7055 - val_loss: 0.7883 - val_accuracy: 0.6476\n","Epoch 42/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7146 - accuracy: 0.7120 - val_loss: 0.7851 - val_accuracy: 0.6519\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7109 - accuracy: 0.7091 - val_loss: 0.7947 - val_accuracy: 0.6509\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7134 - accuracy: 0.7061 - val_loss: 0.7938 - val_accuracy: 0.6336\n","Epoch 45/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7254 - accuracy: 0.6948 - val_loss: 0.7978 - val_accuracy: 0.6369\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7095 - accuracy: 0.7131 - val_loss: 0.7854 - val_accuracy: 0.6519\n","Epoch 47/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7125 - accuracy: 0.7045 - val_loss: 0.7909 - val_accuracy: 0.6487\n","Epoch 48/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.7086 - accuracy: 0.7099 - val_loss: 0.7851 - val_accuracy: 0.6595\n","Epoch 49/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7067 - accuracy: 0.7134 - val_loss: 0.7913 - val_accuracy: 0.6498\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7143 - accuracy: 0.7080 - val_loss: 0.8088 - val_accuracy: 0.6239\n","Epoch 51/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7052 - accuracy: 0.7139 - val_loss: 0.8152 - val_accuracy: 0.6218\n","Epoch 52/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7196 - accuracy: 0.7042 - val_loss: 0.7872 - val_accuracy: 0.6476\n","Epoch 53/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7091 - accuracy: 0.7050 - val_loss: 0.7896 - val_accuracy: 0.6422\n","Epoch 54/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7033 - accuracy: 0.7099 - val_loss: 0.7839 - val_accuracy: 0.6455\n","Epoch 55/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7101 - accuracy: 0.7047 - val_loss: 0.8003 - val_accuracy: 0.6315\n","Epoch 56/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7053 - accuracy: 0.7128 - val_loss: 0.7887 - val_accuracy: 0.6476\n","Epoch 57/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6961 - accuracy: 0.7185 - val_loss: 0.7986 - val_accuracy: 0.6444\n","Epoch 58/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.7004 - accuracy: 0.7147 - val_loss: 0.8090 - val_accuracy: 0.6282\n","Epoch 59/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6961 - accuracy: 0.7193 - val_loss: 0.7910 - val_accuracy: 0.6487\n","Epoch 60/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6908 - accuracy: 0.7204 - val_loss: 0.7920 - val_accuracy: 0.6476\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6943 - accuracy: 0.7217 - val_loss: 0.7945 - val_accuracy: 0.6519\n","Epoch 62/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6887 - accuracy: 0.7217 - val_loss: 0.7873 - val_accuracy: 0.6519\n","Epoch 63/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.7158 - val_loss: 0.8206 - val_accuracy: 0.6175\n","Epoch 64/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6965 - accuracy: 0.7134 - val_loss: 0.7897 - val_accuracy: 0.6509\n","Epoch 65/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6951 - accuracy: 0.7193 - val_loss: 0.8139 - val_accuracy: 0.6153\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6840 - accuracy: 0.7336 - val_loss: 0.8221 - val_accuracy: 0.6164\n","Epoch 67/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6876 - accuracy: 0.7252 - val_loss: 0.8300 - val_accuracy: 0.6110\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6945 - accuracy: 0.7182 - val_loss: 0.7985 - val_accuracy: 0.6412\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6859 - accuracy: 0.7282 - val_loss: 0.7900 - val_accuracy: 0.6509\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6868 - accuracy: 0.7239 - val_loss: 0.7990 - val_accuracy: 0.6422\n","Epoch 71/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6874 - accuracy: 0.7198 - val_loss: 0.8075 - val_accuracy: 0.6272\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6761 - accuracy: 0.7344 - val_loss: 0.7998 - val_accuracy: 0.6412\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6804 - accuracy: 0.7263 - val_loss: 0.8549 - val_accuracy: 0.6013\n","Epoch 74/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6824 - accuracy: 0.7239 - val_loss: 0.7919 - val_accuracy: 0.6519\n","Epoch 75/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6781 - accuracy: 0.7317 - val_loss: 0.7912 - val_accuracy: 0.6509\n","Epoch 76/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6737 - accuracy: 0.7379 - val_loss: 0.8120 - val_accuracy: 0.6293\n","Epoch 77/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6901 - accuracy: 0.7212 - val_loss: 0.8107 - val_accuracy: 0.6304\n","Epoch 78/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6936 - accuracy: 0.7126 - val_loss: 0.8222 - val_accuracy: 0.6239\n","Epoch 79/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6696 - accuracy: 0.7425 - val_loss: 0.7928 - val_accuracy: 0.6519\n","Epoch 80/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6780 - accuracy: 0.7314 - val_loss: 0.8085 - val_accuracy: 0.6369\n","Epoch 81/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6794 - accuracy: 0.7258 - val_loss: 0.8031 - val_accuracy: 0.6552\n","Epoch 82/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6721 - accuracy: 0.7365 - val_loss: 0.7957 - val_accuracy: 0.6530\n","Epoch 83/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6768 - accuracy: 0.7276 - val_loss: 0.7942 - val_accuracy: 0.6552\n","Epoch 84/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6645 - accuracy: 0.7414 - val_loss: 0.7907 - val_accuracy: 0.6476\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6673 - accuracy: 0.7462 - val_loss: 0.7913 - val_accuracy: 0.6487\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6625 - accuracy: 0.7443 - val_loss: 0.7956 - val_accuracy: 0.6530\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6641 - accuracy: 0.7381 - val_loss: 0.8111 - val_accuracy: 0.6293\n","Epoch 88/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6629 - accuracy: 0.7446 - val_loss: 0.8079 - val_accuracy: 0.6379\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6555 - accuracy: 0.7438 - val_loss: 0.8040 - val_accuracy: 0.6541\n","Epoch 90/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6617 - accuracy: 0.7403 - val_loss: 0.8097 - val_accuracy: 0.6401\n","Epoch 91/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6744 - accuracy: 0.7236 - val_loss: 0.7930 - val_accuracy: 0.6509\n","Epoch 92/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6503 - accuracy: 0.7519 - val_loss: 0.7909 - val_accuracy: 0.6509\n","Epoch 93/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6646 - accuracy: 0.7368 - val_loss: 0.7933 - val_accuracy: 0.6562\n","Epoch 94/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6474 - accuracy: 0.7551 - val_loss: 0.8102 - val_accuracy: 0.6390\n","Epoch 95/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6576 - accuracy: 0.7403 - val_loss: 0.7952 - val_accuracy: 0.6509\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6511 - accuracy: 0.7492 - val_loss: 0.7975 - val_accuracy: 0.6412\n","Epoch 97/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6458 - accuracy: 0.7470 - val_loss: 0.7952 - val_accuracy: 0.6401\n","Epoch 98/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6455 - accuracy: 0.7530 - val_loss: 0.7983 - val_accuracy: 0.6498\n","Epoch 99/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6448 - accuracy: 0.7554 - val_loss: 0.7997 - val_accuracy: 0.6422\n","Epoch 100/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6535 - accuracy: 0.7513 - val_loss: 0.8095 - val_accuracy: 0.6390\n","{'loss': [0.7773203253746033, 0.7725852727890015, 0.7654630541801453, 0.761168897151947, 0.7610989809036255, 0.758354663848877, 0.7589349150657654, 0.7572707533836365, 0.7529442310333252, 0.7560150623321533, 0.7594408988952637, 0.7553331851959229, 0.7530981302261353, 0.7646851539611816, 0.7506120204925537, 0.7469626069068909, 0.746724545955658, 0.748581051826477, 0.7443026900291443, 0.7420048117637634, 0.7379711270332336, 0.739600419998169, 0.7408173680305481, 0.7370482683181763, 0.7351551651954651, 0.7387568354606628, 0.7306585907936096, 0.7291356325149536, 0.7303066849708557, 0.729446530342102, 0.7333818078041077, 0.729371964931488, 0.72510826587677, 0.7351148128509521, 0.7368366718292236, 0.7275584936141968, 0.7183444499969482, 0.7197034955024719, 0.7207467555999756, 0.7139151096343994, 0.7135959267616272, 0.7145849466323853, 0.7108992338180542, 0.7133651971817017, 0.7253775000572205, 0.7095016241073608, 0.7125081419944763, 0.7085924744606018, 0.7066736817359924, 0.7143006324768066, 0.7052169442176819, 0.7196426391601562, 0.7090825438499451, 0.7032718658447266, 0.7100711464881897, 0.7052964568138123, 0.696143388748169, 0.7004330158233643, 0.6961123943328857, 0.6908290386199951, 0.6943397521972656, 0.6887208223342896, 0.6923306584358215, 0.6964737176895142, 0.6951112151145935, 0.6840394735336304, 0.687640368938446, 0.6944828629493713, 0.6859202980995178, 0.6867542266845703, 0.6873824000358582, 0.6761457920074463, 0.6803602576255798, 0.6824321150779724, 0.6780652403831482, 0.6737107038497925, 0.6900811791419983, 0.6936157941818237, 0.6695923209190369, 0.6780370473861694, 0.6794228553771973, 0.6720989346504211, 0.6768180131912231, 0.6644558310508728, 0.6673203706741333, 0.6624500155448914, 0.6641297340393066, 0.6629141569137573, 0.6554757356643677, 0.6616691946983337, 0.6744323372840881, 0.650336742401123, 0.6646314263343811, 0.6473770141601562, 0.6575794816017151, 0.651134729385376, 0.6457587480545044, 0.6455397009849548, 0.6448000073432922, 0.6535276770591736], 'accuracy': [0.6492456793785095, 0.6592133641242981, 0.6689116358757019, 0.670527994632721, 0.6713362336158752, 0.6726831793785095, 0.6778017282485962, 0.6772629022598267, 0.6794180870056152, 0.6742995977401733, 0.6613685488700867, 0.6710668206214905, 0.673491358757019, 0.6640625, 0.6745689511299133, 0.6869612336158752, 0.6848060488700867, 0.678340494632721, 0.6834590435028076, 0.6883081793785095, 0.693965494632721, 0.685883641242981, 0.6869612336158752, 0.6869612336158752, 0.6910021305084229, 0.6829202771186829, 0.6955819129943848, 0.6985452771186829, 0.688847005367279, 0.6931573152542114, 0.6926185488700867, 0.693965494632721, 0.6980064511299133, 0.6869612336158752, 0.6834590435028076, 0.6869612336158752, 0.7009698152542114, 0.703125, 0.701508641242981, 0.701508641242981, 0.7055495977401733, 0.7120150923728943, 0.7090517282485962, 0.7060883641242981, 0.6947737336158752, 0.7130926847457886, 0.704472005367279, 0.7098599076271057, 0.7133620977401733, 0.7079741358757019, 0.7139008641242981, 0.7042025923728943, 0.7050107717514038, 0.7098599076271057, 0.704741358757019, 0.7128232717514038, 0.7184805870056152, 0.7147090435028076, 0.7192887663841248, 0.720366358757019, 0.7217133641242981, 0.7217133641242981, 0.7157866358757019, 0.7133620977401733, 0.7192887663841248, 0.7335668206214905, 0.725215494632721, 0.7182112336158752, 0.728178858757019, 0.7238685488700867, 0.7198275923728943, 0.734375, 0.7262930870056152, 0.7238685488700867, 0.7316810488700867, 0.7378771305084229, 0.7211745977401733, 0.712553858757019, 0.7424569129943848, 0.7314116358757019, 0.7257543206214905, 0.7365301847457886, 0.7276400923728943, 0.7413793206214905, 0.7462284564971924, 0.7443426847457886, 0.7381465435028076, 0.7446120977401733, 0.743803858757019, 0.7403017282485962, 0.7235991358757019, 0.7518857717514038, 0.7367995977401733, 0.7551185488700867, 0.7403017282485962, 0.7491918206214905, 0.7470366358757019, 0.7529633641242981, 0.7553879022598267, 0.751347005367279], 'val_loss': [0.8466649055480957, 0.8464042544364929, 0.8467742204666138, 0.846274733543396, 0.8445755243301392, 0.8446712493896484, 0.844033420085907, 0.8459486961364746, 0.8493173122406006, 0.8537318110466003, 0.843375563621521, 0.8534266352653503, 0.8344478011131287, 0.8382201790809631, 0.8409548401832581, 0.8257841467857361, 0.8188541531562805, 0.8213487267494202, 0.8095879554748535, 0.7999930381774902, 0.7969484925270081, 0.79390949010849, 0.7957131862640381, 0.7897874116897583, 0.8020873069763184, 0.787881076335907, 0.7877779603004456, 0.7858922481536865, 0.7916510105133057, 0.7897272706031799, 0.8215501308441162, 0.7863216996192932, 0.7881423830986023, 0.8149932622909546, 0.8237966299057007, 0.7856805920600891, 0.793958842754364, 0.7895324230194092, 0.7992150783538818, 0.7867003679275513, 0.7883041501045227, 0.7850654125213623, 0.7947344183921814, 0.7937540411949158, 0.7977867126464844, 0.7853732109069824, 0.7909149527549744, 0.7850708365440369, 0.7913475036621094, 0.8088264465332031, 0.815151572227478, 0.7872269153594971, 0.7896479964256287, 0.783901035785675, 0.800264835357666, 0.7887384295463562, 0.7985536456108093, 0.8090279698371887, 0.7910068035125732, 0.791965663433075, 0.7944614291191101, 0.7873276472091675, 0.8206105828285217, 0.7897079586982727, 0.8138803243637085, 0.8221020698547363, 0.8299849033355713, 0.7984675765037537, 0.7899888157844543, 0.7990275621414185, 0.8075230121612549, 0.7998121976852417, 0.854943573474884, 0.7919101715087891, 0.7911981344223022, 0.8120338916778564, 0.8107003569602966, 0.8222365379333496, 0.7927975654602051, 0.8084803819656372, 0.8030639886856079, 0.7957163453102112, 0.7942036986351013, 0.7907290458679199, 0.7913457751274109, 0.7955663204193115, 0.81109619140625, 0.8079379796981812, 0.804007887840271, 0.8096999526023865, 0.7929689884185791, 0.7908527851104736, 0.7933420538902283, 0.8102073073387146, 0.7951602935791016, 0.7974862456321716, 0.7951596975326538, 0.7983158826828003, 0.7996762990951538, 0.8095362186431885], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.48706895112991333, 0.48599138855934143, 0.48706895112991333, 0.48599138855934143, 0.48491379618644714, 0.4892241358757019, 0.48706895112991333, 0.5204741358757019, 0.5129310488700867, 0.5118534564971924, 0.5538793206214905, 0.5905172228813171, 0.5646551847457886, 0.6012930870056152, 0.625, 0.6260775923728943, 0.6282327771186829, 0.6368534564971924, 0.6357758641242981, 0.6142241358757019, 0.6530172228813171, 0.6476293206214905, 0.6519396305084229, 0.6336206793785095, 0.6411637663841248, 0.6066810488700867, 0.6508620977401733, 0.6519396305084229, 0.6131465435028076, 0.6120689511299133, 0.6540948152542114, 0.6433189511299133, 0.642241358757019, 0.625, 0.6487069129943848, 0.6476293206214905, 0.6519396305084229, 0.6508620977401733, 0.6336206793785095, 0.6368534564971924, 0.6519396305084229, 0.6487069129943848, 0.6594827771186829, 0.649784505367279, 0.6239224076271057, 0.6217672228813171, 0.6476293206214905, 0.642241358757019, 0.6454741358757019, 0.631465494632721, 0.6476293206214905, 0.6443965435028076, 0.6282327771186829, 0.6487069129943848, 0.6476293206214905, 0.6519396305084229, 0.6519396305084229, 0.6174569129943848, 0.6508620977401733, 0.6153017282485962, 0.6163793206214905, 0.610991358757019, 0.6411637663841248, 0.6508620977401733, 0.642241358757019, 0.6271551847457886, 0.6411637663841248, 0.6012930870056152, 0.6519396305084229, 0.6508620977401733, 0.6293103694915771, 0.6303879022598267, 0.6239224076271057, 0.6519396305084229, 0.6368534564971924, 0.6551724076271057, 0.6530172228813171, 0.6551724076271057, 0.6476293206214905, 0.6487069129943848, 0.6530172228813171, 0.6293103694915771, 0.6379310488700867, 0.6540948152542114, 0.6400862336158752, 0.6508620977401733, 0.6508620977401733, 0.65625, 0.639008641242981, 0.6508620977401733, 0.6411637663841248, 0.6400862336158752, 0.649784505367279, 0.642241358757019, 0.639008641242981]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.7704 - accuracy: 0.6619"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 61ms/step - loss: 0.7727 - accuracy: 0.6619 - val_loss: 0.8461 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7660 - accuracy: 0.6647 - val_loss: 0.8450 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7655 - accuracy: 0.6692 - val_loss: 0.8460 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7645 - accuracy: 0.6655 - val_loss: 0.8456 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7674 - accuracy: 0.6619 - val_loss: 0.8454 - val_accuracy: 0.4943\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7578 - accuracy: 0.6740 - val_loss: 0.8448 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7619 - accuracy: 0.6644 - val_loss: 0.8444 - val_accuracy: 0.4921\n","Epoch 8/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.7601 - accuracy: 0.6681 - val_loss: 0.8434 - val_accuracy: 0.4966\n","Epoch 9/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7592 - accuracy: 0.6684 - val_loss: 0.8455 - val_accuracy: 0.4932\n","Epoch 10/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7495 - accuracy: 0.6831 - val_loss: 0.8490 - val_accuracy: 0.4932\n","Epoch 11/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.7495 - accuracy: 0.6868 - val_loss: 0.8444 - val_accuracy: 0.5000\n","Epoch 12/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.7530 - accuracy: 0.6740 - val_loss: 0.8392 - val_accuracy: 0.5124\n","Epoch 13/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7531 - accuracy: 0.6740 - val_loss: 0.8527 - val_accuracy: 0.4989\n","Epoch 14/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.7480 - accuracy: 0.6788 - val_loss: 0.8397 - val_accuracy: 0.5249\n","Epoch 15/100\n","28/28 [==============================] - 1s 37ms/step - loss: 0.7455 - accuracy: 0.6791 - val_loss: 0.8333 - val_accuracy: 0.5430\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7489 - accuracy: 0.6760 - val_loss: 0.8306 - val_accuracy: 0.5430\n","Epoch 17/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.7466 - accuracy: 0.6859 - val_loss: 0.8290 - val_accuracy: 0.5520\n","Epoch 18/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.7410 - accuracy: 0.6836 - val_loss: 0.8281 - val_accuracy: 0.5611\n","Epoch 19/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.7404 - accuracy: 0.6933 - val_loss: 0.8262 - val_accuracy: 0.5645\n","Epoch 20/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.7382 - accuracy: 0.6893 - val_loss: 0.8128 - val_accuracy: 0.6041\n","Epoch 21/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7440 - accuracy: 0.6848 - val_loss: 0.8107 - val_accuracy: 0.5973\n","Epoch 22/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7344 - accuracy: 0.6916 - val_loss: 0.8118 - val_accuracy: 0.5916\n","Epoch 23/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7360 - accuracy: 0.6870 - val_loss: 0.8090 - val_accuracy: 0.5905\n","Epoch 24/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.7332 - accuracy: 0.6919 - val_loss: 0.8033 - val_accuracy: 0.6097\n","Epoch 25/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.7371 - accuracy: 0.6935 - val_loss: 0.8043 - val_accuracy: 0.6143\n","Epoch 26/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7308 - accuracy: 0.6967 - val_loss: 0.8233 - val_accuracy: 0.6029\n","Epoch 27/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.7455 - accuracy: 0.6800 - val_loss: 0.7996 - val_accuracy: 0.6210\n","Epoch 28/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.7359 - accuracy: 0.6845 - val_loss: 0.7958 - val_accuracy: 0.6267\n","Epoch 29/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7343 - accuracy: 0.6904 - val_loss: 0.7975 - val_accuracy: 0.6222\n","Epoch 30/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7357 - accuracy: 0.6825 - val_loss: 0.8026 - val_accuracy: 0.6143\n","Epoch 31/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7328 - accuracy: 0.6853 - val_loss: 0.8002 - val_accuracy: 0.6267\n","Epoch 32/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.7300 - accuracy: 0.6876 - val_loss: 0.7967 - val_accuracy: 0.6324\n","Epoch 33/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7270 - accuracy: 0.6964 - val_loss: 0.7977 - val_accuracy: 0.6301\n","Epoch 34/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7263 - accuracy: 0.6992 - val_loss: 0.8015 - val_accuracy: 0.6176\n","Epoch 35/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.7198 - accuracy: 0.7083 - val_loss: 0.7961 - val_accuracy: 0.6357\n","Epoch 36/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7176 - accuracy: 0.7074 - val_loss: 0.8048 - val_accuracy: 0.6154\n","Epoch 37/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7220 - accuracy: 0.6964 - val_loss: 0.7983 - val_accuracy: 0.6301\n","Epoch 38/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7196 - accuracy: 0.7001 - val_loss: 0.8023 - val_accuracy: 0.6290\n","Epoch 39/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7142 - accuracy: 0.7114 - val_loss: 0.8013 - val_accuracy: 0.6267\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7114 - accuracy: 0.7102 - val_loss: 0.8234 - val_accuracy: 0.6007\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7131 - accuracy: 0.7105 - val_loss: 0.8178 - val_accuracy: 0.5950\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7185 - accuracy: 0.6958 - val_loss: 0.8057 - val_accuracy: 0.6176\n","Epoch 43/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7143 - accuracy: 0.7074 - val_loss: 0.8028 - val_accuracy: 0.6244\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7077 - accuracy: 0.7187 - val_loss: 0.8103 - val_accuracy: 0.6199\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7181 - accuracy: 0.7060 - val_loss: 0.8345 - val_accuracy: 0.6041\n","Epoch 46/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7093 - accuracy: 0.7134 - val_loss: 0.8068 - val_accuracy: 0.6210\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7108 - accuracy: 0.7088 - val_loss: 0.8132 - val_accuracy: 0.6143\n","Epoch 48/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7156 - accuracy: 0.7037 - val_loss: 0.8022 - val_accuracy: 0.6301\n","Epoch 49/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7057 - accuracy: 0.7100 - val_loss: 0.8087 - val_accuracy: 0.6063\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7059 - accuracy: 0.7080 - val_loss: 0.8076 - val_accuracy: 0.6199\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7125 - accuracy: 0.7066 - val_loss: 0.8025 - val_accuracy: 0.6278\n","Epoch 52/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7013 - accuracy: 0.7119 - val_loss: 0.8042 - val_accuracy: 0.6233\n","Epoch 53/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6992 - accuracy: 0.7216 - val_loss: 0.8049 - val_accuracy: 0.6312\n","Epoch 54/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7007 - accuracy: 0.7252 - val_loss: 0.8205 - val_accuracy: 0.6063\n","Epoch 55/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7030 - accuracy: 0.7136 - val_loss: 0.8106 - val_accuracy: 0.6165\n","Epoch 56/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7007 - accuracy: 0.7122 - val_loss: 0.8071 - val_accuracy: 0.6176\n","Epoch 57/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7121 - accuracy: 0.6978 - val_loss: 0.8089 - val_accuracy: 0.6278\n","Epoch 58/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7035 - accuracy: 0.7145 - val_loss: 0.8063 - val_accuracy: 0.6222\n","Epoch 59/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6957 - accuracy: 0.7182 - val_loss: 0.8047 - val_accuracy: 0.6222\n","Epoch 60/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6884 - accuracy: 0.7312 - val_loss: 0.8059 - val_accuracy: 0.6312\n","Epoch 61/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6895 - accuracy: 0.7264 - val_loss: 0.8080 - val_accuracy: 0.6143\n","Epoch 62/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6937 - accuracy: 0.7233 - val_loss: 0.8069 - val_accuracy: 0.6256\n","Epoch 63/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6970 - accuracy: 0.7145 - val_loss: 0.8214 - val_accuracy: 0.6154\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6929 - accuracy: 0.7196 - val_loss: 0.8085 - val_accuracy: 0.6210\n","Epoch 65/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6827 - accuracy: 0.7317 - val_loss: 0.8118 - val_accuracy: 0.6244\n","Epoch 66/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6860 - accuracy: 0.7275 - val_loss: 0.8064 - val_accuracy: 0.6199\n","Epoch 67/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6820 - accuracy: 0.7267 - val_loss: 0.8124 - val_accuracy: 0.6097\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6827 - accuracy: 0.7312 - val_loss: 0.8439 - val_accuracy: 0.6018\n","Epoch 69/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6911 - accuracy: 0.7168 - val_loss: 0.8139 - val_accuracy: 0.6233\n","Epoch 70/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6770 - accuracy: 0.7400 - val_loss: 0.8130 - val_accuracy: 0.6176\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6825 - accuracy: 0.7267 - val_loss: 0.8193 - val_accuracy: 0.6143\n","Epoch 72/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6836 - accuracy: 0.7278 - val_loss: 0.8112 - val_accuracy: 0.6188\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6747 - accuracy: 0.7371 - val_loss: 0.8427 - val_accuracy: 0.6097\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6780 - accuracy: 0.7309 - val_loss: 0.8186 - val_accuracy: 0.6154\n","Epoch 75/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6695 - accuracy: 0.7448 - val_loss: 0.8443 - val_accuracy: 0.6109\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6854 - accuracy: 0.7233 - val_loss: 0.8669 - val_accuracy: 0.6007\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6765 - accuracy: 0.7320 - val_loss: 0.8144 - val_accuracy: 0.6267\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6712 - accuracy: 0.7368 - val_loss: 0.8366 - val_accuracy: 0.6143\n","Epoch 79/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6664 - accuracy: 0.7411 - val_loss: 0.8162 - val_accuracy: 0.6244\n","Epoch 80/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6661 - accuracy: 0.7436 - val_loss: 0.8227 - val_accuracy: 0.6131\n","Epoch 81/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6707 - accuracy: 0.7303 - val_loss: 0.8198 - val_accuracy: 0.6188\n","Epoch 82/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6733 - accuracy: 0.7360 - val_loss: 0.8263 - val_accuracy: 0.6097\n","Epoch 83/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6724 - accuracy: 0.7329 - val_loss: 0.8109 - val_accuracy: 0.6154\n","Epoch 84/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6662 - accuracy: 0.7371 - val_loss: 0.8135 - val_accuracy: 0.6176\n","Epoch 85/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6605 - accuracy: 0.7459 - val_loss: 0.8188 - val_accuracy: 0.6131\n","Epoch 86/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6595 - accuracy: 0.7462 - val_loss: 0.8207 - val_accuracy: 0.6120\n","Epoch 87/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6584 - accuracy: 0.7479 - val_loss: 0.8202 - val_accuracy: 0.6131\n","Epoch 88/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6541 - accuracy: 0.7465 - val_loss: 0.8245 - val_accuracy: 0.6222\n","Epoch 89/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6511 - accuracy: 0.7521 - val_loss: 0.8204 - val_accuracy: 0.6256\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6530 - accuracy: 0.7467 - val_loss: 0.8204 - val_accuracy: 0.6165\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6607 - accuracy: 0.7482 - val_loss: 0.8455 - val_accuracy: 0.6131\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6540 - accuracy: 0.7555 - val_loss: 0.8234 - val_accuracy: 0.6188\n","Epoch 93/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6567 - accuracy: 0.7538 - val_loss: 0.8388 - val_accuracy: 0.6188\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6526 - accuracy: 0.7476 - val_loss: 0.8201 - val_accuracy: 0.6210\n","Epoch 95/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6507 - accuracy: 0.7535 - val_loss: 0.8251 - val_accuracy: 0.6097\n","Epoch 96/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6489 - accuracy: 0.7479 - val_loss: 0.8548 - val_accuracy: 0.6120\n","Epoch 97/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6540 - accuracy: 0.7507 - val_loss: 0.8435 - val_accuracy: 0.6097\n","Epoch 98/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6429 - accuracy: 0.7606 - val_loss: 0.8235 - val_accuracy: 0.6075\n","Epoch 99/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6385 - accuracy: 0.7646 - val_loss: 0.8332 - val_accuracy: 0.6188\n","Epoch 100/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6433 - accuracy: 0.7555 - val_loss: 0.8299 - val_accuracy: 0.6052\n","{'loss': [0.7726647853851318, 0.7660187482833862, 0.7654724717140198, 0.7645250558853149, 0.7674376368522644, 0.7577946186065674, 0.7619463801383972, 0.760063886642456, 0.7592110633850098, 0.7494776844978333, 0.7494649887084961, 0.7529991865158081, 0.7530875205993652, 0.7480402588844299, 0.7455033659934998, 0.7488806843757629, 0.746644914150238, 0.7409566640853882, 0.7404204607009888, 0.7382174134254456, 0.7440028786659241, 0.7344352006912231, 0.736017107963562, 0.7331698536872864, 0.7370606064796448, 0.7308422327041626, 0.7455410361289978, 0.7359493970870972, 0.7343145608901978, 0.7356935739517212, 0.7327532768249512, 0.7300100922584534, 0.727017879486084, 0.7262830138206482, 0.719811737537384, 0.7175678610801697, 0.7219837307929993, 0.7195780277252197, 0.7142424583435059, 0.7113553881645203, 0.7131009697914124, 0.718483567237854, 0.7142760753631592, 0.7077125310897827, 0.7180790901184082, 0.7092703580856323, 0.7108059525489807, 0.7156057953834534, 0.7056552767753601, 0.7059029340744019, 0.712459146976471, 0.7012590765953064, 0.6992456912994385, 0.7007293105125427, 0.7029938697814941, 0.7007319331169128, 0.7121155261993408, 0.7035136818885803, 0.69569993019104, 0.6883693337440491, 0.6894679665565491, 0.6937000751495361, 0.6970161199569702, 0.6929466724395752, 0.6827198266983032, 0.6860201358795166, 0.681986927986145, 0.6827065944671631, 0.6910983920097351, 0.6769707202911377, 0.6825467348098755, 0.683584988117218, 0.674691379070282, 0.6779640913009644, 0.6695330739021301, 0.6853756308555603, 0.6764536499977112, 0.6712143421173096, 0.6663858890533447, 0.6660573482513428, 0.6706805229187012, 0.6733450889587402, 0.6724380850791931, 0.6661953926086426, 0.6604778170585632, 0.6594663858413696, 0.6584303379058838, 0.6541284918785095, 0.6511383056640625, 0.6529926657676697, 0.6606863141059875, 0.6540489792823792, 0.6567155122756958, 0.6525749564170837, 0.6506768465042114, 0.6488897204399109, 0.654013454914093, 0.6428928971290588, 0.6385098695755005, 0.6433284282684326], 'accuracy': [0.6618562340736389, 0.6646859049797058, 0.6692133545875549, 0.6655347943305969, 0.6618562340736389, 0.6740237474441528, 0.664402961730957, 0.668081521987915, 0.6683644652366638, 0.6830786466598511, 0.6867572069168091, 0.6740237474441528, 0.6740237474441528, 0.6788341999053955, 0.6791171431541443, 0.6760045289993286, 0.685908317565918, 0.6836445927619934, 0.693265438079834, 0.6893039345741272, 0.6847764849662781, 0.691567599773407, 0.6870402097702026, 0.6918506026268005, 0.6935483813285828, 0.6966609954833984, 0.6799660325050354, 0.6844934821128845, 0.6904357671737671, 0.6825127601623535, 0.6853423714637756, 0.6876060962677002, 0.6963780522346497, 0.6992077231407166, 0.70826256275177, 0.7074136734008789, 0.6963780522346497, 0.7000566124916077, 0.7113752365112305, 0.7102433443069458, 0.7105262875556946, 0.6958121061325073, 0.7074136734008789, 0.7187322974205017, 0.7059988975524902, 0.7133559584617615, 0.7088285088539124, 0.7037351727485657, 0.709960401058197, 0.7079796195030212, 0.7065647840499878, 0.711941123008728, 0.7215619683265686, 0.7252405285835266, 0.713638961315155, 0.7122241258621216, 0.6977928876876831, 0.7144878506660461, 0.7181664109230042, 0.7311828136444092, 0.7263723611831665, 0.7232597470283508, 0.7144878506660461, 0.7195811867713928, 0.7317487001419067, 0.7275042533874512, 0.7266553640365601, 0.7311828136444092, 0.7167515754699707, 0.7399547100067139, 0.7266553640365601, 0.7277871966362, 0.7371250987052917, 0.7308998107910156, 0.7447651624679565, 0.7232597470283508, 0.7320317029953003, 0.7368420958518982, 0.7410866022109985, 0.7436332702636719, 0.7303339242935181, 0.7359932065010071, 0.7328805923461914, 0.7371250987052917, 0.7458969950675964, 0.7461799383163452, 0.7478777766227722, 0.7464629411697388, 0.7521222233772278, 0.7467458844184875, 0.748160719871521, 0.755517840385437, 0.7538200616836548, 0.7475947737693787, 0.7535370588302612, 0.7478777766227722, 0.7507073879241943, 0.7606111764907837, 0.7645727396011353, 0.755517840385437], 'val_loss': [0.8460754752159119, 0.8450173735618591, 0.8459630012512207, 0.8456409573554993, 0.8454084992408752, 0.8448038697242737, 0.8444275259971619, 0.8433834910392761, 0.8455258011817932, 0.8489705324172974, 0.844352662563324, 0.8391867280006409, 0.8527417182922363, 0.8397024869918823, 0.8333473205566406, 0.8306146860122681, 0.8290408849716187, 0.8280654549598694, 0.8262321352958679, 0.8127962946891785, 0.8107336163520813, 0.8117862343788147, 0.8090351223945618, 0.8032633662223816, 0.8042994737625122, 0.8232877850532532, 0.799564778804779, 0.7958236336708069, 0.797498881816864, 0.8026306629180908, 0.8002249598503113, 0.7966628670692444, 0.7977016568183899, 0.8015449047088623, 0.7961102724075317, 0.8048201203346252, 0.7982686758041382, 0.8023006319999695, 0.801302969455719, 0.8233922719955444, 0.8178396821022034, 0.8056630492210388, 0.802844226360321, 0.8103104829788208, 0.8345440030097961, 0.8067650198936462, 0.8131787776947021, 0.802190363407135, 0.8086875081062317, 0.8075785636901855, 0.8025487661361694, 0.8041871190071106, 0.8048689365386963, 0.8205475211143494, 0.8106262683868408, 0.8070613145828247, 0.808900773525238, 0.8062729835510254, 0.8046569228172302, 0.8058938980102539, 0.8080022931098938, 0.8069427013397217, 0.821439802646637, 0.80852210521698, 0.811767041683197, 0.8064374923706055, 0.8124277591705322, 0.8438710570335388, 0.8138798475265503, 0.8129692077636719, 0.8193151354789734, 0.8112325072288513, 0.8426565527915955, 0.818627119064331, 0.8442712426185608, 0.8668503165245056, 0.8143813014030457, 0.8365930318832397, 0.8162106871604919, 0.8227331042289734, 0.8198089003562927, 0.8263272047042847, 0.8109210729598999, 0.8134834170341492, 0.8187873959541321, 0.8206933736801147, 0.8202264308929443, 0.8244872689247131, 0.8204293251037598, 0.8203809261322021, 0.8455296158790588, 0.8233986496925354, 0.8388428092002869, 0.8201417326927185, 0.8250640630722046, 0.8548046350479126, 0.8435020446777344, 0.8234752416610718, 0.8332338929176331, 0.8298839926719666], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4943438768386841, 0.4954751133918762, 0.4920814335346222, 0.49660632014274597, 0.49321267008781433, 0.49321267008781433, 0.5, 0.5124434232711792, 0.49886876344680786, 0.5248869061470032, 0.5429864525794983, 0.5429864525794983, 0.5520362257957458, 0.5610859990119934, 0.564479649066925, 0.6040723919868469, 0.5972850918769836, 0.5916289687156677, 0.5904977321624756, 0.6097285151481628, 0.6142534017562866, 0.6029411554336548, 0.6210407018661499, 0.6266968250274658, 0.622171938419342, 0.6142534017562866, 0.6266968250274658, 0.6323529481887817, 0.6300904750823975, 0.6176470518112183, 0.6357465982437134, 0.6153846383094788, 0.6300904750823975, 0.6289592981338501, 0.6266968250274658, 0.6006787419319153, 0.5950226187705994, 0.6176470518112183, 0.6244344115257263, 0.6199095249176025, 0.6040723919868469, 0.6210407018661499, 0.6142534017562866, 0.6300904750823975, 0.6063348650932312, 0.6199095249176025, 0.627828061580658, 0.6233031749725342, 0.6312217116355896, 0.6063348650932312, 0.6165158152580261, 0.6176470518112183, 0.627828061580658, 0.622171938419342, 0.622171938419342, 0.6312217116355896, 0.6142534017562866, 0.6255655884742737, 0.6153846383094788, 0.6210407018661499, 0.6244344115257263, 0.6199095249176025, 0.6097285151481628, 0.6018099784851074, 0.6233031749725342, 0.6176470518112183, 0.6142534017562866, 0.6187782883644104, 0.6097285151481628, 0.6153846383094788, 0.610859751701355, 0.6006787419319153, 0.6266968250274658, 0.6142534017562866, 0.6244344115257263, 0.6131221652030945, 0.6187782883644104, 0.6097285151481628, 0.6153846383094788, 0.6176470518112183, 0.6131221652030945, 0.6119909286499023, 0.6131221652030945, 0.622171938419342, 0.6255655884742737, 0.6165158152580261, 0.6131221652030945, 0.6187782883644104, 0.6187782883644104, 0.6210407018661499, 0.6097285151481628, 0.6119909286499023, 0.6097285151481628, 0.6074660420417786, 0.6187782883644104, 0.6052036285400391]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.7824 - accuracy: 0.6466"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 57ms/step - loss: 0.7824 - accuracy: 0.6468 - val_loss: 0.8467 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7864 - accuracy: 0.6354 - val_loss: 0.8473 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7738 - accuracy: 0.6556 - val_loss: 0.8481 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7697 - accuracy: 0.6602 - val_loss: 0.8481 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7690 - accuracy: 0.6599 - val_loss: 0.8513 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7728 - accuracy: 0.6506 - val_loss: 0.8510 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7619 - accuracy: 0.6682 - val_loss: 0.8535 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7636 - accuracy: 0.6592 - val_loss: 0.8541 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7694 - accuracy: 0.6589 - val_loss: 0.8619 - val_accuracy: 0.4855\n","Epoch 10/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7611 - accuracy: 0.6574 - val_loss: 0.8570 - val_accuracy: 0.4855\n","Epoch 11/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.7699 - accuracy: 0.6460 - val_loss: 0.8596 - val_accuracy: 0.4866\n","Epoch 12/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7610 - accuracy: 0.6656 - val_loss: 0.8711 - val_accuracy: 0.4866\n","Epoch 13/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7587 - accuracy: 0.6664 - val_loss: 0.8615 - val_accuracy: 0.4897\n","Epoch 14/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7512 - accuracy: 0.6814 - val_loss: 0.8459 - val_accuracy: 0.5103\n","Epoch 15/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7606 - accuracy: 0.6599 - val_loss: 0.8499 - val_accuracy: 0.5093\n","Epoch 16/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7540 - accuracy: 0.6721 - val_loss: 0.8483 - val_accuracy: 0.5196\n","Epoch 17/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7502 - accuracy: 0.6752 - val_loss: 0.8248 - val_accuracy: 0.5754\n","Epoch 18/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.7555 - accuracy: 0.6638 - val_loss: 0.8158 - val_accuracy: 0.5826\n","Epoch 19/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7619 - accuracy: 0.6618 - val_loss: 0.8158 - val_accuracy: 0.6023\n","Epoch 20/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7491 - accuracy: 0.6783 - val_loss: 0.8172 - val_accuracy: 0.5961\n","Epoch 21/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7508 - accuracy: 0.6731 - val_loss: 0.8139 - val_accuracy: 0.5837\n","Epoch 22/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.7574 - accuracy: 0.6685 - val_loss: 0.8219 - val_accuracy: 0.6054\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7474 - accuracy: 0.6734 - val_loss: 0.8141 - val_accuracy: 0.5899\n","Epoch 24/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7430 - accuracy: 0.6739 - val_loss: 0.8104 - val_accuracy: 0.6043\n","Epoch 25/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7489 - accuracy: 0.6687 - val_loss: 0.8321 - val_accuracy: 0.6023\n","Epoch 26/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.7451 - accuracy: 0.6708 - val_loss: 0.8121 - val_accuracy: 0.6095\n","Epoch 27/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7399 - accuracy: 0.6811 - val_loss: 0.8094 - val_accuracy: 0.6074\n","Epoch 28/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.7374 - accuracy: 0.6891 - val_loss: 0.8122 - val_accuracy: 0.6147\n","Epoch 29/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.7405 - accuracy: 0.6708 - val_loss: 0.8123 - val_accuracy: 0.6105\n","Epoch 30/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7438 - accuracy: 0.6747 - val_loss: 0.8284 - val_accuracy: 0.6074\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7347 - accuracy: 0.6824 - val_loss: 0.8156 - val_accuracy: 0.6064\n","Epoch 32/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7327 - accuracy: 0.6848 - val_loss: 0.8163 - val_accuracy: 0.6043\n","Epoch 33/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.7338 - accuracy: 0.6855 - val_loss: 0.8221 - val_accuracy: 0.6198\n","Epoch 34/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7287 - accuracy: 0.6922 - val_loss: 0.8178 - val_accuracy: 0.6105\n","Epoch 35/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7361 - accuracy: 0.6835 - val_loss: 0.8162 - val_accuracy: 0.6126\n","Epoch 36/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7308 - accuracy: 0.6904 - val_loss: 0.8245 - val_accuracy: 0.6095\n","Epoch 37/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7308 - accuracy: 0.6829 - val_loss: 0.8500 - val_accuracy: 0.6043\n","Epoch 38/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7314 - accuracy: 0.6848 - val_loss: 0.8168 - val_accuracy: 0.6116\n","Epoch 39/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7283 - accuracy: 0.6886 - val_loss: 0.8172 - val_accuracy: 0.6012\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7249 - accuracy: 0.6943 - val_loss: 0.8176 - val_accuracy: 0.6085\n","Epoch 41/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7249 - accuracy: 0.6943 - val_loss: 0.8358 - val_accuracy: 0.6085\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7289 - accuracy: 0.6840 - val_loss: 0.8177 - val_accuracy: 0.6085\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7166 - accuracy: 0.7013 - val_loss: 0.8296 - val_accuracy: 0.6002\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7192 - accuracy: 0.6964 - val_loss: 0.8446 - val_accuracy: 0.6023\n","Epoch 45/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7243 - accuracy: 0.6943 - val_loss: 0.8429 - val_accuracy: 0.6023\n","Epoch 46/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7190 - accuracy: 0.6943 - val_loss: 0.8540 - val_accuracy: 0.5971\n","Epoch 47/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7168 - accuracy: 0.7028 - val_loss: 0.8193 - val_accuracy: 0.6033\n","Epoch 48/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7176 - accuracy: 0.6972 - val_loss: 0.8196 - val_accuracy: 0.6085\n","Epoch 49/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7194 - accuracy: 0.7023 - val_loss: 0.8297 - val_accuracy: 0.6054\n","Epoch 50/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7125 - accuracy: 0.6995 - val_loss: 0.8211 - val_accuracy: 0.6167\n","Epoch 51/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.7169 - accuracy: 0.6969 - val_loss: 0.8306 - val_accuracy: 0.6116\n","Epoch 52/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7102 - accuracy: 0.6930 - val_loss: 0.8428 - val_accuracy: 0.6085\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7149 - accuracy: 0.7000 - val_loss: 0.8778 - val_accuracy: 0.5950\n","Epoch 54/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7151 - accuracy: 0.6959 - val_loss: 0.8220 - val_accuracy: 0.6074\n","Epoch 55/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7080 - accuracy: 0.7054 - val_loss: 0.8220 - val_accuracy: 0.6012\n","Epoch 56/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7004 - accuracy: 0.7127 - val_loss: 0.8249 - val_accuracy: 0.6074\n","Epoch 57/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7060 - accuracy: 0.7072 - val_loss: 0.8486 - val_accuracy: 0.5940\n","Epoch 58/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7078 - accuracy: 0.6992 - val_loss: 0.9113 - val_accuracy: 0.5868\n","Epoch 59/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7121 - accuracy: 0.6930 - val_loss: 0.8416 - val_accuracy: 0.6033\n","Epoch 60/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7122 - accuracy: 0.6964 - val_loss: 0.8438 - val_accuracy: 0.6023\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7042 - accuracy: 0.7075 - val_loss: 0.8231 - val_accuracy: 0.6043\n","Epoch 62/100\n","31/31 [==============================] - 1s 46ms/step - loss: 0.7020 - accuracy: 0.7057 - val_loss: 0.8252 - val_accuracy: 0.6260\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7096 - accuracy: 0.6977 - val_loss: 0.8519 - val_accuracy: 0.6023\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7002 - accuracy: 0.7119 - val_loss: 0.8282 - val_accuracy: 0.5930\n","Epoch 65/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7014 - accuracy: 0.7088 - val_loss: 0.8341 - val_accuracy: 0.5806\n","Epoch 66/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6953 - accuracy: 0.7155 - val_loss: 0.8392 - val_accuracy: 0.6012\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6891 - accuracy: 0.7191 - val_loss: 0.8326 - val_accuracy: 0.6198\n","Epoch 68/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6907 - accuracy: 0.7158 - val_loss: 0.8287 - val_accuracy: 0.6095\n","Epoch 69/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6952 - accuracy: 0.7147 - val_loss: 0.8419 - val_accuracy: 0.6043\n","Epoch 70/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6915 - accuracy: 0.7152 - val_loss: 0.8297 - val_accuracy: 0.6126\n","Epoch 71/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6908 - accuracy: 0.7152 - val_loss: 0.8355 - val_accuracy: 0.6002\n","Epoch 72/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6937 - accuracy: 0.7137 - val_loss: 0.8471 - val_accuracy: 0.6002\n","Epoch 73/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6908 - accuracy: 0.7165 - val_loss: 0.8400 - val_accuracy: 0.6157\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6922 - accuracy: 0.7163 - val_loss: 0.8321 - val_accuracy: 0.6054\n","Epoch 75/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6776 - accuracy: 0.7336 - val_loss: 0.8992 - val_accuracy: 0.5837\n","Epoch 76/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6816 - accuracy: 0.7220 - val_loss: 0.8364 - val_accuracy: 0.6147\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6913 - accuracy: 0.7171 - val_loss: 0.8308 - val_accuracy: 0.6002\n","Epoch 78/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6785 - accuracy: 0.7341 - val_loss: 0.8314 - val_accuracy: 0.6074\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6742 - accuracy: 0.7362 - val_loss: 0.8314 - val_accuracy: 0.6033\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6804 - accuracy: 0.7233 - val_loss: 0.9507 - val_accuracy: 0.5723\n","Epoch 81/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6863 - accuracy: 0.7222 - val_loss: 0.8563 - val_accuracy: 0.5981\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6856 - accuracy: 0.7189 - val_loss: 0.8756 - val_accuracy: 0.5971\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6695 - accuracy: 0.7382 - val_loss: 0.8573 - val_accuracy: 0.5971\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6882 - accuracy: 0.7062 - val_loss: 0.8605 - val_accuracy: 0.6023\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6714 - accuracy: 0.7344 - val_loss: 0.8357 - val_accuracy: 0.6147\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6729 - accuracy: 0.7271 - val_loss: 0.8526 - val_accuracy: 0.6105\n","Epoch 87/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6649 - accuracy: 0.7362 - val_loss: 0.8527 - val_accuracy: 0.6023\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6645 - accuracy: 0.7447 - val_loss: 0.9325 - val_accuracy: 0.5785\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6710 - accuracy: 0.7310 - val_loss: 0.8419 - val_accuracy: 0.6095\n","Epoch 90/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6579 - accuracy: 0.7401 - val_loss: 0.8752 - val_accuracy: 0.5919\n","Epoch 91/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6629 - accuracy: 0.7349 - val_loss: 0.8664 - val_accuracy: 0.5950\n","Epoch 92/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6605 - accuracy: 0.7413 - val_loss: 0.8651 - val_accuracy: 0.5940\n","Epoch 93/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6597 - accuracy: 0.7406 - val_loss: 0.8429 - val_accuracy: 0.6033\n","Epoch 94/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6656 - accuracy: 0.7323 - val_loss: 0.8885 - val_accuracy: 0.5899\n","Epoch 95/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6563 - accuracy: 0.7450 - val_loss: 0.8447 - val_accuracy: 0.6085\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6588 - accuracy: 0.7419 - val_loss: 0.8709 - val_accuracy: 0.6002\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6714 - accuracy: 0.7302 - val_loss: 0.9358 - val_accuracy: 0.5837\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6657 - accuracy: 0.7253 - val_loss: 0.8583 - val_accuracy: 0.5950\n","Epoch 99/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6541 - accuracy: 0.7488 - val_loss: 0.8654 - val_accuracy: 0.5919\n","Epoch 100/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6509 - accuracy: 0.7478 - val_loss: 0.8760 - val_accuracy: 0.5899\n","{'loss': [0.782390296459198, 0.7864251732826233, 0.7738354802131653, 0.7697399258613586, 0.7689759731292725, 0.7727600932121277, 0.7619414925575256, 0.7635980844497681, 0.7693995237350464, 0.7610621452331543, 0.7698565125465393, 0.7610295414924622, 0.7587011456489563, 0.7511893510818481, 0.7606388330459595, 0.7539739608764648, 0.75020831823349, 0.7555292844772339, 0.7618900537490845, 0.7490867376327515, 0.7507569789886475, 0.7574377059936523, 0.7473924160003662, 0.7430385947227478, 0.7488617300987244, 0.7450933456420898, 0.7398819923400879, 0.7374493479728699, 0.7405148148536682, 0.7438290119171143, 0.7347114682197571, 0.7327355742454529, 0.733814537525177, 0.7286875247955322, 0.7360534071922302, 0.7307838797569275, 0.7308141589164734, 0.7314082980155945, 0.7282620072364807, 0.7248811721801758, 0.7248930931091309, 0.7289170622825623, 0.7165819406509399, 0.7191781401634216, 0.7242960333824158, 0.7189944386482239, 0.7167962789535522, 0.7176482081413269, 0.7193882465362549, 0.712480366230011, 0.7168760895729065, 0.7102468609809875, 0.7148951888084412, 0.7151147127151489, 0.7080082297325134, 0.7003931403160095, 0.7059851288795471, 0.7078457474708557, 0.712070882320404, 0.7122262716293335, 0.7042101621627808, 0.702031672000885, 0.7095838785171509, 0.7002167105674744, 0.7013750672340393, 0.6953155994415283, 0.6890533566474915, 0.690740168094635, 0.695245623588562, 0.6915318369865417, 0.6908167004585266, 0.6936560273170471, 0.6907567977905273, 0.6921713352203369, 0.6775578856468201, 0.6816322803497314, 0.6912936568260193, 0.678484320640564, 0.6741999983787537, 0.6803845763206482, 0.6862565875053406, 0.6855931878089905, 0.6694556474685669, 0.6881967782974243, 0.6714195609092712, 0.6728839874267578, 0.6648731827735901, 0.6644870638847351, 0.6709926128387451, 0.6579328179359436, 0.662912130355835, 0.6605326533317566, 0.6597143411636353, 0.6656409502029419, 0.6563048362731934, 0.6587915420532227, 0.6713679432868958, 0.6656617522239685, 0.6540971994400024, 0.6508715152740479], 'accuracy': [0.6467700004577637, 0.6354005336761475, 0.6555555462837219, 0.6602067351341248, 0.6599483489990234, 0.6506459712982178, 0.6682170629501343, 0.6591731309890747, 0.6589147448539734, 0.6573643684387207, 0.6459948420524597, 0.6656330823898315, 0.6664082407951355, 0.6813953518867493, 0.6599483489990234, 0.6720930337905884, 0.6751937866210938, 0.6638242602348328, 0.6617571115493774, 0.6782945990562439, 0.6731266379356384, 0.6684754490852356, 0.6733850240707397, 0.6739017963409424, 0.6687338352203369, 0.670801043510437, 0.681136965751648, 0.6891472935676575, 0.670801043510437, 0.6746770143508911, 0.6824289560317993, 0.6847545504570007, 0.6855297088623047, 0.6922480463981628, 0.6834625601768494, 0.6904392838478088, 0.682945728302002, 0.6847545504570007, 0.6886304616928101, 0.6943152546882629, 0.6943152546882629, 0.683979332447052, 0.7012919783592224, 0.6963824033737183, 0.6943152546882629, 0.6943152546882629, 0.7028423547744751, 0.697157621383667, 0.7023255825042725, 0.6994832158088684, 0.6968992352485657, 0.6930232644081116, 0.699999988079071, 0.6958656311035156, 0.7054263353347778, 0.7126615047454834, 0.7072351574897766, 0.6992248296737671, 0.6930232644081116, 0.6963824033737183, 0.7074935436248779, 0.7056847810745239, 0.6976743936538696, 0.7118862867355347, 0.7087855339050293, 0.7155038714408875, 0.7191214561462402, 0.7157622575759888, 0.7147286534309387, 0.7152454853057861, 0.7152454853057861, 0.7136951088905334, 0.7165374755859375, 0.7162790894508362, 0.7335917353630066, 0.7219638228416443, 0.7170542478561401, 0.7341085076332092, 0.7361757159233093, 0.7232558131217957, 0.7222222089767456, 0.7188630700111389, 0.7382428646087646, 0.7062015533447266, 0.7343669533729553, 0.7271317839622498, 0.7361757159233093, 0.7447028160095215, 0.7310077548027039, 0.7400516867637634, 0.734883725643158, 0.7413436770439148, 0.7405684590339661, 0.7322997450828552, 0.7449612617492676, 0.7418604493141174, 0.7302325367927551, 0.7253230214118958, 0.7488372325897217, 0.7478036284446716], 'val_loss': [0.84671550989151, 0.8473241925239563, 0.8480979204177856, 0.8480690121650696, 0.8513240814208984, 0.8510151505470276, 0.8534592390060425, 0.854099690914154, 0.861890971660614, 0.8569705486297607, 0.8596294522285461, 0.8710546493530273, 0.8615304231643677, 0.8458796739578247, 0.8498932123184204, 0.8483029007911682, 0.8248244524002075, 0.8158464431762695, 0.8158401250839233, 0.8172265887260437, 0.8139464855194092, 0.8219053149223328, 0.8140610456466675, 0.8103537559509277, 0.8320935368537903, 0.8121198415756226, 0.8094249367713928, 0.8122224807739258, 0.8123428821563721, 0.8283725380897522, 0.8156226873397827, 0.8162776231765747, 0.8220841884613037, 0.8178466558456421, 0.8162397146224976, 0.824545681476593, 0.8499556183815002, 0.8168101906776428, 0.8171598315238953, 0.8176027536392212, 0.8358485698699951, 0.8177155256271362, 0.8295624852180481, 0.8446160554885864, 0.84287428855896, 0.8540464043617249, 0.8193196654319763, 0.8195836544036865, 0.8297101855278015, 0.8210960626602173, 0.8305504322052002, 0.8428311944007874, 0.8777945041656494, 0.8220195770263672, 0.8220464587211609, 0.8249461054801941, 0.8485686182975769, 0.9112874269485474, 0.8415734767913818, 0.8437689542770386, 0.823132336139679, 0.8251757621765137, 0.8518517017364502, 0.828217625617981, 0.8340650796890259, 0.8392184376716614, 0.8326493501663208, 0.8286536931991577, 0.841912031173706, 0.8296692967414856, 0.8354661464691162, 0.8471470475196838, 0.8400133848190308, 0.8320927619934082, 0.8991607427597046, 0.8364415168762207, 0.8307920694351196, 0.8314201235771179, 0.8313604593276978, 0.950690507888794, 0.8562610745429993, 0.8756258487701416, 0.8573333621025085, 0.8605260848999023, 0.8357306718826294, 0.8526269793510437, 0.8526772260665894, 0.932525634765625, 0.8418805599212646, 0.8751717209815979, 0.8664352893829346, 0.8651122450828552, 0.8429185748100281, 0.8885374665260315, 0.8447265625, 0.8708800673484802, 0.9357720613479614, 0.8582671880722046, 0.865354597568512, 0.8759567737579346], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.48657023906707764, 0.48966941237449646, 0.5103305578231812, 0.5092975497245789, 0.51962810754776, 0.5754132270812988, 0.5826446413993835, 0.6022727489471436, 0.5960744023323059, 0.5836777091026306, 0.60537189245224, 0.5898760557174683, 0.6043388247489929, 0.6022727489471436, 0.6095041036605835, 0.6074380278587341, 0.6146694421768188, 0.6105371713638306, 0.6074380278587341, 0.6064049601554871, 0.6043388247489929, 0.6198347210884094, 0.6105371713638306, 0.6126033067703247, 0.6095041036605835, 0.6043388247489929, 0.6115702390670776, 0.6012396812438965, 0.6084710955619812, 0.6084710955619812, 0.6084710955619812, 0.6002066135406494, 0.6022727489471436, 0.6022727489471436, 0.5971074104309082, 0.6033057570457458, 0.6084710955619812, 0.60537189245224, 0.6167355179786682, 0.6115702390670776, 0.6084710955619812, 0.5950413346290588, 0.6074380278587341, 0.6012396812438965, 0.6074380278587341, 0.5940082669258118, 0.586776852607727, 0.6033057570457458, 0.6022727489471436, 0.6043388247489929, 0.6260330677032471, 0.6022727489471436, 0.5929751992225647, 0.5805785059928894, 0.6012396812438965, 0.6198347210884094, 0.6095041036605835, 0.6043388247489929, 0.6126033067703247, 0.6002066135406494, 0.6002066135406494, 0.6157024502754211, 0.60537189245224, 0.5836777091026306, 0.6146694421768188, 0.6002066135406494, 0.6074380278587341, 0.6033057570457458, 0.5723140239715576, 0.5981404781341553, 0.5971074104309082, 0.5971074104309082, 0.6022727489471436, 0.6146694421768188, 0.6105371713638306, 0.6022727489471436, 0.5785123705863953, 0.6095041036605835, 0.5919421315193176, 0.5950413346290588, 0.5940082669258118, 0.6033057570457458, 0.5898760557174683, 0.6084710955619812, 0.6002066135406494, 0.5836777091026306, 0.5950413346290588, 0.5919421315193176, 0.5898760557174683]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.7088 - accuracy: 0.6984"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 57ms/step - loss: 0.7044 - accuracy: 0.7015 - val_loss: 0.8329 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6871 - accuracy: 0.7198 - val_loss: 0.8339 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6879 - accuracy: 0.7182 - val_loss: 0.8339 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6759 - accuracy: 0.7284 - val_loss: 0.8379 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6746 - accuracy: 0.7325 - val_loss: 0.8462 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6750 - accuracy: 0.7301 - val_loss: 0.8476 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6770 - accuracy: 0.7236 - val_loss: 0.8507 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6752 - accuracy: 0.7274 - val_loss: 0.8650 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6689 - accuracy: 0.7376 - val_loss: 0.8760 - val_accuracy: 0.4849\n","Epoch 10/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6843 - accuracy: 0.7182 - val_loss: 0.9039 - val_accuracy: 0.4849\n","Epoch 11/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.7014 - accuracy: 0.7047 - val_loss: 0.8595 - val_accuracy: 0.4881\n","Epoch 12/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6693 - accuracy: 0.7330 - val_loss: 0.8703 - val_accuracy: 0.4903\n","Epoch 13/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6666 - accuracy: 0.7411 - val_loss: 0.8972 - val_accuracy: 0.4892\n","Epoch 14/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6625 - accuracy: 0.7400 - val_loss: 0.8865 - val_accuracy: 0.4881\n","Epoch 15/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.6649 - accuracy: 0.7452 - val_loss: 0.8870 - val_accuracy: 0.4935\n","Epoch 16/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.6666 - accuracy: 0.7390 - val_loss: 0.8442 - val_accuracy: 0.5248\n","Epoch 17/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6540 - accuracy: 0.7495 - val_loss: 0.8680 - val_accuracy: 0.5216\n","Epoch 18/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.6558 - accuracy: 0.7452 - val_loss: 0.8837 - val_accuracy: 0.5312\n","Epoch 19/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6538 - accuracy: 0.7430 - val_loss: 0.7927 - val_accuracy: 0.6024\n","Epoch 20/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6563 - accuracy: 0.7403 - val_loss: 0.8132 - val_accuracy: 0.5894\n","Epoch 21/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6647 - accuracy: 0.7392 - val_loss: 0.7908 - val_accuracy: 0.6131\n","Epoch 22/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.6535 - accuracy: 0.7411 - val_loss: 0.7671 - val_accuracy: 0.6379\n","Epoch 23/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6597 - accuracy: 0.7452 - val_loss: 0.7642 - val_accuracy: 0.6519\n","Epoch 24/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6519 - accuracy: 0.7398 - val_loss: 0.7579 - val_accuracy: 0.6530\n","Epoch 25/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6493 - accuracy: 0.7470 - val_loss: 0.7631 - val_accuracy: 0.6433\n","Epoch 26/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6459 - accuracy: 0.7527 - val_loss: 0.7637 - val_accuracy: 0.6509\n","Epoch 27/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.6485 - accuracy: 0.7497 - val_loss: 0.7517 - val_accuracy: 0.6778\n","Epoch 28/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6383 - accuracy: 0.7602 - val_loss: 0.7607 - val_accuracy: 0.6606\n","Epoch 29/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6584 - accuracy: 0.7403 - val_loss: 0.7681 - val_accuracy: 0.6509\n","Epoch 30/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6418 - accuracy: 0.7516 - val_loss: 0.7612 - val_accuracy: 0.6681\n","Epoch 31/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6383 - accuracy: 0.7562 - val_loss: 0.7528 - val_accuracy: 0.6735\n","Epoch 32/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6338 - accuracy: 0.7570 - val_loss: 0.7557 - val_accuracy: 0.6789\n","Epoch 33/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6346 - accuracy: 0.7565 - val_loss: 0.7608 - val_accuracy: 0.6724\n","Epoch 34/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6262 - accuracy: 0.7667 - val_loss: 0.7574 - val_accuracy: 0.6778\n","Epoch 35/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6356 - accuracy: 0.7519 - val_loss: 0.7634 - val_accuracy: 0.6756\n","Epoch 36/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6474 - accuracy: 0.7489 - val_loss: 0.7611 - val_accuracy: 0.6735\n","Epoch 37/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6406 - accuracy: 0.7532 - val_loss: 0.7549 - val_accuracy: 0.6756\n","Epoch 38/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6302 - accuracy: 0.7584 - val_loss: 0.7611 - val_accuracy: 0.6724\n","Epoch 39/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6362 - accuracy: 0.7559 - val_loss: 0.7740 - val_accuracy: 0.6573\n","Epoch 40/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6345 - accuracy: 0.7532 - val_loss: 0.7769 - val_accuracy: 0.6584\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6283 - accuracy: 0.7654 - val_loss: 0.7606 - val_accuracy: 0.6735\n","Epoch 42/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6236 - accuracy: 0.7678 - val_loss: 0.7584 - val_accuracy: 0.6756\n","Epoch 43/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6235 - accuracy: 0.7686 - val_loss: 0.7664 - val_accuracy: 0.6767\n","Epoch 44/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6238 - accuracy: 0.7648 - val_loss: 0.7819 - val_accuracy: 0.6595\n","Epoch 45/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6248 - accuracy: 0.7640 - val_loss: 0.7589 - val_accuracy: 0.6810\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6251 - accuracy: 0.7597 - val_loss: 0.7653 - val_accuracy: 0.6800\n","Epoch 47/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6184 - accuracy: 0.7745 - val_loss: 0.8096 - val_accuracy: 0.6412\n","Epoch 48/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6183 - accuracy: 0.7678 - val_loss: 0.7626 - val_accuracy: 0.6713\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6247 - accuracy: 0.7659 - val_loss: 0.7741 - val_accuracy: 0.6616\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6357 - accuracy: 0.7497 - val_loss: 0.7778 - val_accuracy: 0.6616\n","Epoch 51/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6655 - accuracy: 0.7338 - val_loss: 0.7559 - val_accuracy: 0.6810\n","Epoch 52/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6149 - accuracy: 0.7761 - val_loss: 0.7568 - val_accuracy: 0.6756\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6076 - accuracy: 0.7753 - val_loss: 0.7696 - val_accuracy: 0.6595\n","Epoch 54/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6234 - accuracy: 0.7667 - val_loss: 0.7645 - val_accuracy: 0.6724\n","Epoch 55/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6072 - accuracy: 0.7726 - val_loss: 0.7823 - val_accuracy: 0.6562\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6004 - accuracy: 0.7786 - val_loss: 0.7668 - val_accuracy: 0.6713\n","Epoch 57/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6037 - accuracy: 0.7796 - val_loss: 0.7845 - val_accuracy: 0.6638\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6039 - accuracy: 0.7732 - val_loss: 0.7706 - val_accuracy: 0.6800\n","Epoch 59/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5932 - accuracy: 0.7883 - val_loss: 0.7773 - val_accuracy: 0.6778\n","Epoch 60/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6039 - accuracy: 0.7845 - val_loss: 0.7722 - val_accuracy: 0.6713\n","Epoch 61/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6114 - accuracy: 0.7721 - val_loss: 0.7706 - val_accuracy: 0.6756\n","Epoch 62/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6080 - accuracy: 0.7732 - val_loss: 0.7664 - val_accuracy: 0.6735\n","Epoch 63/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6001 - accuracy: 0.7810 - val_loss: 0.7742 - val_accuracy: 0.6789\n","Epoch 64/100\n","29/29 [==============================] - 1s 47ms/step - loss: 0.5968 - accuracy: 0.7802 - val_loss: 0.7650 - val_accuracy: 0.6972\n","Epoch 65/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5887 - accuracy: 0.7861 - val_loss: 0.7808 - val_accuracy: 0.6692\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6089 - accuracy: 0.7705 - val_loss: 0.7908 - val_accuracy: 0.6616\n","Epoch 67/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5984 - accuracy: 0.7767 - val_loss: 0.7681 - val_accuracy: 0.6789\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5885 - accuracy: 0.7823 - val_loss: 0.7713 - val_accuracy: 0.6713\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5854 - accuracy: 0.7874 - val_loss: 0.7748 - val_accuracy: 0.6810\n","Epoch 70/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5864 - accuracy: 0.7872 - val_loss: 0.7769 - val_accuracy: 0.6713\n","Epoch 71/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5874 - accuracy: 0.7877 - val_loss: 0.7789 - val_accuracy: 0.6800\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5940 - accuracy: 0.7880 - val_loss: 0.7746 - val_accuracy: 0.6767\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5971 - accuracy: 0.7775 - val_loss: 0.8270 - val_accuracy: 0.6390\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5801 - accuracy: 0.7934 - val_loss: 0.7760 - val_accuracy: 0.6767\n","Epoch 75/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5788 - accuracy: 0.7942 - val_loss: 0.7846 - val_accuracy: 0.6670\n","Epoch 76/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5785 - accuracy: 0.7893 - val_loss: 0.7842 - val_accuracy: 0.6735\n","Epoch 77/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5814 - accuracy: 0.7893 - val_loss: 0.7804 - val_accuracy: 0.6681\n","Epoch 78/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6063 - accuracy: 0.7718 - val_loss: 0.8514 - val_accuracy: 0.6282\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5875 - accuracy: 0.7866 - val_loss: 0.7797 - val_accuracy: 0.6800\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5943 - accuracy: 0.7872 - val_loss: 0.7893 - val_accuracy: 0.6616\n","Epoch 81/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5879 - accuracy: 0.7810 - val_loss: 0.8419 - val_accuracy: 0.6239\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5742 - accuracy: 0.7990 - val_loss: 0.7776 - val_accuracy: 0.6810\n","Epoch 83/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5667 - accuracy: 0.8015 - val_loss: 0.8264 - val_accuracy: 0.6422\n","Epoch 84/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5744 - accuracy: 0.7912 - val_loss: 0.8148 - val_accuracy: 0.6627\n","Epoch 85/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5795 - accuracy: 0.7899 - val_loss: 0.7997 - val_accuracy: 0.6476\n","Epoch 86/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5679 - accuracy: 0.8001 - val_loss: 0.7789 - val_accuracy: 0.6670\n","Epoch 87/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5652 - accuracy: 0.8033 - val_loss: 0.7917 - val_accuracy: 0.6659\n","Epoch 88/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5628 - accuracy: 0.8033 - val_loss: 0.8061 - val_accuracy: 0.6573\n","Epoch 89/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5593 - accuracy: 0.8044 - val_loss: 0.8256 - val_accuracy: 0.6369\n","Epoch 90/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5670 - accuracy: 0.7980 - val_loss: 0.7856 - val_accuracy: 0.6778\n","Epoch 91/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5586 - accuracy: 0.8117 - val_loss: 0.7890 - val_accuracy: 0.6810\n","Epoch 92/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5569 - accuracy: 0.8012 - val_loss: 0.8094 - val_accuracy: 0.6681\n","Epoch 93/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5784 - accuracy: 0.7907 - val_loss: 0.8269 - val_accuracy: 0.6466\n","Epoch 94/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5565 - accuracy: 0.8023 - val_loss: 0.8063 - val_accuracy: 0.6455\n","Epoch 95/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5529 - accuracy: 0.8074 - val_loss: 0.7970 - val_accuracy: 0.6821\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5613 - accuracy: 0.7990 - val_loss: 0.7928 - val_accuracy: 0.6789\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5495 - accuracy: 0.8120 - val_loss: 0.7950 - val_accuracy: 0.6843\n","Epoch 98/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5637 - accuracy: 0.8023 - val_loss: 0.8250 - val_accuracy: 0.6433\n","Epoch 99/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5494 - accuracy: 0.8095 - val_loss: 0.7901 - val_accuracy: 0.6746\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5446 - accuracy: 0.8165 - val_loss: 0.8175 - val_accuracy: 0.6606\n","{'loss': [0.7043535113334656, 0.68706214427948, 0.6878752112388611, 0.6758595705032349, 0.6745558977127075, 0.6750011444091797, 0.6769712567329407, 0.6752117276191711, 0.6689091324806213, 0.6842736601829529, 0.701412558555603, 0.6692886352539062, 0.6666081547737122, 0.6624679565429688, 0.664875864982605, 0.6666226983070374, 0.6540147066116333, 0.6558274626731873, 0.6538100242614746, 0.6563120484352112, 0.6647480130195618, 0.65352463722229, 0.6596676111221313, 0.6518863439559937, 0.6492725610733032, 0.6459411382675171, 0.6484916806221008, 0.6382899880409241, 0.6584118008613586, 0.6417899131774902, 0.6383408308029175, 0.633799135684967, 0.6345659494400024, 0.6262073516845703, 0.6356257200241089, 0.6474054455757141, 0.6405500173568726, 0.6302356719970703, 0.6361805200576782, 0.6345464587211609, 0.6283032894134521, 0.6236110925674438, 0.623506486415863, 0.623761773109436, 0.624785304069519, 0.625146746635437, 0.6183922290802002, 0.6183255314826965, 0.6247429847717285, 0.6357325911521912, 0.6654945015907288, 0.6148791313171387, 0.6075662970542908, 0.6233503818511963, 0.6071580648422241, 0.6003625392913818, 0.6036599278450012, 0.6039137840270996, 0.593245804309845, 0.6038926243782043, 0.6114238500595093, 0.6079604625701904, 0.6001123785972595, 0.596808910369873, 0.5886760950088501, 0.6088816523551941, 0.5983684659004211, 0.5884602665901184, 0.5853684544563293, 0.5863679647445679, 0.5874085426330566, 0.5939688682556152, 0.5970708131790161, 0.580053985118866, 0.5787519216537476, 0.5784869194030762, 0.5813505053520203, 0.6063379049301147, 0.5875204205513, 0.594277024269104, 0.5879236459732056, 0.5742398500442505, 0.5666820406913757, 0.5744197368621826, 0.5795217752456665, 0.5679026246070862, 0.565218985080719, 0.5628316402435303, 0.559338390827179, 0.5669946074485779, 0.5585944652557373, 0.5568620562553406, 0.5783903002738953, 0.5564503073692322, 0.5528762340545654, 0.5613202452659607, 0.5494729280471802, 0.5637175440788269, 0.5493620038032532, 0.5445610284805298], 'accuracy': [0.701508641242981, 0.7198275923728943, 0.7182112336158752, 0.7284482717514038, 0.7324892282485962, 0.7300646305084229, 0.7235991358757019, 0.7273706793785095, 0.7376077771186829, 0.7182112336158752, 0.704741358757019, 0.733027994632721, 0.7411099076271057, 0.7400323152542114, 0.7451508641242981, 0.7389547228813171, 0.7494612336158752, 0.7451508641242981, 0.7429956793785095, 0.7403017282485962, 0.7392241358757019, 0.7411099076271057, 0.7451508641242981, 0.7397629022598267, 0.7470366358757019, 0.7526939511299133, 0.7497305870056152, 0.7602370977401733, 0.7403017282485962, 0.751616358757019, 0.756196141242981, 0.7570043206214905, 0.756465494632721, 0.7667025923728943, 0.7518857717514038, 0.7489224076271057, 0.7532327771186829, 0.7583512663841248, 0.7559267282485962, 0.7532327771186829, 0.7653555870056152, 0.7677801847457886, 0.7685883641242981, 0.7648168206214905, 0.764008641242981, 0.7596982717514038, 0.7745150923728943, 0.7677801847457886, 0.7658944129943848, 0.7497305870056152, 0.7338362336158752, 0.7761314511299133, 0.7753232717514038, 0.7667025923728943, 0.7726293206214905, 0.7785560488700867, 0.779633641242981, 0.7731680870056152, 0.7882543206214905, 0.7844827771186829, 0.772090494632721, 0.7731680870056152, 0.7809805870056152, 0.7801724076271057, 0.7860991358757019, 0.7704741358757019, 0.7766702771186829, 0.7823275923728943, 0.787446141242981, 0.7871767282485962, 0.787715494632721, 0.7879849076271057, 0.7774784564971924, 0.7933728694915771, 0.7941810488700867, 0.7893319129943848, 0.7893319129943848, 0.771821141242981, 0.7866379022598267, 0.7871767282485962, 0.7809805870056152, 0.7990301847457886, 0.8014547228813171, 0.7912176847457886, 0.7898706793785095, 0.8001077771186829, 0.803340494632721, 0.803340494632721, 0.8044180870056152, 0.7979525923728943, 0.8116918206214905, 0.8011853694915771, 0.790678858757019, 0.8022629022598267, 0.8073814511299133, 0.7990301847457886, 0.8119612336158752, 0.8022629022598267, 0.8095366358757019, 0.8165409564971924], 'val_loss': [0.8329023122787476, 0.8338655829429626, 0.8338747620582581, 0.8379278779029846, 0.8461743593215942, 0.8476481437683105, 0.8507111072540283, 0.8650450706481934, 0.8759574890136719, 0.903914213180542, 0.8595269322395325, 0.8702893257141113, 0.8971905708312988, 0.8864565491676331, 0.8869990110397339, 0.8442159295082092, 0.8680111169815063, 0.8837400078773499, 0.7926927804946899, 0.8132498264312744, 0.7907652854919434, 0.7671242952346802, 0.7641527056694031, 0.7578849196434021, 0.7631469964981079, 0.7637016177177429, 0.7517114877700806, 0.7607147097587585, 0.7681034803390503, 0.7612327933311462, 0.7528299689292908, 0.7556983828544617, 0.7608323097229004, 0.7573635578155518, 0.7634177803993225, 0.7610788941383362, 0.7549298405647278, 0.7610766291618347, 0.7740305662155151, 0.7769452929496765, 0.7605551481246948, 0.7583681344985962, 0.7664260268211365, 0.781894862651825, 0.7588800191879272, 0.7652660012245178, 0.8095855116844177, 0.76263427734375, 0.7740827798843384, 0.7778058052062988, 0.7559331059455872, 0.7568269371986389, 0.7695997357368469, 0.7645347714424133, 0.7822826504707336, 0.7668194770812988, 0.7845178246498108, 0.7706321477890015, 0.7773073315620422, 0.7722439169883728, 0.7705885171890259, 0.7664192914962769, 0.7742286920547485, 0.7649919390678406, 0.7807744145393372, 0.7908242344856262, 0.7681348919868469, 0.7712588310241699, 0.7747646570205688, 0.776938259601593, 0.7789065837860107, 0.7745608687400818, 0.8270144462585449, 0.7760029435157776, 0.7846389412879944, 0.7841626405715942, 0.7803781628608704, 0.8514460921287537, 0.7797202467918396, 0.7892754077911377, 0.8419407606124878, 0.7775560021400452, 0.8264181613922119, 0.8148064613342285, 0.7997481226921082, 0.7788636684417725, 0.7917179465293884, 0.8061307072639465, 0.8256123065948486, 0.7856159806251526, 0.7889575958251953, 0.8093734383583069, 0.8268898725509644, 0.8063111901283264, 0.7969812154769897, 0.7927727699279785, 0.7950239777565002, 0.8249648809432983, 0.7900564074516296, 0.8174814581871033], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.4881465435028076, 0.4903017282485962, 0.4892241358757019, 0.4881465435028076, 0.49353447556495667, 0.524784505367279, 0.5215517282485962, 0.53125, 0.6023706793785095, 0.5894396305084229, 0.6131465435028076, 0.6379310488700867, 0.6519396305084229, 0.6530172228813171, 0.6433189511299133, 0.6508620977401733, 0.6778017282485962, 0.6605603694915771, 0.6508620977401733, 0.6681034564971924, 0.673491358757019, 0.6788793206214905, 0.6724137663841248, 0.6778017282485962, 0.6756465435028076, 0.673491358757019, 0.6756465435028076, 0.6724137663841248, 0.6573275923728943, 0.6584051847457886, 0.673491358757019, 0.6756465435028076, 0.6767241358757019, 0.6594827771186829, 0.681034505367279, 0.6799569129943848, 0.6411637663841248, 0.6713362336158752, 0.6616379022598267, 0.6616379022598267, 0.681034505367279, 0.6756465435028076, 0.6594827771186829, 0.6724137663841248, 0.65625, 0.6713362336158752, 0.6637930870056152, 0.6799569129943848, 0.6778017282485962, 0.6713362336158752, 0.6756465435028076, 0.673491358757019, 0.6788793206214905, 0.6971982717514038, 0.6691810488700867, 0.6616379022598267, 0.6788793206214905, 0.6713362336158752, 0.681034505367279, 0.6713362336158752, 0.6799569129943848, 0.6767241358757019, 0.639008641242981, 0.6767241358757019, 0.6670258641242981, 0.673491358757019, 0.6681034564971924, 0.6282327771186829, 0.6799569129943848, 0.6616379022598267, 0.6239224076271057, 0.681034505367279, 0.642241358757019, 0.662715494632721, 0.6476293206214905, 0.6670258641242981, 0.6659482717514038, 0.6573275923728943, 0.6368534564971924, 0.6778017282485962, 0.681034505367279, 0.6681034564971924, 0.6465517282485962, 0.6454741358757019, 0.6821120977401733, 0.6788793206214905, 0.6842672228813171, 0.6433189511299133, 0.6745689511299133, 0.6605603694915771]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.6983 - accuracy: 0.7088"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 10s 64ms/step - loss: 0.7015 - accuracy: 0.7066 - val_loss: 0.8286 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7007 - accuracy: 0.7074 - val_loss: 0.8317 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6763 - accuracy: 0.7278 - val_loss: 0.8325 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6762 - accuracy: 0.7281 - val_loss: 0.8396 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6701 - accuracy: 0.7233 - val_loss: 0.8426 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6756 - accuracy: 0.7241 - val_loss: 0.8477 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6668 - accuracy: 0.7431 - val_loss: 0.8493 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6717 - accuracy: 0.7329 - val_loss: 0.8637 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6592 - accuracy: 0.7434 - val_loss: 0.8613 - val_accuracy: 0.4943\n","Epoch 10/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6657 - accuracy: 0.7397 - val_loss: 0.8595 - val_accuracy: 0.4932\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6769 - accuracy: 0.7238 - val_loss: 0.8617 - val_accuracy: 0.4921\n","Epoch 12/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6717 - accuracy: 0.7312 - val_loss: 0.9286 - val_accuracy: 0.4943\n","Epoch 13/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6647 - accuracy: 0.7309 - val_loss: 0.9246 - val_accuracy: 0.4932\n","Epoch 14/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6552 - accuracy: 0.7490 - val_loss: 0.9257 - val_accuracy: 0.4943\n","Epoch 15/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.6624 - accuracy: 0.7391 - val_loss: 0.9084 - val_accuracy: 0.5000\n","Epoch 16/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.6596 - accuracy: 0.7391 - val_loss: 0.8598 - val_accuracy: 0.5294\n","Epoch 17/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.6792 - accuracy: 0.7168 - val_loss: 0.8484 - val_accuracy: 0.5566\n","Epoch 18/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6542 - accuracy: 0.7419 - val_loss: 0.8844 - val_accuracy: 0.5328\n","Epoch 19/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.6499 - accuracy: 0.7484 - val_loss: 0.8231 - val_accuracy: 0.5633\n","Epoch 20/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.6547 - accuracy: 0.7507 - val_loss: 0.8144 - val_accuracy: 0.5713\n","Epoch 21/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6502 - accuracy: 0.7490 - val_loss: 0.8255 - val_accuracy: 0.5781\n","Epoch 22/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6464 - accuracy: 0.7518 - val_loss: 0.8085 - val_accuracy: 0.5973\n","Epoch 23/100\n","28/28 [==============================] - 3s 117ms/step - loss: 0.6476 - accuracy: 0.7518 - val_loss: 0.7966 - val_accuracy: 0.6143\n","Epoch 24/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.6575 - accuracy: 0.7425 - val_loss: 0.7928 - val_accuracy: 0.6244\n","Epoch 25/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6444 - accuracy: 0.7541 - val_loss: 0.7861 - val_accuracy: 0.6131\n","Epoch 26/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6424 - accuracy: 0.7496 - val_loss: 0.7799 - val_accuracy: 0.6278\n","Epoch 27/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6448 - accuracy: 0.7479 - val_loss: 0.7998 - val_accuracy: 0.6301\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6420 - accuracy: 0.7578 - val_loss: 0.8285 - val_accuracy: 0.6063\n","Epoch 29/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6446 - accuracy: 0.7453 - val_loss: 0.7787 - val_accuracy: 0.6357\n","Epoch 30/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6474 - accuracy: 0.7490 - val_loss: 0.8094 - val_accuracy: 0.6222\n","Epoch 31/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6500 - accuracy: 0.7428 - val_loss: 0.8256 - val_accuracy: 0.6176\n","Epoch 32/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6467 - accuracy: 0.7504 - val_loss: 0.7861 - val_accuracy: 0.6357\n","Epoch 33/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.6550 - accuracy: 0.7462 - val_loss: 0.7783 - val_accuracy: 0.6448\n","Epoch 34/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6357 - accuracy: 0.7547 - val_loss: 0.7779 - val_accuracy: 0.6380\n","Epoch 35/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.6236 - accuracy: 0.7688 - val_loss: 0.7782 - val_accuracy: 0.6482\n","Epoch 36/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6281 - accuracy: 0.7632 - val_loss: 0.8104 - val_accuracy: 0.6301\n","Epoch 37/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6292 - accuracy: 0.7578 - val_loss: 0.7944 - val_accuracy: 0.6380\n","Epoch 38/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6313 - accuracy: 0.7668 - val_loss: 0.7844 - val_accuracy: 0.6414\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6247 - accuracy: 0.7683 - val_loss: 0.7863 - val_accuracy: 0.6437\n","Epoch 40/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6316 - accuracy: 0.7575 - val_loss: 0.7849 - val_accuracy: 0.6380\n","Epoch 41/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6259 - accuracy: 0.7649 - val_loss: 0.7865 - val_accuracy: 0.6493\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6580 - accuracy: 0.7377 - val_loss: 0.8235 - val_accuracy: 0.6244\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6509 - accuracy: 0.7411 - val_loss: 0.7829 - val_accuracy: 0.6459\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6238 - accuracy: 0.7711 - val_loss: 0.7887 - val_accuracy: 0.6437\n","Epoch 45/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6245 - accuracy: 0.7705 - val_loss: 0.7848 - val_accuracy: 0.6391\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6109 - accuracy: 0.7787 - val_loss: 0.7910 - val_accuracy: 0.6357\n","Epoch 47/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6319 - accuracy: 0.7634 - val_loss: 0.7872 - val_accuracy: 0.6324\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6154 - accuracy: 0.7722 - val_loss: 0.7878 - val_accuracy: 0.6448\n","Epoch 49/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6122 - accuracy: 0.7801 - val_loss: 0.7927 - val_accuracy: 0.6391\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6245 - accuracy: 0.7623 - val_loss: 0.7928 - val_accuracy: 0.6312\n","Epoch 51/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6140 - accuracy: 0.7705 - val_loss: 0.8050 - val_accuracy: 0.6380\n","Epoch 52/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6323 - accuracy: 0.7663 - val_loss: 0.8026 - val_accuracy: 0.6346\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6112 - accuracy: 0.7694 - val_loss: 0.7908 - val_accuracy: 0.6482\n","Epoch 54/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6033 - accuracy: 0.7852 - val_loss: 0.8080 - val_accuracy: 0.6391\n","Epoch 55/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.6069 - accuracy: 0.7782 - val_loss: 0.7950 - val_accuracy: 0.6357\n","Epoch 56/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6056 - accuracy: 0.7813 - val_loss: 0.7967 - val_accuracy: 0.6380\n","Epoch 57/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5964 - accuracy: 0.7864 - val_loss: 0.8053 - val_accuracy: 0.6403\n","Epoch 58/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6122 - accuracy: 0.7649 - val_loss: 0.7980 - val_accuracy: 0.6346\n","Epoch 59/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5977 - accuracy: 0.7872 - val_loss: 0.8002 - val_accuracy: 0.6380\n","Epoch 60/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6014 - accuracy: 0.7824 - val_loss: 0.7955 - val_accuracy: 0.6290\n","Epoch 61/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6030 - accuracy: 0.7750 - val_loss: 0.8054 - val_accuracy: 0.6357\n","Epoch 62/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5920 - accuracy: 0.7830 - val_loss: 0.7970 - val_accuracy: 0.6357\n","Epoch 63/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5942 - accuracy: 0.7838 - val_loss: 0.8587 - val_accuracy: 0.6233\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6097 - accuracy: 0.7739 - val_loss: 0.8000 - val_accuracy: 0.6437\n","Epoch 65/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5936 - accuracy: 0.7872 - val_loss: 0.8060 - val_accuracy: 0.6335\n","Epoch 66/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5944 - accuracy: 0.7861 - val_loss: 0.7999 - val_accuracy: 0.6459\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5865 - accuracy: 0.7946 - val_loss: 0.8036 - val_accuracy: 0.6335\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5876 - accuracy: 0.7917 - val_loss: 0.8101 - val_accuracy: 0.6380\n","Epoch 69/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5957 - accuracy: 0.7770 - val_loss: 0.8090 - val_accuracy: 0.6346\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5949 - accuracy: 0.7844 - val_loss: 0.8269 - val_accuracy: 0.6391\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5828 - accuracy: 0.7946 - val_loss: 0.8075 - val_accuracy: 0.6335\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5879 - accuracy: 0.7889 - val_loss: 0.8307 - val_accuracy: 0.6278\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5825 - accuracy: 0.7875 - val_loss: 0.8080 - val_accuracy: 0.6391\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5825 - accuracy: 0.7926 - val_loss: 0.8129 - val_accuracy: 0.6482\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5816 - accuracy: 0.7951 - val_loss: 0.8239 - val_accuracy: 0.6369\n","Epoch 76/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5930 - accuracy: 0.7824 - val_loss: 0.8138 - val_accuracy: 0.6369\n","Epoch 77/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5859 - accuracy: 0.7949 - val_loss: 0.8181 - val_accuracy: 0.6403\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5723 - accuracy: 0.7974 - val_loss: 0.8198 - val_accuracy: 0.6369\n","Epoch 79/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5906 - accuracy: 0.7878 - val_loss: 0.8245 - val_accuracy: 0.6425\n","Epoch 80/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5662 - accuracy: 0.8045 - val_loss: 0.8322 - val_accuracy: 0.6425\n","Epoch 81/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5747 - accuracy: 0.7937 - val_loss: 0.8168 - val_accuracy: 0.6324\n","Epoch 82/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5756 - accuracy: 0.7903 - val_loss: 0.8504 - val_accuracy: 0.6256\n","Epoch 83/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5841 - accuracy: 0.7895 - val_loss: 0.8291 - val_accuracy: 0.6312\n","Epoch 84/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5773 - accuracy: 0.7932 - val_loss: 0.8596 - val_accuracy: 0.6301\n","Epoch 85/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5668 - accuracy: 0.8053 - val_loss: 0.8105 - val_accuracy: 0.6391\n","Epoch 86/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5526 - accuracy: 0.8104 - val_loss: 0.8435 - val_accuracy: 0.6324\n","Epoch 87/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5627 - accuracy: 0.8016 - val_loss: 0.8435 - val_accuracy: 0.6301\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5774 - accuracy: 0.7985 - val_loss: 0.8238 - val_accuracy: 0.6414\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5992 - accuracy: 0.7782 - val_loss: 0.8206 - val_accuracy: 0.6369\n","Epoch 90/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5813 - accuracy: 0.7895 - val_loss: 0.8237 - val_accuracy: 0.6380\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5619 - accuracy: 0.8053 - val_loss: 0.8212 - val_accuracy: 0.6391\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5846 - accuracy: 0.7849 - val_loss: 0.8348 - val_accuracy: 0.6278\n","Epoch 93/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5730 - accuracy: 0.7985 - val_loss: 0.8233 - val_accuracy: 0.6425\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5627 - accuracy: 0.8008 - val_loss: 0.8508 - val_accuracy: 0.6346\n","Epoch 95/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5604 - accuracy: 0.8065 - val_loss: 0.8418 - val_accuracy: 0.6233\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5620 - accuracy: 0.8065 - val_loss: 0.8294 - val_accuracy: 0.6459\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5565 - accuracy: 0.8036 - val_loss: 0.8519 - val_accuracy: 0.6278\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5487 - accuracy: 0.8113 - val_loss: 0.8348 - val_accuracy: 0.6301\n","Epoch 99/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5514 - accuracy: 0.8059 - val_loss: 0.8387 - val_accuracy: 0.6391\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5520 - accuracy: 0.8113 - val_loss: 0.8370 - val_accuracy: 0.6391\n","{'loss': [0.7014744877815247, 0.7007018327713013, 0.6762731671333313, 0.6762189865112305, 0.6701160073280334, 0.675579845905304, 0.6668217182159424, 0.6716782450675964, 0.6592080593109131, 0.6656710505485535, 0.6769068837165833, 0.6716590523719788, 0.6647163033485413, 0.6552268266677856, 0.6624104976654053, 0.6596126556396484, 0.6792064905166626, 0.6541838049888611, 0.649893045425415, 0.654689610004425, 0.6501690149307251, 0.6464425921440125, 0.6475825905799866, 0.6574894785881042, 0.6444229483604431, 0.6423859596252441, 0.6448436975479126, 0.6420120596885681, 0.644596517086029, 0.6474223732948303, 0.6499818563461304, 0.6466777920722961, 0.6549846529960632, 0.6356553435325623, 0.6236351728439331, 0.6281476020812988, 0.6291670799255371, 0.6312755942344666, 0.6246964931488037, 0.6316007971763611, 0.6259145140647888, 0.6580199003219604, 0.6508979201316833, 0.6237969994544983, 0.6244824528694153, 0.6109257936477661, 0.6319159269332886, 0.6153590083122253, 0.6121873259544373, 0.624472439289093, 0.613965630531311, 0.6323300004005432, 0.6111885905265808, 0.603277862071991, 0.6068741083145142, 0.6056056022644043, 0.5964183211326599, 0.6121842861175537, 0.5976947546005249, 0.6013687252998352, 0.6030113697052002, 0.5920076966285706, 0.5942461490631104, 0.6097370386123657, 0.5935525894165039, 0.5944386124610901, 0.5864709615707397, 0.5875838398933411, 0.5957345366477966, 0.5949181914329529, 0.582758367061615, 0.5878794193267822, 0.5824519395828247, 0.5825316309928894, 0.5815721154212952, 0.5929885506629944, 0.5859110355377197, 0.5722973942756653, 0.5905926823616028, 0.5661623477935791, 0.5746952891349792, 0.5755988359451294, 0.5840661525726318, 0.57731693983078, 0.5667696595191956, 0.5526140332221985, 0.5627133846282959, 0.5774208903312683, 0.5991705060005188, 0.5812523365020752, 0.5618810057640076, 0.584576427936554, 0.573000967502594, 0.5627240538597107, 0.5604115128517151, 0.5620449781417847, 0.5564744472503662, 0.5487058758735657, 0.5513919591903687, 0.5520024299621582], 'accuracy': [0.7065647840499878, 0.7074136734008789, 0.7277871966362, 0.7280701994895935, 0.7232597470283508, 0.7241086363792419, 0.7430673241615295, 0.7328805923461914, 0.7433503270149231, 0.7396717667579651, 0.7238256931304932, 0.7311828136444092, 0.7308998107910156, 0.7490096092224121, 0.7391058206558228, 0.7391058206558228, 0.7167515754699707, 0.7419354915618896, 0.7484436631202698, 0.7507073879241943, 0.7490096092224121, 0.751839280128479, 0.751839280128479, 0.742501437664032, 0.7541030049324036, 0.7495755553245544, 0.7478777766227722, 0.7577815651893616, 0.7453310489654541, 0.7490096092224121, 0.7427843809127808, 0.7504244446754456, 0.7461799383163452, 0.7546689510345459, 0.7688171863555908, 0.7631579041481018, 0.7577815651893616, 0.7668364644050598, 0.7682512998580933, 0.757498562335968, 0.764855682849884, 0.7376909852027893, 0.7410866022109985, 0.7710809111595154, 0.7705150246620178, 0.7787209749221802, 0.7634408473968506, 0.7722128033638, 0.7801358103752136, 0.7623090147972107, 0.7705150246620178, 0.7662705183029175, 0.7693831324577332, 0.7852292060852051, 0.7781550884246826, 0.7812677025794983, 0.786361038684845, 0.764855682849884, 0.7872099876403809, 0.7823995351791382, 0.7750424742698669, 0.7829654812812805, 0.7838143706321716, 0.7739105820655823, 0.7872099876403809, 0.7860780954360962, 0.7945670485496521, 0.79173743724823, 0.777023196220398, 0.784380316734314, 0.7945670485496521, 0.7889077663421631, 0.7874929308891296, 0.7925863265991211, 0.7951329946517944, 0.7823995351791382, 0.7948500514030457, 0.797396719455719, 0.7877758741378784, 0.8044708371162415, 0.793718159198761, 0.7903226017951965, 0.7894737124443054, 0.7931522130966187, 0.8053197264671326, 0.810413122177124, 0.8016412258148193, 0.7985285520553589, 0.7781550884246826, 0.7894737124443054, 0.8053197264671326, 0.7849462628364563, 0.7985285520553589, 0.8007922768592834, 0.8064516186714172, 0.8064516186714172, 0.8036219477653503, 0.8112620115280151, 0.8058856725692749, 0.8112620115280151], 'val_loss': [0.8285733461380005, 0.8316771984100342, 0.832459032535553, 0.8395716547966003, 0.8426164984703064, 0.8476619124412537, 0.8492780327796936, 0.863670825958252, 0.8613080382347107, 0.8595417141914368, 0.8617270588874817, 0.9286472201347351, 0.9245761036872864, 0.9256749749183655, 0.9083641767501831, 0.8597568273544312, 0.8483628034591675, 0.8843840956687927, 0.8231301307678223, 0.8143781423568726, 0.8254756331443787, 0.8085470795631409, 0.7966326475143433, 0.7927754521369934, 0.7860996127128601, 0.7798616290092468, 0.799780011177063, 0.8284519910812378, 0.7786551713943481, 0.8093581199645996, 0.8256446719169617, 0.7860930562019348, 0.7783430814743042, 0.7779068946838379, 0.7781787514686584, 0.8103933334350586, 0.7943795919418335, 0.7843966484069824, 0.7863154411315918, 0.7848638892173767, 0.7864695191383362, 0.8235133290290833, 0.7829093337059021, 0.7887163758277893, 0.784824788570404, 0.7910293936729431, 0.7872301340103149, 0.787838876247406, 0.7927064299583435, 0.7928197383880615, 0.8049762845039368, 0.8026332259178162, 0.7907614707946777, 0.8080427646636963, 0.7950473427772522, 0.7967046499252319, 0.8052905797958374, 0.7979506254196167, 0.800203263759613, 0.795539379119873, 0.8053910136222839, 0.7970263361930847, 0.8587316274642944, 0.8000068664550781, 0.8059952259063721, 0.7998683452606201, 0.8035930395126343, 0.8101410269737244, 0.8089697360992432, 0.8268975019454956, 0.8074637055397034, 0.8307127356529236, 0.8079553246498108, 0.8128662109375, 0.8239288330078125, 0.8137747645378113, 0.8181179761886597, 0.8198257088661194, 0.8244852423667908, 0.832179605960846, 0.8167980313301086, 0.8504215478897095, 0.8291457295417786, 0.8596177101135254, 0.8104835748672485, 0.8435027599334717, 0.8434893488883972, 0.8238137364387512, 0.8205909132957458, 0.823654055595398, 0.8211800456047058, 0.8348477482795715, 0.8233431577682495, 0.8507968187332153, 0.8418052792549133, 0.8293940424919128, 0.8519495129585266, 0.8348380327224731, 0.8387329578399658, 0.8370122313499451], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4943438768386841, 0.49321267008781433, 0.4920814335346222, 0.4943438768386841, 0.49321267008781433, 0.4943438768386841, 0.5, 0.529411792755127, 0.5565611124038696, 0.5328054428100586, 0.5633484125137329, 0.5712669491767883, 0.5780543088912964, 0.5972850918769836, 0.6142534017562866, 0.6244344115257263, 0.6131221652030945, 0.627828061580658, 0.6300904750823975, 0.6063348650932312, 0.6357465982437134, 0.622171938419342, 0.6176470518112183, 0.6357465982437134, 0.6447963714599609, 0.6380090713500977, 0.6481900215148926, 0.6300904750823975, 0.6380090713500977, 0.6414027214050293, 0.6436651349067688, 0.6380090713500977, 0.6493212580680847, 0.6244344115257263, 0.6459276080131531, 0.6436651349067688, 0.639140248298645, 0.6357465982437134, 0.6323529481887817, 0.6447963714599609, 0.639140248298645, 0.6312217116355896, 0.6380090713500977, 0.6346153616905212, 0.6481900215148926, 0.639140248298645, 0.6357465982437134, 0.6380090713500977, 0.6402714848518372, 0.6346153616905212, 0.6380090713500977, 0.6289592981338501, 0.6357465982437134, 0.6357465982437134, 0.6233031749725342, 0.6436651349067688, 0.6334841847419739, 0.6459276080131531, 0.6334841847419739, 0.6380090713500977, 0.6346153616905212, 0.639140248298645, 0.6334841847419739, 0.627828061580658, 0.639140248298645, 0.6481900215148926, 0.6368778347969055, 0.6368778347969055, 0.6402714848518372, 0.6368778347969055, 0.6425339579582214, 0.6425339579582214, 0.6323529481887817, 0.6255655884742737, 0.6312217116355896, 0.6300904750823975, 0.639140248298645, 0.6323529481887817, 0.6300904750823975, 0.6414027214050293, 0.6368778347969055, 0.6380090713500977, 0.639140248298645, 0.627828061580658, 0.6425339579582214, 0.6346153616905212, 0.6233031749725342, 0.6459276080131531, 0.627828061580658, 0.6300904750823975, 0.639140248298645, 0.639140248298645]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.7269 - accuracy: 0.6801"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 57ms/step - loss: 0.7269 - accuracy: 0.6801 - val_loss: 0.8326 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6895 - accuracy: 0.7124 - val_loss: 0.8364 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6887 - accuracy: 0.7145 - val_loss: 0.8385 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6837 - accuracy: 0.7214 - val_loss: 0.8420 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6824 - accuracy: 0.7207 - val_loss: 0.8525 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6777 - accuracy: 0.7258 - val_loss: 0.8645 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6752 - accuracy: 0.7258 - val_loss: 0.8777 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6819 - accuracy: 0.7124 - val_loss: 0.8752 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6787 - accuracy: 0.7204 - val_loss: 0.9000 - val_accuracy: 0.4855\n","Epoch 10/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6865 - accuracy: 0.7183 - val_loss: 0.9081 - val_accuracy: 0.4855\n","Epoch 11/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6672 - accuracy: 0.7346 - val_loss: 0.9553 - val_accuracy: 0.4855\n","Epoch 12/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6680 - accuracy: 0.7367 - val_loss: 0.9814 - val_accuracy: 0.4855\n","Epoch 13/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6780 - accuracy: 0.7266 - val_loss: 0.9540 - val_accuracy: 0.4876\n","Epoch 14/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6708 - accuracy: 0.7339 - val_loss: 1.0208 - val_accuracy: 0.4866\n","Epoch 15/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6696 - accuracy: 0.7300 - val_loss: 0.9325 - val_accuracy: 0.4979\n","Epoch 16/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6724 - accuracy: 0.7271 - val_loss: 0.9076 - val_accuracy: 0.5103\n","Epoch 17/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6628 - accuracy: 0.7339 - val_loss: 0.8943 - val_accuracy: 0.5238\n","Epoch 18/100\n","31/31 [==============================] - 2s 56ms/step - loss: 0.6724 - accuracy: 0.7297 - val_loss: 0.8067 - val_accuracy: 0.6074\n","Epoch 19/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6785 - accuracy: 0.7178 - val_loss: 0.8085 - val_accuracy: 0.6085\n","Epoch 20/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6636 - accuracy: 0.7372 - val_loss: 0.8195 - val_accuracy: 0.6012\n","Epoch 21/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6684 - accuracy: 0.7253 - val_loss: 0.8371 - val_accuracy: 0.5971\n","Epoch 22/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6665 - accuracy: 0.7300 - val_loss: 0.8004 - val_accuracy: 0.6178\n","Epoch 23/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.6584 - accuracy: 0.7388 - val_loss: 0.8055 - val_accuracy: 0.6188\n","Epoch 24/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.6713 - accuracy: 0.7251 - val_loss: 0.8022 - val_accuracy: 0.6229\n","Epoch 25/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.6589 - accuracy: 0.7377 - val_loss: 0.7989 - val_accuracy: 0.6281\n","Epoch 26/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.6551 - accuracy: 0.7444 - val_loss: 0.8062 - val_accuracy: 0.6291\n","Epoch 27/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6564 - accuracy: 0.7382 - val_loss: 0.8186 - val_accuracy: 0.6116\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6522 - accuracy: 0.7439 - val_loss: 0.8133 - val_accuracy: 0.6240\n","Epoch 29/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6494 - accuracy: 0.7434 - val_loss: 0.7993 - val_accuracy: 0.6395\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6509 - accuracy: 0.7470 - val_loss: 0.8210 - val_accuracy: 0.6250\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6557 - accuracy: 0.7403 - val_loss: 0.8190 - val_accuracy: 0.6085\n","Epoch 32/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6456 - accuracy: 0.7488 - val_loss: 0.8097 - val_accuracy: 0.6364\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6433 - accuracy: 0.7506 - val_loss: 0.8160 - val_accuracy: 0.6167\n","Epoch 34/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6489 - accuracy: 0.7468 - val_loss: 0.8146 - val_accuracy: 0.6271\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6378 - accuracy: 0.7612 - val_loss: 0.8127 - val_accuracy: 0.6260\n","Epoch 36/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6483 - accuracy: 0.7470 - val_loss: 0.8386 - val_accuracy: 0.6198\n","Epoch 37/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6427 - accuracy: 0.7519 - val_loss: 0.8116 - val_accuracy: 0.6312\n","Epoch 38/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6396 - accuracy: 0.7532 - val_loss: 0.8135 - val_accuracy: 0.6178\n","Epoch 39/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6394 - accuracy: 0.7543 - val_loss: 0.8295 - val_accuracy: 0.6219\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6335 - accuracy: 0.7592 - val_loss: 0.8163 - val_accuracy: 0.6281\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6486 - accuracy: 0.7413 - val_loss: 0.8340 - val_accuracy: 0.6188\n","Epoch 42/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6655 - accuracy: 0.7310 - val_loss: 0.8484 - val_accuracy: 0.5981\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6537 - accuracy: 0.7357 - val_loss: 0.8156 - val_accuracy: 0.6260\n","Epoch 44/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6377 - accuracy: 0.7540 - val_loss: 0.8169 - val_accuracy: 0.6291\n","Epoch 45/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6467 - accuracy: 0.7429 - val_loss: 0.8600 - val_accuracy: 0.6074\n","Epoch 46/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6323 - accuracy: 0.7540 - val_loss: 0.8307 - val_accuracy: 0.6240\n","Epoch 47/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6261 - accuracy: 0.7643 - val_loss: 0.8167 - val_accuracy: 0.6240\n","Epoch 48/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6370 - accuracy: 0.7535 - val_loss: 0.8444 - val_accuracy: 0.6229\n","Epoch 49/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6358 - accuracy: 0.7475 - val_loss: 0.8178 - val_accuracy: 0.6302\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6468 - accuracy: 0.7444 - val_loss: 0.8602 - val_accuracy: 0.6167\n","Epoch 51/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6470 - accuracy: 0.7351 - val_loss: 0.8123 - val_accuracy: 0.6322\n","Epoch 52/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6200 - accuracy: 0.7641 - val_loss: 0.8120 - val_accuracy: 0.6364\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6225 - accuracy: 0.7566 - val_loss: 0.8378 - val_accuracy: 0.6178\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6279 - accuracy: 0.7535 - val_loss: 0.8220 - val_accuracy: 0.6291\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6128 - accuracy: 0.7690 - val_loss: 0.8273 - val_accuracy: 0.6281\n","Epoch 56/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6147 - accuracy: 0.7734 - val_loss: 0.8323 - val_accuracy: 0.6250\n","Epoch 57/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6321 - accuracy: 0.7540 - val_loss: 0.8248 - val_accuracy: 0.6271\n","Epoch 58/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6223 - accuracy: 0.7643 - val_loss: 0.8271 - val_accuracy: 0.6136\n","Epoch 59/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6111 - accuracy: 0.7698 - val_loss: 0.8812 - val_accuracy: 0.6054\n","Epoch 60/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6263 - accuracy: 0.7579 - val_loss: 0.9119 - val_accuracy: 0.6033\n","Epoch 61/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6204 - accuracy: 0.7656 - val_loss: 0.8210 - val_accuracy: 0.6281\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6154 - accuracy: 0.7682 - val_loss: 0.9480 - val_accuracy: 0.5919\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6425 - accuracy: 0.7444 - val_loss: 0.8168 - val_accuracy: 0.6322\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6140 - accuracy: 0.7685 - val_loss: 0.8293 - val_accuracy: 0.6229\n","Epoch 65/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6065 - accuracy: 0.7817 - val_loss: 0.8211 - val_accuracy: 0.6219\n","Epoch 66/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6109 - accuracy: 0.7749 - val_loss: 0.8455 - val_accuracy: 0.6271\n","Epoch 67/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6001 - accuracy: 0.7796 - val_loss: 0.8280 - val_accuracy: 0.6271\n","Epoch 68/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6043 - accuracy: 0.7742 - val_loss: 0.8409 - val_accuracy: 0.6229\n","Epoch 69/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6088 - accuracy: 0.7724 - val_loss: 0.8292 - val_accuracy: 0.6229\n","Epoch 70/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5945 - accuracy: 0.7773 - val_loss: 0.8382 - val_accuracy: 0.6322\n","Epoch 71/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5925 - accuracy: 0.7868 - val_loss: 0.8668 - val_accuracy: 0.6229\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6210 - accuracy: 0.7561 - val_loss: 0.8305 - val_accuracy: 0.6312\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5955 - accuracy: 0.7822 - val_loss: 0.8314 - val_accuracy: 0.6312\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6008 - accuracy: 0.7760 - val_loss: 0.8764 - val_accuracy: 0.6074\n","Epoch 75/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5987 - accuracy: 0.7749 - val_loss: 0.8439 - val_accuracy: 0.6281\n","Epoch 76/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5959 - accuracy: 0.7845 - val_loss: 0.8439 - val_accuracy: 0.6343\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5914 - accuracy: 0.7860 - val_loss: 0.8359 - val_accuracy: 0.6364\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6065 - accuracy: 0.7711 - val_loss: 0.8874 - val_accuracy: 0.6147\n","Epoch 79/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6025 - accuracy: 0.7718 - val_loss: 0.8443 - val_accuracy: 0.6178\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5928 - accuracy: 0.7824 - val_loss: 0.8567 - val_accuracy: 0.6240\n","Epoch 81/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5868 - accuracy: 0.7889 - val_loss: 0.8424 - val_accuracy: 0.6291\n","Epoch 82/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5846 - accuracy: 0.7814 - val_loss: 0.8531 - val_accuracy: 0.6281\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6042 - accuracy: 0.7736 - val_loss: 0.8375 - val_accuracy: 0.6167\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5951 - accuracy: 0.7775 - val_loss: 0.8728 - val_accuracy: 0.6126\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5883 - accuracy: 0.7853 - val_loss: 0.8447 - val_accuracy: 0.6312\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5818 - accuracy: 0.7956 - val_loss: 0.8393 - val_accuracy: 0.6198\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6026 - accuracy: 0.7819 - val_loss: 0.8761 - val_accuracy: 0.6136\n","Epoch 88/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5866 - accuracy: 0.7853 - val_loss: 0.9328 - val_accuracy: 0.6074\n","Epoch 89/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5873 - accuracy: 0.7868 - val_loss: 0.8975 - val_accuracy: 0.6105\n","Epoch 90/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5823 - accuracy: 0.7806 - val_loss: 0.8457 - val_accuracy: 0.6198\n","Epoch 91/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5753 - accuracy: 0.7930 - val_loss: 0.8482 - val_accuracy: 0.6343\n","Epoch 92/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5715 - accuracy: 0.7977 - val_loss: 0.8488 - val_accuracy: 0.6229\n","Epoch 93/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5805 - accuracy: 0.7935 - val_loss: 0.8436 - val_accuracy: 0.6219\n","Epoch 94/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5812 - accuracy: 0.7871 - val_loss: 0.8614 - val_accuracy: 0.6260\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5740 - accuracy: 0.7941 - val_loss: 0.8729 - val_accuracy: 0.6188\n","Epoch 96/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5828 - accuracy: 0.7850 - val_loss: 0.9091 - val_accuracy: 0.6116\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5686 - accuracy: 0.7974 - val_loss: 0.8680 - val_accuracy: 0.6281\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5622 - accuracy: 0.8036 - val_loss: 0.8885 - val_accuracy: 0.6240\n","Epoch 99/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5628 - accuracy: 0.7997 - val_loss: 0.8568 - val_accuracy: 0.6167\n","Epoch 100/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5717 - accuracy: 0.7966 - val_loss: 0.8849 - val_accuracy: 0.6291\n","{'loss': [0.7269412279129028, 0.6894534826278687, 0.6887279748916626, 0.6837042570114136, 0.682357907295227, 0.6777146458625793, 0.6751589179039001, 0.6818983554840088, 0.6787464618682861, 0.6864690780639648, 0.6671800017356873, 0.6680341958999634, 0.6780316233634949, 0.6707906723022461, 0.6695787310600281, 0.6724047064781189, 0.6628342270851135, 0.6724244356155396, 0.678473949432373, 0.6636107563972473, 0.6684174537658691, 0.6665046215057373, 0.6584262847900391, 0.6713411808013916, 0.6588506102561951, 0.6550849676132202, 0.6563816070556641, 0.6522397398948669, 0.6493679881095886, 0.6508803963661194, 0.6556770205497742, 0.6455572247505188, 0.6432909369468689, 0.6488634347915649, 0.6377936601638794, 0.6483287215232849, 0.6426904797554016, 0.6396476030349731, 0.6393553614616394, 0.6335003972053528, 0.6485612392425537, 0.6655442118644714, 0.6537347435951233, 0.6376659274101257, 0.6466853618621826, 0.6323066353797913, 0.6260898113250732, 0.637027382850647, 0.6358212828636169, 0.6467819213867188, 0.6469522714614868, 0.619983434677124, 0.6224931478500366, 0.6279336214065552, 0.612781822681427, 0.6147433519363403, 0.6320876479148865, 0.6223034262657166, 0.6110751628875732, 0.6262738704681396, 0.6203973293304443, 0.615350604057312, 0.6425012350082397, 0.6140045523643494, 0.6064561605453491, 0.6108965277671814, 0.6001477241516113, 0.6042715311050415, 0.6087826490402222, 0.5945068597793579, 0.5924663543701172, 0.6209814548492432, 0.5955247282981873, 0.6008226275444031, 0.5986912250518799, 0.5959049463272095, 0.5914137959480286, 0.6064555048942566, 0.6024788618087769, 0.5927845239639282, 0.5868473649024963, 0.5846139788627625, 0.6042264699935913, 0.5951277613639832, 0.5883104205131531, 0.5818431377410889, 0.6026246547698975, 0.5865647196769714, 0.5873261094093323, 0.5823466777801514, 0.5752794742584229, 0.5714932084083557, 0.5804908871650696, 0.5812422037124634, 0.5739741921424866, 0.5828496217727661, 0.5685720443725586, 0.5622116327285767, 0.5627973675727844, 0.5716572403907776], 'accuracy': [0.6801033616065979, 0.7124031186103821, 0.7144702672958374, 0.7214470505714417, 0.7206718325614929, 0.7258397936820984, 0.7258397936820984, 0.7124031186103821, 0.7204134464263916, 0.7183462381362915, 0.7346253395080566, 0.736692488193512, 0.7266150116920471, 0.7338501214981079, 0.7299741506576538, 0.7271317839622498, 0.7338501214981079, 0.7297157645225525, 0.7178294658660889, 0.7372093200683594, 0.7253230214118958, 0.7299741506576538, 0.7387596964836121, 0.7250645756721497, 0.737726092338562, 0.7444444298744202, 0.7382428646087646, 0.7439276576042175, 0.7434108257293701, 0.7470284104347229, 0.7403100728988647, 0.7488372325897217, 0.7506459951400757, 0.7467700242996216, 0.7612403035163879, 0.7470284104347229, 0.751937985420227, 0.7532299757003784, 0.7542635798454285, 0.7591731548309326, 0.7413436770439148, 0.7310077548027039, 0.7356589436531067, 0.7540051937103271, 0.7428940534591675, 0.7540051937103271, 0.7643410563468933, 0.7534883618354797, 0.7475452423095703, 0.7444444298744202, 0.7351421117782593, 0.764082670211792, 0.7565891742706299, 0.7534883618354797, 0.7689922451972961, 0.7733849883079529, 0.7540051937103271, 0.7643410563468933, 0.7697674632072449, 0.7578811645507812, 0.7656330466270447, 0.7682170271873474, 0.7444444298744202, 0.7684754729270935, 0.7816537618637085, 0.7749354243278503, 0.7795865535736084, 0.7741602063179016, 0.7723514437675476, 0.777260959148407, 0.786821722984314, 0.7560723423957825, 0.7821705341339111, 0.7759689688682556, 0.7749354243278503, 0.7844961285591125, 0.7860465049743652, 0.7710594534873962, 0.7718346118927002, 0.7824289202690125, 0.7888888716697693, 0.7813953757286072, 0.773643434047699, 0.7775194048881531, 0.7852713465690613, 0.7956072092056274, 0.7819121479988098, 0.7852713465690613, 0.786821722984314, 0.7806201577186584, 0.7930232286453247, 0.7976744174957275, 0.7935400605201721, 0.7870801091194153, 0.7940568327903748, 0.7850129008293152, 0.7974160313606262, 0.8036175966262817, 0.7997416257858276, 0.7966408133506775], 'val_loss': [0.8326264023780823, 0.8363654613494873, 0.8385446071624756, 0.8419572114944458, 0.8525094985961914, 0.8645489811897278, 0.8776599764823914, 0.8752020597457886, 0.8999800086021423, 0.9080671072006226, 0.9553476572036743, 0.9813821911811829, 0.9539977312088013, 1.0207912921905518, 0.9324706792831421, 0.9076086282730103, 0.8943321108818054, 0.8067086935043335, 0.8085194826126099, 0.8195146918296814, 0.8371097445487976, 0.8004130125045776, 0.8054723143577576, 0.8022080659866333, 0.7989324331283569, 0.8061798810958862, 0.8186120390892029, 0.8132964968681335, 0.7992574572563171, 0.820954442024231, 0.8189771175384521, 0.8097121119499207, 0.8159962296485901, 0.8146177530288696, 0.8127443194389343, 0.838616132736206, 0.8116223216056824, 0.8134952783584595, 0.829510509967804, 0.8163325190544128, 0.8339518904685974, 0.84843510389328, 0.8155816793441772, 0.816851794719696, 0.860011100769043, 0.8306908011436462, 0.8167136907577515, 0.8444263339042664, 0.8177965879440308, 0.860179603099823, 0.812300980091095, 0.8120386600494385, 0.837776243686676, 0.8219714164733887, 0.8272628784179688, 0.8322994709014893, 0.8248423337936401, 0.8271036744117737, 0.8812192678451538, 0.9119175672531128, 0.8210425972938538, 0.9480360746383667, 0.8167754411697388, 0.8292558789253235, 0.8211180567741394, 0.845538318157196, 0.8279743194580078, 0.8409379720687866, 0.8292137384414673, 0.8382302522659302, 0.8667556643486023, 0.8305093050003052, 0.8313615918159485, 0.8763921856880188, 0.843934953212738, 0.8439114093780518, 0.8359270095825195, 0.8874040246009827, 0.8443301916122437, 0.8566834926605225, 0.8423821330070496, 0.8530747890472412, 0.8374830484390259, 0.8727627992630005, 0.8447174429893494, 0.83934086561203, 0.8760964274406433, 0.9327861070632935, 0.8974626064300537, 0.8457288146018982, 0.8481728434562683, 0.8488199710845947, 0.8436200022697449, 0.8613688349723816, 0.8729059100151062, 0.9090797901153564, 0.8680028915405273, 0.8884761333465576, 0.8567859530448914, 0.8849093317985535], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4876033067703247, 0.48657023906707764, 0.49793389439582825, 0.5103305578231812, 0.5237603187561035, 0.6074380278587341, 0.6084710955619812, 0.6012396812438965, 0.5971074104309082, 0.6177685856819153, 0.6188016533851624, 0.6229338645935059, 0.6280992031097412, 0.6291322112083435, 0.6115702390670776, 0.6239669322967529, 0.6394628286361694, 0.625, 0.6084710955619812, 0.6363636255264282, 0.6167355179786682, 0.6270661354064941, 0.6260330677032471, 0.6198347210884094, 0.6311983466148376, 0.6177685856819153, 0.6219007968902588, 0.6280992031097412, 0.6188016533851624, 0.5981404781341553, 0.6260330677032471, 0.6291322112083435, 0.6074380278587341, 0.6239669322967529, 0.6239669322967529, 0.6229338645935059, 0.6301652789115906, 0.6167355179786682, 0.6322314143180847, 0.6363636255264282, 0.6177685856819153, 0.6291322112083435, 0.6280992031097412, 0.625, 0.6270661354064941, 0.6136363744735718, 0.60537189245224, 0.6033057570457458, 0.6280992031097412, 0.5919421315193176, 0.6322314143180847, 0.6229338645935059, 0.6219007968902588, 0.6270661354064941, 0.6270661354064941, 0.6229338645935059, 0.6229338645935059, 0.6322314143180847, 0.6229338645935059, 0.6311983466148376, 0.6311983466148376, 0.6074380278587341, 0.6280992031097412, 0.6342975497245789, 0.6363636255264282, 0.6146694421768188, 0.6177685856819153, 0.6239669322967529, 0.6291322112083435, 0.6280992031097412, 0.6167355179786682, 0.6126033067703247, 0.6311983466148376, 0.6198347210884094, 0.6136363744735718, 0.6074380278587341, 0.6105371713638306, 0.6198347210884094, 0.6342975497245789, 0.6229338645935059, 0.6219007968902588, 0.6260330677032471, 0.6188016533851624, 0.6115702390670776, 0.6280992031097412, 0.6239669322967529, 0.6167355179786682, 0.6291322112083435]}\n","32/32 [==============================] - 1s 4ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_gru"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":519},"collapsed":true,"id":"kleLoWSV5B7Y","executionInfo":{"status":"ok","timestamp":1717530984347,"user_tz":-360,"elapsed":9,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"outputId":"04938402-3831-49e5-a564-a878b214e1e3"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision    Recall        F1  Sensitivity  Specificity  \\\n","0        0  0.526801   0.526756  0.527638  0.527197     0.527638     0.525963   \n","1        1  0.571328   0.556805  0.699153  0.619912     0.699153     0.443503   \n","2        2  0.605422   0.615385  0.562249  0.587618     0.562249     0.648594   \n","3        0  0.553601   0.549689  0.592965  0.570508     0.592965     0.514238   \n","4        1  0.567797   0.571006  0.545198  0.557803     0.545198     0.590395   \n","5        2  0.610442   0.638889  0.508032  0.565996     0.508032     0.712851   \n","6        0  0.557789   0.565714  0.497487  0.529412     0.497487     0.618090   \n","7        1  0.579802   0.575033  0.611582  0.592745     0.611582     0.548023   \n","8        2  0.614458   0.699301  0.401606  0.510204     0.401606     0.827309   \n","9        0  0.567839   0.587097  0.457286  0.514124     0.457286     0.678392   \n","10       1  0.605226   0.612708  0.572034  0.591673     0.572034     0.638418   \n","11       2  0.618474   0.641148  0.538153  0.585153     0.538153     0.698795   \n","12       0  0.597152   0.617409  0.510888  0.559120     0.510888     0.683417   \n","13       1  0.624294   0.687234  0.456215  0.548387     0.456215     0.792373   \n","14       2  0.643574   0.700280  0.502008  0.584795     0.502008     0.785141   \n","\n","       Kappa  \n","0   0.053601  \n","1   0.142655  \n","2   0.210843  \n","3   0.107203  \n","4   0.135593  \n","5   0.220884  \n","6   0.115578  \n","7   0.159605  \n","8   0.228916  \n","9   0.135678  \n","10  0.210452  \n","11  0.236948  \n","12  0.194305  \n","13  0.248588  \n","14  0.287149  "],"text/html":["\n","  <div id=\"df-8144e323-6bdf-4969-87a1-c67b00603ee7\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.526801</td>\n","      <td>0.526756</td>\n","      <td>0.527638</td>\n","      <td>0.527197</td>\n","      <td>0.527638</td>\n","      <td>0.525963</td>\n","      <td>0.053601</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.571328</td>\n","      <td>0.556805</td>\n","      <td>0.699153</td>\n","      <td>0.619912</td>\n","      <td>0.699153</td>\n","      <td>0.443503</td>\n","      <td>0.142655</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.605422</td>\n","      <td>0.615385</td>\n","      <td>0.562249</td>\n","      <td>0.587618</td>\n","      <td>0.562249</td>\n","      <td>0.648594</td>\n","      <td>0.210843</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.553601</td>\n","      <td>0.549689</td>\n","      <td>0.592965</td>\n","      <td>0.570508</td>\n","      <td>0.592965</td>\n","      <td>0.514238</td>\n","      <td>0.107203</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.567797</td>\n","      <td>0.571006</td>\n","      <td>0.545198</td>\n","      <td>0.557803</td>\n","      <td>0.545198</td>\n","      <td>0.590395</td>\n","      <td>0.135593</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.610442</td>\n","      <td>0.638889</td>\n","      <td>0.508032</td>\n","      <td>0.565996</td>\n","      <td>0.508032</td>\n","      <td>0.712851</td>\n","      <td>0.220884</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.557789</td>\n","      <td>0.565714</td>\n","      <td>0.497487</td>\n","      <td>0.529412</td>\n","      <td>0.497487</td>\n","      <td>0.618090</td>\n","      <td>0.115578</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.579802</td>\n","      <td>0.575033</td>\n","      <td>0.611582</td>\n","      <td>0.592745</td>\n","      <td>0.611582</td>\n","      <td>0.548023</td>\n","      <td>0.159605</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.614458</td>\n","      <td>0.699301</td>\n","      <td>0.401606</td>\n","      <td>0.510204</td>\n","      <td>0.401606</td>\n","      <td>0.827309</td>\n","      <td>0.228916</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.567839</td>\n","      <td>0.587097</td>\n","      <td>0.457286</td>\n","      <td>0.514124</td>\n","      <td>0.457286</td>\n","      <td>0.678392</td>\n","      <td>0.135678</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.605226</td>\n","      <td>0.612708</td>\n","      <td>0.572034</td>\n","      <td>0.591673</td>\n","      <td>0.572034</td>\n","      <td>0.638418</td>\n","      <td>0.210452</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.618474</td>\n","      <td>0.641148</td>\n","      <td>0.538153</td>\n","      <td>0.585153</td>\n","      <td>0.538153</td>\n","      <td>0.698795</td>\n","      <td>0.236948</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.597152</td>\n","      <td>0.617409</td>\n","      <td>0.510888</td>\n","      <td>0.559120</td>\n","      <td>0.510888</td>\n","      <td>0.683417</td>\n","      <td>0.194305</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.624294</td>\n","      <td>0.687234</td>\n","      <td>0.456215</td>\n","      <td>0.548387</td>\n","      <td>0.456215</td>\n","      <td>0.792373</td>\n","      <td>0.248588</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.643574</td>\n","      <td>0.700280</td>\n","      <td>0.502008</td>\n","      <td>0.584795</td>\n","      <td>0.502008</td>\n","      <td>0.785141</td>\n","      <td>0.287149</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8144e323-6bdf-4969-87a1-c67b00603ee7')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8144e323-6bdf-4969-87a1-c67b00603ee7 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8144e323-6bdf-4969-87a1-c67b00603ee7');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d6982aac-8ae8-439c-a491-3020dc81a600\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6982aac-8ae8-439c-a491-3020dc81a600')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d6982aac-8ae8-439c-a491-3020dc81a600 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"metrics_df_gru","summary":"{\n  \"name\": \"metrics_df_gru\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03183081291406457,\n        \"min\": 0.5268006700167505,\n        \"max\": 0.643574297188755,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.5678391959798995,\n          0.6184738955823293,\n          0.5268006700167505\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05516843105919211,\n        \"min\": 0.5267558528428093,\n        \"max\": 0.7002801120448179,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.5870967741935483,\n          0.6411483253588517,\n          0.5267558528428093\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07180189005259298,\n        \"min\": 0.40160642570281124,\n        \"max\": 0.6991525423728814,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.457286432160804,\n          0.5381526104417671,\n          0.5276381909547738\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03209910723045005,\n        \"min\": 0.510204081632653,\n        \"max\": 0.6199123356293049,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.5141242937853108,\n          0.5851528384279476,\n          0.5271966527196652\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07180189005259298,\n        \"min\": 0.40160642570281124,\n        \"max\": 0.6991525423728814,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.457286432160804,\n          0.5381526104417671,\n          0.5276381909547738\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11008362362294274,\n        \"min\": 0.4435028248587571,\n        \"max\": 0.8273092369477911,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.678391959798995,\n          0.6987951807228916,\n          0.525963149078727\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06366162582812915,\n        \"min\": 0.05360134003350081,\n        \"max\": 0.28714859437751006,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.13567839195979903,\n          0.23694779116465858,\n          0.05360134003350081\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["metrics_df_gru.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/DWT/CNN_GRU/Alpha_DWT_GRU.csv', index = False)"],"metadata":{"id":"QWSx6aHR5Bwr","executionInfo":{"status":"ok","timestamp":1717530984348,"user_tz":-360,"elapsed":5,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["print('hello')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zDNgj2wFmwqH","executionInfo":{"status":"ok","timestamp":1717531066202,"user_tz":-360,"elapsed":525,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"outputId":"8f325435-b87f-45b5-d4a8-e498b92a9919"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["hello\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"o3TQg_ht1Dri"},"execution_count":null,"outputs":[]}]}