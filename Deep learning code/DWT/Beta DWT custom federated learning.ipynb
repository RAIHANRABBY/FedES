{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["ZUR_QwblhNjJ"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Mbfw8uvdftFM"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sb"]},{"cell_type":"code","source":["from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"INiFJfLjgOkx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score, cross_val_predict"],"metadata":{"id":"lYo2Uq77gQSH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPool1D, Flatten, Dropout,LSTM"],"metadata":{"id":"g66575_xgVzz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MOCNWlamfr3v","executionInfo":{"status":"ok","timestamp":1717527774876,"user_tz":-360,"elapsed":34651,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}},"outputId":"bbb2f613-d05e-4c8e-fecd-4e72aacb5d13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Raw_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/only data/raw_data.npz'\n","\n","Theta_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/DWT/Raw/Beta_DWT.npz'\n","\n","\n","\n","# RAW = np.load(Raw_data, allow_pickle=True)  # Allow loading pickled object arrays\n","# X = RAW['X'].astype('float64')\n","# Y = RAW['Y'].astype('float64')\n","# group = RAW['Group'].astype('float64')"],"metadata":{"id":"iNy9eOGMf2qO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This is a good performing model"],"metadata":{"id":"PzeABzSyHgKg"}},{"cell_type":"code","source":["# %%capture\n","# !pip install wandb"],"metadata":{"id":"2w6s3AKGZFZ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import wandb\n","# !wandb login"],"metadata":{"id":"ctC5cKBgZHNk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CNN-LSTM"],"metadata":{"id":"6DhAYwXUSE9z"}},{"cell_type":"code","source":["%%capture\n","!pip install tensorflow_addons"],"metadata":{"id":"fxwgRS-C1tES"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Beta/CNN_LSTM/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Beta/CNN_LSTM/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"-kPJ3TCp9vdp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717527782223,"user_tz":-360,"elapsed":23,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}},"outputId":"c9159a7a-0677-4f5b-fa83-4672dbf98321"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["global_model, metrics_df = federated_learning(Theta_data)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVURUnmYNNNg","outputId":"c5fa068a-9fd0-4eeb-fd04-70b99c93c839","executionInfo":{"status":"ok","timestamp":1717529153003,"user_tz":-360,"elapsed":472594,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}}},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 1.7698 - accuracy: 0.4983"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 24s 92ms/step - loss: 1.7678 - accuracy: 0.4987 - val_loss: 1.7085 - val_accuracy: 0.5151\n","Epoch 2/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.6574 - accuracy: 0.4987 - val_loss: 1.6040 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.5565 - accuracy: 0.5339 - val_loss: 1.5092 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.4616 - accuracy: 0.5765 - val_loss: 1.4252 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3475 - accuracy: 0.6395 - val_loss: 1.3572 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.2494 - accuracy: 0.6641 - val_loss: 1.3033 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1851 - accuracy: 0.6754 - val_loss: 1.2448 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1317 - accuracy: 0.6837 - val_loss: 1.2062 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0884 - accuracy: 0.6805 - val_loss: 1.1655 - val_accuracy: 0.4849\n","Epoch 10/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0369 - accuracy: 0.6959 - val_loss: 1.1317 - val_accuracy: 0.4849\n","Epoch 11/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0010 - accuracy: 0.6994 - val_loss: 1.0756 - val_accuracy: 0.5032\n","Epoch 12/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9810 - accuracy: 0.6872 - val_loss: 1.0686 - val_accuracy: 0.4849\n","Epoch 13/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9353 - accuracy: 0.7004 - val_loss: 1.0711 - val_accuracy: 0.4849\n","Epoch 14/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9132 - accuracy: 0.6964 - val_loss: 1.0312 - val_accuracy: 0.4838\n","Epoch 15/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8844 - accuracy: 0.6983 - val_loss: 0.9802 - val_accuracy: 0.5086\n","Epoch 16/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8650 - accuracy: 0.6991 - val_loss: 0.9865 - val_accuracy: 0.4946\n","Epoch 17/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.8428 - accuracy: 0.7058 - val_loss: 0.9379 - val_accuracy: 0.5269\n","Epoch 18/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8316 - accuracy: 0.6923 - val_loss: 0.9758 - val_accuracy: 0.4957\n","Epoch 19/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.8145 - accuracy: 0.6988 - val_loss: 0.8973 - val_accuracy: 0.5582\n","Epoch 20/100\n","29/29 [==============================] - 1s 35ms/step - loss: 0.7910 - accuracy: 0.7115 - val_loss: 0.8529 - val_accuracy: 0.6056\n","Epoch 21/100\n","29/29 [==============================] - 1s 42ms/step - loss: 0.7972 - accuracy: 0.6942 - val_loss: 0.8772 - val_accuracy: 0.5754\n","Epoch 22/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.7692 - accuracy: 0.7058 - val_loss: 0.8581 - val_accuracy: 0.5787\n","Epoch 23/100\n","29/29 [==============================] - 1s 51ms/step - loss: 0.7598 - accuracy: 0.7042 - val_loss: 0.7668 - val_accuracy: 0.6972\n","Epoch 24/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.7402 - accuracy: 0.7115 - val_loss: 0.7679 - val_accuracy: 0.6832\n","Epoch 25/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7465 - accuracy: 0.6932 - val_loss: 0.7686 - val_accuracy: 0.6703\n","Epoch 26/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7448 - accuracy: 0.6907 - val_loss: 0.7737 - val_accuracy: 0.6616\n","Epoch 27/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.7148 - accuracy: 0.7139 - val_loss: 0.7303 - val_accuracy: 0.7004\n","Epoch 28/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.7109 - accuracy: 0.7082 - val_loss: 0.7120 - val_accuracy: 0.7091\n","Epoch 29/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7033 - accuracy: 0.7091 - val_loss: 0.7088 - val_accuracy: 0.7037\n","Epoch 30/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6943 - accuracy: 0.7123 - val_loss: 0.7033 - val_accuracy: 0.6983\n","Epoch 31/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6917 - accuracy: 0.7123 - val_loss: 0.6954 - val_accuracy: 0.7069\n","Epoch 32/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6776 - accuracy: 0.7220 - val_loss: 0.6978 - val_accuracy: 0.7047\n","Epoch 33/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6714 - accuracy: 0.7171 - val_loss: 0.6906 - val_accuracy: 0.7015\n","Epoch 34/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6705 - accuracy: 0.7101 - val_loss: 0.6816 - val_accuracy: 0.7058\n","Epoch 35/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6672 - accuracy: 0.7158 - val_loss: 0.6863 - val_accuracy: 0.7015\n","Epoch 36/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6592 - accuracy: 0.7126 - val_loss: 0.6853 - val_accuracy: 0.6875\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6518 - accuracy: 0.7188 - val_loss: 0.6759 - val_accuracy: 0.7058\n","Epoch 38/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6514 - accuracy: 0.7241 - val_loss: 0.6804 - val_accuracy: 0.7004\n","Epoch 39/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6469 - accuracy: 0.7231 - val_loss: 0.6689 - val_accuracy: 0.6897\n","Epoch 40/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6314 - accuracy: 0.7231 - val_loss: 0.6621 - val_accuracy: 0.7112\n","Epoch 41/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6307 - accuracy: 0.7252 - val_loss: 0.7026 - val_accuracy: 0.6573\n","Epoch 42/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6329 - accuracy: 0.7204 - val_loss: 0.7175 - val_accuracy: 0.6466\n","Epoch 43/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6437 - accuracy: 0.7147 - val_loss: 0.6664 - val_accuracy: 0.6972\n","Epoch 44/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6193 - accuracy: 0.7198 - val_loss: 0.6525 - val_accuracy: 0.6983\n","Epoch 45/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6237 - accuracy: 0.7228 - val_loss: 0.6507 - val_accuracy: 0.7047\n","Epoch 46/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6129 - accuracy: 0.7244 - val_loss: 0.7255 - val_accuracy: 0.6703\n","Epoch 47/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6145 - accuracy: 0.7255 - val_loss: 0.6569 - val_accuracy: 0.6950\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6106 - accuracy: 0.7263 - val_loss: 0.6428 - val_accuracy: 0.7080\n","Epoch 49/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5942 - accuracy: 0.7368 - val_loss: 0.6464 - val_accuracy: 0.7069\n","Epoch 50/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5975 - accuracy: 0.7322 - val_loss: 0.6517 - val_accuracy: 0.6961\n","Epoch 51/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6065 - accuracy: 0.7306 - val_loss: 0.6524 - val_accuracy: 0.6961\n","Epoch 52/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5890 - accuracy: 0.7338 - val_loss: 0.6579 - val_accuracy: 0.7080\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5872 - accuracy: 0.7400 - val_loss: 0.6804 - val_accuracy: 0.6670\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5951 - accuracy: 0.7336 - val_loss: 0.6415 - val_accuracy: 0.7004\n","Epoch 55/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5679 - accuracy: 0.7438 - val_loss: 0.6681 - val_accuracy: 0.7004\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5624 - accuracy: 0.7548 - val_loss: 0.6311 - val_accuracy: 0.7091\n","Epoch 57/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5594 - accuracy: 0.7487 - val_loss: 0.6529 - val_accuracy: 0.7037\n","Epoch 58/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5702 - accuracy: 0.7411 - val_loss: 0.6415 - val_accuracy: 0.7004\n","Epoch 59/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5674 - accuracy: 0.7478 - val_loss: 0.6397 - val_accuracy: 0.7112\n","Epoch 60/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5622 - accuracy: 0.7505 - val_loss: 0.6314 - val_accuracy: 0.7112\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5580 - accuracy: 0.7511 - val_loss: 0.6316 - val_accuracy: 0.7037\n","Epoch 62/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5461 - accuracy: 0.7530 - val_loss: 0.6359 - val_accuracy: 0.7047\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5463 - accuracy: 0.7567 - val_loss: 0.6636 - val_accuracy: 0.7037\n","Epoch 64/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5333 - accuracy: 0.7645 - val_loss: 0.7272 - val_accuracy: 0.6983\n","Epoch 65/100\n","29/29 [==============================] - 2s 62ms/step - loss: 0.5316 - accuracy: 0.7619 - val_loss: 0.6341 - val_accuracy: 0.7134\n","Epoch 66/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5422 - accuracy: 0.7570 - val_loss: 0.6287 - val_accuracy: 0.7026\n","Epoch 67/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5214 - accuracy: 0.7697 - val_loss: 0.7082 - val_accuracy: 0.6907\n","Epoch 68/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5066 - accuracy: 0.7748 - val_loss: 0.6738 - val_accuracy: 0.6983\n","Epoch 69/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4945 - accuracy: 0.7812 - val_loss: 0.7647 - val_accuracy: 0.6950\n","Epoch 70/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5115 - accuracy: 0.7699 - val_loss: 0.7245 - val_accuracy: 0.6961\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5167 - accuracy: 0.7645 - val_loss: 0.6657 - val_accuracy: 0.7058\n","Epoch 72/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4998 - accuracy: 0.7799 - val_loss: 0.6389 - val_accuracy: 0.7101\n","Epoch 73/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4829 - accuracy: 0.7907 - val_loss: 0.7017 - val_accuracy: 0.7080\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4778 - accuracy: 0.7974 - val_loss: 0.7119 - val_accuracy: 0.6994\n","Epoch 75/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4644 - accuracy: 0.8028 - val_loss: 0.6745 - val_accuracy: 0.7112\n","Epoch 76/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4501 - accuracy: 0.8082 - val_loss: 0.6788 - val_accuracy: 0.7188\n","Epoch 77/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4434 - accuracy: 0.8112 - val_loss: 0.6718 - val_accuracy: 0.7112\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4437 - accuracy: 0.8147 - val_loss: 0.7168 - val_accuracy: 0.6886\n","Epoch 79/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4591 - accuracy: 0.8001 - val_loss: 0.6409 - val_accuracy: 0.7080\n","Epoch 80/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4588 - accuracy: 0.8031 - val_loss: 0.6670 - val_accuracy: 0.6950\n","Epoch 81/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4301 - accuracy: 0.8217 - val_loss: 0.7258 - val_accuracy: 0.7004\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4257 - accuracy: 0.8233 - val_loss: 0.6981 - val_accuracy: 0.7155\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4088 - accuracy: 0.8343 - val_loss: 0.7343 - val_accuracy: 0.7155\n","Epoch 84/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3980 - accuracy: 0.8384 - val_loss: 0.7926 - val_accuracy: 0.6972\n","Epoch 85/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4171 - accuracy: 0.8289 - val_loss: 0.7532 - val_accuracy: 0.6972\n","Epoch 86/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3792 - accuracy: 0.8402 - val_loss: 0.7529 - val_accuracy: 0.7058\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4073 - accuracy: 0.8297 - val_loss: 0.6982 - val_accuracy: 0.6800\n","Epoch 88/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3803 - accuracy: 0.8454 - val_loss: 0.7923 - val_accuracy: 0.7155\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3651 - accuracy: 0.8556 - val_loss: 0.8891 - val_accuracy: 0.7177\n","Epoch 90/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3439 - accuracy: 0.8631 - val_loss: 0.9113 - val_accuracy: 0.7134\n","Epoch 91/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3455 - accuracy: 0.8634 - val_loss: 0.9865 - val_accuracy: 0.6789\n","Epoch 92/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3694 - accuracy: 0.8508 - val_loss: 0.8441 - val_accuracy: 0.7037\n","Epoch 93/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3443 - accuracy: 0.8564 - val_loss: 0.7488 - val_accuracy: 0.6864\n","Epoch 94/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3234 - accuracy: 0.8780 - val_loss: 0.8102 - val_accuracy: 0.6940\n","Epoch 95/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2988 - accuracy: 0.8858 - val_loss: 0.8273 - val_accuracy: 0.7123\n","Epoch 96/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3181 - accuracy: 0.8774 - val_loss: 0.9757 - val_accuracy: 0.6983\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3043 - accuracy: 0.8798 - val_loss: 0.9036 - val_accuracy: 0.7047\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2903 - accuracy: 0.8885 - val_loss: 0.8824 - val_accuracy: 0.6907\n","Epoch 99/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2746 - accuracy: 0.8955 - val_loss: 0.9722 - val_accuracy: 0.7080\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2679 - accuracy: 0.9009 - val_loss: 1.0391 - val_accuracy: 0.6897\n","{'loss': [1.7677648067474365, 1.6573599576950073, 1.5564550161361694, 1.461646318435669, 1.3475041389465332, 1.2494486570358276, 1.1850502490997314, 1.1317347288131714, 1.0884262323379517, 1.036891222000122, 1.001028060913086, 0.9810254573822021, 0.9352601170539856, 0.9132393598556519, 0.8843876123428345, 0.8650283813476562, 0.8428410291671753, 0.8315962553024292, 0.8145204186439514, 0.7910307049751282, 0.7971566319465637, 0.7691986560821533, 0.7597781419754028, 0.7401500344276428, 0.7464578747749329, 0.7448195815086365, 0.7148362994194031, 0.7108514904975891, 0.7033392786979675, 0.694299578666687, 0.6916849613189697, 0.6775597333908081, 0.6713887453079224, 0.6705282926559448, 0.6671789288520813, 0.6591563820838928, 0.6518304347991943, 0.6513744592666626, 0.64687579870224, 0.6314349174499512, 0.6307142376899719, 0.6328843832015991, 0.6437082886695862, 0.6192847490310669, 0.6237272024154663, 0.612909197807312, 0.614504873752594, 0.6106095314025879, 0.5941683053970337, 0.5974667072296143, 0.6064541935920715, 0.5890306234359741, 0.5871951580047607, 0.5951277613639832, 0.5678539872169495, 0.5623946785926819, 0.5593522191047668, 0.5701826810836792, 0.5674252510070801, 0.562152624130249, 0.5580081939697266, 0.5460793972015381, 0.5462831258773804, 0.5332645177841187, 0.5316480994224548, 0.5422428846359253, 0.5214462876319885, 0.5066008567810059, 0.49453890323638916, 0.5115001797676086, 0.5167400240898132, 0.499759316444397, 0.482861191034317, 0.4778207540512085, 0.46443960070610046, 0.4500609040260315, 0.4434273838996887, 0.4437430799007416, 0.45910578966140747, 0.45876434445381165, 0.43008798360824585, 0.4257441461086273, 0.40884244441986084, 0.39800941944122314, 0.41705405712127686, 0.37921831011772156, 0.40732342004776, 0.3802700638771057, 0.3651396632194519, 0.34387028217315674, 0.34548747539520264, 0.369423508644104, 0.3442757725715637, 0.3234364688396454, 0.29876506328582764, 0.3180820345878601, 0.3043058514595032, 0.2902596890926361, 0.2745700776576996, 0.26791515946388245], 'accuracy': [0.49865302443504333, 0.49865302443504333, 0.5339439511299133, 0.576508641242981, 0.6395474076271057, 0.6640625, 0.6753771305084229, 0.6837284564971924, 0.6804956793785095, 0.6958512663841248, 0.6993534564971924, 0.6872305870056152, 0.7004310488700867, 0.6963900923728943, 0.6982758641242981, 0.6990840435028076, 0.7058189511299133, 0.6923491358757019, 0.6988146305084229, 0.7114762663841248, 0.6942349076271057, 0.7058189511299133, 0.7042025923728943, 0.7114762663841248, 0.6931573152542114, 0.6907327771186829, 0.7139008641242981, 0.7082435488700867, 0.7090517282485962, 0.712284505367279, 0.712284505367279, 0.7219827771186829, 0.717133641242981, 0.7101293206214905, 0.7157866358757019, 0.712553858757019, 0.71875, 0.7241379022598267, 0.7230603694915771, 0.7230603694915771, 0.725215494632721, 0.720366358757019, 0.7147090435028076, 0.7198275923728943, 0.7227909564971924, 0.7244073152542114, 0.7254849076271057, 0.7262930870056152, 0.7367995977401733, 0.7322198152542114, 0.7306034564971924, 0.7338362336158752, 0.7400323152542114, 0.7335668206214905, 0.743803858757019, 0.7548491358757019, 0.748652994632721, 0.7411099076271057, 0.7478448152542114, 0.7505387663841248, 0.7510775923728943, 0.7529633641242981, 0.7567349076271057, 0.7645474076271057, 0.7618534564971924, 0.7570043206214905, 0.7696659564971924, 0.774784505367279, 0.78125, 0.7699353694915771, 0.7645474076271057, 0.779902994632721, 0.790678858757019, 0.7974137663841248, 0.8028017282485962, 0.8081896305084229, 0.811152994632721, 0.8146551847457886, 0.8001077771186829, 0.803071141242981, 0.821659505367279, 0.8232758641242981, 0.834321141242981, 0.8383620977401733, 0.8289331793785095, 0.8402478694915771, 0.829741358757019, 0.845366358757019, 0.8556034564971924, 0.8631465435028076, 0.8634159564971924, 0.8507543206214905, 0.8564116358757019, 0.8779633641242981, 0.8857758641242981, 0.8774245977401733, 0.8798491358757019, 0.8884698152542114, 0.8954741358757019, 0.9008620977401733], 'val_loss': [1.708465576171875, 1.60395348072052, 1.5091530084609985, 1.4251577854156494, 1.3571932315826416, 1.3032630681991577, 1.2447597980499268, 1.2062324285507202, 1.1654983758926392, 1.1317098140716553, 1.07563316822052, 1.068565011024475, 1.0711448192596436, 1.0311821699142456, 0.980191171169281, 0.9865396618843079, 0.9379482865333557, 0.9758328795433044, 0.8972518444061279, 0.8529438376426697, 0.877196729183197, 0.8581122159957886, 0.7668289542198181, 0.7678971886634827, 0.7685672640800476, 0.7737261652946472, 0.7303319573402405, 0.7120482921600342, 0.7088006734848022, 0.7032514214515686, 0.6953672170639038, 0.6978440284729004, 0.6905542016029358, 0.6815717816352844, 0.6863376498222351, 0.6853037476539612, 0.675902247428894, 0.680397629737854, 0.6688964366912842, 0.6620931029319763, 0.7025770545005798, 0.7174533605575562, 0.6664024591445923, 0.6524685025215149, 0.6507079005241394, 0.725486159324646, 0.6569094657897949, 0.6428142786026001, 0.6463971734046936, 0.6517015099525452, 0.6523905992507935, 0.6579280495643616, 0.6803890466690063, 0.6415324807167053, 0.6681285500526428, 0.6310511231422424, 0.652940571308136, 0.6414958834648132, 0.6396864056587219, 0.6314388513565063, 0.6316450834274292, 0.6358604431152344, 0.6636496782302856, 0.7272472381591797, 0.6340962052345276, 0.6287023425102234, 0.708215594291687, 0.6737582087516785, 0.7647388577461243, 0.724513590335846, 0.6657418012619019, 0.6389079689979553, 0.701727569103241, 0.7118824124336243, 0.6745385527610779, 0.6787508130073547, 0.6718323230743408, 0.7168445587158203, 0.640860378742218, 0.6670248508453369, 0.7258322238922119, 0.6981456875801086, 0.7342826724052429, 0.7925574779510498, 0.7532488703727722, 0.7528617978096008, 0.6982141137123108, 0.7922887206077576, 0.8890703320503235, 0.9112793207168579, 0.9864755272865295, 0.8441022634506226, 0.7487597465515137, 0.810226559638977, 0.827287495136261, 0.9757044315338135, 0.9036398530006409, 0.882369339466095, 0.9721853733062744, 1.039108157157898], 'val_accuracy': [0.5150862336158752, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.5032327771186829, 0.48491379618644714, 0.48491379618644714, 0.48383620381355286, 0.5086206793785095, 0.49461206793785095, 0.5269396305084229, 0.49568966031074524, 0.5581896305084229, 0.6056034564971924, 0.5754310488700867, 0.5786637663841248, 0.6971982717514038, 0.6831896305084229, 0.670258641242981, 0.6616379022598267, 0.7004310488700867, 0.7090517282485962, 0.7036637663841248, 0.6982758641242981, 0.7068965435028076, 0.704741358757019, 0.701508641242981, 0.7058189511299133, 0.701508641242981, 0.6875, 0.7058189511299133, 0.7004310488700867, 0.6896551847457886, 0.7112069129943848, 0.6573275923728943, 0.6465517282485962, 0.6971982717514038, 0.6982758641242981, 0.704741358757019, 0.670258641242981, 0.6950430870056152, 0.7079741358757019, 0.7068965435028076, 0.6961206793785095, 0.6961206793785095, 0.7079741358757019, 0.6670258641242981, 0.7004310488700867, 0.7004310488700867, 0.7090517282485962, 0.7036637663841248, 0.7004310488700867, 0.7112069129943848, 0.7112069129943848, 0.7036637663841248, 0.704741358757019, 0.7036637663841248, 0.6982758641242981, 0.7133620977401733, 0.7025862336158752, 0.6907327771186829, 0.6982758641242981, 0.6950430870056152, 0.6961206793785095, 0.7058189511299133, 0.7101293206214905, 0.7079741358757019, 0.6993534564971924, 0.7112069129943848, 0.71875, 0.7112069129943848, 0.6885775923728943, 0.7079741358757019, 0.6950430870056152, 0.7004310488700867, 0.7155172228813171, 0.7155172228813171, 0.6971982717514038, 0.6971982717514038, 0.7058189511299133, 0.6799569129943848, 0.7155172228813171, 0.7176724076271057, 0.7133620977401733, 0.6788793206214905, 0.7036637663841248, 0.6864224076271057, 0.693965494632721, 0.712284505367279, 0.6982758641242981, 0.704741358757019, 0.6907327771186829, 0.7079741358757019, 0.6896551847457886]}\n","38/38 [==============================] - 1s 10ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 1.7692 - accuracy: 0.5096"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 10s 87ms/step - loss: 1.7692 - accuracy: 0.5096 - val_loss: 1.7112 - val_accuracy: 0.5045\n","Epoch 2/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.6631 - accuracy: 0.5003 - val_loss: 1.6122 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.5623 - accuracy: 0.5860 - val_loss: 1.5236 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.4448 - accuracy: 0.6381 - val_loss: 1.4442 - val_accuracy: 0.5317\n","Epoch 5/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.3475 - accuracy: 0.6579 - val_loss: 1.3849 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2790 - accuracy: 0.6729 - val_loss: 1.3290 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2327 - accuracy: 0.6556 - val_loss: 1.2797 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1692 - accuracy: 0.6845 - val_loss: 1.2348 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1326 - accuracy: 0.6794 - val_loss: 1.1856 - val_accuracy: 0.5260\n","Epoch 10/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0953 - accuracy: 0.6695 - val_loss: 1.1566 - val_accuracy: 0.4966\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0672 - accuracy: 0.6658 - val_loss: 1.1143 - val_accuracy: 0.5305\n","Epoch 12/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.0202 - accuracy: 0.6851 - val_loss: 1.0833 - val_accuracy: 0.5170\n","Epoch 13/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.9971 - accuracy: 0.6822 - val_loss: 1.0474 - val_accuracy: 0.6086\n","Epoch 14/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9739 - accuracy: 0.6757 - val_loss: 1.0208 - val_accuracy: 0.5577\n","Epoch 15/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9401 - accuracy: 0.6853 - val_loss: 0.9934 - val_accuracy: 0.5713\n","Epoch 16/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9324 - accuracy: 0.6661 - val_loss: 0.9876 - val_accuracy: 0.5215\n","Epoch 17/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.8958 - accuracy: 0.6913 - val_loss: 0.9383 - val_accuracy: 0.6244\n","Epoch 18/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8800 - accuracy: 0.6873 - val_loss: 0.9473 - val_accuracy: 0.5362\n","Epoch 19/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8717 - accuracy: 0.6757 - val_loss: 0.9086 - val_accuracy: 0.6007\n","Epoch 20/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.8457 - accuracy: 0.6904 - val_loss: 0.8722 - val_accuracy: 0.6652\n","Epoch 21/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.8279 - accuracy: 0.6950 - val_loss: 0.8495 - val_accuracy: 0.6719\n","Epoch 22/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8141 - accuracy: 0.6941 - val_loss: 0.8345 - val_accuracy: 0.6708\n","Epoch 23/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.8036 - accuracy: 0.6902 - val_loss: 0.8168 - val_accuracy: 0.6912\n","Epoch 24/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7935 - accuracy: 0.6975 - val_loss: 0.7990 - val_accuracy: 0.6889\n","Epoch 25/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.7773 - accuracy: 0.6986 - val_loss: 0.7784 - val_accuracy: 0.7025\n","Epoch 26/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7785 - accuracy: 0.6935 - val_loss: 0.7909 - val_accuracy: 0.6799\n","Epoch 27/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7577 - accuracy: 0.7046 - val_loss: 0.7681 - val_accuracy: 0.6821\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7453 - accuracy: 0.7097 - val_loss: 0.7602 - val_accuracy: 0.6878\n","Epoch 29/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7358 - accuracy: 0.7105 - val_loss: 0.7691 - val_accuracy: 0.6787\n","Epoch 30/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7475 - accuracy: 0.6933 - val_loss: 0.7444 - val_accuracy: 0.6867\n","Epoch 31/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7202 - accuracy: 0.7153 - val_loss: 0.7616 - val_accuracy: 0.6697\n","Epoch 32/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.7192 - accuracy: 0.7077 - val_loss: 0.7815 - val_accuracy: 0.6301\n","Epoch 33/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7078 - accuracy: 0.7122 - val_loss: 0.7233 - val_accuracy: 0.6934\n","Epoch 34/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6906 - accuracy: 0.7207 - val_loss: 0.7153 - val_accuracy: 0.7014\n","Epoch 35/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6875 - accuracy: 0.7196 - val_loss: 0.7293 - val_accuracy: 0.6697\n","Epoch 36/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6854 - accuracy: 0.7151 - val_loss: 0.7091 - val_accuracy: 0.6878\n","Epoch 37/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6807 - accuracy: 0.7168 - val_loss: 0.7137 - val_accuracy: 0.6980\n","Epoch 38/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6673 - accuracy: 0.7193 - val_loss: 0.7326 - val_accuracy: 0.6810\n","Epoch 39/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6646 - accuracy: 0.7250 - val_loss: 0.7178 - val_accuracy: 0.6753\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6550 - accuracy: 0.7292 - val_loss: 0.7528 - val_accuracy: 0.6561\n","Epoch 41/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6690 - accuracy: 0.7148 - val_loss: 0.7019 - val_accuracy: 0.6867\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6461 - accuracy: 0.7295 - val_loss: 0.6977 - val_accuracy: 0.6900\n","Epoch 43/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6367 - accuracy: 0.7354 - val_loss: 0.6977 - val_accuracy: 0.6946\n","Epoch 44/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6377 - accuracy: 0.7303 - val_loss: 0.6935 - val_accuracy: 0.6821\n","Epoch 45/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6391 - accuracy: 0.7247 - val_loss: 0.6963 - val_accuracy: 0.6799\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6202 - accuracy: 0.7459 - val_loss: 0.6934 - val_accuracy: 0.6731\n","Epoch 47/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6193 - accuracy: 0.7419 - val_loss: 0.6958 - val_accuracy: 0.6776\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6116 - accuracy: 0.7496 - val_loss: 0.6733 - val_accuracy: 0.6991\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6279 - accuracy: 0.7326 - val_loss: 0.6707 - val_accuracy: 0.7025\n","Epoch 50/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6071 - accuracy: 0.7473 - val_loss: 0.6800 - val_accuracy: 0.6844\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5869 - accuracy: 0.7564 - val_loss: 0.7923 - val_accuracy: 0.6357\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5948 - accuracy: 0.7516 - val_loss: 0.7396 - val_accuracy: 0.6708\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6156 - accuracy: 0.7343 - val_loss: 0.6659 - val_accuracy: 0.7002\n","Epoch 54/100\n","28/28 [==============================] - 2s 55ms/step - loss: 0.5899 - accuracy: 0.7538 - val_loss: 0.6656 - val_accuracy: 0.7127\n","Epoch 55/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5770 - accuracy: 0.7575 - val_loss: 0.6697 - val_accuracy: 0.7081\n","Epoch 56/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5616 - accuracy: 0.7634 - val_loss: 0.6586 - val_accuracy: 0.7048\n","Epoch 57/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5464 - accuracy: 0.7759 - val_loss: 0.6746 - val_accuracy: 0.6957\n","Epoch 58/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5540 - accuracy: 0.7716 - val_loss: 0.6963 - val_accuracy: 0.6561\n","Epoch 59/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5425 - accuracy: 0.7776 - val_loss: 0.6852 - val_accuracy: 0.6991\n","Epoch 60/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5414 - accuracy: 0.7773 - val_loss: 0.6847 - val_accuracy: 0.6957\n","Epoch 61/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5543 - accuracy: 0.7668 - val_loss: 0.8297 - val_accuracy: 0.6267\n","Epoch 62/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5375 - accuracy: 0.7770 - val_loss: 0.6821 - val_accuracy: 0.6799\n","Epoch 63/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5281 - accuracy: 0.7824 - val_loss: 0.7254 - val_accuracy: 0.6980\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5074 - accuracy: 0.8005 - val_loss: 0.7844 - val_accuracy: 0.6346\n","Epoch 65/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4942 - accuracy: 0.8039 - val_loss: 0.7452 - val_accuracy: 0.6765\n","Epoch 66/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4924 - accuracy: 0.8045 - val_loss: 0.6887 - val_accuracy: 0.6833\n","Epoch 67/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4927 - accuracy: 0.8081 - val_loss: 0.6678 - val_accuracy: 0.7002\n","Epoch 68/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.4923 - accuracy: 0.8073 - val_loss: 0.7177 - val_accuracy: 0.6742\n","Epoch 69/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5082 - accuracy: 0.7965 - val_loss: 0.7733 - val_accuracy: 0.6652\n","Epoch 70/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4584 - accuracy: 0.8214 - val_loss: 0.7200 - val_accuracy: 0.6787\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4379 - accuracy: 0.8387 - val_loss: 0.7789 - val_accuracy: 0.6731\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4289 - accuracy: 0.8381 - val_loss: 0.8102 - val_accuracy: 0.6595\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4379 - accuracy: 0.8294 - val_loss: 0.7537 - val_accuracy: 0.6912\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4193 - accuracy: 0.8410 - val_loss: 0.8377 - val_accuracy: 0.6493\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4270 - accuracy: 0.8404 - val_loss: 0.7943 - val_accuracy: 0.6765\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4140 - accuracy: 0.8466 - val_loss: 0.7662 - val_accuracy: 0.6889\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4120 - accuracy: 0.8455 - val_loss: 0.7778 - val_accuracy: 0.6776\n","Epoch 78/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3963 - accuracy: 0.8588 - val_loss: 0.7613 - val_accuracy: 0.6787\n","Epoch 79/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3585 - accuracy: 0.8727 - val_loss: 0.8806 - val_accuracy: 0.6799\n","Epoch 80/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4128 - accuracy: 0.8486 - val_loss: 0.8052 - val_accuracy: 0.6686\n","Epoch 81/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3785 - accuracy: 0.8602 - val_loss: 0.7912 - val_accuracy: 0.6844\n","Epoch 82/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3611 - accuracy: 0.8721 - val_loss: 0.8926 - val_accuracy: 0.6934\n","Epoch 83/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3622 - accuracy: 0.8792 - val_loss: 0.8899 - val_accuracy: 0.6912\n","Epoch 84/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3317 - accuracy: 0.8874 - val_loss: 0.9500 - val_accuracy: 0.6708\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3484 - accuracy: 0.8724 - val_loss: 0.8544 - val_accuracy: 0.6923\n","Epoch 86/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3243 - accuracy: 0.8933 - val_loss: 0.9022 - val_accuracy: 0.6753\n","Epoch 87/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3177 - accuracy: 0.8919 - val_loss: 0.8669 - val_accuracy: 0.6640\n","Epoch 88/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3007 - accuracy: 0.9018 - val_loss: 0.9808 - val_accuracy: 0.6516\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2731 - accuracy: 0.9148 - val_loss: 0.9530 - val_accuracy: 0.6765\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3023 - accuracy: 0.9004 - val_loss: 1.0318 - val_accuracy: 0.6572\n","Epoch 91/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2635 - accuracy: 0.9165 - val_loss: 1.0728 - val_accuracy: 0.6380\n","Epoch 92/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2846 - accuracy: 0.9109 - val_loss: 0.9781 - val_accuracy: 0.6787\n","Epoch 93/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2989 - accuracy: 0.9007 - val_loss: 0.8485 - val_accuracy: 0.6799\n","Epoch 94/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2704 - accuracy: 0.9117 - val_loss: 0.9524 - val_accuracy: 0.6719\n","Epoch 95/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2542 - accuracy: 0.9264 - val_loss: 1.0669 - val_accuracy: 0.6674\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2505 - accuracy: 0.9253 - val_loss: 0.9290 - val_accuracy: 0.6674\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2270 - accuracy: 0.9377 - val_loss: 1.2675 - val_accuracy: 0.6674\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2074 - accuracy: 0.9440 - val_loss: 1.1269 - val_accuracy: 0.6810\n","Epoch 99/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2341 - accuracy: 0.9310 - val_loss: 1.0420 - val_accuracy: 0.6889\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2414 - accuracy: 0.9242 - val_loss: 1.1359 - val_accuracy: 0.6663\n","{'loss': [1.76919686794281, 1.6630628108978271, 1.5623365640640259, 1.444846749305725, 1.3475033044815063, 1.279024600982666, 1.2327343225479126, 1.1692469120025635, 1.1326273679733276, 1.0952820777893066, 1.067163109779358, 1.0201884508132935, 0.997124433517456, 0.9739002585411072, 0.940114438533783, 0.9324312210083008, 0.8957849740982056, 0.8800160884857178, 0.8716729283332825, 0.8456888794898987, 0.8278594017028809, 0.8140552639961243, 0.8035523295402527, 0.7934643626213074, 0.7772989273071289, 0.7784876227378845, 0.7576866149902344, 0.7453272938728333, 0.7358031868934631, 0.7474517226219177, 0.7202203869819641, 0.7192440629005432, 0.7078068256378174, 0.6906235218048096, 0.6874696016311646, 0.6854187846183777, 0.6807073950767517, 0.667259693145752, 0.6645680665969849, 0.6550268530845642, 0.6690026521682739, 0.6460785269737244, 0.6367029547691345, 0.6376523971557617, 0.6391357779502869, 0.620167076587677, 0.619310200214386, 0.6115891933441162, 0.6278541684150696, 0.6071057915687561, 0.5868662595748901, 0.5947691798210144, 0.6156206130981445, 0.5898665189743042, 0.577049970626831, 0.5615765452384949, 0.5464333295822144, 0.5540373921394348, 0.5425025820732117, 0.5413779616355896, 0.5543191432952881, 0.5375404357910156, 0.5280619263648987, 0.507409930229187, 0.4942335784435272, 0.4923665225505829, 0.4926922619342804, 0.49233338236808777, 0.5081899166107178, 0.45842042565345764, 0.437909871339798, 0.4289010465145111, 0.4378902316093445, 0.419264018535614, 0.4269823133945465, 0.41402795910835266, 0.4120396375656128, 0.396266907453537, 0.3584887385368347, 0.4128318727016449, 0.3785135746002197, 0.3611248731613159, 0.36220860481262207, 0.33170443773269653, 0.3484000265598297, 0.3243062496185303, 0.3177054524421692, 0.30066704750061035, 0.27312034368515015, 0.30230674147605896, 0.2634730935096741, 0.2845595180988312, 0.29887834191322327, 0.27040570974349976, 0.25424355268478394, 0.2505037188529968, 0.22697825729846954, 0.20743609964847565, 0.23411893844604492, 0.24135443568229675], 'accuracy': [0.5096208453178406, 0.5002829432487488, 0.5860214829444885, 0.6380871534347534, 0.6578947305679321, 0.6728919148445129, 0.6556310057640076, 0.6844934821128845, 0.6794000864028931, 0.6694962978363037, 0.6658177971839905, 0.6850594282150269, 0.68222975730896, 0.6757215857505798, 0.6853423714637756, 0.6661007404327393, 0.6912846565246582, 0.6873231530189514, 0.6757215857505798, 0.6904357671737671, 0.6949632167816162, 0.6941143274307251, 0.6901528239250183, 0.6975098848342896, 0.6986417770385742, 0.6935483813285828, 0.7045840620994568, 0.7096773982048035, 0.7105262875556946, 0.693265438079834, 0.7153367400169373, 0.7076966762542725, 0.7122241258621216, 0.7207130789756775, 0.7195811867713928, 0.7150537371635437, 0.7167515754699707, 0.719298243522644, 0.7249575257301331, 0.7292020320892334, 0.7147707939147949, 0.7294849753379822, 0.7354272603988647, 0.7303339242935181, 0.7246745824813843, 0.7458969950675964, 0.7419354915618896, 0.7495755553245544, 0.7325976490974426, 0.7473118305206299, 0.7563667297363281, 0.7515563368797302, 0.7342954277992249, 0.7538200616836548, 0.757498562335968, 0.7634408473968506, 0.7758913636207581, 0.7716468572616577, 0.7775891423225403, 0.7773061394691467, 0.7668364644050598, 0.777023196220398, 0.7823995351791382, 0.8005093336105347, 0.8039049506187439, 0.8044708371162415, 0.8081493973731995, 0.8073005080223083, 0.7965478301048279, 0.821448802947998, 0.8387096524238586, 0.8381437659263611, 0.8293718099594116, 0.8409733772277832, 0.8404074907302856, 0.846632719039917, 0.8455008268356323, 0.8588002324104309, 0.872665524482727, 0.848613440990448, 0.8602150678634644, 0.8720995783805847, 0.879173755645752, 0.8873797655105591, 0.8723825812339783, 0.8933219909667969, 0.8919072151184082, 0.9018110036849976, 0.9148274064064026, 0.9003961682319641, 0.9165251851081848, 0.9108659029006958, 0.9006791114807129, 0.9117147922515869, 0.9264289736747742, 0.9252971410751343, 0.937747597694397, 0.9439728260040283, 0.9309564232826233, 0.9241652488708496], 'val_loss': [1.7111563682556152, 1.6122000217437744, 1.5235621929168701, 1.4441641569137573, 1.3849172592163086, 1.3290045261383057, 1.2797168493270874, 1.2347826957702637, 1.1856114864349365, 1.1565974950790405, 1.1142644882202148, 1.0832597017288208, 1.0474438667297363, 1.0207597017288208, 0.9933841824531555, 0.9875953197479248, 0.9383023381233215, 0.9472731351852417, 0.9085534811019897, 0.8722217679023743, 0.8495373129844666, 0.8345228433609009, 0.8167797923088074, 0.7990182042121887, 0.7784245014190674, 0.7908533811569214, 0.7681178450584412, 0.7602371573448181, 0.7691335082054138, 0.7444133758544922, 0.7616396546363831, 0.7814613580703735, 0.7233240008354187, 0.715307354927063, 0.7292737364768982, 0.7090779542922974, 0.7137464880943298, 0.7325530052185059, 0.7177684903144836, 0.7528129816055298, 0.701897382736206, 0.6976572871208191, 0.6977167725563049, 0.6934667825698853, 0.6963261961936951, 0.6934417486190796, 0.6958455443382263, 0.6733407974243164, 0.6706773042678833, 0.6799951195716858, 0.7922874689102173, 0.7395764589309692, 0.6658909320831299, 0.6655557155609131, 0.6696776151657104, 0.6585970520973206, 0.6745815277099609, 0.6963056325912476, 0.6851924061775208, 0.6846967339515686, 0.8296899795532227, 0.6821469664573669, 0.7254295945167542, 0.7843530178070068, 0.745213508605957, 0.6887487769126892, 0.6677894592285156, 0.7176735997200012, 0.7733290791511536, 0.7199720740318298, 0.778915524482727, 0.8102141618728638, 0.7537333369255066, 0.8377085328102112, 0.7942753434181213, 0.7661905884742737, 0.777823805809021, 0.761299729347229, 0.8806190490722656, 0.8052390217781067, 0.7912136316299438, 0.8926275372505188, 0.8899048566818237, 0.9499983191490173, 0.8544295430183411, 0.9022344946861267, 0.8668912053108215, 0.9807705879211426, 0.9530436396598816, 1.0318464040756226, 1.072768211364746, 0.9780642986297607, 0.8485205173492432, 0.9524287581443787, 1.0669400691986084, 0.9290302395820618, 1.2674598693847656, 1.126868486404419, 1.0420362949371338, 1.1359342336654663], 'val_accuracy': [0.5045248866081238, 0.4954751133918762, 0.4954751133918762, 0.5316742062568665, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.5260180830955505, 0.49660632014274597, 0.5305429697036743, 0.516968309879303, 0.6085972785949707, 0.557692289352417, 0.5712669491767883, 0.5214931964874268, 0.6244344115257263, 0.5361990928649902, 0.6006787419319153, 0.6651583909988403, 0.6719456911087036, 0.6708144545555115, 0.6911764740943909, 0.6889140009880066, 0.7024886608123779, 0.679864227771759, 0.6821267008781433, 0.6877828240394592, 0.6787330508232117, 0.6866515874862671, 0.6696832776069641, 0.6300904750823975, 0.6934388875961304, 0.7013574838638306, 0.6696832776069641, 0.6877828240394592, 0.6979637742042542, 0.6809954643249512, 0.6753393411636353, 0.6561086177825928, 0.6866515874862671, 0.6900452375411987, 0.6945701241493225, 0.6821267008781433, 0.679864227771759, 0.6730769276618958, 0.6776018142700195, 0.6990950107574463, 0.7024886608123779, 0.6843891143798828, 0.6357465982437134, 0.6708144545555115, 0.7002262473106384, 0.7126696705818176, 0.7081447839736938, 0.7047511339187622, 0.6957013607025146, 0.6561086177825928, 0.6990950107574463, 0.6957013607025146, 0.6266968250274658, 0.679864227771759, 0.6979637742042542, 0.6346153616905212, 0.6764705777168274, 0.6832579374313354, 0.7002262473106384, 0.6742081642150879, 0.6651583909988403, 0.6787330508232117, 0.6730769276618958, 0.6595022678375244, 0.6911764740943909, 0.6493212580680847, 0.6764705777168274, 0.6889140009880066, 0.6776018142700195, 0.6787330508232117, 0.679864227771759, 0.668552041053772, 0.6843891143798828, 0.6934388875961304, 0.6911764740943909, 0.6708144545555115, 0.692307710647583, 0.6753393411636353, 0.6640271544456482, 0.651583731174469, 0.6764705777168274, 0.6572397947311401, 0.6380090713500977, 0.6787330508232117, 0.679864227771759, 0.6719456911087036, 0.6674208045005798, 0.6674208045005798, 0.6674208045005798, 0.6809954643249512, 0.6889140009880066, 0.6662895679473877]}\n","45/45 [==============================] - 1s 8ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 1.7642 - accuracy: 0.5031"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 9s 75ms/step - loss: 1.7642 - accuracy: 0.5031 - val_loss: 1.6984 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.6433 - accuracy: 0.5336 - val_loss: 1.5860 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5361 - accuracy: 0.5140 - val_loss: 1.4868 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.4113 - accuracy: 0.6494 - val_loss: 1.3949 - val_accuracy: 0.6353\n","Epoch 5/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3728 - accuracy: 0.5711 - val_loss: 1.3397 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2437 - accuracy: 0.6674 - val_loss: 1.2891 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1704 - accuracy: 0.6817 - val_loss: 1.2331 - val_accuracy: 0.4866\n","Epoch 8/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1196 - accuracy: 0.6848 - val_loss: 1.1864 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0783 - accuracy: 0.6829 - val_loss: 1.1435 - val_accuracy: 0.4886\n","Epoch 10/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0342 - accuracy: 0.6879 - val_loss: 1.0978 - val_accuracy: 0.5517\n","Epoch 11/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0151 - accuracy: 0.6783 - val_loss: 1.0902 - val_accuracy: 0.4866\n","Epoch 12/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9747 - accuracy: 0.6855 - val_loss: 1.0651 - val_accuracy: 0.4876\n","Epoch 13/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9445 - accuracy: 0.6884 - val_loss: 1.0071 - val_accuracy: 0.5661\n","Epoch 14/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9181 - accuracy: 0.6873 - val_loss: 1.0170 - val_accuracy: 0.5145\n","Epoch 15/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8991 - accuracy: 0.6827 - val_loss: 0.9451 - val_accuracy: 0.6353\n","Epoch 16/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8761 - accuracy: 0.6925 - val_loss: 0.9634 - val_accuracy: 0.5372\n","Epoch 17/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8698 - accuracy: 0.6752 - val_loss: 0.9807 - val_accuracy: 0.5041\n","Epoch 18/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.8462 - accuracy: 0.6840 - val_loss: 0.8660 - val_accuracy: 0.6653\n","Epoch 19/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8294 - accuracy: 0.6855 - val_loss: 0.9295 - val_accuracy: 0.5826\n","Epoch 20/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8072 - accuracy: 0.6961 - val_loss: 0.9280 - val_accuracy: 0.5806\n","Epoch 21/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8015 - accuracy: 0.6881 - val_loss: 0.8175 - val_accuracy: 0.6591\n","Epoch 22/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7872 - accuracy: 0.6837 - val_loss: 0.8645 - val_accuracy: 0.6219\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7748 - accuracy: 0.6904 - val_loss: 0.7992 - val_accuracy: 0.6581\n","Epoch 24/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7595 - accuracy: 0.6961 - val_loss: 0.7943 - val_accuracy: 0.6560\n","Epoch 25/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7546 - accuracy: 0.6879 - val_loss: 0.7723 - val_accuracy: 0.6674\n","Epoch 26/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.7468 - accuracy: 0.6915 - val_loss: 0.7646 - val_accuracy: 0.6694\n","Epoch 27/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7467 - accuracy: 0.6840 - val_loss: 0.7631 - val_accuracy: 0.6684\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7231 - accuracy: 0.6961 - val_loss: 0.7542 - val_accuracy: 0.6674\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7173 - accuracy: 0.6959 - val_loss: 0.7605 - val_accuracy: 0.6622\n","Epoch 30/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7083 - accuracy: 0.7000 - val_loss: 0.7381 - val_accuracy: 0.6777\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7039 - accuracy: 0.6984 - val_loss: 0.7292 - val_accuracy: 0.6777\n","Epoch 32/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6936 - accuracy: 0.7000 - val_loss: 0.7525 - val_accuracy: 0.6705\n","Epoch 33/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6964 - accuracy: 0.6982 - val_loss: 0.7333 - val_accuracy: 0.6798\n","Epoch 34/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6880 - accuracy: 0.6979 - val_loss: 0.7337 - val_accuracy: 0.6591\n","Epoch 35/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6758 - accuracy: 0.7031 - val_loss: 0.7177 - val_accuracy: 0.6746\n","Epoch 36/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.6660 - accuracy: 0.7140 - val_loss: 0.7100 - val_accuracy: 0.6921\n","Epoch 37/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6629 - accuracy: 0.7145 - val_loss: 0.7099 - val_accuracy: 0.6643\n","Epoch 38/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6816 - accuracy: 0.6897 - val_loss: 0.7185 - val_accuracy: 0.6725\n","Epoch 39/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6569 - accuracy: 0.7090 - val_loss: 0.7063 - val_accuracy: 0.6787\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6568 - accuracy: 0.7070 - val_loss: 0.6981 - val_accuracy: 0.6767\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6436 - accuracy: 0.7160 - val_loss: 0.6969 - val_accuracy: 0.6880\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6426 - accuracy: 0.7134 - val_loss: 0.7018 - val_accuracy: 0.6632\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6399 - accuracy: 0.7137 - val_loss: 0.6794 - val_accuracy: 0.6808\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6325 - accuracy: 0.7121 - val_loss: 0.6766 - val_accuracy: 0.6756\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6284 - accuracy: 0.7127 - val_loss: 0.6689 - val_accuracy: 0.6839\n","Epoch 46/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6192 - accuracy: 0.7209 - val_loss: 0.6868 - val_accuracy: 0.6715\n","Epoch 47/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6098 - accuracy: 0.7310 - val_loss: 0.7148 - val_accuracy: 0.6818\n","Epoch 48/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6100 - accuracy: 0.7209 - val_loss: 0.6603 - val_accuracy: 0.6829\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6116 - accuracy: 0.7212 - val_loss: 0.7171 - val_accuracy: 0.6663\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6024 - accuracy: 0.7251 - val_loss: 0.6558 - val_accuracy: 0.6911\n","Epoch 51/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5949 - accuracy: 0.7292 - val_loss: 0.6872 - val_accuracy: 0.6932\n","Epoch 52/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5824 - accuracy: 0.7388 - val_loss: 0.6585 - val_accuracy: 0.6942\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6100 - accuracy: 0.7248 - val_loss: 0.8314 - val_accuracy: 0.6012\n","Epoch 54/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6004 - accuracy: 0.7261 - val_loss: 0.6890 - val_accuracy: 0.6818\n","Epoch 55/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5832 - accuracy: 0.7344 - val_loss: 0.7574 - val_accuracy: 0.6643\n","Epoch 56/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.5872 - accuracy: 0.7328 - val_loss: 0.6579 - val_accuracy: 0.7087\n","Epoch 57/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5694 - accuracy: 0.7452 - val_loss: 0.6448 - val_accuracy: 0.7035\n","Epoch 58/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5741 - accuracy: 0.7323 - val_loss: 0.6343 - val_accuracy: 0.7014\n","Epoch 59/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5574 - accuracy: 0.7535 - val_loss: 0.6513 - val_accuracy: 0.6963\n","Epoch 60/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5393 - accuracy: 0.7548 - val_loss: 0.6914 - val_accuracy: 0.6653\n","Epoch 61/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5443 - accuracy: 0.7599 - val_loss: 0.6631 - val_accuracy: 0.6890\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5570 - accuracy: 0.7543 - val_loss: 0.6871 - val_accuracy: 0.6880\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5355 - accuracy: 0.7625 - val_loss: 0.7174 - val_accuracy: 0.6570\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5494 - accuracy: 0.7532 - val_loss: 0.6877 - val_accuracy: 0.6674\n","Epoch 65/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5577 - accuracy: 0.7463 - val_loss: 0.6436 - val_accuracy: 0.7025\n","Epoch 66/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5190 - accuracy: 0.7705 - val_loss: 0.6491 - val_accuracy: 0.6921\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5160 - accuracy: 0.7687 - val_loss: 0.6897 - val_accuracy: 0.6849\n","Epoch 68/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5315 - accuracy: 0.7643 - val_loss: 0.6294 - val_accuracy: 0.7118\n","Epoch 69/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5100 - accuracy: 0.7742 - val_loss: 0.6729 - val_accuracy: 0.6880\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5067 - accuracy: 0.7724 - val_loss: 0.7486 - val_accuracy: 0.6736\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4767 - accuracy: 0.7972 - val_loss: 0.6646 - val_accuracy: 0.7087\n","Epoch 72/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4847 - accuracy: 0.7915 - val_loss: 0.6341 - val_accuracy: 0.7252\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5037 - accuracy: 0.7718 - val_loss: 0.6510 - val_accuracy: 0.6663\n","Epoch 74/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5154 - accuracy: 0.7646 - val_loss: 0.6770 - val_accuracy: 0.6921\n","Epoch 75/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4656 - accuracy: 0.8021 - val_loss: 0.6752 - val_accuracy: 0.6921\n","Epoch 76/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4546 - accuracy: 0.8034 - val_loss: 0.8043 - val_accuracy: 0.6829\n","Epoch 77/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4883 - accuracy: 0.7858 - val_loss: 0.6794 - val_accuracy: 0.6921\n","Epoch 78/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4545 - accuracy: 0.8059 - val_loss: 0.6613 - val_accuracy: 0.7066\n","Epoch 79/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4489 - accuracy: 0.8031 - val_loss: 0.7052 - val_accuracy: 0.6921\n","Epoch 80/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4324 - accuracy: 0.8145 - val_loss: 0.7337 - val_accuracy: 0.7045\n","Epoch 81/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4412 - accuracy: 0.8062 - val_loss: 0.7258 - val_accuracy: 0.6663\n","Epoch 82/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4361 - accuracy: 0.8168 - val_loss: 0.8592 - val_accuracy: 0.6674\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4099 - accuracy: 0.8235 - val_loss: 0.7429 - val_accuracy: 0.6725\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4150 - accuracy: 0.8233 - val_loss: 0.6962 - val_accuracy: 0.7025\n","Epoch 85/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4100 - accuracy: 0.8227 - val_loss: 0.6957 - val_accuracy: 0.7252\n","Epoch 86/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4042 - accuracy: 0.8238 - val_loss: 0.7303 - val_accuracy: 0.7097\n","Epoch 87/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3898 - accuracy: 0.8349 - val_loss: 0.7424 - val_accuracy: 0.6911\n","Epoch 88/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3756 - accuracy: 0.8460 - val_loss: 0.7944 - val_accuracy: 0.6942\n","Epoch 89/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3575 - accuracy: 0.8527 - val_loss: 0.8218 - val_accuracy: 0.7025\n","Epoch 90/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3619 - accuracy: 0.8470 - val_loss: 0.9337 - val_accuracy: 0.6963\n","Epoch 91/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3515 - accuracy: 0.8566 - val_loss: 0.7402 - val_accuracy: 0.7107\n","Epoch 92/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3574 - accuracy: 0.8486 - val_loss: 0.8092 - val_accuracy: 0.6994\n","Epoch 93/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3384 - accuracy: 0.8633 - val_loss: 0.8772 - val_accuracy: 0.7025\n","Epoch 94/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3228 - accuracy: 0.8713 - val_loss: 1.2000 - val_accuracy: 0.6260\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3284 - accuracy: 0.8636 - val_loss: 0.8888 - val_accuracy: 0.6756\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3359 - accuracy: 0.8659 - val_loss: 0.8560 - val_accuracy: 0.6818\n","Epoch 97/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3270 - accuracy: 0.8700 - val_loss: 0.9500 - val_accuracy: 0.6818\n","Epoch 98/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2818 - accuracy: 0.8897 - val_loss: 0.9085 - val_accuracy: 0.6798\n","Epoch 99/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2874 - accuracy: 0.8819 - val_loss: 0.9134 - val_accuracy: 0.7045\n","Epoch 100/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2972 - accuracy: 0.8762 - val_loss: 0.8683 - val_accuracy: 0.6901\n","{'loss': [1.7641710042953491, 1.643315076828003, 1.536056637763977, 1.4112871885299683, 1.3727844953536987, 1.243749976158142, 1.1703931093215942, 1.1195766925811768, 1.0783380270004272, 1.034186840057373, 1.0150693655014038, 0.9746816754341125, 0.9445238709449768, 0.918124258518219, 0.899051308631897, 0.8761355876922607, 0.8698439002037048, 0.8461804986000061, 0.8294054269790649, 0.8071725964546204, 0.8014809489250183, 0.78719162940979, 0.7747865915298462, 0.7594864368438721, 0.7546008229255676, 0.746846079826355, 0.7467377781867981, 0.7231477499008179, 0.7173240184783936, 0.7083166241645813, 0.7039328813552856, 0.6935685873031616, 0.6964263319969177, 0.6879630088806152, 0.6758133172988892, 0.6660444140434265, 0.6628707051277161, 0.6816490292549133, 0.6569443345069885, 0.6567613482475281, 0.643631637096405, 0.6425811052322388, 0.6399219632148743, 0.6324949264526367, 0.6284089684486389, 0.6191942095756531, 0.6097830533981323, 0.6100203394889832, 0.6116466522216797, 0.6023810505867004, 0.5948801636695862, 0.5824114084243774, 0.6099931597709656, 0.6003738641738892, 0.5831657648086548, 0.5871813893318176, 0.5693845748901367, 0.57408607006073, 0.5574321746826172, 0.53931725025177, 0.5443386435508728, 0.557025671005249, 0.5355308651924133, 0.549448549747467, 0.5577277541160583, 0.5190216898918152, 0.5159712433815002, 0.5315354466438293, 0.5100127458572388, 0.5067014694213867, 0.47672536969184875, 0.4847325086593628, 0.5036999583244324, 0.5153791308403015, 0.4655616581439972, 0.4546428918838501, 0.4882706105709076, 0.45450130105018616, 0.44893041253089905, 0.43242141604423523, 0.44115084409713745, 0.43608126044273376, 0.409889280796051, 0.4150345027446747, 0.40997377038002014, 0.40422606468200684, 0.3898431062698364, 0.37564483284950256, 0.3574797809123993, 0.3619336783885956, 0.35151493549346924, 0.35742926597595215, 0.33835113048553467, 0.32281044125556946, 0.3284156322479248, 0.33587387204170227, 0.327005535364151, 0.2817772328853607, 0.28735244274139404, 0.29722124338150024], 'accuracy': [0.5031007528305054, 0.5335917472839355, 0.5139535069465637, 0.6493539810180664, 0.5710594058036804, 0.6674418449401855, 0.6816537380218506, 0.6847545504570007, 0.682945728302002, 0.6878553032875061, 0.6782945990562439, 0.6855297088623047, 0.6883720755577087, 0.6873385310173035, 0.6826873421669006, 0.6925064325332642, 0.6751937866210938, 0.683979332447052, 0.6855297088623047, 0.6961240172386169, 0.6881136894226074, 0.6837209463119507, 0.6904392838478088, 0.6961240172386169, 0.6878553032875061, 0.6914728879928589, 0.683979332447052, 0.6961240172386169, 0.6958656311035156, 0.699999988079071, 0.6984496116638184, 0.699999988079071, 0.698191225528717, 0.6979328393936157, 0.7031008005142212, 0.7139534950256348, 0.7144702672958374, 0.6896640658378601, 0.7090439200401306, 0.7069767713546753, 0.7160206437110901, 0.7134366631507874, 0.7136951088905334, 0.7121447324752808, 0.7126615047454834, 0.7209302186965942, 0.7310077548027039, 0.7209302186965942, 0.7211886048316956, 0.7250645756721497, 0.7291989922523499, 0.7387596964836121, 0.7248061895370483, 0.7260981798171997, 0.7343669533729553, 0.7328165173530579, 0.7452196478843689, 0.7322997450828552, 0.7534883618354797, 0.7547803521156311, 0.7599483132362366, 0.7542635798454285, 0.7625322937965393, 0.7532299757003784, 0.746253252029419, 0.7705426216125488, 0.7687338590621948, 0.7643410563468933, 0.7741602063179016, 0.7723514437675476, 0.7971576452255249, 0.791472852230072, 0.7718346118927002, 0.7645995020866394, 0.8020671606063843, 0.8033591508865356, 0.7857881188392639, 0.8059431314468384, 0.8031007647514343, 0.8144702911376953, 0.8062015771865845, 0.8167958855628967, 0.8235142230987549, 0.8232558369636536, 0.8227390050888062, 0.8237726092338562, 0.8348837494850159, 0.8459948301315308, 0.8527131676673889, 0.8470284342765808, 0.856589138507843, 0.8485788106918335, 0.8633074760437012, 0.8713178038597107, 0.8635658621788025, 0.8658914566040039, 0.8700258135795593, 0.8896640539169312, 0.8819121718406677, 0.8762273788452148], 'val_loss': [1.6984262466430664, 1.5860201120376587, 1.4867910146713257, 1.3948990106582642, 1.3396872282028198, 1.2890586853027344, 1.2331080436706543, 1.1863852739334106, 1.1434862613677979, 1.097816824913025, 1.0901532173156738, 1.0651323795318604, 1.0070984363555908, 1.0170435905456543, 0.945117175579071, 0.9634152054786682, 0.9806985259056091, 0.8659998178482056, 0.9294520616531372, 0.9279730916023254, 0.8174501061439514, 0.8644647002220154, 0.799163818359375, 0.7943390607833862, 0.7723471522331238, 0.7645682692527771, 0.7631096243858337, 0.7541884183883667, 0.7604854106903076, 0.7380686402320862, 0.7292248606681824, 0.7524824738502502, 0.7332741618156433, 0.7337383031845093, 0.7177097201347351, 0.710015058517456, 0.7099273204803467, 0.7185356020927429, 0.7062891721725464, 0.6980865597724915, 0.6969215869903564, 0.7017759680747986, 0.6793864369392395, 0.6766348481178284, 0.6689376831054688, 0.6867693066596985, 0.7148067355155945, 0.6602625846862793, 0.7171183824539185, 0.65584796667099, 0.6871999502182007, 0.6585127115249634, 0.8313696980476379, 0.6889979839324951, 0.7574139833450317, 0.6579222679138184, 0.6447858214378357, 0.6343278884887695, 0.6512534618377686, 0.6914087533950806, 0.6630863547325134, 0.6871193647384644, 0.7174362540245056, 0.687671422958374, 0.6435784697532654, 0.6490628123283386, 0.6897139549255371, 0.6294106245040894, 0.6728743314743042, 0.7485700845718384, 0.6645925045013428, 0.6341291069984436, 0.6509978175163269, 0.6769830584526062, 0.6751703023910522, 0.8042854070663452, 0.6794379949569702, 0.6613168716430664, 0.7052339315414429, 0.7337414622306824, 0.7258421182632446, 0.8592060208320618, 0.742863655090332, 0.6962254047393799, 0.695683479309082, 0.7303394675254822, 0.7424421310424805, 0.7943891882896423, 0.8218121528625488, 0.9336727261543274, 0.7402418255805969, 0.8092319965362549, 0.8772278428077698, 1.2000142335891724, 0.8888412117958069, 0.8559913039207458, 0.9500419497489929, 0.9084836840629578, 0.9134404063224792, 0.868261456489563], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.6353305578231812, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.48553720116615295, 0.4886363744735718, 0.5516529083251953, 0.48657023906707764, 0.4876033067703247, 0.56611567735672, 0.5144628286361694, 0.6353305578231812, 0.5371900796890259, 0.5041322112083435, 0.6652892827987671, 0.5826446413993835, 0.5805785059928894, 0.6590909361839294, 0.6219007968902588, 0.6580578684806824, 0.6559917330741882, 0.6673553586006165, 0.6694214940071106, 0.6683884263038635, 0.6673553586006165, 0.6621900796890259, 0.6776859760284424, 0.6776859760284424, 0.6704545617103577, 0.6797520518302917, 0.6590909361839294, 0.6745867729187012, 0.692148745059967, 0.66425621509552, 0.672520637512207, 0.6787189841270447, 0.6766529083251953, 0.6880165338516235, 0.663223147392273, 0.6807851195335388, 0.6756198406219482, 0.68388432264328, 0.6714876294136047, 0.6818181872367859, 0.682851254940033, 0.6663222908973694, 0.69111567735672, 0.6931818127632141, 0.6942148804664612, 0.6012396812438965, 0.6818181872367859, 0.66425621509552, 0.7086777091026306, 0.7035123705863953, 0.7014462947845459, 0.6962810158729553, 0.6652892827987671, 0.6890496015548706, 0.6880165338516235, 0.6570248007774353, 0.6673553586006165, 0.702479362487793, 0.692148745059967, 0.6849173307418823, 0.711776852607727, 0.6880165338516235, 0.6735537052154541, 0.7086777091026306, 0.7252066135406494, 0.6663222908973694, 0.692148745059967, 0.692148745059967, 0.682851254940033, 0.692148745059967, 0.7066115736961365, 0.692148745059967, 0.7045454382896423, 0.6663222908973694, 0.6673553586006165, 0.672520637512207, 0.702479362487793, 0.7252066135406494, 0.7097107172012329, 0.69111567735672, 0.6942148804664612, 0.702479362487793, 0.6962810158729553, 0.71074378490448, 0.6993801593780518, 0.702479362487793, 0.6260330677032471, 0.6756198406219482, 0.6818181872367859, 0.6818181872367859, 0.6797520518302917, 0.7045454382896423, 0.6900826692581177]}\n","32/32 [==============================] - 1s 10ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.6081 - accuracy: 0.7048"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 7s 59ms/step - loss: 0.6081 - accuracy: 0.7047 - val_loss: 0.7254 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5534 - accuracy: 0.7309 - val_loss: 0.7230 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5227 - accuracy: 0.7592 - val_loss: 0.7238 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5288 - accuracy: 0.7476 - val_loss: 0.7257 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4914 - accuracy: 0.7683 - val_loss: 0.7223 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4589 - accuracy: 0.7958 - val_loss: 0.7194 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4594 - accuracy: 0.7848 - val_loss: 0.7318 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4277 - accuracy: 0.8125 - val_loss: 0.7157 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4176 - accuracy: 0.8222 - val_loss: 0.7142 - val_accuracy: 0.4860\n","Epoch 10/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.3922 - accuracy: 0.8295 - val_loss: 0.6983 - val_accuracy: 0.5075\n","Epoch 11/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.3692 - accuracy: 0.8508 - val_loss: 0.7191 - val_accuracy: 0.5086\n","Epoch 12/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.3916 - accuracy: 0.8244 - val_loss: 0.6755 - val_accuracy: 0.5765\n","Epoch 13/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3471 - accuracy: 0.8551 - val_loss: 0.6728 - val_accuracy: 0.5700\n","Epoch 14/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3240 - accuracy: 0.8731 - val_loss: 0.7012 - val_accuracy: 0.5668\n","Epoch 15/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3133 - accuracy: 0.8790 - val_loss: 0.6302 - val_accuracy: 0.6649\n","Epoch 16/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2918 - accuracy: 0.8852 - val_loss: 0.6235 - val_accuracy: 0.6595\n","Epoch 17/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2876 - accuracy: 0.8877 - val_loss: 0.6629 - val_accuracy: 0.6433\n","Epoch 18/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3004 - accuracy: 0.8747 - val_loss: 0.6276 - val_accuracy: 0.6724\n","Epoch 19/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2625 - accuracy: 0.9022 - val_loss: 0.6439 - val_accuracy: 0.6670\n","Epoch 20/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2771 - accuracy: 0.8890 - val_loss: 0.6771 - val_accuracy: 0.6584\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2697 - accuracy: 0.8895 - val_loss: 0.7520 - val_accuracy: 0.6649\n","Epoch 22/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2468 - accuracy: 0.9071 - val_loss: 0.7748 - val_accuracy: 0.6562\n","Epoch 23/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2128 - accuracy: 0.9205 - val_loss: 0.8463 - val_accuracy: 0.6595\n","Epoch 24/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.2012 - accuracy: 0.9294 - val_loss: 0.7965 - val_accuracy: 0.7155\n","Epoch 25/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.1889 - accuracy: 0.9351 - val_loss: 0.7264 - val_accuracy: 0.7209\n","Epoch 26/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1755 - accuracy: 0.9456 - val_loss: 0.8324 - val_accuracy: 0.7037\n","Epoch 27/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2086 - accuracy: 0.9243 - val_loss: 0.7901 - val_accuracy: 0.6832\n","Epoch 28/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2344 - accuracy: 0.9098 - val_loss: 0.8947 - val_accuracy: 0.7134\n","Epoch 29/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.1947 - accuracy: 0.9313 - val_loss: 0.8126 - val_accuracy: 0.7435\n","Epoch 30/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1848 - accuracy: 0.9327 - val_loss: 1.0156 - val_accuracy: 0.6972\n","Epoch 31/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1611 - accuracy: 0.9442 - val_loss: 0.9399 - val_accuracy: 0.7220\n","Epoch 32/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1380 - accuracy: 0.9542 - val_loss: 1.1021 - val_accuracy: 0.7155\n","Epoch 33/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1493 - accuracy: 0.9491 - val_loss: 0.9765 - val_accuracy: 0.7220\n","Epoch 34/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1271 - accuracy: 0.9615 - val_loss: 1.1463 - val_accuracy: 0.7317\n","Epoch 35/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1374 - accuracy: 0.9566 - val_loss: 1.0747 - val_accuracy: 0.7252\n","Epoch 36/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1274 - accuracy: 0.9596 - val_loss: 1.2276 - val_accuracy: 0.7069\n","Epoch 37/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1707 - accuracy: 0.9353 - val_loss: 1.0959 - val_accuracy: 0.6746\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1756 - accuracy: 0.9380 - val_loss: 1.0425 - val_accuracy: 0.7101\n","Epoch 39/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1184 - accuracy: 0.9607 - val_loss: 1.0465 - val_accuracy: 0.7306\n","Epoch 40/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0982 - accuracy: 0.9744 - val_loss: 1.2462 - val_accuracy: 0.7231\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1224 - accuracy: 0.9604 - val_loss: 1.1022 - val_accuracy: 0.7123\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1034 - accuracy: 0.9663 - val_loss: 1.3492 - val_accuracy: 0.7091\n","Epoch 43/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1100 - accuracy: 0.9671 - val_loss: 1.1745 - val_accuracy: 0.7058\n","Epoch 44/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1417 - accuracy: 0.9515 - val_loss: 1.1619 - val_accuracy: 0.7155\n","Epoch 45/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1373 - accuracy: 0.9515 - val_loss: 1.0677 - val_accuracy: 0.7252\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0865 - accuracy: 0.9768 - val_loss: 1.3958 - val_accuracy: 0.7241\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0861 - accuracy: 0.9741 - val_loss: 1.3549 - val_accuracy: 0.7123\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0883 - accuracy: 0.9766 - val_loss: 1.4316 - val_accuracy: 0.6950\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0827 - accuracy: 0.9758 - val_loss: 1.2449 - val_accuracy: 0.7198\n","Epoch 50/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0896 - accuracy: 0.9747 - val_loss: 1.3220 - val_accuracy: 0.7188\n","Epoch 51/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1316 - accuracy: 0.9572 - val_loss: 0.9925 - val_accuracy: 0.7144\n","Epoch 52/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0928 - accuracy: 0.9739 - val_loss: 1.2890 - val_accuracy: 0.7080\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0665 - accuracy: 0.9852 - val_loss: 1.5303 - val_accuracy: 0.6778\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0642 - accuracy: 0.9849 - val_loss: 1.4704 - val_accuracy: 0.7026\n","Epoch 55/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0810 - accuracy: 0.9774 - val_loss: 1.6455 - val_accuracy: 0.6918\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1137 - accuracy: 0.9628 - val_loss: 1.3739 - val_accuracy: 0.6972\n","Epoch 57/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0999 - accuracy: 0.9714 - val_loss: 1.4777 - val_accuracy: 0.6886\n","Epoch 58/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1110 - accuracy: 0.9688 - val_loss: 1.1464 - val_accuracy: 0.7155\n","Epoch 59/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0616 - accuracy: 0.9844 - val_loss: 1.5404 - val_accuracy: 0.7037\n","Epoch 60/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0975 - accuracy: 0.9714 - val_loss: 1.1943 - val_accuracy: 0.7252\n","Epoch 61/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0766 - accuracy: 0.9801 - val_loss: 1.3302 - val_accuracy: 0.7198\n","Epoch 62/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0660 - accuracy: 0.9833 - val_loss: 1.5226 - val_accuracy: 0.7026\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0960 - accuracy: 0.9739 - val_loss: 1.2068 - val_accuracy: 0.6950\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0822 - accuracy: 0.9782 - val_loss: 1.4352 - val_accuracy: 0.7058\n","Epoch 65/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0674 - accuracy: 0.9833 - val_loss: 1.4672 - val_accuracy: 0.7155\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0629 - accuracy: 0.9841 - val_loss: 1.4763 - val_accuracy: 0.6983\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0494 - accuracy: 0.9916 - val_loss: 1.6166 - val_accuracy: 0.7252\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0472 - accuracy: 0.9919 - val_loss: 1.8347 - val_accuracy: 0.6983\n","Epoch 69/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0759 - accuracy: 0.9798 - val_loss: 1.4803 - val_accuracy: 0.7188\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1022 - accuracy: 0.9690 - val_loss: 1.2611 - val_accuracy: 0.7047\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0851 - accuracy: 0.9768 - val_loss: 1.3833 - val_accuracy: 0.7080\n","Epoch 72/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0901 - accuracy: 0.9741 - val_loss: 1.2758 - val_accuracy: 0.7241\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0694 - accuracy: 0.9809 - val_loss: 1.4653 - val_accuracy: 0.6843\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0572 - accuracy: 0.9865 - val_loss: 1.5314 - val_accuracy: 0.7112\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0567 - accuracy: 0.9871 - val_loss: 1.6522 - val_accuracy: 0.6983\n","Epoch 76/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0627 - accuracy: 0.9844 - val_loss: 1.4682 - val_accuracy: 0.7209\n","Epoch 77/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0629 - accuracy: 0.9846 - val_loss: 1.4710 - val_accuracy: 0.6983\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0467 - accuracy: 0.9908 - val_loss: 1.5927 - val_accuracy: 0.7177\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0423 - accuracy: 0.9922 - val_loss: 1.6447 - val_accuracy: 0.7177\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0644 - accuracy: 0.9841 - val_loss: 1.5761 - val_accuracy: 0.7080\n","Epoch 81/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1081 - accuracy: 0.9677 - val_loss: 1.1355 - val_accuracy: 0.7091\n","Epoch 82/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0643 - accuracy: 0.9836 - val_loss: 1.5432 - val_accuracy: 0.6994\n","Epoch 83/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0560 - accuracy: 0.9852 - val_loss: 1.5128 - val_accuracy: 0.7209\n","Epoch 84/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1075 - accuracy: 0.9682 - val_loss: 1.2007 - val_accuracy: 0.7015\n","Epoch 85/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0552 - accuracy: 0.9876 - val_loss: 1.4936 - val_accuracy: 0.7220\n","Epoch 86/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0416 - accuracy: 0.9927 - val_loss: 1.6443 - val_accuracy: 0.7123\n","Epoch 87/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0369 - accuracy: 0.9943 - val_loss: 1.6148 - val_accuracy: 0.7295\n","Epoch 88/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0345 - accuracy: 0.9957 - val_loss: 1.7217 - val_accuracy: 0.7274\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0320 - accuracy: 0.9968 - val_loss: 1.6913 - val_accuracy: 0.7080\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0309 - accuracy: 0.9976 - val_loss: 1.6982 - val_accuracy: 0.7112\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0419 - accuracy: 0.9911 - val_loss: 1.8189 - val_accuracy: 0.6703\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0598 - accuracy: 0.9841 - val_loss: 1.4566 - val_accuracy: 0.6918\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0698 - accuracy: 0.9817 - val_loss: 1.5751 - val_accuracy: 0.7069\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0550 - accuracy: 0.9884 - val_loss: 1.6398 - val_accuracy: 0.7123\n","Epoch 95/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0554 - accuracy: 0.9863 - val_loss: 1.5766 - val_accuracy: 0.7144\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0604 - accuracy: 0.9855 - val_loss: 1.4182 - val_accuracy: 0.7058\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0924 - accuracy: 0.9739 - val_loss: 1.4358 - val_accuracy: 0.6950\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0841 - accuracy: 0.9763 - val_loss: 1.3128 - val_accuracy: 0.7047\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0563 - accuracy: 0.9876 - val_loss: 1.5749 - val_accuracy: 0.6864\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0588 - accuracy: 0.9860 - val_loss: 1.4860 - val_accuracy: 0.7026\n","{'loss': [0.6081492304801941, 0.5533581376075745, 0.5227001905441284, 0.5288105010986328, 0.49135005474090576, 0.45888182520866394, 0.45937037467956543, 0.427653044462204, 0.41760748624801636, 0.39223894476890564, 0.3692066967487335, 0.39161449670791626, 0.34709012508392334, 0.32404592633247375, 0.3132861852645874, 0.2918136417865753, 0.28758135437965393, 0.3003944754600525, 0.2625012993812561, 0.27712514996528625, 0.26970604062080383, 0.2468203604221344, 0.21275660395622253, 0.20115350186824799, 0.18886952102184296, 0.17546065151691437, 0.20858658850193024, 0.23442333936691284, 0.19466377794742584, 0.18483632802963257, 0.16111882030963898, 0.13801145553588867, 0.14927896857261658, 0.12711505591869354, 0.13738174736499786, 0.12736794352531433, 0.17071057856082916, 0.1756230890750885, 0.11844652891159058, 0.09819141775369644, 0.12242601811885834, 0.10335574299097061, 0.10999734699726105, 0.14174234867095947, 0.1373460739850998, 0.0864945501089096, 0.08612751215696335, 0.08825836330652237, 0.0827140137553215, 0.08955749124288559, 0.13162420690059662, 0.09284071624279022, 0.0665120780467987, 0.06418110430240631, 0.08099884539842606, 0.11367186158895493, 0.09993737936019897, 0.11101873219013214, 0.061646707355976105, 0.09754689037799835, 0.07659382373094559, 0.06604768335819244, 0.09601704031229019, 0.08224222809076309, 0.06742134690284729, 0.06292922049760818, 0.049427617341279984, 0.04718529433012009, 0.07593595236539841, 0.10224531590938568, 0.0850522518157959, 0.09011125564575195, 0.06941747665405273, 0.057213786989450455, 0.05670367181301117, 0.06274032592773438, 0.06286832690238953, 0.04668441787362099, 0.04233100637793541, 0.06437695771455765, 0.1081065684556961, 0.06434164941310883, 0.05599381774663925, 0.10753034800291061, 0.05515190213918686, 0.04163796454668045, 0.03693270683288574, 0.03451617807149887, 0.03195847570896149, 0.030940765514969826, 0.041939981281757355, 0.059806618839502335, 0.06980060040950775, 0.05498383939266205, 0.05543144792318344, 0.06040320545434952, 0.09240604192018509, 0.08413093537092209, 0.05630612373352051, 0.05882256105542183], 'accuracy': [0.704741358757019, 0.7308728694915771, 0.759159505367279, 0.7475754022598267, 0.7683189511299133, 0.7957974076271057, 0.7847521305084229, 0.8125, 0.8221982717514038, 0.829472005367279, 0.8507543206214905, 0.8243534564971924, 0.8550646305084229, 0.8731142282485962, 0.8790409564971924, 0.8852370977401733, 0.8876616358757019, 0.8747305870056152, 0.9022090435028076, 0.889008641242981, 0.8895474076271057, 0.9070581793785095, 0.920527994632721, 0.9294180870056152, 0.9350754022598267, 0.9455819129943848, 0.9242995977401733, 0.9097521305084229, 0.931303858757019, 0.9326508641242981, 0.9442349076271057, 0.9542025923728943, 0.9490840435028076, 0.9614762663841248, 0.9566271305084229, 0.959590494632721, 0.9353448152542114, 0.9380387663841248, 0.9606680870056152, 0.9744073152542114, 0.9603987336158752, 0.9663254022598267, 0.967133641242981, 0.951508641242981, 0.951508641242981, 0.9768319129943848, 0.9741379022598267, 0.9765625, 0.9757543206214905, 0.9746767282485962, 0.9571659564971924, 0.9738685488700867, 0.9851831793785095, 0.9849137663841248, 0.9773706793785095, 0.9628232717514038, 0.9714439511299133, 0.96875, 0.984375, 0.9714439511299133, 0.9800646305084229, 0.9832974076271057, 0.9738685488700867, 0.978178858757019, 0.9832974076271057, 0.9841055870056152, 0.9916487336158752, 0.9919180870056152, 0.9797952771186829, 0.9690194129943848, 0.9768319129943848, 0.9741379022598267, 0.9808728694915771, 0.9865301847457886, 0.9870689511299133, 0.984375, 0.9846444129943848, 0.990840494632721, 0.9921875, 0.9841055870056152, 0.9676724076271057, 0.9835668206214905, 0.9851831793785095, 0.9682112336158752, 0.9876077771186829, 0.9927262663841248, 0.9943426847457886, 0.9956896305084229, 0.9967672228813171, 0.9975754022598267, 0.9911099076271057, 0.9841055870056152, 0.9816810488700867, 0.9884159564971924, 0.9862607717514038, 0.9854525923728943, 0.9738685488700867, 0.9762930870056152, 0.9876077771186829, 0.985991358757019], 'val_loss': [0.7253965735435486, 0.7229701280593872, 0.7237815260887146, 0.7256515026092529, 0.7222952842712402, 0.7193856239318848, 0.731780469417572, 0.7157397270202637, 0.7141767740249634, 0.6983424425125122, 0.7190818786621094, 0.6755293607711792, 0.672770082950592, 0.7012221813201904, 0.6302263140678406, 0.6235180497169495, 0.6628886461257935, 0.6276024580001831, 0.6438939571380615, 0.677095890045166, 0.7520295977592468, 0.774807333946228, 0.8463492393493652, 0.7965459227561951, 0.72642982006073, 0.8324087858200073, 0.7901497483253479, 0.8946878910064697, 0.8126334547996521, 1.0155844688415527, 0.9399190545082092, 1.102115511894226, 0.9765118956565857, 1.1463160514831543, 1.0747361183166504, 1.22761869430542, 1.0959489345550537, 1.0425347089767456, 1.0464533567428589, 1.24619722366333, 1.1021623611450195, 1.349249243736267, 1.1745178699493408, 1.1619480848312378, 1.0676758289337158, 1.3958277702331543, 1.3549141883850098, 1.4316414594650269, 1.2449438571929932, 1.322007417678833, 0.9924734234809875, 1.2890121936798096, 1.5303208827972412, 1.4703954458236694, 1.6455219984054565, 1.373902678489685, 1.477660059928894, 1.1464141607284546, 1.5404318571090698, 1.1942604780197144, 1.3301517963409424, 1.5225985050201416, 1.206766963005066, 1.4351575374603271, 1.467239499092102, 1.4763014316558838, 1.6165838241577148, 1.8347219228744507, 1.4803298711776733, 1.2610712051391602, 1.3832793235778809, 1.275848627090454, 1.4652713537216187, 1.5314404964447021, 1.6521728038787842, 1.468170404434204, 1.4710493087768555, 1.5926661491394043, 1.6447374820709229, 1.5761486291885376, 1.1355156898498535, 1.5432089567184448, 1.5127931833267212, 1.2006595134735107, 1.4936171770095825, 1.644258975982666, 1.614804744720459, 1.7216871976852417, 1.6912591457366943, 1.6981675624847412, 1.8189438581466675, 1.4566105604171753, 1.575067162513733, 1.6398135423660278, 1.5766257047653198, 1.41823148727417, 1.4358394145965576, 1.3128037452697754, 1.5749133825302124, 1.485993504524231], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.5075430870056152, 0.5086206793785095, 0.576508641242981, 0.5700430870056152, 0.5668103694915771, 0.6648706793785095, 0.6594827771186829, 0.6433189511299133, 0.6724137663841248, 0.6670258641242981, 0.6584051847457886, 0.6648706793785095, 0.65625, 0.6594827771186829, 0.7155172228813171, 0.7209051847457886, 0.7036637663841248, 0.6831896305084229, 0.7133620977401733, 0.743534505367279, 0.6971982717514038, 0.7219827771186829, 0.7155172228813171, 0.7219827771186829, 0.7316810488700867, 0.725215494632721, 0.7068965435028076, 0.6745689511299133, 0.7101293206214905, 0.7306034564971924, 0.7230603694915771, 0.712284505367279, 0.7090517282485962, 0.7058189511299133, 0.7155172228813171, 0.725215494632721, 0.7241379022598267, 0.712284505367279, 0.6950430870056152, 0.7198275923728943, 0.71875, 0.7144396305084229, 0.7079741358757019, 0.6778017282485962, 0.7025862336158752, 0.6918103694915771, 0.6971982717514038, 0.6885775923728943, 0.7155172228813171, 0.7036637663841248, 0.725215494632721, 0.7198275923728943, 0.7025862336158752, 0.6950430870056152, 0.7058189511299133, 0.7155172228813171, 0.6982758641242981, 0.725215494632721, 0.6982758641242981, 0.71875, 0.704741358757019, 0.7079741358757019, 0.7241379022598267, 0.6842672228813171, 0.7112069129943848, 0.6982758641242981, 0.7209051847457886, 0.6982758641242981, 0.7176724076271057, 0.7176724076271057, 0.7079741358757019, 0.7090517282485962, 0.6993534564971924, 0.7209051847457886, 0.701508641242981, 0.7219827771186829, 0.712284505367279, 0.7295258641242981, 0.7273706793785095, 0.7079741358757019, 0.7112069129943848, 0.670258641242981, 0.6918103694915771, 0.7068965435028076, 0.712284505367279, 0.7144396305084229, 0.7058189511299133, 0.6950430870056152, 0.704741358757019, 0.6864224076271057, 0.7025862336158752]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.6075 - accuracy: 0.7035"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 7s 63ms/step - loss: 0.6075 - accuracy: 0.7035 - val_loss: 0.7223 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5519 - accuracy: 0.7383 - val_loss: 0.7210 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5226 - accuracy: 0.7547 - val_loss: 0.7197 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5028 - accuracy: 0.7600 - val_loss: 0.7190 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4681 - accuracy: 0.7915 - val_loss: 0.7181 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4474 - accuracy: 0.7963 - val_loss: 0.7160 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4303 - accuracy: 0.8124 - val_loss: 0.7128 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.4228 - accuracy: 0.8152 - val_loss: 0.7090 - val_accuracy: 0.4977\n","Epoch 9/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3961 - accuracy: 0.8362 - val_loss: 0.7148 - val_accuracy: 0.4955\n","Epoch 10/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3837 - accuracy: 0.8356 - val_loss: 0.7045 - val_accuracy: 0.5113\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3965 - accuracy: 0.8325 - val_loss: 0.7164 - val_accuracy: 0.4977\n","Epoch 12/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3349 - accuracy: 0.8693 - val_loss: 0.7014 - val_accuracy: 0.5339\n","Epoch 13/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3203 - accuracy: 0.8755 - val_loss: 0.6652 - val_accuracy: 0.5984\n","Epoch 14/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3313 - accuracy: 0.8735 - val_loss: 0.7188 - val_accuracy: 0.5441\n","Epoch 15/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3297 - accuracy: 0.8746 - val_loss: 0.7411 - val_accuracy: 0.5294\n","Epoch 16/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.2980 - accuracy: 0.8846 - val_loss: 0.6744 - val_accuracy: 0.6109\n","Epoch 17/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2651 - accuracy: 0.8962 - val_loss: 0.7098 - val_accuracy: 0.5973\n","Epoch 18/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.2932 - accuracy: 0.8840 - val_loss: 0.6730 - val_accuracy: 0.6290\n","Epoch 19/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.2281 - accuracy: 0.9253 - val_loss: 0.6478 - val_accuracy: 0.6606\n","Epoch 20/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2283 - accuracy: 0.9177 - val_loss: 0.7560 - val_accuracy: 0.6459\n","Epoch 21/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2742 - accuracy: 0.8984 - val_loss: 0.7664 - val_accuracy: 0.6233\n","Epoch 22/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.2141 - accuracy: 0.9270 - val_loss: 0.6782 - val_accuracy: 0.6912\n","Epoch 23/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.2041 - accuracy: 0.9341 - val_loss: 0.7121 - val_accuracy: 0.6934\n","Epoch 24/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.1911 - accuracy: 0.9383 - val_loss: 0.7002 - val_accuracy: 0.7025\n","Epoch 25/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2265 - accuracy: 0.9160 - val_loss: 0.7456 - val_accuracy: 0.6719\n","Epoch 26/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.1871 - accuracy: 0.9383 - val_loss: 0.7852 - val_accuracy: 0.6844\n","Epoch 27/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1763 - accuracy: 0.9406 - val_loss: 0.8435 - val_accuracy: 0.6652\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1879 - accuracy: 0.9375 - val_loss: 0.8423 - val_accuracy: 0.6889\n","Epoch 29/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2270 - accuracy: 0.9242 - val_loss: 0.7279 - val_accuracy: 0.7002\n","Epoch 30/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1809 - accuracy: 0.9389 - val_loss: 0.9674 - val_accuracy: 0.6991\n","Epoch 31/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1525 - accuracy: 0.9508 - val_loss: 1.0449 - val_accuracy: 0.6742\n","Epoch 32/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1282 - accuracy: 0.9618 - val_loss: 1.1114 - val_accuracy: 0.6991\n","Epoch 33/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1496 - accuracy: 0.9527 - val_loss: 1.0695 - val_accuracy: 0.6923\n","Epoch 34/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.1546 - accuracy: 0.9525 - val_loss: 1.0081 - val_accuracy: 0.7127\n","Epoch 35/100\n","28/28 [==============================] - 1s 44ms/step - loss: 0.1292 - accuracy: 0.9601 - val_loss: 1.0759 - val_accuracy: 0.7217\n","Epoch 36/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1105 - accuracy: 0.9717 - val_loss: 1.1360 - val_accuracy: 0.7025\n","Epoch 37/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1027 - accuracy: 0.9726 - val_loss: 1.2232 - val_accuracy: 0.7104\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1077 - accuracy: 0.9726 - val_loss: 1.1968 - val_accuracy: 0.6878\n","Epoch 39/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1068 - accuracy: 0.9717 - val_loss: 1.3171 - val_accuracy: 0.6821\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1378 - accuracy: 0.9564 - val_loss: 1.1168 - val_accuracy: 0.6844\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1208 - accuracy: 0.9646 - val_loss: 1.2132 - val_accuracy: 0.6719\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1191 - accuracy: 0.9677 - val_loss: 1.1777 - val_accuracy: 0.7025\n","Epoch 43/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1064 - accuracy: 0.9700 - val_loss: 1.3531 - val_accuracy: 0.6708\n","Epoch 44/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1422 - accuracy: 0.9539 - val_loss: 1.0348 - val_accuracy: 0.6844\n","Epoch 45/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1144 - accuracy: 0.9646 - val_loss: 1.2881 - val_accuracy: 0.6923\n","Epoch 46/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0906 - accuracy: 0.9743 - val_loss: 1.3757 - val_accuracy: 0.6946\n","Epoch 47/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1258 - accuracy: 0.9629 - val_loss: 1.0794 - val_accuracy: 0.6810\n","Epoch 48/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.1376 - accuracy: 0.9533 - val_loss: 1.2834 - val_accuracy: 0.6776\n","Epoch 49/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0818 - accuracy: 0.9796 - val_loss: 1.3245 - val_accuracy: 0.6991\n","Epoch 50/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0807 - accuracy: 0.9802 - val_loss: 1.4901 - val_accuracy: 0.6912\n","Epoch 51/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0853 - accuracy: 0.9765 - val_loss: 1.3506 - val_accuracy: 0.7014\n","Epoch 52/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1051 - accuracy: 0.9709 - val_loss: 1.2469 - val_accuracy: 0.6821\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0683 - accuracy: 0.9853 - val_loss: 1.4578 - val_accuracy: 0.7070\n","Epoch 54/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0614 - accuracy: 0.9856 - val_loss: 1.6916 - val_accuracy: 0.6719\n","Epoch 55/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1103 - accuracy: 0.9641 - val_loss: 1.2437 - val_accuracy: 0.7002\n","Epoch 56/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1006 - accuracy: 0.9740 - val_loss: 1.2322 - val_accuracy: 0.6968\n","Epoch 57/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0842 - accuracy: 0.9768 - val_loss: 1.3728 - val_accuracy: 0.6980\n","Epoch 58/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0918 - accuracy: 0.9751 - val_loss: 1.2761 - val_accuracy: 0.7036\n","Epoch 59/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0726 - accuracy: 0.9827 - val_loss: 1.5125 - val_accuracy: 0.6855\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0714 - accuracy: 0.9816 - val_loss: 1.3799 - val_accuracy: 0.6878\n","Epoch 61/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0587 - accuracy: 0.9884 - val_loss: 1.5055 - val_accuracy: 0.7014\n","Epoch 62/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0611 - accuracy: 0.9875 - val_loss: 1.5100 - val_accuracy: 0.6821\n","Epoch 63/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0887 - accuracy: 0.9745 - val_loss: 1.3437 - val_accuracy: 0.7048\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1071 - accuracy: 0.9686 - val_loss: 1.2207 - val_accuracy: 0.6991\n","Epoch 65/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1060 - accuracy: 0.9694 - val_loss: 1.3118 - val_accuracy: 0.6799\n","Epoch 66/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0781 - accuracy: 0.9802 - val_loss: 1.3348 - val_accuracy: 0.7138\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0421 - accuracy: 0.9941 - val_loss: 1.6324 - val_accuracy: 0.7081\n","Epoch 68/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0417 - accuracy: 0.9941 - val_loss: 1.6345 - val_accuracy: 0.7036\n","Epoch 69/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0419 - accuracy: 0.9941 - val_loss: 1.7398 - val_accuracy: 0.6697\n","Epoch 70/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0392 - accuracy: 0.9943 - val_loss: 1.7091 - val_accuracy: 0.7025\n","Epoch 71/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0462 - accuracy: 0.9909 - val_loss: 1.8138 - val_accuracy: 0.6833\n","Epoch 72/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0588 - accuracy: 0.9856 - val_loss: 1.5780 - val_accuracy: 0.6810\n","Epoch 73/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0700 - accuracy: 0.9833 - val_loss: 1.4853 - val_accuracy: 0.6697\n","Epoch 74/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0692 - accuracy: 0.9813 - val_loss: 1.4691 - val_accuracy: 0.6821\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0766 - accuracy: 0.9796 - val_loss: 1.4629 - val_accuracy: 0.6833\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0798 - accuracy: 0.9796 - val_loss: 1.4501 - val_accuracy: 0.6878\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0864 - accuracy: 0.9743 - val_loss: 1.3440 - val_accuracy: 0.7070\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0717 - accuracy: 0.9813 - val_loss: 1.4005 - val_accuracy: 0.7070\n","Epoch 79/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0642 - accuracy: 0.9833 - val_loss: 1.4991 - val_accuracy: 0.6900\n","Epoch 80/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0433 - accuracy: 0.9932 - val_loss: 1.7349 - val_accuracy: 0.6889\n","Epoch 81/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0421 - accuracy: 0.9941 - val_loss: 1.5819 - val_accuracy: 0.6980\n","Epoch 82/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0593 - accuracy: 0.9859 - val_loss: 1.5210 - val_accuracy: 0.6765\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0605 - accuracy: 0.9853 - val_loss: 1.6466 - val_accuracy: 0.6900\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0688 - accuracy: 0.9830 - val_loss: 1.4713 - val_accuracy: 0.6810\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0625 - accuracy: 0.9856 - val_loss: 1.4963 - val_accuracy: 0.6889\n","Epoch 86/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0580 - accuracy: 0.9873 - val_loss: 1.5850 - val_accuracy: 0.6821\n","Epoch 87/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0576 - accuracy: 0.9873 - val_loss: 1.4723 - val_accuracy: 0.6753\n","Epoch 88/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0368 - accuracy: 0.9952 - val_loss: 1.6709 - val_accuracy: 0.6923\n","Epoch 89/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0288 - accuracy: 0.9977 - val_loss: 1.7141 - val_accuracy: 0.7048\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0370 - accuracy: 0.9949 - val_loss: 1.6779 - val_accuracy: 0.6821\n","Epoch 91/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0732 - accuracy: 0.9810 - val_loss: 1.2790 - val_accuracy: 0.6889\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0796 - accuracy: 0.9796 - val_loss: 1.3812 - val_accuracy: 0.6912\n","Epoch 93/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0617 - accuracy: 0.9842 - val_loss: 1.4431 - val_accuracy: 0.6821\n","Epoch 94/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0506 - accuracy: 0.9890 - val_loss: 1.6434 - val_accuracy: 0.6980\n","Epoch 95/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0420 - accuracy: 0.9932 - val_loss: 1.6282 - val_accuracy: 0.6968\n","Epoch 96/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0407 - accuracy: 0.9935 - val_loss: 1.8198 - val_accuracy: 0.6765\n","Epoch 97/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0539 - accuracy: 0.9873 - val_loss: 1.6710 - val_accuracy: 0.6878\n","Epoch 98/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0587 - accuracy: 0.9870 - val_loss: 1.4308 - val_accuracy: 0.6946\n","Epoch 99/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0428 - accuracy: 0.9924 - val_loss: 1.6009 - val_accuracy: 0.7036\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0268 - accuracy: 0.9986 - val_loss: 1.6999 - val_accuracy: 0.6934\n","{'loss': [0.6075248122215271, 0.5519425868988037, 0.5225640535354614, 0.5028398633003235, 0.468061625957489, 0.4473688304424286, 0.4302932620048523, 0.42281875014305115, 0.39607444405555725, 0.38367941975593567, 0.39649906754493713, 0.33494827151298523, 0.3203350603580475, 0.33125126361846924, 0.3297032415866852, 0.2979515492916107, 0.2650534510612488, 0.29318925738334656, 0.2281317114830017, 0.22832196950912476, 0.2742404043674469, 0.21414628624916077, 0.2040727734565735, 0.19107943773269653, 0.22649866342544556, 0.18707478046417236, 0.17629064619541168, 0.1878736913204193, 0.22700442373752594, 0.18094831705093384, 0.15251363813877106, 0.1282186508178711, 0.14956653118133545, 0.15462256968021393, 0.12920302152633667, 0.1104828268289566, 0.10266942530870438, 0.10771039128303528, 0.10683558136224747, 0.13779042661190033, 0.12082629650831223, 0.11908955872058868, 0.1063925251364708, 0.14224457740783691, 0.11442902684211731, 0.09055519849061966, 0.12583349645137787, 0.13757185637950897, 0.08178754895925522, 0.08069194853305817, 0.08529075980186462, 0.10508143901824951, 0.06832856684923172, 0.06143355742096901, 0.11033955216407776, 0.10056977719068527, 0.0842071920633316, 0.09177006036043167, 0.07260935008525848, 0.07142569869756699, 0.05868133157491684, 0.06114104390144348, 0.08871186524629593, 0.10705485939979553, 0.10601112246513367, 0.07811310142278671, 0.04207213595509529, 0.041723936796188354, 0.04190858453512192, 0.03915679082274437, 0.046247757971286774, 0.05876718461513519, 0.06995674967765808, 0.0691751167178154, 0.07663340866565704, 0.07976503670215607, 0.08637752383947372, 0.07172584533691406, 0.06415224820375443, 0.043258458375930786, 0.0420750193297863, 0.0592966265976429, 0.06054816022515297, 0.06878051906824112, 0.06254161149263382, 0.058007512241601944, 0.05758330598473549, 0.036824725568294525, 0.028814522549510002, 0.03695501759648323, 0.07323040813207626, 0.0796206146478653, 0.06171301379799843, 0.05062469094991684, 0.04195849969983101, 0.040709443390369415, 0.0539214126765728, 0.05870545282959938, 0.0427921898663044, 0.02679678611457348], 'accuracy': [0.7034521698951721, 0.7382569313049316, 0.7546689510345459, 0.7600452899932861, 0.7914544343948364, 0.7962648272514343, 0.8123939037322998, 0.8152235150337219, 0.8361629843711853, 0.835597038269043, 0.8324844241142273, 0.8692699670791626, 0.875495195388794, 0.8735144138336182, 0.8746463060379028, 0.8845500946044922, 0.8961516618728638, 0.8839841485023499, 0.9252971410751343, 0.9176570177078247, 0.8984153866767883, 0.9269949197769165, 0.934069037437439, 0.9383135437965393, 0.9159592390060425, 0.9383135437965393, 0.9405772686004639, 0.9374646544456482, 0.9241652488708496, 0.9388794302940369, 0.950764000415802, 0.961799681186676, 0.9527447819709778, 0.9524617791175842, 0.960101842880249, 0.9717034697532654, 0.9725523591041565, 0.9725523591041565, 0.9717034697532654, 0.9564233422279358, 0.9646292924880981, 0.9677419066429138, 0.9700056314468384, 0.9538766145706177, 0.9646292924880981, 0.9742501378059387, 0.9629315137863159, 0.9533106684684753, 0.979626476764679, 0.9801924228668213, 0.9765138626098633, 0.9708545804023743, 0.9852858185768127, 0.9855687618255615, 0.9640634059906006, 0.9739671945571899, 0.9767968058586121, 0.9750990271568298, 0.9827390909194946, 0.9816072583198547, 0.9883984327316284, 0.9875495433807373, 0.9745330810546875, 0.9685908555984497, 0.9694397449493408, 0.9801924228668213, 0.9940577149391174, 0.9940577149391174, 0.9940577149391174, 0.994340717792511, 0.9909451007843018, 0.9855687618255615, 0.983305037021637, 0.9813242554664612, 0.979626476764679, 0.979626476764679, 0.9742501378059387, 0.9813242554664612, 0.983305037021637, 0.9932088255882263, 0.9940577149391174, 0.9858517050743103, 0.9852858185768127, 0.9830220937728882, 0.9855687618255615, 0.9872665405273438, 0.9872665405273438, 0.9951896071434021, 0.9977362751960754, 0.9949066042900085, 0.9810413122177124, 0.979626476764679, 0.9841539263725281, 0.988964319229126, 0.9932088255882263, 0.9934917688369751, 0.9872665405273438, 0.986983597278595, 0.9923599362373352, 0.9985851645469666], 'val_loss': [0.7223074436187744, 0.7209652066230774, 0.7196776270866394, 0.7190433144569397, 0.7181364893913269, 0.7160444259643555, 0.7127636075019836, 0.7090228796005249, 0.7147634029388428, 0.7045472860336304, 0.7164101600646973, 0.701373279094696, 0.6652127504348755, 0.7188328504562378, 0.7410964369773865, 0.6743528842926025, 0.7098245620727539, 0.6730279922485352, 0.6477911472320557, 0.7559953331947327, 0.7663909196853638, 0.678243100643158, 0.7120619416236877, 0.7002025842666626, 0.745590090751648, 0.7852365374565125, 0.8434640765190125, 0.8423153758049011, 0.7279078960418701, 0.967401385307312, 1.044853925704956, 1.1114046573638916, 1.0695127248764038, 1.0081079006195068, 1.0758763551712036, 1.1359856128692627, 1.2232367992401123, 1.196824312210083, 1.3170744180679321, 1.1168242692947388, 1.2131919860839844, 1.1776564121246338, 1.353144884109497, 1.0348130464553833, 1.2881176471710205, 1.3756972551345825, 1.079439640045166, 1.283380389213562, 1.3244588375091553, 1.490131139755249, 1.3505771160125732, 1.2468634843826294, 1.4578245878219604, 1.6915525197982788, 1.2437103986740112, 1.2322142124176025, 1.37282395362854, 1.276143193244934, 1.5124645233154297, 1.3799046277999878, 1.5055482387542725, 1.5099867582321167, 1.3437310457229614, 1.2207205295562744, 1.3118135929107666, 1.334783673286438, 1.6323963403701782, 1.634475827217102, 1.7398264408111572, 1.7091034650802612, 1.8137843608856201, 1.5780001878738403, 1.485250473022461, 1.4691441059112549, 1.4628568887710571, 1.4501187801361084, 1.344018816947937, 1.4004952907562256, 1.4991395473480225, 1.734902262687683, 1.5818673372268677, 1.5209863185882568, 1.6465891599655151, 1.4713090658187866, 1.496256709098816, 1.5849915742874146, 1.472308874130249, 1.670912742614746, 1.7141072750091553, 1.6778597831726074, 1.279000997543335, 1.381176471710205, 1.4431058168411255, 1.643381953239441, 1.6282241344451904, 1.8197813034057617, 1.6709892749786377, 1.4308027029037476, 1.6009005308151245, 1.6998977661132812], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4977375566959381, 0.4954751133918762, 0.5113122463226318, 0.4977375566959381, 0.5339366793632507, 0.598416268825531, 0.5441176295280457, 0.529411792755127, 0.610859751701355, 0.5972850918769836, 0.6289592981338501, 0.6606335043907166, 0.6459276080131531, 0.6233031749725342, 0.6911764740943909, 0.6934388875961304, 0.7024886608123779, 0.6719456911087036, 0.6843891143798828, 0.6651583909988403, 0.6889140009880066, 0.7002262473106384, 0.6990950107574463, 0.6742081642150879, 0.6990950107574463, 0.692307710647583, 0.7126696705818176, 0.7217194437980652, 0.7024886608123779, 0.7104072570800781, 0.6877828240394592, 0.6821267008781433, 0.6843891143798828, 0.6719456911087036, 0.7024886608123779, 0.6708144545555115, 0.6843891143798828, 0.692307710647583, 0.6945701241493225, 0.6809954643249512, 0.6776018142700195, 0.6990950107574463, 0.6911764740943909, 0.7013574838638306, 0.6821267008781433, 0.7070135474205017, 0.6719456911087036, 0.7002262473106384, 0.6968325972557068, 0.6979637742042542, 0.7036198973655701, 0.685520350933075, 0.6877828240394592, 0.7013574838638306, 0.6821267008781433, 0.7047511339187622, 0.6990950107574463, 0.679864227771759, 0.7138009071350098, 0.7081447839736938, 0.7036198973655701, 0.6696832776069641, 0.7024886608123779, 0.6832579374313354, 0.6809954643249512, 0.6696832776069641, 0.6821267008781433, 0.6832579374313354, 0.6877828240394592, 0.7070135474205017, 0.7070135474205017, 0.6900452375411987, 0.6889140009880066, 0.6979637742042542, 0.6764705777168274, 0.6900452375411987, 0.6809954643249512, 0.6889140009880066, 0.6821267008781433, 0.6753393411636353, 0.692307710647583, 0.7047511339187622, 0.6821267008781433, 0.6889140009880066, 0.6911764740943909, 0.6821267008781433, 0.6979637742042542, 0.6968325972557068, 0.6764705777168274, 0.6877828240394592, 0.6945701241493225, 0.7036198973655701, 0.6934388875961304]}\n","45/45 [==============================] - 1s 6ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.6020 - accuracy: 0.7045"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 8s 56ms/step - loss: 0.6007 - accuracy: 0.7059 - val_loss: 0.7231 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5567 - accuracy: 0.7256 - val_loss: 0.7241 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5382 - accuracy: 0.7318 - val_loss: 0.7239 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4969 - accuracy: 0.7589 - val_loss: 0.7243 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5006 - accuracy: 0.7623 - val_loss: 0.7324 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4888 - accuracy: 0.7744 - val_loss: 0.7196 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4348 - accuracy: 0.8132 - val_loss: 0.7276 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.4328 - accuracy: 0.8093 - val_loss: 0.7256 - val_accuracy: 0.4866\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4041 - accuracy: 0.8171 - val_loss: 0.7464 - val_accuracy: 0.4855\n","Epoch 10/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.3922 - accuracy: 0.8307 - val_loss: 0.7001 - val_accuracy: 0.5196\n","Epoch 11/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4277 - accuracy: 0.8140 - val_loss: 0.7453 - val_accuracy: 0.4897\n","Epoch 12/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3898 - accuracy: 0.8307 - val_loss: 0.7746 - val_accuracy: 0.4917\n","Epoch 13/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3986 - accuracy: 0.8214 - val_loss: 0.8142 - val_accuracy: 0.4907\n","Epoch 14/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3613 - accuracy: 0.8437 - val_loss: 0.7483 - val_accuracy: 0.5041\n","Epoch 15/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3355 - accuracy: 0.8584 - val_loss: 0.9748 - val_accuracy: 0.4876\n","Epoch 16/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3538 - accuracy: 0.8470 - val_loss: 0.6383 - val_accuracy: 0.6415\n","Epoch 17/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3111 - accuracy: 0.8731 - val_loss: 0.7668 - val_accuracy: 0.5620\n","Epoch 18/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3161 - accuracy: 0.8693 - val_loss: 0.7361 - val_accuracy: 0.5940\n","Epoch 19/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.2661 - accuracy: 0.8933 - val_loss: 0.6328 - val_accuracy: 0.6932\n","Epoch 20/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3435 - accuracy: 0.8548 - val_loss: 0.6577 - val_accuracy: 0.6746\n","Epoch 21/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2718 - accuracy: 0.8881 - val_loss: 0.7004 - val_accuracy: 0.6777\n","Epoch 22/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2560 - accuracy: 0.8953 - val_loss: 0.7301 - val_accuracy: 0.6694\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2371 - accuracy: 0.9111 - val_loss: 0.8945 - val_accuracy: 0.6612\n","Epoch 24/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2304 - accuracy: 0.9145 - val_loss: 0.8184 - val_accuracy: 0.6705\n","Epoch 25/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2032 - accuracy: 0.9258 - val_loss: 0.9273 - val_accuracy: 0.6890\n","Epoch 26/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2360 - accuracy: 0.9078 - val_loss: 0.8932 - val_accuracy: 0.6715\n","Epoch 27/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.2135 - accuracy: 0.9202 - val_loss: 0.8497 - val_accuracy: 0.7025\n","Epoch 28/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2387 - accuracy: 0.9028 - val_loss: 0.9391 - val_accuracy: 0.6705\n","Epoch 29/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1989 - accuracy: 0.9245 - val_loss: 1.0350 - val_accuracy: 0.6983\n","Epoch 30/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1642 - accuracy: 0.9450 - val_loss: 1.3219 - val_accuracy: 0.6612\n","Epoch 31/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.2196 - accuracy: 0.9160 - val_loss: 0.8719 - val_accuracy: 0.7076\n","Epoch 32/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.1640 - accuracy: 0.9416 - val_loss: 1.1495 - val_accuracy: 0.6890\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1331 - accuracy: 0.9568 - val_loss: 1.1309 - val_accuracy: 0.6818\n","Epoch 34/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1663 - accuracy: 0.9432 - val_loss: 1.1325 - val_accuracy: 0.6901\n","Epoch 35/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1477 - accuracy: 0.9501 - val_loss: 1.2499 - val_accuracy: 0.6622\n","Epoch 36/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1715 - accuracy: 0.9382 - val_loss: 1.0714 - val_accuracy: 0.6901\n","Epoch 37/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1989 - accuracy: 0.9245 - val_loss: 0.9872 - val_accuracy: 0.6921\n","Epoch 38/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1535 - accuracy: 0.9447 - val_loss: 1.1957 - val_accuracy: 0.6860\n","Epoch 39/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1220 - accuracy: 0.9592 - val_loss: 1.4922 - val_accuracy: 0.6570\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1524 - accuracy: 0.9481 - val_loss: 1.0804 - val_accuracy: 0.6942\n","Epoch 41/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.1261 - accuracy: 0.9574 - val_loss: 1.2748 - val_accuracy: 0.7128\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2534 - accuracy: 0.9096 - val_loss: 0.9409 - val_accuracy: 0.6942\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1248 - accuracy: 0.9610 - val_loss: 1.4478 - val_accuracy: 0.6932\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1522 - accuracy: 0.9475 - val_loss: 1.3111 - val_accuracy: 0.6921\n","Epoch 45/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1377 - accuracy: 0.9537 - val_loss: 1.1991 - val_accuracy: 0.7087\n","Epoch 46/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1060 - accuracy: 0.9695 - val_loss: 1.3332 - val_accuracy: 0.6890\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1122 - accuracy: 0.9654 - val_loss: 1.4207 - val_accuracy: 0.6715\n","Epoch 48/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1705 - accuracy: 0.9388 - val_loss: 1.0808 - val_accuracy: 0.7097\n","Epoch 49/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1129 - accuracy: 0.9612 - val_loss: 1.4078 - val_accuracy: 0.6952\n","Epoch 50/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0839 - accuracy: 0.9736 - val_loss: 1.6229 - val_accuracy: 0.6911\n","Epoch 51/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0775 - accuracy: 0.9786 - val_loss: 1.6147 - val_accuracy: 0.7035\n","Epoch 52/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0804 - accuracy: 0.9793 - val_loss: 1.5833 - val_accuracy: 0.6932\n","Epoch 53/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0932 - accuracy: 0.9705 - val_loss: 1.5082 - val_accuracy: 0.6870\n","Epoch 54/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1065 - accuracy: 0.9677 - val_loss: 1.5494 - val_accuracy: 0.6849\n","Epoch 55/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1888 - accuracy: 0.9382 - val_loss: 1.0483 - val_accuracy: 0.6880\n","Epoch 56/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0852 - accuracy: 0.9757 - val_loss: 1.5457 - val_accuracy: 0.6963\n","Epoch 57/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1307 - accuracy: 0.9561 - val_loss: 1.2650 - val_accuracy: 0.6622\n","Epoch 58/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0896 - accuracy: 0.9752 - val_loss: 1.6079 - val_accuracy: 0.6715\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0543 - accuracy: 0.9904 - val_loss: 1.6068 - val_accuracy: 0.6932\n","Epoch 60/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0562 - accuracy: 0.9884 - val_loss: 1.7650 - val_accuracy: 0.6921\n","Epoch 61/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0904 - accuracy: 0.9734 - val_loss: 1.4841 - val_accuracy: 0.6756\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0894 - accuracy: 0.9749 - val_loss: 1.4672 - val_accuracy: 0.6942\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0928 - accuracy: 0.9775 - val_loss: 1.6181 - val_accuracy: 0.6581\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1004 - accuracy: 0.9680 - val_loss: 1.4849 - val_accuracy: 0.6705\n","Epoch 65/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0884 - accuracy: 0.9739 - val_loss: 1.4810 - val_accuracy: 0.6829\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0993 - accuracy: 0.9705 - val_loss: 1.4379 - val_accuracy: 0.6983\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1312 - accuracy: 0.9558 - val_loss: 1.2708 - val_accuracy: 0.6849\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0772 - accuracy: 0.9788 - val_loss: 1.5743 - val_accuracy: 0.6860\n","Epoch 69/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0733 - accuracy: 0.9804 - val_loss: 1.4129 - val_accuracy: 0.6911\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0587 - accuracy: 0.9871 - val_loss: 1.5553 - val_accuracy: 0.7107\n","Epoch 71/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0449 - accuracy: 0.9915 - val_loss: 1.8065 - val_accuracy: 0.7066\n","Epoch 72/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0827 - accuracy: 0.9760 - val_loss: 1.4368 - val_accuracy: 0.6921\n","Epoch 73/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.1067 - accuracy: 0.9649 - val_loss: 1.2833 - val_accuracy: 0.6870\n","Epoch 74/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0963 - accuracy: 0.9685 - val_loss: 1.4797 - val_accuracy: 0.6963\n","Epoch 75/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.1199 - accuracy: 0.9594 - val_loss: 1.5331 - val_accuracy: 0.6632\n","Epoch 76/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0796 - accuracy: 0.9765 - val_loss: 1.4416 - val_accuracy: 0.6777\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0636 - accuracy: 0.9848 - val_loss: 1.5382 - val_accuracy: 0.7014\n","Epoch 78/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0550 - accuracy: 0.9886 - val_loss: 1.6363 - val_accuracy: 0.6880\n","Epoch 79/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0430 - accuracy: 0.9925 - val_loss: 1.7515 - val_accuracy: 0.6973\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0474 - accuracy: 0.9925 - val_loss: 1.8469 - val_accuracy: 0.6921\n","Epoch 81/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0635 - accuracy: 0.9848 - val_loss: 1.5651 - val_accuracy: 0.6818\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0815 - accuracy: 0.9765 - val_loss: 1.4470 - val_accuracy: 0.6849\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0788 - accuracy: 0.9773 - val_loss: 1.4978 - val_accuracy: 0.6798\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1562 - accuracy: 0.9444 - val_loss: 1.2669 - val_accuracy: 0.6612\n","Epoch 85/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0808 - accuracy: 0.9765 - val_loss: 1.3876 - val_accuracy: 0.6901\n","Epoch 86/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0479 - accuracy: 0.9920 - val_loss: 1.8133 - val_accuracy: 0.6756\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0531 - accuracy: 0.9876 - val_loss: 1.5950 - val_accuracy: 0.7004\n","Epoch 88/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1109 - accuracy: 0.9654 - val_loss: 1.2075 - val_accuracy: 0.7004\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0649 - accuracy: 0.9835 - val_loss: 1.6614 - val_accuracy: 0.7004\n","Epoch 90/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0464 - accuracy: 0.9907 - val_loss: 1.6037 - val_accuracy: 0.6839\n","Epoch 91/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0390 - accuracy: 0.9935 - val_loss: 1.6930 - val_accuracy: 0.7118\n","Epoch 92/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0317 - accuracy: 0.9961 - val_loss: 1.8742 - val_accuracy: 0.6932\n","Epoch 93/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1435 - accuracy: 0.9543 - val_loss: 1.1271 - val_accuracy: 0.6911\n","Epoch 94/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0895 - accuracy: 0.9744 - val_loss: 1.4801 - val_accuracy: 0.6901\n","Epoch 95/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0591 - accuracy: 0.9850 - val_loss: 1.6086 - val_accuracy: 0.6870\n","Epoch 96/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0452 - accuracy: 0.9904 - val_loss: 1.6526 - val_accuracy: 0.6880\n","Epoch 97/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0357 - accuracy: 0.9956 - val_loss: 1.6837 - val_accuracy: 0.7056\n","Epoch 98/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0302 - accuracy: 0.9964 - val_loss: 1.7921 - val_accuracy: 0.6921\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0314 - accuracy: 0.9946 - val_loss: 1.7808 - val_accuracy: 0.6860\n","Epoch 100/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0785 - accuracy: 0.9788 - val_loss: 1.3963 - val_accuracy: 0.6921\n","{'loss': [0.6006946563720703, 0.556734561920166, 0.5381530523300171, 0.4968908131122589, 0.5006304383277893, 0.4887874126434326, 0.4347850978374481, 0.43283531069755554, 0.4040648341178894, 0.39218008518218994, 0.42771318554878235, 0.38980716466903687, 0.39860206842422485, 0.36130955815315247, 0.33553797006607056, 0.3538067042827606, 0.3110707104206085, 0.31609925627708435, 0.2661031484603882, 0.34353891015052795, 0.2717634439468384, 0.2560367286205292, 0.23706398904323578, 0.23036131262779236, 0.20323941111564636, 0.23604191839694977, 0.2134740650653839, 0.2386695295572281, 0.1989159733057022, 0.1642247587442398, 0.2196233868598938, 0.16400177776813507, 0.133077010512352, 0.1663057804107666, 0.14774592220783234, 0.17146925628185272, 0.198896124958992, 0.15349902212619781, 0.12197422981262207, 0.15239018201828003, 0.12611925601959229, 0.25342631340026855, 0.12477120012044907, 0.1522008627653122, 0.1377490758895874, 0.105974942445755, 0.11221452057361603, 0.17049865424633026, 0.11292900145053864, 0.08390279859304428, 0.0775330513715744, 0.0804072842001915, 0.09316344559192657, 0.10647299885749817, 0.188839852809906, 0.08515000343322754, 0.13071906566619873, 0.08964044600725174, 0.054293736815452576, 0.056173428893089294, 0.09043744951486588, 0.08938944339752197, 0.09282008558511734, 0.10040461272001266, 0.08837240189313889, 0.09926620870828629, 0.13122676312923431, 0.07719093561172485, 0.07330911606550217, 0.05866580456495285, 0.04489326849579811, 0.08267546445131302, 0.10670982301235199, 0.09633287787437439, 0.1198841780424118, 0.07961105555295944, 0.06359009444713593, 0.055011019110679626, 0.04298372566699982, 0.047384560108184814, 0.06352951377630234, 0.0815085768699646, 0.07875195145606995, 0.15615056455135345, 0.08078837394714355, 0.047919731587171555, 0.05308365821838379, 0.1109275296330452, 0.06487839668989182, 0.046441700309515, 0.038960929960012436, 0.03170246630907059, 0.14349186420440674, 0.08954491466283798, 0.059114620089530945, 0.045249562710523605, 0.03565341606736183, 0.03017333336174488, 0.03139449656009674, 0.07849449664354324], 'accuracy': [0.7059431672096252, 0.7255814075469971, 0.7317829728126526, 0.7589147090911865, 0.762273907661438, 0.7744185924530029, 0.813178300857544, 0.8093023300170898, 0.817054271697998, 0.8307493329048157, 0.8139534592628479, 0.8307493329048157, 0.8214470148086548, 0.8436692357063293, 0.8583979606628418, 0.8470284342765808, 0.8731266260147095, 0.8692506551742554, 0.8932816386222839, 0.854780375957489, 0.8881136775016785, 0.895348846912384, 0.9111111164093018, 0.9144702553749084, 0.9258397817611694, 0.9077519178390503, 0.9201550483703613, 0.9028424024581909, 0.9245477914810181, 0.9449612498283386, 0.9160206913948059, 0.9416020512580872, 0.9568475484848022, 0.9431524276733398, 0.9501292109489441, 0.9382429122924805, 0.9245477914810181, 0.9447028636932373, 0.9591731429100037, 0.948062002658844, 0.9573643207550049, 0.9095607399940491, 0.9609819054603577, 0.9475452303886414, 0.9537467956542969, 0.9695090651512146, 0.9653746485710144, 0.9387596845626831, 0.961240291595459, 0.97364342212677, 0.9785529971122742, 0.9793281555175781, 0.9705426096916199, 0.9677002429962158, 0.9382429122924805, 0.9757105708122253, 0.9560723304748535, 0.9751937985420227, 0.9904392957687378, 0.9883720874786377, 0.9733850359916687, 0.9749354124069214, 0.9775193929672241, 0.9679586291313171, 0.9739018082618713, 0.9705426096916199, 0.9558139443397522, 0.9788113832473755, 0.9803617596626282, 0.9870800971984863, 0.9914728403091431, 0.9759690165519714, 0.9648578763008118, 0.9684754610061646, 0.959431529045105, 0.9764857888221741, 0.9847545027732849, 0.988630473613739, 0.9925064444541931, 0.9925064444541931, 0.9847545027732849, 0.9764857888221741, 0.9772610068321228, 0.9444444179534912, 0.9764857888221741, 0.9919896721839905, 0.987596869468689, 0.9653746485710144, 0.9834625124931335, 0.9906976819038391, 0.9935400485992432, 0.9961240291595459, 0.9542635679244995, 0.974418580532074, 0.985012948513031, 0.9904392957687378, 0.9956072568893433, 0.9963824152946472, 0.9945736527442932, 0.9788113832473755], 'val_loss': [0.7230705618858337, 0.7240831255912781, 0.7238569855690002, 0.7242749333381653, 0.7324039936065674, 0.7195593118667603, 0.727609395980835, 0.7256073951721191, 0.7464395761489868, 0.7001320719718933, 0.7453298568725586, 0.774591863155365, 0.8141714334487915, 0.7482520341873169, 0.9748183488845825, 0.6382819414138794, 0.7668287754058838, 0.7360764145851135, 0.6327721476554871, 0.6576796770095825, 0.7003501653671265, 0.7300853133201599, 0.8944635987281799, 0.8183597326278687, 0.9272839426994324, 0.8932350277900696, 0.8497287631034851, 0.9390533566474915, 1.0350314378738403, 1.3219372034072876, 0.871911346912384, 1.149509072303772, 1.1308521032333374, 1.1324868202209473, 1.2498838901519775, 1.0713603496551514, 0.9871944785118103, 1.195722222328186, 1.4922378063201904, 1.0804483890533447, 1.2748109102249146, 0.9409389495849609, 1.4478492736816406, 1.311140537261963, 1.1990880966186523, 1.3332332372665405, 1.4207260608673096, 1.0808076858520508, 1.407800555229187, 1.6229252815246582, 1.6146631240844727, 1.583295464515686, 1.508237600326538, 1.5494353771209717, 1.0483349561691284, 1.5457379817962646, 1.2649993896484375, 1.6078687906265259, 1.6067804098129272, 1.7649586200714111, 1.48410964012146, 1.4671767950057983, 1.6181272268295288, 1.484937310218811, 1.481037974357605, 1.4379223585128784, 1.2708145380020142, 1.5743154287338257, 1.4128749370574951, 1.5553135871887207, 1.8064528703689575, 1.4368458986282349, 1.2832756042480469, 1.4796823263168335, 1.5330784320831299, 1.4416002035140991, 1.5381847620010376, 1.636330485343933, 1.7514667510986328, 1.8468822240829468, 1.5650824308395386, 1.4469856023788452, 1.4977760314941406, 1.2668776512145996, 1.3875889778137207, 1.8132951259613037, 1.5949844121932983, 1.2074928283691406, 1.661404013633728, 1.6037330627441406, 1.6929526329040527, 1.8741735219955444, 1.1270922422409058, 1.4801297187805176, 1.6085553169250488, 1.652642846107483, 1.6837165355682373, 1.7920546531677246, 1.7807713747024536, 1.3962711095809937], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.48553720116615295, 0.51962810754776, 0.48966941237449646, 0.4917355477809906, 0.49070248007774353, 0.5041322112083435, 0.4876033067703247, 0.6415289044380188, 0.5619834661483765, 0.5940082669258118, 0.6931818127632141, 0.6745867729187012, 0.6776859760284424, 0.6694214940071106, 0.6611570119857788, 0.6704545617103577, 0.6890496015548706, 0.6714876294136047, 0.702479362487793, 0.6704545617103577, 0.6983470916748047, 0.6611570119857788, 0.7076446413993835, 0.6890496015548706, 0.6818181872367859, 0.6900826692581177, 0.6621900796890259, 0.6900826692581177, 0.692148745059967, 0.6859503984451294, 0.6570248007774353, 0.6942148804664612, 0.7128099203109741, 0.6942148804664612, 0.6931818127632141, 0.692148745059967, 0.7086777091026306, 0.6890496015548706, 0.6714876294136047, 0.7097107172012329, 0.6952479481697083, 0.69111567735672, 0.7035123705863953, 0.6931818127632141, 0.6869834661483765, 0.6849173307418823, 0.6880165338516235, 0.6962810158729553, 0.6621900796890259, 0.6714876294136047, 0.6931818127632141, 0.692148745059967, 0.6756198406219482, 0.6942148804664612, 0.6580578684806824, 0.6704545617103577, 0.682851254940033, 0.6983470916748047, 0.6849173307418823, 0.6859503984451294, 0.69111567735672, 0.71074378490448, 0.7066115736961365, 0.692148745059967, 0.6869834661483765, 0.6962810158729553, 0.663223147392273, 0.6776859760284424, 0.7014462947845459, 0.6880165338516235, 0.6973140239715576, 0.692148745059967, 0.6818181872367859, 0.6849173307418823, 0.6797520518302917, 0.6611570119857788, 0.6900826692581177, 0.6756198406219482, 0.7004132270812988, 0.7004132270812988, 0.7004132270812988, 0.68388432264328, 0.711776852607727, 0.6931818127632141, 0.69111567735672, 0.6900826692581177, 0.6869834661483765, 0.6880165338516235, 0.7055785059928894, 0.692148745059967, 0.6859503984451294, 0.692148745059967]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.2686 - accuracy: 0.8947"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 7s 58ms/step - loss: 0.2656 - accuracy: 0.8960 - val_loss: 0.7414 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1623 - accuracy: 0.9445 - val_loss: 0.7320 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1318 - accuracy: 0.9537 - val_loss: 0.7352 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1162 - accuracy: 0.9623 - val_loss: 0.7652 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.1038 - accuracy: 0.9666 - val_loss: 0.7707 - val_accuracy: 0.4860\n","Epoch 6/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.0879 - accuracy: 0.9720 - val_loss: 0.7661 - val_accuracy: 0.4892\n","Epoch 7/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0976 - accuracy: 0.9679 - val_loss: 0.8142 - val_accuracy: 0.4881\n","Epoch 8/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1096 - accuracy: 0.9644 - val_loss: 0.8379 - val_accuracy: 0.4892\n","Epoch 9/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.0964 - accuracy: 0.9728 - val_loss: 0.9063 - val_accuracy: 0.4925\n","Epoch 10/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0980 - accuracy: 0.9682 - val_loss: 0.9604 - val_accuracy: 0.4946\n","Epoch 11/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.1076 - accuracy: 0.9644 - val_loss: 0.7589 - val_accuracy: 0.5539\n","Epoch 12/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0967 - accuracy: 0.9720 - val_loss: 0.8163 - val_accuracy: 0.5593\n","Epoch 13/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0840 - accuracy: 0.9733 - val_loss: 0.7996 - val_accuracy: 0.5614\n","Epoch 14/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0759 - accuracy: 0.9782 - val_loss: 0.8877 - val_accuracy: 0.5593\n","Epoch 15/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0570 - accuracy: 0.9857 - val_loss: 1.0565 - val_accuracy: 0.5593\n","Epoch 16/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0638 - accuracy: 0.9822 - val_loss: 0.9175 - val_accuracy: 0.6164\n","Epoch 17/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0696 - accuracy: 0.9803 - val_loss: 0.8577 - val_accuracy: 0.6541\n","Epoch 18/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0854 - accuracy: 0.9744 - val_loss: 0.8326 - val_accuracy: 0.6282\n","Epoch 19/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0689 - accuracy: 0.9793 - val_loss: 0.6447 - val_accuracy: 0.7360\n","Epoch 20/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0619 - accuracy: 0.9838 - val_loss: 0.7496 - val_accuracy: 0.7155\n","Epoch 21/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0546 - accuracy: 0.9876 - val_loss: 0.9810 - val_accuracy: 0.7047\n","Epoch 22/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.1131 - accuracy: 0.9628 - val_loss: 0.5789 - val_accuracy: 0.7543\n","Epoch 23/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0866 - accuracy: 0.9723 - val_loss: 0.6476 - val_accuracy: 0.7694\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0517 - accuracy: 0.9871 - val_loss: 0.8277 - val_accuracy: 0.7532\n","Epoch 25/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.0610 - accuracy: 0.9822 - val_loss: 0.7782 - val_accuracy: 0.7759\n","Epoch 26/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0607 - accuracy: 0.9863 - val_loss: 0.9746 - val_accuracy: 0.7489\n","Epoch 27/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0564 - accuracy: 0.9846 - val_loss: 0.8841 - val_accuracy: 0.7737\n","Epoch 28/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.0549 - accuracy: 0.9873 - val_loss: 0.8394 - val_accuracy: 0.7877\n","Epoch 29/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0802 - accuracy: 0.9766 - val_loss: 0.7927 - val_accuracy: 0.7845\n","Epoch 30/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0672 - accuracy: 0.9806 - val_loss: 0.9423 - val_accuracy: 0.7716\n","Epoch 31/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0505 - accuracy: 0.9863 - val_loss: 0.9531 - val_accuracy: 0.7812\n","Epoch 32/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0644 - accuracy: 0.9801 - val_loss: 0.8903 - val_accuracy: 0.7791\n","Epoch 33/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0526 - accuracy: 0.9879 - val_loss: 1.0231 - val_accuracy: 0.7888\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0661 - accuracy: 0.9809 - val_loss: 0.8257 - val_accuracy: 0.7845\n","Epoch 35/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0407 - accuracy: 0.9911 - val_loss: 0.9365 - val_accuracy: 0.7866\n","Epoch 36/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0383 - accuracy: 0.9903 - val_loss: 1.0399 - val_accuracy: 0.8006\n","Epoch 37/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0412 - accuracy: 0.9927 - val_loss: 1.0023 - val_accuracy: 0.7834\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0415 - accuracy: 0.9916 - val_loss: 1.0860 - val_accuracy: 0.7888\n","Epoch 39/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0463 - accuracy: 0.9906 - val_loss: 1.0826 - val_accuracy: 0.7823\n","Epoch 40/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0381 - accuracy: 0.9927 - val_loss: 0.9888 - val_accuracy: 0.7974\n","Epoch 41/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0405 - accuracy: 0.9925 - val_loss: 1.0442 - val_accuracy: 0.7812\n","Epoch 42/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0700 - accuracy: 0.9787 - val_loss: 0.9317 - val_accuracy: 0.7726\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0864 - accuracy: 0.9725 - val_loss: 0.9253 - val_accuracy: 0.7683\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0595 - accuracy: 0.9838 - val_loss: 0.9814 - val_accuracy: 0.7802\n","Epoch 45/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0482 - accuracy: 0.9876 - val_loss: 0.9755 - val_accuracy: 0.7737\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0479 - accuracy: 0.9895 - val_loss: 0.9883 - val_accuracy: 0.7823\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0303 - accuracy: 0.9949 - val_loss: 1.1238 - val_accuracy: 0.7726\n","Epoch 48/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.0291 - accuracy: 0.9949 - val_loss: 1.0033 - val_accuracy: 0.8017\n","Epoch 49/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0330 - accuracy: 0.9946 - val_loss: 1.1316 - val_accuracy: 0.7845\n","Epoch 50/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0517 - accuracy: 0.9855 - val_loss: 1.2243 - val_accuracy: 0.7769\n","Epoch 51/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0741 - accuracy: 0.9774 - val_loss: 0.8855 - val_accuracy: 0.7629\n","Epoch 52/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0630 - accuracy: 0.9830 - val_loss: 1.0125 - val_accuracy: 0.7694\n","Epoch 53/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0510 - accuracy: 0.9879 - val_loss: 0.9579 - val_accuracy: 0.7780\n","Epoch 54/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0387 - accuracy: 0.9916 - val_loss: 1.0946 - val_accuracy: 0.7769\n","Epoch 55/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0266 - accuracy: 0.9973 - val_loss: 1.1835 - val_accuracy: 0.7716\n","Epoch 56/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0405 - accuracy: 0.9914 - val_loss: 1.0076 - val_accuracy: 0.7759\n","Epoch 57/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0550 - accuracy: 0.9855 - val_loss: 1.1770 - val_accuracy: 0.7500\n","Epoch 58/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0690 - accuracy: 0.9795 - val_loss: 1.0172 - val_accuracy: 0.7672\n","Epoch 59/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0489 - accuracy: 0.9887 - val_loss: 1.0517 - val_accuracy: 0.7619\n","Epoch 60/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0281 - accuracy: 0.9957 - val_loss: 1.1880 - val_accuracy: 0.7565\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0293 - accuracy: 0.9954 - val_loss: 1.0737 - val_accuracy: 0.7845\n","Epoch 62/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0331 - accuracy: 0.9941 - val_loss: 1.1278 - val_accuracy: 0.7651\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0489 - accuracy: 0.9892 - val_loss: 1.1692 - val_accuracy: 0.7511\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0735 - accuracy: 0.9779 - val_loss: 0.8954 - val_accuracy: 0.7716\n","Epoch 65/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0455 - accuracy: 0.9903 - val_loss: 1.1694 - val_accuracy: 0.7511\n","Epoch 66/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0393 - accuracy: 0.9911 - val_loss: 1.0439 - val_accuracy: 0.7619\n","Epoch 67/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0294 - accuracy: 0.9952 - val_loss: 1.0823 - val_accuracy: 0.7812\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0305 - accuracy: 0.9935 - val_loss: 1.2125 - val_accuracy: 0.7672\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0391 - accuracy: 0.9914 - val_loss: 1.1736 - val_accuracy: 0.7619\n","Epoch 70/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0472 - accuracy: 0.9871 - val_loss: 0.9682 - val_accuracy: 0.7834\n","Epoch 71/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9801 - val_loss: 1.0558 - val_accuracy: 0.7640\n","Epoch 72/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0506 - accuracy: 0.9863 - val_loss: 0.9782 - val_accuracy: 0.7683\n","Epoch 73/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0305 - accuracy: 0.9930 - val_loss: 1.0362 - val_accuracy: 0.7737\n","Epoch 74/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0189 - accuracy: 0.9989 - val_loss: 1.1544 - val_accuracy: 0.7834\n","Epoch 75/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0171 - accuracy: 0.9995 - val_loss: 1.0851 - val_accuracy: 0.7953\n","Epoch 76/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.1673 - val_accuracy: 0.7888\n","Epoch 77/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0160 - accuracy: 0.9997 - val_loss: 1.1689 - val_accuracy: 0.7823\n","Epoch 78/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.1504 - val_accuracy: 0.7920\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.1018 - val_accuracy: 0.7953\n","Epoch 80/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0161 - accuracy: 0.9995 - val_loss: 1.1084 - val_accuracy: 0.7963\n","Epoch 81/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0159 - accuracy: 0.9997 - val_loss: 1.1191 - val_accuracy: 0.7899\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0208 - accuracy: 0.9978 - val_loss: 1.2333 - val_accuracy: 0.7705\n","Epoch 83/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0359 - accuracy: 0.9919 - val_loss: 1.0863 - val_accuracy: 0.7640\n","Epoch 84/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0895 - accuracy: 0.9739 - val_loss: 0.7898 - val_accuracy: 0.7565\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0656 - accuracy: 0.9801 - val_loss: 1.0339 - val_accuracy: 0.7554\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0636 - accuracy: 0.9811 - val_loss: 0.8985 - val_accuracy: 0.7780\n","Epoch 87/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0453 - accuracy: 0.9892 - val_loss: 1.0630 - val_accuracy: 0.7597\n","Epoch 88/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0490 - accuracy: 0.9876 - val_loss: 1.0353 - val_accuracy: 0.7705\n","Epoch 89/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0409 - accuracy: 0.9914 - val_loss: 1.1998 - val_accuracy: 0.7640\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0562 - accuracy: 0.9830 - val_loss: 1.1142 - val_accuracy: 0.7392\n","Epoch 91/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0466 - accuracy: 0.9890 - val_loss: 1.1053 - val_accuracy: 0.7597\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0251 - accuracy: 0.9968 - val_loss: 1.2561 - val_accuracy: 0.7500\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0208 - accuracy: 0.9970 - val_loss: 1.1980 - val_accuracy: 0.7726\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0169 - accuracy: 0.9995 - val_loss: 1.2341 - val_accuracy: 0.7791\n","Epoch 95/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0168 - accuracy: 0.9987 - val_loss: 1.3165 - val_accuracy: 0.7575\n","Epoch 96/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0155 - accuracy: 0.9997 - val_loss: 1.2814 - val_accuracy: 0.7705\n","Epoch 97/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.2728 - val_accuracy: 0.7834\n","Epoch 98/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.2712 - val_accuracy: 0.7769\n","Epoch 99/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.2510 - val_accuracy: 0.7802\n","Epoch 100/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.2408 - val_accuracy: 0.7791\n","{'loss': [0.26555129885673523, 0.16228632628917694, 0.1317598670721054, 0.11623170971870422, 0.10376127064228058, 0.08790643513202667, 0.09760059416294098, 0.10960148274898529, 0.09635937958955765, 0.09802740812301636, 0.10755015909671783, 0.09670831263065338, 0.08403783291578293, 0.07588579505681992, 0.05701829493045807, 0.06383107602596283, 0.0695682018995285, 0.08544366806745529, 0.06890484690666199, 0.061901554465293884, 0.05456792935729027, 0.1130819246172905, 0.0866113156080246, 0.05173270031809807, 0.060971926897764206, 0.060733504593372345, 0.056393738836050034, 0.05486467853188515, 0.0801583006978035, 0.06717357784509659, 0.05054476112127304, 0.06439941376447678, 0.05261977016925812, 0.06605251133441925, 0.04073292389512062, 0.03832273557782173, 0.04120391979813576, 0.041487667709589005, 0.0462762825191021, 0.03809493035078049, 0.040458545088768005, 0.06997498124837875, 0.08640365302562714, 0.05953521654009819, 0.04821210727095604, 0.04794628918170929, 0.03027166612446308, 0.0290991198271513, 0.03301136940717697, 0.05174730718135834, 0.07411374896764755, 0.06297171115875244, 0.05103515088558197, 0.03872497007250786, 0.02659222111105919, 0.04047242924571037, 0.054974161088466644, 0.06896175444126129, 0.048868242651224136, 0.028124185279011726, 0.02925276942551136, 0.033107876777648926, 0.048900920897722244, 0.07351686805486679, 0.04547146335244179, 0.03931830823421478, 0.02941695787012577, 0.030547088012099266, 0.0391295850276947, 0.04724891111254692, 0.0670272558927536, 0.050607215613126755, 0.030533334240317345, 0.018893711268901825, 0.017117826268076897, 0.01634524203836918, 0.015960372984409332, 0.015257584862411022, 0.015191338025033474, 0.01607719250023365, 0.015851303935050964, 0.020786814391613007, 0.03589397296309471, 0.08952541649341583, 0.0656011626124382, 0.06356620043516159, 0.04533502459526062, 0.049003180116415024, 0.04090161249041557, 0.056162167340517044, 0.04661903530359268, 0.025107907131314278, 0.02080574445426464, 0.016928168013691902, 0.01684553362429142, 0.01550319418311119, 0.013973657041788101, 0.013826584443449974, 0.013383706100285053, 0.013180810026824474], 'accuracy': [0.8960129022598267, 0.9445043206214905, 0.9536637663841248, 0.962284505367279, 0.9665948152542114, 0.9719827771186829, 0.9679418206214905, 0.9644396305084229, 0.9727909564971924, 0.9682112336158752, 0.9644396305084229, 0.9719827771186829, 0.9733297228813171, 0.978178858757019, 0.985722005367279, 0.9822198152542114, 0.9803340435028076, 0.9744073152542114, 0.9792564511299133, 0.9838362336158752, 0.9876077771186829, 0.9628232717514038, 0.9722521305084229, 0.9870689511299133, 0.9822198152542114, 0.9862607717514038, 0.9846444129943848, 0.9873383641242981, 0.9765625, 0.9806034564971924, 0.9862607717514038, 0.9800646305084229, 0.9878771305084229, 0.9808728694915771, 0.9911099076271057, 0.9903017282485962, 0.9927262663841248, 0.9916487336158752, 0.990571141242981, 0.9927262663841248, 0.9924569129943848, 0.9787176847457886, 0.9725215435028076, 0.9838362336158752, 0.9876077771186829, 0.9894935488700867, 0.9948814511299133, 0.9948814511299133, 0.9946120977401733, 0.9854525923728943, 0.9773706793785095, 0.983027994632721, 0.9878771305084229, 0.9916487336158752, 0.9973060488700867, 0.9913793206214905, 0.9854525923728943, 0.9795258641242981, 0.9886853694915771, 0.9956896305084229, 0.9954202771186829, 0.9940732717514038, 0.9892241358757019, 0.977909505367279, 0.9903017282485962, 0.9911099076271057, 0.9951508641242981, 0.993534505367279, 0.9913793206214905, 0.9870689511299133, 0.9800646305084229, 0.9862607717514038, 0.9929956793785095, 0.9989224076271057, 0.9994612336158752, 1.0, 0.9997305870056152, 1.0, 1.0, 0.9994612336158752, 0.9997305870056152, 0.9978448152542114, 0.9919180870056152, 0.9738685488700867, 0.9800646305084229, 0.9811422228813171, 0.9892241358757019, 0.9876077771186829, 0.9913793206214905, 0.983027994632721, 0.9889547228813171, 0.9967672228813171, 0.9970366358757019, 0.9994612336158752, 0.998652994632721, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.7414379119873047, 0.7319627404212952, 0.7352131605148315, 0.7651869654655457, 0.7706717252731323, 0.7660855054855347, 0.8141881823539734, 0.8379024267196655, 0.9062989950180054, 0.9604484438896179, 0.7588710784912109, 0.8163207769393921, 0.7995865941047668, 0.8877480626106262, 1.0565061569213867, 0.9174875020980835, 0.857715368270874, 0.8325958847999573, 0.6447028517723083, 0.7496129870414734, 0.9809683561325073, 0.5789042115211487, 0.6475955843925476, 0.8277019262313843, 0.7781527042388916, 0.9745712280273438, 0.8841467499732971, 0.8394193053245544, 0.7926579713821411, 0.9423147439956665, 0.9530956149101257, 0.8902938961982727, 1.023077130317688, 0.8257154822349548, 0.9364944100379944, 1.039915919303894, 1.0023373365402222, 1.0860490798950195, 1.0825879573822021, 0.9887725710868835, 1.044172763824463, 0.93166583776474, 0.9252829551696777, 0.9814006686210632, 0.9755213260650635, 0.9883100390434265, 1.1237865686416626, 1.003334403038025, 1.1316274404525757, 1.2243413925170898, 0.8855209946632385, 1.0125168561935425, 0.9578573703765869, 1.09456467628479, 1.1834746599197388, 1.0075665712356567, 1.1770161390304565, 1.0171592235565186, 1.0517133474349976, 1.1879664659500122, 1.0736818313598633, 1.1277979612350464, 1.1692389249801636, 0.8953901529312134, 1.1694309711456299, 1.0439225435256958, 1.0822949409484863, 1.2125064134597778, 1.1735754013061523, 0.9681723117828369, 1.0557682514190674, 0.9781913757324219, 1.036240816116333, 1.154433012008667, 1.0850820541381836, 1.1672910451889038, 1.1689109802246094, 1.1504329442977905, 1.1018376350402832, 1.108436107635498, 1.1190900802612305, 1.2333364486694336, 1.0863207578659058, 0.7897775769233704, 1.033876657485962, 0.8984959125518799, 1.062963843345642, 1.0352789163589478, 1.1997653245925903, 1.1142083406448364, 1.105305790901184, 1.2560619115829468, 1.198035717010498, 1.2340656518936157, 1.3165218830108643, 1.2814457416534424, 1.2727755308151245, 1.2712149620056152, 1.2509976625442505, 1.2407586574554443], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.4892241358757019, 0.4881465435028076, 0.4892241358757019, 0.4924568831920624, 0.49461206793785095, 0.5538793206214905, 0.5592672228813171, 0.5614224076271057, 0.5592672228813171, 0.5592672228813171, 0.6163793206214905, 0.6540948152542114, 0.6282327771186829, 0.735991358757019, 0.7155172228813171, 0.704741358757019, 0.7543103694915771, 0.7693965435028076, 0.7532327771186829, 0.7758620977401733, 0.7489224076271057, 0.7737069129943848, 0.787715494632721, 0.7844827771186829, 0.7715517282485962, 0.78125, 0.7790948152542114, 0.7887930870056152, 0.7844827771186829, 0.7866379022598267, 0.8006465435028076, 0.7834051847457886, 0.7887930870056152, 0.7823275923728943, 0.7974137663841248, 0.78125, 0.7726293206214905, 0.7683189511299133, 0.7801724076271057, 0.7737069129943848, 0.7823275923728943, 0.7726293206214905, 0.8017241358757019, 0.7844827771186829, 0.7769396305084229, 0.7629310488700867, 0.7693965435028076, 0.7780172228813171, 0.7769396305084229, 0.7715517282485962, 0.7758620977401733, 0.75, 0.767241358757019, 0.7618534564971924, 0.756465494632721, 0.7844827771186829, 0.7650862336158752, 0.7510775923728943, 0.7715517282485962, 0.7510775923728943, 0.7618534564971924, 0.78125, 0.767241358757019, 0.7618534564971924, 0.7834051847457886, 0.764008641242981, 0.7683189511299133, 0.7737069129943848, 0.7834051847457886, 0.795258641242981, 0.7887930870056152, 0.7823275923728943, 0.7920258641242981, 0.795258641242981, 0.7963362336158752, 0.7898706793785095, 0.7704741358757019, 0.764008641242981, 0.756465494632721, 0.7553879022598267, 0.7780172228813171, 0.7596982717514038, 0.7704741358757019, 0.764008641242981, 0.7392241358757019, 0.7596982717514038, 0.75, 0.7726293206214905, 0.7790948152542114, 0.7575430870056152, 0.7704741358757019, 0.7834051847457886, 0.7769396305084229, 0.7801724076271057, 0.7790948152542114]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.2873 - accuracy: 0.8924"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 9s 66ms/step - loss: 0.2846 - accuracy: 0.8939 - val_loss: 0.7400 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1641 - accuracy: 0.9474 - val_loss: 0.7366 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1285 - accuracy: 0.9539 - val_loss: 0.7666 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1185 - accuracy: 0.9598 - val_loss: 0.7463 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1193 - accuracy: 0.9604 - val_loss: 0.8097 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0998 - accuracy: 0.9717 - val_loss: 0.7808 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0709 - accuracy: 0.9813 - val_loss: 0.8873 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0831 - accuracy: 0.9768 - val_loss: 0.9185 - val_accuracy: 0.4966\n","Epoch 9/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.1358 - accuracy: 0.9584 - val_loss: 0.7511 - val_accuracy: 0.5226\n","Epoch 10/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0845 - accuracy: 0.9745 - val_loss: 0.8732 - val_accuracy: 0.5113\n","Epoch 11/100\n","28/28 [==============================] - 1s 38ms/step - loss: 0.0568 - accuracy: 0.9847 - val_loss: 0.8753 - val_accuracy: 0.5373\n","Epoch 12/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0768 - accuracy: 0.9788 - val_loss: 0.6903 - val_accuracy: 0.6097\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0777 - accuracy: 0.9788 - val_loss: 0.8012 - val_accuracy: 0.5735\n","Epoch 14/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0547 - accuracy: 0.9864 - val_loss: 0.8284 - val_accuracy: 0.6290\n","Epoch 15/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.0818 - accuracy: 0.9762 - val_loss: 0.7525 - val_accuracy: 0.6335\n","Epoch 16/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.0830 - accuracy: 0.9745 - val_loss: 0.7891 - val_accuracy: 0.6437\n","Epoch 17/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0751 - accuracy: 0.9799 - val_loss: 0.9245 - val_accuracy: 0.6097\n","Epoch 18/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.0716 - accuracy: 0.9805 - val_loss: 0.8091 - val_accuracy: 0.6753\n","Epoch 19/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.0545 - accuracy: 0.9878 - val_loss: 0.8188 - val_accuracy: 0.6968\n","Epoch 20/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0546 - accuracy: 0.9850 - val_loss: 0.9964 - val_accuracy: 0.6742\n","Epoch 21/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0604 - accuracy: 0.9861 - val_loss: 0.9254 - val_accuracy: 0.6957\n","Epoch 22/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0952 - accuracy: 0.9697 - val_loss: 0.5840 - val_accuracy: 0.7726\n","Epoch 23/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0864 - accuracy: 0.9748 - val_loss: 0.6405 - val_accuracy: 0.7523\n","Epoch 24/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0456 - accuracy: 0.9898 - val_loss: 0.7326 - val_accuracy: 0.7624\n","Epoch 25/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0572 - accuracy: 0.9856 - val_loss: 0.8325 - val_accuracy: 0.7443\n","Epoch 26/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0705 - accuracy: 0.9810 - val_loss: 0.7186 - val_accuracy: 0.7681\n","Epoch 27/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0584 - accuracy: 0.9853 - val_loss: 0.7889 - val_accuracy: 0.7749\n","Epoch 28/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0615 - accuracy: 0.9853 - val_loss: 1.3740 - val_accuracy: 0.7149\n","Epoch 29/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1145 - accuracy: 0.9601 - val_loss: 0.8159 - val_accuracy: 0.7715\n","Epoch 30/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0820 - accuracy: 0.9743 - val_loss: 0.8739 - val_accuracy: 0.7636\n","Epoch 31/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0547 - accuracy: 0.9873 - val_loss: 0.9149 - val_accuracy: 0.7749\n","Epoch 32/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0395 - accuracy: 0.9929 - val_loss: 1.0414 - val_accuracy: 0.7715\n","Epoch 33/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0451 - accuracy: 0.9907 - val_loss: 1.0008 - val_accuracy: 0.7692\n","Epoch 34/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0496 - accuracy: 0.9878 - val_loss: 1.0865 - val_accuracy: 0.7783\n","Epoch 35/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0648 - accuracy: 0.9813 - val_loss: 0.8943 - val_accuracy: 0.7839\n","Epoch 36/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0557 - accuracy: 0.9870 - val_loss: 0.9507 - val_accuracy: 0.7602\n","Epoch 37/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.0338 - accuracy: 0.9960 - val_loss: 0.9827 - val_accuracy: 0.7907\n","Epoch 38/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0241 - accuracy: 0.9989 - val_loss: 1.0657 - val_accuracy: 0.7760\n","Epoch 39/100\n","28/28 [==============================] - 1s 48ms/step - loss: 0.0204 - accuracy: 0.9994 - val_loss: 1.0422 - val_accuracy: 0.7930\n","Epoch 40/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0213 - accuracy: 0.9994 - val_loss: 1.1222 - val_accuracy: 0.7760\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0267 - accuracy: 0.9969 - val_loss: 1.2179 - val_accuracy: 0.7636\n","Epoch 42/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0484 - accuracy: 0.9873 - val_loss: 1.2443 - val_accuracy: 0.7398\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0794 - accuracy: 0.9779 - val_loss: 1.0110 - val_accuracy: 0.7670\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0711 - accuracy: 0.9805 - val_loss: 0.8360 - val_accuracy: 0.7726\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0572 - accuracy: 0.9842 - val_loss: 0.9273 - val_accuracy: 0.7670\n","Epoch 46/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0468 - accuracy: 0.9895 - val_loss: 0.9915 - val_accuracy: 0.7545\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0454 - accuracy: 0.9890 - val_loss: 0.9667 - val_accuracy: 0.7636\n","Epoch 48/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0332 - accuracy: 0.9946 - val_loss: 0.9852 - val_accuracy: 0.7817\n","Epoch 49/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0339 - accuracy: 0.9946 - val_loss: 1.0380 - val_accuracy: 0.7760\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0332 - accuracy: 0.9938 - val_loss: 1.1333 - val_accuracy: 0.7579\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0461 - accuracy: 0.9884 - val_loss: 1.2229 - val_accuracy: 0.7523\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1122 - accuracy: 0.9649 - val_loss: 0.8508 - val_accuracy: 0.7387\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0765 - accuracy: 0.9776 - val_loss: 0.9495 - val_accuracy: 0.7681\n","Epoch 54/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0497 - accuracy: 0.9887 - val_loss: 1.0006 - val_accuracy: 0.7794\n","Epoch 55/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0294 - accuracy: 0.9946 - val_loss: 1.0594 - val_accuracy: 0.7726\n","Epoch 56/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0289 - accuracy: 0.9958 - val_loss: 1.1462 - val_accuracy: 0.7771\n","Epoch 57/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0253 - accuracy: 0.9969 - val_loss: 1.1988 - val_accuracy: 0.7681\n","Epoch 58/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0242 - accuracy: 0.9972 - val_loss: 1.2307 - val_accuracy: 0.7602\n","Epoch 59/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0292 - accuracy: 0.9946 - val_loss: 1.2964 - val_accuracy: 0.7410\n","Epoch 60/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0596 - accuracy: 0.9853 - val_loss: 1.0447 - val_accuracy: 0.7658\n","Epoch 61/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0455 - accuracy: 0.9890 - val_loss: 0.9796 - val_accuracy: 0.7545\n","Epoch 62/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0406 - accuracy: 0.9904 - val_loss: 1.0372 - val_accuracy: 0.7670\n","Epoch 63/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0407 - accuracy: 0.9907 - val_loss: 1.1468 - val_accuracy: 0.7692\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0557 - accuracy: 0.9859 - val_loss: 1.0474 - val_accuracy: 0.7477\n","Epoch 65/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0493 - accuracy: 0.9856 - val_loss: 0.9807 - val_accuracy: 0.7624\n","Epoch 66/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0380 - accuracy: 0.9932 - val_loss: 1.0557 - val_accuracy: 0.7557\n","Epoch 67/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0348 - accuracy: 0.9932 - val_loss: 1.1613 - val_accuracy: 0.7590\n","Epoch 68/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0277 - accuracy: 0.9952 - val_loss: 1.0770 - val_accuracy: 0.7715\n","Epoch 69/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0285 - accuracy: 0.9958 - val_loss: 1.1543 - val_accuracy: 0.7636\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0402 - accuracy: 0.9904 - val_loss: 1.2334 - val_accuracy: 0.7319\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0758 - accuracy: 0.9762 - val_loss: 1.0195 - val_accuracy: 0.7534\n","Epoch 72/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0612 - accuracy: 0.9833 - val_loss: 1.0736 - val_accuracy: 0.7624\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0489 - accuracy: 0.9873 - val_loss: 0.9745 - val_accuracy: 0.7647\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0294 - accuracy: 0.9952 - val_loss: 1.1449 - val_accuracy: 0.7534\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0252 - accuracy: 0.9955 - val_loss: 1.0464 - val_accuracy: 0.7896\n","Epoch 76/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0340 - accuracy: 0.9918 - val_loss: 1.2366 - val_accuracy: 0.7545\n","Epoch 77/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0594 - accuracy: 0.9844 - val_loss: 1.0419 - val_accuracy: 0.7545\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0526 - accuracy: 0.9847 - val_loss: 1.0508 - val_accuracy: 0.7443\n","Epoch 79/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0341 - accuracy: 0.9918 - val_loss: 1.1343 - val_accuracy: 0.7647\n","Epoch 80/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0385 - accuracy: 0.9924 - val_loss: 1.0579 - val_accuracy: 0.7613\n","Epoch 81/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0805 - accuracy: 0.9757 - val_loss: 0.9180 - val_accuracy: 0.7545\n","Epoch 82/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0475 - accuracy: 0.9887 - val_loss: 0.9548 - val_accuracy: 0.7749\n","Epoch 83/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0243 - accuracy: 0.9977 - val_loss: 1.1130 - val_accuracy: 0.7624\n","Epoch 84/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0185 - accuracy: 0.9989 - val_loss: 1.1888 - val_accuracy: 0.7613\n","Epoch 85/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0171 - accuracy: 0.9994 - val_loss: 1.1945 - val_accuracy: 0.7692\n","Epoch 86/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.2170 - val_accuracy: 0.7670\n","Epoch 87/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.1890 - val_accuracy: 0.7738\n","Epoch 88/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.1801 - val_accuracy: 0.7828\n","Epoch 89/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.1805 - val_accuracy: 0.7771\n","Epoch 90/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.1630 - val_accuracy: 0.7794\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.1543 - val_accuracy: 0.7783\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.1452 - val_accuracy: 0.7817\n","Epoch 93/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.1420 - val_accuracy: 0.7794\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.1280 - val_accuracy: 0.7760\n","Epoch 95/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.1180 - val_accuracy: 0.7771\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.1145 - val_accuracy: 0.7805\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.1048 - val_accuracy: 0.7738\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.1012 - val_accuracy: 0.7760\n","Epoch 99/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.0947 - val_accuracy: 0.7738\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.0854 - val_accuracy: 0.7771\n","{'loss': [0.2845730483531952, 0.16405360400676727, 0.12854455411434174, 0.11852476745843887, 0.1193080022931099, 0.09978058934211731, 0.0708799958229065, 0.08314542472362518, 0.13582444190979004, 0.08454662561416626, 0.05684198439121246, 0.07675709575414658, 0.07771427184343338, 0.054693058133125305, 0.08179135620594025, 0.08299490809440613, 0.07511870563030243, 0.071554996073246, 0.05446159839630127, 0.05462029576301575, 0.06042816489934921, 0.09524092823266983, 0.08638995885848999, 0.04564403370022774, 0.057237107306718826, 0.07052270323038101, 0.058413855731487274, 0.06150689348578453, 0.11450538039207458, 0.08198919892311096, 0.05472161993384361, 0.039516691118478775, 0.0450957790017128, 0.049630071967840195, 0.06479676812887192, 0.05569342151284218, 0.03383197262883186, 0.02411866933107376, 0.020422132685780525, 0.021339481696486473, 0.02667282521724701, 0.04844002053141594, 0.07943546026945114, 0.07106492668390274, 0.05716179311275482, 0.046800896525382996, 0.04537533223628998, 0.03323504701256752, 0.033890727907419205, 0.03318629786372185, 0.04613921791315079, 0.11217230558395386, 0.07648412883281708, 0.04967060685157776, 0.029447972774505615, 0.028877077624201775, 0.025255007669329643, 0.02416956052184105, 0.029196444898843765, 0.0596344880759716, 0.045452140271663666, 0.04060931131243706, 0.040686193853616714, 0.05566110834479332, 0.049319278448820114, 0.037972185760736465, 0.034753989428281784, 0.027737032622098923, 0.028466176241636276, 0.04022034630179405, 0.0757511630654335, 0.061182692646980286, 0.048934485763311386, 0.02941739372909069, 0.02517594024538994, 0.03402399644255638, 0.05940013751387596, 0.05259837955236435, 0.03405012562870979, 0.03848912939429283, 0.08051507920026779, 0.047519780695438385, 0.024258017539978027, 0.018513517454266548, 0.017086902633309364, 0.01525911409407854, 0.01486037764698267, 0.014218456111848354, 0.013996570371091366, 0.013872633688151836, 0.013733353465795517, 0.013630499131977558, 0.013411461375653744, 0.013277108781039715, 0.013164140284061432, 0.01304870005697012, 0.0129017299041152, 0.012806940823793411, 0.012746654450893402, 0.012607271783053875], 'accuracy': [0.8938879370689392, 0.9473684430122375, 0.9538766145706177, 0.9598188996315002, 0.9603848457336426, 0.9717034697532654, 0.9813242554664612, 0.9767968058586121, 0.9584040641784668, 0.9745330810546875, 0.9847198724746704, 0.9787775874137878, 0.9787775874137878, 0.9864176511764526, 0.9762309193611145, 0.9745330810546875, 0.9799094796180725, 0.9804753661155701, 0.9878324866294861, 0.9850028157234192, 0.9861347079277039, 0.9697226881980896, 0.974816083908081, 0.9898132681846619, 0.9855687618255615, 0.9810413122177124, 0.9852858185768127, 0.9852858185768127, 0.960101842880249, 0.9742501378059387, 0.9872665405273438, 0.9929258823394775, 0.990662157535553, 0.9878324866294861, 0.9813242554664612, 0.986983597278595, 0.9960384964942932, 0.9988681674003601, 0.9994340538978577, 0.9994340538978577, 0.9968873858451843, 0.9872665405273438, 0.9779286980628967, 0.9804753661155701, 0.9841539263725281, 0.9895302653312683, 0.988964319229126, 0.9946236610412598, 0.9946236610412598, 0.9937747716903687, 0.9883984327316284, 0.9649122953414917, 0.977645754814148, 0.9886813759803772, 0.9946236610412598, 0.9957554936408997, 0.9968873858451843, 0.9971703290939331, 0.9946236610412598, 0.9852858185768127, 0.988964319229126, 0.9903791546821594, 0.990662157535553, 0.9858517050743103, 0.9855687618255615, 0.9932088255882263, 0.9932088255882263, 0.9951896071434021, 0.9957554936408997, 0.9903791546821594, 0.9762309193611145, 0.983305037021637, 0.9872665405273438, 0.9951896071434021, 0.9954725503921509, 0.9917939901351929, 0.9844368696212769, 0.9847198724746704, 0.9917939901351929, 0.9923599362373352, 0.9756649732589722, 0.9886813759803772, 0.9977362751960754, 0.9988681674003601, 0.9994340538978577, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.7399595379829407, 0.7366480231285095, 0.7666481137275696, 0.7463129162788391, 0.8097378015518188, 0.7807700037956238, 0.8873168230056763, 0.9185339212417603, 0.7511401176452637, 0.8731690049171448, 0.8752866983413696, 0.6902592778205872, 0.8011661171913147, 0.8284240961074829, 0.7524508833885193, 0.7890804409980774, 0.9244546294212341, 0.8091332912445068, 0.8187861442565918, 0.9963942766189575, 0.9254114627838135, 0.583991289138794, 0.6405311822891235, 0.7326111197471619, 0.8325212597846985, 0.7185516357421875, 0.7889172434806824, 1.3739731311798096, 0.8158726692199707, 0.8738635182380676, 0.914891242980957, 1.0414224863052368, 1.0007951259613037, 1.0864993333816528, 0.8943333625793457, 0.9506812691688538, 0.9827341437339783, 1.0656979084014893, 1.0422134399414062, 1.1221880912780762, 1.2178595066070557, 1.244256615638733, 1.0110280513763428, 0.8360132575035095, 0.9272742867469788, 0.9914540648460388, 0.9666969776153564, 0.9852390289306641, 1.038024663925171, 1.1332672834396362, 1.2229018211364746, 0.8508175015449524, 0.9495238065719604, 1.000632643699646, 1.0593584775924683, 1.1461824178695679, 1.1987522840499878, 1.2307478189468384, 1.2963743209838867, 1.044654369354248, 0.9795701503753662, 1.0371719598770142, 1.1467726230621338, 1.0474340915679932, 0.9806503653526306, 1.055747628211975, 1.161328911781311, 1.0769742727279663, 1.154312014579773, 1.2333732843399048, 1.0195385217666626, 1.0735714435577393, 0.9744609594345093, 1.1449300050735474, 1.0463616847991943, 1.2366389036178589, 1.0418716669082642, 1.0508266687393188, 1.134347915649414, 1.0578758716583252, 0.9179838299751282, 0.954766571521759, 1.1129751205444336, 1.1887922286987305, 1.1944876909255981, 1.2169514894485474, 1.1889684200286865, 1.1800769567489624, 1.1805438995361328, 1.1629717350006104, 1.1543223857879639, 1.1452041864395142, 1.1419786214828491, 1.1280287504196167, 1.1180000305175781, 1.1144795417785645, 1.1048383712768555, 1.1011581420898438, 1.0947041511535645, 1.0853782892227173], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.5226244330406189, 0.5113122463226318, 0.5373303294181824, 0.6097285151481628, 0.5735294222831726, 0.6289592981338501, 0.6334841847419739, 0.6436651349067688, 0.6097285151481628, 0.6753393411636353, 0.6968325972557068, 0.6742081642150879, 0.6957013607025146, 0.7726244330406189, 0.7522624731063843, 0.7624434232711792, 0.7443438768386841, 0.7680995464324951, 0.7748869061470032, 0.7149321436882019, 0.7714931964874268, 0.7635746598243713, 0.7748869061470032, 0.7714931964874268, 0.7692307829856873, 0.7782805562019348, 0.7839366793632507, 0.7601810097694397, 0.790723979473114, 0.7760180830955505, 0.7929864525794983, 0.7760180830955505, 0.7635746598243713, 0.7398189902305603, 0.766968309879303, 0.7726244330406189, 0.766968309879303, 0.7545248866081238, 0.7635746598243713, 0.7816742062568665, 0.7760180830955505, 0.7579185366630554, 0.7522624731063843, 0.7386877536773682, 0.7680995464324951, 0.779411792755127, 0.7726244330406189, 0.7771493196487427, 0.7680995464324951, 0.7601810097694397, 0.7409502267837524, 0.7658371329307556, 0.7545248866081238, 0.766968309879303, 0.7692307829856873, 0.7477375268936157, 0.7624434232711792, 0.7556561231613159, 0.7590497732162476, 0.7714931964874268, 0.7635746598243713, 0.7319004535675049, 0.7533936500549316, 0.7624434232711792, 0.7647058963775635, 0.7533936500549316, 0.7895927429199219, 0.7545248866081238, 0.7545248866081238, 0.7443438768386841, 0.7647058963775635, 0.7613122463226318, 0.7545248866081238, 0.7748869061470032, 0.7624434232711792, 0.7613122463226318, 0.7692307829856873, 0.766968309879303, 0.773755669593811, 0.7828054428100586, 0.7771493196487427, 0.779411792755127, 0.7782805562019348, 0.7816742062568665, 0.779411792755127, 0.7760180830955505, 0.7771493196487427, 0.7805429697036743, 0.773755669593811, 0.7760180830955505, 0.773755669593811, 0.7771493196487427]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.3254 - accuracy: 0.8781"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 8s 57ms/step - loss: 0.3255 - accuracy: 0.8773 - val_loss: 0.7421 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1764 - accuracy: 0.9429 - val_loss: 0.7707 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1447 - accuracy: 0.9504 - val_loss: 0.7534 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.1436 - accuracy: 0.9535 - val_loss: 0.7719 - val_accuracy: 0.4866\n","Epoch 5/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.1316 - accuracy: 0.9496 - val_loss: 0.7491 - val_accuracy: 0.4897\n","Epoch 6/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.1036 - accuracy: 0.9667 - val_loss: 0.7855 - val_accuracy: 0.4948\n","Epoch 7/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.1425 - accuracy: 0.9537 - val_loss: 0.7589 - val_accuracy: 0.4990\n","Epoch 8/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1182 - accuracy: 0.9597 - val_loss: 0.8423 - val_accuracy: 0.4938\n","Epoch 9/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0987 - accuracy: 0.9705 - val_loss: 0.8329 - val_accuracy: 0.5072\n","Epoch 10/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0851 - accuracy: 0.9762 - val_loss: 0.8593 - val_accuracy: 0.5269\n","Epoch 11/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0975 - accuracy: 0.9690 - val_loss: 0.8937 - val_accuracy: 0.5155\n","Epoch 12/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.0751 - accuracy: 0.9775 - val_loss: 0.9819 - val_accuracy: 0.5331\n","Epoch 13/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.0832 - accuracy: 0.9739 - val_loss: 0.9131 - val_accuracy: 0.5723\n","Epoch 14/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0791 - accuracy: 0.9747 - val_loss: 1.0509 - val_accuracy: 0.5558\n","Epoch 15/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0770 - accuracy: 0.9783 - val_loss: 1.0676 - val_accuracy: 0.5630\n","Epoch 16/100\n","31/31 [==============================] - 1s 40ms/step - loss: 0.0611 - accuracy: 0.9853 - val_loss: 0.7457 - val_accuracy: 0.6870\n","Epoch 17/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0775 - accuracy: 0.9747 - val_loss: 0.6586 - val_accuracy: 0.7242\n","Epoch 18/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0811 - accuracy: 0.9762 - val_loss: 0.7809 - val_accuracy: 0.6963\n","Epoch 19/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0589 - accuracy: 0.9860 - val_loss: 0.7973 - val_accuracy: 0.7438\n","Epoch 20/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1091 - accuracy: 0.9685 - val_loss: 0.6400 - val_accuracy: 0.7397\n","Epoch 21/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0587 - accuracy: 0.9871 - val_loss: 1.0048 - val_accuracy: 0.7138\n","Epoch 22/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0616 - accuracy: 0.9837 - val_loss: 0.8122 - val_accuracy: 0.7572\n","Epoch 23/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0588 - accuracy: 0.9853 - val_loss: 0.8040 - val_accuracy: 0.7593\n","Epoch 24/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0666 - accuracy: 0.9804 - val_loss: 0.9235 - val_accuracy: 0.7686\n","Epoch 25/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0847 - accuracy: 0.9729 - val_loss: 0.7887 - val_accuracy: 0.7572\n","Epoch 26/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1572 - accuracy: 0.9455 - val_loss: 0.6530 - val_accuracy: 0.7552\n","Epoch 27/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.1151 - accuracy: 0.9618 - val_loss: 0.7871 - val_accuracy: 0.7707\n","Epoch 28/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0583 - accuracy: 0.9853 - val_loss: 0.9614 - val_accuracy: 0.7789\n","Epoch 29/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0679 - accuracy: 0.9827 - val_loss: 0.9782 - val_accuracy: 0.7479\n","Epoch 30/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0380 - accuracy: 0.9948 - val_loss: 1.0665 - val_accuracy: 0.7789\n","Epoch 31/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0548 - accuracy: 0.9860 - val_loss: 1.0995 - val_accuracy: 0.7510\n","Epoch 32/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0685 - accuracy: 0.9798 - val_loss: 0.9806 - val_accuracy: 0.7314\n","Epoch 33/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0716 - accuracy: 0.9775 - val_loss: 0.9976 - val_accuracy: 0.7696\n","Epoch 34/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0729 - accuracy: 0.9791 - val_loss: 1.0558 - val_accuracy: 0.7572\n","Epoch 35/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0809 - accuracy: 0.9755 - val_loss: 0.9893 - val_accuracy: 0.7479\n","Epoch 36/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0526 - accuracy: 0.9881 - val_loss: 1.1525 - val_accuracy: 0.7490\n","Epoch 37/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0419 - accuracy: 0.9925 - val_loss: 1.1582 - val_accuracy: 0.7417\n","Epoch 38/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0458 - accuracy: 0.9894 - val_loss: 1.1428 - val_accuracy: 0.7562\n","Epoch 39/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0394 - accuracy: 0.9928 - val_loss: 1.0804 - val_accuracy: 0.7820\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0551 - accuracy: 0.9866 - val_loss: 1.1263 - val_accuracy: 0.7562\n","Epoch 41/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0740 - accuracy: 0.9788 - val_loss: 1.0260 - val_accuracy: 0.7438\n","Epoch 42/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0655 - accuracy: 0.9819 - val_loss: 1.1236 - val_accuracy: 0.7335\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0614 - accuracy: 0.9845 - val_loss: 1.0985 - val_accuracy: 0.7603\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0534 - accuracy: 0.9863 - val_loss: 1.1182 - val_accuracy: 0.7479\n","Epoch 45/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0617 - accuracy: 0.9811 - val_loss: 1.2270 - val_accuracy: 0.7738\n","Epoch 46/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0948 - accuracy: 0.9656 - val_loss: 0.9381 - val_accuracy: 0.7459\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0723 - accuracy: 0.9791 - val_loss: 0.9979 - val_accuracy: 0.7531\n","Epoch 48/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0537 - accuracy: 0.9858 - val_loss: 1.0703 - val_accuracy: 0.7634\n","Epoch 49/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0410 - accuracy: 0.9910 - val_loss: 1.1862 - val_accuracy: 0.7376\n","Epoch 50/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0287 - accuracy: 0.9959 - val_loss: 1.2926 - val_accuracy: 0.7521\n","Epoch 51/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0320 - accuracy: 0.9953 - val_loss: 1.1910 - val_accuracy: 0.7500\n","Epoch 52/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0793 - accuracy: 0.9775 - val_loss: 1.0046 - val_accuracy: 0.7459\n","Epoch 53/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0675 - accuracy: 0.9806 - val_loss: 1.0740 - val_accuracy: 0.7417\n","Epoch 54/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0384 - accuracy: 0.9928 - val_loss: 1.1634 - val_accuracy: 0.7552\n","Epoch 55/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0287 - accuracy: 0.9953 - val_loss: 1.4142 - val_accuracy: 0.7335\n","Epoch 56/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0389 - accuracy: 0.9907 - val_loss: 1.1639 - val_accuracy: 0.7583\n","Epoch 57/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1292 - accuracy: 0.9584 - val_loss: 0.8273 - val_accuracy: 0.7469\n","Epoch 58/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0552 - accuracy: 0.9863 - val_loss: 1.0861 - val_accuracy: 0.7531\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0263 - accuracy: 0.9979 - val_loss: 1.1695 - val_accuracy: 0.7603\n","Epoch 60/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0226 - accuracy: 0.9977 - val_loss: 1.2449 - val_accuracy: 0.7583\n","Epoch 61/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0302 - accuracy: 0.9933 - val_loss: 1.3324 - val_accuracy: 0.7397\n","Epoch 62/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0432 - accuracy: 0.9886 - val_loss: 1.1752 - val_accuracy: 0.7448\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0706 - accuracy: 0.9822 - val_loss: 1.0708 - val_accuracy: 0.7335\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0556 - accuracy: 0.9860 - val_loss: 1.1086 - val_accuracy: 0.7376\n","Epoch 65/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0646 - accuracy: 0.9793 - val_loss: 1.0388 - val_accuracy: 0.7397\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0514 - accuracy: 0.9866 - val_loss: 1.0779 - val_accuracy: 0.7593\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0306 - accuracy: 0.9941 - val_loss: 1.1327 - val_accuracy: 0.7593\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0237 - accuracy: 0.9974 - val_loss: 1.2404 - val_accuracy: 0.7448\n","Epoch 69/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0251 - accuracy: 0.9974 - val_loss: 1.1992 - val_accuracy: 0.7572\n","Epoch 70/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0179 - accuracy: 0.9995 - val_loss: 1.1981 - val_accuracy: 0.7562\n","Epoch 71/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.2198 - val_accuracy: 0.7614\n","Epoch 72/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.2390 - val_accuracy: 0.7593\n","Epoch 73/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.2460 - val_accuracy: 0.7552\n","Epoch 74/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.2406 - val_accuracy: 0.7572\n","Epoch 75/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.2232 - val_accuracy: 0.7593\n","Epoch 76/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.2172 - val_accuracy: 0.7552\n","Epoch 77/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.2039 - val_accuracy: 0.7583\n","Epoch 78/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.1953 - val_accuracy: 0.7552\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.1833 - val_accuracy: 0.7552\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.1779 - val_accuracy: 0.7562\n","Epoch 81/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.1779 - val_accuracy: 0.7541\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.1683 - val_accuracy: 0.7552\n","Epoch 83/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.1633 - val_accuracy: 0.7552\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.1618 - val_accuracy: 0.7624\n","Epoch 85/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.1531 - val_accuracy: 0.7624\n","Epoch 86/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.1554 - val_accuracy: 0.7562\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.1432 - val_accuracy: 0.7603\n","Epoch 88/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.1420 - val_accuracy: 0.7614\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.1459 - val_accuracy: 0.7603\n","Epoch 90/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.1447 - val_accuracy: 0.7562\n","Epoch 91/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.1499 - val_accuracy: 0.7614\n","Epoch 92/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.1383 - val_accuracy: 0.7593\n","Epoch 93/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.1319 - val_accuracy: 0.7572\n","Epoch 94/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.1301 - val_accuracy: 0.7624\n","Epoch 95/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.1334 - val_accuracy: 0.7614\n","Epoch 96/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.1325 - val_accuracy: 0.7572\n","Epoch 97/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.1299 - val_accuracy: 0.7583\n","Epoch 98/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.1239 - val_accuracy: 0.7541\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.1261 - val_accuracy: 0.7603\n","Epoch 100/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.1191 - val_accuracy: 0.7562\n","{'loss': [0.3254677355289459, 0.17643529176712036, 0.1447194218635559, 0.1436185985803604, 0.13157975673675537, 0.10356695204973221, 0.14249566197395325, 0.11819178611040115, 0.09866654872894287, 0.08514995872974396, 0.09751786291599274, 0.07514707744121552, 0.08318807929754257, 0.07905037701129913, 0.07701075077056885, 0.061082080006599426, 0.07746649533510208, 0.08114338666200638, 0.05892099067568779, 0.10914796590805054, 0.058659762144088745, 0.06163874641060829, 0.05875612422823906, 0.06661013513803482, 0.08474910259246826, 0.1572050005197525, 0.11511170864105225, 0.05826961249113083, 0.06786826252937317, 0.038003068417310715, 0.054807618260383606, 0.06853219866752625, 0.07155749946832657, 0.0728510320186615, 0.08090918511152267, 0.052634529769420624, 0.04192313551902771, 0.04575565829873085, 0.039409440010786057, 0.0550692081451416, 0.07403819262981415, 0.06551750749349594, 0.0614086277782917, 0.053415484726428986, 0.06169181317090988, 0.09480607509613037, 0.07233311980962753, 0.0536944679915905, 0.04104029759764671, 0.02868429571390152, 0.031969040632247925, 0.07929384708404541, 0.06748484820127487, 0.03839936479926109, 0.02873525582253933, 0.038942206650972366, 0.12923675775527954, 0.0552314855158329, 0.02631581947207451, 0.02255965583026409, 0.030189089477062225, 0.043209515511989594, 0.07059570401906967, 0.05564884841442108, 0.06457041203975677, 0.0514027364552021, 0.030598381534218788, 0.02369518019258976, 0.025128211826086044, 0.017926467582583427, 0.016278810799121857, 0.015786126255989075, 0.015586694702506065, 0.015259678475558758, 0.015068571083247662, 0.014910315163433552, 0.014722475782036781, 0.014558517374098301, 0.014463893137872219, 0.014341386035084724, 0.014195207506418228, 0.01400794554501772, 0.013898021541535854, 0.01375568751245737, 0.013699193485081196, 0.01356787234544754, 0.013409771956503391, 0.013328739441931248, 0.013209681026637554, 0.013079202733933926, 0.012971268966794014, 0.012886963784694672, 0.012720894068479538, 0.01265036128461361, 0.012551246210932732, 0.012462323531508446, 0.012335553765296936, 0.01221748348325491, 0.012139633297920227, 0.01202181726694107], 'accuracy': [0.8772609829902649, 0.9428940415382385, 0.9503875970840454, 0.9534883499145508, 0.9496123790740967, 0.9666666388511658, 0.9537467956542969, 0.9596899151802063, 0.9705426096916199, 0.9762274026870728, 0.9689922332763672, 0.9775193929672241, 0.9739018082618713, 0.9746770262718201, 0.9782945513725281, 0.9852713346481323, 0.9746770262718201, 0.9762274026870728, 0.9860464930534363, 0.9684754610061646, 0.9870800971984863, 0.9837209582328796, 0.9852713346481323, 0.9803617596626282, 0.9728682041168213, 0.9454780220985413, 0.9617571234703064, 0.9852713346481323, 0.9826873540878296, 0.9948320388793945, 0.9860464930534363, 0.9798449873924255, 0.9775193929672241, 0.9790697693824768, 0.975452184677124, 0.9881137013435364, 0.9925064444541931, 0.9894056916236877, 0.9927648305892944, 0.9865633249282837, 0.9788113832473755, 0.9819121360778809, 0.9844961166381836, 0.9863049387931824, 0.9811369776725769, 0.9656330943107605, 0.9790697693824768, 0.985788106918335, 0.9909560680389404, 0.9958656430244446, 0.9953488111495972, 0.9775193929672241, 0.9806201457977295, 0.9927648305892944, 0.9953488111495972, 0.9906976819038391, 0.9583979249000549, 0.9863049387931824, 0.9979327917098999, 0.9976744055747986, 0.9932816624641418, 0.988630473613739, 0.9821705222129822, 0.9860464930534363, 0.9793281555175781, 0.9865633249282837, 0.9940568208694458, 0.9974160194396973, 0.9974160194396973, 0.9994832277297974, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.7421112060546875, 0.7707080245018005, 0.753358006477356, 0.7719093561172485, 0.7491097450256348, 0.7855364084243774, 0.7589040994644165, 0.8422510027885437, 0.8329315185546875, 0.8592877984046936, 0.893699586391449, 0.9818658232688904, 0.9131331443786621, 1.0508863925933838, 1.0676027536392212, 0.7456940412521362, 0.6586177349090576, 0.7808591723442078, 0.7973324656486511, 0.6399776339530945, 1.0048240423202515, 0.8121569752693176, 0.8039871454238892, 0.9234978556632996, 0.7887259125709534, 0.6530050039291382, 0.7870548367500305, 0.9614441394805908, 0.9782052040100098, 1.0664660930633545, 1.09947669506073, 0.9806311726570129, 0.997568666934967, 1.0558034181594849, 0.9892656803131104, 1.152461051940918, 1.1582077741622925, 1.1428093910217285, 1.0804171562194824, 1.1263102293014526, 1.0260062217712402, 1.1235989332199097, 1.0985175371170044, 1.1182312965393066, 1.2269959449768066, 0.9381380677223206, 0.9978744387626648, 1.07028067111969, 1.1862261295318604, 1.292575716972351, 1.1909620761871338, 1.0045769214630127, 1.0739761590957642, 1.16337251663208, 1.4142128229141235, 1.1638671159744263, 0.8273236751556396, 1.0860886573791504, 1.1695231199264526, 1.244949221611023, 1.3323601484298706, 1.1751772165298462, 1.0707656145095825, 1.1086441278457642, 1.0388004779815674, 1.0778728723526, 1.1326686143875122, 1.2403539419174194, 1.199162483215332, 1.1980563402175903, 1.2197794914245605, 1.2390211820602417, 1.2459570169448853, 1.2405976057052612, 1.2232449054718018, 1.2171962261199951, 1.2039148807525635, 1.1953121423721313, 1.1833206415176392, 1.177876591682434, 1.1778831481933594, 1.168284296989441, 1.1633461713790894, 1.161839246749878, 1.1531096696853638, 1.1553624868392944, 1.1432136297225952, 1.1420353651046753, 1.1458978652954102, 1.1446902751922607, 1.1498862504959106, 1.1382821798324585, 1.1319020986557007, 1.130131721496582, 1.1334314346313477, 1.1325455904006958, 1.1298987865447998, 1.1238590478897095, 1.1260524988174438, 1.1191093921661377], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.48966941237449646, 0.4948347210884094, 0.49896693229675293, 0.49380165338516235, 0.5072314143180847, 0.5268595218658447, 0.5154958963394165, 0.5330578684806824, 0.5723140239715576, 0.5557851195335388, 0.5630165338516235, 0.6869834661483765, 0.7241735458374023, 0.6962810158729553, 0.7438016533851624, 0.7396694421768188, 0.7138429880142212, 0.7572314143180847, 0.7592975497245789, 0.7685950398445129, 0.7572314143180847, 0.7551652789115906, 0.7706611752510071, 0.7789255976676941, 0.7479338645935059, 0.7789255976676941, 0.7510330677032471, 0.7314049601554871, 0.76962810754776, 0.7572314143180847, 0.7479338645935059, 0.7489669322967529, 0.7417355179786682, 0.7561983466148376, 0.7820248007774353, 0.7561983466148376, 0.7438016533851624, 0.7334710955619812, 0.7603305578231812, 0.7479338645935059, 0.7737603187561035, 0.7458677887916565, 0.7530992031097412, 0.7634297609329224, 0.7376033067703247, 0.7520661354064941, 0.75, 0.7458677887916565, 0.7417355179786682, 0.7551652789115906, 0.7334710955619812, 0.7582644820213318, 0.7469007968902588, 0.7530992031097412, 0.7603305578231812, 0.7582644820213318, 0.7396694421768188, 0.7448347210884094, 0.7334710955619812, 0.7376033067703247, 0.7396694421768188, 0.7592975497245789, 0.7592975497245789, 0.7448347210884094, 0.7572314143180847, 0.7561983466148376, 0.7613636255264282, 0.7592975497245789, 0.7551652789115906, 0.7572314143180847, 0.7592975497245789, 0.7551652789115906, 0.7582644820213318, 0.7551652789115906, 0.7551652789115906, 0.7561983466148376, 0.7541322112083435, 0.7551652789115906, 0.7551652789115906, 0.7623966932296753, 0.7623966932296753, 0.7561983466148376, 0.7603305578231812, 0.7613636255264282, 0.7603305578231812, 0.7561983466148376, 0.7613636255264282, 0.7592975497245789, 0.7572314143180847, 0.7623966932296753, 0.7613636255264282, 0.7572314143180847, 0.7582644820213318, 0.7541322112083435, 0.7603305578231812, 0.7561983466148376]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.1340 - accuracy: 0.9554"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 8s 60ms/step - loss: 0.1335 - accuracy: 0.9555 - val_loss: 0.7445 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0545 - accuracy: 0.9873 - val_loss: 0.8224 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0406 - accuracy: 0.9881 - val_loss: 0.9037 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0442 - accuracy: 0.9895 - val_loss: 0.9112 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0504 - accuracy: 0.9863 - val_loss: 0.9571 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0570 - accuracy: 0.9838 - val_loss: 1.0062 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0477 - accuracy: 0.9873 - val_loss: 1.0059 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0695 - accuracy: 0.9768 - val_loss: 0.9479 - val_accuracy: 0.4871\n","Epoch 9/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0441 - accuracy: 0.9903 - val_loss: 1.0902 - val_accuracy: 0.4871\n","Epoch 10/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0263 - accuracy: 0.9957 - val_loss: 1.2573 - val_accuracy: 0.4903\n","Epoch 11/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0294 - accuracy: 0.9933 - val_loss: 1.1623 - val_accuracy: 0.5162\n","Epoch 12/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0730 - accuracy: 0.9755 - val_loss: 1.4263 - val_accuracy: 0.4914\n","Epoch 13/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0717 - accuracy: 0.9787 - val_loss: 1.0934 - val_accuracy: 0.5162\n","Epoch 14/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0351 - accuracy: 0.9903 - val_loss: 1.3055 - val_accuracy: 0.5366\n","Epoch 15/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.0523 - accuracy: 0.9865 - val_loss: 0.6467 - val_accuracy: 0.6983\n","Epoch 16/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0973 - accuracy: 0.9679 - val_loss: 0.8323 - val_accuracy: 0.5970\n","Epoch 17/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.0442 - accuracy: 0.9892 - val_loss: 0.6332 - val_accuracy: 0.7306\n","Epoch 18/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0477 - accuracy: 0.9868 - val_loss: 0.7970 - val_accuracy: 0.6713\n","Epoch 19/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0615 - accuracy: 0.9820 - val_loss: 0.6136 - val_accuracy: 0.7478\n","Epoch 20/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0357 - accuracy: 0.9914 - val_loss: 0.9306 - val_accuracy: 0.6961\n","Epoch 21/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0398 - accuracy: 0.9881 - val_loss: 0.6495 - val_accuracy: 0.7737\n","Epoch 22/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0264 - accuracy: 0.9949 - val_loss: 0.6438 - val_accuracy: 0.8028\n","Epoch 23/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0178 - accuracy: 0.9984 - val_loss: 0.7728 - val_accuracy: 0.7909\n","Epoch 24/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0187 - accuracy: 0.9976 - val_loss: 0.6987 - val_accuracy: 0.8168\n","Epoch 25/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0241 - accuracy: 0.9962 - val_loss: 0.8534 - val_accuracy: 0.7953\n","Epoch 26/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0542 - accuracy: 0.9860 - val_loss: 0.6185 - val_accuracy: 0.7963\n","Epoch 27/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0513 - accuracy: 0.9849 - val_loss: 0.6349 - val_accuracy: 0.8147\n","Epoch 28/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0465 - accuracy: 0.9879 - val_loss: 0.6987 - val_accuracy: 0.8082\n","Epoch 29/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.0345 - accuracy: 0.9911 - val_loss: 0.7227 - val_accuracy: 0.8373\n","Epoch 30/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0278 - accuracy: 0.9938 - val_loss: 0.7804 - val_accuracy: 0.8373\n","Epoch 31/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0375 - accuracy: 0.9911 - val_loss: 0.7276 - val_accuracy: 0.8287\n","Epoch 32/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0705 - accuracy: 0.9774 - val_loss: 0.6670 - val_accuracy: 0.8179\n","Epoch 33/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0860 - accuracy: 0.9723 - val_loss: 0.5826 - val_accuracy: 0.8028\n","Epoch 34/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0352 - accuracy: 0.9938 - val_loss: 0.6421 - val_accuracy: 0.8341\n","Epoch 35/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.0201 - accuracy: 0.9978 - val_loss: 0.6711 - val_accuracy: 0.8470\n","Epoch 36/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0219 - accuracy: 0.9962 - val_loss: 0.8555 - val_accuracy: 0.8233\n","Epoch 37/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0173 - accuracy: 0.9984 - val_loss: 0.7758 - val_accuracy: 0.8341\n","Epoch 38/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.0148 - accuracy: 0.9995 - val_loss: 0.7540 - val_accuracy: 0.8491\n","Epoch 39/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0133 - accuracy: 0.9995 - val_loss: 0.7039 - val_accuracy: 0.8459\n","Epoch 40/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.7634 - val_accuracy: 0.8470\n","Epoch 41/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.7583 - val_accuracy: 0.8427\n","Epoch 42/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.7196 - val_accuracy: 0.8470\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.8459\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.8459\n","Epoch 45/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 0.8470\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.6863 - val_accuracy: 0.8491\n","Epoch 47/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.6772 - val_accuracy: 0.8491\n","Epoch 48/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.6652 - val_accuracy: 0.8534\n","Epoch 49/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.6589 - val_accuracy: 0.8524\n","Epoch 50/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.6550 - val_accuracy: 0.8502\n","Epoch 51/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.6520 - val_accuracy: 0.8491\n","Epoch 52/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.6570 - val_accuracy: 0.8491\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.6439 - val_accuracy: 0.8513\n","Epoch 54/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.6399 - val_accuracy: 0.8545\n","Epoch 55/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.6378 - val_accuracy: 0.8545\n","Epoch 56/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.6354 - val_accuracy: 0.8545\n","Epoch 57/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.6399 - val_accuracy: 0.8545\n","Epoch 58/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.6404 - val_accuracy: 0.8545\n","Epoch 59/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.6429 - val_accuracy: 0.8513\n","Epoch 60/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.6375 - val_accuracy: 0.8534\n","Epoch 61/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.6356 - val_accuracy: 0.8513\n","Epoch 62/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.6417 - val_accuracy: 0.8567\n","Epoch 63/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.6386 - val_accuracy: 0.8513\n","Epoch 64/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.6392 - val_accuracy: 0.8524\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.6382 - val_accuracy: 0.8545\n","Epoch 66/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.6362 - val_accuracy: 0.8545\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.6409 - val_accuracy: 0.8513\n","Epoch 68/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.6390 - val_accuracy: 0.8524\n","Epoch 69/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.6383 - val_accuracy: 0.8534\n","Epoch 70/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.6409 - val_accuracy: 0.8524\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.6343 - val_accuracy: 0.8534\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.6394 - val_accuracy: 0.8534\n","Epoch 73/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.6413 - val_accuracy: 0.8567\n","Epoch 74/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.6378 - val_accuracy: 0.8545\n","Epoch 75/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.6434 - val_accuracy: 0.8545\n","Epoch 76/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.6440 - val_accuracy: 0.8524\n","Epoch 77/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.6492 - val_accuracy: 0.8534\n","Epoch 78/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.6460 - val_accuracy: 0.8534\n","Epoch 79/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 0.8545\n","Epoch 80/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.6538 - val_accuracy: 0.8556\n","Epoch 81/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.6574 - val_accuracy: 0.8556\n","Epoch 82/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.6657 - val_accuracy: 0.8534\n","Epoch 83/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.6701 - val_accuracy: 0.8534\n","Epoch 84/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.6800 - val_accuracy: 0.8470\n","Epoch 85/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.6824 - val_accuracy: 0.8491\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.6814 - val_accuracy: 0.8502\n","Epoch 87/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.6895 - val_accuracy: 0.8491\n","Epoch 88/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.6966 - val_accuracy: 0.8481\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.6989 - val_accuracy: 0.8448\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.7063 - val_accuracy: 0.8427\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.6903 - val_accuracy: 0.8513\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.6936 - val_accuracy: 0.8470\n","Epoch 93/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.7067 - val_accuracy: 0.8438\n","Epoch 94/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.6936 - val_accuracy: 0.8491\n","Epoch 95/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.7025 - val_accuracy: 0.8470\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.6997 - val_accuracy: 0.8534\n","Epoch 97/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.6923 - val_accuracy: 0.8524\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.7511 - val_accuracy: 0.8438\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.7370 - val_accuracy: 0.8470\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.8470\n","{'loss': [0.13349321484565735, 0.05448101460933685, 0.040635280311107635, 0.04418160021305084, 0.05044439807534218, 0.05700839310884476, 0.04773970693349838, 0.06952834129333496, 0.0440981388092041, 0.02634289301931858, 0.02942197397351265, 0.0729716494679451, 0.07168891280889511, 0.03508061543107033, 0.052256833761930466, 0.09731592237949371, 0.044160857796669006, 0.04770275205373764, 0.06149003282189369, 0.03567275404930115, 0.03980836644768715, 0.026382816955447197, 0.017839178442955017, 0.018727242946624756, 0.024137243628501892, 0.054159555584192276, 0.05129103362560272, 0.046507056802511215, 0.03446369990706444, 0.027784116566181183, 0.03746536374092102, 0.07048797607421875, 0.08599048852920532, 0.03520245850086212, 0.020055178552865982, 0.02191459946334362, 0.017281370237469673, 0.014771796762943268, 0.01330637652426958, 0.012524469755589962, 0.01197031233459711, 0.011714470572769642, 0.011537047103047371, 0.011422485113143921, 0.0113067040219903, 0.011192278005182743, 0.011083435267210007, 0.010956350713968277, 0.010888121090829372, 0.01077270694077015, 0.010713331401348114, 0.010640241205692291, 0.010533532127737999, 0.010456263087689877, 0.010380923748016357, 0.010284578427672386, 0.010220957919955254, 0.01014980673789978, 0.010064712725579739, 0.009993049316108227, 0.00991794466972351, 0.009871009737253189, 0.0097946897149086, 0.009723551571369171, 0.009642782621085644, 0.009595882147550583, 0.009508011862635612, 0.009441993199288845, 0.009371902793645859, 0.009306621737778187, 0.00925061758607626, 0.0091971755027771, 0.009119649417698383, 0.009046160615980625, 0.008998429402709007, 0.00892234779894352, 0.008853279985487461, 0.008800083771348, 0.008718850091099739, 0.00867827795445919, 0.008593643084168434, 0.008528796024620533, 0.008430765941739082, 0.008380712941288948, 0.008272293023765087, 0.008234723471105099, 0.008150020614266396, 0.008100406266748905, 0.008054970763623714, 0.007979040965437889, 0.007924368605017662, 0.007865887135267258, 0.007801051717251539, 0.00776257598772645, 0.007696789223700762, 0.007671982981264591, 0.007606902625411749, 0.0076206582598388195, 0.00761043606325984, 0.007544399239122868], 'accuracy': [0.9555495977401733, 0.9873383641242981, 0.9881465435028076, 0.9894935488700867, 0.9862607717514038, 0.9838362336158752, 0.9873383641242981, 0.9768319129943848, 0.9903017282485962, 0.9956896305084229, 0.9932650923728943, 0.9754849076271057, 0.9787176847457886, 0.9903017282485962, 0.9865301847457886, 0.9679418206214905, 0.9892241358757019, 0.9867995977401733, 0.9819504022598267, 0.9913793206214905, 0.9881465435028076, 0.9948814511299133, 0.998383641242981, 0.9975754022598267, 0.9962284564971924, 0.985991358757019, 0.9849137663841248, 0.9878771305084229, 0.9911099076271057, 0.993803858757019, 0.9911099076271057, 0.9773706793785095, 0.9722521305084229, 0.993803858757019, 0.9978448152542114, 0.9962284564971924, 0.998383641242981, 0.9994612336158752, 0.9994612336158752, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.7445024847984314, 0.8224202990531921, 0.9036997556686401, 0.9111930131912231, 0.9571322798728943, 1.00617516040802, 1.0058996677398682, 0.9479368329048157, 1.0901920795440674, 1.2573431730270386, 1.1623269319534302, 1.4262559413909912, 1.0934497117996216, 1.305540919303894, 0.6466719508171082, 0.8322544097900391, 0.6331571936607361, 0.7970244884490967, 0.6136332750320435, 0.9305646419525146, 0.6495404243469238, 0.6437619924545288, 0.772817850112915, 0.6987451910972595, 0.8533675670623779, 0.6184573769569397, 0.6349121332168579, 0.6987017393112183, 0.7227022647857666, 0.7804087400436401, 0.7276334166526794, 0.667029619216919, 0.5825951099395752, 0.6421325206756592, 0.6711395978927612, 0.8554977774620056, 0.7757807970046997, 0.7539726495742798, 0.7038557529449463, 0.7634460926055908, 0.7583420872688293, 0.7196488380432129, 0.7095445990562439, 0.7043550610542297, 0.6947461366653442, 0.6862745881080627, 0.6771624088287354, 0.6651854515075684, 0.6588515639305115, 0.6550026535987854, 0.6520274877548218, 0.656980574131012, 0.6438753008842468, 0.6399081945419312, 0.6378302574157715, 0.6353871822357178, 0.6398605704307556, 0.6403763294219971, 0.6429157853126526, 0.6374589204788208, 0.6355560421943665, 0.6416786313056946, 0.6385589838027954, 0.6391696333885193, 0.6381580829620361, 0.6361554861068726, 0.6408629417419434, 0.6389937996864319, 0.6383268237113953, 0.6409059762954712, 0.6342663168907166, 0.6394170522689819, 0.6412615180015564, 0.6378151178359985, 0.643385112285614, 0.6440294981002808, 0.6491956114768982, 0.6459976434707642, 0.6475777626037598, 0.6537517309188843, 0.6574445962905884, 0.6657171845436096, 0.67014080286026, 0.6800254583358765, 0.6824107766151428, 0.6814498901367188, 0.6894798874855042, 0.6966015100479126, 0.6988645195960999, 0.706265389919281, 0.6902574896812439, 0.6935766339302063, 0.7066808938980103, 0.6935981512069702, 0.7025375962257385, 0.6996681094169617, 0.6922803521156311, 0.751069188117981, 0.7370359301567078, 0.712753176689148], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48706895112991333, 0.48706895112991333, 0.4903017282485962, 0.5161637663841248, 0.4913793206214905, 0.5161637663841248, 0.5366379022598267, 0.6982758641242981, 0.5969827771186829, 0.7306034564971924, 0.6713362336158752, 0.7478448152542114, 0.6961206793785095, 0.7737069129943848, 0.8028017282485962, 0.7909482717514038, 0.8168103694915771, 0.795258641242981, 0.7963362336158752, 0.8146551847457886, 0.8081896305084229, 0.837284505367279, 0.837284505367279, 0.8286637663841248, 0.8178879022598267, 0.8028017282485962, 0.8340517282485962, 0.8469827771186829, 0.8232758641242981, 0.8340517282485962, 0.8491379022598267, 0.8459051847457886, 0.8469827771186829, 0.8426724076271057, 0.8469827771186829, 0.8459051847457886, 0.8459051847457886, 0.8469827771186829, 0.8491379022598267, 0.8491379022598267, 0.8534482717514038, 0.8523706793785095, 0.850215494632721, 0.8491379022598267, 0.8491379022598267, 0.8512930870056152, 0.8545258641242981, 0.8545258641242981, 0.8545258641242981, 0.8545258641242981, 0.8545258641242981, 0.8512930870056152, 0.8534482717514038, 0.8512930870056152, 0.8566810488700867, 0.8512930870056152, 0.8523706793785095, 0.8545258641242981, 0.8545258641242981, 0.8512930870056152, 0.8523706793785095, 0.8534482717514038, 0.8523706793785095, 0.8534482717514038, 0.8534482717514038, 0.8566810488700867, 0.8545258641242981, 0.8545258641242981, 0.8523706793785095, 0.8534482717514038, 0.8534482717514038, 0.8545258641242981, 0.8556034564971924, 0.8556034564971924, 0.8534482717514038, 0.8534482717514038, 0.8469827771186829, 0.8491379022598267, 0.850215494632721, 0.8491379022598267, 0.8480603694915771, 0.8448275923728943, 0.8426724076271057, 0.8512930870056152, 0.8469827771186829, 0.84375, 0.8491379022598267, 0.8469827771186829, 0.8534482717514038, 0.8523706793785095, 0.84375, 0.8469827771186829, 0.8469827771186829]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.1129 - accuracy: 0.9657"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 9s 117ms/step - loss: 0.1105 - accuracy: 0.9669 - val_loss: 0.8011 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0485 - accuracy: 0.9898 - val_loss: 0.8549 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0304 - accuracy: 0.9946 - val_loss: 0.9495 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0371 - accuracy: 0.9892 - val_loss: 0.9801 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0596 - accuracy: 0.9822 - val_loss: 0.8786 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0753 - accuracy: 0.9759 - val_loss: 0.8879 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0496 - accuracy: 0.9867 - val_loss: 1.0107 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 1.1225 - val_accuracy: 0.4977\n","Epoch 9/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0356 - accuracy: 0.9909 - val_loss: 1.0779 - val_accuracy: 0.5034\n","Epoch 10/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0330 - accuracy: 0.9932 - val_loss: 1.2223 - val_accuracy: 0.5079\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0388 - accuracy: 0.9892 - val_loss: 1.4542 - val_accuracy: 0.5000\n","Epoch 12/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.0686 - accuracy: 0.9796 - val_loss: 0.8297 - val_accuracy: 0.5633\n","Epoch 13/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0915 - accuracy: 0.9680 - val_loss: 0.8110 - val_accuracy: 0.5769\n","Epoch 14/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0460 - accuracy: 0.9878 - val_loss: 0.9904 - val_accuracy: 0.5758\n","Epoch 15/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0308 - accuracy: 0.9938 - val_loss: 1.3195 - val_accuracy: 0.5532\n","Epoch 16/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.0308 - accuracy: 0.9932 - val_loss: 1.2815 - val_accuracy: 0.5848\n","Epoch 17/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.0348 - accuracy: 0.9904 - val_loss: 0.9211 - val_accuracy: 0.6606\n","Epoch 18/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0516 - accuracy: 0.9856 - val_loss: 1.0890 - val_accuracy: 0.6143\n","Epoch 19/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0580 - accuracy: 0.9873 - val_loss: 1.0387 - val_accuracy: 0.6527\n","Epoch 20/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.0668 - accuracy: 0.9802 - val_loss: 0.8400 - val_accuracy: 0.6889\n","Epoch 21/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0419 - accuracy: 0.9892 - val_loss: 0.6581 - val_accuracy: 0.7590\n","Epoch 22/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.0227 - accuracy: 0.9966 - val_loss: 0.7654 - val_accuracy: 0.7738\n","Epoch 23/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0224 - accuracy: 0.9969 - val_loss: 0.7716 - val_accuracy: 0.7896\n","Epoch 24/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0218 - accuracy: 0.9972 - val_loss: 0.8706 - val_accuracy: 0.7715\n","Epoch 25/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.0335 - accuracy: 0.9918 - val_loss: 0.7561 - val_accuracy: 0.8111\n","Epoch 26/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0327 - accuracy: 0.9912 - val_loss: 0.7220 - val_accuracy: 0.8020\n","Epoch 27/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.0379 - accuracy: 0.9924 - val_loss: 0.6310 - val_accuracy: 0.8292\n","Epoch 28/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0515 - accuracy: 0.9875 - val_loss: 0.6315 - val_accuracy: 0.8201\n","Epoch 29/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0397 - accuracy: 0.9904 - val_loss: 0.7013 - val_accuracy: 0.8235\n","Epoch 30/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0380 - accuracy: 0.9909 - val_loss: 0.7182 - val_accuracy: 0.8213\n","Epoch 31/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0357 - accuracy: 0.9909 - val_loss: 0.8390 - val_accuracy: 0.8133\n","Epoch 32/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0482 - accuracy: 0.9870 - val_loss: 0.7101 - val_accuracy: 0.8145\n","Epoch 33/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0463 - accuracy: 0.9881 - val_loss: 0.6820 - val_accuracy: 0.8348\n","Epoch 34/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0517 - accuracy: 0.9859 - val_loss: 0.5442 - val_accuracy: 0.8416\n","Epoch 35/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0307 - accuracy: 0.9935 - val_loss: 0.6522 - val_accuracy: 0.8326\n","Epoch 36/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.0183 - accuracy: 0.9975 - val_loss: 0.6613 - val_accuracy: 0.8439\n","Epoch 37/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0144 - accuracy: 0.9992 - val_loss: 0.6780 - val_accuracy: 0.8405\n","Epoch 38/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.0135 - accuracy: 0.9994 - val_loss: 0.6852 - val_accuracy: 0.8518\n","Epoch 39/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.0128 - accuracy: 0.9997 - val_loss: 0.5981 - val_accuracy: 0.8654\n","Epoch 40/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.5880 - val_accuracy: 0.8710\n","Epoch 41/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.5860 - val_accuracy: 0.8722\n","Epoch 42/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.5830 - val_accuracy: 0.8744\n","Epoch 43/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.5815 - val_accuracy: 0.8710\n","Epoch 44/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.5793 - val_accuracy: 0.8710\n","Epoch 45/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.5731 - val_accuracy: 0.8676\n","Epoch 46/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.5692 - val_accuracy: 0.8654\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.5651 - val_accuracy: 0.8665\n","Epoch 48/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.5620 - val_accuracy: 0.8676\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.5602 - val_accuracy: 0.8688\n","Epoch 50/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.5597 - val_accuracy: 0.8676\n","Epoch 51/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.5567 - val_accuracy: 0.8688\n","Epoch 52/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.5570 - val_accuracy: 0.8665\n","Epoch 53/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.5579 - val_accuracy: 0.8665\n","Epoch 54/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.5589 - val_accuracy: 0.8654\n","Epoch 55/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.5613 - val_accuracy: 0.8620\n","Epoch 56/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.5610 - val_accuracy: 0.8631\n","Epoch 57/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.5621 - val_accuracy: 0.8643\n","Epoch 58/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.5582 - val_accuracy: 0.8620\n","Epoch 59/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.5601 - val_accuracy: 0.8643\n","Epoch 60/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.5572 - val_accuracy: 0.8563\n","Epoch 61/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.5580 - val_accuracy: 0.8597\n","Epoch 62/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.5552 - val_accuracy: 0.8631\n","Epoch 63/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.5586 - val_accuracy: 0.8620\n","Epoch 64/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.5555 - val_accuracy: 0.8631\n","Epoch 65/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.5564 - val_accuracy: 0.8643\n","Epoch 66/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.5608 - val_accuracy: 0.8620\n","Epoch 67/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.5584 - val_accuracy: 0.8643\n","Epoch 68/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.5584 - val_accuracy: 0.8631\n","Epoch 69/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.5613 - val_accuracy: 0.8597\n","Epoch 70/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.5636 - val_accuracy: 0.8654\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.5599 - val_accuracy: 0.8620\n","Epoch 72/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.5628 - val_accuracy: 0.8609\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.5706 - val_accuracy: 0.8654\n","Epoch 74/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.5671 - val_accuracy: 0.8620\n","Epoch 75/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.5706 - val_accuracy: 0.8620\n","Epoch 76/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.5717 - val_accuracy: 0.8643\n","Epoch 77/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.5694 - val_accuracy: 0.8620\n","Epoch 78/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.5724 - val_accuracy: 0.8654\n","Epoch 79/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.5725 - val_accuracy: 0.8643\n","Epoch 80/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.5730 - val_accuracy: 0.8597\n","Epoch 81/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.5749 - val_accuracy: 0.8620\n","Epoch 82/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.5845 - val_accuracy: 0.8631\n","Epoch 83/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.5855 - val_accuracy: 0.8575\n","Epoch 84/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.5831 - val_accuracy: 0.8597\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.5812 - val_accuracy: 0.8597\n","Epoch 86/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.5782 - val_accuracy: 0.8597\n","Epoch 87/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.5777 - val_accuracy: 0.8609\n","Epoch 88/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.5758 - val_accuracy: 0.8609\n","Epoch 89/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.5799 - val_accuracy: 0.8620\n","Epoch 90/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.5786 - val_accuracy: 0.8631\n","Epoch 91/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.5771 - val_accuracy: 0.8620\n","Epoch 92/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.5828 - val_accuracy: 0.8620\n","Epoch 93/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.5849 - val_accuracy: 0.8620\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.5910 - val_accuracy: 0.8609\n","Epoch 95/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.6136 - val_accuracy: 0.8586\n","Epoch 96/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.5982 - val_accuracy: 0.8609\n","Epoch 97/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.5949 - val_accuracy: 0.8575\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.5947 - val_accuracy: 0.8586\n","Epoch 99/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.5952 - val_accuracy: 0.8563\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.5967 - val_accuracy: 0.8575\n","{'loss': [0.11046023666858673, 0.048511672765016556, 0.030400799587368965, 0.03706034645438194, 0.05957885831594467, 0.07534343749284744, 0.049574337899684906, 0.03571601212024689, 0.035611592233181, 0.033034805208444595, 0.038829974830150604, 0.06856019049882889, 0.09151233732700348, 0.04599517956376076, 0.030802659690380096, 0.03075822815299034, 0.0347837433218956, 0.051644790917634964, 0.05804109573364258, 0.06678168475627899, 0.04185184836387634, 0.022650746628642082, 0.022359240800142288, 0.02182765305042267, 0.03346117213368416, 0.03273196145892143, 0.0379277840256691, 0.051535896956920624, 0.03966321051120758, 0.03796829655766487, 0.03573819622397423, 0.048216138035058975, 0.04633847251534462, 0.05172613635659218, 0.03074977733194828, 0.01834196038544178, 0.014394696801900864, 0.01354849524796009, 0.012823967263102531, 0.011906205676496029, 0.011625604704022408, 0.011481906287372112, 0.011341962963342667, 0.011218338273465633, 0.011111542582511902, 0.011007859371602535, 0.01087794080376625, 0.01077967882156372, 0.010699732229113579, 0.010602246969938278, 0.010517417453229427, 0.010424738749861717, 0.01034405454993248, 0.010247139260172844, 0.01017469447106123, 0.010101144202053547, 0.010022880509495735, 0.009938529692590237, 0.0098726786673069, 0.009783962741494179, 0.00972248800098896, 0.00965036265552044, 0.009597591124475002, 0.009493967518210411, 0.009413258172571659, 0.009341797791421413, 0.009281201288104057, 0.009216085076332092, 0.009136950597167015, 0.00906423944979906, 0.009011786431074142, 0.008925123140215874, 0.008865772746503353, 0.008793945424258709, 0.008725426159799099, 0.008673028089106083, 0.008585972711443901, 0.008524454198777676, 0.00848111417144537, 0.008411345072090626, 0.008373251184821129, 0.008305976167321205, 0.00825409684330225, 0.008178919553756714, 0.00811147503554821, 0.008049620315432549, 0.008017178624868393, 0.007944226264953613, 0.007881642319262028, 0.007848399691283703, 0.007777376566082239, 0.00771904643625021, 0.007675078231841326, 0.007619793526828289, 0.007579490542411804, 0.0075410520657896996, 0.007486789021641016, 0.0074297720566391945, 0.00735880620777607, 0.007321173325181007], 'accuracy': [0.9668930172920227, 0.9898132681846619, 0.9946236610412598, 0.9892473220825195, 0.9821732044219971, 0.975947916507721, 0.9867005944252014, 0.9912280440330505, 0.9909451007843018, 0.9932088255882263, 0.9892473220825195, 0.979626476764679, 0.9680249094963074, 0.9878324866294861, 0.9937747716903687, 0.9932088255882263, 0.9903791546821594, 0.9855687618255615, 0.9872665405273438, 0.9801924228668213, 0.9892473220825195, 0.9966044425964355, 0.9968873858451843, 0.9971703290939331, 0.9917939901351929, 0.9912280440330505, 0.9923599362373352, 0.9875495433807373, 0.9903791546821594, 0.9909451007843018, 0.9909451007843018, 0.986983597278595, 0.9881154298782349, 0.9858517050743103, 0.9934917688369751, 0.9974533319473267, 0.9991511106491089, 0.9994340538978577, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.8010703921318054, 0.8548524379730225, 0.9494777917861938, 0.9801439642906189, 0.8785979747772217, 0.8879006505012512, 1.0107289552688599, 1.1224514245986938, 1.0779364109039307, 1.2223299741744995, 1.454241156578064, 0.8297142386436462, 0.8110142350196838, 0.9903536438941956, 1.31949782371521, 1.2815144062042236, 0.9211152195930481, 1.0890194177627563, 1.0387378931045532, 0.8399512767791748, 0.6581266522407532, 0.7653908729553223, 0.7716381549835205, 0.8706107139587402, 0.7560532689094543, 0.7220044732093811, 0.6310364603996277, 0.6314964890480042, 0.7012884616851807, 0.7181628346443176, 0.8390085697174072, 0.710128664970398, 0.6820194721221924, 0.5441527366638184, 0.6522156596183777, 0.6613144278526306, 0.678026556968689, 0.6851670145988464, 0.5980561375617981, 0.5879519581794739, 0.5860061049461365, 0.5830287337303162, 0.5814505815505981, 0.5793418288230896, 0.5731098055839539, 0.5692452192306519, 0.5651081800460815, 0.5620476603507996, 0.5601903200149536, 0.5596764087677002, 0.5566871762275696, 0.5569860339164734, 0.5579451322555542, 0.5588735938072205, 0.5612848401069641, 0.5610290169715881, 0.5621001124382019, 0.5581652522087097, 0.5600619316101074, 0.5572195053100586, 0.5579588413238525, 0.5551689863204956, 0.5585907697677612, 0.5555183291435242, 0.5564061999320984, 0.5607859492301941, 0.558390200138092, 0.5583592057228088, 0.5613160729408264, 0.5636192560195923, 0.559911847114563, 0.5628318190574646, 0.5705901384353638, 0.5671467185020447, 0.5705991387367249, 0.5717405080795288, 0.5694469809532166, 0.5724167823791504, 0.5724944472312927, 0.5730146765708923, 0.5749212503433228, 0.5844525694847107, 0.5855347514152527, 0.5830568075180054, 0.5811665654182434, 0.5782085657119751, 0.5776560306549072, 0.575844943523407, 0.5798724293708801, 0.5785945057868958, 0.5770851373672485, 0.5828051567077637, 0.5849292278289795, 0.5910108089447021, 0.6136289834976196, 0.5981724858283997, 0.5948716998100281, 0.5946575999259949, 0.5952332615852356, 0.5967314839363098], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4977375566959381, 0.5033936500549316, 0.5079185366630554, 0.5, 0.5633484125137329, 0.5769230723381042, 0.5757918357849121, 0.5531674027442932, 0.5848416090011597, 0.6606335043907166, 0.6142534017562866, 0.6527149081230164, 0.6889140009880066, 0.7590497732162476, 0.773755669593811, 0.7895927429199219, 0.7714931964874268, 0.8110859990119934, 0.8020362257957458, 0.8291855454444885, 0.820135772228241, 0.8235294222831726, 0.8212669491767883, 0.8133484125137329, 0.814479649066925, 0.8348416090011597, 0.8416289687156677, 0.8325791954994202, 0.8438913822174072, 0.8404977321624756, 0.8518099784851074, 0.8653846383094788, 0.8710407018661499, 0.872171938419342, 0.8744344115257263, 0.8710407018661499, 0.8710407018661499, 0.8676470518112183, 0.8653846383094788, 0.8665158152580261, 0.8676470518112183, 0.8687782883644104, 0.8676470518112183, 0.8687782883644104, 0.8665158152580261, 0.8665158152580261, 0.8653846383094788, 0.8619909286499023, 0.8631221652030945, 0.8642534017562866, 0.8619909286499023, 0.8642534017562866, 0.8563348650932312, 0.8597285151481628, 0.8631221652030945, 0.8619909286499023, 0.8631221652030945, 0.8642534017562866, 0.8619909286499023, 0.8642534017562866, 0.8631221652030945, 0.8597285151481628, 0.8653846383094788, 0.8619909286499023, 0.860859751701355, 0.8653846383094788, 0.8619909286499023, 0.8619909286499023, 0.8642534017562866, 0.8619909286499023, 0.8653846383094788, 0.8642534017562866, 0.8597285151481628, 0.8619909286499023, 0.8631221652030945, 0.8574660420417786, 0.8597285151481628, 0.8597285151481628, 0.8597285151481628, 0.860859751701355, 0.860859751701355, 0.8619909286499023, 0.8631221652030945, 0.8619909286499023, 0.8619909286499023, 0.8619909286499023, 0.860859751701355, 0.8585972785949707, 0.860859751701355, 0.8574660420417786, 0.8585972785949707, 0.8563348650932312, 0.8574660420417786]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.1312 - accuracy: 0.9622"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 75ms/step - loss: 0.1304 - accuracy: 0.9625 - val_loss: 0.7698 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0648 - accuracy: 0.9804 - val_loss: 0.8727 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0654 - accuracy: 0.9809 - val_loss: 0.8558 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0476 - accuracy: 0.9876 - val_loss: 0.9508 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0871 - accuracy: 0.9721 - val_loss: 0.8399 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0735 - accuracy: 0.9778 - val_loss: 0.8685 - val_accuracy: 0.4876\n","Epoch 7/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0413 - accuracy: 0.9886 - val_loss: 1.0891 - val_accuracy: 0.4866\n","Epoch 8/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0596 - accuracy: 0.9817 - val_loss: 1.1115 - val_accuracy: 0.4886\n","Epoch 9/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0574 - accuracy: 0.9842 - val_loss: 1.1043 - val_accuracy: 0.4938\n","Epoch 10/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0546 - accuracy: 0.9832 - val_loss: 1.2463 - val_accuracy: 0.4938\n","Epoch 11/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0495 - accuracy: 0.9842 - val_loss: 1.0883 - val_accuracy: 0.5134\n","Epoch 12/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0277 - accuracy: 0.9956 - val_loss: 1.1957 - val_accuracy: 0.5434\n","Epoch 13/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0332 - accuracy: 0.9925 - val_loss: 1.2250 - val_accuracy: 0.5610\n","Epoch 14/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0855 - accuracy: 0.9731 - val_loss: 1.0650 - val_accuracy: 0.5640\n","Epoch 15/100\n","31/31 [==============================] - 1s 35ms/step - loss: 0.0805 - accuracy: 0.9752 - val_loss: 0.8304 - val_accuracy: 0.6302\n","Epoch 16/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0398 - accuracy: 0.9907 - val_loss: 1.0091 - val_accuracy: 0.6219\n","Epoch 17/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.0252 - accuracy: 0.9961 - val_loss: 0.6846 - val_accuracy: 0.7500\n","Epoch 18/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0269 - accuracy: 0.9941 - val_loss: 0.8467 - val_accuracy: 0.7428\n","Epoch 19/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0572 - accuracy: 0.9798 - val_loss: 0.6679 - val_accuracy: 0.7707\n","Epoch 20/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0799 - accuracy: 0.9734 - val_loss: 0.5600 - val_accuracy: 0.8048\n","Epoch 21/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0581 - accuracy: 0.9817 - val_loss: 0.6051 - val_accuracy: 0.7955\n","Epoch 22/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0289 - accuracy: 0.9956 - val_loss: 0.7034 - val_accuracy: 0.7924\n","Epoch 23/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0252 - accuracy: 0.9966 - val_loss: 0.6006 - val_accuracy: 0.8347\n","Epoch 24/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0868 - accuracy: 0.9726 - val_loss: 0.5990 - val_accuracy: 0.7986\n","Epoch 25/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0793 - accuracy: 0.9770 - val_loss: 0.5576 - val_accuracy: 0.8192\n","Epoch 26/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0236 - accuracy: 0.9972 - val_loss: 0.6347 - val_accuracy: 0.8440\n","Epoch 27/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0153 - accuracy: 0.9995 - val_loss: 0.7066 - val_accuracy: 0.8388\n","Epoch 28/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0135 - accuracy: 0.9997 - val_loss: 0.6859 - val_accuracy: 0.8461\n","Epoch 29/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.8461\n","Epoch 30/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.6958 - val_accuracy: 0.8533\n","Epoch 31/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.6992 - val_accuracy: 0.8461\n","Epoch 32/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.6866 - val_accuracy: 0.8440\n","Epoch 33/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.6924 - val_accuracy: 0.8481\n","Epoch 34/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.6892 - val_accuracy: 0.8461\n","Epoch 35/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.6838 - val_accuracy: 0.8502\n","Epoch 36/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.6810 - val_accuracy: 0.8471\n","Epoch 37/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.6749 - val_accuracy: 0.8502\n","Epoch 38/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.6737 - val_accuracy: 0.8471\n","Epoch 39/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.6702 - val_accuracy: 0.8502\n","Epoch 40/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.6603 - val_accuracy: 0.8523\n","Epoch 41/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.6601 - val_accuracy: 0.8523\n","Epoch 42/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.6561 - val_accuracy: 0.8533\n","Epoch 43/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.6551 - val_accuracy: 0.8523\n","Epoch 44/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.6558 - val_accuracy: 0.8523\n","Epoch 45/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.6551 - val_accuracy: 0.8512\n","Epoch 46/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.6568 - val_accuracy: 0.8523\n","Epoch 47/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.6560 - val_accuracy: 0.8533\n","Epoch 48/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.6594 - val_accuracy: 0.8512\n","Epoch 49/100\n","31/31 [==============================] - 2s 53ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.6549 - val_accuracy: 0.8543\n","Epoch 50/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.6510 - val_accuracy: 0.8533\n","Epoch 51/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.6569 - val_accuracy: 0.8492\n","Epoch 52/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.6669 - val_accuracy: 0.8512\n","Epoch 53/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.6597 - val_accuracy: 0.8492\n","Epoch 54/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.6550 - val_accuracy: 0.8502\n","Epoch 55/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.6592 - val_accuracy: 0.8502\n","Epoch 56/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.6608 - val_accuracy: 0.8471\n","Epoch 57/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.6533 - val_accuracy: 0.8512\n","Epoch 58/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.6563 - val_accuracy: 0.8502\n","Epoch 59/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.6609 - val_accuracy: 0.8492\n","Epoch 60/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.6613 - val_accuracy: 0.8502\n","Epoch 61/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.6700 - val_accuracy: 0.8492\n","Epoch 62/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.6686 - val_accuracy: 0.8492\n","Epoch 63/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0108 - accuracy: 0.9992 - val_loss: 0.9975 - val_accuracy: 0.7924\n","Epoch 64/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3090 - accuracy: 0.8858 - val_loss: 0.5165 - val_accuracy: 0.7779\n","Epoch 65/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1109 - accuracy: 0.9607 - val_loss: 0.7157 - val_accuracy: 0.7872\n","Epoch 66/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1421 - accuracy: 0.9473 - val_loss: 0.5724 - val_accuracy: 0.7872\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0940 - accuracy: 0.9713 - val_loss: 0.6813 - val_accuracy: 0.8110\n","Epoch 68/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0502 - accuracy: 0.9855 - val_loss: 0.8764 - val_accuracy: 0.7913\n","Epoch 69/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1388 - accuracy: 0.9494 - val_loss: 0.6745 - val_accuracy: 0.7521\n","Epoch 70/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0656 - accuracy: 0.9804 - val_loss: 0.7465 - val_accuracy: 0.8027\n","Epoch 71/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0400 - accuracy: 0.9910 - val_loss: 0.7260 - val_accuracy: 0.8151\n","Epoch 72/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0316 - accuracy: 0.9935 - val_loss: 0.8643 - val_accuracy: 0.7965\n","Epoch 73/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0878 - accuracy: 0.9703 - val_loss: 0.7806 - val_accuracy: 0.7789\n","Epoch 74/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0404 - accuracy: 0.9897 - val_loss: 0.7539 - val_accuracy: 0.8140\n","Epoch 75/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0266 - accuracy: 0.9935 - val_loss: 0.8414 - val_accuracy: 0.8037\n","Epoch 76/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0251 - accuracy: 0.9938 - val_loss: 0.9612 - val_accuracy: 0.7872\n","Epoch 77/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0579 - accuracy: 0.9822 - val_loss: 0.8193 - val_accuracy: 0.8140\n","Epoch 78/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0699 - accuracy: 0.9791 - val_loss: 0.7926 - val_accuracy: 0.7893\n","Epoch 79/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0378 - accuracy: 0.9904 - val_loss: 0.8291 - val_accuracy: 0.8140\n","Epoch 80/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0197 - accuracy: 0.9977 - val_loss: 0.9003 - val_accuracy: 0.8110\n","Epoch 81/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0206 - accuracy: 0.9956 - val_loss: 0.9127 - val_accuracy: 0.8079\n","Epoch 82/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0316 - accuracy: 0.9897 - val_loss: 1.0201 - val_accuracy: 0.7727\n","Epoch 83/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0498 - accuracy: 0.9868 - val_loss: 0.9856 - val_accuracy: 0.7789\n","Epoch 84/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0798 - accuracy: 0.9744 - val_loss: 0.7324 - val_accuracy: 0.7924\n","Epoch 85/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0451 - accuracy: 0.9881 - val_loss: 0.7309 - val_accuracy: 0.8006\n","Epoch 86/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0230 - accuracy: 0.9964 - val_loss: 0.8787 - val_accuracy: 0.7913\n","Epoch 87/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0201 - accuracy: 0.9961 - val_loss: 0.8461 - val_accuracy: 0.8151\n","Epoch 88/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0248 - accuracy: 0.9948 - val_loss: 0.9156 - val_accuracy: 0.8027\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0505 - accuracy: 0.9848 - val_loss: 0.8784 - val_accuracy: 0.7769\n","Epoch 90/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0444 - accuracy: 0.9866 - val_loss: 0.8607 - val_accuracy: 0.7882\n","Epoch 91/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0255 - accuracy: 0.9935 - val_loss: 0.8325 - val_accuracy: 0.8006\n","Epoch 92/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0785 - accuracy: 0.9765 - val_loss: 0.7923 - val_accuracy: 0.7717\n","Epoch 93/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0466 - accuracy: 0.9873 - val_loss: 0.7404 - val_accuracy: 0.8027\n","Epoch 94/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0272 - accuracy: 0.9941 - val_loss: 1.0271 - val_accuracy: 0.7851\n","Epoch 95/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0250 - accuracy: 0.9938 - val_loss: 1.1127 - val_accuracy: 0.7686\n","Epoch 96/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0377 - accuracy: 0.9899 - val_loss: 0.8688 - val_accuracy: 0.7996\n","Epoch 97/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0345 - accuracy: 0.9897 - val_loss: 1.1916 - val_accuracy: 0.7293\n","Epoch 98/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0357 - accuracy: 0.9894 - val_loss: 1.0199 - val_accuracy: 0.7779\n","Epoch 99/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0236 - accuracy: 0.9938 - val_loss: 1.0700 - val_accuracy: 0.7831\n","Epoch 100/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0257 - accuracy: 0.9941 - val_loss: 0.9751 - val_accuracy: 0.7955\n","{'loss': [0.13043904304504395, 0.06481758505105972, 0.06539880484342575, 0.04759155958890915, 0.08713553845882416, 0.07354268431663513, 0.04131751507520676, 0.059630803763866425, 0.05735062062740326, 0.05460140481591225, 0.04945601895451546, 0.027689386159181595, 0.033189237117767334, 0.08552591502666473, 0.08050568401813507, 0.039772097021341324, 0.025202453136444092, 0.026909982785582542, 0.057153504341840744, 0.0799441784620285, 0.058126300573349, 0.028934672474861145, 0.025235701352357864, 0.08676482737064362, 0.07931172847747803, 0.023641321808099747, 0.015311420895159245, 0.013478978537023067, 0.012821849435567856, 0.012510089203715324, 0.012177642434835434, 0.01200843695551157, 0.011825690045952797, 0.01168535090982914, 0.011595889925956726, 0.011474503204226494, 0.011373522691428661, 0.01124792080372572, 0.011146439239382744, 0.01106211170554161, 0.010962056927382946, 0.010823441669344902, 0.010787524282932281, 0.010669701732695103, 0.010564792901277542, 0.010487288236618042, 0.010406821966171265, 0.01031681802123785, 0.010243060067296028, 0.01016162522137165, 0.010089810006320477, 0.010093079879879951, 0.009919686242938042, 0.0098312608897686, 0.009757200255990028, 0.009666996076703072, 0.009585541673004627, 0.00949320662766695, 0.009433801285922527, 0.009338355623185635, 0.009306087158620358, 0.009232625365257263, 0.01078397873789072, 0.3090372383594513, 0.11092758178710938, 0.14211972057819366, 0.0939863994717598, 0.050239402800798416, 0.13880066573619843, 0.06557673215866089, 0.040039658546447754, 0.03158387914299965, 0.08780577778816223, 0.04041312262415886, 0.026553891599178314, 0.02511702850461006, 0.05789853259921074, 0.06992104649543762, 0.0378231517970562, 0.019672660157084465, 0.020580459386110306, 0.03156059607863426, 0.04975020885467529, 0.07975900173187256, 0.04505765810608864, 0.02304735779762268, 0.020118827000260353, 0.024757757782936096, 0.05051837116479874, 0.044363733381032944, 0.025505512952804565, 0.07849016785621643, 0.04658756032586098, 0.027197061106562614, 0.025006335228681564, 0.03771117329597473, 0.03449339419603348, 0.035744380205869675, 0.023628022521734238, 0.025742830708622932], 'accuracy': [0.9625322818756104, 0.9803617596626282, 0.9808785319328308, 0.987596869468689, 0.9720930457115173, 0.9777777791023254, 0.988630473613739, 0.9816537499427795, 0.9842377305030823, 0.9832041263580322, 0.9842377305030823, 0.9956072568893433, 0.9925064444541931, 0.9731265902519226, 0.9751937985420227, 0.9906976819038391, 0.9961240291595459, 0.9940568208694458, 0.9798449873924255, 0.9733850359916687, 0.9816537499427795, 0.9956072568893433, 0.9966408014297485, 0.97260981798172, 0.9770025610923767, 0.997157633304596, 0.9994832277297974, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9992247819900513, 0.8857881426811218, 0.9607235193252563, 0.94728684425354, 0.9713178277015686, 0.9855297207832336, 0.9493539929389954, 0.9803617596626282, 0.9909560680389404, 0.9935400485992432, 0.9702842235565186, 0.9896640777587891, 0.9935400485992432, 0.9937984347343445, 0.9821705222129822, 0.9790697693824768, 0.9904392957687378, 0.9976744055747986, 0.9956072568893433, 0.9896640777587891, 0.986821711063385, 0.974418580532074, 0.9881137013435364, 0.9963824152946472, 0.9961240291595459, 0.9948320388793945, 0.9847545027732849, 0.9865633249282837, 0.9935400485992432, 0.9764857888221741, 0.9873384833335876, 0.9940568208694458, 0.9937984347343445, 0.9899224638938904, 0.9896640777587891, 0.9894056916236877, 0.9937984347343445, 0.9940568208694458], 'val_loss': [0.7697605490684509, 0.8726508021354675, 0.8558353781700134, 0.950788676738739, 0.839913010597229, 0.8684743046760559, 1.089117407798767, 1.111488938331604, 1.1042919158935547, 1.2463253736495972, 1.0883034467697144, 1.1956812143325806, 1.2249646186828613, 1.0649628639221191, 0.830441415309906, 1.009139895439148, 0.6846246719360352, 0.8466803431510925, 0.6679252982139587, 0.5599691271781921, 0.6050904989242554, 0.7033998966217041, 0.600584089756012, 0.599021852016449, 0.55762779712677, 0.6346780061721802, 0.7066199779510498, 0.6859388947486877, 0.6905951499938965, 0.6957824230194092, 0.6992190480232239, 0.6865890026092529, 0.6924256086349487, 0.6892217993736267, 0.6838334798812866, 0.6810301542282104, 0.6749384999275208, 0.6737287044525146, 0.6702468991279602, 0.6602652072906494, 0.6601341962814331, 0.6561221480369568, 0.6551347970962524, 0.6558049321174622, 0.6550725698471069, 0.6567893624305725, 0.6560268402099609, 0.6593874096870422, 0.6549251675605774, 0.6509861350059509, 0.6569362878799438, 0.6668704748153687, 0.6597130298614502, 0.6549901962280273, 0.6591987013816833, 0.6608400344848633, 0.6533082127571106, 0.6563254594802856, 0.6609340906143188, 0.6612606644630432, 0.6699932217597961, 0.6685609221458435, 0.9974873661994934, 0.5165470838546753, 0.7157115936279297, 0.5723772048950195, 0.6813478469848633, 0.8763863444328308, 0.6745277643203735, 0.7464590072631836, 0.726020097732544, 0.8642858862876892, 0.7805717587471008, 0.7538536190986633, 0.8413760662078857, 0.9612294435501099, 0.819301962852478, 0.7925969958305359, 0.8291465640068054, 0.9003201127052307, 0.9127101898193359, 1.0201225280761719, 0.985628604888916, 0.7323607802391052, 0.7308527231216431, 0.878692626953125, 0.8461219072341919, 0.9155857563018799, 0.8783518671989441, 0.860739529132843, 0.8325385451316833, 0.7922842502593994, 0.7404330372810364, 1.0271402597427368, 1.1126574277877808, 0.868800163269043, 1.191636323928833, 1.0198695659637451, 1.0700188875198364, 0.975138247013092], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4876033067703247, 0.48657023906707764, 0.4886363744735718, 0.49380165338516235, 0.49380165338516235, 0.5134297609329224, 0.5433884263038635, 0.5609503984451294, 0.5640496015548706, 0.6301652789115906, 0.6219007968902588, 0.75, 0.7427685856819153, 0.7706611752510071, 0.8047520518302917, 0.7954545617103577, 0.7923553586006165, 0.8347107172012329, 0.7985537052154541, 0.8192148804664612, 0.8440082669258118, 0.8388429880142212, 0.8460744023323059, 0.8460744023323059, 0.8533057570457458, 0.8460744023323059, 0.8440082669258118, 0.8481404781341553, 0.8460744023323059, 0.8502066135406494, 0.8471074104309082, 0.8502066135406494, 0.8471074104309082, 0.8502066135406494, 0.8522727489471436, 0.8522727489471436, 0.8533057570457458, 0.8522727489471436, 0.8522727489471436, 0.8512396812438965, 0.8522727489471436, 0.8533057570457458, 0.8512396812438965, 0.8543388247489929, 0.8533057570457458, 0.8491735458374023, 0.8512396812438965, 0.8491735458374023, 0.8502066135406494, 0.8502066135406494, 0.8471074104309082, 0.8512396812438965, 0.8502066135406494, 0.8491735458374023, 0.8502066135406494, 0.8491735458374023, 0.8491735458374023, 0.7923553586006165, 0.7778925895690918, 0.7871900796890259, 0.7871900796890259, 0.8109503984451294, 0.7913222908973694, 0.7520661354064941, 0.8026859760284424, 0.8150826692581177, 0.7964876294136047, 0.7789255976676941, 0.8140496015548706, 0.8037189841270447, 0.7871900796890259, 0.8140496015548706, 0.78925621509552, 0.8140496015548706, 0.8109503984451294, 0.807851254940033, 0.7727272510528564, 0.7789255976676941, 0.7923553586006165, 0.8006198406219482, 0.7913222908973694, 0.8150826692581177, 0.8026859760284424, 0.7768595218658447, 0.788223147392273, 0.8006198406219482, 0.7716942429542542, 0.8026859760284424, 0.7851239442825317, 0.7685950398445129, 0.7995867729187012, 0.7293388247489929, 0.7778925895690918, 0.7830578684806824, 0.7954545617103577]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.0769 - accuracy: 0.9751"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 65ms/step - loss: 0.0784 - accuracy: 0.9733 - val_loss: 0.9086 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0342 - accuracy: 0.9911 - val_loss: 1.0267 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0291 - accuracy: 0.9919 - val_loss: 1.0707 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0346 - accuracy: 0.9903 - val_loss: 1.0195 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0441 - accuracy: 0.9876 - val_loss: 0.9726 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0316 - accuracy: 0.9914 - val_loss: 1.1233 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0189 - accuracy: 0.9960 - val_loss: 1.1210 - val_accuracy: 0.4903\n","Epoch 8/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0303 - accuracy: 0.9930 - val_loss: 1.3789 - val_accuracy: 0.4860\n","Epoch 9/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0632 - accuracy: 0.9776 - val_loss: 1.0385 - val_accuracy: 0.4935\n","Epoch 10/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0504 - accuracy: 0.9846 - val_loss: 1.1008 - val_accuracy: 0.4989\n","Epoch 11/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.0313 - accuracy: 0.9922 - val_loss: 1.0391 - val_accuracy: 0.5377\n","Epoch 12/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0397 - accuracy: 0.9898 - val_loss: 1.2077 - val_accuracy: 0.5075\n","Epoch 13/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0382 - accuracy: 0.9881 - val_loss: 0.9397 - val_accuracy: 0.5776\n","Epoch 14/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0403 - accuracy: 0.9890 - val_loss: 0.8708 - val_accuracy: 0.6153\n","Epoch 15/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.0262 - accuracy: 0.9930 - val_loss: 0.8215 - val_accuracy: 0.6649\n","Epoch 16/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.0323 - accuracy: 0.9916 - val_loss: 0.6848 - val_accuracy: 0.7177\n","Epoch 17/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0289 - accuracy: 0.9927 - val_loss: 0.9635 - val_accuracy: 0.6670\n","Epoch 18/100\n","29/29 [==============================] - 1s 39ms/step - loss: 0.0315 - accuracy: 0.9927 - val_loss: 0.6290 - val_accuracy: 0.7640\n","Epoch 19/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0343 - accuracy: 0.9906 - val_loss: 0.5951 - val_accuracy: 0.7769\n","Epoch 20/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0442 - accuracy: 0.9857 - val_loss: 0.7831 - val_accuracy: 0.7349\n","Epoch 21/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0380 - accuracy: 0.9884 - val_loss: 0.6004 - val_accuracy: 0.8039\n","Epoch 22/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0354 - accuracy: 0.9895 - val_loss: 0.4937 - val_accuracy: 0.8244\n","Epoch 23/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0312 - accuracy: 0.9925 - val_loss: 0.4994 - val_accuracy: 0.8438\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0287 - accuracy: 0.9930 - val_loss: 0.5580 - val_accuracy: 0.8319\n","Epoch 25/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0203 - accuracy: 0.9954 - val_loss: 0.4952 - val_accuracy: 0.8491\n","Epoch 26/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0263 - accuracy: 0.9941 - val_loss: 0.5766 - val_accuracy: 0.8427\n","Epoch 27/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0338 - accuracy: 0.9903 - val_loss: 0.6407 - val_accuracy: 0.8384\n","Epoch 28/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0587 - accuracy: 0.9836 - val_loss: 0.5256 - val_accuracy: 0.8384\n","Epoch 29/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0268 - accuracy: 0.9938 - val_loss: 0.5591 - val_accuracy: 0.8524\n","Epoch 30/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0151 - accuracy: 0.9978 - val_loss: 0.5715 - val_accuracy: 0.8879\n","Epoch 31/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0121 - accuracy: 0.9989 - val_loss: 0.6051 - val_accuracy: 0.8772\n","Epoch 32/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0115 - accuracy: 0.9989 - val_loss: 0.6345 - val_accuracy: 0.8869\n","Epoch 33/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0109 - accuracy: 0.9989 - val_loss: 0.5974 - val_accuracy: 0.8901\n","Epoch 34/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.5923 - val_accuracy: 0.8869\n","Epoch 35/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.5709 - val_accuracy: 0.8879\n","Epoch 36/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.5717 - val_accuracy: 0.8879\n","Epoch 37/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.5576 - val_accuracy: 0.8901\n","Epoch 38/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.5571 - val_accuracy: 0.8890\n","Epoch 39/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.5456 - val_accuracy: 0.8890\n","Epoch 40/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.5407 - val_accuracy: 0.8879\n","Epoch 41/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.5407 - val_accuracy: 0.8869\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.5322 - val_accuracy: 0.8869\n","Epoch 43/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.5331 - val_accuracy: 0.8847\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.5295 - val_accuracy: 0.8847\n","Epoch 45/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.5281 - val_accuracy: 0.8836\n","Epoch 46/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.5247 - val_accuracy: 0.8836\n","Epoch 47/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.5253 - val_accuracy: 0.8879\n","Epoch 48/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.5230 - val_accuracy: 0.8879\n","Epoch 49/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.5222 - val_accuracy: 0.8890\n","Epoch 50/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.5239 - val_accuracy: 0.8890\n","Epoch 51/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.5204 - val_accuracy: 0.8869\n","Epoch 52/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.5184 - val_accuracy: 0.8879\n","Epoch 53/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.5167 - val_accuracy: 0.8890\n","Epoch 54/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.5186 - val_accuracy: 0.8879\n","Epoch 55/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.5209 - val_accuracy: 0.8879\n","Epoch 56/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.5168 - val_accuracy: 0.8901\n","Epoch 57/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.5167 - val_accuracy: 0.8890\n","Epoch 58/100\n","29/29 [==============================] - 2s 57ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.5165 - val_accuracy: 0.8933\n","Epoch 59/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.5190 - val_accuracy: 0.8901\n","Epoch 60/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.5190 - val_accuracy: 0.8922\n","Epoch 61/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.5309 - val_accuracy: 0.8869\n","Epoch 62/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.5229 - val_accuracy: 0.8858\n","Epoch 63/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.5195 - val_accuracy: 0.8890\n","Epoch 64/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.5192 - val_accuracy: 0.8912\n","Epoch 65/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.5209 - val_accuracy: 0.8901\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.5225 - val_accuracy: 0.8890\n","Epoch 67/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.5168 - val_accuracy: 0.8955\n","Epoch 68/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.5184 - val_accuracy: 0.8912\n","Epoch 69/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.5217 - val_accuracy: 0.8901\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.5249 - val_accuracy: 0.8890\n","Epoch 71/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.5189 - val_accuracy: 0.8922\n","Epoch 72/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.5210 - val_accuracy: 0.8901\n","Epoch 73/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.5192 - val_accuracy: 0.8922\n","Epoch 74/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.5205 - val_accuracy: 0.8922\n","Epoch 75/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.5227 - val_accuracy: 0.8912\n","Epoch 76/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.5212 - val_accuracy: 0.8912\n","Epoch 77/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.5208 - val_accuracy: 0.8912\n","Epoch 78/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.5205 - val_accuracy: 0.8890\n","Epoch 79/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.5212 - val_accuracy: 0.8890\n","Epoch 80/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.5201 - val_accuracy: 0.8879\n","Epoch 81/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.5205 - val_accuracy: 0.8901\n","Epoch 82/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.5205 - val_accuracy: 0.8890\n","Epoch 83/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.5230 - val_accuracy: 0.8879\n","Epoch 84/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.5244 - val_accuracy: 0.8879\n","Epoch 85/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.5259 - val_accuracy: 0.8879\n","Epoch 86/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.5286 - val_accuracy: 0.8879\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5295 - val_accuracy: 0.8858\n","Epoch 88/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5304 - val_accuracy: 0.8879\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5315 - val_accuracy: 0.8890\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5292 - val_accuracy: 0.8847\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.5294 - val_accuracy: 0.8858\n","Epoch 92/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.5307 - val_accuracy: 0.8879\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.5325 - val_accuracy: 0.8879\n","Epoch 94/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.5306 - val_accuracy: 0.8890\n","Epoch 95/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.5312 - val_accuracy: 0.8836\n","Epoch 96/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.5320 - val_accuracy: 0.8858\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.5335 - val_accuracy: 0.8847\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.5340 - val_accuracy: 0.8879\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5337 - val_accuracy: 0.8858\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5373 - val_accuracy: 0.8869\n","{'loss': [0.07844068855047226, 0.03416035324335098, 0.02905253879725933, 0.03461597114801407, 0.04410701245069504, 0.03161952272057533, 0.018872763961553574, 0.030283581465482712, 0.06315518170595169, 0.050426408648490906, 0.03132510557770729, 0.03965786099433899, 0.03815891593694687, 0.04030739143490791, 0.026249444112181664, 0.03227178752422333, 0.02892845869064331, 0.03146780654788017, 0.03431344032287598, 0.044173918664455414, 0.03803737089037895, 0.03539977967739105, 0.031208954751491547, 0.028742976486682892, 0.02033292129635811, 0.026294488459825516, 0.033835407346487045, 0.058712393045425415, 0.026818037033081055, 0.01512817945331335, 0.012140036560595036, 0.011518683284521103, 0.010927699506282806, 0.009082158096134663, 0.008638848550617695, 0.008476769551634789, 0.008363613858819008, 0.008235488086938858, 0.008108745329082012, 0.008025849238038063, 0.007955999113619328, 0.007881555706262589, 0.007795919664204121, 0.007746001705527306, 0.007679759990423918, 0.007604985032230616, 0.0075660767033696175, 0.007503781002014875, 0.007463212590664625, 0.0074239629320800304, 0.007371388841420412, 0.007335694041103125, 0.007284903898835182, 0.007255797274410725, 0.00720228860154748, 0.007160076405853033, 0.00714310584589839, 0.007113130763173103, 0.007082239259034395, 0.007027424406260252, 0.007003735285252333, 0.0069502550177276134, 0.006927330978214741, 0.006904700305312872, 0.006859854329377413, 0.006826520897448063, 0.006814601831138134, 0.006776621099561453, 0.006746178958564997, 0.0067094434052705765, 0.006670444738119841, 0.006641368381679058, 0.006618074141442776, 0.006597290281206369, 0.006564658135175705, 0.006525691132992506, 0.006505546160042286, 0.006485635880380869, 0.006445585750043392, 0.006409142632037401, 0.00638968963176012, 0.006361457984894514, 0.0063418056815862656, 0.006311431527137756, 0.006284091155976057, 0.006267085205763578, 0.006237765308469534, 0.006207088474184275, 0.0061901588924229145, 0.006158832460641861, 0.006133655086159706, 0.006114521995186806, 0.006086081266403198, 0.006051620468497276, 0.006036292761564255, 0.006013888865709305, 0.005988921970129013, 0.005965996067970991, 0.005941525101661682, 0.005926552694290876], 'accuracy': [0.9733297228813171, 0.9911099076271057, 0.9919180870056152, 0.9903017282485962, 0.9876077771186829, 0.9913793206214905, 0.9959590435028076, 0.9929956793785095, 0.9776400923728943, 0.9846444129943848, 0.9921875, 0.9897629022598267, 0.9881465435028076, 0.9889547228813171, 0.9929956793785095, 0.9916487336158752, 0.9927262663841248, 0.9927262663841248, 0.990571141242981, 0.985722005367279, 0.9884159564971924, 0.9894935488700867, 0.9924569129943848, 0.9929956793785095, 0.9954202771186829, 0.9940732717514038, 0.9903017282485962, 0.9835668206214905, 0.993803858757019, 0.9978448152542114, 0.9989224076271057, 0.9989224076271057, 0.9989224076271057, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.9085606932640076, 1.0267130136489868, 1.070740818977356, 1.0194898843765259, 0.972557783126831, 1.1233253479003906, 1.1210037469863892, 1.3788669109344482, 1.0385421514511108, 1.1007741689682007, 1.0391449928283691, 1.2076842784881592, 0.9396782517433167, 0.8708220720291138, 0.821512758731842, 0.684847891330719, 0.9635017514228821, 0.6289877891540527, 0.5951170921325684, 0.7831470966339111, 0.6003519296646118, 0.49368947744369507, 0.499360591173172, 0.5579550266265869, 0.4952044188976288, 0.5765634775161743, 0.6406570076942444, 0.5256215929985046, 0.5590859651565552, 0.571480393409729, 0.605134129524231, 0.6345177292823792, 0.5974236130714417, 0.5923058986663818, 0.5708503127098083, 0.5717154145240784, 0.5576157569885254, 0.5570705533027649, 0.5456092953681946, 0.5406560301780701, 0.5406582951545715, 0.5322461724281311, 0.5331143736839294, 0.5294712781906128, 0.5280538201332092, 0.5246898531913757, 0.5252729058265686, 0.5229792594909668, 0.5221942663192749, 0.5239169001579285, 0.520418643951416, 0.5184215903282166, 0.5166999697685242, 0.5185902714729309, 0.5208542346954346, 0.5168089866638184, 0.516660213470459, 0.5165324211120605, 0.5190246105194092, 0.519042432308197, 0.5309491157531738, 0.52287757396698, 0.5194754004478455, 0.5192355513572693, 0.5209221839904785, 0.5225374102592468, 0.516844630241394, 0.5183604955673218, 0.5216622352600098, 0.5248507857322693, 0.5188776254653931, 0.5210120677947998, 0.5192139148712158, 0.520499050617218, 0.5227130651473999, 0.5211671590805054, 0.5208362936973572, 0.5204998254776001, 0.5212062001228333, 0.5201455354690552, 0.5204911828041077, 0.5204586982727051, 0.5229936838150024, 0.5243909358978271, 0.5259311199188232, 0.5285677313804626, 0.5295169949531555, 0.5303839445114136, 0.5315261483192444, 0.5291951894760132, 0.5294140577316284, 0.5307417511940002, 0.5325473546981812, 0.5305674076080322, 0.5311502814292908, 0.5320038199424744, 0.5335489511489868, 0.5340306758880615, 0.5337371230125427, 0.5373194813728333], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.4903017282485962, 0.48599138855934143, 0.49353447556495667, 0.4989224076271057, 0.537715494632721, 0.5075430870056152, 0.5775862336158752, 0.6153017282485962, 0.6648706793785095, 0.7176724076271057, 0.6670258641242981, 0.764008641242981, 0.7769396305084229, 0.7349137663841248, 0.8038793206214905, 0.8243534564971924, 0.84375, 0.8318965435028076, 0.8491379022598267, 0.8426724076271057, 0.8383620977401733, 0.8383620977401733, 0.8523706793785095, 0.8879310488700867, 0.8771551847457886, 0.8868534564971924, 0.8900862336158752, 0.8868534564971924, 0.8879310488700867, 0.8879310488700867, 0.8900862336158752, 0.889008641242981, 0.889008641242981, 0.8879310488700867, 0.8868534564971924, 0.8868534564971924, 0.8846982717514038, 0.8846982717514038, 0.8836206793785095, 0.8836206793785095, 0.8879310488700867, 0.8879310488700867, 0.889008641242981, 0.889008641242981, 0.8868534564971924, 0.8879310488700867, 0.889008641242981, 0.8879310488700867, 0.8879310488700867, 0.8900862336158752, 0.889008641242981, 0.8933189511299133, 0.8900862336158752, 0.892241358757019, 0.8868534564971924, 0.8857758641242981, 0.889008641242981, 0.8911637663841248, 0.8900862336158752, 0.889008641242981, 0.8954741358757019, 0.8911637663841248, 0.8900862336158752, 0.889008641242981, 0.892241358757019, 0.8900862336158752, 0.892241358757019, 0.892241358757019, 0.8911637663841248, 0.8911637663841248, 0.8911637663841248, 0.889008641242981, 0.889008641242981, 0.8879310488700867, 0.8900862336158752, 0.889008641242981, 0.8879310488700867, 0.8879310488700867, 0.8879310488700867, 0.8879310488700867, 0.8857758641242981, 0.8879310488700867, 0.889008641242981, 0.8846982717514038, 0.8857758641242981, 0.8879310488700867, 0.8879310488700867, 0.889008641242981, 0.8836206793785095, 0.8857758641242981, 0.8846982717514038, 0.8879310488700867, 0.8857758641242981, 0.8868534564971924]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.0883 - accuracy: 0.9721"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 81ms/step - loss: 0.0880 - accuracy: 0.9723 - val_loss: 0.7809 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0348 - accuracy: 0.9912 - val_loss: 0.9538 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0184 - accuracy: 0.9977 - val_loss: 1.0860 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0258 - accuracy: 0.9926 - val_loss: 1.0988 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0380 - accuracy: 0.9898 - val_loss: 1.0685 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0546 - accuracy: 0.9819 - val_loss: 0.8628 - val_accuracy: 0.4977\n","Epoch 7/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0323 - accuracy: 0.9915 - val_loss: 1.0681 - val_accuracy: 0.4977\n","Epoch 8/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0179 - accuracy: 0.9977 - val_loss: 1.3240 - val_accuracy: 0.5011\n","Epoch 9/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0197 - accuracy: 0.9969 - val_loss: 1.4123 - val_accuracy: 0.5000\n","Epoch 10/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0320 - accuracy: 0.9909 - val_loss: 1.2559 - val_accuracy: 0.5000\n","Epoch 11/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0652 - accuracy: 0.9768 - val_loss: 0.9075 - val_accuracy: 0.5588\n","Epoch 12/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0442 - accuracy: 0.9850 - val_loss: 0.9156 - val_accuracy: 0.5611\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0260 - accuracy: 0.9946 - val_loss: 1.3491 - val_accuracy: 0.5396\n","Epoch 14/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0420 - accuracy: 0.9870 - val_loss: 1.1860 - val_accuracy: 0.5633\n","Epoch 15/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0458 - accuracy: 0.9864 - val_loss: 1.0103 - val_accuracy: 0.5962\n","Epoch 16/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0303 - accuracy: 0.9924 - val_loss: 0.7037 - val_accuracy: 0.7093\n","Epoch 17/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0322 - accuracy: 0.9921 - val_loss: 0.7317 - val_accuracy: 0.7149\n","Epoch 18/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.0260 - accuracy: 0.9926 - val_loss: 0.5800 - val_accuracy: 0.7828\n","Epoch 19/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0305 - accuracy: 0.9921 - val_loss: 0.8073 - val_accuracy: 0.7206\n","Epoch 20/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0242 - accuracy: 0.9946 - val_loss: 0.7187 - val_accuracy: 0.7443\n","Epoch 21/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0308 - accuracy: 0.9909 - val_loss: 0.6298 - val_accuracy: 0.7692\n","Epoch 22/100\n","28/28 [==============================] - 1s 39ms/step - loss: 0.0283 - accuracy: 0.9918 - val_loss: 0.7330 - val_accuracy: 0.7907\n","Epoch 23/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.0678 - accuracy: 0.9802 - val_loss: 0.5365 - val_accuracy: 0.7919\n","Epoch 24/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 0.4669 - val_accuracy: 0.8473\n","Epoch 25/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0152 - accuracy: 0.9980 - val_loss: 0.4736 - val_accuracy: 0.8643\n","Epoch 26/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0124 - accuracy: 0.9994 - val_loss: 0.4338 - val_accuracy: 0.8756\n","Epoch 27/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.4592 - val_accuracy: 0.8914\n","Epoch 28/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.4484 - val_accuracy: 0.8937\n","Epoch 29/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.4395 - val_accuracy: 0.8948\n","Epoch 30/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.8982\n","Epoch 31/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.9016\n","Epoch 32/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.4278 - val_accuracy: 0.9038\n","Epoch 33/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.9050\n","Epoch 34/100\n","28/28 [==============================] - 1s 45ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4241 - val_accuracy: 0.9061\n","Epoch 35/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4225 - val_accuracy: 0.9038\n","Epoch 36/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4215 - val_accuracy: 0.9050\n","Epoch 37/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4220 - val_accuracy: 0.9050\n","Epoch 38/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.4219 - val_accuracy: 0.9027\n","Epoch 39/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.9038\n","Epoch 40/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.8971\n","Epoch 41/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.4210 - val_accuracy: 0.8982\n","Epoch 42/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4180 - val_accuracy: 0.9038\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4154 - val_accuracy: 0.9038\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.9027\n","Epoch 45/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4156 - val_accuracy: 0.9016\n","Epoch 46/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 0.9016\n","Epoch 47/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4153 - val_accuracy: 0.9038\n","Epoch 48/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.9016\n","Epoch 49/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.9005\n","Epoch 50/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4147 - val_accuracy: 0.9005\n","Epoch 51/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4134 - val_accuracy: 0.9050\n","Epoch 52/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.9016\n","Epoch 53/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4156 - val_accuracy: 0.9050\n","Epoch 54/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.9027\n","Epoch 55/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.9027\n","Epoch 56/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4163 - val_accuracy: 0.9027\n","Epoch 57/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4169 - val_accuracy: 0.9005\n","Epoch 58/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.9061\n","Epoch 59/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4162 - val_accuracy: 0.9005\n","Epoch 60/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4154 - val_accuracy: 0.9050\n","Epoch 61/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4178 - val_accuracy: 0.9038\n","Epoch 62/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.9038\n","Epoch 63/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4186 - val_accuracy: 0.9061\n","Epoch 64/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4205 - val_accuracy: 0.9050\n","Epoch 65/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4242 - val_accuracy: 0.9027\n","Epoch 66/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4241 - val_accuracy: 0.9061\n","Epoch 67/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4248 - val_accuracy: 0.9038\n","Epoch 68/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.4253 - val_accuracy: 0.9061\n","Epoch 69/100\n","28/28 [==============================] - 2s 58ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.4257 - val_accuracy: 0.9072\n","Epoch 70/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.4265 - val_accuracy: 0.9050\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.4256 - val_accuracy: 0.9050\n","Epoch 72/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 0.9016\n","Epoch 73/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.9027\n","Epoch 74/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4337 - val_accuracy: 0.9027\n","Epoch 75/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.9027\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.9027\n","Epoch 77/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.4363 - val_accuracy: 0.9016\n","Epoch 78/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.4398 - val_accuracy: 0.8993\n","Epoch 79/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.9005\n","Epoch 80/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.4402 - val_accuracy: 0.9038\n","Epoch 81/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.4403 - val_accuracy: 0.9005\n","Epoch 82/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.9027\n","Epoch 83/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4458 - val_accuracy: 0.8993\n","Epoch 84/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4505 - val_accuracy: 0.8982\n","Epoch 85/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4448 - val_accuracy: 0.9005\n","Epoch 86/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.8993\n","Epoch 87/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4451 - val_accuracy: 0.8971\n","Epoch 88/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.8982\n","Epoch 89/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4474 - val_accuracy: 0.8993\n","Epoch 90/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4484 - val_accuracy: 0.8982\n","Epoch 91/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.8971\n","Epoch 92/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4587 - val_accuracy: 0.8982\n","Epoch 93/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4583 - val_accuracy: 0.8971\n","Epoch 94/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4611 - val_accuracy: 0.8971\n","Epoch 95/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.8971\n","Epoch 96/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.4594 - val_accuracy: 0.8982\n","Epoch 97/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.4664 - val_accuracy: 0.8971\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.4641 - val_accuracy: 0.8993\n","Epoch 99/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.4683 - val_accuracy: 0.8993\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.8959\n","{'loss': [0.08799932897090912, 0.0347871407866478, 0.01836339570581913, 0.025774171575903893, 0.03802794963121414, 0.05456273630261421, 0.032329414039850235, 0.017927715554833412, 0.019729429855942726, 0.03199494630098343, 0.06516389548778534, 0.04417567700147629, 0.02601253241300583, 0.04202479496598244, 0.045775819569826126, 0.03025943785905838, 0.032176800072193146, 0.026022927835583687, 0.030469045042991638, 0.02420591190457344, 0.030815821141004562, 0.028271907940506935, 0.06776846945285797, 0.028357641771435738, 0.01516354363411665, 0.012392272241413593, 0.009561706334352493, 0.008876455016434193, 0.008546477183699608, 0.008424285799264908, 0.008318474516272545, 0.0082359304651618, 0.008173790760338306, 0.008065922185778618, 0.008001546375453472, 0.007942792028188705, 0.00787423551082611, 0.007813038304448128, 0.007742458954453468, 0.007707413751631975, 0.007650455925613642, 0.007601930294185877, 0.0075430977158248425, 0.007520284038037062, 0.007473416160792112, 0.007415233179926872, 0.007386747747659683, 0.007349896710366011, 0.007296764757484198, 0.007263666484504938, 0.007236106786876917, 0.007179850246757269, 0.007148458622395992, 0.007111894432455301, 0.007088901475071907, 0.00704686576500535, 0.0070136901922523975, 0.006974067073315382, 0.006948478985577822, 0.006911398842930794, 0.006885318551212549, 0.00684718694537878, 0.0068120029754936695, 0.006784290540963411, 0.0067504090256989, 0.006720563396811485, 0.006689175497740507, 0.00664776423946023, 0.006624473258852959, 0.0065948194824159145, 0.006568756885826588, 0.006539463996887207, 0.00650755176320672, 0.006477442104369402, 0.006447033025324345, 0.0064178467728197575, 0.006395889911800623, 0.0063709719106554985, 0.006336791906505823, 0.006305833347141743, 0.0062801954336464405, 0.0062593077309429646, 0.0062346127815544605, 0.00620933948084712, 0.006175300106406212, 0.006156053859740496, 0.006135615520179272, 0.006110686808824539, 0.006086326204240322, 0.006057949271053076, 0.006036000791937113, 0.0060069747269153595, 0.005986098200082779, 0.005967829376459122, 0.005939657799899578, 0.005921451840549707, 0.0058954209089279175, 0.005878672935068607, 0.005851550959050655, 0.0058400388807058334], 'accuracy': [0.9722693562507629, 0.9912280440330505, 0.9977362751960754, 0.992642879486084, 0.9898132681846619, 0.9818902015686035, 0.9915110468864441, 0.9977362751960754, 0.9968873858451843, 0.9909451007843018, 0.9767968058586121, 0.9850028157234192, 0.9946236610412598, 0.986983597278595, 0.9864176511764526, 0.9923599362373352, 0.9920769929885864, 0.992642879486084, 0.9920769929885864, 0.9946236610412598, 0.9909451007843018, 0.9917939901351929, 0.9801924228668213, 0.9912280440330505, 0.9980192184448242, 0.9994340538978577, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.7809274196624756, 0.9538020491600037, 1.086049199104309, 1.0987873077392578, 1.0684854984283447, 0.8628138899803162, 1.0680632591247559, 1.3240249156951904, 1.4122837781906128, 1.255854845046997, 0.9075023531913757, 0.9156147241592407, 1.3491281270980835, 1.1860305070877075, 1.0102927684783936, 0.7037023305892944, 0.7316838502883911, 0.5800395011901855, 0.807297945022583, 0.7186802625656128, 0.6298439502716064, 0.7330352663993835, 0.5365284085273743, 0.4669296145439148, 0.47363266348838806, 0.4338088929653168, 0.4591658115386963, 0.44838425517082214, 0.4395253360271454, 0.4333038926124573, 0.43046197295188904, 0.4277816712856293, 0.42536431550979614, 0.42405638098716736, 0.4225049614906311, 0.4215306341648102, 0.4220287501811981, 0.4218663275241852, 0.42085444927215576, 0.4217297434806824, 0.42097169160842896, 0.41803672909736633, 0.4153655767440796, 0.41668665409088135, 0.415607213973999, 0.415021151304245, 0.4153420031070709, 0.4143986701965332, 0.4151279628276825, 0.4147472381591797, 0.41341787576675415, 0.41592147946357727, 0.41555672883987427, 0.41669419407844543, 0.41510602831840515, 0.4162815809249878, 0.4168902635574341, 0.41593968868255615, 0.416155606508255, 0.4153668284416199, 0.41782766580581665, 0.4185246229171753, 0.41864708065986633, 0.42050299048423767, 0.4242446720600128, 0.4241422414779663, 0.4248308539390564, 0.4253162741661072, 0.42570099234580994, 0.42645615339279175, 0.42563897371292114, 0.42877131700515747, 0.43499886989593506, 0.4337005317211151, 0.43413177132606506, 0.4353225827217102, 0.4362551271915436, 0.4397766888141632, 0.43900981545448303, 0.4401800334453583, 0.4403444230556488, 0.4419187605381012, 0.44584953784942627, 0.45046016573905945, 0.44476988911628723, 0.4430570602416992, 0.44512465596199036, 0.446817010641098, 0.4474402070045471, 0.44842293858528137, 0.45237451791763306, 0.45866015553474426, 0.4583035707473755, 0.46111321449279785, 0.45484089851379395, 0.45942243933677673, 0.4663848876953125, 0.46413707733154297, 0.46832388639450073, 0.46598923206329346], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4977375566959381, 0.4977375566959381, 0.5011312365531921, 0.5, 0.5, 0.5588235259056091, 0.5610859990119934, 0.5395927429199219, 0.5633484125137329, 0.5961538553237915, 0.709276020526886, 0.7149321436882019, 0.7828054428100586, 0.720588207244873, 0.7443438768386841, 0.7692307829856873, 0.790723979473114, 0.7918552160263062, 0.8472850918769836, 0.8642534017562866, 0.8755655884742737, 0.8914027214050293, 0.8936651349067688, 0.8947963714599609, 0.8981900215148926, 0.901583731174469, 0.9038461446762085, 0.9049773812294006, 0.9061086177825928, 0.9038461446762085, 0.9049773812294006, 0.9049773812294006, 0.9027149081230164, 0.9038461446762085, 0.8970588445663452, 0.8981900215148926, 0.9038461446762085, 0.9038461446762085, 0.9027149081230164, 0.901583731174469, 0.901583731174469, 0.9038461446762085, 0.901583731174469, 0.9004524946212769, 0.9004524946212769, 0.9049773812294006, 0.901583731174469, 0.9049773812294006, 0.9027149081230164, 0.9027149081230164, 0.9027149081230164, 0.9004524946212769, 0.9061086177825928, 0.9004524946212769, 0.9049773812294006, 0.9038461446762085, 0.9038461446762085, 0.9061086177825928, 0.9049773812294006, 0.9027149081230164, 0.9061086177825928, 0.9038461446762085, 0.9061086177825928, 0.9072397947311401, 0.9049773812294006, 0.9049773812294006, 0.901583731174469, 0.9027149081230164, 0.9027149081230164, 0.9027149081230164, 0.9027149081230164, 0.901583731174469, 0.8993212580680847, 0.9004524946212769, 0.9038461446762085, 0.9004524946212769, 0.9027149081230164, 0.8993212580680847, 0.8981900215148926, 0.9004524946212769, 0.8993212580680847, 0.8970588445663452, 0.8981900215148926, 0.8993212580680847, 0.8981900215148926, 0.8970588445663452, 0.8981900215148926, 0.8970588445663452, 0.8970588445663452, 0.8970588445663452, 0.8981900215148926, 0.8970588445663452, 0.8993212580680847, 0.8993212580680847, 0.8959276080131531]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.0684 - accuracy: 0.9782"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 9s 62ms/step - loss: 0.0688 - accuracy: 0.9778 - val_loss: 0.8348 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 1.0980 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0374 - accuracy: 0.9886 - val_loss: 1.1452 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0381 - accuracy: 0.9897 - val_loss: 1.2476 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0517 - accuracy: 0.9837 - val_loss: 1.0432 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0404 - accuracy: 0.9897 - val_loss: 1.2665 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0226 - accuracy: 0.9946 - val_loss: 1.5002 - val_accuracy: 0.4866\n","Epoch 8/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0444 - accuracy: 0.9853 - val_loss: 1.2061 - val_accuracy: 0.4907\n","Epoch 9/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0669 - accuracy: 0.9796 - val_loss: 1.1312 - val_accuracy: 0.4917\n","Epoch 10/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0369 - accuracy: 0.9912 - val_loss: 1.2651 - val_accuracy: 0.5010\n","Epoch 11/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0658 - accuracy: 0.9773 - val_loss: 1.2331 - val_accuracy: 0.5041\n","Epoch 12/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0366 - accuracy: 0.9889 - val_loss: 1.1932 - val_accuracy: 0.5331\n","Epoch 13/100\n","31/31 [==============================] - 1s 37ms/step - loss: 0.0384 - accuracy: 0.9907 - val_loss: 0.9600 - val_accuracy: 0.5981\n","Epoch 14/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.0282 - accuracy: 0.9935 - val_loss: 0.9971 - val_accuracy: 0.6281\n","Epoch 15/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0145 - accuracy: 0.9987 - val_loss: 1.3448 - val_accuracy: 0.6116\n","Epoch 16/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0133 - accuracy: 0.9987 - val_loss: 1.5914 - val_accuracy: 0.5940\n","Epoch 17/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0164 - accuracy: 0.9972 - val_loss: 1.3358 - val_accuracy: 0.6446\n","Epoch 18/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0402 - accuracy: 0.9873 - val_loss: 0.9267 - val_accuracy: 0.6777\n","Epoch 19/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0352 - accuracy: 0.9904 - val_loss: 0.8983 - val_accuracy: 0.7118\n","Epoch 20/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0713 - accuracy: 0.9788 - val_loss: 0.6098 - val_accuracy: 0.7727\n","Epoch 21/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0296 - accuracy: 0.9938 - val_loss: 0.5974 - val_accuracy: 0.8182\n","Epoch 22/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0177 - accuracy: 0.9974 - val_loss: 0.6046 - val_accuracy: 0.8450\n","Epoch 23/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0397 - accuracy: 0.9891 - val_loss: 0.6669 - val_accuracy: 0.8275\n","Epoch 24/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0566 - accuracy: 0.9817 - val_loss: 0.5293 - val_accuracy: 0.8275\n","Epoch 25/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0866 - accuracy: 0.9700 - val_loss: 0.5656 - val_accuracy: 0.7934\n","Epoch 26/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0386 - accuracy: 0.9884 - val_loss: 0.5420 - val_accuracy: 0.8523\n","Epoch 27/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0230 - accuracy: 0.9959 - val_loss: 0.7407 - val_accuracy: 0.8254\n","Epoch 28/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0413 - accuracy: 0.9871 - val_loss: 0.7481 - val_accuracy: 0.8037\n","Epoch 29/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0433 - accuracy: 0.9873 - val_loss: 0.5506 - val_accuracy: 0.8533\n","Epoch 30/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0195 - accuracy: 0.9974 - val_loss: 0.6441 - val_accuracy: 0.8378\n","Epoch 31/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.0134 - accuracy: 0.9984 - val_loss: 0.6457 - val_accuracy: 0.8605\n","Epoch 32/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.6612 - val_accuracy: 0.8595\n","Epoch 33/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.6612 - val_accuracy: 0.8595\n","Epoch 34/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.6625 - val_accuracy: 0.8605\n","Epoch 35/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.6552 - val_accuracy: 0.8616\n","Epoch 36/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.6493 - val_accuracy: 0.8636\n","Epoch 37/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.6422 - val_accuracy: 0.8616\n","Epoch 38/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.6388 - val_accuracy: 0.8626\n","Epoch 39/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.6366 - val_accuracy: 0.8636\n","Epoch 40/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.6340 - val_accuracy: 0.8636\n","Epoch 41/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.6313 - val_accuracy: 0.8626\n","Epoch 42/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.6306 - val_accuracy: 0.8626\n","Epoch 43/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.6294 - val_accuracy: 0.8626\n","Epoch 44/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.6259 - val_accuracy: 0.8605\n","Epoch 45/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.6214 - val_accuracy: 0.8626\n","Epoch 46/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.6193 - val_accuracy: 0.8616\n","Epoch 47/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6191 - val_accuracy: 0.8605\n","Epoch 48/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6196 - val_accuracy: 0.8585\n","Epoch 49/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.6178 - val_accuracy: 0.8595\n","Epoch 50/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.6190 - val_accuracy: 0.8585\n","Epoch 51/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.6216 - val_accuracy: 0.8616\n","Epoch 52/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.6240 - val_accuracy: 0.8605\n","Epoch 53/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.6223 - val_accuracy: 0.8595\n","Epoch 54/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.6210 - val_accuracy: 0.8564\n","Epoch 55/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.6221 - val_accuracy: 0.8554\n","Epoch 56/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.6205 - val_accuracy: 0.8605\n","Epoch 57/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.6214 - val_accuracy: 0.8574\n","Epoch 58/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.6218 - val_accuracy: 0.8605\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.6264 - val_accuracy: 0.8574\n","Epoch 60/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.6265 - val_accuracy: 0.8574\n","Epoch 61/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.6264 - val_accuracy: 0.8564\n","Epoch 62/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.6274 - val_accuracy: 0.8543\n","Epoch 63/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.6281 - val_accuracy: 0.8554\n","Epoch 64/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.6300 - val_accuracy: 0.8533\n","Epoch 65/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.6285 - val_accuracy: 0.8574\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.6285 - val_accuracy: 0.8574\n","Epoch 67/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.6293 - val_accuracy: 0.8605\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.6337 - val_accuracy: 0.8574\n","Epoch 69/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.6341 - val_accuracy: 0.8595\n","Epoch 70/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.6350 - val_accuracy: 0.8585\n","Epoch 71/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.6363 - val_accuracy: 0.8605\n","Epoch 72/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.6350 - val_accuracy: 0.8636\n","Epoch 73/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.6354 - val_accuracy: 0.8616\n","Epoch 74/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.6410 - val_accuracy: 0.8554\n","Epoch 75/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.6456 - val_accuracy: 0.8585\n","Epoch 76/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.6458 - val_accuracy: 0.8585\n","Epoch 77/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.6454 - val_accuracy: 0.8585\n","Epoch 78/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.6477 - val_accuracy: 0.8574\n","Epoch 79/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.6504 - val_accuracy: 0.8585\n","Epoch 80/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.6562 - val_accuracy: 0.8595\n","Epoch 81/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.6563 - val_accuracy: 0.8605\n","Epoch 82/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.6567 - val_accuracy: 0.8585\n","Epoch 83/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.6590 - val_accuracy: 0.8605\n","Epoch 84/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.6632 - val_accuracy: 0.8616\n","Epoch 85/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.6617 - val_accuracy: 0.8605\n","Epoch 86/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.6608 - val_accuracy: 0.8605\n","Epoch 87/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.6601 - val_accuracy: 0.8616\n","Epoch 88/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.6625 - val_accuracy: 0.8605\n","Epoch 89/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.6648 - val_accuracy: 0.8605\n","Epoch 90/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.6660 - val_accuracy: 0.8605\n","Epoch 91/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.6663 - val_accuracy: 0.8574\n","Epoch 92/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6700 - val_accuracy: 0.8585\n","Epoch 93/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6703 - val_accuracy: 0.8574\n","Epoch 94/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6745 - val_accuracy: 0.8605\n","Epoch 95/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6728 - val_accuracy: 0.8616\n","Epoch 96/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6749 - val_accuracy: 0.8543\n","Epoch 97/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.6757 - val_accuracy: 0.8605\n","Epoch 98/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.6784 - val_accuracy: 0.8585\n","Epoch 99/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 0.8471\n","Epoch 100/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.8585\n","{'loss': [0.06882190704345703, 0.043872229754924774, 0.037380993366241455, 0.03813442215323448, 0.05167863517999649, 0.04039181396365166, 0.022575637325644493, 0.04443836212158203, 0.06687776744365692, 0.03692645579576492, 0.0658457800745964, 0.036623015999794006, 0.03837957605719566, 0.028203871101140976, 0.014539272524416447, 0.013348007574677467, 0.016404420137405396, 0.04017170891165733, 0.03520495072007179, 0.07134699821472168, 0.029586387798190117, 0.017682505771517754, 0.03971688449382782, 0.05659956485033035, 0.0865638330578804, 0.03857789561152458, 0.02304181084036827, 0.041284799575805664, 0.04327937960624695, 0.01945536583662033, 0.013354698196053505, 0.009423455223441124, 0.008811820298433304, 0.008607505820691586, 0.008475610986351967, 0.008343592286109924, 0.008263778872787952, 0.008172569796442986, 0.008077183738350868, 0.00799266342073679, 0.00792829878628254, 0.007848892360925674, 0.0077703301794826984, 0.007708126679062843, 0.007648005615919828, 0.007600037846714258, 0.007537369150668383, 0.007477999664843082, 0.007434431929141283, 0.007395083550363779, 0.007355005946010351, 0.007294111419469118, 0.007253602612763643, 0.007222471758723259, 0.007178780157119036, 0.0071280356496572495, 0.007084399461746216, 0.007049710489809513, 0.007006263360381126, 0.006980028003454208, 0.006933513563126326, 0.006898294668644667, 0.006866799667477608, 0.006837441585958004, 0.006796413101255894, 0.006774998735636473, 0.006734138820320368, 0.006702766288071871, 0.00667838379740715, 0.006637140642851591, 0.006615859922021627, 0.006578928790986538, 0.006549989804625511, 0.006526127923280001, 0.006486453581601381, 0.0064514391124248505, 0.006426949519664049, 0.006399818230420351, 0.00636450806632638, 0.006339984480291605, 0.006312279496341944, 0.006304676178842783, 0.006280534900724888, 0.006245479453355074, 0.006217547692358494, 0.006191010121256113, 0.00615813909098506, 0.006142310332506895, 0.006109674461185932, 0.006088234484195709, 0.006066880188882351, 0.006041168700903654, 0.006018226034939289, 0.005996412597596645, 0.005970085971057415, 0.0059530832804739475, 0.00593241723254323, 0.005905195605009794, 0.005917082075029612, 0.005890787113457918], 'accuracy': [0.9777777791023254, 0.9865633249282837, 0.988630473613739, 0.9896640777587891, 0.9837209582328796, 0.9896640777587891, 0.9945736527442932, 0.9852713346481323, 0.9795865416526794, 0.9912144541740417, 0.9772610068321228, 0.9888888597488403, 0.9906976819038391, 0.9935400485992432, 0.9987080097198486, 0.9987080097198486, 0.997157633304596, 0.9873384833335876, 0.9904392957687378, 0.9788113832473755, 0.9937984347343445, 0.9974160194396973, 0.9891473054885864, 0.9816537499427795, 0.9700258374214172, 0.9883720874786377, 0.9958656430244446, 0.9870800971984863, 0.9873384833335876, 0.9974160194396973, 0.9984496235847473, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.8347735404968262, 1.0980240106582642, 1.1452230215072632, 1.24760901927948, 1.0432082414627075, 1.2665494680404663, 1.500232458114624, 1.206056833267212, 1.1311702728271484, 1.2651110887527466, 1.2331280708312988, 1.1931681632995605, 0.960039496421814, 0.9971022605895996, 1.3447649478912354, 1.5913915634155273, 1.3358051776885986, 0.9266791343688965, 0.8982793688774109, 0.6098304986953735, 0.5973739624023438, 0.6045580506324768, 0.6668606400489807, 0.529349148273468, 0.5656173825263977, 0.541972815990448, 0.7406923770904541, 0.7480796575546265, 0.5505582094192505, 0.6440722942352295, 0.6457295417785645, 0.661243200302124, 0.6612302660942078, 0.6625008583068848, 0.6552287936210632, 0.6493483185768127, 0.6421828269958496, 0.6388311386108398, 0.636622965335846, 0.6340030431747437, 0.6312777996063232, 0.6306293606758118, 0.6294208765029907, 0.6258525848388672, 0.621448278427124, 0.6192728281021118, 0.6191451549530029, 0.6195862293243408, 0.6178465485572815, 0.6189565658569336, 0.6215500235557556, 0.6240312457084656, 0.622323215007782, 0.6210119128227234, 0.6221072673797607, 0.6204844117164612, 0.6214378476142883, 0.6217941641807556, 0.6264221668243408, 0.6265174746513367, 0.6263625621795654, 0.6274064779281616, 0.62813800573349, 0.6299591064453125, 0.6285462379455566, 0.6285040974617004, 0.6293383240699768, 0.6337160468101501, 0.6340707540512085, 0.6350205540657043, 0.636252760887146, 0.6349600553512573, 0.6354243755340576, 0.6410248875617981, 0.6455638408660889, 0.6458390951156616, 0.6454196572303772, 0.6477123498916626, 0.6504265666007996, 0.6562031507492065, 0.6563418507575989, 0.6566689014434814, 0.6590167880058289, 0.6632418632507324, 0.6616674661636353, 0.6607897877693176, 0.660068929195404, 0.6625102758407593, 0.664802610874176, 0.6660090088844299, 0.6662836074829102, 0.6700010895729065, 0.670254647731781, 0.6744571328163147, 0.6727865934371948, 0.6749339699745178, 0.6756598353385925, 0.6783734560012817, 0.6920081377029419, 0.682239294052124], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.49070248007774353, 0.4917355477809906, 0.5010330677032471, 0.5041322112083435, 0.5330578684806824, 0.5981404781341553, 0.6280992031097412, 0.6115702390670776, 0.5940082669258118, 0.64462810754776, 0.6776859760284424, 0.711776852607727, 0.7727272510528564, 0.8181818127632141, 0.8450413346290588, 0.827479362487793, 0.827479362487793, 0.7933884263038635, 0.8522727489471436, 0.8254132270812988, 0.8037189841270447, 0.8533057570457458, 0.8378099203109741, 0.8605371713638306, 0.8595041036605835, 0.8595041036605835, 0.8605371713638306, 0.8615702390670776, 0.8636363744735718, 0.8615702390670776, 0.8626033067703247, 0.8636363744735718, 0.8636363744735718, 0.8626033067703247, 0.8626033067703247, 0.8626033067703247, 0.8605371713638306, 0.8626033067703247, 0.8615702390670776, 0.8605371713638306, 0.8584710955619812, 0.8595041036605835, 0.8584710955619812, 0.8615702390670776, 0.8605371713638306, 0.8595041036605835, 0.8564049601554871, 0.85537189245224, 0.8605371713638306, 0.8574380278587341, 0.8605371713638306, 0.8574380278587341, 0.8574380278587341, 0.8564049601554871, 0.8543388247489929, 0.85537189245224, 0.8533057570457458, 0.8574380278587341, 0.8574380278587341, 0.8605371713638306, 0.8574380278587341, 0.8595041036605835, 0.8584710955619812, 0.8605371713638306, 0.8636363744735718, 0.8615702390670776, 0.85537189245224, 0.8584710955619812, 0.8584710955619812, 0.8584710955619812, 0.8574380278587341, 0.8584710955619812, 0.8595041036605835, 0.8605371713638306, 0.8584710955619812, 0.8605371713638306, 0.8615702390670776, 0.8605371713638306, 0.8605371713638306, 0.8615702390670776, 0.8605371713638306, 0.8605371713638306, 0.8605371713638306, 0.8574380278587341, 0.8584710955619812, 0.8574380278587341, 0.8605371713638306, 0.8615702390670776, 0.8543388247489929, 0.8605371713638306, 0.8584710955619812, 0.8471074104309082, 0.8584710955619812]}\n","32/32 [==============================] - 1s 6ms/step\n"]}]},{"cell_type":"code","source":["\n","metrics_df.round(3)"],"metadata":{"id":"Ik5JoVP2NPvY","colab":{"base_uri":"https://localhost:8080/","height":519},"executionInfo":{"status":"ok","timestamp":1717529153018,"user_tz":-360,"elapsed":11,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}},"outputId":"afb8beec-5e7f-4f4a-b1de-e009098dcb6f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.636      0.628   0.665  0.646        0.665        0.606   \n","1        1     0.660      0.670   0.631  0.650        0.631        0.689   \n","2        2     0.645      0.647   0.637  0.642        0.637        0.653   \n","3        0     0.666      0.658   0.692  0.674        0.692        0.640   \n","4        1     0.643      0.637   0.662  0.650        0.662        0.623   \n","5        2     0.659      0.686   0.584  0.631        0.584        0.733   \n","6        0     0.765      0.755   0.786  0.770        0.786        0.745   \n","7        1     0.756      0.746   0.777  0.761        0.777        0.736   \n","8        2     0.755      0.740   0.787  0.763        0.787        0.723   \n","9        0     0.808      0.788   0.844  0.815        0.844        0.772   \n","10       1     0.817      0.799   0.847  0.822        0.847        0.787   \n","11       2     0.820      0.787   0.878  0.830        0.878        0.763   \n","12       0     0.853      0.848   0.861  0.855        0.861        0.846   \n","13       1     0.871      0.858   0.890  0.874        0.890        0.853   \n","14       2     0.837      0.809   0.884  0.845        0.884        0.791   \n","\n","    Kappa  \n","0   0.271  \n","1   0.321  \n","2   0.289  \n","3   0.332  \n","4   0.285  \n","5   0.317  \n","6   0.531  \n","7   0.513  \n","8   0.510  \n","9   0.616  \n","10  0.634  \n","11  0.641  \n","12  0.707  \n","13  0.743  \n","14  0.675  "],"text/html":["\n","  <div id=\"df-0a2e3a58-8f12-4a81-8d18-d0baa6b278f1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.636</td>\n","      <td>0.628</td>\n","      <td>0.665</td>\n","      <td>0.646</td>\n","      <td>0.665</td>\n","      <td>0.606</td>\n","      <td>0.271</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.660</td>\n","      <td>0.670</td>\n","      <td>0.631</td>\n","      <td>0.650</td>\n","      <td>0.631</td>\n","      <td>0.689</td>\n","      <td>0.321</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.645</td>\n","      <td>0.647</td>\n","      <td>0.637</td>\n","      <td>0.642</td>\n","      <td>0.637</td>\n","      <td>0.653</td>\n","      <td>0.289</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.666</td>\n","      <td>0.658</td>\n","      <td>0.692</td>\n","      <td>0.674</td>\n","      <td>0.692</td>\n","      <td>0.640</td>\n","      <td>0.332</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.643</td>\n","      <td>0.637</td>\n","      <td>0.662</td>\n","      <td>0.650</td>\n","      <td>0.662</td>\n","      <td>0.623</td>\n","      <td>0.285</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.659</td>\n","      <td>0.686</td>\n","      <td>0.584</td>\n","      <td>0.631</td>\n","      <td>0.584</td>\n","      <td>0.733</td>\n","      <td>0.317</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.765</td>\n","      <td>0.755</td>\n","      <td>0.786</td>\n","      <td>0.770</td>\n","      <td>0.786</td>\n","      <td>0.745</td>\n","      <td>0.531</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.756</td>\n","      <td>0.746</td>\n","      <td>0.777</td>\n","      <td>0.761</td>\n","      <td>0.777</td>\n","      <td>0.736</td>\n","      <td>0.513</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.755</td>\n","      <td>0.740</td>\n","      <td>0.787</td>\n","      <td>0.763</td>\n","      <td>0.787</td>\n","      <td>0.723</td>\n","      <td>0.510</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.808</td>\n","      <td>0.788</td>\n","      <td>0.844</td>\n","      <td>0.815</td>\n","      <td>0.844</td>\n","      <td>0.772</td>\n","      <td>0.616</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.817</td>\n","      <td>0.799</td>\n","      <td>0.847</td>\n","      <td>0.822</td>\n","      <td>0.847</td>\n","      <td>0.787</td>\n","      <td>0.634</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.820</td>\n","      <td>0.787</td>\n","      <td>0.878</td>\n","      <td>0.830</td>\n","      <td>0.878</td>\n","      <td>0.763</td>\n","      <td>0.641</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.853</td>\n","      <td>0.848</td>\n","      <td>0.861</td>\n","      <td>0.855</td>\n","      <td>0.861</td>\n","      <td>0.846</td>\n","      <td>0.707</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.871</td>\n","      <td>0.858</td>\n","      <td>0.890</td>\n","      <td>0.874</td>\n","      <td>0.890</td>\n","      <td>0.853</td>\n","      <td>0.743</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.837</td>\n","      <td>0.809</td>\n","      <td>0.884</td>\n","      <td>0.845</td>\n","      <td>0.884</td>\n","      <td>0.791</td>\n","      <td>0.675</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a2e3a58-8f12-4a81-8d18-d0baa6b278f1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0a2e3a58-8f12-4a81-8d18-d0baa6b278f1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0a2e3a58-8f12-4a81-8d18-d0baa6b278f1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-fb079b8b-70fd-4886-8b6b-798bf9e3f82c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb079b8b-70fd-4886-8b6b-798bf9e3f82c')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-fb079b8b-70fd-4886-8b6b-798bf9e3f82c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08640971065359548,\n        \"min\": 0.636,\n        \"max\": 0.871,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.808,\n          0.82,\n          0.636\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.077835418550634,\n        \"min\": 0.628,\n        \"max\": 0.858,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.788,\n          0.787,\n          0.628\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10646170784885634,\n        \"min\": 0.584,\n        \"max\": 0.89,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.844,\n          0.878,\n          0.665\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09036028415394093,\n        \"min\": 0.631,\n        \"max\": 0.874,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.822,\n          0.855,\n          0.646\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10646170784885634,\n        \"min\": 0.584,\n        \"max\": 0.89,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.844,\n          0.878,\n          0.665\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07618367529170787,\n        \"min\": 0.606,\n        \"max\": 0.853,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.772,\n          0.763,\n          0.606\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17343284689167845,\n        \"min\": 0.271,\n        \"max\": 0.743,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.616,\n          0.641,\n          0.271\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["metrics_df.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/DWT/CNN_LSTM/Beta_DWT_CNN_LSTM.csv', index = False)"],"metadata":{"id":"Ncf_cMAQF6g4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CNN-LSTM Graph"],"metadata":{"id":"ZUR_QwblhNjJ"}},{"cell_type":"code","source":["import wandb\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import re\n","import seaborn as sns\n","\n","# Initialize the API\n","api = wandb.Api()\n","\n","# Specify the entity and project\n","entity = \"raihanrabby\"\n","project = \"Beta_time_domain_CNN_Lstm\"\n","\n","# Fetch all runs from the project\n","runs = api.runs(f\"{entity}/{project}\")\n","\n","# List to store the dataframes\n","dataframes = []\n","\n","# Iterate over each run and fetch the history\n","for run in runs:\n","    # Fetch the history for each run\n","    history = run.history()\n","\n","    # Add columns to identify the run, model name, epoch, and client\n","    history['run_id'] = run.id\n","    history['model_name'] = run.name\n","\n","    # Extract epoch and client from model name\n","    match = re.match(r'epoch_(\\d+)_client_(\\d+)', run.name)\n","    if match:\n","        history['epoch_number'] = int(match.group(1))\n","        history['client_number'] = int(match.group(2))\n","    else:\n","        history['epoch_number'] = None\n","        history['client_number'] = None\n","\n","    # Append to the list of dataframes\n","    dataframes.append(history)\n","\n","# Concatenate all dataframes into a single dataframe\n","all_metrics_df = pd.concat(dataframes)\n","\n","# Filter out rows with None epoch_number\n","all_metrics_df = all_metrics_df.dropna(subset=['epoch_number'])\n","\n","# Get the unique epochs\n","unique_epochs = sorted(all_metrics_df['epoch_number'].unique())\n","\n","# Set the Seaborn style\n","sns.set(style=\"whitegrid\")\n","\n","# Create subplots for each epoch\n","fig, axes = plt.subplots(2, len(unique_epochs), figsize=(len(unique_epochs) * 3, 4.5), sharex=True)\n","\n","# Set the color palette\n","palette = sns.color_palette(\"Set1\", n_colors=all_metrics_df['client_number'].nunique())\n","\n","# Store the lines and labels for the legend\n","lines = []\n","labels = []\n","\n","# Iterate through each epoch and plot the training and validation accuracy\n","for i, epoch in enumerate(unique_epochs):\n","    epoch_df = all_metrics_df[all_metrics_df['epoch_number'] == epoch]\n","    for j, client in enumerate(epoch_df['client_number'].unique()):\n","        client_df = epoch_df[epoch_df['client_number'] == client]\n","        line, = axes[0, i].plot(client_df['accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","        axes[1, i].plot(client_df['val_accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","\n","        if i == 0:\n","            lines.append(line)\n","            labels.append(f'Client {client}')\n","\n","    axes[0, i].set_title(f'Epoch {epoch}', fontsize=12, fontweight='bold')\n","    axes[0, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","    axes[1, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","    # axes[0, i].set_ylim(0.5)  # Ensure y-axis covers full range of accuracy\n","    axes[1, i].set_ylim(0.5, 1.0)  # Ensure y-axis covers full range of accuracy\n","    axes[1, i].set_xlabel('Steps', fontsize=10, fontweight='bold')\n","    axes[0, i].grid(True)\n","    axes[1, i].grid(True)\n","    axes[0, i].tick_params(axis='both', which='major', labelsize=10)\n","    axes[1, i].tick_params(axis='both', which='major', labelsize=10)\n","\n","# Add a single legend for the entire figure\n","fig.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 1.0), ncol=len(labels), fontsize=10, frameon=True)\n","\n","# Add row labels\n","fig.text(0.04, 0.75, 'Training Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","fig.text(0.04, 0.25, 'Validation Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","\n","plt.tight_layout(rect=[0.05, 0, 1, 0.95])\n","plt.subplots_adjust(hspace=0.2, top=0.88)  # Add some space between the rows and reduce space between the legend and plot\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":462},"id":"zdihdEQAk8x9","executionInfo":{"status":"ok","timestamp":1716740043376,"user_tz":-360,"elapsed":15427,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"6f210444-99b7-4a2d-e54d-c63ffe64373a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x450 with 10 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"F0IzJ6S5k8vk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_metrics_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"dF-KSdKdhsqv","executionInfo":{"status":"ok","timestamp":1716636800286,"user_tz":-360,"elapsed":373,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"468ed3c0-e85c-4f92-da49-0afecd4c142c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      _runtime  accuracy  val_loss    _timestamp  val_accuracy      loss  \\\n","0    13.310213  0.894723  0.860759  1.716588e+09      0.504283  0.247455   \n","1    22.364346  0.917493  0.848398  1.716588e+09      0.504283  0.195490   \n","2    33.860330  0.914814  0.825522  1.716588e+09      0.504283  0.204736   \n","3    43.363837  0.909992  0.825889  1.716588e+09      0.504283  0.208303   \n","4    44.307076  0.922047  0.801610  1.716588e+09      0.504283  0.188477   \n","..         ...       ...       ...           ...           ...       ...   \n","95  416.614793  0.788910  0.553507  1.716585e+09      0.730193  0.455315   \n","96  417.041695  0.782213  0.548009  1.716585e+09      0.732334  0.458011   \n","97  417.444440  0.778998  0.550679  1.716585e+09      0.729122  0.459626   \n","98  417.884801  0.792660  0.559028  1.716585e+09      0.722698  0.451855   \n","99  418.304440  0.782748  0.551085  1.716585e+09      0.729122  0.454946   \n","\n","    _step  epoch    run_id  \n","0       0      0  2nsbmzjb  \n","1       1      1  2nsbmzjb  \n","2       2      2  2nsbmzjb  \n","3       3      3  2nsbmzjb  \n","4       4      4  2nsbmzjb  \n","..    ...    ...       ...  \n","95     95     95  u6ki5wej  \n","96     96     96  u6ki5wej  \n","97     97     97  u6ki5wej  \n","98     98     98  u6ki5wej  \n","99     99     99  u6ki5wej  \n","\n","[1500 rows x 9 columns]"],"text/html":["\n","  <div id=\"df-c54c6cd2-19dd-4a84-90fb-57f868070b89\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>_runtime</th>\n","      <th>accuracy</th>\n","      <th>val_loss</th>\n","      <th>_timestamp</th>\n","      <th>val_accuracy</th>\n","      <th>loss</th>\n","      <th>_step</th>\n","      <th>epoch</th>\n","      <th>run_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>13.310213</td>\n","      <td>0.894723</td>\n","      <td>0.860759</td>\n","      <td>1.716588e+09</td>\n","      <td>0.504283</td>\n","      <td>0.247455</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2nsbmzjb</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>22.364346</td>\n","      <td>0.917493</td>\n","      <td>0.848398</td>\n","      <td>1.716588e+09</td>\n","      <td>0.504283</td>\n","      <td>0.195490</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2nsbmzjb</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>33.860330</td>\n","      <td>0.914814</td>\n","      <td>0.825522</td>\n","      <td>1.716588e+09</td>\n","      <td>0.504283</td>\n","      <td>0.204736</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2nsbmzjb</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>43.363837</td>\n","      <td>0.909992</td>\n","      <td>0.825889</td>\n","      <td>1.716588e+09</td>\n","      <td>0.504283</td>\n","      <td>0.208303</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2nsbmzjb</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>44.307076</td>\n","      <td>0.922047</td>\n","      <td>0.801610</td>\n","      <td>1.716588e+09</td>\n","      <td>0.504283</td>\n","      <td>0.188477</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>2nsbmzjb</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>416.614793</td>\n","      <td>0.788910</td>\n","      <td>0.553507</td>\n","      <td>1.716585e+09</td>\n","      <td>0.730193</td>\n","      <td>0.455315</td>\n","      <td>95</td>\n","      <td>95</td>\n","      <td>u6ki5wej</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>417.041695</td>\n","      <td>0.782213</td>\n","      <td>0.548009</td>\n","      <td>1.716585e+09</td>\n","      <td>0.732334</td>\n","      <td>0.458011</td>\n","      <td>96</td>\n","      <td>96</td>\n","      <td>u6ki5wej</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>417.444440</td>\n","      <td>0.778998</td>\n","      <td>0.550679</td>\n","      <td>1.716585e+09</td>\n","      <td>0.729122</td>\n","      <td>0.459626</td>\n","      <td>97</td>\n","      <td>97</td>\n","      <td>u6ki5wej</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>417.884801</td>\n","      <td>0.792660</td>\n","      <td>0.559028</td>\n","      <td>1.716585e+09</td>\n","      <td>0.722698</td>\n","      <td>0.451855</td>\n","      <td>98</td>\n","      <td>98</td>\n","      <td>u6ki5wej</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>418.304440</td>\n","      <td>0.782748</td>\n","      <td>0.551085</td>\n","      <td>1.716585e+09</td>\n","      <td>0.729122</td>\n","      <td>0.454946</td>\n","      <td>99</td>\n","      <td>99</td>\n","      <td>u6ki5wej</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1500 rows  9 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c54c6cd2-19dd-4a84-90fb-57f868070b89')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c54c6cd2-19dd-4a84-90fb-57f868070b89 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c54c6cd2-19dd-4a84-90fb-57f868070b89');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d2db8c50-ed3f-4d64-8b19-fc6d9c84f4c6\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2db8c50-ed3f-4d64-8b19-fc6d9c84f4c6')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d2db8c50-ed3f-4d64-8b19-fc6d9c84f4c6 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_af67ca15-c1be-45e1-84f8-5c85a974368d\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('all_metrics_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_af67ca15-c1be-45e1-84f8-5c85a974368d button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('all_metrics_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"all_metrics_df","summary":"{\n  \"name\": \"all_metrics_df\",\n  \"rows\": 1500,\n  \"fields\": [\n    {\n      \"column\": \"_runtime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 88.45497529136644,\n        \"min\": 10.388507843017578,\n        \"max\": 525.9502971172333,\n        \"num_unique_values\": 1499,\n        \"samples\": [\n          171.23451471328735,\n          514.5650720596313,\n          154.19228529930115\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08458249714165784,\n        \"min\": 0.5001339316368103,\n        \"max\": 0.9694615602493286,\n        \"num_unique_values\": 773,\n        \"samples\": [\n          0.8494508266448975,\n          0.7013126015663147,\n          0.7811411619186401\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07423729060194581,\n        \"min\": 0.42367106676101685,\n        \"max\": 0.898168683052063,\n        \"num_unique_values\": 1498,\n        \"samples\": [\n          0.49998635053634644,\n          0.6923187971115112,\n          0.5667726397514343\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_timestamp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1152.2215388098273,\n        \"min\": 1716584329.3731794,\n        \"max\": 1716588576.7424233,\n        \"num_unique_values\": 1500,\n        \"samples\": [\n          1716585811.4945405,\n          1716585200.7616174,\n          1716587598.5155294\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08631999854487923,\n        \"min\": 0.4860813617706299,\n        \"max\": 0.835117757320404,\n        \"num_unique_values\": 240,\n        \"samples\": [\n          0.7644539475440979,\n          0.5920770764350891,\n          0.5224839448928833\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1503027321511436,\n        \"min\": 0.08336261659860611,\n        \"max\": 0.6930587291717529,\n        \"num_unique_values\": 1500,\n        \"samples\": [\n          0.46639472246170044,\n          0.4926566481590271,\n          0.23360194265842438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_step\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          83,\n          53,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          83,\n          53,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"run_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"0ebggn8j\",\n          \"tsl17cy8\",\n          \"2nsbmzjb\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["# CNN"],"metadata":{"id":"QUuWzfMHSNmi"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    # model.add(Dropout(0.5))\n","    # model.add(LSTM(256, return_sequences=True))\n","    # model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Beta/CNN/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Beta/CNN/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"8xrx_fxBSWGd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["global_model_CNN, metrics_df_CNN = federated_learning(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1TaNdIbSfkq","outputId":"055ba5d3-488a-4c20-8ea5-7cd02ed013ef","executionInfo":{"status":"ok","timestamp":1717530317929,"user_tz":-360,"elapsed":258120,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}},"collapsed":true},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 2.0052 - accuracy: 0.6085"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 8s 83ms/step - loss: 2.0035 - accuracy: 0.6161 - val_loss: 2.0032 - val_accuracy: 0.5043\n","Epoch 2/100\n","29/29 [==============================] - 2s 54ms/step - loss: 1.9687 - accuracy: 0.6342 - val_loss: 1.9832 - val_accuracy: 0.5334\n","Epoch 3/100\n","29/29 [==============================] - 1s 43ms/step - loss: 1.9364 - accuracy: 0.6719 - val_loss: 1.9633 - val_accuracy: 0.5948\n","Epoch 4/100\n","29/29 [==============================] - 1s 41ms/step - loss: 1.9069 - accuracy: 0.6622 - val_loss: 1.9435 - val_accuracy: 0.6034\n","Epoch 5/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.8748 - accuracy: 0.6891 - val_loss: 1.9239 - val_accuracy: 0.5905\n","Epoch 6/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.8470 - accuracy: 0.6810 - val_loss: 1.9053 - val_accuracy: 0.5119\n","Epoch 7/100\n","29/29 [==============================] - 1s 35ms/step - loss: 1.8191 - accuracy: 0.6926 - val_loss: 1.8841 - val_accuracy: 0.6218\n","Epoch 8/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.7979 - accuracy: 0.6813 - val_loss: 1.8656 - val_accuracy: 0.5614\n","Epoch 9/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.7748 - accuracy: 0.6969 - val_loss: 1.8465 - val_accuracy: 0.5603\n","Epoch 10/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.7552 - accuracy: 0.6945 - val_loss: 1.8269 - val_accuracy: 0.5700\n","Epoch 11/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.7359 - accuracy: 0.6940 - val_loss: 1.8077 - val_accuracy: 0.5733\n","Epoch 12/100\n","29/29 [==============================] - 1s 47ms/step - loss: 1.7187 - accuracy: 0.6945 - val_loss: 1.7843 - val_accuracy: 0.6347\n","Epoch 13/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.6987 - accuracy: 0.7026 - val_loss: 1.7643 - val_accuracy: 0.6336\n","Epoch 14/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.6868 - accuracy: 0.6953 - val_loss: 1.7442 - val_accuracy: 0.6336\n","Epoch 15/100\n","29/29 [==============================] - 1s 51ms/step - loss: 1.6672 - accuracy: 0.7002 - val_loss: 1.7235 - val_accuracy: 0.6444\n","Epoch 16/100\n","29/29 [==============================] - 2s 55ms/step - loss: 1.6527 - accuracy: 0.7010 - val_loss: 1.6959 - val_accuracy: 0.6994\n","Epoch 17/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.6424 - accuracy: 0.6918 - val_loss: 1.6807 - val_accuracy: 0.6724\n","Epoch 18/100\n","29/29 [==============================] - 2s 55ms/step - loss: 1.6231 - accuracy: 0.7058 - val_loss: 1.6530 - val_accuracy: 0.7069\n","Epoch 19/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.6088 - accuracy: 0.7007 - val_loss: 1.6333 - val_accuracy: 0.6983\n","Epoch 20/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.5954 - accuracy: 0.7029 - val_loss: 1.6134 - val_accuracy: 0.7047\n","Epoch 21/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.5831 - accuracy: 0.6980 - val_loss: 1.5952 - val_accuracy: 0.7015\n","Epoch 22/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.5706 - accuracy: 0.7045 - val_loss: 1.6103 - val_accuracy: 0.6358\n","Epoch 23/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.5610 - accuracy: 0.6985 - val_loss: 1.5739 - val_accuracy: 0.6843\n","Epoch 24/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.5453 - accuracy: 0.6977 - val_loss: 1.5545 - val_accuracy: 0.6961\n","Epoch 25/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.5306 - accuracy: 0.6988 - val_loss: 1.5330 - val_accuracy: 0.7144\n","Epoch 26/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5199 - accuracy: 0.7055 - val_loss: 1.5193 - val_accuracy: 0.7091\n","Epoch 27/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5069 - accuracy: 0.7074 - val_loss: 1.5069 - val_accuracy: 0.7091\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4938 - accuracy: 0.7115 - val_loss: 1.4947 - val_accuracy: 0.7101\n","Epoch 29/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4822 - accuracy: 0.7088 - val_loss: 1.4837 - val_accuracy: 0.7091\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4720 - accuracy: 0.7072 - val_loss: 1.4719 - val_accuracy: 0.7069\n","Epoch 31/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4590 - accuracy: 0.7131 - val_loss: 1.4740 - val_accuracy: 0.6907\n","Epoch 32/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4506 - accuracy: 0.7026 - val_loss: 1.4644 - val_accuracy: 0.6897\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4426 - accuracy: 0.7069 - val_loss: 1.4496 - val_accuracy: 0.6994\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4354 - accuracy: 0.7010 - val_loss: 1.4294 - val_accuracy: 0.7037\n","Epoch 35/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4202 - accuracy: 0.7082 - val_loss: 1.4246 - val_accuracy: 0.7037\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4081 - accuracy: 0.7080 - val_loss: 1.4110 - val_accuracy: 0.7123\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4000 - accuracy: 0.7047 - val_loss: 1.4120 - val_accuracy: 0.6950\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3888 - accuracy: 0.7058 - val_loss: 1.3939 - val_accuracy: 0.7004\n","Epoch 39/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3803 - accuracy: 0.7069 - val_loss: 1.3805 - val_accuracy: 0.7091\n","Epoch 40/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3711 - accuracy: 0.7074 - val_loss: 1.3714 - val_accuracy: 0.7101\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3583 - accuracy: 0.7142 - val_loss: 1.3660 - val_accuracy: 0.7069\n","Epoch 42/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3507 - accuracy: 0.7101 - val_loss: 1.3536 - val_accuracy: 0.7080\n","Epoch 43/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3418 - accuracy: 0.7061 - val_loss: 1.3469 - val_accuracy: 0.7058\n","Epoch 44/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.3347 - accuracy: 0.7072 - val_loss: 1.3450 - val_accuracy: 0.7004\n","Epoch 45/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3237 - accuracy: 0.7112 - val_loss: 1.3273 - val_accuracy: 0.7091\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3157 - accuracy: 0.7144 - val_loss: 1.3293 - val_accuracy: 0.6994\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3106 - accuracy: 0.7104 - val_loss: 1.3121 - val_accuracy: 0.7112\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3012 - accuracy: 0.7082 - val_loss: 1.3081 - val_accuracy: 0.7026\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2963 - accuracy: 0.7047 - val_loss: 1.2956 - val_accuracy: 0.7069\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2822 - accuracy: 0.7115 - val_loss: 1.3080 - val_accuracy: 0.6821\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2766 - accuracy: 0.7131 - val_loss: 1.2802 - val_accuracy: 0.7123\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2680 - accuracy: 0.7142 - val_loss: 1.2781 - val_accuracy: 0.7134\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2592 - accuracy: 0.7117 - val_loss: 1.2661 - val_accuracy: 0.7123\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2520 - accuracy: 0.7139 - val_loss: 1.2599 - val_accuracy: 0.7069\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2449 - accuracy: 0.7161 - val_loss: 1.2518 - val_accuracy: 0.7123\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2431 - accuracy: 0.7099 - val_loss: 1.2450 - val_accuracy: 0.7080\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2352 - accuracy: 0.7128 - val_loss: 1.2580 - val_accuracy: 0.6853\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2275 - accuracy: 0.7061 - val_loss: 1.2477 - val_accuracy: 0.6918\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2194 - accuracy: 0.7171 - val_loss: 1.2245 - val_accuracy: 0.7123\n","Epoch 60/100\n","29/29 [==============================] - 1s 50ms/step - loss: 1.2125 - accuracy: 0.7158 - val_loss: 1.2237 - val_accuracy: 0.7155\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2094 - accuracy: 0.7139 - val_loss: 1.2360 - val_accuracy: 0.6918\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2059 - accuracy: 0.7093 - val_loss: 1.2065 - val_accuracy: 0.7069\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1918 - accuracy: 0.7109 - val_loss: 1.2110 - val_accuracy: 0.7069\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1862 - accuracy: 0.7112 - val_loss: 1.1940 - val_accuracy: 0.7112\n","Epoch 65/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1829 - accuracy: 0.7109 - val_loss: 1.1877 - val_accuracy: 0.7134\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1747 - accuracy: 0.7177 - val_loss: 1.2151 - val_accuracy: 0.6778\n","Epoch 67/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1711 - accuracy: 0.7131 - val_loss: 1.1863 - val_accuracy: 0.7101\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1634 - accuracy: 0.7066 - val_loss: 1.1954 - val_accuracy: 0.6810\n","Epoch 69/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1585 - accuracy: 0.7136 - val_loss: 1.1657 - val_accuracy: 0.7134\n","Epoch 70/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.1518 - accuracy: 0.7136 - val_loss: 1.1688 - val_accuracy: 0.7069\n","Epoch 71/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.1503 - accuracy: 0.7128 - val_loss: 1.1572 - val_accuracy: 0.7047\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1435 - accuracy: 0.7115 - val_loss: 1.1512 - val_accuracy: 0.7069\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1341 - accuracy: 0.7214 - val_loss: 1.1552 - val_accuracy: 0.7112\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1291 - accuracy: 0.7204 - val_loss: 1.1530 - val_accuracy: 0.7091\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1262 - accuracy: 0.7150 - val_loss: 1.1343 - val_accuracy: 0.7155\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1186 - accuracy: 0.7166 - val_loss: 1.1358 - val_accuracy: 0.7144\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1155 - accuracy: 0.7161 - val_loss: 1.1526 - val_accuracy: 0.6810\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1173 - accuracy: 0.7109 - val_loss: 1.1325 - val_accuracy: 0.7101\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1023 - accuracy: 0.7179 - val_loss: 1.1167 - val_accuracy: 0.7112\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0995 - accuracy: 0.7177 - val_loss: 1.1150 - val_accuracy: 0.7155\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0950 - accuracy: 0.7150 - val_loss: 1.1096 - val_accuracy: 0.7037\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0900 - accuracy: 0.7239 - val_loss: 1.1043 - val_accuracy: 0.7155\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0840 - accuracy: 0.7214 - val_loss: 1.0989 - val_accuracy: 0.7112\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0810 - accuracy: 0.7196 - val_loss: 1.0987 - val_accuracy: 0.7155\n","Epoch 85/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0730 - accuracy: 0.7201 - val_loss: 1.0910 - val_accuracy: 0.7069\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0726 - accuracy: 0.7217 - val_loss: 1.0934 - val_accuracy: 0.7123\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0684 - accuracy: 0.7223 - val_loss: 1.0880 - val_accuracy: 0.7112\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0608 - accuracy: 0.7204 - val_loss: 1.0783 - val_accuracy: 0.7123\n","Epoch 89/100\n","29/29 [==============================] - 2s 56ms/step - loss: 1.0572 - accuracy: 0.7220 - val_loss: 1.0785 - val_accuracy: 0.7177\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0588 - accuracy: 0.7193 - val_loss: 1.0845 - val_accuracy: 0.7123\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0517 - accuracy: 0.7212 - val_loss: 1.1004 - val_accuracy: 0.6756\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0524 - accuracy: 0.7155 - val_loss: 1.0790 - val_accuracy: 0.7123\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0461 - accuracy: 0.7201 - val_loss: 1.0620 - val_accuracy: 0.7037\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0388 - accuracy: 0.7258 - val_loss: 1.0564 - val_accuracy: 0.7155\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0382 - accuracy: 0.7139 - val_loss: 1.0549 - val_accuracy: 0.7058\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0296 - accuracy: 0.7182 - val_loss: 1.0488 - val_accuracy: 0.7144\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0256 - accuracy: 0.7271 - val_loss: 1.0541 - val_accuracy: 0.7123\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0228 - accuracy: 0.7252 - val_loss: 1.0447 - val_accuracy: 0.7166\n","Epoch 99/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0197 - accuracy: 0.7204 - val_loss: 1.0618 - val_accuracy: 0.6961\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0238 - accuracy: 0.7236 - val_loss: 1.0400 - val_accuracy: 0.7177\n","{'loss': [2.0034704208374023, 1.9686675071716309, 1.9364113807678223, 1.906875491142273, 1.8748482465744019, 1.846983551979065, 1.8191189765930176, 1.7979315519332886, 1.7748472690582275, 1.7551881074905396, 1.7359445095062256, 1.7187217473983765, 1.6987254619598389, 1.6868175268173218, 1.6672453880310059, 1.652716040611267, 1.6424047946929932, 1.623071551322937, 1.6087863445281982, 1.59535551071167, 1.5831315517425537, 1.5705673694610596, 1.5609618425369263, 1.5453386306762695, 1.5306284427642822, 1.5198873281478882, 1.506925106048584, 1.493774652481079, 1.4821685552597046, 1.4720247983932495, 1.4590004682540894, 1.450584053993225, 1.4426381587982178, 1.4354159832000732, 1.4202346801757812, 1.408064842224121, 1.3999632596969604, 1.3888092041015625, 1.3802804946899414, 1.3710649013519287, 1.358309268951416, 1.3506776094436646, 1.3417688608169556, 1.3346672058105469, 1.323744297027588, 1.3156849145889282, 1.3106207847595215, 1.3012441396713257, 1.2963149547576904, 1.2821567058563232, 1.2765885591506958, 1.268009066581726, 1.2591601610183716, 1.251985788345337, 1.2449418306350708, 1.2430943250656128, 1.2351773977279663, 1.2275488376617432, 1.2194052934646606, 1.2125275135040283, 1.2094111442565918, 1.2059060335159302, 1.1918220520019531, 1.1862092018127441, 1.182892918586731, 1.1746660470962524, 1.1711236238479614, 1.1633868217468262, 1.1585266590118408, 1.1518499851226807, 1.150347113609314, 1.1435457468032837, 1.1340668201446533, 1.1290615797042847, 1.1261883974075317, 1.1185935735702515, 1.1155290603637695, 1.1173346042633057, 1.1022875308990479, 1.099501132965088, 1.0950100421905518, 1.0900312662124634, 1.083953857421875, 1.080991506576538, 1.0730082988739014, 1.072561502456665, 1.0683858394622803, 1.0608223676681519, 1.0571541786193848, 1.0587815046310425, 1.051657795906067, 1.0524249076843262, 1.0461260080337524, 1.0387580394744873, 1.0381509065628052, 1.0295509099960327, 1.0255873203277588, 1.0228136777877808, 1.019675850868225, 1.0237667560577393], 'accuracy': [0.6161099076271057, 0.634159505367279, 0.671875, 0.6621767282485962, 0.689116358757019, 0.681034505367279, 0.6926185488700867, 0.681303858757019, 0.696928858757019, 0.6945043206214905, 0.693965494632721, 0.6945043206214905, 0.7025862336158752, 0.6953125, 0.7001616358757019, 0.7009698152542114, 0.6918103694915771, 0.7058189511299133, 0.7007004022598267, 0.7028555870056152, 0.6980064511299133, 0.704472005367279, 0.6985452771186829, 0.6977370977401733, 0.6988146305084229, 0.7055495977401733, 0.7074353694915771, 0.7114762663841248, 0.7087823152542114, 0.7071659564971924, 0.7130926847457886, 0.7025862336158752, 0.7068965435028076, 0.7009698152542114, 0.7082435488700867, 0.7079741358757019, 0.704741358757019, 0.7058189511299133, 0.7068965435028076, 0.7074353694915771, 0.7141702771186829, 0.7101293206214905, 0.7060883641242981, 0.7071659564971924, 0.7112069129943848, 0.7144396305084229, 0.7103987336158752, 0.7082435488700867, 0.704741358757019, 0.7114762663841248, 0.7130926847457886, 0.7141702771186829, 0.7117456793785095, 0.7139008641242981, 0.7160560488700867, 0.7098599076271057, 0.7128232717514038, 0.7060883641242981, 0.717133641242981, 0.7157866358757019, 0.7139008641242981, 0.709321141242981, 0.7109375, 0.7112069129943848, 0.7109375, 0.7176724076271057, 0.7130926847457886, 0.7066271305084229, 0.7136314511299133, 0.7136314511299133, 0.7128232717514038, 0.7114762663841248, 0.7214439511299133, 0.720366358757019, 0.7149784564971924, 0.7165948152542114, 0.7160560488700867, 0.7109375, 0.7179418206214905, 0.7176724076271057, 0.7149784564971924, 0.7238685488700867, 0.7214439511299133, 0.7195581793785095, 0.720097005367279, 0.7217133641242981, 0.7222521305084229, 0.720366358757019, 0.7219827771186829, 0.7192887663841248, 0.7211745977401733, 0.7155172228813171, 0.720097005367279, 0.7257543206214905, 0.7139008641242981, 0.7182112336158752, 0.7271012663841248, 0.725215494632721, 0.720366358757019, 0.7235991358757019], 'val_loss': [2.0032403469085693, 1.9831522703170776, 1.9632713794708252, 1.9435021877288818, 1.923880696296692, 1.9052553176879883, 1.8840680122375488, 1.865566611289978, 1.8465476036071777, 1.8269098997116089, 1.8076950311660767, 1.7843258380889893, 1.7643343210220337, 1.7441580295562744, 1.7234712839126587, 1.6958887577056885, 1.6807191371917725, 1.653045654296875, 1.6333177089691162, 1.613379955291748, 1.595200777053833, 1.6102967262268066, 1.5739229917526245, 1.5545309782028198, 1.5330002307891846, 1.519327998161316, 1.5069016218185425, 1.4946813583374023, 1.483702540397644, 1.4718670845031738, 1.4739986658096313, 1.4643770456314087, 1.4496102333068848, 1.4294264316558838, 1.4245508909225464, 1.4110146760940552, 1.4120334386825562, 1.3938740491867065, 1.3805463314056396, 1.3713771104812622, 1.3659688234329224, 1.3536044359207153, 1.3469488620758057, 1.345034122467041, 1.3273392915725708, 1.3293033838272095, 1.312061071395874, 1.308091402053833, 1.2955946922302246, 1.3079746961593628, 1.2802422046661377, 1.2781312465667725, 1.2661070823669434, 1.2598814964294434, 1.251840353012085, 1.245013952255249, 1.257989525794983, 1.2477388381958008, 1.2244559526443481, 1.223689079284668, 1.2360295057296753, 1.206497073173523, 1.2110342979431152, 1.1939854621887207, 1.1877198219299316, 1.2150894403457642, 1.1862560510635376, 1.1954152584075928, 1.165718913078308, 1.1688140630722046, 1.1572341918945312, 1.151166319847107, 1.155167818069458, 1.1530367136001587, 1.134253740310669, 1.1357747316360474, 1.152567982673645, 1.1324907541275024, 1.116711974143982, 1.1150007247924805, 1.1096335649490356, 1.1043190956115723, 1.098941683769226, 1.0987322330474854, 1.0910471677780151, 1.0933600664138794, 1.0879628658294678, 1.0782873630523682, 1.078452706336975, 1.0845263004302979, 1.1004164218902588, 1.0790222883224487, 1.0620183944702148, 1.0563991069793701, 1.0548620223999023, 1.0488337278366089, 1.0541465282440186, 1.0446860790252686, 1.0617687702178955, 1.040040373802185], 'val_accuracy': [0.5043103694915771, 0.5334051847457886, 0.5948275923728943, 0.6034482717514038, 0.5905172228813171, 0.5118534564971924, 0.6217672228813171, 0.5614224076271057, 0.5603448152542114, 0.5700430870056152, 0.5732758641242981, 0.6346982717514038, 0.6336206793785095, 0.6336206793785095, 0.6443965435028076, 0.6993534564971924, 0.6724137663841248, 0.7068965435028076, 0.6982758641242981, 0.704741358757019, 0.701508641242981, 0.6357758641242981, 0.6842672228813171, 0.6961206793785095, 0.7144396305084229, 0.7090517282485962, 0.7090517282485962, 0.7101293206214905, 0.7090517282485962, 0.7068965435028076, 0.6907327771186829, 0.6896551847457886, 0.6993534564971924, 0.7036637663841248, 0.7036637663841248, 0.712284505367279, 0.6950430870056152, 0.7004310488700867, 0.7090517282485962, 0.7101293206214905, 0.7068965435028076, 0.7079741358757019, 0.7058189511299133, 0.7004310488700867, 0.7090517282485962, 0.6993534564971924, 0.7112069129943848, 0.7025862336158752, 0.7068965435028076, 0.6821120977401733, 0.712284505367279, 0.7133620977401733, 0.712284505367279, 0.7068965435028076, 0.712284505367279, 0.7079741358757019, 0.6853448152542114, 0.6918103694915771, 0.712284505367279, 0.7155172228813171, 0.6918103694915771, 0.7068965435028076, 0.7068965435028076, 0.7112069129943848, 0.7133620977401733, 0.6778017282485962, 0.7101293206214905, 0.681034505367279, 0.7133620977401733, 0.7068965435028076, 0.704741358757019, 0.7068965435028076, 0.7112069129943848, 0.7090517282485962, 0.7155172228813171, 0.7144396305084229, 0.681034505367279, 0.7101293206214905, 0.7112069129943848, 0.7155172228813171, 0.7036637663841248, 0.7155172228813171, 0.7112069129943848, 0.7155172228813171, 0.7068965435028076, 0.712284505367279, 0.7112069129943848, 0.712284505367279, 0.7176724076271057, 0.712284505367279, 0.6756465435028076, 0.712284505367279, 0.7036637663841248, 0.7155172228813171, 0.7058189511299133, 0.7144396305084229, 0.712284505367279, 0.7165948152542114, 0.6961206793785095, 0.7176724076271057]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 2.0109 - accuracy: 0.5379"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 5s 36ms/step - loss: 2.0098 - accuracy: 0.5374 - val_loss: 2.0042 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.9805 - accuracy: 0.6387 - val_loss: 1.9848 - val_accuracy: 0.6719\n","Epoch 3/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.9519 - accuracy: 0.6548 - val_loss: 1.9658 - val_accuracy: 0.5848\n","Epoch 4/100\n","28/28 [==============================] - 1s 30ms/step - loss: 1.9243 - accuracy: 0.6517 - val_loss: 1.9468 - val_accuracy: 0.6844\n","Epoch 5/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.8969 - accuracy: 0.6624 - val_loss: 1.9277 - val_accuracy: 0.6742\n","Epoch 6/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.8722 - accuracy: 0.6604 - val_loss: 1.9090 - val_accuracy: 0.6810\n","Epoch 7/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.8479 - accuracy: 0.6613 - val_loss: 1.8901 - val_accuracy: 0.6459\n","Epoch 8/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.8254 - accuracy: 0.6686 - val_loss: 1.8720 - val_accuracy: 0.6357\n","Epoch 9/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.8012 - accuracy: 0.6740 - val_loss: 1.8536 - val_accuracy: 0.5905\n","Epoch 10/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.7814 - accuracy: 0.6658 - val_loss: 1.8342 - val_accuracy: 0.6414\n","Epoch 11/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.7616 - accuracy: 0.6766 - val_loss: 1.8166 - val_accuracy: 0.5860\n","Epoch 12/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.7591 - accuracy: 0.6553 - val_loss: 1.7969 - val_accuracy: 0.6425\n","Epoch 13/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.7336 - accuracy: 0.6664 - val_loss: 1.7770 - val_accuracy: 0.6753\n","Epoch 14/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.7158 - accuracy: 0.6667 - val_loss: 1.7596 - val_accuracy: 0.6448\n","Epoch 15/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.6959 - accuracy: 0.6797 - val_loss: 1.7386 - val_accuracy: 0.6697\n","Epoch 16/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.6772 - accuracy: 0.6873 - val_loss: 1.7205 - val_accuracy: 0.6493\n","Epoch 17/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.6638 - accuracy: 0.6811 - val_loss: 1.6994 - val_accuracy: 0.6618\n","Epoch 18/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.6495 - accuracy: 0.6811 - val_loss: 1.6780 - val_accuracy: 0.6912\n","Epoch 19/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.6352 - accuracy: 0.6811 - val_loss: 1.6593 - val_accuracy: 0.6878\n","Epoch 20/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.6204 - accuracy: 0.6873 - val_loss: 1.6427 - val_accuracy: 0.6708\n","Epoch 21/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.6064 - accuracy: 0.6842 - val_loss: 1.6214 - val_accuracy: 0.6867\n","Epoch 22/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5910 - accuracy: 0.6885 - val_loss: 1.6043 - val_accuracy: 0.6889\n","Epoch 23/100\n","28/28 [==============================] - 1s 32ms/step - loss: 1.5825 - accuracy: 0.6794 - val_loss: 1.5879 - val_accuracy: 0.6934\n","Epoch 24/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.5709 - accuracy: 0.6885 - val_loss: 1.5732 - val_accuracy: 0.6867\n","Epoch 25/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.5557 - accuracy: 0.6834 - val_loss: 1.5575 - val_accuracy: 0.6946\n","Epoch 26/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.5421 - accuracy: 0.6873 - val_loss: 1.5446 - val_accuracy: 0.6878\n","Epoch 27/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5292 - accuracy: 0.6907 - val_loss: 1.5354 - val_accuracy: 0.6878\n","Epoch 28/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5180 - accuracy: 0.6836 - val_loss: 1.5298 - val_accuracy: 0.6731\n","Epoch 29/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.5069 - accuracy: 0.6876 - val_loss: 1.5086 - val_accuracy: 0.6923\n","Epoch 30/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4953 - accuracy: 0.6853 - val_loss: 1.4952 - val_accuracy: 0.6912\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4849 - accuracy: 0.6941 - val_loss: 1.4892 - val_accuracy: 0.6867\n","Epoch 32/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.4714 - accuracy: 0.6930 - val_loss: 1.4736 - val_accuracy: 0.6980\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4638 - accuracy: 0.6868 - val_loss: 1.4719 - val_accuracy: 0.6844\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4525 - accuracy: 0.6950 - val_loss: 1.4516 - val_accuracy: 0.6946\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4411 - accuracy: 0.6927 - val_loss: 1.4555 - val_accuracy: 0.6742\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4337 - accuracy: 0.6902 - val_loss: 1.4313 - val_accuracy: 0.6957\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4242 - accuracy: 0.6924 - val_loss: 1.4249 - val_accuracy: 0.6912\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4091 - accuracy: 0.6921 - val_loss: 1.4138 - val_accuracy: 0.6957\n","Epoch 39/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.4007 - accuracy: 0.6941 - val_loss: 1.4028 - val_accuracy: 0.7002\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3900 - accuracy: 0.6938 - val_loss: 1.3959 - val_accuracy: 0.6900\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3810 - accuracy: 0.6876 - val_loss: 1.3937 - val_accuracy: 0.6855\n","Epoch 42/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3732 - accuracy: 0.6899 - val_loss: 1.3788 - val_accuracy: 0.6912\n","Epoch 43/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3699 - accuracy: 0.6890 - val_loss: 1.3766 - val_accuracy: 0.6821\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3543 - accuracy: 0.6958 - val_loss: 1.3589 - val_accuracy: 0.6991\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3482 - accuracy: 0.6944 - val_loss: 1.3498 - val_accuracy: 0.7002\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3358 - accuracy: 0.6955 - val_loss: 1.3417 - val_accuracy: 0.6946\n","Epoch 47/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.3252 - accuracy: 0.7001 - val_loss: 1.3389 - val_accuracy: 0.6923\n","Epoch 48/100\n","28/28 [==============================] - 1s 41ms/step - loss: 1.3186 - accuracy: 0.7015 - val_loss: 1.3252 - val_accuracy: 0.6968\n","Epoch 49/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.3127 - accuracy: 0.6944 - val_loss: 1.3173 - val_accuracy: 0.6968\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3027 - accuracy: 0.6924 - val_loss: 1.3198 - val_accuracy: 0.6833\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2989 - accuracy: 0.6944 - val_loss: 1.3162 - val_accuracy: 0.6810\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2889 - accuracy: 0.6904 - val_loss: 1.2982 - val_accuracy: 0.6923\n","Epoch 53/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2794 - accuracy: 0.6986 - val_loss: 1.2869 - val_accuracy: 0.6946\n","Epoch 54/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2739 - accuracy: 0.6992 - val_loss: 1.2963 - val_accuracy: 0.6776\n","Epoch 55/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.2669 - accuracy: 0.6944 - val_loss: 1.2726 - val_accuracy: 0.6957\n","Epoch 56/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.2584 - accuracy: 0.7003 - val_loss: 1.2685 - val_accuracy: 0.7025\n","Epoch 57/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2491 - accuracy: 0.7035 - val_loss: 1.2631 - val_accuracy: 0.6946\n","Epoch 58/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2445 - accuracy: 0.6995 - val_loss: 1.2524 - val_accuracy: 0.6968\n","Epoch 59/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2353 - accuracy: 0.7003 - val_loss: 1.2461 - val_accuracy: 0.7002\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2283 - accuracy: 0.6981 - val_loss: 1.2425 - val_accuracy: 0.6980\n","Epoch 61/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.2277 - accuracy: 0.6941 - val_loss: 1.2336 - val_accuracy: 0.7059\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2159 - accuracy: 0.7029 - val_loss: 1.2368 - val_accuracy: 0.6821\n","Epoch 63/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2118 - accuracy: 0.7026 - val_loss: 1.2218 - val_accuracy: 0.6878\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2013 - accuracy: 0.7068 - val_loss: 1.2143 - val_accuracy: 0.6934\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1947 - accuracy: 0.7040 - val_loss: 1.2081 - val_accuracy: 0.7002\n","Epoch 66/100\n","28/28 [==============================] - 1s 31ms/step - loss: 1.1889 - accuracy: 0.6989 - val_loss: 1.2015 - val_accuracy: 0.6991\n","Epoch 67/100\n","28/28 [==============================] - 1s 38ms/step - loss: 1.1817 - accuracy: 0.7012 - val_loss: 1.1975 - val_accuracy: 0.7070\n","Epoch 68/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1819 - accuracy: 0.6989 - val_loss: 1.1904 - val_accuracy: 0.6923\n","Epoch 69/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1716 - accuracy: 0.7018 - val_loss: 1.1840 - val_accuracy: 0.7048\n","Epoch 70/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1661 - accuracy: 0.6992 - val_loss: 1.1892 - val_accuracy: 0.6912\n","Epoch 71/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1594 - accuracy: 0.7051 - val_loss: 1.1796 - val_accuracy: 0.6968\n","Epoch 72/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1527 - accuracy: 0.7071 - val_loss: 1.1681 - val_accuracy: 0.7014\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1500 - accuracy: 0.7060 - val_loss: 1.1625 - val_accuracy: 0.6934\n","Epoch 74/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1519 - accuracy: 0.6984 - val_loss: 1.1648 - val_accuracy: 0.6912\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1419 - accuracy: 0.7032 - val_loss: 1.1510 - val_accuracy: 0.7025\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1297 - accuracy: 0.7077 - val_loss: 1.1465 - val_accuracy: 0.7002\n","Epoch 77/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1243 - accuracy: 0.7032 - val_loss: 1.1423 - val_accuracy: 0.7036\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1232 - accuracy: 0.7105 - val_loss: 1.1361 - val_accuracy: 0.6957\n","Epoch 79/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1201 - accuracy: 0.7097 - val_loss: 1.1318 - val_accuracy: 0.7002\n","Epoch 80/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1110 - accuracy: 0.7074 - val_loss: 1.1288 - val_accuracy: 0.6946\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1132 - accuracy: 0.6992 - val_loss: 1.1223 - val_accuracy: 0.7048\n","Epoch 82/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1038 - accuracy: 0.7071 - val_loss: 1.1227 - val_accuracy: 0.7025\n","Epoch 83/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0992 - accuracy: 0.7085 - val_loss: 1.1125 - val_accuracy: 0.7014\n","Epoch 84/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0885 - accuracy: 0.7153 - val_loss: 1.1088 - val_accuracy: 0.7014\n","Epoch 85/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0837 - accuracy: 0.7114 - val_loss: 1.1045 - val_accuracy: 0.7002\n","Epoch 86/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.0797 - accuracy: 0.7131 - val_loss: 1.1052 - val_accuracy: 0.7081\n","Epoch 87/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.0774 - accuracy: 0.7119 - val_loss: 1.0974 - val_accuracy: 0.7115\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0721 - accuracy: 0.7153 - val_loss: 1.1003 - val_accuracy: 0.7025\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0672 - accuracy: 0.7119 - val_loss: 1.0879 - val_accuracy: 0.7104\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0630 - accuracy: 0.7054 - val_loss: 1.0855 - val_accuracy: 0.7093\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0604 - accuracy: 0.7125 - val_loss: 1.0821 - val_accuracy: 0.7104\n","Epoch 92/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0559 - accuracy: 0.7151 - val_loss: 1.0775 - val_accuracy: 0.7104\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0495 - accuracy: 0.7159 - val_loss: 1.0801 - val_accuracy: 0.6912\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0481 - accuracy: 0.7136 - val_loss: 1.0683 - val_accuracy: 0.7025\n","Epoch 95/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0409 - accuracy: 0.7176 - val_loss: 1.0655 - val_accuracy: 0.7014\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0398 - accuracy: 0.7142 - val_loss: 1.0632 - val_accuracy: 0.6980\n","Epoch 97/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0331 - accuracy: 0.7201 - val_loss: 1.0565 - val_accuracy: 0.7081\n","Epoch 98/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0283 - accuracy: 0.7210 - val_loss: 1.0533 - val_accuracy: 0.7036\n","Epoch 99/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0229 - accuracy: 0.7199 - val_loss: 1.0499 - val_accuracy: 0.7059\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0223 - accuracy: 0.7224 - val_loss: 1.0457 - val_accuracy: 0.7115\n","{'loss': [2.0097758769989014, 1.9804869890213013, 1.9518544673919678, 1.924310326576233, 1.8969058990478516, 1.8722059726715088, 1.8479360342025757, 1.8253908157348633, 1.8012049198150635, 1.7813769578933716, 1.761577844619751, 1.7590512037277222, 1.7336375713348389, 1.7157831192016602, 1.695866584777832, 1.6772420406341553, 1.6637519598007202, 1.649466872215271, 1.6352413892745972, 1.6204205751419067, 1.606424331665039, 1.5909557342529297, 1.5824720859527588, 1.5709173679351807, 1.5557316541671753, 1.5421364307403564, 1.5292023420333862, 1.5180091857910156, 1.5069125890731812, 1.4952996969223022, 1.484941840171814, 1.4714266061782837, 1.4637553691864014, 1.452484130859375, 1.4410995244979858, 1.4337022304534912, 1.4241937398910522, 1.40914785861969, 1.4006738662719727, 1.3899643421173096, 1.3809725046157837, 1.3732374906539917, 1.3699268102645874, 1.3543092012405396, 1.34824800491333, 1.3358176946640015, 1.3251937627792358, 1.3186346292495728, 1.3126598596572876, 1.3027267456054688, 1.2989221811294556, 1.2889379262924194, 1.2794108390808105, 1.2739285230636597, 1.2668795585632324, 1.258436918258667, 1.249125361442566, 1.244523048400879, 1.2353202104568481, 1.2282854318618774, 1.2277474403381348, 1.2159092426300049, 1.211796760559082, 1.2012888193130493, 1.1946529150009155, 1.1888946294784546, 1.1817430257797241, 1.181914210319519, 1.1716291904449463, 1.1661443710327148, 1.159353256225586, 1.1527204513549805, 1.1499615907669067, 1.1519109010696411, 1.1419425010681152, 1.129654049873352, 1.1243306398391724, 1.1231716871261597, 1.120066523551941, 1.1110137701034546, 1.113168478012085, 1.1037936210632324, 1.0991636514663696, 1.0884573459625244, 1.0837371349334717, 1.07974374294281, 1.0774455070495605, 1.0721255540847778, 1.06720769405365, 1.062990665435791, 1.0603511333465576, 1.0559396743774414, 1.0494890213012695, 1.0481252670288086, 1.0408893823623657, 1.0397934913635254, 1.033121943473816, 1.0282814502716064, 1.0228554010391235, 1.022302269935608], 'accuracy': [0.5373514294624329, 0.6386530995368958, 0.6547821164131165, 0.6516695022583008, 0.6624221801757812, 0.6604413986206055, 0.6612903475761414, 0.6686474084854126, 0.6740237474441528, 0.6658177971839905, 0.676570475101471, 0.6553480625152588, 0.666383683681488, 0.6666666865348816, 0.6796830892562866, 0.6873231530189514, 0.6810979247093201, 0.6810979247093201, 0.6810979247093201, 0.6873231530189514, 0.6842105388641357, 0.6884549856185913, 0.6794000864028931, 0.6884549856185913, 0.6833616495132446, 0.6873231530189514, 0.6907187104225159, 0.6836445927619934, 0.6876060962677002, 0.6853423714637756, 0.6941143274307251, 0.6929824352264404, 0.6867572069168091, 0.6949632167816162, 0.6926994919776917, 0.6901528239250183, 0.6924165487289429, 0.6921335458755493, 0.6941143274307251, 0.6938313245773315, 0.6876060962677002, 0.6898698210716248, 0.6890209317207336, 0.6958121061325073, 0.6943972706794739, 0.6955291628837585, 0.7000566124916077, 0.7014714479446411, 0.6943972706794739, 0.6924165487289429, 0.6943972706794739, 0.6904357671737671, 0.6986417770385742, 0.6992077231407166, 0.6943972706794739, 0.7003395557403564, 0.7034521698951721, 0.6994906663894653, 0.7003395557403564, 0.6980758309364319, 0.6941143274307251, 0.7028862237930298, 0.702603280544281, 0.7068477869033813, 0.7040181159973145, 0.698924720287323, 0.7011884450912476, 0.698924720287323, 0.7017543911933899, 0.6992077231407166, 0.7051499485969543, 0.7071307301521301, 0.7059988975524902, 0.6983587741851807, 0.7031692266464233, 0.7076966762542725, 0.7031692266464233, 0.7105262875556946, 0.7096773982048035, 0.7074136734008789, 0.6992077231407166, 0.7071307301521301, 0.7085455656051636, 0.7153367400169373, 0.7113752365112305, 0.7130730152130127, 0.711941123008728, 0.7153367400169373, 0.711941123008728, 0.7054329514503479, 0.7125070691108704, 0.7150537371635437, 0.7159026861190796, 0.713638961315155, 0.7176004648208618, 0.7142048478126526, 0.7201471328735352, 0.7209960222244263, 0.7198641896247864, 0.7224108576774597], 'val_loss': [2.004178047180176, 1.984832525253296, 1.9658029079437256, 1.946765661239624, 1.9277416467666626, 1.908983588218689, 1.890122652053833, 1.8719662427902222, 1.8536267280578613, 1.834222674369812, 1.8165802955627441, 1.7968987226486206, 1.7770321369171143, 1.759613275527954, 1.738643765449524, 1.7204722166061401, 1.6994138956069946, 1.6779735088348389, 1.6592587232589722, 1.6426993608474731, 1.621375560760498, 1.6042673587799072, 1.5879179239273071, 1.5732372999191284, 1.5575133562088013, 1.544629693031311, 1.5353524684906006, 1.5298426151275635, 1.5086032152175903, 1.4951728582382202, 1.4891574382781982, 1.4736361503601074, 1.4719219207763672, 1.4516133069992065, 1.4555031061172485, 1.4313268661499023, 1.4248701333999634, 1.4137639999389648, 1.402801752090454, 1.3958618640899658, 1.393670678138733, 1.3787550926208496, 1.3766182661056519, 1.3588663339614868, 1.3497577905654907, 1.3416827917099, 1.3389256000518799, 1.3251749277114868, 1.3172770738601685, 1.3198074102401733, 1.316205382347107, 1.298231840133667, 1.2868986129760742, 1.2963134050369263, 1.272573471069336, 1.2684760093688965, 1.2630572319030762, 1.252363920211792, 1.2460538148880005, 1.242454171180725, 1.2335691452026367, 1.2368042469024658, 1.221757411956787, 1.2142771482467651, 1.2080707550048828, 1.2014776468276978, 1.1975421905517578, 1.1903945207595825, 1.1839854717254639, 1.1891567707061768, 1.1795904636383057, 1.168080449104309, 1.1625345945358276, 1.164780616760254, 1.1509960889816284, 1.1465104818344116, 1.142307996749878, 1.136102557182312, 1.131811261177063, 1.1287702322006226, 1.1222572326660156, 1.1226776838302612, 1.112534761428833, 1.1088449954986572, 1.1045011281967163, 1.1051907539367676, 1.0973777770996094, 1.1003361940383911, 1.0879336595535278, 1.0854860544204712, 1.0821080207824707, 1.0775336027145386, 1.0801427364349365, 1.0683282613754272, 1.065501093864441, 1.0632121562957764, 1.0564908981323242, 1.0533214807510376, 1.0498732328414917, 1.045672059059143], 'val_accuracy': [0.4954751133918762, 0.6719456911087036, 0.5848416090011597, 0.6843891143798828, 0.6742081642150879, 0.6809954643249512, 0.6459276080131531, 0.6357465982437134, 0.5904977321624756, 0.6414027214050293, 0.5859728455543518, 0.6425339579582214, 0.6753393411636353, 0.6447963714599609, 0.6696832776069641, 0.6493212580680847, 0.6617646813392639, 0.6911764740943909, 0.6877828240394592, 0.6708144545555115, 0.6866515874862671, 0.6889140009880066, 0.6934388875961304, 0.6866515874862671, 0.6945701241493225, 0.6877828240394592, 0.6877828240394592, 0.6730769276618958, 0.692307710647583, 0.6911764740943909, 0.6866515874862671, 0.6979637742042542, 0.6843891143798828, 0.6945701241493225, 0.6742081642150879, 0.6957013607025146, 0.6911764740943909, 0.6957013607025146, 0.7002262473106384, 0.6900452375411987, 0.685520350933075, 0.6911764740943909, 0.6821267008781433, 0.6990950107574463, 0.7002262473106384, 0.6945701241493225, 0.692307710647583, 0.6968325972557068, 0.6968325972557068, 0.6832579374313354, 0.6809954643249512, 0.692307710647583, 0.6945701241493225, 0.6776018142700195, 0.6957013607025146, 0.7024886608123779, 0.6945701241493225, 0.6968325972557068, 0.7002262473106384, 0.6979637742042542, 0.7058823704719543, 0.6821267008781433, 0.6877828240394592, 0.6934388875961304, 0.7002262473106384, 0.6990950107574463, 0.7070135474205017, 0.692307710647583, 0.7047511339187622, 0.6911764740943909, 0.6968325972557068, 0.7013574838638306, 0.6934388875961304, 0.6911764740943909, 0.7024886608123779, 0.7002262473106384, 0.7036198973655701, 0.6957013607025146, 0.7002262473106384, 0.6945701241493225, 0.7047511339187622, 0.7024886608123779, 0.7013574838638306, 0.7013574838638306, 0.7002262473106384, 0.7081447839736938, 0.7115384340286255, 0.7024886608123779, 0.7104072570800781, 0.709276020526886, 0.7104072570800781, 0.7104072570800781, 0.6911764740943909, 0.7024886608123779, 0.7013574838638306, 0.6979637742042542, 0.7081447839736938, 0.7036198973655701, 0.7058823704719543, 0.7115384340286255]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 2.0086 - accuracy: 0.5413"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 5s 37ms/step - loss: 2.0086 - accuracy: 0.5413 - val_loss: 2.0022 - val_accuracy: 0.6426\n","Epoch 2/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.9769 - accuracy: 0.6320 - val_loss: 1.9812 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.9456 - accuracy: 0.6483 - val_loss: 1.9600 - val_accuracy: 0.6364\n","Epoch 4/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.9137 - accuracy: 0.6693 - val_loss: 1.9393 - val_accuracy: 0.6436\n","Epoch 5/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.8822 - accuracy: 0.6705 - val_loss: 1.9188 - val_accuracy: 0.5919\n","Epoch 6/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.8506 - accuracy: 0.6801 - val_loss: 1.8975 - val_accuracy: 0.6529\n","Epoch 7/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.8235 - accuracy: 0.6718 - val_loss: 1.8781 - val_accuracy: 0.5682\n","Epoch 8/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.8019 - accuracy: 0.6641 - val_loss: 1.8559 - val_accuracy: 0.6612\n","Epoch 9/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.7818 - accuracy: 0.6659 - val_loss: 1.8368 - val_accuracy: 0.6436\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.7539 - accuracy: 0.6850 - val_loss: 1.8195 - val_accuracy: 0.5558\n","Epoch 11/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.7404 - accuracy: 0.6747 - val_loss: 1.7960 - val_accuracy: 0.6477\n","Epoch 12/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.7146 - accuracy: 0.6876 - val_loss: 1.7729 - val_accuracy: 0.6467\n","Epoch 13/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.6983 - accuracy: 0.6863 - val_loss: 1.7555 - val_accuracy: 0.6467\n","Epoch 14/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.6811 - accuracy: 0.6860 - val_loss: 1.7364 - val_accuracy: 0.6312\n","Epoch 15/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.6638 - accuracy: 0.6842 - val_loss: 1.7119 - val_accuracy: 0.6529\n","Epoch 16/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.6468 - accuracy: 0.6902 - val_loss: 1.6875 - val_accuracy: 0.6643\n","Epoch 17/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.6313 - accuracy: 0.6879 - val_loss: 1.6753 - val_accuracy: 0.6498\n","Epoch 18/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.6187 - accuracy: 0.6845 - val_loss: 1.6478 - val_accuracy: 0.6550\n","Epoch 19/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.6012 - accuracy: 0.6956 - val_loss: 1.6302 - val_accuracy: 0.6643\n","Epoch 20/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.5847 - accuracy: 0.6930 - val_loss: 1.6124 - val_accuracy: 0.6694\n","Epoch 21/100\n","31/31 [==============================] - 1s 31ms/step - loss: 1.5704 - accuracy: 0.6956 - val_loss: 1.5948 - val_accuracy: 0.6736\n","Epoch 22/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5567 - accuracy: 0.6953 - val_loss: 1.5873 - val_accuracy: 0.6601\n","Epoch 23/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.5423 - accuracy: 0.6992 - val_loss: 1.5651 - val_accuracy: 0.6746\n","Epoch 24/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.5291 - accuracy: 0.6935 - val_loss: 1.5518 - val_accuracy: 0.6767\n","Epoch 25/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.5185 - accuracy: 0.6920 - val_loss: 1.5444 - val_accuracy: 0.6622\n","Epoch 26/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.5061 - accuracy: 0.6943 - val_loss: 1.5282 - val_accuracy: 0.6705\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.4905 - accuracy: 0.6990 - val_loss: 1.5178 - val_accuracy: 0.6632\n","Epoch 28/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4848 - accuracy: 0.6798 - val_loss: 1.5019 - val_accuracy: 0.6663\n","Epoch 29/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.4675 - accuracy: 0.6935 - val_loss: 1.4920 - val_accuracy: 0.6643\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.4572 - accuracy: 0.6948 - val_loss: 1.4811 - val_accuracy: 0.6705\n","Epoch 31/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.4439 - accuracy: 0.6948 - val_loss: 1.4680 - val_accuracy: 0.6725\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.4305 - accuracy: 0.7047 - val_loss: 1.4588 - val_accuracy: 0.6653\n","Epoch 33/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.4212 - accuracy: 0.6948 - val_loss: 1.4456 - val_accuracy: 0.6684\n","Epoch 34/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4086 - accuracy: 0.7016 - val_loss: 1.4355 - val_accuracy: 0.6694\n","Epoch 35/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.3967 - accuracy: 0.6992 - val_loss: 1.4250 - val_accuracy: 0.6663\n","Epoch 36/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.3920 - accuracy: 0.6969 - val_loss: 1.4139 - val_accuracy: 0.6736\n","Epoch 37/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3772 - accuracy: 0.7018 - val_loss: 1.4048 - val_accuracy: 0.6725\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3668 - accuracy: 0.7021 - val_loss: 1.3998 - val_accuracy: 0.6674\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3589 - accuracy: 0.7005 - val_loss: 1.3856 - val_accuracy: 0.6705\n","Epoch 40/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3466 - accuracy: 0.7044 - val_loss: 1.3850 - val_accuracy: 0.6705\n","Epoch 41/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3405 - accuracy: 0.6977 - val_loss: 1.3671 - val_accuracy: 0.6663\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3277 - accuracy: 0.7036 - val_loss: 1.3577 - val_accuracy: 0.6643\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3186 - accuracy: 0.7008 - val_loss: 1.3488 - val_accuracy: 0.6705\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3100 - accuracy: 0.7023 - val_loss: 1.3393 - val_accuracy: 0.6725\n","Epoch 45/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3042 - accuracy: 0.7036 - val_loss: 1.3329 - val_accuracy: 0.6715\n","Epoch 46/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2954 - accuracy: 0.6987 - val_loss: 1.3244 - val_accuracy: 0.6705\n","Epoch 47/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2838 - accuracy: 0.7062 - val_loss: 1.3252 - val_accuracy: 0.6684\n","Epoch 48/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2809 - accuracy: 0.6969 - val_loss: 1.3088 - val_accuracy: 0.6715\n","Epoch 49/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2654 - accuracy: 0.7088 - val_loss: 1.2992 - val_accuracy: 0.6705\n","Epoch 50/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2588 - accuracy: 0.7065 - val_loss: 1.3012 - val_accuracy: 0.6705\n","Epoch 51/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2542 - accuracy: 0.7003 - val_loss: 1.2944 - val_accuracy: 0.6684\n","Epoch 52/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2453 - accuracy: 0.7052 - val_loss: 1.2788 - val_accuracy: 0.6725\n","Epoch 53/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2378 - accuracy: 0.7026 - val_loss: 1.3165 - val_accuracy: 0.6384\n","Epoch 54/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2343 - accuracy: 0.6977 - val_loss: 1.2928 - val_accuracy: 0.6405\n","Epoch 55/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2236 - accuracy: 0.7028 - val_loss: 1.2525 - val_accuracy: 0.6705\n","Epoch 56/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2145 - accuracy: 0.7075 - val_loss: 1.2499 - val_accuracy: 0.6736\n","Epoch 57/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2097 - accuracy: 0.7008 - val_loss: 1.2398 - val_accuracy: 0.6746\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1993 - accuracy: 0.7119 - val_loss: 1.2318 - val_accuracy: 0.6725\n","Epoch 59/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1896 - accuracy: 0.7121 - val_loss: 1.2262 - val_accuracy: 0.6725\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1863 - accuracy: 0.7054 - val_loss: 1.2186 - val_accuracy: 0.6736\n","Epoch 61/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1755 - accuracy: 0.7078 - val_loss: 1.2119 - val_accuracy: 0.6715\n","Epoch 62/100\n","31/31 [==============================] - 2s 54ms/step - loss: 1.1712 - accuracy: 0.7085 - val_loss: 1.2074 - val_accuracy: 0.6777\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1645 - accuracy: 0.7178 - val_loss: 1.2242 - val_accuracy: 0.6612\n","Epoch 64/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1652 - accuracy: 0.7028 - val_loss: 1.1959 - val_accuracy: 0.6715\n","Epoch 65/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1503 - accuracy: 0.7129 - val_loss: 1.1891 - val_accuracy: 0.6746\n","Epoch 66/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.1447 - accuracy: 0.7147 - val_loss: 1.1978 - val_accuracy: 0.6684\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1407 - accuracy: 0.7083 - val_loss: 1.1848 - val_accuracy: 0.6705\n","Epoch 68/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1339 - accuracy: 0.7142 - val_loss: 1.1741 - val_accuracy: 0.6725\n","Epoch 69/100\n","31/31 [==============================] - 1s 28ms/step - loss: 1.1288 - accuracy: 0.7152 - val_loss: 1.1637 - val_accuracy: 0.6798\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1197 - accuracy: 0.7132 - val_loss: 1.1600 - val_accuracy: 0.6787\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1146 - accuracy: 0.7132 - val_loss: 1.1603 - val_accuracy: 0.6777\n","Epoch 72/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1149 - accuracy: 0.7093 - val_loss: 1.1472 - val_accuracy: 0.6787\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1034 - accuracy: 0.7176 - val_loss: 1.1449 - val_accuracy: 0.6787\n","Epoch 74/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.0973 - accuracy: 0.7158 - val_loss: 1.1369 - val_accuracy: 0.6808\n","Epoch 75/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0926 - accuracy: 0.7145 - val_loss: 1.1322 - val_accuracy: 0.6829\n","Epoch 76/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0881 - accuracy: 0.7140 - val_loss: 1.1273 - val_accuracy: 0.6798\n","Epoch 77/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0845 - accuracy: 0.7150 - val_loss: 1.1303 - val_accuracy: 0.6808\n","Epoch 78/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0834 - accuracy: 0.7085 - val_loss: 1.1169 - val_accuracy: 0.6808\n","Epoch 79/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0741 - accuracy: 0.7158 - val_loss: 1.1188 - val_accuracy: 0.6880\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0699 - accuracy: 0.7158 - val_loss: 1.1102 - val_accuracy: 0.6860\n","Epoch 81/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0619 - accuracy: 0.7165 - val_loss: 1.1019 - val_accuracy: 0.6839\n","Epoch 82/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0624 - accuracy: 0.7119 - val_loss: 1.0977 - val_accuracy: 0.6849\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0634 - accuracy: 0.7124 - val_loss: 1.1068 - val_accuracy: 0.6829\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0511 - accuracy: 0.7165 - val_loss: 1.0890 - val_accuracy: 0.6860\n","Epoch 85/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0455 - accuracy: 0.7140 - val_loss: 1.1028 - val_accuracy: 0.6777\n","Epoch 86/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0487 - accuracy: 0.7070 - val_loss: 1.0805 - val_accuracy: 0.6818\n","Epoch 87/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0368 - accuracy: 0.7230 - val_loss: 1.0771 - val_accuracy: 0.6808\n","Epoch 88/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0307 - accuracy: 0.7233 - val_loss: 1.0758 - val_accuracy: 0.6787\n","Epoch 89/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0249 - accuracy: 0.7279 - val_loss: 1.0744 - val_accuracy: 0.6787\n","Epoch 90/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0260 - accuracy: 0.7171 - val_loss: 1.0660 - val_accuracy: 0.6808\n","Epoch 91/100\n","31/31 [==============================] - 1s 28ms/step - loss: 1.0165 - accuracy: 0.7269 - val_loss: 1.0627 - val_accuracy: 0.6890\n","Epoch 92/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0132 - accuracy: 0.7243 - val_loss: 1.0587 - val_accuracy: 0.6798\n","Epoch 93/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0096 - accuracy: 0.7212 - val_loss: 1.0543 - val_accuracy: 0.6870\n","Epoch 94/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0062 - accuracy: 0.7230 - val_loss: 1.0512 - val_accuracy: 0.6839\n","Epoch 95/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0024 - accuracy: 0.7227 - val_loss: 1.0472 - val_accuracy: 0.6890\n","Epoch 96/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.9999 - accuracy: 0.7271 - val_loss: 1.0497 - val_accuracy: 0.6901\n","Epoch 97/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9935 - accuracy: 0.7258 - val_loss: 1.0438 - val_accuracy: 0.6870\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9899 - accuracy: 0.7248 - val_loss: 1.0396 - val_accuracy: 0.6818\n","Epoch 99/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9870 - accuracy: 0.7276 - val_loss: 1.0321 - val_accuracy: 0.6860\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9918 - accuracy: 0.7207 - val_loss: 1.0293 - val_accuracy: 0.6849\n","{'loss': [2.0086119174957275, 1.9769319295883179, 1.9456050395965576, 1.9137378931045532, 1.8821719884872437, 1.8506014347076416, 1.823496699333191, 1.8019356727600098, 1.7818421125411987, 1.7538604736328125, 1.7403508424758911, 1.7145856618881226, 1.698290467262268, 1.6811299324035645, 1.663849115371704, 1.6467522382736206, 1.6313360929489136, 1.618704915046692, 1.6012009382247925, 1.5846935510635376, 1.57038414478302, 1.556705355644226, 1.5422720909118652, 1.5290741920471191, 1.5185285806655884, 1.5060726404190063, 1.490545630455017, 1.4848062992095947, 1.4675397872924805, 1.457160472869873, 1.4439234733581543, 1.4304840564727783, 1.421197533607483, 1.4086483716964722, 1.3967053890228271, 1.3920021057128906, 1.377153754234314, 1.366765022277832, 1.3588621616363525, 1.3465995788574219, 1.3404834270477295, 1.3277226686477661, 1.3186273574829102, 1.3100193738937378, 1.3041540384292603, 1.2954448461532593, 1.2838032245635986, 1.2808500528335571, 1.265447735786438, 1.2588467597961426, 1.2541886568069458, 1.2452778816223145, 1.2378160953521729, 1.2342524528503418, 1.2236263751983643, 1.2144737243652344, 1.2097349166870117, 1.1992568969726562, 1.1895803213119507, 1.1863083839416504, 1.1754661798477173, 1.1712191104888916, 1.1644673347473145, 1.1652191877365112, 1.1503067016601562, 1.1446523666381836, 1.1406707763671875, 1.1338764429092407, 1.1288232803344727, 1.1196751594543457, 1.1145589351654053, 1.1149168014526367, 1.1033636331558228, 1.0973273515701294, 1.092581868171692, 1.0880695581436157, 1.0845032930374146, 1.0834450721740723, 1.074054479598999, 1.0698635578155518, 1.06187105178833, 1.062369704246521, 1.063369870185852, 1.0511428117752075, 1.0454922914505005, 1.0486606359481812, 1.0367640256881714, 1.0307347774505615, 1.0249354839324951, 1.0259569883346558, 1.0164666175842285, 1.0131577253341675, 1.0096406936645508, 1.006231427192688, 1.0024105310440063, 0.9998971819877625, 0.9934580326080322, 0.9898865222930908, 0.9869892001152039, 0.9918346405029297], 'accuracy': [0.5413436889648438, 0.632041335105896, 0.6483204364776611, 0.6692506670951843, 0.6705426573753357, 0.6801033616065979, 0.6718346476554871, 0.6640827059745789, 0.6658914685249329, 0.685012936592102, 0.6746770143508911, 0.6875969171524048, 0.6863049268722534, 0.6860465407371521, 0.6842377185821533, 0.6901808977127075, 0.6878553032875061, 0.6844961047172546, 0.6956072449684143, 0.6930232644081116, 0.6956072449684143, 0.695348858833313, 0.6992248296737671, 0.6935400366783142, 0.6919896602630615, 0.6943152546882629, 0.698966383934021, 0.6798449754714966, 0.6935400366783142, 0.6948320269584656, 0.6948320269584656, 0.7046511769294739, 0.6948320269584656, 0.7015503644943237, 0.6992248296737671, 0.6968992352485657, 0.7018088102340698, 0.7020671963691711, 0.7005168199539185, 0.7043927907943726, 0.6976743936538696, 0.7036175727844238, 0.7007752060890198, 0.7023255825042725, 0.7036175727844238, 0.6987079977989197, 0.7062015533447266, 0.6968992352485657, 0.7087855339050293, 0.7064599394798279, 0.7002583742141724, 0.7051679491996765, 0.7025839686393738, 0.6976743936538696, 0.7028423547744751, 0.7074935436248779, 0.7007752060890198, 0.7118862867355347, 0.7121447324752808, 0.7054263353347778, 0.7077519297599792, 0.708527147769928, 0.7178294658660889, 0.7028423547744751, 0.7129198908805847, 0.7147286534309387, 0.7082687616348267, 0.7142118811607361, 0.7152454853057861, 0.713178277015686, 0.713178277015686, 0.7093023061752319, 0.7175710797309875, 0.7157622575759888, 0.7144702672958374, 0.7139534950256348, 0.7149870991706848, 0.708527147769928, 0.7157622575759888, 0.7157622575759888, 0.7165374755859375, 0.7118862867355347, 0.7124031186103821, 0.7165374755859375, 0.7139534950256348, 0.7069767713546753, 0.7229974269866943, 0.7232558131217957, 0.7279070019721985, 0.7170542478561401, 0.7268733978271484, 0.7242894172668457, 0.7211886048316956, 0.7229974269866943, 0.722739040851593, 0.7271317839622498, 0.7258397936820984, 0.7248061895370483, 0.7276485562324524, 0.7206718325614929], 'val_loss': [2.002200126647949, 1.9811910390853882, 1.960027813911438, 1.939260721206665, 1.918768048286438, 1.8975422382354736, 1.8781455755233765, 1.8558751344680786, 1.83677339553833, 1.8194924592971802, 1.7960374355316162, 1.7729054689407349, 1.7554535865783691, 1.7364400625228882, 1.7119181156158447, 1.687488079071045, 1.675309181213379, 1.6478389501571655, 1.6301580667495728, 1.6123647689819336, 1.5948224067687988, 1.5872784852981567, 1.5650559663772583, 1.5518194437026978, 1.5444411039352417, 1.5282361507415771, 1.5177963972091675, 1.5019303560256958, 1.4919768571853638, 1.4811320304870605, 1.468011736869812, 1.4588059186935425, 1.4455578327178955, 1.435539960861206, 1.4249716997146606, 1.4139008522033691, 1.4048445224761963, 1.3997554779052734, 1.3856362104415894, 1.3849754333496094, 1.3670530319213867, 1.3576828241348267, 1.3487818241119385, 1.3392925262451172, 1.3328824043273926, 1.3244493007659912, 1.3252298831939697, 1.308763027191162, 1.2992357015609741, 1.301177978515625, 1.2944203615188599, 1.2788190841674805, 1.3164865970611572, 1.292790174484253, 1.2525063753128052, 1.2498527765274048, 1.2398453950881958, 1.2318477630615234, 1.2261781692504883, 1.2186253070831299, 1.2119479179382324, 1.207403540611267, 1.224190592765808, 1.195923089981079, 1.1890568733215332, 1.1978318691253662, 1.1847702264785767, 1.1740775108337402, 1.1637187004089355, 1.1600245237350464, 1.1603171825408936, 1.147223711013794, 1.1448708772659302, 1.136885404586792, 1.1321632862091064, 1.1273037195205688, 1.1302865743637085, 1.1169203519821167, 1.1187634468078613, 1.110172152519226, 1.1019062995910645, 1.097705602645874, 1.106801986694336, 1.0889928340911865, 1.102799892425537, 1.0804530382156372, 1.077109932899475, 1.0758047103881836, 1.0743885040283203, 1.0660178661346436, 1.0627027750015259, 1.0587291717529297, 1.0543240308761597, 1.0512100458145142, 1.0471750497817993, 1.0496834516525269, 1.0438257455825806, 1.0396196842193604, 1.0320820808410645, 1.0292644500732422], 'val_accuracy': [0.6425619721412659, 0.48553720116615295, 0.6363636255264282, 0.6435950398445129, 0.5919421315193176, 0.6528925895690918, 0.5681818127632141, 0.6611570119857788, 0.6435950398445129, 0.5557851195335388, 0.6477272510528564, 0.6466942429542542, 0.6466942429542542, 0.6311983466148376, 0.6528925895690918, 0.66425621509552, 0.6497933864593506, 0.6549586653709412, 0.66425621509552, 0.6694214940071106, 0.6735537052154541, 0.6601239442825317, 0.6745867729187012, 0.6766529083251953, 0.6621900796890259, 0.6704545617103577, 0.663223147392273, 0.6663222908973694, 0.66425621509552, 0.6704545617103577, 0.672520637512207, 0.6652892827987671, 0.6683884263038635, 0.6694214940071106, 0.6663222908973694, 0.6735537052154541, 0.672520637512207, 0.6673553586006165, 0.6704545617103577, 0.6704545617103577, 0.6663222908973694, 0.66425621509552, 0.6704545617103577, 0.672520637512207, 0.6714876294136047, 0.6704545617103577, 0.6683884263038635, 0.6714876294136047, 0.6704545617103577, 0.6704545617103577, 0.6683884263038635, 0.672520637512207, 0.6384297609329224, 0.6404958963394165, 0.6704545617103577, 0.6735537052154541, 0.6745867729187012, 0.672520637512207, 0.672520637512207, 0.6735537052154541, 0.6714876294136047, 0.6776859760284424, 0.6611570119857788, 0.6714876294136047, 0.6745867729187012, 0.6683884263038635, 0.6704545617103577, 0.672520637512207, 0.6797520518302917, 0.6787189841270447, 0.6776859760284424, 0.6787189841270447, 0.6787189841270447, 0.6807851195335388, 0.682851254940033, 0.6797520518302917, 0.6807851195335388, 0.6807851195335388, 0.6880165338516235, 0.6859503984451294, 0.68388432264328, 0.6849173307418823, 0.682851254940033, 0.6859503984451294, 0.6776859760284424, 0.6818181872367859, 0.6807851195335388, 0.6787189841270447, 0.6787189841270447, 0.6807851195335388, 0.6890496015548706, 0.6797520518302917, 0.6869834661483765, 0.68388432264328, 0.6890496015548706, 0.6900826692581177, 0.6869834661483765, 0.6818181872367859, 0.6859503984451294, 0.6849173307418823]}\n","32/32 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 1.0230 - accuracy: 0.7098"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 4s 36ms/step - loss: 1.0224 - accuracy: 0.7101 - val_loss: 1.1396 - val_accuracy: 0.4914\n","Epoch 2/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0160 - accuracy: 0.7152 - val_loss: 1.1344 - val_accuracy: 0.4903\n","Epoch 3/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0072 - accuracy: 0.7152 - val_loss: 1.1294 - val_accuracy: 0.4914\n","Epoch 4/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0022 - accuracy: 0.7134 - val_loss: 1.1251 - val_accuracy: 0.4871\n","Epoch 5/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9960 - accuracy: 0.7206 - val_loss: 1.1196 - val_accuracy: 0.4914\n","Epoch 6/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9936 - accuracy: 0.7179 - val_loss: 1.1228 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9922 - accuracy: 0.7091 - val_loss: 1.1131 - val_accuracy: 0.4860\n","Epoch 8/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9830 - accuracy: 0.7196 - val_loss: 1.1066 - val_accuracy: 0.4914\n","Epoch 9/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.9790 - accuracy: 0.7209 - val_loss: 1.1003 - val_accuracy: 0.4968\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9832 - accuracy: 0.7131 - val_loss: 1.1106 - val_accuracy: 0.4849\n","Epoch 11/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9730 - accuracy: 0.7174 - val_loss: 1.1194 - val_accuracy: 0.4849\n","Epoch 12/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9753 - accuracy: 0.7115 - val_loss: 1.0943 - val_accuracy: 0.4925\n","Epoch 13/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.9650 - accuracy: 0.7214 - val_loss: 1.0904 - val_accuracy: 0.4989\n","Epoch 14/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.9648 - accuracy: 0.7228 - val_loss: 1.0753 - val_accuracy: 0.5269\n","Epoch 15/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9570 - accuracy: 0.7231 - val_loss: 1.0792 - val_accuracy: 0.5162\n","Epoch 16/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.9529 - accuracy: 0.7220 - val_loss: 1.0706 - val_accuracy: 0.5366\n","Epoch 17/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.9510 - accuracy: 0.7276 - val_loss: 1.0333 - val_accuracy: 0.6164\n","Epoch 18/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.9468 - accuracy: 0.7290 - val_loss: 1.0245 - val_accuracy: 0.6207\n","Epoch 19/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9453 - accuracy: 0.7282 - val_loss: 1.0337 - val_accuracy: 0.5991\n","Epoch 20/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.9495 - accuracy: 0.7209 - val_loss: 1.0092 - val_accuracy: 0.6390\n","Epoch 21/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9386 - accuracy: 0.7249 - val_loss: 1.0110 - val_accuracy: 0.6336\n","Epoch 22/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9380 - accuracy: 0.7263 - val_loss: 0.9686 - val_accuracy: 0.7155\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9426 - accuracy: 0.7182 - val_loss: 1.0000 - val_accuracy: 0.6444\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9332 - accuracy: 0.7247 - val_loss: 0.9670 - val_accuracy: 0.7015\n","Epoch 25/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9279 - accuracy: 0.7311 - val_loss: 0.9543 - val_accuracy: 0.7155\n","Epoch 26/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9282 - accuracy: 0.7252 - val_loss: 0.9699 - val_accuracy: 0.6821\n","Epoch 27/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.9245 - accuracy: 0.7322 - val_loss: 0.9434 - val_accuracy: 0.7241\n","Epoch 28/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.9218 - accuracy: 0.7274 - val_loss: 0.9400 - val_accuracy: 0.7274\n","Epoch 29/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9213 - accuracy: 0.7303 - val_loss: 0.9372 - val_accuracy: 0.7241\n","Epoch 30/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9179 - accuracy: 0.7309 - val_loss: 0.9387 - val_accuracy: 0.7177\n","Epoch 31/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9134 - accuracy: 0.7314 - val_loss: 0.9340 - val_accuracy: 0.7209\n","Epoch 32/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9119 - accuracy: 0.7333 - val_loss: 0.9512 - val_accuracy: 0.6907\n","Epoch 33/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9133 - accuracy: 0.7311 - val_loss: 0.9408 - val_accuracy: 0.7091\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9105 - accuracy: 0.7303 - val_loss: 0.9260 - val_accuracy: 0.7209\n","Epoch 35/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9085 - accuracy: 0.7244 - val_loss: 0.9251 - val_accuracy: 0.7231\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9013 - accuracy: 0.7352 - val_loss: 0.9233 - val_accuracy: 0.7263\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9016 - accuracy: 0.7387 - val_loss: 0.9249 - val_accuracy: 0.7188\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9035 - accuracy: 0.7293 - val_loss: 0.9225 - val_accuracy: 0.7209\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8965 - accuracy: 0.7390 - val_loss: 0.9187 - val_accuracy: 0.7220\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8946 - accuracy: 0.7330 - val_loss: 0.9251 - val_accuracy: 0.7188\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8919 - accuracy: 0.7346 - val_loss: 0.9143 - val_accuracy: 0.7274\n","Epoch 42/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8895 - accuracy: 0.7365 - val_loss: 0.9116 - val_accuracy: 0.7263\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8858 - accuracy: 0.7408 - val_loss: 0.9206 - val_accuracy: 0.7177\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8845 - accuracy: 0.7384 - val_loss: 0.9100 - val_accuracy: 0.7198\n","Epoch 45/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.8825 - accuracy: 0.7352 - val_loss: 0.9073 - val_accuracy: 0.7284\n","Epoch 46/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8837 - accuracy: 0.7403 - val_loss: 0.9140 - val_accuracy: 0.7198\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8799 - accuracy: 0.7373 - val_loss: 0.9058 - val_accuracy: 0.7263\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8764 - accuracy: 0.7408 - val_loss: 0.9207 - val_accuracy: 0.7080\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8776 - accuracy: 0.7311 - val_loss: 0.9152 - val_accuracy: 0.7134\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8734 - accuracy: 0.7422 - val_loss: 0.9143 - val_accuracy: 0.7144\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8710 - accuracy: 0.7416 - val_loss: 0.9175 - val_accuracy: 0.7037\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8687 - accuracy: 0.7435 - val_loss: 0.9106 - val_accuracy: 0.7198\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8662 - accuracy: 0.7422 - val_loss: 0.8987 - val_accuracy: 0.7220\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8631 - accuracy: 0.7441 - val_loss: 0.8996 - val_accuracy: 0.7220\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8605 - accuracy: 0.7454 - val_loss: 0.8936 - val_accuracy: 0.7284\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8595 - accuracy: 0.7438 - val_loss: 0.8999 - val_accuracy: 0.7177\n","Epoch 57/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.8586 - accuracy: 0.7430 - val_loss: 0.8932 - val_accuracy: 0.7306\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8555 - accuracy: 0.7473 - val_loss: 0.8902 - val_accuracy: 0.7231\n","Epoch 59/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8530 - accuracy: 0.7487 - val_loss: 0.8889 - val_accuracy: 0.7274\n","Epoch 60/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8563 - accuracy: 0.7484 - val_loss: 0.9123 - val_accuracy: 0.7015\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8580 - accuracy: 0.7373 - val_loss: 0.8860 - val_accuracy: 0.7284\n","Epoch 62/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8487 - accuracy: 0.7478 - val_loss: 0.8862 - val_accuracy: 0.7220\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8462 - accuracy: 0.7435 - val_loss: 0.8849 - val_accuracy: 0.7274\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8472 - accuracy: 0.7446 - val_loss: 0.8994 - val_accuracy: 0.7123\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8432 - accuracy: 0.7516 - val_loss: 0.8849 - val_accuracy: 0.7306\n","Epoch 66/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8450 - accuracy: 0.7460 - val_loss: 0.8810 - val_accuracy: 0.7263\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8428 - accuracy: 0.7465 - val_loss: 0.9149 - val_accuracy: 0.6843\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8375 - accuracy: 0.7513 - val_loss: 0.8809 - val_accuracy: 0.7274\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8399 - accuracy: 0.7503 - val_loss: 0.8853 - val_accuracy: 0.7177\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8308 - accuracy: 0.7538 - val_loss: 0.8755 - val_accuracy: 0.7263\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8306 - accuracy: 0.7476 - val_loss: 0.9097 - val_accuracy: 0.6875\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8413 - accuracy: 0.7468 - val_loss: 0.8740 - val_accuracy: 0.7284\n","Epoch 73/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.8264 - accuracy: 0.7575 - val_loss: 0.8760 - val_accuracy: 0.7317\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8259 - accuracy: 0.7532 - val_loss: 0.8711 - val_accuracy: 0.7317\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8319 - accuracy: 0.7535 - val_loss: 0.8697 - val_accuracy: 0.7284\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8209 - accuracy: 0.7546 - val_loss: 0.8684 - val_accuracy: 0.7295\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8175 - accuracy: 0.7640 - val_loss: 0.8696 - val_accuracy: 0.7231\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8176 - accuracy: 0.7559 - val_loss: 0.8683 - val_accuracy: 0.7274\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8140 - accuracy: 0.7608 - val_loss: 0.8678 - val_accuracy: 0.7231\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8152 - accuracy: 0.7605 - val_loss: 0.8758 - val_accuracy: 0.7177\n","Epoch 81/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.8151 - accuracy: 0.7586 - val_loss: 0.8638 - val_accuracy: 0.7338\n","Epoch 82/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8067 - accuracy: 0.7632 - val_loss: 0.8626 - val_accuracy: 0.7252\n","Epoch 83/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8089 - accuracy: 0.7654 - val_loss: 0.8632 - val_accuracy: 0.7295\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8071 - accuracy: 0.7592 - val_loss: 0.8627 - val_accuracy: 0.7317\n","Epoch 85/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8087 - accuracy: 0.7645 - val_loss: 0.8599 - val_accuracy: 0.7295\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8050 - accuracy: 0.7635 - val_loss: 0.8653 - val_accuracy: 0.7263\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8019 - accuracy: 0.7664 - val_loss: 0.8902 - val_accuracy: 0.6940\n","Epoch 88/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8006 - accuracy: 0.7624 - val_loss: 0.8798 - val_accuracy: 0.7101\n","Epoch 89/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7998 - accuracy: 0.7632 - val_loss: 0.8626 - val_accuracy: 0.7209\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7945 - accuracy: 0.7656 - val_loss: 0.8825 - val_accuracy: 0.7123\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7958 - accuracy: 0.7694 - val_loss: 0.8664 - val_accuracy: 0.7188\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8072 - accuracy: 0.7557 - val_loss: 0.8556 - val_accuracy: 0.7284\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7930 - accuracy: 0.7640 - val_loss: 0.8532 - val_accuracy: 0.7306\n","Epoch 94/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7889 - accuracy: 0.7664 - val_loss: 0.8543 - val_accuracy: 0.7209\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7951 - accuracy: 0.7648 - val_loss: 0.8534 - val_accuracy: 0.7284\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7873 - accuracy: 0.7659 - val_loss: 0.8534 - val_accuracy: 0.7263\n","Epoch 97/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7826 - accuracy: 0.7734 - val_loss: 0.8510 - val_accuracy: 0.7284\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7804 - accuracy: 0.7737 - val_loss: 0.8585 - val_accuracy: 0.7263\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7782 - accuracy: 0.7761 - val_loss: 0.8564 - val_accuracy: 0.7231\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7866 - accuracy: 0.7610 - val_loss: 0.8481 - val_accuracy: 0.7284\n","{'loss': [1.0223548412322998, 1.0160248279571533, 1.00716233253479, 1.002214789390564, 0.9960236549377441, 0.993594765663147, 0.9921713471412659, 0.9830252528190613, 0.9790427684783936, 0.9831984043121338, 0.9730154871940613, 0.9753372073173523, 0.964999794960022, 0.964823842048645, 0.9570126533508301, 0.952877938747406, 0.9509543776512146, 0.9468066692352295, 0.9453434944152832, 0.9494587182998657, 0.9385964870452881, 0.9380312561988831, 0.9425718784332275, 0.933165967464447, 0.9279393553733826, 0.9281555414199829, 0.9245218634605408, 0.9217853546142578, 0.9212938547134399, 0.9179238677024841, 0.9134155511856079, 0.9118806719779968, 0.9133152961730957, 0.9104753136634827, 0.9085264801979065, 0.9013441205024719, 0.9016120433807373, 0.9034703969955444, 0.8965399265289307, 0.8945550322532654, 0.8918578028678894, 0.889496922492981, 0.8857731223106384, 0.8844574093818665, 0.8825352191925049, 0.8837061524391174, 0.8799412250518799, 0.8763726353645325, 0.877640962600708, 0.8733975887298584, 0.8709631562232971, 0.8687373995780945, 0.8662362694740295, 0.8631497621536255, 0.8605406284332275, 0.859454333782196, 0.8586253523826599, 0.8555131554603577, 0.8530471324920654, 0.8562911748886108, 0.8579519987106323, 0.8486685752868652, 0.8462241888046265, 0.847242534160614, 0.8432339429855347, 0.8450338840484619, 0.8427709937095642, 0.8374577164649963, 0.8399112224578857, 0.8307929039001465, 0.8305984139442444, 0.8412723541259766, 0.8264327049255371, 0.8258780241012573, 0.8318511843681335, 0.8208754062652588, 0.8174672722816467, 0.8175880908966064, 0.813993513584137, 0.8151662349700928, 0.815092146396637, 0.8067440986633301, 0.8088533878326416, 0.8071229457855225, 0.8087112903594971, 0.8049858212471008, 0.8018766641616821, 0.8005508184432983, 0.7998047471046448, 0.7944660186767578, 0.7957901358604431, 0.8071733117103577, 0.7930226922035217, 0.7889137864112854, 0.7951133847236633, 0.7872986197471619, 0.782619297504425, 0.7803518176078796, 0.7781636714935303, 0.7865841388702393], 'accuracy': [0.7101293206214905, 0.7152478694915771, 0.7152478694915771, 0.7133620977401733, 0.7206357717514038, 0.7179418206214905, 0.7090517282485962, 0.7195581793785095, 0.7209051847457886, 0.7130926847457886, 0.717402994632721, 0.7114762663841248, 0.7214439511299133, 0.7227909564971924, 0.7230603694915771, 0.7219827771186829, 0.7276400923728943, 0.7289870977401733, 0.728178858757019, 0.7209051847457886, 0.724946141242981, 0.7262930870056152, 0.7182112336158752, 0.7246767282485962, 0.7311422228813171, 0.725215494632721, 0.7322198152542114, 0.7273706793785095, 0.7303340435028076, 0.7308728694915771, 0.7314116358757019, 0.7332974076271057, 0.7311422228813171, 0.7303340435028076, 0.7244073152542114, 0.7351831793785095, 0.7386853694915771, 0.7292564511299133, 0.7389547228813171, 0.733027994632721, 0.7346444129943848, 0.7365301847457886, 0.740840494632721, 0.7384159564971924, 0.7351831793785095, 0.7403017282485962, 0.7373383641242981, 0.740840494632721, 0.7311422228813171, 0.7421875, 0.7416487336158752, 0.743534505367279, 0.7421875, 0.7440732717514038, 0.7454202771186829, 0.743803858757019, 0.7429956793785095, 0.7473060488700867, 0.748652994632721, 0.748383641242981, 0.7373383641242981, 0.7478448152542114, 0.743534505367279, 0.7446120977401733, 0.751616358757019, 0.7459590435028076, 0.7464978694915771, 0.751347005367279, 0.7502694129943848, 0.7537715435028076, 0.7475754022598267, 0.7467672228813171, 0.7575430870056152, 0.7532327771186829, 0.7535021305084229, 0.7545797228813171, 0.764008641242981, 0.7559267282485962, 0.7607758641242981, 0.7605064511299133, 0.7586206793785095, 0.7632004022598267, 0.7653555870056152, 0.759159505367279, 0.7645474076271057, 0.7634698152542114, 0.7664331793785095, 0.7623922228813171, 0.7632004022598267, 0.765625, 0.7693965435028076, 0.7556573152542114, 0.764008641242981, 0.7664331793785095, 0.7648168206214905, 0.7658944129943848, 0.7734375, 0.7737069129943848, 0.7761314511299133, 0.7610452771186829], 'val_loss': [1.1395764350891113, 1.1344338655471802, 1.129353642463684, 1.125125527381897, 1.1196188926696777, 1.1228294372558594, 1.1131346225738525, 1.1065634489059448, 1.1003044843673706, 1.110588788986206, 1.1193832159042358, 1.0942565202713013, 1.0904306173324585, 1.0752642154693604, 1.0792354345321655, 1.0705634355545044, 1.0332791805267334, 1.024549961090088, 1.033677339553833, 1.0092447996139526, 1.0110493898391724, 0.9685820937156677, 0.9999585151672363, 0.9669747948646545, 0.9543054103851318, 0.9698638319969177, 0.9433525800704956, 0.9399762153625488, 0.9371809363365173, 0.9387476444244385, 0.9340285658836365, 0.9511662125587463, 0.9408186078071594, 0.9259622097015381, 0.9250993132591248, 0.9233145713806152, 0.9249352216720581, 0.9224754571914673, 0.9186659455299377, 0.9251005053520203, 0.9143463373184204, 0.911608874797821, 0.9206485748291016, 0.9099547266960144, 0.9073284864425659, 0.913986086845398, 0.9057839512825012, 0.9207183718681335, 0.915208637714386, 0.9143114686012268, 0.9175047874450684, 0.9105629324913025, 0.8986519575119019, 0.8995990753173828, 0.8936300873756409, 0.8998881578445435, 0.8932429552078247, 0.8901832699775696, 0.8889113664627075, 0.912254810333252, 0.8859907984733582, 0.8861979842185974, 0.8849323391914368, 0.8994151949882507, 0.8848732709884644, 0.8810019493103027, 0.9149426817893982, 0.880940854549408, 0.8853251934051514, 0.8754916191101074, 0.90972900390625, 0.8740131258964539, 0.8759871125221252, 0.8710607886314392, 0.8696649074554443, 0.8684433698654175, 0.8696281313896179, 0.8683053851127625, 0.8678207397460938, 0.8757550716400146, 0.863793134689331, 0.8626225590705872, 0.8631947636604309, 0.8627113699913025, 0.8598693609237671, 0.8653373718261719, 0.8901873230934143, 0.8797662854194641, 0.8625906705856323, 0.8825467228889465, 0.866423487663269, 0.8556486964225769, 0.8532132506370544, 0.8542786836624146, 0.8534417152404785, 0.8533697724342346, 0.8510133028030396, 0.8584634065628052, 0.8564252257347107, 0.8481304049491882], 'val_accuracy': [0.4913793206214905, 0.4903017282485962, 0.4913793206214905, 0.48706895112991333, 0.4913793206214905, 0.48491379618644714, 0.48599138855934143, 0.4913793206214905, 0.4967672526836395, 0.48491379618644714, 0.48491379618644714, 0.4924568831920624, 0.4989224076271057, 0.5269396305084229, 0.5161637663841248, 0.5366379022598267, 0.6163793206214905, 0.6206896305084229, 0.5991379022598267, 0.639008641242981, 0.6336206793785095, 0.7155172228813171, 0.6443965435028076, 0.701508641242981, 0.7155172228813171, 0.6821120977401733, 0.7241379022598267, 0.7273706793785095, 0.7241379022598267, 0.7176724076271057, 0.7209051847457886, 0.6907327771186829, 0.7090517282485962, 0.7209051847457886, 0.7230603694915771, 0.7262930870056152, 0.71875, 0.7209051847457886, 0.7219827771186829, 0.71875, 0.7273706793785095, 0.7262930870056152, 0.7176724076271057, 0.7198275923728943, 0.7284482717514038, 0.7198275923728943, 0.7262930870056152, 0.7079741358757019, 0.7133620977401733, 0.7144396305084229, 0.7036637663841248, 0.7198275923728943, 0.7219827771186829, 0.7219827771186829, 0.7284482717514038, 0.7176724076271057, 0.7306034564971924, 0.7230603694915771, 0.7273706793785095, 0.701508641242981, 0.7284482717514038, 0.7219827771186829, 0.7273706793785095, 0.712284505367279, 0.7306034564971924, 0.7262930870056152, 0.6842672228813171, 0.7273706793785095, 0.7176724076271057, 0.7262930870056152, 0.6875, 0.7284482717514038, 0.7316810488700867, 0.7316810488700867, 0.7284482717514038, 0.7295258641242981, 0.7230603694915771, 0.7273706793785095, 0.7230603694915771, 0.7176724076271057, 0.7338362336158752, 0.725215494632721, 0.7295258641242981, 0.7316810488700867, 0.7295258641242981, 0.7262930870056152, 0.693965494632721, 0.7101293206214905, 0.7209051847457886, 0.712284505367279, 0.71875, 0.7284482717514038, 0.7306034564971924, 0.7209051847457886, 0.7284482717514038, 0.7262930870056152, 0.7284482717514038, 0.7262930870056152, 0.7230603694915771, 0.7284482717514038]}\n","38/38 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 1.0453 - accuracy: 0.6839"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 4s 37ms/step - loss: 1.0453 - accuracy: 0.6839 - val_loss: 1.1397 - val_accuracy: 0.5113\n","Epoch 2/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0305 - accuracy: 0.6989 - val_loss: 1.1349 - val_accuracy: 0.5011\n","Epoch 3/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.0253 - accuracy: 0.7003 - val_loss: 1.1297 - val_accuracy: 0.5136\n","Epoch 4/100\n","28/28 [==============================] - 1s 31ms/step - loss: 1.0156 - accuracy: 0.7054 - val_loss: 1.1244 - val_accuracy: 0.5249\n","Epoch 5/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.0141 - accuracy: 0.7003 - val_loss: 1.1198 - val_accuracy: 0.5238\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0122 - accuracy: 0.7018 - val_loss: 1.1166 - val_accuracy: 0.5011\n","Epoch 7/100\n","28/28 [==============================] - 1s 34ms/step - loss: 1.0057 - accuracy: 0.7040 - val_loss: 1.1098 - val_accuracy: 0.5271\n","Epoch 8/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.9990 - accuracy: 0.7063 - val_loss: 1.1031 - val_accuracy: 0.5814\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9931 - accuracy: 0.7131 - val_loss: 1.1034 - val_accuracy: 0.5057\n","Epoch 10/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9905 - accuracy: 0.7097 - val_loss: 1.0943 - val_accuracy: 0.5373\n","Epoch 11/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9868 - accuracy: 0.7117 - val_loss: 1.0890 - val_accuracy: 0.5407\n","Epoch 12/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9818 - accuracy: 0.7111 - val_loss: 1.0812 - val_accuracy: 0.5713\n","Epoch 13/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9779 - accuracy: 0.7091 - val_loss: 1.0772 - val_accuracy: 0.5554\n","Epoch 14/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9763 - accuracy: 0.7111 - val_loss: 1.0774 - val_accuracy: 0.5373\n","Epoch 15/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9726 - accuracy: 0.7162 - val_loss: 1.0639 - val_accuracy: 0.5792\n","Epoch 16/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9684 - accuracy: 0.7080 - val_loss: 1.0604 - val_accuracy: 0.5701\n","Epoch 17/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9661 - accuracy: 0.7170 - val_loss: 1.0490 - val_accuracy: 0.5984\n","Epoch 18/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.9658 - accuracy: 0.7119 - val_loss: 1.0433 - val_accuracy: 0.6075\n","Epoch 19/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9625 - accuracy: 0.7117 - val_loss: 1.0376 - val_accuracy: 0.6109\n","Epoch 20/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9600 - accuracy: 0.7173 - val_loss: 1.0105 - val_accuracy: 0.6878\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9507 - accuracy: 0.7190 - val_loss: 1.0146 - val_accuracy: 0.6448\n","Epoch 22/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.9511 - accuracy: 0.7151 - val_loss: 0.9939 - val_accuracy: 0.6957\n","Epoch 23/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9489 - accuracy: 0.7151 - val_loss: 0.9912 - val_accuracy: 0.6833\n","Epoch 24/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.9426 - accuracy: 0.7207 - val_loss: 0.9723 - val_accuracy: 0.7115\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9399 - accuracy: 0.7252 - val_loss: 0.9738 - val_accuracy: 0.7002\n","Epoch 26/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9395 - accuracy: 0.7227 - val_loss: 0.9695 - val_accuracy: 0.7014\n","Epoch 27/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.9373 - accuracy: 0.7216 - val_loss: 0.9585 - val_accuracy: 0.7195\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9369 - accuracy: 0.7199 - val_loss: 0.9552 - val_accuracy: 0.7172\n","Epoch 29/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.9307 - accuracy: 0.7216 - val_loss: 0.9504 - val_accuracy: 0.7206\n","Epoch 30/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9294 - accuracy: 0.7241 - val_loss: 0.9491 - val_accuracy: 0.7206\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9243 - accuracy: 0.7320 - val_loss: 0.9471 - val_accuracy: 0.7172\n","Epoch 32/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.9227 - accuracy: 0.7233 - val_loss: 0.9435 - val_accuracy: 0.7229\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9197 - accuracy: 0.7250 - val_loss: 0.9434 - val_accuracy: 0.7172\n","Epoch 34/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9180 - accuracy: 0.7284 - val_loss: 0.9395 - val_accuracy: 0.7206\n","Epoch 35/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9142 - accuracy: 0.7258 - val_loss: 0.9372 - val_accuracy: 0.7195\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9114 - accuracy: 0.7326 - val_loss: 0.9363 - val_accuracy: 0.7183\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9092 - accuracy: 0.7284 - val_loss: 0.9390 - val_accuracy: 0.7149\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9127 - accuracy: 0.7258 - val_loss: 0.9316 - val_accuracy: 0.7229\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9075 - accuracy: 0.7281 - val_loss: 0.9344 - val_accuracy: 0.7115\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9022 - accuracy: 0.7326 - val_loss: 0.9350 - val_accuracy: 0.7183\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9047 - accuracy: 0.7312 - val_loss: 0.9388 - val_accuracy: 0.7014\n","Epoch 42/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9027 - accuracy: 0.7337 - val_loss: 0.9257 - val_accuracy: 0.7217\n","Epoch 43/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.8985 - accuracy: 0.7315 - val_loss: 0.9245 - val_accuracy: 0.7240\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8926 - accuracy: 0.7363 - val_loss: 0.9226 - val_accuracy: 0.7240\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8925 - accuracy: 0.7326 - val_loss: 0.9221 - val_accuracy: 0.7240\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8880 - accuracy: 0.7326 - val_loss: 0.9350 - val_accuracy: 0.6991\n","Epoch 47/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.8877 - accuracy: 0.7391 - val_loss: 0.9192 - val_accuracy: 0.7285\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8830 - accuracy: 0.7383 - val_loss: 0.9154 - val_accuracy: 0.7262\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8845 - accuracy: 0.7351 - val_loss: 0.9214 - val_accuracy: 0.7127\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8868 - accuracy: 0.7334 - val_loss: 0.9120 - val_accuracy: 0.7274\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8774 - accuracy: 0.7374 - val_loss: 0.9123 - val_accuracy: 0.7240\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8787 - accuracy: 0.7408 - val_loss: 0.9103 - val_accuracy: 0.7274\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8715 - accuracy: 0.7445 - val_loss: 0.9121 - val_accuracy: 0.7183\n","Epoch 54/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8729 - accuracy: 0.7380 - val_loss: 0.9126 - val_accuracy: 0.7115\n","Epoch 55/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8692 - accuracy: 0.7408 - val_loss: 0.9052 - val_accuracy: 0.7262\n","Epoch 56/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8662 - accuracy: 0.7425 - val_loss: 0.9060 - val_accuracy: 0.7206\n","Epoch 57/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8643 - accuracy: 0.7490 - val_loss: 0.9038 - val_accuracy: 0.7274\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8624 - accuracy: 0.7504 - val_loss: 0.9024 - val_accuracy: 0.7251\n","Epoch 59/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8595 - accuracy: 0.7462 - val_loss: 0.9009 - val_accuracy: 0.7262\n","Epoch 60/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.8614 - accuracy: 0.7400 - val_loss: 0.9165 - val_accuracy: 0.7115\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8568 - accuracy: 0.7479 - val_loss: 0.9160 - val_accuracy: 0.6900\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8570 - accuracy: 0.7462 - val_loss: 0.8963 - val_accuracy: 0.7262\n","Epoch 63/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8491 - accuracy: 0.7513 - val_loss: 0.8966 - val_accuracy: 0.7240\n","Epoch 64/100\n","28/28 [==============================] - 2s 59ms/step - loss: 0.8473 - accuracy: 0.7524 - val_loss: 0.8971 - val_accuracy: 0.7319\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8499 - accuracy: 0.7434 - val_loss: 0.9229 - val_accuracy: 0.7036\n","Epoch 66/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8502 - accuracy: 0.7431 - val_loss: 0.8928 - val_accuracy: 0.7172\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8451 - accuracy: 0.7547 - val_loss: 0.9148 - val_accuracy: 0.7048\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8422 - accuracy: 0.7564 - val_loss: 0.8993 - val_accuracy: 0.7115\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8389 - accuracy: 0.7569 - val_loss: 0.8902 - val_accuracy: 0.7296\n","Epoch 70/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8375 - accuracy: 0.7581 - val_loss: 0.8892 - val_accuracy: 0.7251\n","Epoch 71/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8363 - accuracy: 0.7600 - val_loss: 0.8958 - val_accuracy: 0.7149\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8333 - accuracy: 0.7566 - val_loss: 0.8901 - val_accuracy: 0.7206\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8347 - accuracy: 0.7603 - val_loss: 0.8874 - val_accuracy: 0.7183\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8275 - accuracy: 0.7612 - val_loss: 0.8881 - val_accuracy: 0.7183\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8273 - accuracy: 0.7612 - val_loss: 0.8904 - val_accuracy: 0.7149\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8251 - accuracy: 0.7561 - val_loss: 0.8958 - val_accuracy: 0.7104\n","Epoch 77/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8206 - accuracy: 0.7688 - val_loss: 0.9081 - val_accuracy: 0.6765\n","Epoch 78/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8257 - accuracy: 0.7592 - val_loss: 0.8786 - val_accuracy: 0.7319\n","Epoch 79/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8167 - accuracy: 0.7666 - val_loss: 0.8769 - val_accuracy: 0.7285\n","Epoch 80/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8162 - accuracy: 0.7660 - val_loss: 0.9003 - val_accuracy: 0.7059\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8162 - accuracy: 0.7589 - val_loss: 0.8780 - val_accuracy: 0.7262\n","Epoch 82/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8086 - accuracy: 0.7694 - val_loss: 0.8780 - val_accuracy: 0.7217\n","Epoch 83/100\n","28/28 [==============================] - 2s 62ms/step - loss: 0.8142 - accuracy: 0.7617 - val_loss: 0.8740 - val_accuracy: 0.7330\n","Epoch 84/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8069 - accuracy: 0.7694 - val_loss: 0.8736 - val_accuracy: 0.7330\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8085 - accuracy: 0.7677 - val_loss: 0.8744 - val_accuracy: 0.7217\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8012 - accuracy: 0.7731 - val_loss: 0.8731 - val_accuracy: 0.7262\n","Epoch 87/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.7988 - accuracy: 0.7790 - val_loss: 0.8697 - val_accuracy: 0.7387\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8046 - accuracy: 0.7680 - val_loss: 0.8727 - val_accuracy: 0.7251\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8037 - accuracy: 0.7694 - val_loss: 0.9076 - val_accuracy: 0.7048\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8177 - accuracy: 0.7487 - val_loss: 0.8722 - val_accuracy: 0.7285\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8015 - accuracy: 0.7623 - val_loss: 0.8746 - val_accuracy: 0.7138\n","Epoch 92/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7935 - accuracy: 0.7708 - val_loss: 0.8653 - val_accuracy: 0.7387\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7917 - accuracy: 0.7750 - val_loss: 0.8678 - val_accuracy: 0.7262\n","Epoch 94/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7902 - accuracy: 0.7733 - val_loss: 0.8649 - val_accuracy: 0.7319\n","Epoch 95/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7920 - accuracy: 0.7677 - val_loss: 0.8666 - val_accuracy: 0.7285\n","Epoch 96/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7879 - accuracy: 0.7753 - val_loss: 0.8812 - val_accuracy: 0.6946\n","Epoch 97/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7855 - accuracy: 0.7722 - val_loss: 0.8604 - val_accuracy: 0.7387\n","Epoch 98/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7834 - accuracy: 0.7765 - val_loss: 0.8715 - val_accuracy: 0.7195\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7813 - accuracy: 0.7784 - val_loss: 0.8617 - val_accuracy: 0.7342\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7810 - accuracy: 0.7765 - val_loss: 0.8698 - val_accuracy: 0.7217\n","{'loss': [1.0453073978424072, 1.0305365324020386, 1.025321125984192, 1.0155878067016602, 1.0140924453735352, 1.012150526046753, 1.005670189857483, 0.9990124106407166, 0.9930688738822937, 0.99051833152771, 0.9867579340934753, 0.9818044304847717, 0.9778698086738586, 0.9763206243515015, 0.972626805305481, 0.9683583378791809, 0.9661368727684021, 0.9658321142196655, 0.9624540209770203, 0.9600212574005127, 0.9506637454032898, 0.9510566592216492, 0.9488843083381653, 0.9426174759864807, 0.9398559331893921, 0.9394927024841309, 0.937343180179596, 0.9368775486946106, 0.9306820034980774, 0.9293908476829529, 0.9242550730705261, 0.9226940274238586, 0.91971755027771, 0.9180278182029724, 0.9141801595687866, 0.9114458560943604, 0.9092094898223877, 0.9127436876296997, 0.9074745178222656, 0.9022250175476074, 0.904674232006073, 0.9027243256568909, 0.8984764218330383, 0.8926038146018982, 0.8924868106842041, 0.8879905939102173, 0.8876897692680359, 0.8829777240753174, 0.8845287561416626, 0.8868481516838074, 0.8773608803749084, 0.8786988854408264, 0.8714909553527832, 0.8728868961334229, 0.8691934943199158, 0.8662014603614807, 0.8642563819885254, 0.8624433279037476, 0.8594533801078796, 0.8614068031311035, 0.856787919998169, 0.8570420742034912, 0.8490892648696899, 0.8473303318023682, 0.8499172925949097, 0.8502169847488403, 0.8450976014137268, 0.842205286026001, 0.8388658165931702, 0.8375332355499268, 0.8362767100334167, 0.833336591720581, 0.8347250819206238, 0.8275445103645325, 0.8273035287857056, 0.8250906467437744, 0.820553719997406, 0.8257027864456177, 0.8166526556015015, 0.8162446618080139, 0.8162425756454468, 0.8085817694664001, 0.8141942024230957, 0.8068749308586121, 0.8085116744041443, 0.8012399077415466, 0.7987914681434631, 0.8046207427978516, 0.803666353225708, 0.8177222013473511, 0.8015162348747253, 0.7934674620628357, 0.7916545867919922, 0.7902480959892273, 0.7920137643814087, 0.7878924608230591, 0.7854936718940735, 0.7833989858627319, 0.7813247442245483, 0.7810430526733398], 'accuracy': [0.6839275360107422, 0.698924720287323, 0.7003395557403564, 0.7054329514503479, 0.7003395557403564, 0.7017543911933899, 0.7040181159973145, 0.706281840801239, 0.7130730152130127, 0.7096773982048035, 0.7116581797599792, 0.7110922336578369, 0.7091115117073059, 0.7110922336578369, 0.7161856293678284, 0.7079796195030212, 0.7170345187187195, 0.711941123008728, 0.7116581797599792, 0.7173174619674683, 0.7190153002738953, 0.7150537371635437, 0.7150537371635437, 0.7207130789756775, 0.7252405285835266, 0.7226938605308533, 0.7215619683265686, 0.7198641896247864, 0.7215619683265686, 0.7241086363792419, 0.7320317029953003, 0.7232597470283508, 0.7249575257301331, 0.7283531427383423, 0.725806474685669, 0.7325976490974426, 0.7283531427383423, 0.725806474685669, 0.7280701994895935, 0.7325976490974426, 0.7311828136444092, 0.7337294816970825, 0.731465756893158, 0.7362761497497559, 0.7325976490974426, 0.7325976490974426, 0.7391058206558228, 0.7382569313049316, 0.735144317150116, 0.7334465384483337, 0.7374080419540405, 0.740803599357605, 0.744482159614563, 0.7379739880561829, 0.740803599357605, 0.742501437664032, 0.7490096092224121, 0.7504244446754456, 0.7461799383163452, 0.7399547100067139, 0.7478777766227722, 0.7461799383163452, 0.7512733340263367, 0.7524052262306213, 0.7433503270149231, 0.7430673241615295, 0.7546689510345459, 0.7563667297363281, 0.7569326758384705, 0.7580645084381104, 0.7600452899932861, 0.7566496729850769, 0.7603282332420349, 0.761177122592926, 0.761177122592926, 0.7560837864875793, 0.7688171863555908, 0.759196400642395, 0.7665534615516663, 0.7659875750541687, 0.7589133977890015, 0.7693831324577332, 0.7617430686950684, 0.7693831324577332, 0.7676853537559509, 0.7730616927146912, 0.7790039777755737, 0.7679682970046997, 0.7693831324577332, 0.7487266659736633, 0.7623090147972107, 0.7707979679107666, 0.7750424742698669, 0.7733446359634399, 0.7676853537559509, 0.7753254175186157, 0.7722128033638, 0.7764572501182556, 0.7784380316734314, 0.7764572501182556], 'val_loss': [1.139661431312561, 1.1349225044250488, 1.1297264099121094, 1.124405860900879, 1.1197597980499268, 1.116637945175171, 1.109846830368042, 1.1030887365341187, 1.1034233570098877, 1.094342589378357, 1.0890400409698486, 1.0812175273895264, 1.0771760940551758, 1.0774177312850952, 1.0639435052871704, 1.0604135990142822, 1.049032211303711, 1.04329514503479, 1.0376380681991577, 1.010453701019287, 1.0145646333694458, 0.9939103722572327, 0.9912100434303284, 0.972256600856781, 0.9737575054168701, 0.9695352911949158, 0.958504319190979, 0.9552221298217773, 0.9503680467605591, 0.9491346478462219, 0.9470675587654114, 0.9435428380966187, 0.9434322714805603, 0.9395133852958679, 0.9371944069862366, 0.9363142848014832, 0.9390193223953247, 0.9316197633743286, 0.9343762397766113, 0.9349551796913147, 0.9387722015380859, 0.9256535768508911, 0.9244723320007324, 0.9226030111312866, 0.9221038222312927, 0.935024619102478, 0.9191533923149109, 0.9154350757598877, 0.9214469194412231, 0.9119717478752136, 0.9122923612594604, 0.9103429913520813, 0.912122905254364, 0.9126269817352295, 0.9052355885505676, 0.905973494052887, 0.9037635326385498, 0.9023904204368591, 0.9008868336677551, 0.9164559841156006, 0.9160455465316772, 0.8963102698326111, 0.8966301679611206, 0.8971349596977234, 0.922926127910614, 0.8928287625312805, 0.9148306250572205, 0.8992925882339478, 0.8902343511581421, 0.8891587853431702, 0.8958360552787781, 0.8901070356369019, 0.8873986005783081, 0.8880733847618103, 0.8903780579566956, 0.8957971334457397, 0.9080836176872253, 0.8786278367042542, 0.8769168853759766, 0.9002590179443359, 0.878027617931366, 0.8780456781387329, 0.8740427494049072, 0.873641848564148, 0.8743573427200317, 0.8731106519699097, 0.8696882724761963, 0.87271648645401, 0.9076188206672668, 0.8722289800643921, 0.8746057748794556, 0.8653022050857544, 0.8678398728370667, 0.8648682832717896, 0.8665981292724609, 0.8812097907066345, 0.8603911399841309, 0.8714964985847473, 0.8617117404937744, 0.8697580695152283], 'val_accuracy': [0.5113122463226318, 0.5011312365531921, 0.5135746598243713, 0.5248869061470032, 0.523755669593811, 0.5011312365531921, 0.5271493196487427, 0.581447958946228, 0.5056561231613159, 0.5373303294181824, 0.540723979473114, 0.5712669491767883, 0.5554298758506775, 0.5373303294181824, 0.5791855454444885, 0.570135772228241, 0.598416268825531, 0.6074660420417786, 0.610859751701355, 0.6877828240394592, 0.6447963714599609, 0.6957013607025146, 0.6832579374313354, 0.7115384340286255, 0.7002262473106384, 0.7013574838638306, 0.7194570302963257, 0.7171945571899414, 0.720588207244873, 0.720588207244873, 0.7171945571899414, 0.7228506803512573, 0.7171945571899414, 0.720588207244873, 0.7194570302963257, 0.7183257937431335, 0.7149321436882019, 0.7228506803512573, 0.7115384340286255, 0.7183257937431335, 0.7013574838638306, 0.7217194437980652, 0.7239819169044495, 0.7239819169044495, 0.7239819169044495, 0.6990950107574463, 0.7285068035125732, 0.726244330406189, 0.7126696705818176, 0.7273755669593811, 0.7239819169044495, 0.7273755669593811, 0.7183257937431335, 0.7115384340286255, 0.726244330406189, 0.720588207244873, 0.7273755669593811, 0.7251130938529968, 0.726244330406189, 0.7115384340286255, 0.6900452375411987, 0.726244330406189, 0.7239819169044495, 0.7319004535675049, 0.7036198973655701, 0.7171945571899414, 0.7047511339187622, 0.7115384340286255, 0.7296379804611206, 0.7251130938529968, 0.7149321436882019, 0.720588207244873, 0.7183257937431335, 0.7183257937431335, 0.7149321436882019, 0.7104072570800781, 0.6764705777168274, 0.7319004535675049, 0.7285068035125732, 0.7058823704719543, 0.726244330406189, 0.7217194437980652, 0.733031690120697, 0.733031690120697, 0.7217194437980652, 0.726244330406189, 0.7386877536773682, 0.7251130938529968, 0.7047511339187622, 0.7285068035125732, 0.7138009071350098, 0.7386877536773682, 0.726244330406189, 0.7319004535675049, 0.7285068035125732, 0.6945701241493225, 0.7386877536773682, 0.7194570302963257, 0.7341628670692444, 0.7217194437980652]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 1.0279 - accuracy: 0.6984"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 5s 35ms/step - loss: 1.0288 - accuracy: 0.6977 - val_loss: 1.1401 - val_accuracy: 0.4917\n","Epoch 2/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0154 - accuracy: 0.7065 - val_loss: 1.1351 - val_accuracy: 0.4876\n","Epoch 3/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.0129 - accuracy: 0.7026 - val_loss: 1.1295 - val_accuracy: 0.4959\n","Epoch 4/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0045 - accuracy: 0.7103 - val_loss: 1.1239 - val_accuracy: 0.5062\n","Epoch 5/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9991 - accuracy: 0.7121 - val_loss: 1.1212 - val_accuracy: 0.4886\n","Epoch 6/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9958 - accuracy: 0.7034 - val_loss: 1.1122 - val_accuracy: 0.5279\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9891 - accuracy: 0.7137 - val_loss: 1.1065 - val_accuracy: 0.5351\n","Epoch 8/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9848 - accuracy: 0.7127 - val_loss: 1.1015 - val_accuracy: 0.5269\n","Epoch 9/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9784 - accuracy: 0.7163 - val_loss: 1.0949 - val_accuracy: 0.5362\n","Epoch 10/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9735 - accuracy: 0.7183 - val_loss: 1.0922 - val_accuracy: 0.5217\n","Epoch 11/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9732 - accuracy: 0.7155 - val_loss: 1.0928 - val_accuracy: 0.5041\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9672 - accuracy: 0.7121 - val_loss: 1.0750 - val_accuracy: 0.5610\n","Epoch 13/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9630 - accuracy: 0.7140 - val_loss: 1.0652 - val_accuracy: 0.6043\n","Epoch 14/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9587 - accuracy: 0.7160 - val_loss: 1.0592 - val_accuracy: 0.6023\n","Epoch 15/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.9574 - accuracy: 0.7191 - val_loss: 1.0474 - val_accuracy: 0.6260\n","Epoch 16/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9557 - accuracy: 0.7142 - val_loss: 1.0403 - val_accuracy: 0.6322\n","Epoch 17/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.9494 - accuracy: 0.7186 - val_loss: 1.0358 - val_accuracy: 0.6333\n","Epoch 18/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9446 - accuracy: 0.7212 - val_loss: 1.0179 - val_accuracy: 0.6539\n","Epoch 19/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9402 - accuracy: 0.7194 - val_loss: 1.0156 - val_accuracy: 0.6550\n","Epoch 20/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9432 - accuracy: 0.7132 - val_loss: 1.0180 - val_accuracy: 0.6498\n","Epoch 21/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9371 - accuracy: 0.7196 - val_loss: 0.9813 - val_accuracy: 0.6911\n","Epoch 22/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9326 - accuracy: 0.7240 - val_loss: 0.9756 - val_accuracy: 0.7025\n","Epoch 23/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9320 - accuracy: 0.7256 - val_loss: 0.9879 - val_accuracy: 0.6674\n","Epoch 24/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9281 - accuracy: 0.7243 - val_loss: 0.9833 - val_accuracy: 0.6736\n","Epoch 25/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9244 - accuracy: 0.7240 - val_loss: 0.9635 - val_accuracy: 0.6911\n","Epoch 26/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9213 - accuracy: 0.7287 - val_loss: 0.9609 - val_accuracy: 0.6901\n","Epoch 27/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9205 - accuracy: 0.7251 - val_loss: 0.9645 - val_accuracy: 0.6911\n","Epoch 28/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9224 - accuracy: 0.7222 - val_loss: 0.9590 - val_accuracy: 0.6849\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9141 - accuracy: 0.7271 - val_loss: 0.9520 - val_accuracy: 0.6921\n","Epoch 30/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9130 - accuracy: 0.7266 - val_loss: 0.9848 - val_accuracy: 0.6705\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9104 - accuracy: 0.7225 - val_loss: 0.9490 - val_accuracy: 0.6973\n","Epoch 32/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9035 - accuracy: 0.7328 - val_loss: 0.9613 - val_accuracy: 0.6963\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9036 - accuracy: 0.7310 - val_loss: 0.9484 - val_accuracy: 0.6839\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8991 - accuracy: 0.7328 - val_loss: 0.9942 - val_accuracy: 0.6550\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9041 - accuracy: 0.7251 - val_loss: 0.9485 - val_accuracy: 0.6994\n","Epoch 36/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8974 - accuracy: 0.7326 - val_loss: 0.9381 - val_accuracy: 0.6963\n","Epoch 37/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8951 - accuracy: 0.7326 - val_loss: 0.9359 - val_accuracy: 0.7014\n","Epoch 38/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8885 - accuracy: 0.7375 - val_loss: 0.9524 - val_accuracy: 0.6983\n","Epoch 39/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8952 - accuracy: 0.7230 - val_loss: 0.9334 - val_accuracy: 0.6880\n","Epoch 40/100\n","31/31 [==============================] - 2s 57ms/step - loss: 0.8866 - accuracy: 0.7408 - val_loss: 0.9447 - val_accuracy: 0.7066\n","Epoch 41/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8881 - accuracy: 0.7313 - val_loss: 0.9288 - val_accuracy: 0.6942\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8817 - accuracy: 0.7349 - val_loss: 0.9307 - val_accuracy: 0.6901\n","Epoch 43/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8810 - accuracy: 0.7331 - val_loss: 0.9569 - val_accuracy: 0.6674\n","Epoch 44/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8855 - accuracy: 0.7292 - val_loss: 0.9241 - val_accuracy: 0.6952\n","Epoch 45/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8721 - accuracy: 0.7408 - val_loss: 0.9213 - val_accuracy: 0.7025\n","Epoch 46/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8756 - accuracy: 0.7349 - val_loss: 0.9231 - val_accuracy: 0.6942\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8770 - accuracy: 0.7292 - val_loss: 0.9236 - val_accuracy: 0.7035\n","Epoch 48/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8761 - accuracy: 0.7362 - val_loss: 0.9155 - val_accuracy: 0.6952\n","Epoch 49/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8668 - accuracy: 0.7401 - val_loss: 0.9196 - val_accuracy: 0.6901\n","Epoch 50/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8628 - accuracy: 0.7439 - val_loss: 0.9270 - val_accuracy: 0.7076\n","Epoch 51/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8643 - accuracy: 0.7401 - val_loss: 0.9344 - val_accuracy: 0.6715\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8606 - accuracy: 0.7385 - val_loss: 0.9297 - val_accuracy: 0.6715\n","Epoch 53/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8598 - accuracy: 0.7416 - val_loss: 0.9129 - val_accuracy: 0.6952\n","Epoch 54/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8545 - accuracy: 0.7434 - val_loss: 0.9075 - val_accuracy: 0.6994\n","Epoch 55/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8506 - accuracy: 0.7468 - val_loss: 0.9078 - val_accuracy: 0.7035\n","Epoch 56/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8516 - accuracy: 0.7468 - val_loss: 0.9030 - val_accuracy: 0.7035\n","Epoch 57/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8495 - accuracy: 0.7380 - val_loss: 0.9058 - val_accuracy: 0.7035\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8520 - accuracy: 0.7426 - val_loss: 0.9219 - val_accuracy: 0.7004\n","Epoch 59/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8482 - accuracy: 0.7450 - val_loss: 0.9185 - val_accuracy: 0.7097\n","Epoch 60/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8427 - accuracy: 0.7545 - val_loss: 0.8977 - val_accuracy: 0.7097\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8504 - accuracy: 0.7346 - val_loss: 0.9078 - val_accuracy: 0.6921\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8391 - accuracy: 0.7450 - val_loss: 0.8960 - val_accuracy: 0.7056\n","Epoch 63/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8376 - accuracy: 0.7478 - val_loss: 0.8976 - val_accuracy: 0.6952\n","Epoch 64/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8362 - accuracy: 0.7470 - val_loss: 0.8932 - val_accuracy: 0.7014\n","Epoch 65/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8318 - accuracy: 0.7535 - val_loss: 0.8945 - val_accuracy: 0.6994\n","Epoch 66/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8286 - accuracy: 0.7537 - val_loss: 0.8891 - val_accuracy: 0.7138\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8259 - accuracy: 0.7548 - val_loss: 0.8885 - val_accuracy: 0.7118\n","Epoch 68/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.8270 - accuracy: 0.7486 - val_loss: 0.8874 - val_accuracy: 0.7159\n","Epoch 69/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8227 - accuracy: 0.7496 - val_loss: 0.8895 - val_accuracy: 0.7045\n","Epoch 70/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8219 - accuracy: 0.7556 - val_loss: 0.8851 - val_accuracy: 0.7076\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8225 - accuracy: 0.7537 - val_loss: 0.8830 - val_accuracy: 0.7138\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8200 - accuracy: 0.7592 - val_loss: 0.8833 - val_accuracy: 0.7056\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8171 - accuracy: 0.7522 - val_loss: 0.8947 - val_accuracy: 0.6880\n","Epoch 74/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8166 - accuracy: 0.7566 - val_loss: 0.8897 - val_accuracy: 0.6839\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8139 - accuracy: 0.7576 - val_loss: 0.8796 - val_accuracy: 0.7066\n","Epoch 76/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8168 - accuracy: 0.7535 - val_loss: 0.8778 - val_accuracy: 0.7128\n","Epoch 77/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8170 - accuracy: 0.7537 - val_loss: 0.8755 - val_accuracy: 0.7097\n","Epoch 78/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8042 - accuracy: 0.7641 - val_loss: 0.8781 - val_accuracy: 0.7107\n","Epoch 79/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8053 - accuracy: 0.7618 - val_loss: 0.8741 - val_accuracy: 0.7118\n","Epoch 80/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8023 - accuracy: 0.7553 - val_loss: 0.8857 - val_accuracy: 0.7066\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8058 - accuracy: 0.7610 - val_loss: 0.8716 - val_accuracy: 0.7087\n","Epoch 82/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8012 - accuracy: 0.7636 - val_loss: 0.8695 - val_accuracy: 0.7180\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7972 - accuracy: 0.7713 - val_loss: 0.8754 - val_accuracy: 0.7087\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7961 - accuracy: 0.7638 - val_loss: 0.8707 - val_accuracy: 0.7097\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7927 - accuracy: 0.7700 - val_loss: 0.8689 - val_accuracy: 0.7159\n","Epoch 86/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7950 - accuracy: 0.7651 - val_loss: 0.8690 - val_accuracy: 0.7180\n","Epoch 87/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7913 - accuracy: 0.7708 - val_loss: 0.8893 - val_accuracy: 0.6983\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8003 - accuracy: 0.7506 - val_loss: 0.8672 - val_accuracy: 0.7128\n","Epoch 89/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7886 - accuracy: 0.7674 - val_loss: 0.8644 - val_accuracy: 0.7149\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7850 - accuracy: 0.7685 - val_loss: 0.8693 - val_accuracy: 0.7107\n","Epoch 91/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7828 - accuracy: 0.7680 - val_loss: 0.8638 - val_accuracy: 0.7159\n","Epoch 92/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7792 - accuracy: 0.7734 - val_loss: 0.8626 - val_accuracy: 0.7149\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7770 - accuracy: 0.7773 - val_loss: 0.8740 - val_accuracy: 0.6901\n","Epoch 94/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7767 - accuracy: 0.7749 - val_loss: 0.8656 - val_accuracy: 0.7025\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7796 - accuracy: 0.7698 - val_loss: 0.8640 - val_accuracy: 0.7045\n","Epoch 96/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7752 - accuracy: 0.7698 - val_loss: 0.8659 - val_accuracy: 0.6921\n","Epoch 97/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7702 - accuracy: 0.7817 - val_loss: 0.8607 - val_accuracy: 0.7045\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7733 - accuracy: 0.7749 - val_loss: 0.8760 - val_accuracy: 0.7056\n","Epoch 99/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7742 - accuracy: 0.7669 - val_loss: 0.8603 - val_accuracy: 0.7128\n","Epoch 100/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7657 - accuracy: 0.7747 - val_loss: 0.8557 - val_accuracy: 0.7149\n","{'loss': [1.028801441192627, 1.0153658390045166, 1.0128815174102783, 1.004517912864685, 0.9991227388381958, 0.995751678943634, 0.9890661239624023, 0.9847938418388367, 0.9783746004104614, 0.9734906554222107, 0.9731704592704773, 0.9671674966812134, 0.9630321264266968, 0.9587304592132568, 0.9573802947998047, 0.9556969404220581, 0.9493899345397949, 0.9446028470993042, 0.9402269721031189, 0.9432433247566223, 0.9371107220649719, 0.9325887560844421, 0.9320415258407593, 0.9280725121498108, 0.9243909120559692, 0.9212607741355896, 0.9204579591751099, 0.922416090965271, 0.9140617847442627, 0.9129654169082642, 0.910367488861084, 0.903539776802063, 0.903566837310791, 0.899133563041687, 0.9040505290031433, 0.8973608613014221, 0.8951377272605896, 0.8885412812232971, 0.8952006101608276, 0.8866156339645386, 0.888086199760437, 0.881701648235321, 0.8810405135154724, 0.885528564453125, 0.8720858097076416, 0.8756497502326965, 0.8770239949226379, 0.8760616183280945, 0.8668467998504639, 0.8627935647964478, 0.8643243908882141, 0.8606132864952087, 0.8597951531410217, 0.8545128703117371, 0.8505991697311401, 0.8516207933425903, 0.8495043516159058, 0.8520451784133911, 0.8482467532157898, 0.8427399396896362, 0.8504210710525513, 0.8391389846801758, 0.8375885486602783, 0.8362099528312683, 0.8317919373512268, 0.8286348581314087, 0.8259415626525879, 0.8270025253295898, 0.822719156742096, 0.8218927383422852, 0.8224642872810364, 0.8200358748435974, 0.8170915842056274, 0.816584050655365, 0.8139140605926514, 0.8168423771858215, 0.8169553279876709, 0.8042031526565552, 0.8053104281425476, 0.8022884130477905, 0.8057517409324646, 0.8011612296104431, 0.7971774339675903, 0.7961488962173462, 0.7926580905914307, 0.794961154460907, 0.7912986278533936, 0.800304114818573, 0.7885820865631104, 0.7849519848823547, 0.782798171043396, 0.7791550755500793, 0.7769594788551331, 0.7766655087471008, 0.7795602083206177, 0.7752012014389038, 0.7702057957649231, 0.7732707858085632, 0.7741519808769226, 0.7657323479652405], 'accuracy': [0.6976743936538696, 0.7064599394798279, 0.7025839686393738, 0.710335910320282, 0.7121447324752808, 0.7033591866493225, 0.7136951088905334, 0.7126615047454834, 0.7162790894508362, 0.7183462381362915, 0.7155038714408875, 0.7121447324752808, 0.7139534950256348, 0.7160206437110901, 0.7191214561462402, 0.7142118811607361, 0.7186046242713928, 0.7211886048316956, 0.7193798422813416, 0.713178277015686, 0.7196382284164429, 0.7240310311317444, 0.7255814075469971, 0.7242894172668457, 0.7240310311317444, 0.7286821603775024, 0.7250645756721497, 0.7222222089767456, 0.7271317839622498, 0.7266150116920471, 0.7224805951118469, 0.7328165173530579, 0.7310077548027039, 0.7328165173530579, 0.7250645756721497, 0.7325581312179565, 0.7325581312179565, 0.7374677062034607, 0.7229974269866943, 0.7408268451690674, 0.7312661409378052, 0.734883725643158, 0.733074963092804, 0.7291989922523499, 0.7408268451690674, 0.734883725643158, 0.7291989922523499, 0.7361757159233093, 0.7400516867637634, 0.7439276576042175, 0.7400516867637634, 0.7385013103485107, 0.7416020631790161, 0.7434108257293701, 0.7467700242996216, 0.7467700242996216, 0.7379844784736633, 0.7426356673240662, 0.7449612617492676, 0.7545219659805298, 0.7346253395080566, 0.7449612617492676, 0.7478036284446716, 0.7470284104347229, 0.7534883618354797, 0.753746747970581, 0.7547803521156311, 0.7485787868499756, 0.7496123909950256, 0.7555555701255798, 0.753746747970581, 0.7591731548309326, 0.7521963715553284, 0.7565891742706299, 0.7576227188110352, 0.7534883618354797, 0.753746747970581, 0.764082670211792, 0.7617571353912354, 0.7552971839904785, 0.7609819173812866, 0.7635658979415894, 0.7713178396224976, 0.7638242840766907, 0.7700258493423462, 0.765116274356842, 0.7708010077476501, 0.7506459951400757, 0.7674418687820435, 0.7684754729270935, 0.7679586410522461, 0.7733849883079529, 0.777260959148407, 0.7749354243278503, 0.7697674632072449, 0.7697674632072449, 0.7816537618637085, 0.7749354243278503, 0.766925036907196, 0.7746769785881042], 'val_loss': [1.1400889158248901, 1.1351325511932373, 1.1294821500778198, 1.1239187717437744, 1.1212141513824463, 1.112227439880371, 1.1065242290496826, 1.1015455722808838, 1.09488844871521, 1.0921655893325806, 1.092785358428955, 1.074993371963501, 1.0651570558547974, 1.0591909885406494, 1.0473641157150269, 1.040260910987854, 1.0357975959777832, 1.0178779363632202, 1.0155718326568604, 1.0179980993270874, 0.9813210964202881, 0.9756089448928833, 0.9879358410835266, 0.983291745185852, 0.9634573459625244, 0.9608823657035828, 0.9645390510559082, 0.9589731097221375, 0.9520202875137329, 0.9848288893699646, 0.9489985704421997, 0.9613131880760193, 0.9484378695487976, 0.9941717982292175, 0.948493480682373, 0.9381433129310608, 0.9359346628189087, 0.952382504940033, 0.93338543176651, 0.9447091817855835, 0.9288328886032104, 0.930735170841217, 0.9569113254547119, 0.9240781664848328, 0.9213102459907532, 0.9230670928955078, 0.9235898852348328, 0.9154673218727112, 0.9196237325668335, 0.9270238876342773, 0.9344318509101868, 0.9297176003456116, 0.9128883481025696, 0.9075042009353638, 0.9078070521354675, 0.9029908776283264, 0.905799925327301, 0.921917736530304, 0.9184600710868835, 0.8976534008979797, 0.9078026413917542, 0.8959643244743347, 0.8975685238838196, 0.893225371837616, 0.8945038318634033, 0.8890891671180725, 0.8884923458099365, 0.8873656988143921, 0.8895144462585449, 0.8850755095481873, 0.883041501045227, 0.8833426237106323, 0.8947387933731079, 0.8896985054016113, 0.8795690536499023, 0.8777563571929932, 0.8754894733428955, 0.8780739903450012, 0.874091625213623, 0.8856777548789978, 0.8716362118721008, 0.8694508075714111, 0.8753780126571655, 0.8707401752471924, 0.8688639402389526, 0.869047999382019, 0.8893190622329712, 0.867240309715271, 0.8644453883171082, 0.8692792057991028, 0.8637603521347046, 0.8625861406326294, 0.8739603161811829, 0.8655687570571899, 0.8639997839927673, 0.8658532500267029, 0.8606585264205933, 0.8759730458259583, 0.860291600227356, 0.8556973934173584], 'val_accuracy': [0.4917355477809906, 0.4876033067703247, 0.4958677589893341, 0.5061983466148376, 0.4886363744735718, 0.5278925895690918, 0.5351239442825317, 0.5268595218658447, 0.5361570119857788, 0.5216942429542542, 0.5041322112083435, 0.5609503984451294, 0.6043388247489929, 0.6022727489471436, 0.6260330677032471, 0.6322314143180847, 0.6332644820213318, 0.6539255976676941, 0.6549586653709412, 0.6497933864593506, 0.69111567735672, 0.702479362487793, 0.6673553586006165, 0.6735537052154541, 0.69111567735672, 0.6900826692581177, 0.69111567735672, 0.6849173307418823, 0.692148745059967, 0.6704545617103577, 0.6973140239715576, 0.6962810158729553, 0.68388432264328, 0.6549586653709412, 0.6993801593780518, 0.6962810158729553, 0.7014462947845459, 0.6983470916748047, 0.6880165338516235, 0.7066115736961365, 0.6942148804664612, 0.6900826692581177, 0.6673553586006165, 0.6952479481697083, 0.702479362487793, 0.6942148804664612, 0.7035123705863953, 0.6952479481697083, 0.6900826692581177, 0.7076446413993835, 0.6714876294136047, 0.6714876294136047, 0.6952479481697083, 0.6993801593780518, 0.7035123705863953, 0.7035123705863953, 0.7035123705863953, 0.7004132270812988, 0.7097107172012329, 0.7097107172012329, 0.692148745059967, 0.7055785059928894, 0.6952479481697083, 0.7014462947845459, 0.6993801593780518, 0.7138429880142212, 0.711776852607727, 0.7159090638160706, 0.7045454382896423, 0.7076446413993835, 0.7138429880142212, 0.7055785059928894, 0.6880165338516235, 0.68388432264328, 0.7066115736961365, 0.7128099203109741, 0.7097107172012329, 0.71074378490448, 0.711776852607727, 0.7066115736961365, 0.7086777091026306, 0.7179751992225647, 0.7086777091026306, 0.7097107172012329, 0.7159090638160706, 0.7179751992225647, 0.6983470916748047, 0.7128099203109741, 0.7148760557174683, 0.71074378490448, 0.7159090638160706, 0.7148760557174683, 0.6900826692581177, 0.702479362487793, 0.7045454382896423, 0.692148745059967, 0.7045454382896423, 0.7055785059928894, 0.7128099203109741, 0.7148760557174683]}\n","32/32 [==============================] - 0s 2ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.8332 - accuracy: 0.7363"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 5s 46ms/step - loss: 0.8315 - accuracy: 0.7381 - val_loss: 0.9942 - val_accuracy: 0.4860\n","Epoch 2/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8065 - accuracy: 0.7513 - val_loss: 0.9953 - val_accuracy: 0.4860\n","Epoch 3/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.8037 - accuracy: 0.7575 - val_loss: 0.9922 - val_accuracy: 0.4871\n","Epoch 4/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7991 - accuracy: 0.7554 - val_loss: 0.9909 - val_accuracy: 0.4871\n","Epoch 5/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8005 - accuracy: 0.7594 - val_loss: 0.9950 - val_accuracy: 0.4860\n","Epoch 6/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7925 - accuracy: 0.7594 - val_loss: 0.9922 - val_accuracy: 0.4871\n","Epoch 7/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7894 - accuracy: 0.7605 - val_loss: 1.0036 - val_accuracy: 0.4860\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7941 - accuracy: 0.7567 - val_loss: 1.0027 - val_accuracy: 0.4871\n","Epoch 9/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7898 - accuracy: 0.7610 - val_loss: 1.0010 - val_accuracy: 0.4871\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7849 - accuracy: 0.7654 - val_loss: 0.9967 - val_accuracy: 0.4871\n","Epoch 11/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7853 - accuracy: 0.7621 - val_loss: 1.0423 - val_accuracy: 0.4860\n","Epoch 12/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7827 - accuracy: 0.7702 - val_loss: 1.0290 - val_accuracy: 0.4871\n","Epoch 13/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7799 - accuracy: 0.7621 - val_loss: 1.0414 - val_accuracy: 0.4871\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7791 - accuracy: 0.7659 - val_loss: 1.0433 - val_accuracy: 0.4871\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7764 - accuracy: 0.7686 - val_loss: 1.0613 - val_accuracy: 0.4871\n","Epoch 16/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.7748 - accuracy: 0.7699 - val_loss: 1.0405 - val_accuracy: 0.4935\n","Epoch 17/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.7839 - accuracy: 0.7532 - val_loss: 1.0386 - val_accuracy: 0.5022\n","Epoch 18/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.7747 - accuracy: 0.7640 - val_loss: 1.0457 - val_accuracy: 0.5075\n","Epoch 19/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.7682 - accuracy: 0.7683 - val_loss: 0.8982 - val_accuracy: 0.6422\n","Epoch 20/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7929 - accuracy: 0.7481 - val_loss: 0.9248 - val_accuracy: 0.6067\n","Epoch 21/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7656 - accuracy: 0.7740 - val_loss: 0.9286 - val_accuracy: 0.6034\n","Epoch 22/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7662 - accuracy: 0.7680 - val_loss: 0.9466 - val_accuracy: 0.6013\n","Epoch 23/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7700 - accuracy: 0.7675 - val_loss: 0.9316 - val_accuracy: 0.6088\n","Epoch 24/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.7732 - accuracy: 0.7691 - val_loss: 0.8448 - val_accuracy: 0.7101\n","Epoch 25/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.7657 - accuracy: 0.7705 - val_loss: 0.8310 - val_accuracy: 0.7123\n","Epoch 26/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7631 - accuracy: 0.7716 - val_loss: 0.8567 - val_accuracy: 0.6950\n","Epoch 27/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.7574 - accuracy: 0.7699 - val_loss: 0.8468 - val_accuracy: 0.7134\n","Epoch 28/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.7561 - accuracy: 0.7756 - val_loss: 0.8222 - val_accuracy: 0.7284\n","Epoch 29/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7562 - accuracy: 0.7796 - val_loss: 0.8166 - val_accuracy: 0.7284\n","Epoch 30/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.7619 - accuracy: 0.7662 - val_loss: 0.8098 - val_accuracy: 0.7425\n","Epoch 31/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7527 - accuracy: 0.7751 - val_loss: 0.8558 - val_accuracy: 0.7026\n","Epoch 32/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7509 - accuracy: 0.7759 - val_loss: 0.8108 - val_accuracy: 0.7371\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7583 - accuracy: 0.7718 - val_loss: 0.8128 - val_accuracy: 0.7284\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7484 - accuracy: 0.7804 - val_loss: 0.8207 - val_accuracy: 0.7338\n","Epoch 35/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.7503 - accuracy: 0.7804 - val_loss: 0.8080 - val_accuracy: 0.7435\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7483 - accuracy: 0.7756 - val_loss: 0.8112 - val_accuracy: 0.7392\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7510 - accuracy: 0.7772 - val_loss: 0.8105 - val_accuracy: 0.7349\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7416 - accuracy: 0.7880 - val_loss: 0.8118 - val_accuracy: 0.7435\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7375 - accuracy: 0.7877 - val_loss: 0.8108 - val_accuracy: 0.7403\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7353 - accuracy: 0.7858 - val_loss: 0.8071 - val_accuracy: 0.7381\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7384 - accuracy: 0.7909 - val_loss: 0.8184 - val_accuracy: 0.7349\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7381 - accuracy: 0.7858 - val_loss: 0.8198 - val_accuracy: 0.7241\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7401 - accuracy: 0.7769 - val_loss: 0.8182 - val_accuracy: 0.7349\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7342 - accuracy: 0.7888 - val_loss: 0.8070 - val_accuracy: 0.7284\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7330 - accuracy: 0.7848 - val_loss: 0.8159 - val_accuracy: 0.7284\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7284 - accuracy: 0.7874 - val_loss: 0.8078 - val_accuracy: 0.7338\n","Epoch 47/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7272 - accuracy: 0.7907 - val_loss: 0.8073 - val_accuracy: 0.7371\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7253 - accuracy: 0.7931 - val_loss: 0.8057 - val_accuracy: 0.7403\n","Epoch 49/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7311 - accuracy: 0.7815 - val_loss: 0.8214 - val_accuracy: 0.7284\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7377 - accuracy: 0.7761 - val_loss: 0.8338 - val_accuracy: 0.7177\n","Epoch 51/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7416 - accuracy: 0.7775 - val_loss: 0.8010 - val_accuracy: 0.7349\n","Epoch 52/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7255 - accuracy: 0.7818 - val_loss: 0.8310 - val_accuracy: 0.7220\n","Epoch 53/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7314 - accuracy: 0.7831 - val_loss: 0.8561 - val_accuracy: 0.7026\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7289 - accuracy: 0.7834 - val_loss: 0.8054 - val_accuracy: 0.7349\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7165 - accuracy: 0.7950 - val_loss: 0.8328 - val_accuracy: 0.7144\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7180 - accuracy: 0.7893 - val_loss: 0.8047 - val_accuracy: 0.7328\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7154 - accuracy: 0.7920 - val_loss: 0.8067 - val_accuracy: 0.7381\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7279 - accuracy: 0.7837 - val_loss: 0.8020 - val_accuracy: 0.7349\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7119 - accuracy: 0.7907 - val_loss: 0.8015 - val_accuracy: 0.7435\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7148 - accuracy: 0.7874 - val_loss: 0.8013 - val_accuracy: 0.7381\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7099 - accuracy: 0.7961 - val_loss: 0.8129 - val_accuracy: 0.7306\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7121 - accuracy: 0.7901 - val_loss: 0.8325 - val_accuracy: 0.7155\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7110 - accuracy: 0.7971 - val_loss: 0.8029 - val_accuracy: 0.7414\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7032 - accuracy: 0.8020 - val_loss: 0.8022 - val_accuracy: 0.7360\n","Epoch 65/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7088 - accuracy: 0.7953 - val_loss: 0.8078 - val_accuracy: 0.7414\n","Epoch 66/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7009 - accuracy: 0.8077 - val_loss: 0.7966 - val_accuracy: 0.7435\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6984 - accuracy: 0.8052 - val_loss: 0.7998 - val_accuracy: 0.7371\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7015 - accuracy: 0.7958 - val_loss: 0.8058 - val_accuracy: 0.7360\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7007 - accuracy: 0.7974 - val_loss: 0.8163 - val_accuracy: 0.7274\n","Epoch 70/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7049 - accuracy: 0.7969 - val_loss: 0.7967 - val_accuracy: 0.7360\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6986 - accuracy: 0.7926 - val_loss: 0.7971 - val_accuracy: 0.7414\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6918 - accuracy: 0.8103 - val_loss: 0.7992 - val_accuracy: 0.7381\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6897 - accuracy: 0.8052 - val_loss: 0.7970 - val_accuracy: 0.7414\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6928 - accuracy: 0.8041 - val_loss: 0.8831 - val_accuracy: 0.6724\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6964 - accuracy: 0.8052 - val_loss: 0.8049 - val_accuracy: 0.7274\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6898 - accuracy: 0.8090 - val_loss: 0.7969 - val_accuracy: 0.7360\n","Epoch 77/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6930 - accuracy: 0.7985 - val_loss: 0.7981 - val_accuracy: 0.7349\n","Epoch 78/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7104 - accuracy: 0.7810 - val_loss: 0.8241 - val_accuracy: 0.7231\n","Epoch 79/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6878 - accuracy: 0.8085 - val_loss: 0.8067 - val_accuracy: 0.7263\n","Epoch 80/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6887 - accuracy: 0.8063 - val_loss: 0.7969 - val_accuracy: 0.7317\n","Epoch 81/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6989 - accuracy: 0.7899 - val_loss: 0.8122 - val_accuracy: 0.7231\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6816 - accuracy: 0.8044 - val_loss: 0.7990 - val_accuracy: 0.7425\n","Epoch 83/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6847 - accuracy: 0.8082 - val_loss: 0.8055 - val_accuracy: 0.7435\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6819 - accuracy: 0.8044 - val_loss: 0.7961 - val_accuracy: 0.7328\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6822 - accuracy: 0.8036 - val_loss: 0.7986 - val_accuracy: 0.7317\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6779 - accuracy: 0.8058 - val_loss: 0.7978 - val_accuracy: 0.7425\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6770 - accuracy: 0.8149 - val_loss: 0.7988 - val_accuracy: 0.7435\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6696 - accuracy: 0.8179 - val_loss: 0.7994 - val_accuracy: 0.7392\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6726 - accuracy: 0.8190 - val_loss: 0.8145 - val_accuracy: 0.7241\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6760 - accuracy: 0.8106 - val_loss: 0.8026 - val_accuracy: 0.7328\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6870 - accuracy: 0.7993 - val_loss: 0.8254 - val_accuracy: 0.7209\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6678 - accuracy: 0.8144 - val_loss: 0.8139 - val_accuracy: 0.7263\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6816 - accuracy: 0.8001 - val_loss: 0.8094 - val_accuracy: 0.7198\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6649 - accuracy: 0.8192 - val_loss: 0.8010 - val_accuracy: 0.7392\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6717 - accuracy: 0.8141 - val_loss: 0.8083 - val_accuracy: 0.7263\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6735 - accuracy: 0.8079 - val_loss: 0.8239 - val_accuracy: 0.7220\n","Epoch 97/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6598 - accuracy: 0.8203 - val_loss: 0.8081 - val_accuracy: 0.7328\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6608 - accuracy: 0.8192 - val_loss: 0.8299 - val_accuracy: 0.7112\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6617 - accuracy: 0.8160 - val_loss: 0.7962 - val_accuracy: 0.7381\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6730 - accuracy: 0.8047 - val_loss: 0.8697 - val_accuracy: 0.6810\n","{'loss': [0.8315250277519226, 0.8064808249473572, 0.8036542534828186, 0.7990619540214539, 0.8004804849624634, 0.7924773097038269, 0.7893626689910889, 0.7940512895584106, 0.7898133993148804, 0.7849010229110718, 0.7852931618690491, 0.7826993465423584, 0.7799074053764343, 0.7791352272033691, 0.7764039635658264, 0.7748051285743713, 0.7838526368141174, 0.7746974229812622, 0.7681882977485657, 0.7929468750953674, 0.7656183838844299, 0.7661998271942139, 0.7699725031852722, 0.7731536626815796, 0.7656978964805603, 0.763110876083374, 0.7573577761650085, 0.7560948729515076, 0.7561516761779785, 0.7619108557701111, 0.7526772022247314, 0.7509230971336365, 0.7582995891571045, 0.7484492659568787, 0.7502776980400085, 0.7482984066009521, 0.7509751319885254, 0.7416331171989441, 0.7374935746192932, 0.7352576851844788, 0.7384282946586609, 0.7380945086479187, 0.7401061058044434, 0.7342086434364319, 0.7330225110054016, 0.7284238934516907, 0.7272050976753235, 0.7253260612487793, 0.7310678362846375, 0.7376889586448669, 0.7415923476219177, 0.7254524827003479, 0.7313856482505798, 0.7289328575134277, 0.7165485620498657, 0.7180356383323669, 0.7154039144515991, 0.7278783917427063, 0.7119343280792236, 0.7147859334945679, 0.7098729610443115, 0.712133526802063, 0.7110137939453125, 0.703237771987915, 0.7087986469268799, 0.7009061574935913, 0.698416531085968, 0.7015177607536316, 0.7006584405899048, 0.7049213647842407, 0.6986347436904907, 0.6917974948883057, 0.6897329688072205, 0.6928036212921143, 0.6964382529258728, 0.6897649168968201, 0.6930224299430847, 0.7103504538536072, 0.6877723336219788, 0.6887103915214539, 0.6989423036575317, 0.6815946102142334, 0.6846979856491089, 0.6819440722465515, 0.6821926832199097, 0.6778717041015625, 0.6769670844078064, 0.669550359249115, 0.6725529432296753, 0.675986647605896, 0.6869524717330933, 0.6677641868591309, 0.6815618276596069, 0.6648752093315125, 0.6716711521148682, 0.6734914183616638, 0.6597699522972107, 0.6607879400253296, 0.6617270708084106, 0.6730062961578369], 'accuracy': [0.7381465435028076, 0.751347005367279, 0.7575430870056152, 0.7553879022598267, 0.759428858757019, 0.759428858757019, 0.7605064511299133, 0.7567349076271057, 0.7610452771186829, 0.7653555870056152, 0.7621228694915771, 0.7702047228813171, 0.7621228694915771, 0.7658944129943848, 0.7685883641242981, 0.7699353694915771, 0.7532327771186829, 0.764008641242981, 0.7683189511299133, 0.7481142282485962, 0.7739762663841248, 0.7680495977401733, 0.7675107717514038, 0.7691271305084229, 0.7704741358757019, 0.7715517282485962, 0.7699353694915771, 0.7755926847457886, 0.779633641242981, 0.7661637663841248, 0.775053858757019, 0.7758620977401733, 0.771821141242981, 0.7804418206214905, 0.7804418206214905, 0.7755926847457886, 0.7772090435028076, 0.7879849076271057, 0.787715494632721, 0.7858297228813171, 0.7909482717514038, 0.7858297228813171, 0.7769396305084229, 0.7887930870056152, 0.7847521305084229, 0.787446141242981, 0.790678858757019, 0.7931034564971924, 0.7815194129943848, 0.7761314511299133, 0.7774784564971924, 0.7817887663841248, 0.7831357717514038, 0.7834051847457886, 0.7949892282485962, 0.7893319129943848, 0.7920258641242981, 0.7836745977401733, 0.790678858757019, 0.787446141242981, 0.7960668206214905, 0.7901400923728943, 0.7971444129943848, 0.8019935488700867, 0.795258641242981, 0.8076508641242981, 0.8052262663841248, 0.7957974076271057, 0.7974137663841248, 0.796875, 0.7925646305084229, 0.8103448152542114, 0.8052262663841248, 0.8041487336158752, 0.8052262663841248, 0.8089978694915771, 0.798491358757019, 0.7809805870056152, 0.8084590435028076, 0.806303858757019, 0.7898706793785095, 0.8044180870056152, 0.8081896305084229, 0.8044180870056152, 0.8036099076271057, 0.8057650923728943, 0.8149245977401733, 0.8178879022598267, 0.818965494632721, 0.8106142282485962, 0.7992995977401733, 0.8143857717514038, 0.8001077771186829, 0.8192349076271057, 0.814116358757019, 0.8079202771186829, 0.8203125, 0.8192349076271057, 0.8160021305084229, 0.8046875], 'val_loss': [0.9942284226417542, 0.995342493057251, 0.9921957850456238, 0.9908537864685059, 0.9949706792831421, 0.992168664932251, 1.0035701990127563, 1.0027400255203247, 1.001011848449707, 0.9967187643051147, 1.042286992073059, 1.0290414094924927, 1.0414223670959473, 1.0432806015014648, 1.0613226890563965, 1.0405045747756958, 1.0386379957199097, 1.045680284500122, 0.8982462882995605, 0.9247587323188782, 0.9286001920700073, 0.9465792179107666, 0.9316281676292419, 0.844795286655426, 0.8310086727142334, 0.8566505312919617, 0.8468037247657776, 0.8221796154975891, 0.8166285753250122, 0.8098070621490479, 0.8557947874069214, 0.8108223080635071, 0.8127573728561401, 0.8207039833068848, 0.8079850673675537, 0.8112175464630127, 0.810505747795105, 0.8118101954460144, 0.810764491558075, 0.8071439266204834, 0.8183751702308655, 0.819756031036377, 0.8182374835014343, 0.8070333003997803, 0.8158515691757202, 0.8078240752220154, 0.8073351383209229, 0.8056628704071045, 0.8213890790939331, 0.8337581157684326, 0.8010232448577881, 0.8309669494628906, 0.8561304807662964, 0.8054080009460449, 0.8328090906143188, 0.8046794533729553, 0.8066655397415161, 0.8019581437110901, 0.8014668822288513, 0.8013449311256409, 0.8128678798675537, 0.8325049877166748, 0.8028920888900757, 0.8021685481071472, 0.8077511787414551, 0.7966017723083496, 0.7997542023658752, 0.8057551980018616, 0.816277801990509, 0.796720564365387, 0.7970979809761047, 0.7992115020751953, 0.7969768047332764, 0.8831024169921875, 0.8048638701438904, 0.7969264388084412, 0.7980780601501465, 0.8240538239479065, 0.8066958785057068, 0.7969179749488831, 0.8121904730796814, 0.7989569306373596, 0.805536687374115, 0.7961248755455017, 0.7986094951629639, 0.7977707982063293, 0.7987634539604187, 0.7994384169578552, 0.8145378828048706, 0.8026489019393921, 0.8253938555717468, 0.8138864040374756, 0.809359610080719, 0.8009836077690125, 0.8083489537239075, 0.8239296078681946, 0.8080673217773438, 0.829909086227417, 0.7962275743484497, 0.8696609735488892], 'val_accuracy': [0.48599138855934143, 0.48599138855934143, 0.48706895112991333, 0.48706895112991333, 0.48599138855934143, 0.48706895112991333, 0.48599138855934143, 0.48706895112991333, 0.48706895112991333, 0.48706895112991333, 0.48599138855934143, 0.48706895112991333, 0.48706895112991333, 0.48706895112991333, 0.48706895112991333, 0.49353447556495667, 0.5021551847457886, 0.5075430870056152, 0.642241358757019, 0.6066810488700867, 0.6034482717514038, 0.6012930870056152, 0.6088362336158752, 0.7101293206214905, 0.712284505367279, 0.6950430870056152, 0.7133620977401733, 0.7284482717514038, 0.7284482717514038, 0.7424569129943848, 0.7025862336158752, 0.7370689511299133, 0.7284482717514038, 0.7338362336158752, 0.743534505367279, 0.7392241358757019, 0.7349137663841248, 0.743534505367279, 0.7403017282485962, 0.7381465435028076, 0.7349137663841248, 0.7241379022598267, 0.7349137663841248, 0.7284482717514038, 0.7284482717514038, 0.7338362336158752, 0.7370689511299133, 0.7403017282485962, 0.7284482717514038, 0.7176724076271057, 0.7349137663841248, 0.7219827771186829, 0.7025862336158752, 0.7349137663841248, 0.7144396305084229, 0.732758641242981, 0.7381465435028076, 0.7349137663841248, 0.743534505367279, 0.7381465435028076, 0.7306034564971924, 0.7155172228813171, 0.7413793206214905, 0.735991358757019, 0.7413793206214905, 0.743534505367279, 0.7370689511299133, 0.735991358757019, 0.7273706793785095, 0.735991358757019, 0.7413793206214905, 0.7381465435028076, 0.7413793206214905, 0.6724137663841248, 0.7273706793785095, 0.735991358757019, 0.7349137663841248, 0.7230603694915771, 0.7262930870056152, 0.7316810488700867, 0.7230603694915771, 0.7424569129943848, 0.743534505367279, 0.732758641242981, 0.7316810488700867, 0.7424569129943848, 0.743534505367279, 0.7392241358757019, 0.7241379022598267, 0.732758641242981, 0.7209051847457886, 0.7262930870056152, 0.7198275923728943, 0.7392241358757019, 0.7262930870056152, 0.7219827771186829, 0.732758641242981, 0.7112069129943848, 0.7381465435028076, 0.681034505367279]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.8316 - accuracy: 0.7355"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 4s 43ms/step - loss: 0.8310 - accuracy: 0.7354 - val_loss: 0.9921 - val_accuracy: 0.4977\n","Epoch 2/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8080 - accuracy: 0.7524 - val_loss: 0.9898 - val_accuracy: 0.4977\n","Epoch 3/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8057 - accuracy: 0.7569 - val_loss: 0.9896 - val_accuracy: 0.4977\n","Epoch 4/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.8027 - accuracy: 0.7490 - val_loss: 0.9865 - val_accuracy: 0.4989\n","Epoch 5/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.7985 - accuracy: 0.7629 - val_loss: 0.9828 - val_accuracy: 0.5045\n","Epoch 6/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7957 - accuracy: 0.7651 - val_loss: 0.9870 - val_accuracy: 0.4977\n","Epoch 7/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8022 - accuracy: 0.7521 - val_loss: 0.9757 - val_accuracy: 0.5147\n","Epoch 8/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8010 - accuracy: 0.7530 - val_loss: 0.9857 - val_accuracy: 0.5000\n","Epoch 9/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7988 - accuracy: 0.7459 - val_loss: 0.9790 - val_accuracy: 0.5090\n","Epoch 10/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7873 - accuracy: 0.7680 - val_loss: 0.9936 - val_accuracy: 0.4989\n","Epoch 11/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7872 - accuracy: 0.7677 - val_loss: 0.9826 - val_accuracy: 0.5090\n","Epoch 12/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7827 - accuracy: 0.7705 - val_loss: 0.9749 - val_accuracy: 0.5147\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7816 - accuracy: 0.7711 - val_loss: 0.9993 - val_accuracy: 0.5023\n","Epoch 14/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7867 - accuracy: 0.7674 - val_loss: 0.9726 - val_accuracy: 0.5158\n","Epoch 15/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7793 - accuracy: 0.7685 - val_loss: 0.9848 - val_accuracy: 0.5147\n","Epoch 16/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.7748 - accuracy: 0.7725 - val_loss: 0.9880 - val_accuracy: 0.5170\n","Epoch 17/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.7722 - accuracy: 0.7759 - val_loss: 0.9888 - val_accuracy: 0.5271\n","Epoch 18/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7726 - accuracy: 0.7782 - val_loss: 0.9587 - val_accuracy: 0.5622\n","Epoch 19/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.7714 - accuracy: 0.7719 - val_loss: 0.9299 - val_accuracy: 0.6063\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7675 - accuracy: 0.7762 - val_loss: 0.9572 - val_accuracy: 0.5803\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7657 - accuracy: 0.7750 - val_loss: 0.9416 - val_accuracy: 0.5939\n","Epoch 22/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7660 - accuracy: 0.7770 - val_loss: 0.8760 - val_accuracy: 0.6708\n","Epoch 23/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.7690 - accuracy: 0.7745 - val_loss: 0.8692 - val_accuracy: 0.6810\n","Epoch 24/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.7652 - accuracy: 0.7722 - val_loss: 0.8562 - val_accuracy: 0.6957\n","Epoch 25/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.7636 - accuracy: 0.7821 - val_loss: 0.8440 - val_accuracy: 0.7104\n","Epoch 26/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.7640 - accuracy: 0.7714 - val_loss: 0.8326 - val_accuracy: 0.7364\n","Epoch 27/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7582 - accuracy: 0.7753 - val_loss: 0.8308 - val_accuracy: 0.7319\n","Epoch 28/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7617 - accuracy: 0.7750 - val_loss: 0.8279 - val_accuracy: 0.7330\n","Epoch 29/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7567 - accuracy: 0.7742 - val_loss: 0.8399 - val_accuracy: 0.6980\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7506 - accuracy: 0.7832 - val_loss: 0.8321 - val_accuracy: 0.7206\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7591 - accuracy: 0.7748 - val_loss: 0.8282 - val_accuracy: 0.7262\n","Epoch 32/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7479 - accuracy: 0.7875 - val_loss: 0.8225 - val_accuracy: 0.7308\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7488 - accuracy: 0.7816 - val_loss: 0.8403 - val_accuracy: 0.6980\n","Epoch 34/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7513 - accuracy: 0.7790 - val_loss: 0.8191 - val_accuracy: 0.7376\n","Epoch 35/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7440 - accuracy: 0.7841 - val_loss: 0.8271 - val_accuracy: 0.7296\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7446 - accuracy: 0.7878 - val_loss: 0.8267 - val_accuracy: 0.7240\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7424 - accuracy: 0.7937 - val_loss: 0.8780 - val_accuracy: 0.6697\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7674 - accuracy: 0.7535 - val_loss: 0.8230 - val_accuracy: 0.7342\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7391 - accuracy: 0.7849 - val_loss: 0.8291 - val_accuracy: 0.7183\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7611 - accuracy: 0.7643 - val_loss: 0.8203 - val_accuracy: 0.7319\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7374 - accuracy: 0.7923 - val_loss: 0.8164 - val_accuracy: 0.7376\n","Epoch 42/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7305 - accuracy: 0.7951 - val_loss: 0.8213 - val_accuracy: 0.7296\n","Epoch 43/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7308 - accuracy: 0.7951 - val_loss: 0.8271 - val_accuracy: 0.7285\n","Epoch 44/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7405 - accuracy: 0.7779 - val_loss: 0.8171 - val_accuracy: 0.7398\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7308 - accuracy: 0.7923 - val_loss: 0.8376 - val_accuracy: 0.7217\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7402 - accuracy: 0.7756 - val_loss: 0.8150 - val_accuracy: 0.7376\n","Epoch 47/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.7239 - accuracy: 0.7991 - val_loss: 0.8156 - val_accuracy: 0.7410\n","Epoch 48/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7267 - accuracy: 0.7963 - val_loss: 0.8151 - val_accuracy: 0.7398\n","Epoch 49/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7183 - accuracy: 0.8028 - val_loss: 0.8138 - val_accuracy: 0.7353\n","Epoch 50/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7238 - accuracy: 0.7900 - val_loss: 0.8254 - val_accuracy: 0.7353\n","Epoch 51/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7226 - accuracy: 0.7965 - val_loss: 0.8185 - val_accuracy: 0.7398\n","Epoch 52/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7235 - accuracy: 0.7946 - val_loss: 0.8205 - val_accuracy: 0.7229\n","Epoch 53/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7186 - accuracy: 0.7923 - val_loss: 0.8533 - val_accuracy: 0.7229\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7251 - accuracy: 0.7869 - val_loss: 0.8173 - val_accuracy: 0.7353\n","Epoch 55/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7155 - accuracy: 0.7971 - val_loss: 0.8120 - val_accuracy: 0.7432\n","Epoch 56/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7109 - accuracy: 0.8005 - val_loss: 0.8201 - val_accuracy: 0.7387\n","Epoch 57/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7104 - accuracy: 0.7977 - val_loss: 0.8158 - val_accuracy: 0.7387\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7073 - accuracy: 0.8090 - val_loss: 0.8161 - val_accuracy: 0.7319\n","Epoch 59/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7055 - accuracy: 0.8067 - val_loss: 0.8151 - val_accuracy: 0.7387\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7033 - accuracy: 0.8039 - val_loss: 0.8120 - val_accuracy: 0.7330\n","Epoch 61/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7047 - accuracy: 0.8070 - val_loss: 0.8151 - val_accuracy: 0.7330\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7035 - accuracy: 0.8033 - val_loss: 0.8314 - val_accuracy: 0.7285\n","Epoch 63/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6972 - accuracy: 0.8121 - val_loss: 0.8123 - val_accuracy: 0.7353\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7042 - accuracy: 0.8016 - val_loss: 0.8460 - val_accuracy: 0.6912\n","Epoch 65/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6977 - accuracy: 0.8050 - val_loss: 0.8154 - val_accuracy: 0.7308\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7001 - accuracy: 0.8036 - val_loss: 0.8156 - val_accuracy: 0.7285\n","Epoch 67/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6927 - accuracy: 0.8110 - val_loss: 0.8265 - val_accuracy: 0.7081\n","Epoch 68/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6941 - accuracy: 0.8093 - val_loss: 0.8220 - val_accuracy: 0.7455\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6955 - accuracy: 0.8076 - val_loss: 0.8605 - val_accuracy: 0.6855\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6974 - accuracy: 0.8022 - val_loss: 0.8131 - val_accuracy: 0.7285\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6889 - accuracy: 0.8104 - val_loss: 0.8143 - val_accuracy: 0.7364\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6943 - accuracy: 0.7971 - val_loss: 0.8130 - val_accuracy: 0.7387\n","Epoch 73/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7137 - accuracy: 0.7909 - val_loss: 0.8679 - val_accuracy: 0.6855\n","Epoch 74/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7046 - accuracy: 0.7971 - val_loss: 0.8381 - val_accuracy: 0.6923\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6906 - accuracy: 0.8081 - val_loss: 0.8340 - val_accuracy: 0.7206\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6856 - accuracy: 0.8090 - val_loss: 0.8232 - val_accuracy: 0.7342\n","Epoch 77/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7055 - accuracy: 0.7915 - val_loss: 0.8304 - val_accuracy: 0.7308\n","Epoch 78/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7014 - accuracy: 0.7943 - val_loss: 0.8123 - val_accuracy: 0.7308\n","Epoch 79/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6825 - accuracy: 0.8121 - val_loss: 0.8319 - val_accuracy: 0.7059\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6788 - accuracy: 0.8220 - val_loss: 0.8127 - val_accuracy: 0.7240\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6743 - accuracy: 0.8169 - val_loss: 0.8343 - val_accuracy: 0.7014\n","Epoch 82/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6725 - accuracy: 0.8231 - val_loss: 0.8527 - val_accuracy: 0.6946\n","Epoch 83/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6844 - accuracy: 0.8059 - val_loss: 0.8125 - val_accuracy: 0.7319\n","Epoch 84/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6700 - accuracy: 0.8183 - val_loss: 0.8147 - val_accuracy: 0.7262\n","Epoch 85/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6671 - accuracy: 0.8268 - val_loss: 0.8238 - val_accuracy: 0.7104\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6700 - accuracy: 0.8175 - val_loss: 0.8137 - val_accuracy: 0.7229\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6681 - accuracy: 0.8209 - val_loss: 0.8198 - val_accuracy: 0.7127\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6645 - accuracy: 0.8234 - val_loss: 0.8172 - val_accuracy: 0.7319\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6720 - accuracy: 0.8164 - val_loss: 0.8179 - val_accuracy: 0.7398\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6603 - accuracy: 0.8285 - val_loss: 0.8560 - val_accuracy: 0.7183\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6719 - accuracy: 0.8192 - val_loss: 0.8191 - val_accuracy: 0.7330\n","Epoch 92/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6608 - accuracy: 0.8254 - val_loss: 0.8151 - val_accuracy: 0.7330\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6622 - accuracy: 0.8178 - val_loss: 0.8267 - val_accuracy: 0.7036\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6592 - accuracy: 0.8285 - val_loss: 0.8310 - val_accuracy: 0.7059\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6763 - accuracy: 0.8022 - val_loss: 0.8155 - val_accuracy: 0.7364\n","Epoch 96/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6573 - accuracy: 0.8263 - val_loss: 0.8163 - val_accuracy: 0.7262\n","Epoch 97/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6570 - accuracy: 0.8229 - val_loss: 0.8164 - val_accuracy: 0.7342\n","Epoch 98/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6511 - accuracy: 0.8297 - val_loss: 0.8186 - val_accuracy: 0.7308\n","Epoch 99/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6487 - accuracy: 0.8336 - val_loss: 0.8164 - val_accuracy: 0.7330\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6622 - accuracy: 0.8183 - val_loss: 0.8193 - val_accuracy: 0.7251\n","{'loss': [0.8310431241989136, 0.8080371022224426, 0.8056687116622925, 0.8026862144470215, 0.7985157370567322, 0.7957273125648499, 0.8021848797798157, 0.8010252714157104, 0.7988190650939941, 0.787257194519043, 0.7871704697608948, 0.7826917767524719, 0.7815922498703003, 0.78667813539505, 0.7793103456497192, 0.7748450636863708, 0.7721578478813171, 0.7725878953933716, 0.7713800668716431, 0.7675142884254456, 0.7656907439231873, 0.765998899936676, 0.769006073474884, 0.765244722366333, 0.7636371850967407, 0.7640451788902283, 0.7582331895828247, 0.7617421746253967, 0.7566977143287659, 0.7506246566772461, 0.7591290473937988, 0.7479076981544495, 0.7488487362861633, 0.7512562870979309, 0.7440263628959656, 0.7445868253707886, 0.7424381375312805, 0.7674248814582825, 0.739061176776886, 0.76113361120224, 0.7373641729354858, 0.7305275201797485, 0.730793833732605, 0.740505576133728, 0.7307650446891785, 0.7401588559150696, 0.7238849401473999, 0.7267363667488098, 0.718321681022644, 0.7237845659255981, 0.7225645184516907, 0.7235402464866638, 0.7186071276664734, 0.7251258492469788, 0.7155289053916931, 0.7109364867210388, 0.7104445099830627, 0.7073057889938354, 0.7054895758628845, 0.7032999396324158, 0.7046904563903809, 0.7035475969314575, 0.6971996426582336, 0.704201877117157, 0.6976509094238281, 0.7000914216041565, 0.6927274465560913, 0.6941226124763489, 0.6955153346061707, 0.6974297761917114, 0.6888785362243652, 0.6942784190177917, 0.7137019634246826, 0.704608678817749, 0.6906030774116516, 0.6855512261390686, 0.7055221796035767, 0.7013649344444275, 0.682510495185852, 0.6788360476493835, 0.674321711063385, 0.6724715828895569, 0.6843857765197754, 0.6700350046157837, 0.6670929789543152, 0.6699627041816711, 0.6680880784988403, 0.6644765138626099, 0.6720409393310547, 0.6603071093559265, 0.6718891859054565, 0.660778284072876, 0.6621930599212646, 0.6591838598251343, 0.6762748956680298, 0.6572887897491455, 0.6569939851760864, 0.6511078476905823, 0.6486725211143494, 0.6621898412704468], 'accuracy': [0.7354272603988647, 0.7524052262306213, 0.7569326758384705, 0.7490096092224121, 0.7628749012947083, 0.7651386260986328, 0.7521222233772278, 0.7529711127281189, 0.7458969950675964, 0.7679682970046997, 0.7676853537559509, 0.7705150246620178, 0.7710809111595154, 0.7674023509025574, 0.768534243106842, 0.7724957466125488, 0.7758913636207581, 0.7781550884246826, 0.7719298005104065, 0.7761743068695068, 0.7750424742698669, 0.777023196220398, 0.7744765281677246, 0.7722128033638, 0.7821165919303894, 0.7713639140129089, 0.7753254175186157, 0.7750424742698669, 0.774193525314331, 0.7832484245300293, 0.7747594714164734, 0.7874929308891296, 0.7815506458282471, 0.7790039777755737, 0.7840973138809204, 0.7877758741378784, 0.793718159198761, 0.7535370588302612, 0.7849462628364563, 0.7642897367477417, 0.7923033237457275, 0.7951329946517944, 0.7951329946517944, 0.7778720855712891, 0.7923033237457275, 0.7756083607673645, 0.7990944981575012, 0.7962648272514343, 0.8027730584144592, 0.790039598941803, 0.7965478301048279, 0.7945670485496521, 0.7923033237457275, 0.7869269847869873, 0.7971137762069702, 0.8005093336105347, 0.7976796627044678, 0.8089982867240906, 0.806734561920166, 0.8039049506187439, 0.8070175647735596, 0.8033390045166016, 0.8121109008789062, 0.8016412258148193, 0.8050367832183838, 0.8036219477653503, 0.8109790682792664, 0.8092812895774841, 0.8075834512710571, 0.8022071123123169, 0.810413122177124, 0.7971137762069702, 0.7908884882926941, 0.7971137762069702, 0.8081493973731995, 0.8089982867240906, 0.7914544343948364, 0.7942841053009033, 0.8121109008789062, 0.8220146894454956, 0.8169213533401489, 0.8231465816497803, 0.8058856725692749, 0.8183361887931824, 0.8268251419067383, 0.8174872398376465, 0.8208828568458557, 0.823429524898529, 0.8163554072380066, 0.8285229206085205, 0.8191850781440735, 0.8254103064537048, 0.81777024269104, 0.8285229206085205, 0.8022071123123169, 0.826259195804596, 0.8228636384010315, 0.8296547532081604, 0.833616316318512, 0.8183361887931824], 'val_loss': [0.9920542240142822, 0.989754319190979, 0.9896462559700012, 0.9864631295204163, 0.9828252792358398, 0.9870039224624634, 0.9756927490234375, 0.9856894612312317, 0.9790236949920654, 0.9936122894287109, 0.9826241135597229, 0.9748728275299072, 0.9993122220039368, 0.9725627899169922, 0.9847894310951233, 0.9880352020263672, 0.9888378977775574, 0.9586700201034546, 0.929928183555603, 0.9571825861930847, 0.9415844082832336, 0.875959038734436, 0.8691934943199158, 0.8562426567077637, 0.8440184593200684, 0.8325982689857483, 0.8307656645774841, 0.8278995752334595, 0.8398615121841431, 0.8320948481559753, 0.8281950354576111, 0.8225065469741821, 0.8402888774871826, 0.8190780282020569, 0.8271397352218628, 0.8266507387161255, 0.8780133128166199, 0.8230088949203491, 0.8290634751319885, 0.8202592730522156, 0.816423773765564, 0.8213493227958679, 0.8271056413650513, 0.8170515894889832, 0.8375864028930664, 0.8150027990341187, 0.8155811429023743, 0.8151118159294128, 0.8138417601585388, 0.8254022598266602, 0.8184629678726196, 0.8205342292785645, 0.8533478379249573, 0.817255437374115, 0.8119727373123169, 0.8200770616531372, 0.8157776594161987, 0.8161316514015198, 0.8151384592056274, 0.812002956867218, 0.8150888681411743, 0.8313586115837097, 0.8122610449790955, 0.8459842205047607, 0.8153733015060425, 0.8155760765075684, 0.8265454769134521, 0.8220381140708923, 0.8605416417121887, 0.8131226301193237, 0.8143498301506042, 0.8130375742912292, 0.8679308295249939, 0.8380982875823975, 0.8339988589286804, 0.8231810927391052, 0.8303658962249756, 0.8123406171798706, 0.8319404125213623, 0.8127220273017883, 0.8343400955200195, 0.8526620864868164, 0.8124733567237854, 0.8146786689758301, 0.8237597346305847, 0.8136700391769409, 0.8198434114456177, 0.8171513080596924, 0.8178502321243286, 0.8559687733650208, 0.8191052079200745, 0.8150786757469177, 0.8267315626144409, 0.8309552073478699, 0.8155196309089661, 0.81629478931427, 0.8164486289024353, 0.818580687046051, 0.8163695335388184, 0.819258451461792], 'val_accuracy': [0.4977375566959381, 0.4977375566959381, 0.4977375566959381, 0.49886876344680786, 0.5045248866081238, 0.4977375566959381, 0.5147058963775635, 0.5, 0.5090497732162476, 0.49886876344680786, 0.5090497732162476, 0.5147058963775635, 0.5022624731063843, 0.5158371329307556, 0.5147058963775635, 0.516968309879303, 0.5271493196487427, 0.5622171759605408, 0.6063348650932312, 0.5803167223930359, 0.5938913822174072, 0.6708144545555115, 0.6809954643249512, 0.6957013607025146, 0.7104072570800781, 0.7364253401756287, 0.7319004535675049, 0.733031690120697, 0.6979637742042542, 0.720588207244873, 0.726244330406189, 0.7307692170143127, 0.6979637742042542, 0.7375565767288208, 0.7296379804611206, 0.7239819169044495, 0.6696832776069641, 0.7341628670692444, 0.7183257937431335, 0.7319004535675049, 0.7375565767288208, 0.7296379804611206, 0.7285068035125732, 0.7398189902305603, 0.7217194437980652, 0.7375565767288208, 0.7409502267837524, 0.7398189902305603, 0.7352941036224365, 0.7352941036224365, 0.7398189902305603, 0.7228506803512573, 0.7228506803512573, 0.7352941036224365, 0.7432126402854919, 0.7386877536773682, 0.7386877536773682, 0.7319004535675049, 0.7386877536773682, 0.733031690120697, 0.733031690120697, 0.7285068035125732, 0.7352941036224365, 0.6911764740943909, 0.7307692170143127, 0.7285068035125732, 0.7081447839736938, 0.7454751133918762, 0.685520350933075, 0.7285068035125732, 0.7364253401756287, 0.7386877536773682, 0.685520350933075, 0.692307710647583, 0.720588207244873, 0.7341628670692444, 0.7307692170143127, 0.7307692170143127, 0.7058823704719543, 0.7239819169044495, 0.7013574838638306, 0.6945701241493225, 0.7319004535675049, 0.726244330406189, 0.7104072570800781, 0.7228506803512573, 0.7126696705818176, 0.7319004535675049, 0.7398189902305603, 0.7183257937431335, 0.733031690120697, 0.733031690120697, 0.7036198973655701, 0.7058823704719543, 0.7364253401756287, 0.726244330406189, 0.7341628670692444, 0.7307692170143127, 0.733031690120697, 0.7251130938529968]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.8165 - accuracy: 0.7442"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 6s 55ms/step - loss: 0.8165 - accuracy: 0.7442 - val_loss: 0.9914 - val_accuracy: 0.4886\n","Epoch 2/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7954 - accuracy: 0.7659 - val_loss: 0.9900 - val_accuracy: 0.4876\n","Epoch 3/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7943 - accuracy: 0.7597 - val_loss: 0.9860 - val_accuracy: 0.4938\n","Epoch 4/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7995 - accuracy: 0.7519 - val_loss: 0.9868 - val_accuracy: 0.4886\n","Epoch 5/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7922 - accuracy: 0.7636 - val_loss: 0.9901 - val_accuracy: 0.4876\n","Epoch 6/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7874 - accuracy: 0.7558 - val_loss: 0.9893 - val_accuracy: 0.4876\n","Epoch 7/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7841 - accuracy: 0.7643 - val_loss: 0.9996 - val_accuracy: 0.4886\n","Epoch 8/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7859 - accuracy: 0.7587 - val_loss: 1.0085 - val_accuracy: 0.4886\n","Epoch 9/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7844 - accuracy: 0.7618 - val_loss: 0.9951 - val_accuracy: 0.4886\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7758 - accuracy: 0.7641 - val_loss: 1.0083 - val_accuracy: 0.4876\n","Epoch 11/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7771 - accuracy: 0.7664 - val_loss: 0.9881 - val_accuracy: 0.4979\n","Epoch 12/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.7735 - accuracy: 0.7693 - val_loss: 0.9706 - val_accuracy: 0.5227\n","Epoch 13/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7850 - accuracy: 0.7548 - val_loss: 1.0073 - val_accuracy: 0.4959\n","Epoch 14/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7699 - accuracy: 0.7760 - val_loss: 1.0112 - val_accuracy: 0.5031\n","Epoch 15/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.7683 - accuracy: 0.7693 - val_loss: 0.9721 - val_accuracy: 0.5320\n","Epoch 16/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7679 - accuracy: 0.7755 - val_loss: 1.0069 - val_accuracy: 0.5248\n","Epoch 17/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7619 - accuracy: 0.7742 - val_loss: 1.0123 - val_accuracy: 0.5269\n","Epoch 18/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7639 - accuracy: 0.7736 - val_loss: 1.0065 - val_accuracy: 0.5413\n","Epoch 19/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.7627 - accuracy: 0.7752 - val_loss: 0.9113 - val_accuracy: 0.6250\n","Epoch 20/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.7722 - accuracy: 0.7646 - val_loss: 0.8757 - val_accuracy: 0.6694\n","Epoch 21/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.7772 - accuracy: 0.7532 - val_loss: 0.8470 - val_accuracy: 0.7045\n","Epoch 22/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.7617 - accuracy: 0.7695 - val_loss: 0.8491 - val_accuracy: 0.7056\n","Epoch 23/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.7547 - accuracy: 0.7806 - val_loss: 0.8368 - val_accuracy: 0.7138\n","Epoch 24/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7596 - accuracy: 0.7667 - val_loss: 0.8379 - val_accuracy: 0.7025\n","Epoch 25/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.7507 - accuracy: 0.7786 - val_loss: 0.8322 - val_accuracy: 0.7355\n","Epoch 26/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7550 - accuracy: 0.7788 - val_loss: 0.8279 - val_accuracy: 0.7231\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7495 - accuracy: 0.7793 - val_loss: 0.8333 - val_accuracy: 0.6952\n","Epoch 28/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7458 - accuracy: 0.7783 - val_loss: 0.8410 - val_accuracy: 0.6901\n","Epoch 29/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7547 - accuracy: 0.7788 - val_loss: 0.8445 - val_accuracy: 0.6829\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7513 - accuracy: 0.7749 - val_loss: 0.8301 - val_accuracy: 0.7014\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7447 - accuracy: 0.7842 - val_loss: 0.8242 - val_accuracy: 0.7180\n","Epoch 32/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7395 - accuracy: 0.7860 - val_loss: 0.8260 - val_accuracy: 0.7097\n","Epoch 33/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7469 - accuracy: 0.7770 - val_loss: 0.8216 - val_accuracy: 0.7252\n","Epoch 34/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7421 - accuracy: 0.7845 - val_loss: 0.8229 - val_accuracy: 0.7221\n","Epoch 35/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7369 - accuracy: 0.7860 - val_loss: 0.8238 - val_accuracy: 0.7169\n","Epoch 36/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7333 - accuracy: 0.7871 - val_loss: 0.8231 - val_accuracy: 0.7159\n","Epoch 37/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7408 - accuracy: 0.7814 - val_loss: 0.8206 - val_accuracy: 0.7304\n","Epoch 38/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7318 - accuracy: 0.7917 - val_loss: 0.8279 - val_accuracy: 0.7066\n","Epoch 39/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7285 - accuracy: 0.7889 - val_loss: 0.8248 - val_accuracy: 0.7169\n","Epoch 40/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7390 - accuracy: 0.7840 - val_loss: 0.8324 - val_accuracy: 0.7004\n","Epoch 41/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7405 - accuracy: 0.7690 - val_loss: 0.8289 - val_accuracy: 0.7283\n","Epoch 42/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7375 - accuracy: 0.7876 - val_loss: 0.8215 - val_accuracy: 0.7128\n","Epoch 43/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7224 - accuracy: 0.7935 - val_loss: 0.8250 - val_accuracy: 0.7035\n","Epoch 44/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7271 - accuracy: 0.7871 - val_loss: 0.8198 - val_accuracy: 0.7200\n","Epoch 45/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7203 - accuracy: 0.7917 - val_loss: 0.8246 - val_accuracy: 0.7097\n","Epoch 46/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7214 - accuracy: 0.7928 - val_loss: 0.8157 - val_accuracy: 0.7252\n","Epoch 47/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7295 - accuracy: 0.7824 - val_loss: 0.8406 - val_accuracy: 0.7138\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7243 - accuracy: 0.7855 - val_loss: 0.8173 - val_accuracy: 0.7211\n","Epoch 49/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7211 - accuracy: 0.7881 - val_loss: 0.8478 - val_accuracy: 0.6870\n","Epoch 50/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7171 - accuracy: 0.7946 - val_loss: 0.8321 - val_accuracy: 0.7314\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7151 - accuracy: 0.7920 - val_loss: 0.8200 - val_accuracy: 0.7252\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7173 - accuracy: 0.7881 - val_loss: 0.8203 - val_accuracy: 0.7076\n","Epoch 53/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7163 - accuracy: 0.7850 - val_loss: 0.8536 - val_accuracy: 0.6870\n","Epoch 54/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7248 - accuracy: 0.7791 - val_loss: 0.8155 - val_accuracy: 0.7169\n","Epoch 55/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7079 - accuracy: 0.8000 - val_loss: 0.8183 - val_accuracy: 0.7159\n","Epoch 56/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7053 - accuracy: 0.7951 - val_loss: 0.8175 - val_accuracy: 0.7221\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7101 - accuracy: 0.7884 - val_loss: 0.8176 - val_accuracy: 0.7159\n","Epoch 58/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7079 - accuracy: 0.7969 - val_loss: 0.8154 - val_accuracy: 0.7128\n","Epoch 59/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7085 - accuracy: 0.7961 - val_loss: 0.8198 - val_accuracy: 0.7252\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7072 - accuracy: 0.7915 - val_loss: 0.8423 - val_accuracy: 0.7138\n","Epoch 61/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7178 - accuracy: 0.7881 - val_loss: 0.8178 - val_accuracy: 0.7180\n","Epoch 62/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7047 - accuracy: 0.7920 - val_loss: 0.8198 - val_accuracy: 0.7273\n","Epoch 63/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7032 - accuracy: 0.7992 - val_loss: 0.8249 - val_accuracy: 0.7035\n","Epoch 64/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6969 - accuracy: 0.8023 - val_loss: 0.8525 - val_accuracy: 0.6860\n","Epoch 65/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6992 - accuracy: 0.7959 - val_loss: 0.8517 - val_accuracy: 0.6901\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7079 - accuracy: 0.7897 - val_loss: 0.8178 - val_accuracy: 0.7138\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6935 - accuracy: 0.7984 - val_loss: 0.8121 - val_accuracy: 0.7190\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6915 - accuracy: 0.7992 - val_loss: 0.8212 - val_accuracy: 0.7087\n","Epoch 69/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6863 - accuracy: 0.8121 - val_loss: 0.8227 - val_accuracy: 0.7190\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6888 - accuracy: 0.8065 - val_loss: 0.8248 - val_accuracy: 0.7169\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6885 - accuracy: 0.8049 - val_loss: 0.8164 - val_accuracy: 0.7118\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6861 - accuracy: 0.8052 - val_loss: 0.8185 - val_accuracy: 0.7180\n","Epoch 73/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6818 - accuracy: 0.8098 - val_loss: 0.8192 - val_accuracy: 0.7149\n","Epoch 74/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6892 - accuracy: 0.8018 - val_loss: 0.8674 - val_accuracy: 0.6746\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6938 - accuracy: 0.7933 - val_loss: 0.8133 - val_accuracy: 0.7169\n","Epoch 76/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6797 - accuracy: 0.8080 - val_loss: 0.8224 - val_accuracy: 0.7138\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6784 - accuracy: 0.8070 - val_loss: 0.8473 - val_accuracy: 0.7087\n","Epoch 78/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6783 - accuracy: 0.8088 - val_loss: 0.8243 - val_accuracy: 0.7190\n","Epoch 79/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6799 - accuracy: 0.8078 - val_loss: 0.8295 - val_accuracy: 0.7190\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6922 - accuracy: 0.7961 - val_loss: 0.8467 - val_accuracy: 0.6767\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6851 - accuracy: 0.8021 - val_loss: 0.8150 - val_accuracy: 0.7180\n","Epoch 82/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6672 - accuracy: 0.8168 - val_loss: 0.8242 - val_accuracy: 0.7200\n","Epoch 83/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6696 - accuracy: 0.8103 - val_loss: 0.8183 - val_accuracy: 0.7128\n","Epoch 84/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6706 - accuracy: 0.8127 - val_loss: 0.8200 - val_accuracy: 0.7056\n","Epoch 85/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6685 - accuracy: 0.8158 - val_loss: 0.8210 - val_accuracy: 0.7200\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6688 - accuracy: 0.8147 - val_loss: 0.8248 - val_accuracy: 0.7045\n","Epoch 87/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6643 - accuracy: 0.8173 - val_loss: 0.8183 - val_accuracy: 0.7097\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6639 - accuracy: 0.8217 - val_loss: 0.8558 - val_accuracy: 0.6808\n","Epoch 89/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6779 - accuracy: 0.8062 - val_loss: 0.8426 - val_accuracy: 0.6932\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6965 - accuracy: 0.7912 - val_loss: 0.8151 - val_accuracy: 0.7138\n","Epoch 91/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6588 - accuracy: 0.8199 - val_loss: 0.8284 - val_accuracy: 0.7025\n","Epoch 92/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6684 - accuracy: 0.8044 - val_loss: 0.8380 - val_accuracy: 0.7169\n","Epoch 93/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6578 - accuracy: 0.8176 - val_loss: 0.8701 - val_accuracy: 0.7056\n","Epoch 94/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6605 - accuracy: 0.8129 - val_loss: 0.8108 - val_accuracy: 0.7293\n","Epoch 95/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6504 - accuracy: 0.8230 - val_loss: 0.8180 - val_accuracy: 0.7159\n","Epoch 96/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6536 - accuracy: 0.8238 - val_loss: 0.8209 - val_accuracy: 0.7097\n","Epoch 97/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6590 - accuracy: 0.8160 - val_loss: 0.8152 - val_accuracy: 0.7159\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6546 - accuracy: 0.8207 - val_loss: 0.8208 - val_accuracy: 0.7242\n","Epoch 99/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6575 - accuracy: 0.8137 - val_loss: 0.8289 - val_accuracy: 0.7180\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6534 - accuracy: 0.8202 - val_loss: 0.8155 - val_accuracy: 0.7169\n","{'loss': [0.8164548873901367, 0.7953677773475647, 0.7942665815353394, 0.7995172739028931, 0.7921692728996277, 0.7874359488487244, 0.7840886116027832, 0.7858638763427734, 0.7843936681747437, 0.7757705450057983, 0.7771135568618774, 0.7735490798950195, 0.7850453853607178, 0.7699499726295471, 0.7682994604110718, 0.7679386138916016, 0.7619253396987915, 0.7638891339302063, 0.762675404548645, 0.7722254395484924, 0.7771669030189514, 0.7616769671440125, 0.7546757459640503, 0.7596029043197632, 0.750694215297699, 0.7549852728843689, 0.7495183944702148, 0.7457903623580933, 0.7547170519828796, 0.7513495087623596, 0.7447413802146912, 0.7394641637802124, 0.7469020485877991, 0.7421047687530518, 0.7368512153625488, 0.7332761287689209, 0.7408002018928528, 0.7318036556243896, 0.7285066246986389, 0.738970160484314, 0.740454912185669, 0.737450122833252, 0.7224488258361816, 0.7270504832267761, 0.7203401923179626, 0.7213900089263916, 0.729508101940155, 0.7242522239685059, 0.721124529838562, 0.7170513272285461, 0.7150533199310303, 0.7172569036483765, 0.7163320779800415, 0.7248354554176331, 0.7079428434371948, 0.7053065299987793, 0.7100721597671509, 0.7079465389251709, 0.7085119485855103, 0.7072350978851318, 0.7177581787109375, 0.7046943306922913, 0.7031940817832947, 0.696911633014679, 0.6992424726486206, 0.707886815071106, 0.6935398578643799, 0.6915331482887268, 0.6862507462501526, 0.6887627243995667, 0.6884950399398804, 0.6861422061920166, 0.6818090081214905, 0.6891717910766602, 0.6937929391860962, 0.6797003149986267, 0.6783933639526367, 0.6782682538032532, 0.6799458861351013, 0.6921584010124207, 0.6851104497909546, 0.6672421097755432, 0.6695635318756104, 0.6705716252326965, 0.6685415506362915, 0.6688389778137207, 0.6643093824386597, 0.6639046669006348, 0.6778541207313538, 0.6965196132659912, 0.6588158011436462, 0.6684169173240662, 0.6577872037887573, 0.660470187664032, 0.6504233479499817, 0.653617799282074, 0.6590172648429871, 0.6546458601951599, 0.6574602127075195, 0.6534188389778137], 'accuracy': [0.7441860437393188, 0.7658914923667908, 0.7596899271011353, 0.751937985420227, 0.7635658979415894, 0.7558139562606812, 0.7643410563468933, 0.7586563229560852, 0.7617571353912354, 0.764082670211792, 0.7664082646369934, 0.7692506313323975, 0.7547803521156311, 0.7759689688682556, 0.7692506313323975, 0.775452196598053, 0.7741602063179016, 0.773643434047699, 0.7751938104629517, 0.7645995020866394, 0.7532299757003784, 0.7695090174674988, 0.7806201577186584, 0.7666666507720947, 0.7785529494285583, 0.7788113951683044, 0.7793281674385071, 0.778294563293457, 0.7788113951683044, 0.7749354243278503, 0.7842377424240112, 0.7860465049743652, 0.7770025730133057, 0.7844961285591125, 0.7860465049743652, 0.7870801091194153, 0.7813953757286072, 0.7917312383651733, 0.7888888716697693, 0.7839793562889099, 0.7689922451972961, 0.7875968813896179, 0.7935400605201721, 0.7870801091194153, 0.7917312383651733, 0.7927648425102234, 0.7824289202690125, 0.7855297327041626, 0.7881137132644653, 0.7945736646652222, 0.7919896841049194, 0.7881137132644653, 0.7850129008293152, 0.7790697813034058, 0.800000011920929, 0.7950904369354248, 0.7883720993995667, 0.7968991994857788, 0.7961240410804749, 0.791472852230072, 0.7881137132644653, 0.7919896841049194, 0.7992247939109802, 0.8023256063461304, 0.7958656549453735, 0.789664089679718, 0.7984496355056763, 0.7992247939109802, 0.8121446967124939, 0.8064599633216858, 0.8049095869064331, 0.8051679730415344, 0.8098191022872925, 0.801808774471283, 0.7932816743850708, 0.8080103397369385, 0.8069767355918884, 0.8087855577468872, 0.8077519536018372, 0.7961240410804749, 0.8020671606063843, 0.8167958855628967, 0.8103359341621399, 0.8126614689826965, 0.8157622814178467, 0.8147286772727966, 0.8173126578330994, 0.8217054009437561, 0.8062015771865845, 0.7912144660949707, 0.8198966383934021, 0.8043927550315857, 0.8175710439682007, 0.8129199147224426, 0.8229973912239075, 0.8237726092338562, 0.816020667552948, 0.8206718564033508, 0.8136950731277466, 0.8201550245285034], 'val_loss': [0.9914405941963196, 0.9900005459785461, 0.9859963059425354, 0.9868331551551819, 0.9901490211486816, 0.9893047213554382, 0.9995893239974976, 1.0085095167160034, 0.9951019287109375, 1.0083445310592651, 0.988145112991333, 0.9705844521522522, 1.007306694984436, 1.0111660957336426, 0.9721207022666931, 1.0069093704223633, 1.012306809425354, 1.0065250396728516, 0.9113112092018127, 0.8756988644599915, 0.8470303416252136, 0.8490785956382751, 0.8367551565170288, 0.8378633856773376, 0.8322038054466248, 0.8279491066932678, 0.8332642912864685, 0.8409633040428162, 0.84454345703125, 0.8301289081573486, 0.8241882920265198, 0.826042115688324, 0.8215511441230774, 0.8229398131370544, 0.8238488435745239, 0.8230665922164917, 0.820609450340271, 0.8278513550758362, 0.8248257040977478, 0.8323745131492615, 0.8289397954940796, 0.821541428565979, 0.8250458836555481, 0.8197785019874573, 0.8246152400970459, 0.8156800866127014, 0.8405805826187134, 0.8172902464866638, 0.8478248119354248, 0.832118809223175, 0.8199878931045532, 0.8203096985816956, 0.8535527586936951, 0.81550532579422, 0.8182647228240967, 0.8174697160720825, 0.8175786733627319, 0.8153563141822815, 0.8197670578956604, 0.8422603011131287, 0.8177918195724487, 0.8197585940361023, 0.824866533279419, 0.8525120615959167, 0.851655900478363, 0.8177968859672546, 0.8120571970939636, 0.8212149143218994, 0.8227486610412598, 0.8247616291046143, 0.8163631558418274, 0.8184552192687988, 0.8191861510276794, 0.867414653301239, 0.8133251070976257, 0.8223831653594971, 0.8472508788108826, 0.8242923617362976, 0.829523503780365, 0.8467442393302917, 0.8150046467781067, 0.8242050409317017, 0.8183063268661499, 0.8200450539588928, 0.8209963440895081, 0.8248283863067627, 0.8183174729347229, 0.8557714819908142, 0.8426128625869751, 0.8151307106018066, 0.8283630013465881, 0.8380462527275085, 0.8701498508453369, 0.8107600212097168, 0.8180447816848755, 0.8209488391876221, 0.8151748180389404, 0.8208497166633606, 0.8289403319358826, 0.8154721260070801], 'val_accuracy': [0.4886363744735718, 0.4876033067703247, 0.49380165338516235, 0.4886363744735718, 0.4876033067703247, 0.4876033067703247, 0.4886363744735718, 0.4886363744735718, 0.4886363744735718, 0.4876033067703247, 0.49793389439582825, 0.5227272510528564, 0.4958677589893341, 0.5030992031097412, 0.5320248007774353, 0.5247933864593506, 0.5268595218658447, 0.5413222908973694, 0.625, 0.6694214940071106, 0.7045454382896423, 0.7055785059928894, 0.7138429880142212, 0.702479362487793, 0.7355371713638306, 0.7231404781341553, 0.6952479481697083, 0.6900826692581177, 0.682851254940033, 0.7014462947845459, 0.7179751992225647, 0.7097107172012329, 0.7252066135406494, 0.7221074104309082, 0.7169421315193176, 0.7159090638160706, 0.73037189245224, 0.7066115736961365, 0.7169421315193176, 0.7004132270812988, 0.7283057570457458, 0.7128099203109741, 0.7035123705863953, 0.7200413346290588, 0.7097107172012329, 0.7252066135406494, 0.7138429880142212, 0.7210744023323059, 0.6869834661483765, 0.7314049601554871, 0.7252066135406494, 0.7076446413993835, 0.6869834661483765, 0.7169421315193176, 0.7159090638160706, 0.7221074104309082, 0.7159090638160706, 0.7128099203109741, 0.7252066135406494, 0.7138429880142212, 0.7179751992225647, 0.7272727489471436, 0.7035123705863953, 0.6859503984451294, 0.6900826692581177, 0.7138429880142212, 0.7190082669258118, 0.7086777091026306, 0.7190082669258118, 0.7169421315193176, 0.711776852607727, 0.7179751992225647, 0.7148760557174683, 0.6745867729187012, 0.7169421315193176, 0.7138429880142212, 0.7086777091026306, 0.7190082669258118, 0.7190082669258118, 0.6766529083251953, 0.7179751992225647, 0.7200413346290588, 0.7128099203109741, 0.7055785059928894, 0.7200413346290588, 0.7045454382896423, 0.7097107172012329, 0.6807851195335388, 0.6931818127632141, 0.7138429880142212, 0.702479362487793, 0.7169421315193176, 0.7055785059928894, 0.7293388247489929, 0.7159090638160706, 0.7097107172012329, 0.7159090638160706, 0.7241735458374023, 0.7179751992225647, 0.7169421315193176]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.7245 - accuracy: 0.7729"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 5s 44ms/step - loss: 0.7245 - accuracy: 0.7729 - val_loss: 0.9571 - val_accuracy: 0.4871\n","Epoch 2/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6981 - accuracy: 0.7942 - val_loss: 0.9579 - val_accuracy: 0.4871\n","Epoch 3/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6884 - accuracy: 0.7990 - val_loss: 0.9585 - val_accuracy: 0.4871\n","Epoch 4/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6896 - accuracy: 0.7985 - val_loss: 0.9582 - val_accuracy: 0.4871\n","Epoch 5/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6841 - accuracy: 0.7998 - val_loss: 0.9681 - val_accuracy: 0.4871\n","Epoch 6/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6863 - accuracy: 0.7998 - val_loss: 0.9585 - val_accuracy: 0.4892\n","Epoch 7/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6861 - accuracy: 0.8015 - val_loss: 0.9859 - val_accuracy: 0.4871\n","Epoch 8/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6847 - accuracy: 0.7969 - val_loss: 0.9917 - val_accuracy: 0.4871\n","Epoch 9/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6856 - accuracy: 0.7993 - val_loss: 1.0010 - val_accuracy: 0.4871\n","Epoch 10/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6795 - accuracy: 0.8009 - val_loss: 0.9975 - val_accuracy: 0.4892\n","Epoch 11/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6794 - accuracy: 0.8039 - val_loss: 1.0381 - val_accuracy: 0.4871\n","Epoch 12/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6765 - accuracy: 0.8058 - val_loss: 1.0466 - val_accuracy: 0.4881\n","Epoch 13/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6789 - accuracy: 0.7985 - val_loss: 1.0324 - val_accuracy: 0.4914\n","Epoch 14/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6821 - accuracy: 0.7955 - val_loss: 1.1655 - val_accuracy: 0.4871\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6933 - accuracy: 0.7883 - val_loss: 1.1467 - val_accuracy: 0.4903\n","Epoch 16/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6773 - accuracy: 0.8023 - val_loss: 1.0689 - val_accuracy: 0.4968\n","Epoch 17/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6651 - accuracy: 0.8152 - val_loss: 1.1395 - val_accuracy: 0.4968\n","Epoch 18/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6632 - accuracy: 0.8155 - val_loss: 1.0449 - val_accuracy: 0.5280\n","Epoch 19/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6622 - accuracy: 0.8136 - val_loss: 0.9501 - val_accuracy: 0.5690\n","Epoch 20/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6661 - accuracy: 0.8103 - val_loss: 0.9799 - val_accuracy: 0.5657\n","Epoch 21/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6619 - accuracy: 0.8138 - val_loss: 0.9453 - val_accuracy: 0.5894\n","Epoch 22/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.6574 - accuracy: 0.8155 - val_loss: 0.8757 - val_accuracy: 0.6390\n","Epoch 23/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6582 - accuracy: 0.8149 - val_loss: 0.8869 - val_accuracy: 0.6336\n","Epoch 24/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.6710 - accuracy: 0.8066 - val_loss: 0.8123 - val_accuracy: 0.6853\n","Epoch 25/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6665 - accuracy: 0.8039 - val_loss: 0.8961 - val_accuracy: 0.6401\n","Epoch 26/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6607 - accuracy: 0.8101 - val_loss: 0.8350 - val_accuracy: 0.6638\n","Epoch 27/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6591 - accuracy: 0.8117 - val_loss: 0.7727 - val_accuracy: 0.7328\n","Epoch 28/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6597 - accuracy: 0.8098 - val_loss: 0.8453 - val_accuracy: 0.6703\n","Epoch 29/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.6523 - accuracy: 0.8184 - val_loss: 0.7770 - val_accuracy: 0.7338\n","Epoch 30/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6485 - accuracy: 0.8200 - val_loss: 0.7655 - val_accuracy: 0.7511\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6486 - accuracy: 0.8138 - val_loss: 0.7703 - val_accuracy: 0.7425\n","Epoch 32/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6495 - accuracy: 0.8187 - val_loss: 0.7593 - val_accuracy: 0.7565\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6579 - accuracy: 0.8098 - val_loss: 0.7844 - val_accuracy: 0.7295\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6428 - accuracy: 0.8217 - val_loss: 0.7784 - val_accuracy: 0.7381\n","Epoch 35/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6461 - accuracy: 0.8227 - val_loss: 0.7599 - val_accuracy: 0.7597\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6452 - accuracy: 0.8219 - val_loss: 0.7611 - val_accuracy: 0.7586\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6482 - accuracy: 0.8138 - val_loss: 0.7578 - val_accuracy: 0.7575\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6421 - accuracy: 0.8262 - val_loss: 0.7595 - val_accuracy: 0.7575\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6464 - accuracy: 0.8225 - val_loss: 0.7653 - val_accuracy: 0.7532\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6370 - accuracy: 0.8276 - val_loss: 0.7585 - val_accuracy: 0.7565\n","Epoch 41/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6362 - accuracy: 0.8268 - val_loss: 0.7781 - val_accuracy: 0.7403\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6322 - accuracy: 0.8314 - val_loss: 0.7605 - val_accuracy: 0.7586\n","Epoch 43/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6293 - accuracy: 0.8322 - val_loss: 0.7627 - val_accuracy: 0.7586\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6343 - accuracy: 0.8260 - val_loss: 0.7700 - val_accuracy: 0.7489\n","Epoch 45/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6273 - accuracy: 0.8343 - val_loss: 0.7622 - val_accuracy: 0.7575\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6358 - accuracy: 0.8273 - val_loss: 0.7763 - val_accuracy: 0.7468\n","Epoch 47/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.6309 - accuracy: 0.8295 - val_loss: 0.7580 - val_accuracy: 0.7619\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6320 - accuracy: 0.8262 - val_loss: 0.7766 - val_accuracy: 0.7446\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6267 - accuracy: 0.8311 - val_loss: 0.7743 - val_accuracy: 0.7446\n","Epoch 50/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6339 - accuracy: 0.8246 - val_loss: 0.7866 - val_accuracy: 0.7306\n","Epoch 51/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6359 - accuracy: 0.8222 - val_loss: 0.7705 - val_accuracy: 0.7468\n","Epoch 52/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6316 - accuracy: 0.8257 - val_loss: 0.7648 - val_accuracy: 0.7543\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6348 - accuracy: 0.8230 - val_loss: 0.7936 - val_accuracy: 0.7371\n","Epoch 54/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6191 - accuracy: 0.8357 - val_loss: 0.7642 - val_accuracy: 0.7511\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6188 - accuracy: 0.8354 - val_loss: 0.8092 - val_accuracy: 0.7112\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6228 - accuracy: 0.8322 - val_loss: 0.7693 - val_accuracy: 0.7500\n","Epoch 57/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6200 - accuracy: 0.8402 - val_loss: 0.8077 - val_accuracy: 0.7241\n","Epoch 58/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6213 - accuracy: 0.8330 - val_loss: 0.7700 - val_accuracy: 0.7554\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6242 - accuracy: 0.8270 - val_loss: 0.7688 - val_accuracy: 0.7489\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6122 - accuracy: 0.8367 - val_loss: 0.7673 - val_accuracy: 0.7522\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6164 - accuracy: 0.8389 - val_loss: 0.8025 - val_accuracy: 0.7306\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6091 - accuracy: 0.8421 - val_loss: 0.7889 - val_accuracy: 0.7263\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6133 - accuracy: 0.8373 - val_loss: 0.7761 - val_accuracy: 0.7532\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6345 - accuracy: 0.8230 - val_loss: 0.7992 - val_accuracy: 0.7317\n","Epoch 65/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6344 - accuracy: 0.8203 - val_loss: 0.7914 - val_accuracy: 0.7306\n","Epoch 66/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6055 - accuracy: 0.8394 - val_loss: 0.7663 - val_accuracy: 0.7640\n","Epoch 67/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6098 - accuracy: 0.8416 - val_loss: 0.7658 - val_accuracy: 0.7586\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6013 - accuracy: 0.8456 - val_loss: 0.7660 - val_accuracy: 0.7543\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6145 - accuracy: 0.8367 - val_loss: 0.7929 - val_accuracy: 0.7360\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6079 - accuracy: 0.8394 - val_loss: 0.7870 - val_accuracy: 0.7425\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6033 - accuracy: 0.8440 - val_loss: 0.8228 - val_accuracy: 0.7091\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6243 - accuracy: 0.8235 - val_loss: 0.8148 - val_accuracy: 0.7371\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6093 - accuracy: 0.8354 - val_loss: 0.7814 - val_accuracy: 0.7522\n","Epoch 74/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5920 - accuracy: 0.8553 - val_loss: 0.8017 - val_accuracy: 0.7241\n","Epoch 75/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5902 - accuracy: 0.8559 - val_loss: 0.7796 - val_accuracy: 0.7489\n","Epoch 76/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5964 - accuracy: 0.8470 - val_loss: 0.7812 - val_accuracy: 0.7435\n","Epoch 77/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5900 - accuracy: 0.8513 - val_loss: 0.8556 - val_accuracy: 0.6832\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5949 - accuracy: 0.8473 - val_loss: 0.7959 - val_accuracy: 0.7284\n","Epoch 79/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5920 - accuracy: 0.8481 - val_loss: 0.7890 - val_accuracy: 0.7371\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5968 - accuracy: 0.8408 - val_loss: 0.7732 - val_accuracy: 0.7478\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5894 - accuracy: 0.8516 - val_loss: 0.7730 - val_accuracy: 0.7500\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5817 - accuracy: 0.8591 - val_loss: 0.7701 - val_accuracy: 0.7575\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5871 - accuracy: 0.8540 - val_loss: 0.7746 - val_accuracy: 0.7500\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5862 - accuracy: 0.8508 - val_loss: 0.8281 - val_accuracy: 0.7188\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5784 - accuracy: 0.8596 - val_loss: 0.7733 - val_accuracy: 0.7532\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5806 - accuracy: 0.8556 - val_loss: 0.7707 - val_accuracy: 0.7522\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5768 - accuracy: 0.8656 - val_loss: 0.8093 - val_accuracy: 0.7360\n","Epoch 88/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5789 - accuracy: 0.8583 - val_loss: 0.7835 - val_accuracy: 0.7457\n","Epoch 89/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5709 - accuracy: 0.8640 - val_loss: 0.7958 - val_accuracy: 0.7274\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5784 - accuracy: 0.8570 - val_loss: 0.7801 - val_accuracy: 0.7446\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5985 - accuracy: 0.8446 - val_loss: 0.8490 - val_accuracy: 0.7284\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5844 - accuracy: 0.8553 - val_loss: 0.7995 - val_accuracy: 0.7349\n","Epoch 93/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5740 - accuracy: 0.8615 - val_loss: 0.8593 - val_accuracy: 0.6897\n","Epoch 94/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5889 - accuracy: 0.8473 - val_loss: 0.7841 - val_accuracy: 0.7500\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5768 - accuracy: 0.8540 - val_loss: 0.7971 - val_accuracy: 0.7478\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5669 - accuracy: 0.8664 - val_loss: 0.7823 - val_accuracy: 0.7565\n","Epoch 97/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5647 - accuracy: 0.8594 - val_loss: 0.8493 - val_accuracy: 0.7058\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5878 - accuracy: 0.8502 - val_loss: 0.7877 - val_accuracy: 0.7500\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5587 - accuracy: 0.8731 - val_loss: 0.7833 - val_accuracy: 0.7478\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5611 - accuracy: 0.8688 - val_loss: 0.7771 - val_accuracy: 0.7532\n","{'loss': [0.7244967222213745, 0.6981145739555359, 0.6884168386459351, 0.6896268725395203, 0.684076726436615, 0.6862797141075134, 0.6860753297805786, 0.684657633304596, 0.6855677366256714, 0.679483950138092, 0.679441511631012, 0.6764681339263916, 0.6788569688796997, 0.6821110248565674, 0.6933016180992126, 0.6773390173912048, 0.6651468873023987, 0.6632028222084045, 0.662160336971283, 0.6661031246185303, 0.6619479060173035, 0.657370924949646, 0.6581962704658508, 0.6710154414176941, 0.666519284248352, 0.6606932282447815, 0.6590697169303894, 0.6597198843955994, 0.6523007750511169, 0.6484891176223755, 0.648560643196106, 0.6494905948638916, 0.6578576564788818, 0.6428128480911255, 0.6461056470870972, 0.6451672911643982, 0.6482258439064026, 0.6420822739601135, 0.6463768482208252, 0.6369792222976685, 0.6361585259437561, 0.6321959495544434, 0.6293408870697021, 0.6343243718147278, 0.6272526979446411, 0.6358489990234375, 0.6308689117431641, 0.6320416927337646, 0.6266894340515137, 0.6339153051376343, 0.6358954310417175, 0.6315528750419617, 0.6347781419754028, 0.6191272139549255, 0.6187710762023926, 0.6227630972862244, 0.6199554800987244, 0.6213061213493347, 0.6241616010665894, 0.6121557950973511, 0.6163897514343262, 0.6091486811637878, 0.6133209466934204, 0.6345201134681702, 0.6343929171562195, 0.6055198311805725, 0.6098465919494629, 0.6013240814208984, 0.6145180463790894, 0.6078580021858215, 0.6033170819282532, 0.6243178844451904, 0.6093116998672485, 0.5919747948646545, 0.590225100517273, 0.5964455008506775, 0.59000563621521, 0.5948783755302429, 0.5919812917709351, 0.5968047976493835, 0.5893825888633728, 0.5816528797149658, 0.5871232151985168, 0.5861859321594238, 0.5784205794334412, 0.5806125998497009, 0.5767843723297119, 0.5789186954498291, 0.5709289908409119, 0.5783877372741699, 0.5984508395195007, 0.5843895673751831, 0.5739642977714539, 0.5889438390731812, 0.576793909072876, 0.5668528079986572, 0.5646979808807373, 0.5878257155418396, 0.558704137802124, 0.5611256957054138], 'accuracy': [0.7728987336158752, 0.7941810488700867, 0.7990301847457886, 0.798491358757019, 0.7998383641242981, 0.7998383641242981, 0.8014547228813171, 0.796875, 0.7992995977401733, 0.8009159564971924, 0.8038793206214905, 0.8057650923728943, 0.798491358757019, 0.795527994632721, 0.7882543206214905, 0.8022629022598267, 0.8151939511299133, 0.8154633641242981, 0.8135775923728943, 0.8103448152542114, 0.813847005367279, 0.8154633641242981, 0.8149245977401733, 0.8065732717514038, 0.8038793206214905, 0.8100754022598267, 0.8116918206214905, 0.8098060488700867, 0.8184267282485962, 0.8200430870056152, 0.813847005367279, 0.818696141242981, 0.8098060488700867, 0.821659505367279, 0.8227370977401733, 0.821928858757019, 0.813847005367279, 0.8262392282485962, 0.8224676847457886, 0.8275862336158752, 0.826777994632721, 0.8313577771186829, 0.8321659564971924, 0.8259698152542114, 0.834321141242981, 0.8273168206214905, 0.829472005367279, 0.8262392282485962, 0.8310883641242981, 0.8246228694915771, 0.8221982717514038, 0.8257004022598267, 0.8230064511299133, 0.8356680870056152, 0.8353987336158752, 0.8321659564971924, 0.8402478694915771, 0.8329741358757019, 0.8270474076271057, 0.8367456793785095, 0.8389008641242981, 0.842133641242981, 0.837284505367279, 0.8230064511299133, 0.8203125, 0.8394396305084229, 0.8415948152542114, 0.8456357717514038, 0.8367456793785095, 0.8394396305084229, 0.8440194129943848, 0.8235452771186829, 0.8353987336158752, 0.8553340435028076, 0.8558728694915771, 0.8469827771186829, 0.8512930870056152, 0.8472521305084229, 0.8480603694915771, 0.8407866358757019, 0.8515625, 0.8591055870056152, 0.8539870977401733, 0.8507543206214905, 0.8596444129943848, 0.8556034564971924, 0.865571141242981, 0.8582974076271057, 0.8639547228813171, 0.8569504022598267, 0.8445581793785095, 0.8553340435028076, 0.8615301847457886, 0.8472521305084229, 0.8539870977401733, 0.8663793206214905, 0.859375, 0.850215494632721, 0.8731142282485962, 0.868803858757019], 'val_loss': [0.9571293592453003, 0.9579274654388428, 0.9584913849830627, 0.9581685066223145, 0.9680948853492737, 0.9584821462631226, 0.9858723282814026, 0.9917133450508118, 1.0009777545928955, 0.9975365996360779, 1.0381075143814087, 1.046607255935669, 1.0324184894561768, 1.165541648864746, 1.1466574668884277, 1.0688802003860474, 1.1395443677902222, 1.0448908805847168, 0.9501143097877502, 0.9799148440361023, 0.9453215599060059, 0.8756622076034546, 0.8868594765663147, 0.8123339414596558, 0.8960985541343689, 0.8350377082824707, 0.7727300524711609, 0.8453084826469421, 0.7769829034805298, 0.7654967904090881, 0.7702693939208984, 0.759273111820221, 0.7843818664550781, 0.7783802151679993, 0.7599441409111023, 0.7611357569694519, 0.757811963558197, 0.7595009207725525, 0.7653113007545471, 0.7584748268127441, 0.7780940532684326, 0.7605293393135071, 0.7626854181289673, 0.7700034976005554, 0.7621950507164001, 0.7763168215751648, 0.757951021194458, 0.7766128778457642, 0.7742680907249451, 0.7866372466087341, 0.7704677581787109, 0.7647767066955566, 0.7935693264007568, 0.7642174959182739, 0.8092070817947388, 0.7693469524383545, 0.8077355623245239, 0.7700323462486267, 0.7687519192695618, 0.7673208713531494, 0.8024982810020447, 0.788930356502533, 0.7761355042457581, 0.7992239594459534, 0.7913843989372253, 0.7662570476531982, 0.7658397555351257, 0.7660119533538818, 0.7929236888885498, 0.7869767546653748, 0.8227915167808533, 0.8148115277290344, 0.7814098596572876, 0.801699161529541, 0.7795777916908264, 0.7811825275421143, 0.8556274771690369, 0.7958990335464478, 0.7890178561210632, 0.7732365131378174, 0.7729782462120056, 0.770050048828125, 0.7746083736419678, 0.8280864953994751, 0.7733237147331238, 0.7707279324531555, 0.809273898601532, 0.7835176587104797, 0.7957814931869507, 0.780076265335083, 0.8489859104156494, 0.7995169162750244, 0.859321117401123, 0.7840993404388428, 0.7971397042274475, 0.7823498845100403, 0.8492992520332336, 0.7877002358436584, 0.7833225131034851, 0.7771152853965759], 'val_accuracy': [0.48706895112991333, 0.48706895112991333, 0.48706895112991333, 0.48706895112991333, 0.48706895112991333, 0.4892241358757019, 0.48706895112991333, 0.48706895112991333, 0.48706895112991333, 0.4892241358757019, 0.48706895112991333, 0.4881465435028076, 0.4913793206214905, 0.48706895112991333, 0.4903017282485962, 0.4967672526836395, 0.4967672526836395, 0.5280172228813171, 0.568965494632721, 0.5657327771186829, 0.5894396305084229, 0.639008641242981, 0.6336206793785095, 0.6853448152542114, 0.6400862336158752, 0.6637930870056152, 0.732758641242981, 0.670258641242981, 0.7338362336158752, 0.7510775923728943, 0.7424569129943848, 0.756465494632721, 0.7295258641242981, 0.7381465435028076, 0.7596982717514038, 0.7586206793785095, 0.7575430870056152, 0.7575430870056152, 0.7532327771186829, 0.756465494632721, 0.7403017282485962, 0.7586206793785095, 0.7586206793785095, 0.7489224076271057, 0.7575430870056152, 0.7467672228813171, 0.7618534564971924, 0.7446120977401733, 0.7446120977401733, 0.7306034564971924, 0.7467672228813171, 0.7543103694915771, 0.7370689511299133, 0.7510775923728943, 0.7112069129943848, 0.75, 0.7241379022598267, 0.7553879022598267, 0.7489224076271057, 0.7521551847457886, 0.7306034564971924, 0.7262930870056152, 0.7532327771186829, 0.7316810488700867, 0.7306034564971924, 0.764008641242981, 0.7586206793785095, 0.7543103694915771, 0.735991358757019, 0.7424569129943848, 0.7090517282485962, 0.7370689511299133, 0.7521551847457886, 0.7241379022598267, 0.7489224076271057, 0.743534505367279, 0.6831896305084229, 0.7284482717514038, 0.7370689511299133, 0.7478448152542114, 0.75, 0.7575430870056152, 0.75, 0.71875, 0.7532327771186829, 0.7521551847457886, 0.735991358757019, 0.7456896305084229, 0.7273706793785095, 0.7446120977401733, 0.7284482717514038, 0.7349137663841248, 0.6896551847457886, 0.75, 0.7478448152542114, 0.756465494632721, 0.7058189511299133, 0.75, 0.7478448152542114, 0.7532327771186829]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.7152 - accuracy: 0.7881"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 4s 44ms/step - loss: 0.7140 - accuracy: 0.7875 - val_loss: 0.9512 - val_accuracy: 0.4989\n","Epoch 2/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6961 - accuracy: 0.7999 - val_loss: 0.9451 - val_accuracy: 0.5136\n","Epoch 3/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6973 - accuracy: 0.7934 - val_loss: 0.9494 - val_accuracy: 0.5023\n","Epoch 4/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6863 - accuracy: 0.8031 - val_loss: 0.9489 - val_accuracy: 0.5045\n","Epoch 5/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6810 - accuracy: 0.8104 - val_loss: 0.9496 - val_accuracy: 0.5034\n","Epoch 6/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6758 - accuracy: 0.8141 - val_loss: 0.9414 - val_accuracy: 0.5181\n","Epoch 7/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6929 - accuracy: 0.7974 - val_loss: 0.9483 - val_accuracy: 0.5079\n","Epoch 8/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6743 - accuracy: 0.8141 - val_loss: 0.9605 - val_accuracy: 0.5034\n","Epoch 9/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6691 - accuracy: 0.8240 - val_loss: 0.9661 - val_accuracy: 0.5034\n","Epoch 10/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6691 - accuracy: 0.8209 - val_loss: 0.9840 - val_accuracy: 0.5034\n","Epoch 11/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6774 - accuracy: 0.8115 - val_loss: 0.9823 - val_accuracy: 0.5045\n","Epoch 12/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6937 - accuracy: 0.7912 - val_loss: 1.0077 - val_accuracy: 0.5034\n","Epoch 13/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6946 - accuracy: 0.7937 - val_loss: 1.0343 - val_accuracy: 0.5034\n","Epoch 14/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6692 - accuracy: 0.8203 - val_loss: 1.0405 - val_accuracy: 0.5045\n","Epoch 15/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6667 - accuracy: 0.8110 - val_loss: 0.9799 - val_accuracy: 0.5317\n","Epoch 16/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6781 - accuracy: 0.8031 - val_loss: 1.0066 - val_accuracy: 0.5283\n","Epoch 17/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6626 - accuracy: 0.8203 - val_loss: 1.0385 - val_accuracy: 0.5249\n","Epoch 18/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6586 - accuracy: 0.8282 - val_loss: 0.9859 - val_accuracy: 0.5690\n","Epoch 19/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6562 - accuracy: 0.8248 - val_loss: 1.0817 - val_accuracy: 0.5317\n","Epoch 20/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6601 - accuracy: 0.8206 - val_loss: 0.9611 - val_accuracy: 0.5916\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6537 - accuracy: 0.8257 - val_loss: 0.9779 - val_accuracy: 0.5882\n","Epoch 22/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6624 - accuracy: 0.8149 - val_loss: 0.8622 - val_accuracy: 0.6606\n","Epoch 23/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6519 - accuracy: 0.8280 - val_loss: 0.8228 - val_accuracy: 0.6833\n","Epoch 24/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6546 - accuracy: 0.8234 - val_loss: 0.8482 - val_accuracy: 0.6765\n","Epoch 25/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6476 - accuracy: 0.8308 - val_loss: 0.8594 - val_accuracy: 0.6719\n","Epoch 26/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.6499 - accuracy: 0.8209 - val_loss: 0.8255 - val_accuracy: 0.6900\n","Epoch 27/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6448 - accuracy: 0.8314 - val_loss: 0.8183 - val_accuracy: 0.7002\n","Epoch 28/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.6588 - accuracy: 0.8166 - val_loss: 0.7806 - val_accuracy: 0.7455\n","Epoch 29/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6508 - accuracy: 0.8181 - val_loss: 0.7903 - val_accuracy: 0.7443\n","Epoch 30/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6512 - accuracy: 0.8243 - val_loss: 0.8232 - val_accuracy: 0.7014\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6429 - accuracy: 0.8288 - val_loss: 0.7919 - val_accuracy: 0.7387\n","Epoch 32/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6447 - accuracy: 0.8297 - val_loss: 0.7870 - val_accuracy: 0.7523\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6401 - accuracy: 0.8328 - val_loss: 0.7824 - val_accuracy: 0.7330\n","Epoch 34/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6573 - accuracy: 0.8135 - val_loss: 0.8133 - val_accuracy: 0.7251\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6412 - accuracy: 0.8297 - val_loss: 0.7810 - val_accuracy: 0.7511\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6343 - accuracy: 0.8424 - val_loss: 0.7786 - val_accuracy: 0.7523\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6333 - accuracy: 0.8381 - val_loss: 0.7922 - val_accuracy: 0.7466\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6381 - accuracy: 0.8331 - val_loss: 0.7776 - val_accuracy: 0.7500\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6326 - accuracy: 0.8356 - val_loss: 0.7854 - val_accuracy: 0.7330\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6264 - accuracy: 0.8413 - val_loss: 0.7809 - val_accuracy: 0.7489\n","Epoch 41/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6288 - accuracy: 0.8359 - val_loss: 0.7778 - val_accuracy: 0.7534\n","Epoch 42/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6285 - accuracy: 0.8328 - val_loss: 0.7810 - val_accuracy: 0.7534\n","Epoch 43/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6246 - accuracy: 0.8401 - val_loss: 0.7783 - val_accuracy: 0.7398\n","Epoch 44/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6259 - accuracy: 0.8387 - val_loss: 0.7919 - val_accuracy: 0.7545\n","Epoch 45/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6232 - accuracy: 0.8427 - val_loss: 0.7815 - val_accuracy: 0.7274\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6266 - accuracy: 0.8359 - val_loss: 0.8027 - val_accuracy: 0.7149\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6163 - accuracy: 0.8458 - val_loss: 0.7800 - val_accuracy: 0.7443\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6162 - accuracy: 0.8415 - val_loss: 0.7831 - val_accuracy: 0.7545\n","Epoch 49/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6167 - accuracy: 0.8435 - val_loss: 0.8017 - val_accuracy: 0.7410\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6280 - accuracy: 0.8297 - val_loss: 0.8238 - val_accuracy: 0.7104\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6164 - accuracy: 0.8421 - val_loss: 0.7816 - val_accuracy: 0.7500\n","Epoch 52/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6171 - accuracy: 0.8373 - val_loss: 0.7898 - val_accuracy: 0.7534\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6123 - accuracy: 0.8427 - val_loss: 0.7807 - val_accuracy: 0.7489\n","Epoch 54/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6075 - accuracy: 0.8463 - val_loss: 0.7897 - val_accuracy: 0.7240\n","Epoch 55/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6147 - accuracy: 0.8438 - val_loss: 0.7913 - val_accuracy: 0.7342\n","Epoch 56/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6051 - accuracy: 0.8486 - val_loss: 0.7852 - val_accuracy: 0.7319\n","Epoch 57/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6174 - accuracy: 0.8345 - val_loss: 0.7849 - val_accuracy: 0.7421\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6212 - accuracy: 0.8364 - val_loss: 0.8318 - val_accuracy: 0.7240\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6117 - accuracy: 0.8421 - val_loss: 0.8056 - val_accuracy: 0.7183\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6059 - accuracy: 0.8500 - val_loss: 0.7849 - val_accuracy: 0.7398\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6008 - accuracy: 0.8537 - val_loss: 0.8091 - val_accuracy: 0.7376\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6063 - accuracy: 0.8512 - val_loss: 0.8145 - val_accuracy: 0.7161\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5995 - accuracy: 0.8534 - val_loss: 0.7874 - val_accuracy: 0.7353\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5978 - accuracy: 0.8503 - val_loss: 0.7889 - val_accuracy: 0.7466\n","Epoch 65/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6193 - accuracy: 0.8356 - val_loss: 0.8338 - val_accuracy: 0.7308\n","Epoch 66/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6212 - accuracy: 0.8285 - val_loss: 0.8060 - val_accuracy: 0.7342\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6104 - accuracy: 0.8444 - val_loss: 0.7912 - val_accuracy: 0.7511\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5909 - accuracy: 0.8500 - val_loss: 0.7943 - val_accuracy: 0.7251\n","Epoch 69/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6009 - accuracy: 0.8441 - val_loss: 0.8165 - val_accuracy: 0.7104\n","Epoch 70/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5978 - accuracy: 0.8531 - val_loss: 0.7954 - val_accuracy: 0.7500\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5963 - accuracy: 0.8509 - val_loss: 0.8023 - val_accuracy: 0.7262\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5966 - accuracy: 0.8526 - val_loss: 0.7885 - val_accuracy: 0.7432\n","Epoch 73/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5833 - accuracy: 0.8594 - val_loss: 0.8043 - val_accuracy: 0.7161\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5874 - accuracy: 0.8568 - val_loss: 0.7899 - val_accuracy: 0.7376\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5970 - accuracy: 0.8506 - val_loss: 0.7970 - val_accuracy: 0.7206\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6004 - accuracy: 0.8452 - val_loss: 0.7926 - val_accuracy: 0.7410\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5843 - accuracy: 0.8605 - val_loss: 0.8084 - val_accuracy: 0.7443\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5862 - accuracy: 0.8585 - val_loss: 0.8051 - val_accuracy: 0.7206\n","Epoch 79/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5826 - accuracy: 0.8625 - val_loss: 0.8075 - val_accuracy: 0.7443\n","Epoch 80/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5756 - accuracy: 0.8633 - val_loss: 0.7987 - val_accuracy: 0.7262\n","Epoch 81/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5892 - accuracy: 0.8492 - val_loss: 0.8034 - val_accuracy: 0.7455\n","Epoch 82/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5854 - accuracy: 0.8509 - val_loss: 0.8006 - val_accuracy: 0.7274\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5827 - accuracy: 0.8554 - val_loss: 0.8074 - val_accuracy: 0.7149\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5651 - accuracy: 0.8721 - val_loss: 0.8008 - val_accuracy: 0.7274\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5680 - accuracy: 0.8676 - val_loss: 0.7957 - val_accuracy: 0.7410\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5663 - accuracy: 0.8690 - val_loss: 0.7932 - val_accuracy: 0.7443\n","Epoch 87/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5679 - accuracy: 0.8679 - val_loss: 0.8147 - val_accuracy: 0.7387\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5705 - accuracy: 0.8687 - val_loss: 0.7974 - val_accuracy: 0.7432\n","Epoch 89/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5661 - accuracy: 0.8667 - val_loss: 0.8164 - val_accuracy: 0.7432\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5756 - accuracy: 0.8554 - val_loss: 0.8952 - val_accuracy: 0.6923\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5963 - accuracy: 0.8396 - val_loss: 0.8354 - val_accuracy: 0.7353\n","Epoch 92/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5655 - accuracy: 0.8687 - val_loss: 0.8035 - val_accuracy: 0.7229\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5600 - accuracy: 0.8718 - val_loss: 0.8053 - val_accuracy: 0.7296\n","Epoch 94/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5584 - accuracy: 0.8738 - val_loss: 0.8127 - val_accuracy: 0.7206\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5499 - accuracy: 0.8772 - val_loss: 0.8051 - val_accuracy: 0.7229\n","Epoch 96/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5523 - accuracy: 0.8763 - val_loss: 0.8132 - val_accuracy: 0.7127\n","Epoch 97/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5662 - accuracy: 0.8645 - val_loss: 0.8018 - val_accuracy: 0.7398\n","Epoch 98/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5562 - accuracy: 0.8698 - val_loss: 0.8075 - val_accuracy: 0.7342\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5475 - accuracy: 0.8792 - val_loss: 0.8119 - val_accuracy: 0.7466\n","Epoch 100/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5449 - accuracy: 0.8820 - val_loss: 0.8090 - val_accuracy: 0.7387\n","{'loss': [0.7139579057693481, 0.6960811614990234, 0.6973463892936707, 0.6862707138061523, 0.6810125708580017, 0.6758480072021484, 0.6928521394729614, 0.6742981672286987, 0.6691406965255737, 0.6690667867660522, 0.6774497032165527, 0.6937046051025391, 0.6945595145225525, 0.6692221760749817, 0.6667206287384033, 0.6780955195426941, 0.6625834703445435, 0.6586300730705261, 0.6561557054519653, 0.6601063013076782, 0.6536951661109924, 0.6623955965042114, 0.6518553495407104, 0.6545956134796143, 0.647619366645813, 0.649945080280304, 0.6448155045509338, 0.6587868928909302, 0.6508080959320068, 0.6511822938919067, 0.6429174542427063, 0.6446542739868164, 0.6401300430297852, 0.6573393940925598, 0.641213059425354, 0.6342529058456421, 0.6333262920379639, 0.6381179094314575, 0.6326134204864502, 0.626436710357666, 0.6287551522254944, 0.628485918045044, 0.6245627999305725, 0.625872015953064, 0.623216986656189, 0.6266434788703918, 0.61634361743927, 0.6161894798278809, 0.6167462468147278, 0.6280351877212524, 0.616401731967926, 0.6170506477355957, 0.6123431921005249, 0.6074609756469727, 0.6147478818893433, 0.605117678642273, 0.6174285411834717, 0.62120521068573, 0.6117215752601624, 0.6059421896934509, 0.6007770895957947, 0.6062566637992859, 0.5994764566421509, 0.5978461503982544, 0.6192936897277832, 0.6211572885513306, 0.6103824377059937, 0.5908933281898499, 0.6009282469749451, 0.5977538824081421, 0.5963273048400879, 0.5966459512710571, 0.5832692980766296, 0.5874218940734863, 0.596968412399292, 0.6004098653793335, 0.5842815041542053, 0.5861815214157104, 0.5826122164726257, 0.5756279826164246, 0.5892348289489746, 0.5853732824325562, 0.5827354788780212, 0.5651049017906189, 0.5680278539657593, 0.5663232207298279, 0.5679051876068115, 0.5704994797706604, 0.5660952925682068, 0.5755875110626221, 0.5963091254234314, 0.5654852986335754, 0.5600141882896423, 0.5584470629692078, 0.5498925447463989, 0.5522880554199219, 0.5661821961402893, 0.556235671043396, 0.5474809408187866, 0.5449274182319641], 'accuracy': [0.7874929308891296, 0.7999433875083923, 0.7934352159500122, 0.803056001663208, 0.810413122177124, 0.814091682434082, 0.797396719455719, 0.814091682434082, 0.8239954710006714, 0.8208828568458557, 0.8115450143814087, 0.7911714911460876, 0.793718159198761, 0.8203169107437134, 0.8109790682792664, 0.803056001663208, 0.8203169107437134, 0.8282399773597717, 0.8248443603515625, 0.8205999135971069, 0.8256932497024536, 0.8149405717849731, 0.8279569745063782, 0.823429524898529, 0.8307866454124451, 0.8208828568458557, 0.8313525915145874, 0.8166383504867554, 0.8180531859397888, 0.8242784142494202, 0.8288058638572693, 0.8296547532081604, 0.8327674269676208, 0.8135257363319397, 0.8296547532081604, 0.8423882126808167, 0.8381437659263611, 0.8330503702163696, 0.835597038269043, 0.8412563800811768, 0.8358800411224365, 0.8327674269676208, 0.8401244878768921, 0.8387096524238586, 0.8426712155342102, 0.8358800411224365, 0.8457838296890259, 0.8415393233299255, 0.8435201048851013, 0.8296547532081604, 0.8421052694320679, 0.83729487657547, 0.8426712155342102, 0.8463497161865234, 0.8438030481338501, 0.848613440990448, 0.8344652056694031, 0.8364459276199341, 0.8421052694320679, 0.8500282764434814, 0.8537068367004395, 0.8511601686477661, 0.8534238934516907, 0.850311279296875, 0.835597038269043, 0.8285229206085205, 0.8443689942359924, 0.8500282764434814, 0.8440860509872437, 0.8531408905982971, 0.8508771657943726, 0.8525750041007996, 0.8593661785125732, 0.8568194508552551, 0.8505942225456238, 0.8452178835868835, 0.8604980111122131, 0.8585172891616821, 0.8624787926673889, 0.86332768201828, 0.8491793870925903, 0.8508771657943726, 0.8554046154022217, 0.8720995783805847, 0.8675721287727356, 0.868986964225769, 0.8678551316261292, 0.8687040209770203, 0.8667232394218445, 0.8554046154022217, 0.8395586013793945, 0.8687040209770203, 0.8718166351318359, 0.8737974166870117, 0.8771929740905762, 0.8763440847396851, 0.8644595146179199, 0.8698358535766602, 0.879173755645752, 0.8820033669471741], 'val_loss': [0.9511627554893494, 0.9450631737709045, 0.9493861198425293, 0.9489195346832275, 0.9496446847915649, 0.9414367079734802, 0.9482612609863281, 0.9604651927947998, 0.966071367263794, 0.983971118927002, 0.9822785258293152, 1.0077110528945923, 1.0343302488327026, 1.0404605865478516, 0.9799359440803528, 1.006638526916504, 1.0385230779647827, 0.9859064817428589, 1.081707239151001, 0.9610542058944702, 0.9779336452484131, 0.8621528744697571, 0.8227643966674805, 0.8481898307800293, 0.8594086766242981, 0.8254629969596863, 0.8182882070541382, 0.7806206345558167, 0.790307879447937, 0.8231912851333618, 0.7918866872787476, 0.7869880199432373, 0.7823619842529297, 0.8132703900337219, 0.7810264825820923, 0.7785696387290955, 0.792210042476654, 0.7776209712028503, 0.7854277491569519, 0.7808906435966492, 0.7777575850486755, 0.7810189723968506, 0.778329074382782, 0.7919268608093262, 0.7815182209014893, 0.8026836514472961, 0.7800266146659851, 0.7831477522850037, 0.8016730546951294, 0.8238123655319214, 0.7816016674041748, 0.7898178696632385, 0.7806997299194336, 0.7897263169288635, 0.7912748456001282, 0.7851724028587341, 0.7848755121231079, 0.8317773342132568, 0.8056135773658752, 0.7848848104476929, 0.8090919256210327, 0.8144930601119995, 0.7873610854148865, 0.7889131307601929, 0.8337863683700562, 0.8059765100479126, 0.7912202477455139, 0.7942891120910645, 0.816464364528656, 0.7953669428825378, 0.802334725856781, 0.7885122895240784, 0.8042584657669067, 0.7899060845375061, 0.7970001697540283, 0.7926178574562073, 0.8083940744400024, 0.8051009774208069, 0.8075244426727295, 0.7987248301506042, 0.803361177444458, 0.8006032109260559, 0.8074320554733276, 0.8007717132568359, 0.79570472240448, 0.7932485938072205, 0.8146511316299438, 0.7973833084106445, 0.8163764476776123, 0.8951596021652222, 0.8353758454322815, 0.8035320043563843, 0.8053265810012817, 0.8126511573791504, 0.8050751686096191, 0.8132072687149048, 0.80182284116745, 0.8075488209724426, 0.8118988275527954, 0.8089627623558044], 'val_accuracy': [0.49886876344680786, 0.5135746598243713, 0.5022624731063843, 0.5045248866081238, 0.5033936500549316, 0.5180995464324951, 0.5079185366630554, 0.5033936500549316, 0.5033936500549316, 0.5033936500549316, 0.5045248866081238, 0.5033936500549316, 0.5033936500549316, 0.5045248866081238, 0.5316742062568665, 0.5282805562019348, 0.5248869061470032, 0.5690045356750488, 0.5316742062568665, 0.5916289687156677, 0.5882353186607361, 0.6606335043907166, 0.6832579374313354, 0.6764705777168274, 0.6719456911087036, 0.6900452375411987, 0.7002262473106384, 0.7454751133918762, 0.7443438768386841, 0.7013574838638306, 0.7386877536773682, 0.7522624731063843, 0.733031690120697, 0.7251130938529968, 0.7511312365531921, 0.7522624731063843, 0.7466063499450684, 0.75, 0.733031690120697, 0.7488687634468079, 0.7533936500549316, 0.7533936500549316, 0.7398189902305603, 0.7545248866081238, 0.7273755669593811, 0.7149321436882019, 0.7443438768386841, 0.7545248866081238, 0.7409502267837524, 0.7104072570800781, 0.75, 0.7533936500549316, 0.7488687634468079, 0.7239819169044495, 0.7341628670692444, 0.7319004535675049, 0.7420814633369446, 0.7239819169044495, 0.7183257937431335, 0.7398189902305603, 0.7375565767288208, 0.7160633206367493, 0.7352941036224365, 0.7466063499450684, 0.7307692170143127, 0.7341628670692444, 0.7511312365531921, 0.7251130938529968, 0.7104072570800781, 0.75, 0.726244330406189, 0.7432126402854919, 0.7160633206367493, 0.7375565767288208, 0.720588207244873, 0.7409502267837524, 0.7443438768386841, 0.720588207244873, 0.7443438768386841, 0.726244330406189, 0.7454751133918762, 0.7273755669593811, 0.7149321436882019, 0.7273755669593811, 0.7409502267837524, 0.7443438768386841, 0.7386877536773682, 0.7432126402854919, 0.7432126402854919, 0.692307710647583, 0.7352941036224365, 0.7228506803512573, 0.7296379804611206, 0.720588207244873, 0.7228506803512573, 0.7126696705818176, 0.7398189902305603, 0.7341628670692444, 0.7466063499450684, 0.7386877536773682]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.7152 - accuracy: 0.7794"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 4s 44ms/step - loss: 0.7152 - accuracy: 0.7796 - val_loss: 0.9549 - val_accuracy: 0.4886\n","Epoch 2/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6886 - accuracy: 0.7917 - val_loss: 0.9569 - val_accuracy: 0.4886\n","Epoch 3/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6834 - accuracy: 0.8052 - val_loss: 0.9577 - val_accuracy: 0.4886\n","Epoch 4/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6790 - accuracy: 0.8018 - val_loss: 0.9628 - val_accuracy: 0.4886\n","Epoch 5/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6868 - accuracy: 0.7964 - val_loss: 0.9637 - val_accuracy: 0.4897\n","Epoch 6/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6858 - accuracy: 0.7972 - val_loss: 0.9720 - val_accuracy: 0.4886\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6808 - accuracy: 0.8021 - val_loss: 0.9831 - val_accuracy: 0.4886\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6807 - accuracy: 0.8021 - val_loss: 0.9959 - val_accuracy: 0.4886\n","Epoch 9/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.6690 - accuracy: 0.8142 - val_loss: 0.9880 - val_accuracy: 0.4917\n","Epoch 10/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6728 - accuracy: 0.8124 - val_loss: 1.0272 - val_accuracy: 0.4897\n","Epoch 11/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6646 - accuracy: 0.8114 - val_loss: 1.0450 - val_accuracy: 0.4907\n","Epoch 12/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6670 - accuracy: 0.8080 - val_loss: 1.0292 - val_accuracy: 0.4948\n","Epoch 13/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6753 - accuracy: 0.8026 - val_loss: 1.1193 - val_accuracy: 0.4897\n","Epoch 14/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6615 - accuracy: 0.8178 - val_loss: 1.1030 - val_accuracy: 0.4938\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6606 - accuracy: 0.8137 - val_loss: 1.1556 - val_accuracy: 0.4948\n","Epoch 16/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6646 - accuracy: 0.8054 - val_loss: 0.9959 - val_accuracy: 0.5331\n","Epoch 17/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6704 - accuracy: 0.8080 - val_loss: 1.1561 - val_accuracy: 0.5072\n","Epoch 18/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6567 - accuracy: 0.8178 - val_loss: 1.0520 - val_accuracy: 0.5310\n","Epoch 19/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6514 - accuracy: 0.8165 - val_loss: 1.0176 - val_accuracy: 0.5548\n","Epoch 20/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6521 - accuracy: 0.8147 - val_loss: 0.9605 - val_accuracy: 0.5971\n","Epoch 21/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6514 - accuracy: 0.8214 - val_loss: 0.8944 - val_accuracy: 0.6291\n","Epoch 22/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6588 - accuracy: 0.8163 - val_loss: 0.8491 - val_accuracy: 0.6581\n","Epoch 23/100\n","31/31 [==============================] - 4s 148ms/step - loss: 0.6472 - accuracy: 0.8207 - val_loss: 0.8109 - val_accuracy: 0.6942\n","Epoch 24/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6530 - accuracy: 0.8114 - val_loss: 0.8402 - val_accuracy: 0.6746\n","Epoch 25/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6652 - accuracy: 0.8036 - val_loss: 0.8206 - val_accuracy: 0.6942\n","Epoch 26/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6468 - accuracy: 0.8238 - val_loss: 0.7778 - val_accuracy: 0.7459\n","Epoch 27/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6440 - accuracy: 0.8233 - val_loss: 0.8119 - val_accuracy: 0.7004\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6403 - accuracy: 0.8313 - val_loss: 0.8071 - val_accuracy: 0.7087\n","Epoch 29/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6543 - accuracy: 0.8134 - val_loss: 0.7956 - val_accuracy: 0.7366\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6515 - accuracy: 0.8160 - val_loss: 0.7785 - val_accuracy: 0.7355\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6418 - accuracy: 0.8243 - val_loss: 0.7855 - val_accuracy: 0.7211\n","Epoch 32/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6609 - accuracy: 0.8124 - val_loss: 0.7773 - val_accuracy: 0.7366\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6333 - accuracy: 0.8310 - val_loss: 0.7830 - val_accuracy: 0.7211\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6354 - accuracy: 0.8269 - val_loss: 0.7961 - val_accuracy: 0.7221\n","Epoch 35/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6390 - accuracy: 0.8217 - val_loss: 0.7822 - val_accuracy: 0.7314\n","Epoch 36/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6339 - accuracy: 0.8297 - val_loss: 0.8012 - val_accuracy: 0.7293\n","Epoch 37/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6499 - accuracy: 0.8134 - val_loss: 0.8257 - val_accuracy: 0.7025\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6317 - accuracy: 0.8307 - val_loss: 0.8370 - val_accuracy: 0.6921\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6444 - accuracy: 0.8202 - val_loss: 0.8040 - val_accuracy: 0.7304\n","Epoch 40/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6283 - accuracy: 0.8339 - val_loss: 0.7854 - val_accuracy: 0.7355\n","Epoch 41/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6249 - accuracy: 0.8333 - val_loss: 0.7934 - val_accuracy: 0.7242\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6262 - accuracy: 0.8297 - val_loss: 0.8082 - val_accuracy: 0.7097\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6261 - accuracy: 0.8284 - val_loss: 0.7918 - val_accuracy: 0.7304\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6227 - accuracy: 0.8351 - val_loss: 0.7861 - val_accuracy: 0.7345\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6358 - accuracy: 0.8261 - val_loss: 0.8354 - val_accuracy: 0.6973\n","Epoch 46/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6255 - accuracy: 0.8217 - val_loss: 0.7849 - val_accuracy: 0.7242\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6148 - accuracy: 0.8372 - val_loss: 0.7868 - val_accuracy: 0.7345\n","Epoch 48/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6191 - accuracy: 0.8341 - val_loss: 0.8754 - val_accuracy: 0.7118\n","Epoch 49/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7110 - accuracy: 0.7757 - val_loss: 0.7819 - val_accuracy: 0.7366\n","Epoch 50/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6222 - accuracy: 0.8315 - val_loss: 0.7828 - val_accuracy: 0.7273\n","Epoch 51/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6108 - accuracy: 0.8395 - val_loss: 0.7893 - val_accuracy: 0.7273\n","Epoch 52/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6145 - accuracy: 0.8367 - val_loss: 0.8152 - val_accuracy: 0.7262\n","Epoch 53/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6231 - accuracy: 0.8289 - val_loss: 0.8795 - val_accuracy: 0.6787\n","Epoch 54/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6310 - accuracy: 0.8220 - val_loss: 0.8278 - val_accuracy: 0.7087\n","Epoch 55/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6151 - accuracy: 0.8390 - val_loss: 0.8133 - val_accuracy: 0.7304\n","Epoch 56/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6157 - accuracy: 0.8398 - val_loss: 0.8592 - val_accuracy: 0.6880\n","Epoch 57/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6144 - accuracy: 0.8390 - val_loss: 0.7845 - val_accuracy: 0.7335\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6161 - accuracy: 0.8339 - val_loss: 0.7927 - val_accuracy: 0.7262\n","Epoch 59/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6029 - accuracy: 0.8413 - val_loss: 0.7870 - val_accuracy: 0.7273\n","Epoch 60/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6017 - accuracy: 0.8434 - val_loss: 0.7849 - val_accuracy: 0.7335\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6172 - accuracy: 0.8336 - val_loss: 0.8620 - val_accuracy: 0.6839\n","Epoch 62/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6076 - accuracy: 0.8403 - val_loss: 0.8021 - val_accuracy: 0.7355\n","Epoch 63/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6016 - accuracy: 0.8426 - val_loss: 0.7881 - val_accuracy: 0.7283\n","Epoch 64/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5976 - accuracy: 0.8421 - val_loss: 0.7924 - val_accuracy: 0.7304\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5936 - accuracy: 0.8509 - val_loss: 0.7912 - val_accuracy: 0.7314\n","Epoch 66/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6013 - accuracy: 0.8444 - val_loss: 0.7967 - val_accuracy: 0.7366\n","Epoch 67/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5985 - accuracy: 0.8406 - val_loss: 0.7903 - val_accuracy: 0.7314\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5981 - accuracy: 0.8468 - val_loss: 0.8005 - val_accuracy: 0.7355\n","Epoch 69/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6027 - accuracy: 0.8465 - val_loss: 0.7891 - val_accuracy: 0.7345\n","Epoch 70/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5945 - accuracy: 0.8455 - val_loss: 0.7900 - val_accuracy: 0.7386\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6116 - accuracy: 0.8313 - val_loss: 0.7923 - val_accuracy: 0.7366\n","Epoch 72/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5973 - accuracy: 0.8465 - val_loss: 0.8556 - val_accuracy: 0.6932\n","Epoch 73/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5977 - accuracy: 0.8437 - val_loss: 0.8280 - val_accuracy: 0.7293\n","Epoch 74/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5998 - accuracy: 0.8437 - val_loss: 0.7968 - val_accuracy: 0.7252\n","Epoch 75/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5989 - accuracy: 0.8434 - val_loss: 0.7996 - val_accuracy: 0.7283\n","Epoch 76/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5977 - accuracy: 0.8380 - val_loss: 0.8002 - val_accuracy: 0.7324\n","Epoch 77/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5818 - accuracy: 0.8537 - val_loss: 0.8084 - val_accuracy: 0.7149\n","Epoch 78/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5875 - accuracy: 0.8501 - val_loss: 0.7945 - val_accuracy: 0.7335\n","Epoch 79/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5811 - accuracy: 0.8568 - val_loss: 0.7955 - val_accuracy: 0.7273\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5820 - accuracy: 0.8527 - val_loss: 0.8064 - val_accuracy: 0.7345\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5826 - accuracy: 0.8475 - val_loss: 0.8013 - val_accuracy: 0.7355\n","Epoch 82/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5855 - accuracy: 0.8460 - val_loss: 0.8093 - val_accuracy: 0.7293\n","Epoch 83/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5874 - accuracy: 0.8444 - val_loss: 0.8201 - val_accuracy: 0.7138\n","Epoch 84/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5766 - accuracy: 0.8563 - val_loss: 0.7963 - val_accuracy: 0.7293\n","Epoch 85/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5771 - accuracy: 0.8561 - val_loss: 0.8023 - val_accuracy: 0.7273\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6099 - accuracy: 0.8320 - val_loss: 0.8210 - val_accuracy: 0.7283\n","Epoch 87/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5864 - accuracy: 0.8494 - val_loss: 0.8034 - val_accuracy: 0.7293\n","Epoch 88/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5881 - accuracy: 0.8452 - val_loss: 0.8096 - val_accuracy: 0.7293\n","Epoch 89/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5716 - accuracy: 0.8556 - val_loss: 0.8128 - val_accuracy: 0.7231\n","Epoch 90/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5695 - accuracy: 0.8602 - val_loss: 0.8027 - val_accuracy: 0.7293\n","Epoch 91/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5605 - accuracy: 0.8690 - val_loss: 0.8059 - val_accuracy: 0.7273\n","Epoch 92/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5698 - accuracy: 0.8597 - val_loss: 0.8089 - val_accuracy: 0.7293\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5789 - accuracy: 0.8576 - val_loss: 0.8360 - val_accuracy: 0.7056\n","Epoch 94/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5705 - accuracy: 0.8571 - val_loss: 0.8099 - val_accuracy: 0.7293\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5627 - accuracy: 0.8584 - val_loss: 0.8095 - val_accuracy: 0.7273\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5636 - accuracy: 0.8680 - val_loss: 0.8430 - val_accuracy: 0.7025\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5668 - accuracy: 0.8581 - val_loss: 0.8746 - val_accuracy: 0.6890\n","Epoch 98/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5674 - accuracy: 0.8594 - val_loss: 0.8101 - val_accuracy: 0.7221\n","Epoch 99/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5623 - accuracy: 0.8651 - val_loss: 0.8128 - val_accuracy: 0.7314\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5585 - accuracy: 0.8672 - val_loss: 0.8074 - val_accuracy: 0.7335\n","{'loss': [0.7152005434036255, 0.688594400882721, 0.6833838820457458, 0.6789754629135132, 0.6868345737457275, 0.6858370900154114, 0.6808059811592102, 0.6806589961051941, 0.6690244078636169, 0.6728447079658508, 0.6646228432655334, 0.6669687628746033, 0.6753297448158264, 0.661537766456604, 0.6605836153030396, 0.6646183729171753, 0.6703906059265137, 0.656667947769165, 0.6513897776603699, 0.6520755290985107, 0.6513544917106628, 0.6587525606155396, 0.6472414135932922, 0.6530093550682068, 0.665155291557312, 0.6467511653900146, 0.6440431475639343, 0.64029461145401, 0.654287576675415, 0.6514740586280823, 0.6417719721794128, 0.6608691811561584, 0.633345365524292, 0.635351300239563, 0.6389923095703125, 0.6339308619499207, 0.649889349937439, 0.6316736340522766, 0.6443567276000977, 0.6282755136489868, 0.6248885989189148, 0.6262248158454895, 0.626118540763855, 0.6226551532745361, 0.6357862949371338, 0.6254830360412598, 0.6147892475128174, 0.6191389560699463, 0.7109518647193909, 0.6221696734428406, 0.6108136773109436, 0.6145453453063965, 0.6230868697166443, 0.6309970021247864, 0.6150641441345215, 0.615703821182251, 0.6143676042556763, 0.6160634160041809, 0.6028828620910645, 0.601710319519043, 0.61719810962677, 0.607568085193634, 0.6016465425491333, 0.5976269245147705, 0.5936428308486938, 0.6013334393501282, 0.5984595417976379, 0.5981446504592896, 0.6027174592018127, 0.5944774150848389, 0.6115860342979431, 0.5972668528556824, 0.5976757407188416, 0.5997822284698486, 0.5988999009132385, 0.5977034568786621, 0.5818281769752502, 0.5874528884887695, 0.581105649471283, 0.581997275352478, 0.582632839679718, 0.5854660272598267, 0.5874302983283997, 0.5766263604164124, 0.5771092772483826, 0.609923779964447, 0.5863909721374512, 0.5880940556526184, 0.5715681314468384, 0.5694995522499084, 0.5604796409606934, 0.569839358329773, 0.578914999961853, 0.5704820156097412, 0.5627300143241882, 0.563629150390625, 0.566787600517273, 0.5673819780349731, 0.5623227953910828, 0.5584907531738281], 'accuracy': [0.7795865535736084, 0.7917312383651733, 0.8051679730415344, 0.801808774471283, 0.7963824272155762, 0.7971576452255249, 0.8020671606063843, 0.8020671606063843, 0.814211905002594, 0.8124030828475952, 0.8113695383071899, 0.8080103397369385, 0.8025839924812317, 0.817829430103302, 0.8136950731277466, 0.8054263591766357, 0.8080103397369385, 0.817829430103302, 0.8165374398231506, 0.8147286772727966, 0.8214470148086548, 0.8162790536880493, 0.8206718564033508, 0.8113695383071899, 0.8036175966262817, 0.8237726092338562, 0.8232558369636536, 0.8312661647796631, 0.8134366869926453, 0.816020667552948, 0.8242893815040588, 0.8124030828475952, 0.8310077786445618, 0.8268733620643616, 0.8217054009437561, 0.8297157883644104, 0.8134366869926453, 0.8307493329048157, 0.8201550245285034, 0.8338501453399658, 0.8333333134651184, 0.8297157883644104, 0.828423798084259, 0.8351421356201172, 0.8260982036590576, 0.8217054009437561, 0.8372092843055725, 0.8341085314750671, 0.7757105827331543, 0.8315245509147644, 0.8395348787307739, 0.8366925120353699, 0.8289405703544617, 0.8219638466835022, 0.8390181064605713, 0.8397932648658752, 0.8390181064605713, 0.8338501453399658, 0.8413436412811279, 0.843410849571228, 0.8335917592048645, 0.8403100967407227, 0.8426356315612793, 0.8421188592910767, 0.8509044051170349, 0.8444444537162781, 0.840568482875824, 0.8467700481414795, 0.8465116024017334, 0.8454780578613281, 0.8312661647796631, 0.8465116024017334, 0.8436692357063293, 0.8436692357063293, 0.843410849571228, 0.8379845023155212, 0.853746771812439, 0.8501291871070862, 0.8568475246429443, 0.8527131676673889, 0.8475452065467834, 0.8459948301315308, 0.8444444537162781, 0.8563307523727417, 0.8560723662376404, 0.832041323184967, 0.8493540287017822, 0.845219612121582, 0.855555534362793, 0.8602067232131958, 0.868992269039154, 0.8596899509429932, 0.8576227426528931, 0.8571059703826904, 0.8583979606628418, 0.867958664894104, 0.8581395149230957, 0.8594315052032471, 0.8651162981987, 0.8671834468841553], 'val_loss': [0.9548835158348083, 0.9569491147994995, 0.9576587677001953, 0.9627515077590942, 0.9637354016304016, 0.9719943404197693, 0.983104407787323, 0.9958927035331726, 0.9880462288856506, 1.0272161960601807, 1.0449531078338623, 1.0291926860809326, 1.11925208568573, 1.1029729843139648, 1.1555588245391846, 0.9959397912025452, 1.1560534238815308, 1.051985740661621, 1.0175529718399048, 0.9605379700660706, 0.8944165706634521, 0.849111795425415, 0.8108954429626465, 0.8401598334312439, 0.8205967545509338, 0.7778490781784058, 0.8118522763252258, 0.8070594072341919, 0.7955648303031921, 0.7785277366638184, 0.7854631543159485, 0.7773030400276184, 0.7830296158790588, 0.7960625886917114, 0.7822168469429016, 0.8012408018112183, 0.8256858587265015, 0.8369672894477844, 0.8039567470550537, 0.7854030132293701, 0.7933966517448425, 0.8082388043403625, 0.7917841076850891, 0.7860605120658875, 0.8354329466819763, 0.7849416136741638, 0.7868151068687439, 0.875443160533905, 0.7818952202796936, 0.78275066614151, 0.7892656922340393, 0.8152273893356323, 0.8795047402381897, 0.8278119564056396, 0.8133265972137451, 0.8591877222061157, 0.7844663858413696, 0.7927037477493286, 0.786985456943512, 0.7849162220954895, 0.8619971871376038, 0.8020841479301453, 0.78814697265625, 0.7924004197120667, 0.7911739945411682, 0.7966572642326355, 0.7903290390968323, 0.8005074262619019, 0.7890785336494446, 0.7900177240371704, 0.7923060655593872, 0.8556484580039978, 0.8280337452888489, 0.796816349029541, 0.7996219396591187, 0.8002447485923767, 0.8084271550178528, 0.7945423722267151, 0.7954953908920288, 0.8063993453979492, 0.8013196587562561, 0.8093483448028564, 0.8200507164001465, 0.7963184714317322, 0.8022986650466919, 0.8209923505783081, 0.8033656477928162, 0.8095777630805969, 0.8127890825271606, 0.8027375340461731, 0.8059149980545044, 0.8089345097541809, 0.8360359072685242, 0.8098539113998413, 0.8094581961631775, 0.8430246114730835, 0.8745737671852112, 0.8101024627685547, 0.8127599954605103, 0.8074013590812683], 'val_accuracy': [0.4886363744735718, 0.4886363744735718, 0.4886363744735718, 0.4886363744735718, 0.48966941237449646, 0.4886363744735718, 0.4886363744735718, 0.4886363744735718, 0.4917355477809906, 0.48966941237449646, 0.49070248007774353, 0.4948347210884094, 0.48966941237449646, 0.49380165338516235, 0.4948347210884094, 0.5330578684806824, 0.5072314143180847, 0.5309917330741882, 0.5547520518302917, 0.5971074104309082, 0.6291322112083435, 0.6580578684806824, 0.6942148804664612, 0.6745867729187012, 0.6942148804664612, 0.7458677887916565, 0.7004132270812988, 0.7086777091026306, 0.7365702390670776, 0.7355371713638306, 0.7210744023323059, 0.7365702390670776, 0.7210744023323059, 0.7221074104309082, 0.7314049601554871, 0.7293388247489929, 0.702479362487793, 0.692148745059967, 0.73037189245224, 0.7355371713638306, 0.7241735458374023, 0.7097107172012329, 0.73037189245224, 0.7345041036605835, 0.6973140239715576, 0.7241735458374023, 0.7345041036605835, 0.711776852607727, 0.7365702390670776, 0.7272727489471436, 0.7272727489471436, 0.7262396812438965, 0.6787189841270447, 0.7086777091026306, 0.73037189245224, 0.6880165338516235, 0.7334710955619812, 0.7262396812438965, 0.7272727489471436, 0.7334710955619812, 0.68388432264328, 0.7355371713638306, 0.7283057570457458, 0.73037189245224, 0.7314049601554871, 0.7365702390670776, 0.7314049601554871, 0.7355371713638306, 0.7345041036605835, 0.7386363744735718, 0.7365702390670776, 0.6931818127632141, 0.7293388247489929, 0.7252066135406494, 0.7283057570457458, 0.7324380278587341, 0.7148760557174683, 0.7334710955619812, 0.7272727489471436, 0.7345041036605835, 0.7355371713638306, 0.7293388247489929, 0.7138429880142212, 0.7293388247489929, 0.7272727489471436, 0.7283057570457458, 0.7293388247489929, 0.7293388247489929, 0.7231404781341553, 0.7293388247489929, 0.7272727489471436, 0.7293388247489929, 0.7055785059928894, 0.7293388247489929, 0.7272727489471436, 0.702479362487793, 0.6890496015548706, 0.7221074104309082, 0.7314049601554871, 0.7334710955619812]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.6515 - accuracy: 0.8160"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 4s 43ms/step - loss: 0.6465 - accuracy: 0.8190 - val_loss: 0.9446 - val_accuracy: 0.4892\n","Epoch 2/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.6047 - accuracy: 0.8419 - val_loss: 0.9419 - val_accuracy: 0.4925\n","Epoch 3/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.6074 - accuracy: 0.8359 - val_loss: 0.9436 - val_accuracy: 0.4935\n","Epoch 4/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.6067 - accuracy: 0.8351 - val_loss: 0.9430 - val_accuracy: 0.4946\n","Epoch 5/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6061 - accuracy: 0.8384 - val_loss: 0.9454 - val_accuracy: 0.4978\n","Epoch 6/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5986 - accuracy: 0.8432 - val_loss: 0.9655 - val_accuracy: 0.4892\n","Epoch 7/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5939 - accuracy: 0.8435 - val_loss: 0.9756 - val_accuracy: 0.4914\n","Epoch 8/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5927 - accuracy: 0.8451 - val_loss: 0.9839 - val_accuracy: 0.4925\n","Epoch 9/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5890 - accuracy: 0.8475 - val_loss: 0.9876 - val_accuracy: 0.4935\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6184 - accuracy: 0.8279 - val_loss: 1.0263 - val_accuracy: 0.4914\n","Epoch 11/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5852 - accuracy: 0.8524 - val_loss: 1.0218 - val_accuracy: 0.4957\n","Epoch 12/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5830 - accuracy: 0.8526 - val_loss: 1.1108 - val_accuracy: 0.4914\n","Epoch 13/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5964 - accuracy: 0.8483 - val_loss: 1.0239 - val_accuracy: 0.5108\n","Epoch 14/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5880 - accuracy: 0.8473 - val_loss: 1.1185 - val_accuracy: 0.4968\n","Epoch 15/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5801 - accuracy: 0.8532 - val_loss: 1.0544 - val_accuracy: 0.5194\n","Epoch 16/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5825 - accuracy: 0.8478 - val_loss: 1.1681 - val_accuracy: 0.5054\n","Epoch 17/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5727 - accuracy: 0.8634 - val_loss: 1.1734 - val_accuracy: 0.5140\n","Epoch 18/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5779 - accuracy: 0.8570 - val_loss: 1.0973 - val_accuracy: 0.5312\n","Epoch 19/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5759 - accuracy: 0.8570 - val_loss: 1.0102 - val_accuracy: 0.5614\n","Epoch 20/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5762 - accuracy: 0.8570 - val_loss: 1.0426 - val_accuracy: 0.5614\n","Epoch 21/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5705 - accuracy: 0.8596 - val_loss: 0.9635 - val_accuracy: 0.5948\n","Epoch 22/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5705 - accuracy: 0.8580 - val_loss: 1.0580 - val_accuracy: 0.5819\n","Epoch 23/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.5698 - accuracy: 0.8543 - val_loss: 0.9876 - val_accuracy: 0.6056\n","Epoch 24/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.5644 - accuracy: 0.8621 - val_loss: 0.8346 - val_accuracy: 0.6746\n","Epoch 25/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5716 - accuracy: 0.8591 - val_loss: 0.8469 - val_accuracy: 0.6638\n","Epoch 26/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.5701 - accuracy: 0.8610 - val_loss: 0.7792 - val_accuracy: 0.7144\n","Epoch 27/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.5623 - accuracy: 0.8675 - val_loss: 0.7308 - val_accuracy: 0.7608\n","Epoch 28/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5647 - accuracy: 0.8596 - val_loss: 0.7555 - val_accuracy: 0.7468\n","Epoch 29/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5688 - accuracy: 0.8534 - val_loss: 0.7813 - val_accuracy: 0.7220\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5917 - accuracy: 0.8405 - val_loss: 0.8118 - val_accuracy: 0.7080\n","Epoch 31/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5855 - accuracy: 0.8416 - val_loss: 0.7350 - val_accuracy: 0.7802\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5570 - accuracy: 0.8602 - val_loss: 0.7393 - val_accuracy: 0.7748\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5642 - accuracy: 0.8607 - val_loss: 0.7493 - val_accuracy: 0.7662\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5696 - accuracy: 0.8521 - val_loss: 0.7507 - val_accuracy: 0.7565\n","Epoch 35/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5505 - accuracy: 0.8742 - val_loss: 0.7721 - val_accuracy: 0.7381\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5699 - accuracy: 0.8540 - val_loss: 0.7802 - val_accuracy: 0.7381\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5504 - accuracy: 0.8680 - val_loss: 0.7399 - val_accuracy: 0.7705\n","Epoch 38/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5455 - accuracy: 0.8801 - val_loss: 0.7490 - val_accuracy: 0.7586\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5465 - accuracy: 0.8772 - val_loss: 0.7802 - val_accuracy: 0.7586\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5685 - accuracy: 0.8529 - val_loss: 0.7383 - val_accuracy: 0.7726\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5391 - accuracy: 0.8812 - val_loss: 0.7699 - val_accuracy: 0.7532\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5385 - accuracy: 0.8782 - val_loss: 0.7451 - val_accuracy: 0.7640\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5409 - accuracy: 0.8769 - val_loss: 0.7381 - val_accuracy: 0.7716\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5490 - accuracy: 0.8675 - val_loss: 0.7740 - val_accuracy: 0.7489\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5354 - accuracy: 0.8766 - val_loss: 0.7478 - val_accuracy: 0.7683\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5636 - accuracy: 0.8521 - val_loss: 0.8247 - val_accuracy: 0.7166\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5481 - accuracy: 0.8726 - val_loss: 0.7502 - val_accuracy: 0.7543\n","Epoch 48/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5316 - accuracy: 0.8825 - val_loss: 0.7434 - val_accuracy: 0.7748\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5342 - accuracy: 0.8753 - val_loss: 0.7860 - val_accuracy: 0.7414\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5353 - accuracy: 0.8777 - val_loss: 0.7451 - val_accuracy: 0.7586\n","Epoch 51/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5328 - accuracy: 0.8839 - val_loss: 0.7573 - val_accuracy: 0.7575\n","Epoch 52/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5344 - accuracy: 0.8850 - val_loss: 0.7942 - val_accuracy: 0.7328\n","Epoch 53/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5483 - accuracy: 0.8669 - val_loss: 0.8176 - val_accuracy: 0.7306\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5317 - accuracy: 0.8790 - val_loss: 0.7453 - val_accuracy: 0.7683\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5221 - accuracy: 0.8882 - val_loss: 0.7594 - val_accuracy: 0.7565\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5212 - accuracy: 0.8887 - val_loss: 0.7534 - val_accuracy: 0.7640\n","Epoch 57/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5403 - accuracy: 0.8734 - val_loss: 0.7667 - val_accuracy: 0.7565\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5338 - accuracy: 0.8720 - val_loss: 0.7669 - val_accuracy: 0.7565\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5247 - accuracy: 0.8823 - val_loss: 0.7605 - val_accuracy: 0.7522\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5387 - accuracy: 0.8683 - val_loss: 0.8014 - val_accuracy: 0.7435\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5233 - accuracy: 0.8823 - val_loss: 0.8694 - val_accuracy: 0.6994\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5251 - accuracy: 0.8825 - val_loss: 0.7686 - val_accuracy: 0.7575\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5174 - accuracy: 0.8869 - val_loss: 0.7653 - val_accuracy: 0.7575\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5220 - accuracy: 0.8869 - val_loss: 0.7529 - val_accuracy: 0.7640\n","Epoch 65/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5141 - accuracy: 0.8895 - val_loss: 0.7552 - val_accuracy: 0.7683\n","Epoch 66/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5160 - accuracy: 0.8860 - val_loss: 0.7960 - val_accuracy: 0.7414\n","Epoch 67/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5124 - accuracy: 0.8941 - val_loss: 0.7630 - val_accuracy: 0.7662\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5121 - accuracy: 0.8928 - val_loss: 0.7709 - val_accuracy: 0.7575\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5084 - accuracy: 0.8966 - val_loss: 0.7671 - val_accuracy: 0.7608\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5064 - accuracy: 0.8912 - val_loss: 0.8661 - val_accuracy: 0.7069\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5115 - accuracy: 0.8930 - val_loss: 0.8435 - val_accuracy: 0.7188\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5269 - accuracy: 0.8777 - val_loss: 0.8841 - val_accuracy: 0.6897\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5267 - accuracy: 0.8761 - val_loss: 0.7890 - val_accuracy: 0.7360\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5040 - accuracy: 0.8939 - val_loss: 0.7577 - val_accuracy: 0.7597\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4933 - accuracy: 0.9011 - val_loss: 0.8145 - val_accuracy: 0.7274\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5027 - accuracy: 0.8966 - val_loss: 0.7725 - val_accuracy: 0.7532\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4977 - accuracy: 0.8995 - val_loss: 0.7715 - val_accuracy: 0.7586\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4911 - accuracy: 0.9017 - val_loss: 0.7685 - val_accuracy: 0.7565\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4967 - accuracy: 0.9017 - val_loss: 0.7722 - val_accuracy: 0.7468\n","Epoch 80/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4943 - accuracy: 0.9019 - val_loss: 0.8200 - val_accuracy: 0.7371\n","Epoch 81/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4921 - accuracy: 0.8987 - val_loss: 0.7732 - val_accuracy: 0.7619\n","Epoch 82/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4880 - accuracy: 0.9001 - val_loss: 0.7952 - val_accuracy: 0.7478\n","Epoch 83/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4984 - accuracy: 0.8963 - val_loss: 0.7803 - val_accuracy: 0.7586\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4917 - accuracy: 0.9009 - val_loss: 0.7758 - val_accuracy: 0.7575\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4794 - accuracy: 0.9146 - val_loss: 0.7796 - val_accuracy: 0.7511\n","Epoch 86/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4846 - accuracy: 0.9079 - val_loss: 0.7926 - val_accuracy: 0.7435\n","Epoch 87/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4915 - accuracy: 0.9006 - val_loss: 0.7813 - val_accuracy: 0.7543\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4889 - accuracy: 0.9022 - val_loss: 0.7807 - val_accuracy: 0.7651\n","Epoch 89/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4802 - accuracy: 0.9057 - val_loss: 0.7991 - val_accuracy: 0.7446\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4931 - accuracy: 0.8995 - val_loss: 0.8228 - val_accuracy: 0.7360\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4821 - accuracy: 0.9054 - val_loss: 0.8593 - val_accuracy: 0.7231\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4940 - accuracy: 0.8957 - val_loss: 0.7774 - val_accuracy: 0.7575\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4768 - accuracy: 0.9068 - val_loss: 0.8045 - val_accuracy: 0.7457\n","Epoch 94/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4740 - accuracy: 0.9119 - val_loss: 0.8146 - val_accuracy: 0.7435\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4812 - accuracy: 0.8987 - val_loss: 0.7862 - val_accuracy: 0.7435\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4762 - accuracy: 0.9114 - val_loss: 0.8256 - val_accuracy: 0.7381\n","Epoch 97/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4752 - accuracy: 0.9143 - val_loss: 0.7974 - val_accuracy: 0.7478\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4775 - accuracy: 0.9044 - val_loss: 0.7869 - val_accuracy: 0.7457\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4739 - accuracy: 0.9041 - val_loss: 0.7964 - val_accuracy: 0.7575\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4726 - accuracy: 0.9124 - val_loss: 0.7997 - val_accuracy: 0.7457\n","{'loss': [0.6465239524841309, 0.6047035455703735, 0.6073583960533142, 0.6066896915435791, 0.6060988306999207, 0.5986074209213257, 0.5938737988471985, 0.5926622748374939, 0.5889770984649658, 0.6184065341949463, 0.5852111577987671, 0.5829598903656006, 0.5964198708534241, 0.5879894495010376, 0.5800708532333374, 0.5824766755104065, 0.5727092027664185, 0.5778515338897705, 0.5759475827217102, 0.5761801600456238, 0.5704934597015381, 0.5704676508903503, 0.5697764158248901, 0.5644376873970032, 0.571624755859375, 0.5700709223747253, 0.5623162388801575, 0.5647116899490356, 0.5687887072563171, 0.5917322039604187, 0.5854801535606384, 0.5569906830787659, 0.5641996264457703, 0.5696428418159485, 0.5504776239395142, 0.5698546767234802, 0.5504044890403748, 0.5454959869384766, 0.5465419888496399, 0.5684887170791626, 0.5390604138374329, 0.5385128259658813, 0.5408848524093628, 0.5490095615386963, 0.5354251265525818, 0.5636008977890015, 0.5480706691741943, 0.5316301584243774, 0.5342199206352234, 0.535304844379425, 0.5328226685523987, 0.5343683958053589, 0.5482900738716125, 0.5316820740699768, 0.5221495628356934, 0.5212382674217224, 0.5403367877006531, 0.5338159799575806, 0.5247031450271606, 0.5386503338813782, 0.5233347415924072, 0.5251415371894836, 0.5174294710159302, 0.5219566226005554, 0.5141379833221436, 0.5160183906555176, 0.5124028921127319, 0.5121095180511475, 0.5084410905838013, 0.5063707232475281, 0.5114549398422241, 0.526929497718811, 0.5267077684402466, 0.5039716362953186, 0.4933203458786011, 0.5026958584785461, 0.4977492094039917, 0.4911150634288788, 0.49672940373420715, 0.49427199363708496, 0.492051362991333, 0.48803049325942993, 0.49837756156921387, 0.4917020797729492, 0.4793849289417267, 0.48457303643226624, 0.491492360830307, 0.4888537526130676, 0.4802241027355194, 0.49307122826576233, 0.4820537269115448, 0.49398303031921387, 0.4768347144126892, 0.47404783964157104, 0.4811542332172394, 0.476232647895813, 0.47521814703941345, 0.4775380492210388, 0.47391626238822937, 0.4726223349571228], 'accuracy': [0.818965494632721, 0.8418642282485962, 0.8359375, 0.8351293206214905, 0.8383620977401733, 0.8432112336158752, 0.8434805870056152, 0.845097005367279, 0.8475215435028076, 0.8278555870056152, 0.8523706793785095, 0.8526400923728943, 0.8483297228813171, 0.8472521305084229, 0.853178858757019, 0.8477909564971924, 0.8634159564971924, 0.8569504022598267, 0.8569504022598267, 0.8569504022598267, 0.8596444129943848, 0.858027994632721, 0.8542564511299133, 0.8620689511299133, 0.8591055870056152, 0.860991358757019, 0.8674569129943848, 0.8596444129943848, 0.8534482717514038, 0.8405172228813171, 0.8415948152542114, 0.8601831793785095, 0.860722005367279, 0.8521012663841248, 0.8741918206214905, 0.8539870977401733, 0.8679956793785095, 0.8801185488700867, 0.8771551847457886, 0.852909505367279, 0.881196141242981, 0.8782327771186829, 0.8768857717514038, 0.8674569129943848, 0.876616358757019, 0.8521012663841248, 0.8725754022598267, 0.8825430870056152, 0.8752694129943848, 0.8776939511299133, 0.8838900923728943, 0.8849676847457886, 0.8669180870056152, 0.8790409564971924, 0.8882004022598267, 0.8887392282485962, 0.873383641242981, 0.8720366358757019, 0.8822737336158752, 0.8682650923728943, 0.8822737336158752, 0.8825430870056152, 0.8868534564971924, 0.8868534564971924, 0.8895474076271057, 0.8860452771186829, 0.8941271305084229, 0.8927801847457886, 0.8965517282485962, 0.8911637663841248, 0.8930495977401733, 0.8776939511299133, 0.8760775923728943, 0.8938577771186829, 0.9011314511299133, 0.8965517282485962, 0.8995150923728943, 0.9016702771186829, 0.9016702771186829, 0.9019396305084229, 0.8987069129943848, 0.900053858757019, 0.8962823152542114, 0.9008620977401733, 0.9146012663841248, 0.907866358757019, 0.9005926847457886, 0.9022090435028076, 0.9057112336158752, 0.8995150923728943, 0.9054418206214905, 0.8957435488700867, 0.9067887663841248, 0.9119073152542114, 0.8987069129943848, 0.9113685488700867, 0.9143319129943848, 0.9043642282485962, 0.9040948152542114, 0.912446141242981], 'val_loss': [0.9445808529853821, 0.9418839812278748, 0.9436017870903015, 0.9430224299430847, 0.9454295635223389, 0.9654574990272522, 0.9756117463111877, 0.983898937702179, 0.9876195788383484, 1.0263460874557495, 1.0218461751937866, 1.110762357711792, 1.0238678455352783, 1.1185226440429688, 1.054423451423645, 1.1681057214736938, 1.1733899116516113, 1.0972504615783691, 1.0102007389068604, 1.0426210165023804, 0.9634730815887451, 1.0580394268035889, 0.9876366853713989, 0.8346450328826904, 0.8468697667121887, 0.7791671752929688, 0.7307974100112915, 0.7554867267608643, 0.7813345193862915, 0.8117518424987793, 0.7349604368209839, 0.7393295764923096, 0.7492682337760925, 0.7507237195968628, 0.7720867395401001, 0.78023761510849, 0.7399242520332336, 0.7490475177764893, 0.7801844477653503, 0.7382878065109253, 0.769910454750061, 0.7450929880142212, 0.7380558252334595, 0.7740339636802673, 0.7478123903274536, 0.8246932625770569, 0.7502356767654419, 0.7433792352676392, 0.7859681248664856, 0.7450805306434631, 0.7572694420814514, 0.7941905856132507, 0.8175956010818481, 0.7452833652496338, 0.7593873739242554, 0.7533544898033142, 0.7667410373687744, 0.7668597102165222, 0.7604660391807556, 0.8014342188835144, 0.869369387626648, 0.7686192989349365, 0.765319287776947, 0.7529246807098389, 0.7552458643913269, 0.7959792613983154, 0.7629501819610596, 0.7709071040153503, 0.7670866250991821, 0.8661434650421143, 0.8434615731239319, 0.8841018080711365, 0.7890178561210632, 0.7576814293861389, 0.8145333528518677, 0.7724595665931702, 0.7715290784835815, 0.7684999704360962, 0.7721921801567078, 0.8199996948242188, 0.773218035697937, 0.7952008247375488, 0.780305802822113, 0.7757589817047119, 0.7796226143836975, 0.7926234006881714, 0.7812676429748535, 0.7807163000106812, 0.7990735173225403, 0.8227883577346802, 0.8592994809150696, 0.7773833274841309, 0.8044787645339966, 0.8146274089813232, 0.7861918210983276, 0.8256098628044128, 0.7974048256874084, 0.786943793296814, 0.7964046597480774, 0.7997143268585205], 'val_accuracy': [0.4892241358757019, 0.4924568831920624, 0.49353447556495667, 0.49461206793785095, 0.4978448152542114, 0.4892241358757019, 0.4913793206214905, 0.4924568831920624, 0.49353447556495667, 0.4913793206214905, 0.49568966031074524, 0.4913793206214905, 0.5107758641242981, 0.4967672526836395, 0.5193965435028076, 0.5053879022598267, 0.514008641242981, 0.53125, 0.5614224076271057, 0.5614224076271057, 0.5948275923728943, 0.5818965435028076, 0.6056034564971924, 0.6745689511299133, 0.6637930870056152, 0.7144396305084229, 0.7607758641242981, 0.7467672228813171, 0.7219827771186829, 0.7079741358757019, 0.7801724076271057, 0.774784505367279, 0.7661637663841248, 0.756465494632721, 0.7381465435028076, 0.7381465435028076, 0.7704741358757019, 0.7586206793785095, 0.7586206793785095, 0.7726293206214905, 0.7532327771186829, 0.764008641242981, 0.7715517282485962, 0.7489224076271057, 0.7683189511299133, 0.7165948152542114, 0.7543103694915771, 0.774784505367279, 0.7413793206214905, 0.7586206793785095, 0.7575430870056152, 0.732758641242981, 0.7306034564971924, 0.7683189511299133, 0.756465494632721, 0.764008641242981, 0.756465494632721, 0.756465494632721, 0.7521551847457886, 0.743534505367279, 0.6993534564971924, 0.7575430870056152, 0.7575430870056152, 0.764008641242981, 0.7683189511299133, 0.7413793206214905, 0.7661637663841248, 0.7575430870056152, 0.7607758641242981, 0.7068965435028076, 0.71875, 0.6896551847457886, 0.735991358757019, 0.7596982717514038, 0.7273706793785095, 0.7532327771186829, 0.7586206793785095, 0.756465494632721, 0.7467672228813171, 0.7370689511299133, 0.7618534564971924, 0.7478448152542114, 0.7586206793785095, 0.7575430870056152, 0.7510775923728943, 0.743534505367279, 0.7543103694915771, 0.7650862336158752, 0.7446120977401733, 0.735991358757019, 0.7230603694915771, 0.7575430870056152, 0.7456896305084229, 0.743534505367279, 0.743534505367279, 0.7381465435028076, 0.7478448152542114, 0.7456896305084229, 0.7575430870056152, 0.7456896305084229]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.6611 - accuracy: 0.8107"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 4s 36ms/step - loss: 0.6596 - accuracy: 0.8130 - val_loss: 0.9393 - val_accuracy: 0.5034\n","Epoch 2/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6098 - accuracy: 0.8339 - val_loss: 0.9338 - val_accuracy: 0.5124\n","Epoch 3/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5985 - accuracy: 0.8520 - val_loss: 0.9348 - val_accuracy: 0.5147\n","Epoch 4/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5947 - accuracy: 0.8529 - val_loss: 0.9402 - val_accuracy: 0.5090\n","Epoch 5/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6042 - accuracy: 0.8404 - val_loss: 0.9362 - val_accuracy: 0.5147\n","Epoch 6/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5964 - accuracy: 0.8514 - val_loss: 0.9441 - val_accuracy: 0.5113\n","Epoch 7/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6046 - accuracy: 0.8381 - val_loss: 0.9452 - val_accuracy: 0.5158\n","Epoch 8/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6053 - accuracy: 0.8407 - val_loss: 0.9446 - val_accuracy: 0.5226\n","Epoch 9/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5823 - accuracy: 0.8591 - val_loss: 0.9641 - val_accuracy: 0.5113\n","Epoch 10/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5830 - accuracy: 0.8565 - val_loss: 0.9805 - val_accuracy: 0.5113\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5784 - accuracy: 0.8693 - val_loss: 0.9972 - val_accuracy: 0.5136\n","Epoch 12/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5770 - accuracy: 0.8659 - val_loss: 1.0251 - val_accuracy: 0.5158\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5773 - accuracy: 0.8585 - val_loss: 1.0317 - val_accuracy: 0.5158\n","Epoch 14/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.5713 - accuracy: 0.8662 - val_loss: 1.0283 - val_accuracy: 0.5294\n","Epoch 15/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5775 - accuracy: 0.8616 - val_loss: 1.0764 - val_accuracy: 0.5215\n","Epoch 16/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5687 - accuracy: 0.8650 - val_loss: 1.0809 - val_accuracy: 0.5351\n","Epoch 17/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5916 - accuracy: 0.8486 - val_loss: 1.1198 - val_accuracy: 0.5385\n","Epoch 18/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5648 - accuracy: 0.8696 - val_loss: 1.0946 - val_accuracy: 0.5600\n","Epoch 19/100\n","28/28 [==============================] - 3s 96ms/step - loss: 0.5873 - accuracy: 0.8475 - val_loss: 1.0240 - val_accuracy: 0.5871\n","Epoch 20/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5925 - accuracy: 0.8537 - val_loss: 1.1048 - val_accuracy: 0.5679\n","Epoch 21/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5618 - accuracy: 0.8701 - val_loss: 1.0421 - val_accuracy: 0.6041\n","Epoch 22/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5613 - accuracy: 0.8710 - val_loss: 0.9244 - val_accuracy: 0.6403\n","Epoch 23/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5757 - accuracy: 0.8613 - val_loss: 0.9946 - val_accuracy: 0.6199\n","Epoch 24/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5670 - accuracy: 0.8616 - val_loss: 0.8419 - val_accuracy: 0.6867\n","Epoch 25/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5567 - accuracy: 0.8755 - val_loss: 0.8499 - val_accuracy: 0.6934\n","Epoch 26/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5622 - accuracy: 0.8721 - val_loss: 1.0258 - val_accuracy: 0.6256\n","Epoch 27/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5961 - accuracy: 0.8432 - val_loss: 0.7652 - val_accuracy: 0.7624\n","Epoch 28/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5615 - accuracy: 0.8749 - val_loss: 0.7623 - val_accuracy: 0.7534\n","Epoch 29/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5777 - accuracy: 0.8529 - val_loss: 0.9404 - val_accuracy: 0.6550\n","Epoch 30/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5588 - accuracy: 0.8704 - val_loss: 0.7560 - val_accuracy: 0.7523\n","Epoch 31/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5581 - accuracy: 0.8707 - val_loss: 0.8455 - val_accuracy: 0.7059\n","Epoch 32/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5580 - accuracy: 0.8622 - val_loss: 0.7598 - val_accuracy: 0.7557\n","Epoch 33/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5439 - accuracy: 0.8879 - val_loss: 0.7568 - val_accuracy: 0.7545\n","Epoch 34/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5562 - accuracy: 0.8707 - val_loss: 0.7528 - val_accuracy: 0.7636\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5422 - accuracy: 0.8795 - val_loss: 0.7592 - val_accuracy: 0.7545\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5515 - accuracy: 0.8749 - val_loss: 0.7669 - val_accuracy: 0.7557\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5561 - accuracy: 0.8676 - val_loss: 0.7682 - val_accuracy: 0.7443\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5516 - accuracy: 0.8766 - val_loss: 0.7651 - val_accuracy: 0.7613\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5413 - accuracy: 0.8814 - val_loss: 0.7674 - val_accuracy: 0.7489\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5339 - accuracy: 0.8846 - val_loss: 0.7610 - val_accuracy: 0.7489\n","Epoch 41/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5492 - accuracy: 0.8698 - val_loss: 0.8038 - val_accuracy: 0.7342\n","Epoch 42/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5584 - accuracy: 0.8684 - val_loss: 0.7661 - val_accuracy: 0.7670\n","Epoch 43/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5354 - accuracy: 0.8820 - val_loss: 0.7714 - val_accuracy: 0.7500\n","Epoch 44/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5376 - accuracy: 0.8800 - val_loss: 0.7688 - val_accuracy: 0.7466\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5304 - accuracy: 0.8911 - val_loss: 0.7655 - val_accuracy: 0.7613\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5278 - accuracy: 0.8868 - val_loss: 0.8331 - val_accuracy: 0.7387\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5469 - accuracy: 0.8738 - val_loss: 0.7709 - val_accuracy: 0.7647\n","Epoch 48/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5297 - accuracy: 0.8843 - val_loss: 0.7614 - val_accuracy: 0.7579\n","Epoch 49/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5243 - accuracy: 0.8936 - val_loss: 0.8480 - val_accuracy: 0.7183\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5462 - accuracy: 0.8746 - val_loss: 0.7675 - val_accuracy: 0.7455\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5269 - accuracy: 0.8851 - val_loss: 0.7720 - val_accuracy: 0.7489\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5211 - accuracy: 0.8913 - val_loss: 0.7753 - val_accuracy: 0.7398\n","Epoch 53/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5224 - accuracy: 0.8877 - val_loss: 0.7800 - val_accuracy: 0.7681\n","Epoch 54/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5177 - accuracy: 0.8967 - val_loss: 0.7664 - val_accuracy: 0.7624\n","Epoch 55/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5257 - accuracy: 0.8857 - val_loss: 0.7736 - val_accuracy: 0.7455\n","Epoch 56/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5220 - accuracy: 0.8843 - val_loss: 0.7668 - val_accuracy: 0.7681\n","Epoch 57/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5131 - accuracy: 0.8956 - val_loss: 0.7665 - val_accuracy: 0.7557\n","Epoch 58/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5117 - accuracy: 0.8950 - val_loss: 0.7711 - val_accuracy: 0.7636\n","Epoch 59/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5184 - accuracy: 0.8913 - val_loss: 0.7769 - val_accuracy: 0.7455\n","Epoch 60/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5201 - accuracy: 0.8865 - val_loss: 0.7720 - val_accuracy: 0.7511\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5074 - accuracy: 0.8973 - val_loss: 0.8105 - val_accuracy: 0.7353\n","Epoch 62/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5092 - accuracy: 0.8959 - val_loss: 0.7682 - val_accuracy: 0.7658\n","Epoch 63/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5096 - accuracy: 0.8976 - val_loss: 0.8344 - val_accuracy: 0.7466\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5161 - accuracy: 0.8879 - val_loss: 0.7921 - val_accuracy: 0.7410\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5012 - accuracy: 0.9018 - val_loss: 0.7894 - val_accuracy: 0.7568\n","Epoch 66/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5114 - accuracy: 0.8846 - val_loss: 0.7774 - val_accuracy: 0.7545\n","Epoch 67/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5009 - accuracy: 0.9024 - val_loss: 0.7960 - val_accuracy: 0.7342\n","Epoch 68/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5070 - accuracy: 0.8945 - val_loss: 0.7926 - val_accuracy: 0.7342\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5214 - accuracy: 0.8834 - val_loss: 0.8434 - val_accuracy: 0.7376\n","Epoch 70/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5173 - accuracy: 0.8814 - val_loss: 0.7805 - val_accuracy: 0.7511\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4994 - accuracy: 0.9018 - val_loss: 0.8538 - val_accuracy: 0.7308\n","Epoch 72/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4990 - accuracy: 0.8962 - val_loss: 0.8107 - val_accuracy: 0.7477\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4947 - accuracy: 0.9001 - val_loss: 0.7867 - val_accuracy: 0.7421\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4884 - accuracy: 0.9106 - val_loss: 0.7875 - val_accuracy: 0.7387\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4938 - accuracy: 0.9024 - val_loss: 0.8586 - val_accuracy: 0.7330\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4979 - accuracy: 0.8995 - val_loss: 0.8005 - val_accuracy: 0.7308\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4936 - accuracy: 0.9029 - val_loss: 0.8603 - val_accuracy: 0.7296\n","Epoch 78/100\n","28/28 [==============================] - 2s 58ms/step - loss: 0.4957 - accuracy: 0.9032 - val_loss: 0.7943 - val_accuracy: 0.7704\n","Epoch 79/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4964 - accuracy: 0.9029 - val_loss: 0.7934 - val_accuracy: 0.7410\n","Epoch 80/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4910 - accuracy: 0.9035 - val_loss: 0.7931 - val_accuracy: 0.7455\n","Epoch 81/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4801 - accuracy: 0.9143 - val_loss: 0.7897 - val_accuracy: 0.7432\n","Epoch 82/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4785 - accuracy: 0.9111 - val_loss: 0.8137 - val_accuracy: 0.7534\n","Epoch 83/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4805 - accuracy: 0.9106 - val_loss: 0.7955 - val_accuracy: 0.7466\n","Epoch 84/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4872 - accuracy: 0.9035 - val_loss: 0.8043 - val_accuracy: 0.7421\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4811 - accuracy: 0.9083 - val_loss: 0.7906 - val_accuracy: 0.7579\n","Epoch 86/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4898 - accuracy: 0.8998 - val_loss: 0.7899 - val_accuracy: 0.7511\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4868 - accuracy: 0.9044 - val_loss: 0.8014 - val_accuracy: 0.7545\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4814 - accuracy: 0.9058 - val_loss: 0.8056 - val_accuracy: 0.7353\n","Epoch 89/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4810 - accuracy: 0.9089 - val_loss: 0.8731 - val_accuracy: 0.7115\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4771 - accuracy: 0.9089 - val_loss: 0.8132 - val_accuracy: 0.7330\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4862 - accuracy: 0.9044 - val_loss: 0.8373 - val_accuracy: 0.7285\n","Epoch 92/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4708 - accuracy: 0.9126 - val_loss: 0.7998 - val_accuracy: 0.7443\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4763 - accuracy: 0.9097 - val_loss: 0.8175 - val_accuracy: 0.7455\n","Epoch 94/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4603 - accuracy: 0.9199 - val_loss: 0.8144 - val_accuracy: 0.7500\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4708 - accuracy: 0.9182 - val_loss: 0.8025 - val_accuracy: 0.7432\n","Epoch 96/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4621 - accuracy: 0.9171 - val_loss: 0.7987 - val_accuracy: 0.7387\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4710 - accuracy: 0.9143 - val_loss: 0.8387 - val_accuracy: 0.7398\n","Epoch 98/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4677 - accuracy: 0.9151 - val_loss: 0.8142 - val_accuracy: 0.7432\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4640 - accuracy: 0.9148 - val_loss: 0.8186 - val_accuracy: 0.7477\n","Epoch 100/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4797 - accuracy: 0.9004 - val_loss: 0.8091 - val_accuracy: 0.7545\n","{'loss': [0.6595708131790161, 0.6097793579101562, 0.5984824895858765, 0.5947479605674744, 0.6042296886444092, 0.5963742136955261, 0.6046068668365479, 0.6053324341773987, 0.5822585225105286, 0.5830153226852417, 0.5784003734588623, 0.5769677758216858, 0.5772619843482971, 0.5712896585464478, 0.5775431394577026, 0.5687094330787659, 0.5915905237197876, 0.5647507309913635, 0.5873333215713501, 0.5925167202949524, 0.5617998838424683, 0.5612751245498657, 0.5756881833076477, 0.567017138004303, 0.5566661357879639, 0.5621742010116577, 0.5961323976516724, 0.5615059733390808, 0.5777284502983093, 0.558809220790863, 0.5581486821174622, 0.5579589009284973, 0.5438785552978516, 0.5562493205070496, 0.542235255241394, 0.5515240430831909, 0.5560664534568787, 0.5516349077224731, 0.5413381457328796, 0.5339417457580566, 0.5492436289787292, 0.5584431290626526, 0.535382866859436, 0.5375756621360779, 0.5304225087165833, 0.5278093814849854, 0.5469210743904114, 0.5297011733055115, 0.5242720246315002, 0.546247661113739, 0.5269083380699158, 0.521094024181366, 0.5224073529243469, 0.5177395939826965, 0.5257196426391602, 0.5219720602035522, 0.5131179690361023, 0.5116890668869019, 0.5184373259544373, 0.520129382610321, 0.5074191689491272, 0.509236216545105, 0.5095680356025696, 0.5160849690437317, 0.5012257695198059, 0.5113747119903564, 0.5008533000946045, 0.506969153881073, 0.5214005708694458, 0.5173130035400391, 0.49937382340431213, 0.49897071719169617, 0.49474507570266724, 0.4884403347969055, 0.49379029870033264, 0.4978615939617157, 0.4935578405857086, 0.4957404136657715, 0.49640804529190063, 0.49104002118110657, 0.4800703823566437, 0.4784563481807709, 0.4805387556552887, 0.487165242433548, 0.48107999563217163, 0.48975807428359985, 0.48680341243743896, 0.4814343750476837, 0.48095592856407166, 0.47709810733795166, 0.48621731996536255, 0.4707685112953186, 0.47627943754196167, 0.46028104424476624, 0.470839262008667, 0.4620645046234131, 0.4709707498550415, 0.4677189290523529, 0.46401119232177734, 0.47973746061325073], 'accuracy': [0.8129597902297974, 0.8338992595672607, 0.8520090579986572, 0.8528579473495483, 0.8404074907302856, 0.8514431118965149, 0.8381437659263611, 0.8406904339790344, 0.8590831756591797, 0.8565365076065063, 0.8692699670791626, 0.8658743500709534, 0.8585172891616821, 0.8661573529243469, 0.8616299033164978, 0.8650254607200623, 0.848613440990448, 0.8695529103279114, 0.8474816083908081, 0.8537068367004395, 0.8701188564300537, 0.8709677457809448, 0.8613469004631042, 0.8616299033164978, 0.875495195388794, 0.8720995783805847, 0.8432371020317078, 0.8749292492866516, 0.8528579473495483, 0.8704017996788025, 0.870684802532196, 0.8621957898139954, 0.8879456520080566, 0.870684802532196, 0.8794566988945007, 0.8749292492866516, 0.8675721287727356, 0.8766270279884338, 0.8814374804496765, 0.8845500946044922, 0.8698358535766602, 0.8684210777282715, 0.8820033669471741, 0.8800226449966431, 0.8910582661628723, 0.8868138194084167, 0.8737974166870117, 0.8842670917510986, 0.8936049938201904, 0.8746463060379028, 0.8851160407066345, 0.8913412690162659, 0.8876627087593079, 0.8967176079750061, 0.8856819272041321, 0.8842670917510986, 0.8955857157707214, 0.8950198292732239, 0.8913412690162659, 0.8865308165550232, 0.8972835540771484, 0.895868718624115, 0.8975664973258972, 0.8879456520080566, 0.9018110036849976, 0.8845500946044922, 0.9023768901824951, 0.8944538831710815, 0.8834182024002075, 0.8814374804496765, 0.9018110036849976, 0.8961516618728638, 0.9001131653785706, 0.9105829000473022, 0.9023768901824951, 0.899547278881073, 0.9029428362846375, 0.9032257795333862, 0.9029428362846375, 0.9035087823867798, 0.9142614603042603, 0.9111488461494446, 0.9105829000473022, 0.9035087823867798, 0.9083191752433777, 0.8998302221298218, 0.9043576717376709, 0.9057725071907043, 0.90888512134552, 0.90888512134552, 0.9043576717376709, 0.912563681602478, 0.9097340106964111, 0.9199207425117493, 0.918222963809967, 0.9170911312103271, 0.9142614603042603, 0.9151103496551514, 0.9148274064064026, 0.9003961682319641], 'val_loss': [0.9392639398574829, 0.9337723851203918, 0.9348140358924866, 0.9401770830154419, 0.9362242221832275, 0.9441254734992981, 0.9451690316200256, 0.9446460008621216, 0.9641127586364746, 0.9804905652999878, 0.9971786141395569, 1.0251314640045166, 1.0316543579101562, 1.0283442735671997, 1.076400637626648, 1.0809211730957031, 1.1197705268859863, 1.0946238040924072, 1.0240458250045776, 1.1048355102539062, 1.0420900583267212, 0.9243577718734741, 0.994638204574585, 0.8419287204742432, 0.8499367833137512, 1.0257761478424072, 0.7652053236961365, 0.7623304724693298, 0.9404419660568237, 0.7559545636177063, 0.8455278277397156, 0.7597946524620056, 0.7567849159240723, 0.7528055906295776, 0.7592027187347412, 0.7668640613555908, 0.768206000328064, 0.7651101350784302, 0.7673645615577698, 0.7610434293746948, 0.8037619590759277, 0.7660528421401978, 0.7713840007781982, 0.7687709331512451, 0.7654855251312256, 0.8331102132797241, 0.7709049582481384, 0.7613732814788818, 0.848002552986145, 0.767534613609314, 0.7719722986221313, 0.7753198146820068, 0.7799949049949646, 0.7664263248443604, 0.7736139297485352, 0.7667542695999146, 0.7665290236473083, 0.7710732221603394, 0.7768706679344177, 0.771955132484436, 0.8105299472808838, 0.7682376503944397, 0.8344496488571167, 0.7921382784843445, 0.7893640995025635, 0.7774441242218018, 0.7960275411605835, 0.7926111817359924, 0.8433893918991089, 0.7804989814758301, 0.8537851572036743, 0.8107444047927856, 0.7866920828819275, 0.787510871887207, 0.8585801124572754, 0.8004587888717651, 0.860349714756012, 0.7943273782730103, 0.7933813333511353, 0.7931195497512817, 0.789674699306488, 0.8137071132659912, 0.795455813407898, 0.8043032884597778, 0.7906213998794556, 0.7899497747421265, 0.8014146089553833, 0.8055599331855774, 0.8731249570846558, 0.8132259249687195, 0.8372620940208435, 0.7997916340827942, 0.8175488710403442, 0.814412534236908, 0.8025446534156799, 0.7986839413642883, 0.8386937975883484, 0.8141719102859497, 0.8186061978340149, 0.8090646862983704], 'val_accuracy': [0.5033936500549316, 0.5124434232711792, 0.5147058963775635, 0.5090497732162476, 0.5147058963775635, 0.5113122463226318, 0.5158371329307556, 0.5226244330406189, 0.5113122463226318, 0.5113122463226318, 0.5135746598243713, 0.5158371329307556, 0.5158371329307556, 0.529411792755127, 0.5214931964874268, 0.5350678563117981, 0.5384615659713745, 0.5599547624588013, 0.587104082107544, 0.5678732991218567, 0.6040723919868469, 0.6402714848518372, 0.6199095249176025, 0.6866515874862671, 0.6934388875961304, 0.6255655884742737, 0.7624434232711792, 0.7533936500549316, 0.6549773812294006, 0.7522624731063843, 0.7058823704719543, 0.7556561231613159, 0.7545248866081238, 0.7635746598243713, 0.7545248866081238, 0.7556561231613159, 0.7443438768386841, 0.7613122463226318, 0.7488687634468079, 0.7488687634468079, 0.7341628670692444, 0.766968309879303, 0.75, 0.7466063499450684, 0.7613122463226318, 0.7386877536773682, 0.7647058963775635, 0.7579185366630554, 0.7183257937431335, 0.7454751133918762, 0.7488687634468079, 0.7398189902305603, 0.7680995464324951, 0.7624434232711792, 0.7454751133918762, 0.7680995464324951, 0.7556561231613159, 0.7635746598243713, 0.7454751133918762, 0.7511312365531921, 0.7352941036224365, 0.7658371329307556, 0.7466063499450684, 0.7409502267837524, 0.7567873597145081, 0.7545248866081238, 0.7341628670692444, 0.7341628670692444, 0.7375565767288208, 0.7511312365531921, 0.7307692170143127, 0.7477375268936157, 0.7420814633369446, 0.7386877536773682, 0.733031690120697, 0.7307692170143127, 0.7296379804611206, 0.7703620195388794, 0.7409502267837524, 0.7454751133918762, 0.7432126402854919, 0.7533936500549316, 0.7466063499450684, 0.7420814633369446, 0.7579185366630554, 0.7511312365531921, 0.7545248866081238, 0.7352941036224365, 0.7115384340286255, 0.733031690120697, 0.7285068035125732, 0.7443438768386841, 0.7454751133918762, 0.75, 0.7432126402854919, 0.7386877536773682, 0.7398189902305603, 0.7432126402854919, 0.7477375268936157, 0.7545248866081238]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.6411 - accuracy: 0.8114"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 4s 36ms/step - loss: 0.6427 - accuracy: 0.8121 - val_loss: 0.9373 - val_accuracy: 0.4959\n","Epoch 2/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6020 - accuracy: 0.8437 - val_loss: 0.9405 - val_accuracy: 0.4938\n","Epoch 3/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6165 - accuracy: 0.8305 - val_loss: 0.9410 - val_accuracy: 0.4948\n","Epoch 4/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5989 - accuracy: 0.8444 - val_loss: 0.9457 - val_accuracy: 0.4938\n","Epoch 5/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5977 - accuracy: 0.8388 - val_loss: 0.9531 - val_accuracy: 0.4938\n","Epoch 6/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5990 - accuracy: 0.8494 - val_loss: 0.9452 - val_accuracy: 0.4979\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5901 - accuracy: 0.8447 - val_loss: 0.9795 - val_accuracy: 0.4917\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5892 - accuracy: 0.8519 - val_loss: 0.9960 - val_accuracy: 0.4917\n","Epoch 9/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5897 - accuracy: 0.8519 - val_loss: 1.0158 - val_accuracy: 0.4917\n","Epoch 10/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5826 - accuracy: 0.8519 - val_loss: 1.0611 - val_accuracy: 0.4907\n","Epoch 11/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5811 - accuracy: 0.8537 - val_loss: 1.0819 - val_accuracy: 0.4917\n","Epoch 12/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5775 - accuracy: 0.8545 - val_loss: 1.0365 - val_accuracy: 0.5072\n","Epoch 13/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5779 - accuracy: 0.8522 - val_loss: 1.1624 - val_accuracy: 0.4959\n","Epoch 14/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5804 - accuracy: 0.8537 - val_loss: 1.2046 - val_accuracy: 0.4990\n","Epoch 15/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.5810 - accuracy: 0.8499 - val_loss: 1.1965 - val_accuracy: 0.5093\n","Epoch 16/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5951 - accuracy: 0.8442 - val_loss: 1.0677 - val_accuracy: 0.5289\n","Epoch 17/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5936 - accuracy: 0.8388 - val_loss: 1.1249 - val_accuracy: 0.5289\n","Epoch 18/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5946 - accuracy: 0.8434 - val_loss: 1.2091 - val_accuracy: 0.5207\n","Epoch 19/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5693 - accuracy: 0.8641 - val_loss: 1.0847 - val_accuracy: 0.5568\n","Epoch 20/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5875 - accuracy: 0.8432 - val_loss: 1.0141 - val_accuracy: 0.5950\n","Epoch 21/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5647 - accuracy: 0.8576 - val_loss: 1.0626 - val_accuracy: 0.5795\n","Epoch 22/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5704 - accuracy: 0.8607 - val_loss: 0.9390 - val_accuracy: 0.6312\n","Epoch 23/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5662 - accuracy: 0.8615 - val_loss: 0.9774 - val_accuracy: 0.6219\n","Epoch 24/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5751 - accuracy: 0.8504 - val_loss: 0.7698 - val_accuracy: 0.7521\n","Epoch 25/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5752 - accuracy: 0.8491 - val_loss: 0.7669 - val_accuracy: 0.7490\n","Epoch 26/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5658 - accuracy: 0.8620 - val_loss: 0.8848 - val_accuracy: 0.6674\n","Epoch 27/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5631 - accuracy: 0.8597 - val_loss: 0.8447 - val_accuracy: 0.6942\n","Epoch 28/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5613 - accuracy: 0.8628 - val_loss: 0.7595 - val_accuracy: 0.7541\n","Epoch 29/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5549 - accuracy: 0.8713 - val_loss: 0.8062 - val_accuracy: 0.7221\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5532 - accuracy: 0.8700 - val_loss: 0.7640 - val_accuracy: 0.7490\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5545 - accuracy: 0.8638 - val_loss: 0.7923 - val_accuracy: 0.7366\n","Epoch 32/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5722 - accuracy: 0.8506 - val_loss: 0.7596 - val_accuracy: 0.7603\n","Epoch 33/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5516 - accuracy: 0.8690 - val_loss: 0.7731 - val_accuracy: 0.7428\n","Epoch 34/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5508 - accuracy: 0.8646 - val_loss: 0.7737 - val_accuracy: 0.7293\n","Epoch 35/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5512 - accuracy: 0.8669 - val_loss: 0.7631 - val_accuracy: 0.7407\n","Epoch 36/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5473 - accuracy: 0.8760 - val_loss: 0.7717 - val_accuracy: 0.7448\n","Epoch 37/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5628 - accuracy: 0.8633 - val_loss: 0.7742 - val_accuracy: 0.7386\n","Epoch 38/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5418 - accuracy: 0.8736 - val_loss: 0.7790 - val_accuracy: 0.7407\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5505 - accuracy: 0.8672 - val_loss: 0.8069 - val_accuracy: 0.7397\n","Epoch 40/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5539 - accuracy: 0.8602 - val_loss: 0.7710 - val_accuracy: 0.7355\n","Epoch 41/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5415 - accuracy: 0.8762 - val_loss: 0.8186 - val_accuracy: 0.7242\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5501 - accuracy: 0.8687 - val_loss: 0.7732 - val_accuracy: 0.7304\n","Epoch 43/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5385 - accuracy: 0.8729 - val_loss: 0.8105 - val_accuracy: 0.7190\n","Epoch 44/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5404 - accuracy: 0.8721 - val_loss: 0.7864 - val_accuracy: 0.7366\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5339 - accuracy: 0.8817 - val_loss: 0.7870 - val_accuracy: 0.7531\n","Epoch 46/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5360 - accuracy: 0.8744 - val_loss: 0.7765 - val_accuracy: 0.7407\n","Epoch 47/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5413 - accuracy: 0.8690 - val_loss: 0.7739 - val_accuracy: 0.7479\n","Epoch 48/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5367 - accuracy: 0.8749 - val_loss: 0.7808 - val_accuracy: 0.7469\n","Epoch 49/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5310 - accuracy: 0.8773 - val_loss: 0.7888 - val_accuracy: 0.7448\n","Epoch 50/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5364 - accuracy: 0.8739 - val_loss: 0.7812 - val_accuracy: 0.7500\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5278 - accuracy: 0.8829 - val_loss: 0.8872 - val_accuracy: 0.6921\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5394 - accuracy: 0.8685 - val_loss: 0.7906 - val_accuracy: 0.7262\n","Epoch 53/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5239 - accuracy: 0.8840 - val_loss: 0.7799 - val_accuracy: 0.7459\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5388 - accuracy: 0.8716 - val_loss: 0.8786 - val_accuracy: 0.7190\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5388 - accuracy: 0.8654 - val_loss: 0.7769 - val_accuracy: 0.7448\n","Epoch 56/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5168 - accuracy: 0.8840 - val_loss: 0.7778 - val_accuracy: 0.7469\n","Epoch 57/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5291 - accuracy: 0.8778 - val_loss: 0.7837 - val_accuracy: 0.7417\n","Epoch 58/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5223 - accuracy: 0.8845 - val_loss: 0.7931 - val_accuracy: 0.7479\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5330 - accuracy: 0.8739 - val_loss: 0.7831 - val_accuracy: 0.7479\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5377 - accuracy: 0.8705 - val_loss: 0.7829 - val_accuracy: 0.7397\n","Epoch 61/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5306 - accuracy: 0.8832 - val_loss: 0.7770 - val_accuracy: 0.7500\n","Epoch 62/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5232 - accuracy: 0.8806 - val_loss: 0.8146 - val_accuracy: 0.7376\n","Epoch 63/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5210 - accuracy: 0.8822 - val_loss: 0.8107 - val_accuracy: 0.7448\n","Epoch 64/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5121 - accuracy: 0.8969 - val_loss: 0.8452 - val_accuracy: 0.7128\n","Epoch 65/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5146 - accuracy: 0.8848 - val_loss: 0.8341 - val_accuracy: 0.7200\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5296 - accuracy: 0.8767 - val_loss: 0.7865 - val_accuracy: 0.7459\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5095 - accuracy: 0.8817 - val_loss: 0.7910 - val_accuracy: 0.7428\n","Epoch 68/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5132 - accuracy: 0.8907 - val_loss: 0.7927 - val_accuracy: 0.7386\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5062 - accuracy: 0.8912 - val_loss: 0.8109 - val_accuracy: 0.7428\n","Epoch 70/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5135 - accuracy: 0.8855 - val_loss: 0.8118 - val_accuracy: 0.7262\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5080 - accuracy: 0.8891 - val_loss: 0.7953 - val_accuracy: 0.7407\n","Epoch 72/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5008 - accuracy: 0.8953 - val_loss: 0.8009 - val_accuracy: 0.7490\n","Epoch 73/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4994 - accuracy: 0.8969 - val_loss: 0.8006 - val_accuracy: 0.7376\n","Epoch 74/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5000 - accuracy: 0.8969 - val_loss: 0.8256 - val_accuracy: 0.7397\n","Epoch 75/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5419 - accuracy: 0.8674 - val_loss: 0.7945 - val_accuracy: 0.7479\n","Epoch 76/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5062 - accuracy: 0.8897 - val_loss: 0.7978 - val_accuracy: 0.7335\n","Epoch 77/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5120 - accuracy: 0.8863 - val_loss: 0.8724 - val_accuracy: 0.7097\n","Epoch 78/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5050 - accuracy: 0.8886 - val_loss: 0.8169 - val_accuracy: 0.7304\n","Epoch 79/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4881 - accuracy: 0.9052 - val_loss: 0.7952 - val_accuracy: 0.7500\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4919 - accuracy: 0.8997 - val_loss: 0.8293 - val_accuracy: 0.7314\n","Epoch 81/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4951 - accuracy: 0.8987 - val_loss: 0.8041 - val_accuracy: 0.7324\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4897 - accuracy: 0.9023 - val_loss: 0.8101 - val_accuracy: 0.7345\n","Epoch 83/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4910 - accuracy: 0.8961 - val_loss: 0.8120 - val_accuracy: 0.7345\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4922 - accuracy: 0.8979 - val_loss: 0.8041 - val_accuracy: 0.7438\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4917 - accuracy: 0.8972 - val_loss: 0.8207 - val_accuracy: 0.7397\n","Epoch 86/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4875 - accuracy: 0.9008 - val_loss: 0.8229 - val_accuracy: 0.7242\n","Epoch 87/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4893 - accuracy: 0.8982 - val_loss: 0.8247 - val_accuracy: 0.7283\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4829 - accuracy: 0.9070 - val_loss: 0.8062 - val_accuracy: 0.7366\n","Epoch 89/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4764 - accuracy: 0.9059 - val_loss: 0.8682 - val_accuracy: 0.7138\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5018 - accuracy: 0.8894 - val_loss: 0.8045 - val_accuracy: 0.7510\n","Epoch 91/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4799 - accuracy: 0.9078 - val_loss: 0.8206 - val_accuracy: 0.7407\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4929 - accuracy: 0.8987 - val_loss: 0.8116 - val_accuracy: 0.7397\n","Epoch 93/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4741 - accuracy: 0.9101 - val_loss: 0.8123 - val_accuracy: 0.7386\n","Epoch 94/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4736 - accuracy: 0.9132 - val_loss: 0.8180 - val_accuracy: 0.7345\n","Epoch 95/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4767 - accuracy: 0.9124 - val_loss: 0.8158 - val_accuracy: 0.7479\n","Epoch 96/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4791 - accuracy: 0.9036 - val_loss: 0.8132 - val_accuracy: 0.7407\n","Epoch 97/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4890 - accuracy: 0.8938 - val_loss: 0.8213 - val_accuracy: 0.7355\n","Epoch 98/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4714 - accuracy: 0.9109 - val_loss: 0.8360 - val_accuracy: 0.7407\n","Epoch 99/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5012 - accuracy: 0.8876 - val_loss: 0.8952 - val_accuracy: 0.7056\n","Epoch 100/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4736 - accuracy: 0.9093 - val_loss: 0.8172 - val_accuracy: 0.7355\n","{'loss': [0.6426605582237244, 0.6020196676254272, 0.6165075302124023, 0.5988948345184326, 0.5977276563644409, 0.5990363359451294, 0.590050458908081, 0.5892013311386108, 0.5897331833839417, 0.5825554728507996, 0.5810522437095642, 0.5774847269058228, 0.577877938747406, 0.5804350972175598, 0.580964207649231, 0.5950679779052734, 0.5935648679733276, 0.5945795178413391, 0.569298267364502, 0.5875291228294373, 0.5646957159042358, 0.5703808665275574, 0.5661811828613281, 0.5751397609710693, 0.5752121806144714, 0.5657703280448914, 0.5631250739097595, 0.561333417892456, 0.5548719167709351, 0.5532047152519226, 0.5545321702957153, 0.5722038745880127, 0.5515952706336975, 0.550800621509552, 0.5512396693229675, 0.5472724437713623, 0.5627834796905518, 0.5417667031288147, 0.550487220287323, 0.5539124608039856, 0.54153972864151, 0.5501199960708618, 0.5385331511497498, 0.5404158234596252, 0.533901035785675, 0.5360115170478821, 0.5413222312927246, 0.5366694331169128, 0.5309984683990479, 0.53639817237854, 0.5277684330940247, 0.5393571853637695, 0.523873507976532, 0.5387902855873108, 0.5388368964195251, 0.5167551636695862, 0.5290501713752747, 0.5222717523574829, 0.5329631567001343, 0.5376837849617004, 0.5306485295295715, 0.5232377052307129, 0.520993173122406, 0.5121127963066101, 0.5146109461784363, 0.5295692682266235, 0.509519636631012, 0.5131979584693909, 0.5062045454978943, 0.5134801864624023, 0.5080047249794006, 0.5007854104042053, 0.4993557035923004, 0.4999912679195404, 0.5419111251831055, 0.5062183141708374, 0.5119954943656921, 0.5049635171890259, 0.48805931210517883, 0.49186018109321594, 0.49508681893348694, 0.4896995723247528, 0.49103987216949463, 0.4922180473804474, 0.49174314737319946, 0.4874962568283081, 0.4892714023590088, 0.4829280376434326, 0.4764244258403778, 0.501775324344635, 0.4798508286476135, 0.49288663268089294, 0.474102646112442, 0.4736102223396301, 0.4767124354839325, 0.4791189432144165, 0.4890272915363312, 0.4714188277721405, 0.501184344291687, 0.4736012816429138], 'accuracy': [0.8121446967124939, 0.8436692357063293, 0.8304909467697144, 0.8444444537162781, 0.8387596607208252, 0.8493540287017822, 0.8447028398513794, 0.851938009262085, 0.851938009262085, 0.851938009262085, 0.853746771812439, 0.8545219898223877, 0.8521963953971863, 0.853746771812439, 0.8498708009719849, 0.8441860675811768, 0.8387596607208252, 0.843410849571228, 0.8640826940536499, 0.8431524634361267, 0.8576227426528931, 0.8607234954833984, 0.8614987134933472, 0.8503875732421875, 0.8490955829620361, 0.8620154857635498, 0.8596899509429932, 0.8627907037734985, 0.8713178038597107, 0.8700258135795593, 0.8638243079185486, 0.8506460189819336, 0.868992269039154, 0.8645994663238525, 0.866925060749054, 0.8759689927101135, 0.8633074760437012, 0.8736433982849121, 0.8671834468841553, 0.8602067232131958, 0.8762273788452148, 0.868733823299408, 0.8728682398796082, 0.8720930218696594, 0.8816537261009216, 0.8744186162948608, 0.868992269039154, 0.8749353885650635, 0.8772609829902649, 0.8739017844200134, 0.882945716381073, 0.8684754371643066, 0.883979320526123, 0.8715762495994568, 0.8653746843338013, 0.883979320526123, 0.8777777552604675, 0.8844961524009705, 0.8739017844200134, 0.8705426454544067, 0.8832041621208191, 0.8806201815605164, 0.882170557975769, 0.8968992233276367, 0.8847545385360718, 0.8767442107200623, 0.8816537261009216, 0.8906976580619812, 0.8912144899368286, 0.8855296969413757, 0.8891472816467285, 0.895348846912384, 0.8968992233276367, 0.8968992233276367, 0.8674418330192566, 0.8896640539169312, 0.8863049149513245, 0.8886305093765259, 0.9051679372787476, 0.8997415900230408, 0.8987079858779907, 0.9023255705833435, 0.896124005317688, 0.8979328274726868, 0.897157609462738, 0.9007751941680908, 0.8981912136077881, 0.9069767594337463, 0.9059431552886963, 0.8894056677818298, 0.9077519178390503, 0.8987079858779907, 0.9100775122642517, 0.9131782650947571, 0.9124031066894531, 0.9036175608634949, 0.8937984704971313, 0.9108527302742004, 0.8875969052314758, 0.9093023538589478], 'val_loss': [0.9372992515563965, 0.940479576587677, 0.9409803748130798, 0.9457433223724365, 0.9530973434448242, 0.9451723694801331, 0.9794952869415283, 0.9959776401519775, 1.0158220529556274, 1.0610620975494385, 1.0818736553192139, 1.0364552736282349, 1.1623576879501343, 1.2046335935592651, 1.1965391635894775, 1.0677155256271362, 1.124941349029541, 1.2091188430786133, 1.084731936454773, 1.0140624046325684, 1.0626156330108643, 0.9389604330062866, 0.9774110913276672, 0.7697944045066833, 0.7668926119804382, 0.8847948312759399, 0.844668447971344, 0.7595182657241821, 0.806239902973175, 0.7639815807342529, 0.7922833561897278, 0.75962895154953, 0.77305668592453, 0.7737182378768921, 0.7630943059921265, 0.7717034220695496, 0.7741772532463074, 0.7789947390556335, 0.8069263696670532, 0.7709567546844482, 0.8186100721359253, 0.7732246518135071, 0.8105415105819702, 0.7864413261413574, 0.7869802713394165, 0.7764561176300049, 0.7739274501800537, 0.7808122634887695, 0.7887870669364929, 0.7811968326568604, 0.8872234225273132, 0.7906057834625244, 0.7798787355422974, 0.8785901665687561, 0.7769417762756348, 0.7778110504150391, 0.7837368249893188, 0.793074369430542, 0.783115029335022, 0.7828731536865234, 0.7770019173622131, 0.814559817314148, 0.8107282519340515, 0.8452379703521729, 0.834102988243103, 0.7865141034126282, 0.7910411357879639, 0.7927144765853882, 0.8109146356582642, 0.8118468523025513, 0.7953010201454163, 0.8009457588195801, 0.800606906414032, 0.825608491897583, 0.7944634556770325, 0.7978020310401917, 0.8723709583282471, 0.8169409036636353, 0.7952084541320801, 0.8292849063873291, 0.8041030764579773, 0.8100638389587402, 0.8120436072349548, 0.8040774464607239, 0.8207433819770813, 0.8229385018348694, 0.8247414231300354, 0.8061809539794922, 0.8682335019111633, 0.8045497536659241, 0.8205500841140747, 0.8115970492362976, 0.8123284578323364, 0.8180298805236816, 0.8158040046691895, 0.8132455945014954, 0.8213077783584595, 0.8360013961791992, 0.8951815962791443, 0.8171705603599548], 'val_accuracy': [0.4958677589893341, 0.49380165338516235, 0.4948347210884094, 0.49380165338516235, 0.49380165338516235, 0.49793389439582825, 0.4917355477809906, 0.4917355477809906, 0.4917355477809906, 0.49070248007774353, 0.4917355477809906, 0.5072314143180847, 0.4958677589893341, 0.49896693229675293, 0.5092975497245789, 0.5289255976676941, 0.5289255976676941, 0.5206611752510071, 0.5568181872367859, 0.5950413346290588, 0.5795454382896423, 0.6311983466148376, 0.6219007968902588, 0.7520661354064941, 0.7489669322967529, 0.6673553586006165, 0.6942148804664612, 0.7541322112083435, 0.7221074104309082, 0.7489669322967529, 0.7365702390670776, 0.7603305578231812, 0.7427685856819153, 0.7293388247489929, 0.7407024502754211, 0.7448347210884094, 0.7386363744735718, 0.7407024502754211, 0.7396694421768188, 0.7355371713638306, 0.7241735458374023, 0.73037189245224, 0.7190082669258118, 0.7365702390670776, 0.7530992031097412, 0.7407024502754211, 0.7479338645935059, 0.7469007968902588, 0.7448347210884094, 0.75, 0.692148745059967, 0.7262396812438965, 0.7458677887916565, 0.7190082669258118, 0.7448347210884094, 0.7469007968902588, 0.7417355179786682, 0.7479338645935059, 0.7479338645935059, 0.7396694421768188, 0.75, 0.7376033067703247, 0.7448347210884094, 0.7128099203109741, 0.7200413346290588, 0.7458677887916565, 0.7427685856819153, 0.7386363744735718, 0.7427685856819153, 0.7262396812438965, 0.7407024502754211, 0.7489669322967529, 0.7376033067703247, 0.7396694421768188, 0.7479338645935059, 0.7334710955619812, 0.7097107172012329, 0.73037189245224, 0.75, 0.7314049601554871, 0.7324380278587341, 0.7345041036605835, 0.7345041036605835, 0.7438016533851624, 0.7396694421768188, 0.7241735458374023, 0.7283057570457458, 0.7365702390670776, 0.7138429880142212, 0.7510330677032471, 0.7407024502754211, 0.7396694421768188, 0.7386363744735718, 0.7345041036605835, 0.7479338645935059, 0.7407024502754211, 0.7355371713638306, 0.7407024502754211, 0.7055785059928894, 0.7355371713638306]}\n","32/32 [==============================] - 0s 3ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_CNN.round(3)"],"metadata":{"id":"y3RXIk-qZ7ts","colab":{"base_uri":"https://localhost:8080/","height":519},"executionInfo":{"status":"ok","timestamp":1717530317953,"user_tz":-360,"elapsed":18,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}},"outputId":"a7aecd4e-74a9-4073-b4a0-047462709055","collapsed":true},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.604      0.590   0.682  0.632        0.682        0.526   \n","1        1     0.648      0.661   0.606  0.632        0.606        0.689   \n","2        2     0.658      0.670   0.620  0.644        0.620        0.695   \n","3        0     0.640      0.640   0.638  0.639        0.638        0.642   \n","4        1     0.664      0.653   0.701  0.676        0.701        0.627   \n","5        2     0.670      0.654   0.721  0.686        0.721        0.618   \n","6        0     0.678      0.667   0.714  0.689        0.714        0.643   \n","7        1     0.703      0.724   0.655  0.688        0.655        0.750   \n","8        2     0.676      0.679   0.667  0.673        0.667        0.685   \n","9        0     0.701      0.697   0.710  0.704        0.710        0.692   \n","10       1     0.716      0.745   0.657  0.698        0.657        0.775   \n","11       2     0.697      0.662   0.805  0.726        0.805        0.588   \n","12       0     0.740      0.763   0.697  0.729        0.697        0.784   \n","13       1     0.715      0.734   0.675  0.703        0.675        0.756   \n","14       2     0.717      0.699   0.761  0.729        0.761        0.673   \n","\n","    Kappa  \n","0   0.208  \n","1   0.295  \n","2   0.315  \n","3   0.280  \n","4   0.328  \n","5   0.339  \n","6   0.357  \n","7   0.405  \n","8   0.351  \n","9   0.402  \n","10  0.432  \n","11  0.394  \n","12  0.481  \n","13  0.431  \n","14  0.434  "],"text/html":["\n","  <div id=\"df-3f2e0994-8d39-4a1e-ad0b-7ec38faabe40\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.604</td>\n","      <td>0.590</td>\n","      <td>0.682</td>\n","      <td>0.632</td>\n","      <td>0.682</td>\n","      <td>0.526</td>\n","      <td>0.208</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.648</td>\n","      <td>0.661</td>\n","      <td>0.606</td>\n","      <td>0.632</td>\n","      <td>0.606</td>\n","      <td>0.689</td>\n","      <td>0.295</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.658</td>\n","      <td>0.670</td>\n","      <td>0.620</td>\n","      <td>0.644</td>\n","      <td>0.620</td>\n","      <td>0.695</td>\n","      <td>0.315</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.640</td>\n","      <td>0.640</td>\n","      <td>0.638</td>\n","      <td>0.639</td>\n","      <td>0.638</td>\n","      <td>0.642</td>\n","      <td>0.280</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.664</td>\n","      <td>0.653</td>\n","      <td>0.701</td>\n","      <td>0.676</td>\n","      <td>0.701</td>\n","      <td>0.627</td>\n","      <td>0.328</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.670</td>\n","      <td>0.654</td>\n","      <td>0.721</td>\n","      <td>0.686</td>\n","      <td>0.721</td>\n","      <td>0.618</td>\n","      <td>0.339</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.678</td>\n","      <td>0.667</td>\n","      <td>0.714</td>\n","      <td>0.689</td>\n","      <td>0.714</td>\n","      <td>0.643</td>\n","      <td>0.357</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.703</td>\n","      <td>0.724</td>\n","      <td>0.655</td>\n","      <td>0.688</td>\n","      <td>0.655</td>\n","      <td>0.750</td>\n","      <td>0.405</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.676</td>\n","      <td>0.679</td>\n","      <td>0.667</td>\n","      <td>0.673</td>\n","      <td>0.667</td>\n","      <td>0.685</td>\n","      <td>0.351</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.701</td>\n","      <td>0.697</td>\n","      <td>0.710</td>\n","      <td>0.704</td>\n","      <td>0.710</td>\n","      <td>0.692</td>\n","      <td>0.402</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.716</td>\n","      <td>0.745</td>\n","      <td>0.657</td>\n","      <td>0.698</td>\n","      <td>0.657</td>\n","      <td>0.775</td>\n","      <td>0.432</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.697</td>\n","      <td>0.662</td>\n","      <td>0.805</td>\n","      <td>0.726</td>\n","      <td>0.805</td>\n","      <td>0.588</td>\n","      <td>0.394</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.740</td>\n","      <td>0.763</td>\n","      <td>0.697</td>\n","      <td>0.729</td>\n","      <td>0.697</td>\n","      <td>0.784</td>\n","      <td>0.481</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.715</td>\n","      <td>0.734</td>\n","      <td>0.675</td>\n","      <td>0.703</td>\n","      <td>0.675</td>\n","      <td>0.756</td>\n","      <td>0.431</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.717</td>\n","      <td>0.699</td>\n","      <td>0.761</td>\n","      <td>0.729</td>\n","      <td>0.761</td>\n","      <td>0.673</td>\n","      <td>0.434</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f2e0994-8d39-4a1e-ad0b-7ec38faabe40')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3f2e0994-8d39-4a1e-ad0b-7ec38faabe40 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3f2e0994-8d39-4a1e-ad0b-7ec38faabe40');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c34ba668-2f8e-4826-a6e4-5df01fadb911\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c34ba668-2f8e-4826-a6e4-5df01fadb911')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c34ba668-2f8e-4826-a6e4-5df01fadb911 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df_CNN\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0358173940186289,\n        \"min\": 0.604,\n        \"max\": 0.74,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.701,\n          0.697,\n          0.604\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04518196015900067,\n        \"min\": 0.59,\n        \"max\": 0.763,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.697,\n          0.662,\n          0.59\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05213508095962513,\n        \"min\": 0.606,\n        \"max\": 0.805,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.71,\n          0.805,\n          0.682\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03383193757383693,\n        \"min\": 0.632,\n        \"max\": 0.729,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.729,\n          0.698,\n          0.632\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05213508095962513,\n        \"min\": 0.606,\n        \"max\": 0.805,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.71,\n          0.805,\n          0.682\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07194759997982658,\n        \"min\": 0.526,\n        \"max\": 0.784,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.692,\n          0.588,\n          0.526\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07192045870927395,\n        \"min\": 0.208,\n        \"max\": 0.481,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.402,\n          0.394,\n          0.208\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["metrics_df_CNN.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/DWT/CNN/Beta_DWT_CNN.csv', index = False)"],"metadata":{"id":"_iOLsKpkfzdG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# GRU"],"metadata":{"id":"GPlWZUcV48bB"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model_gru(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(GRU(256, return_sequences=True))\n","    model.add(GRU(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning_gru(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model_gru(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model_gru(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Beta/CNN_GRU/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Beta/CNN_GRU/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n","\n"],"metadata":{"id":"ieXSN-9PI4Dx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["global_model_gru, metrics_df_gru = federated_learning_gru(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"lD5S-Pvy5B-r","executionInfo":{"status":"ok","timestamp":1717531573741,"user_tz":-360,"elapsed":664505,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}},"outputId":"103b309e-6f28-498c-c1dd-cc16f72b002a"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 6s 57ms/step - loss: 1.8179 - accuracy: 0.4898 - val_loss: 1.8125 - val_accuracy: 0.5657\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 2/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.8077 - accuracy: 0.5084 - val_loss: 1.8026 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.7961 - accuracy: 0.5221 - val_loss: 1.7927 - val_accuracy: 0.6627\n","Epoch 4/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.7849 - accuracy: 0.5695 - val_loss: 1.7830 - val_accuracy: 0.4946\n","Epoch 5/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.7736 - accuracy: 0.5929 - val_loss: 1.7733 - val_accuracy: 0.4914\n","Epoch 6/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.7614 - accuracy: 0.6080 - val_loss: 1.7635 - val_accuracy: 0.5119\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.7477 - accuracy: 0.6107 - val_loss: 1.7539 - val_accuracy: 0.4860\n","Epoch 8/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.7322 - accuracy: 0.6404 - val_loss: 1.7433 - val_accuracy: 0.5733\n","Epoch 9/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.7155 - accuracy: 0.6463 - val_loss: 1.7318 - val_accuracy: 0.6832\n","Epoch 10/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.6963 - accuracy: 0.6633 - val_loss: 1.7205 - val_accuracy: 0.6821\n","Epoch 11/100\n","29/29 [==============================] - 1s 32ms/step - loss: 1.6792 - accuracy: 0.6638 - val_loss: 1.7069 - val_accuracy: 0.6940\n","Epoch 12/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.6564 - accuracy: 0.6759 - val_loss: 1.6924 - val_accuracy: 0.6907\n","Epoch 13/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.6337 - accuracy: 0.6886 - val_loss: 1.6749 - val_accuracy: 0.6929\n","Epoch 14/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.6203 - accuracy: 0.6783 - val_loss: 1.6582 - val_accuracy: 0.6918\n","Epoch 15/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.6063 - accuracy: 0.6802 - val_loss: 1.6407 - val_accuracy: 0.6929\n","Epoch 16/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.5941 - accuracy: 0.6816 - val_loss: 1.6349 - val_accuracy: 0.6401\n","Epoch 17/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.5826 - accuracy: 0.6872 - val_loss: 1.6095 - val_accuracy: 0.6994\n","Epoch 18/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.5708 - accuracy: 0.6988 - val_loss: 1.5926 - val_accuracy: 0.6961\n","Epoch 19/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.5655 - accuracy: 0.6902 - val_loss: 1.5826 - val_accuracy: 0.6929\n","Epoch 20/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.5566 - accuracy: 0.6921 - val_loss: 1.5655 - val_accuracy: 0.7026\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.5471 - accuracy: 0.6961 - val_loss: 1.5534 - val_accuracy: 0.7015\n","Epoch 22/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.5410 - accuracy: 0.6967 - val_loss: 1.5431 - val_accuracy: 0.7015\n","Epoch 23/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.5342 - accuracy: 0.6918 - val_loss: 1.5368 - val_accuracy: 0.7004\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.5257 - accuracy: 0.6999 - val_loss: 1.5255 - val_accuracy: 0.7026\n","Epoch 25/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.5144 - accuracy: 0.6953 - val_loss: 1.5159 - val_accuracy: 0.7058\n","Epoch 26/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.5106 - accuracy: 0.6991 - val_loss: 1.5097 - val_accuracy: 0.7015\n","Epoch 27/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.5038 - accuracy: 0.6994 - val_loss: 1.5014 - val_accuracy: 0.7058\n","Epoch 28/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.4997 - accuracy: 0.7002 - val_loss: 1.5059 - val_accuracy: 0.6950\n","Epoch 29/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4932 - accuracy: 0.7039 - val_loss: 1.4915 - val_accuracy: 0.6972\n","Epoch 30/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.4854 - accuracy: 0.6910 - val_loss: 1.4869 - val_accuracy: 0.6983\n","Epoch 31/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.4802 - accuracy: 0.6937 - val_loss: 1.4760 - val_accuracy: 0.7047\n","Epoch 32/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.4726 - accuracy: 0.6985 - val_loss: 1.4706 - val_accuracy: 0.7058\n","Epoch 33/100\n","29/29 [==============================] - 1s 33ms/step - loss: 1.4680 - accuracy: 0.7045 - val_loss: 1.4625 - val_accuracy: 0.7069\n","Epoch 34/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.4601 - accuracy: 0.6969 - val_loss: 1.4616 - val_accuracy: 0.7037\n","Epoch 35/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.4574 - accuracy: 0.6980 - val_loss: 1.4525 - val_accuracy: 0.7069\n","Epoch 36/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.4461 - accuracy: 0.6994 - val_loss: 1.4477 - val_accuracy: 0.7047\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4395 - accuracy: 0.7004 - val_loss: 1.4391 - val_accuracy: 0.7058\n","Epoch 38/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.4318 - accuracy: 0.6980 - val_loss: 1.4338 - val_accuracy: 0.7058\n","Epoch 39/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4285 - accuracy: 0.7055 - val_loss: 1.4271 - val_accuracy: 0.7058\n","Epoch 40/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.4211 - accuracy: 0.7026 - val_loss: 1.4236 - val_accuracy: 0.7101\n","Epoch 41/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.4217 - accuracy: 0.6980 - val_loss: 1.4166 - val_accuracy: 0.7112\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4101 - accuracy: 0.7037 - val_loss: 1.4244 - val_accuracy: 0.6972\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4048 - accuracy: 0.7020 - val_loss: 1.4040 - val_accuracy: 0.7037\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4003 - accuracy: 0.7042 - val_loss: 1.4070 - val_accuracy: 0.6972\n","Epoch 45/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3942 - accuracy: 0.6942 - val_loss: 1.3952 - val_accuracy: 0.7080\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3906 - accuracy: 0.7023 - val_loss: 1.3905 - val_accuracy: 0.7037\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3801 - accuracy: 0.7018 - val_loss: 1.3822 - val_accuracy: 0.7080\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3772 - accuracy: 0.7047 - val_loss: 1.3812 - val_accuracy: 0.7091\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3717 - accuracy: 0.7085 - val_loss: 1.3823 - val_accuracy: 0.6994\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3669 - accuracy: 0.6988 - val_loss: 1.3729 - val_accuracy: 0.7058\n","Epoch 51/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.3556 - accuracy: 0.7128 - val_loss: 1.3609 - val_accuracy: 0.7123\n","Epoch 52/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3536 - accuracy: 0.7085 - val_loss: 1.3601 - val_accuracy: 0.7112\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3480 - accuracy: 0.7096 - val_loss: 1.3598 - val_accuracy: 0.7037\n","Epoch 54/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3424 - accuracy: 0.7031 - val_loss: 1.3514 - val_accuracy: 0.7101\n","Epoch 55/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3367 - accuracy: 0.7069 - val_loss: 1.3445 - val_accuracy: 0.7047\n","Epoch 56/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.3328 - accuracy: 0.7042 - val_loss: 1.3358 - val_accuracy: 0.7101\n","Epoch 57/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3262 - accuracy: 0.7099 - val_loss: 1.3312 - val_accuracy: 0.7091\n","Epoch 58/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.3242 - accuracy: 0.7055 - val_loss: 1.3261 - val_accuracy: 0.7091\n","Epoch 59/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.3186 - accuracy: 0.7029 - val_loss: 1.3220 - val_accuracy: 0.7091\n","Epoch 60/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3141 - accuracy: 0.7072 - val_loss: 1.3164 - val_accuracy: 0.7080\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3075 - accuracy: 0.7101 - val_loss: 1.3104 - val_accuracy: 0.7101\n","Epoch 62/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3030 - accuracy: 0.7082 - val_loss: 1.3054 - val_accuracy: 0.7101\n","Epoch 63/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.2965 - accuracy: 0.7112 - val_loss: 1.3050 - val_accuracy: 0.7144\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2938 - accuracy: 0.7037 - val_loss: 1.2963 - val_accuracy: 0.7134\n","Epoch 65/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2858 - accuracy: 0.7080 - val_loss: 1.2955 - val_accuracy: 0.7123\n","Epoch 66/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2844 - accuracy: 0.7026 - val_loss: 1.3021 - val_accuracy: 0.7026\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2812 - accuracy: 0.7101 - val_loss: 1.2819 - val_accuracy: 0.7112\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2707 - accuracy: 0.7107 - val_loss: 1.2804 - val_accuracy: 0.7134\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2660 - accuracy: 0.7166 - val_loss: 1.2759 - val_accuracy: 0.7123\n","Epoch 70/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2637 - accuracy: 0.7171 - val_loss: 1.2783 - val_accuracy: 0.7069\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2586 - accuracy: 0.7085 - val_loss: 1.2636 - val_accuracy: 0.7112\n","Epoch 72/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2531 - accuracy: 0.7134 - val_loss: 1.2606 - val_accuracy: 0.7144\n","Epoch 73/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2522 - accuracy: 0.7055 - val_loss: 1.2552 - val_accuracy: 0.7134\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2425 - accuracy: 0.7123 - val_loss: 1.2853 - val_accuracy: 0.6756\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2425 - accuracy: 0.7190 - val_loss: 1.2513 - val_accuracy: 0.7058\n","Epoch 76/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2399 - accuracy: 0.7109 - val_loss: 1.2620 - val_accuracy: 0.6961\n","Epoch 77/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2348 - accuracy: 0.7058 - val_loss: 1.2396 - val_accuracy: 0.7144\n","Epoch 78/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.2289 - accuracy: 0.7053 - val_loss: 1.2336 - val_accuracy: 0.7144\n","Epoch 79/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.2207 - accuracy: 0.7126 - val_loss: 1.2286 - val_accuracy: 0.7134\n","Epoch 80/100\n","29/29 [==============================] - 1s 31ms/step - loss: 1.2188 - accuracy: 0.7134 - val_loss: 1.2245 - val_accuracy: 0.7155\n","Epoch 81/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.2112 - accuracy: 0.7258 - val_loss: 1.2215 - val_accuracy: 0.7069\n","Epoch 82/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2142 - accuracy: 0.7128 - val_loss: 1.2194 - val_accuracy: 0.7080\n","Epoch 83/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2058 - accuracy: 0.7177 - val_loss: 1.2313 - val_accuracy: 0.6950\n","Epoch 84/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.1998 - accuracy: 0.7179 - val_loss: 1.2086 - val_accuracy: 0.7123\n","Epoch 85/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.1979 - accuracy: 0.7131 - val_loss: 1.2051 - val_accuracy: 0.7177\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1904 - accuracy: 0.7155 - val_loss: 1.2045 - val_accuracy: 0.7155\n","Epoch 87/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.1890 - accuracy: 0.7161 - val_loss: 1.1966 - val_accuracy: 0.7198\n","Epoch 88/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1845 - accuracy: 0.7174 - val_loss: 1.1924 - val_accuracy: 0.7091\n","Epoch 89/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.1801 - accuracy: 0.7182 - val_loss: 1.1901 - val_accuracy: 0.7209\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1752 - accuracy: 0.7136 - val_loss: 1.1845 - val_accuracy: 0.7101\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1700 - accuracy: 0.7217 - val_loss: 1.1880 - val_accuracy: 0.7188\n","Epoch 92/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.1698 - accuracy: 0.7142 - val_loss: 1.1814 - val_accuracy: 0.7177\n","Epoch 93/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.1620 - accuracy: 0.7190 - val_loss: 1.1731 - val_accuracy: 0.7123\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1583 - accuracy: 0.7136 - val_loss: 1.1788 - val_accuracy: 0.7112\n","Epoch 95/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.1561 - accuracy: 0.7182 - val_loss: 1.1663 - val_accuracy: 0.7209\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1503 - accuracy: 0.7182 - val_loss: 1.1634 - val_accuracy: 0.7209\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1474 - accuracy: 0.7188 - val_loss: 1.1585 - val_accuracy: 0.7155\n","Epoch 98/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.1422 - accuracy: 0.7249 - val_loss: 1.1557 - val_accuracy: 0.7220\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1422 - accuracy: 0.7174 - val_loss: 1.1533 - val_accuracy: 0.7123\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1343 - accuracy: 0.7247 - val_loss: 1.1672 - val_accuracy: 0.7004\n","{'loss': [1.8178901672363281, 1.8076727390289307, 1.7961384057998657, 1.7849030494689941, 1.7735910415649414, 1.7614127397537231, 1.7476727962493896, 1.7322440147399902, 1.7155457735061646, 1.6962746381759644, 1.6792008876800537, 1.6564303636550903, 1.6336899995803833, 1.6202601194381714, 1.6062687635421753, 1.594056248664856, 1.5826152563095093, 1.570847511291504, 1.5654881000518799, 1.556633710861206, 1.54705011844635, 1.541035532951355, 1.534221887588501, 1.5256603956222534, 1.5143866539001465, 1.51064133644104, 1.5037554502487183, 1.4996538162231445, 1.493180513381958, 1.4854347705841064, 1.480236530303955, 1.4726306200027466, 1.467975378036499, 1.4600707292556763, 1.4574459791183472, 1.446057677268982, 1.4395017623901367, 1.4317790269851685, 1.42848539352417, 1.4210587739944458, 1.4217287302017212, 1.410075306892395, 1.4047776460647583, 1.400321125984192, 1.394228219985962, 1.390627384185791, 1.3800584077835083, 1.3772152662277222, 1.3717223405838013, 1.3669302463531494, 1.355619192123413, 1.353554606437683, 1.348048448562622, 1.3423645496368408, 1.3367431163787842, 1.3328092098236084, 1.3261908292770386, 1.324191927909851, 1.3185546398162842, 1.3140522241592407, 1.3075366020202637, 1.3030400276184082, 1.2965137958526611, 1.293787956237793, 1.2858312129974365, 1.2844144105911255, 1.2811757326126099, 1.2706823348999023, 1.26595938205719, 1.2636650800704956, 1.2586054801940918, 1.2530856132507324, 1.2522133588790894, 1.2425202131271362, 1.2424860000610352, 1.2399282455444336, 1.234786868095398, 1.2288962602615356, 1.2206672430038452, 1.218772530555725, 1.2111661434173584, 1.2141940593719482, 1.2058258056640625, 1.1997963190078735, 1.1979273557662964, 1.1904261112213135, 1.1890357732772827, 1.1844528913497925, 1.180053949356079, 1.1752455234527588, 1.1700358390808105, 1.1697577238082886, 1.1619874238967896, 1.1582764387130737, 1.1560792922973633, 1.1503307819366455, 1.147420048713684, 1.1421847343444824, 1.1422178745269775, 1.1343265771865845], 'accuracy': [0.48976293206214905, 0.5083512663841248, 0.522090494632721, 0.5695043206214905, 0.5929418206214905, 0.608027994632721, 0.610722005367279, 0.6403555870056152, 0.6462823152542114, 0.6632543206214905, 0.6637930870056152, 0.6759159564971924, 0.6885775923728943, 0.678340494632721, 0.6802262663841248, 0.6815732717514038, 0.6872305870056152, 0.6988146305084229, 0.6901939511299133, 0.6920797228813171, 0.6961206793785095, 0.696659505367279, 0.6918103694915771, 0.6998922228813171, 0.6953125, 0.6990840435028076, 0.6993534564971924, 0.7001616358757019, 0.7039331793785095, 0.6910021305084229, 0.693696141242981, 0.6985452771186829, 0.704472005367279, 0.696928858757019, 0.6980064511299133, 0.6993534564971924, 0.7004310488700867, 0.6980064511299133, 0.7055495977401733, 0.7025862336158752, 0.6980064511299133, 0.7036637663841248, 0.7020474076271057, 0.7042025923728943, 0.6942349076271057, 0.7023168206214905, 0.701777994632721, 0.704741358757019, 0.7085129022598267, 0.6988146305084229, 0.7128232717514038, 0.7085129022598267, 0.709590494632721, 0.703125, 0.7068965435028076, 0.7042025923728943, 0.7098599076271057, 0.7055495977401733, 0.7028555870056152, 0.7071659564971924, 0.7101293206214905, 0.7082435488700867, 0.7112069129943848, 0.7036637663841248, 0.7079741358757019, 0.7025862336158752, 0.7101293206214905, 0.7106680870056152, 0.7165948152542114, 0.717133641242981, 0.7085129022598267, 0.7133620977401733, 0.7055495977401733, 0.712284505367279, 0.7190194129943848, 0.7109375, 0.7058189511299133, 0.7052801847457886, 0.712553858757019, 0.7133620977401733, 0.7257543206214905, 0.7128232717514038, 0.7176724076271057, 0.7179418206214905, 0.7130926847457886, 0.7155172228813171, 0.7160560488700867, 0.717402994632721, 0.7182112336158752, 0.7136314511299133, 0.7217133641242981, 0.7141702771186829, 0.7190194129943848, 0.7136314511299133, 0.7182112336158752, 0.7182112336158752, 0.71875, 0.724946141242981, 0.717402994632721, 0.7246767282485962], 'val_loss': [1.8124665021896362, 1.8026036024093628, 1.7926815748214722, 1.7829619646072388, 1.773309588432312, 1.763505220413208, 1.753928780555725, 1.7433357238769531, 1.7318251132965088, 1.720508098602295, 1.7068734169006348, 1.692395567893982, 1.6749377250671387, 1.658210277557373, 1.6406912803649902, 1.6348779201507568, 1.6095086336135864, 1.5926352739334106, 1.582622766494751, 1.5654500722885132, 1.5534121990203857, 1.543054223060608, 1.5368075370788574, 1.5255076885223389, 1.515918493270874, 1.5096584558486938, 1.50144362449646, 1.5059126615524292, 1.4915201663970947, 1.4868574142456055, 1.4759913682937622, 1.4706227779388428, 1.4625294208526611, 1.4615974426269531, 1.4524894952774048, 1.4477020502090454, 1.4391165971755981, 1.4337637424468994, 1.427079439163208, 1.4236423969268799, 1.4166010618209839, 1.4243687391281128, 1.4039653539657593, 1.4070117473602295, 1.3951586484909058, 1.3904765844345093, 1.3822449445724487, 1.38123619556427, 1.382327914237976, 1.3729184865951538, 1.3609216213226318, 1.3600982427597046, 1.3598289489746094, 1.351440668106079, 1.3444880247116089, 1.3357949256896973, 1.331167459487915, 1.3261131048202515, 1.321975827217102, 1.3164464235305786, 1.3104100227355957, 1.3053630590438843, 1.3049670457839966, 1.296289086341858, 1.2954931259155273, 1.3021105527877808, 1.281863808631897, 1.2803730964660645, 1.2758901119232178, 1.2782961130142212, 1.2636210918426514, 1.2606077194213867, 1.2552387714385986, 1.285325527191162, 1.2513478994369507, 1.26200532913208, 1.2396353483200073, 1.23359215259552, 1.2285711765289307, 1.224549651145935, 1.2215259075164795, 1.2194193601608276, 1.2313117980957031, 1.2085787057876587, 1.2051323652267456, 1.2045400142669678, 1.196643352508545, 1.1923617124557495, 1.1901110410690308, 1.1845260858535767, 1.187974452972412, 1.1814279556274414, 1.1731231212615967, 1.1787742376327515, 1.16627037525177, 1.163359522819519, 1.1584762334823608, 1.1557033061981201, 1.1533206701278687, 1.167193055152893], 'val_accuracy': [0.5657327771186829, 0.48491379618644714, 0.662715494632721, 0.49461206793785095, 0.4913793206214905, 0.5118534564971924, 0.48599138855934143, 0.5732758641242981, 0.6831896305084229, 0.6821120977401733, 0.693965494632721, 0.6907327771186829, 0.6928879022598267, 0.6918103694915771, 0.6928879022598267, 0.6400862336158752, 0.6993534564971924, 0.6961206793785095, 0.6928879022598267, 0.7025862336158752, 0.701508641242981, 0.701508641242981, 0.7004310488700867, 0.7025862336158752, 0.7058189511299133, 0.701508641242981, 0.7058189511299133, 0.6950430870056152, 0.6971982717514038, 0.6982758641242981, 0.704741358757019, 0.7058189511299133, 0.7068965435028076, 0.7036637663841248, 0.7068965435028076, 0.704741358757019, 0.7058189511299133, 0.7058189511299133, 0.7058189511299133, 0.7101293206214905, 0.7112069129943848, 0.6971982717514038, 0.7036637663841248, 0.6971982717514038, 0.7079741358757019, 0.7036637663841248, 0.7079741358757019, 0.7090517282485962, 0.6993534564971924, 0.7058189511299133, 0.712284505367279, 0.7112069129943848, 0.7036637663841248, 0.7101293206214905, 0.704741358757019, 0.7101293206214905, 0.7090517282485962, 0.7090517282485962, 0.7090517282485962, 0.7079741358757019, 0.7101293206214905, 0.7101293206214905, 0.7144396305084229, 0.7133620977401733, 0.712284505367279, 0.7025862336158752, 0.7112069129943848, 0.7133620977401733, 0.712284505367279, 0.7068965435028076, 0.7112069129943848, 0.7144396305084229, 0.7133620977401733, 0.6756465435028076, 0.7058189511299133, 0.6961206793785095, 0.7144396305084229, 0.7144396305084229, 0.7133620977401733, 0.7155172228813171, 0.7068965435028076, 0.7079741358757019, 0.6950430870056152, 0.712284505367279, 0.7176724076271057, 0.7155172228813171, 0.7198275923728943, 0.7090517282485962, 0.7209051847457886, 0.7101293206214905, 0.71875, 0.7176724076271057, 0.712284505367279, 0.7112069129943848, 0.7209051847457886, 0.7209051847457886, 0.7155172228813171, 0.7219827771186829, 0.712284505367279, 0.7004310488700867]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 1.8185 - accuracy: 0.4861"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 7s 76ms/step - loss: 1.8185 - accuracy: 0.4861 - val_loss: 1.8128 - val_accuracy: 0.5577\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.8077 - accuracy: 0.5139 - val_loss: 1.8032 - val_accuracy: 0.4910\n","Epoch 3/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.7977 - accuracy: 0.5303 - val_loss: 1.7936 - val_accuracy: 0.5781\n","Epoch 4/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.7867 - accuracy: 0.5393 - val_loss: 1.7842 - val_accuracy: 0.6278\n","Epoch 5/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.7764 - accuracy: 0.5540 - val_loss: 1.7748 - val_accuracy: 0.5102\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.7650 - accuracy: 0.5863 - val_loss: 1.7654 - val_accuracy: 0.5441\n","Epoch 7/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.7533 - accuracy: 0.5922 - val_loss: 1.7561 - val_accuracy: 0.5645\n","Epoch 8/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.7399 - accuracy: 0.6234 - val_loss: 1.7468 - val_accuracy: 0.5000\n","Epoch 9/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.7269 - accuracy: 0.6149 - val_loss: 1.7368 - val_accuracy: 0.6357\n","Epoch 10/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.7104 - accuracy: 0.6321 - val_loss: 1.7271 - val_accuracy: 0.5170\n","Epoch 11/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.6965 - accuracy: 0.6287 - val_loss: 1.7154 - val_accuracy: 0.6618\n","Epoch 12/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.6758 - accuracy: 0.6587 - val_loss: 1.7026 - val_accuracy: 0.6753\n","Epoch 13/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.6595 - accuracy: 0.6562 - val_loss: 1.6894 - val_accuracy: 0.6527\n","Epoch 14/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.6443 - accuracy: 0.6658 - val_loss: 1.6754 - val_accuracy: 0.6753\n","Epoch 15/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.6285 - accuracy: 0.6650 - val_loss: 1.6604 - val_accuracy: 0.6867\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.6153 - accuracy: 0.6655 - val_loss: 1.6468 - val_accuracy: 0.6810\n","Epoch 17/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.6022 - accuracy: 0.6743 - val_loss: 1.6315 - val_accuracy: 0.6787\n","Epoch 18/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5934 - accuracy: 0.6684 - val_loss: 1.6150 - val_accuracy: 0.6776\n","Epoch 19/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.5867 - accuracy: 0.6689 - val_loss: 1.6034 - val_accuracy: 0.6753\n","Epoch 20/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.5748 - accuracy: 0.6783 - val_loss: 1.5906 - val_accuracy: 0.6821\n","Epoch 21/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.5673 - accuracy: 0.6757 - val_loss: 1.5753 - val_accuracy: 0.6844\n","Epoch 22/100\n","28/28 [==============================] - 1s 32ms/step - loss: 1.5569 - accuracy: 0.6805 - val_loss: 1.5631 - val_accuracy: 0.6912\n","Epoch 23/100\n","28/28 [==============================] - 1s 34ms/step - loss: 1.5555 - accuracy: 0.6723 - val_loss: 1.5540 - val_accuracy: 0.7002\n","Epoch 24/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.5468 - accuracy: 0.6783 - val_loss: 1.5443 - val_accuracy: 0.6912\n","Epoch 25/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5368 - accuracy: 0.6825 - val_loss: 1.5367 - val_accuracy: 0.6855\n","Epoch 26/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.5327 - accuracy: 0.6737 - val_loss: 1.5279 - val_accuracy: 0.6889\n","Epoch 27/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5195 - accuracy: 0.6868 - val_loss: 1.5209 - val_accuracy: 0.6900\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5138 - accuracy: 0.6870 - val_loss: 1.5173 - val_accuracy: 0.6776\n","Epoch 29/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5059 - accuracy: 0.6828 - val_loss: 1.5127 - val_accuracy: 0.6742\n","Epoch 30/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.5053 - accuracy: 0.6851 - val_loss: 1.5029 - val_accuracy: 0.6878\n","Epoch 31/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4944 - accuracy: 0.6836 - val_loss: 1.5088 - val_accuracy: 0.6742\n","Epoch 32/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4932 - accuracy: 0.6828 - val_loss: 1.4867 - val_accuracy: 0.6923\n","Epoch 33/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4862 - accuracy: 0.6800 - val_loss: 1.4882 - val_accuracy: 0.6821\n","Epoch 34/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4786 - accuracy: 0.6766 - val_loss: 1.4744 - val_accuracy: 0.6946\n","Epoch 35/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4681 - accuracy: 0.6902 - val_loss: 1.4686 - val_accuracy: 0.6900\n","Epoch 36/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4674 - accuracy: 0.6876 - val_loss: 1.4650 - val_accuracy: 0.6957\n","Epoch 37/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4574 - accuracy: 0.6930 - val_loss: 1.4599 - val_accuracy: 0.6912\n","Epoch 38/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4492 - accuracy: 0.6961 - val_loss: 1.4499 - val_accuracy: 0.6946\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4435 - accuracy: 0.6868 - val_loss: 1.4477 - val_accuracy: 0.6934\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4420 - accuracy: 0.6819 - val_loss: 1.4475 - val_accuracy: 0.6787\n","Epoch 41/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4319 - accuracy: 0.6896 - val_loss: 1.4331 - val_accuracy: 0.6900\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4278 - accuracy: 0.6868 - val_loss: 1.4326 - val_accuracy: 0.6867\n","Epoch 43/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.4186 - accuracy: 0.6814 - val_loss: 1.4216 - val_accuracy: 0.6900\n","Epoch 44/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.4171 - accuracy: 0.6851 - val_loss: 1.4163 - val_accuracy: 0.6923\n","Epoch 45/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.4125 - accuracy: 0.6800 - val_loss: 1.4108 - val_accuracy: 0.6912\n","Epoch 46/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.4035 - accuracy: 0.6862 - val_loss: 1.4049 - val_accuracy: 0.6889\n","Epoch 47/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.4027 - accuracy: 0.6828 - val_loss: 1.4003 - val_accuracy: 0.6934\n","Epoch 48/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.3920 - accuracy: 0.6910 - val_loss: 1.3948 - val_accuracy: 0.6934\n","Epoch 49/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.3878 - accuracy: 0.6933 - val_loss: 1.3884 - val_accuracy: 0.6946\n","Epoch 50/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.3803 - accuracy: 0.6907 - val_loss: 1.3836 - val_accuracy: 0.6889\n","Epoch 51/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.3755 - accuracy: 0.6876 - val_loss: 1.3792 - val_accuracy: 0.6934\n","Epoch 52/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3690 - accuracy: 0.6927 - val_loss: 1.3728 - val_accuracy: 0.6934\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3656 - accuracy: 0.6935 - val_loss: 1.3743 - val_accuracy: 0.6855\n","Epoch 54/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3612 - accuracy: 0.6921 - val_loss: 1.3623 - val_accuracy: 0.6946\n","Epoch 55/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3569 - accuracy: 0.6834 - val_loss: 1.3587 - val_accuracy: 0.6957\n","Epoch 56/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3518 - accuracy: 0.6964 - val_loss: 1.3611 - val_accuracy: 0.6912\n","Epoch 57/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.3463 - accuracy: 0.6952 - val_loss: 1.3474 - val_accuracy: 0.6912\n","Epoch 58/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3421 - accuracy: 0.6910 - val_loss: 1.3429 - val_accuracy: 0.6946\n","Epoch 59/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3345 - accuracy: 0.6930 - val_loss: 1.3376 - val_accuracy: 0.6923\n","Epoch 60/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3355 - accuracy: 0.6907 - val_loss: 1.3451 - val_accuracy: 0.6855\n","Epoch 61/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3243 - accuracy: 0.6921 - val_loss: 1.3283 - val_accuracy: 0.6946\n","Epoch 62/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3218 - accuracy: 0.6879 - val_loss: 1.3234 - val_accuracy: 0.6968\n","Epoch 63/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.3121 - accuracy: 0.6879 - val_loss: 1.3216 - val_accuracy: 0.6878\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3126 - accuracy: 0.6887 - val_loss: 1.3130 - val_accuracy: 0.6923\n","Epoch 65/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3061 - accuracy: 0.6941 - val_loss: 1.3106 - val_accuracy: 0.6923\n","Epoch 66/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.3004 - accuracy: 0.6972 - val_loss: 1.3068 - val_accuracy: 0.6912\n","Epoch 67/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2947 - accuracy: 0.6930 - val_loss: 1.3077 - val_accuracy: 0.6934\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2911 - accuracy: 0.6958 - val_loss: 1.2940 - val_accuracy: 0.6934\n","Epoch 69/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.2857 - accuracy: 0.6975 - val_loss: 1.2896 - val_accuracy: 0.6923\n","Epoch 70/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.2808 - accuracy: 0.6984 - val_loss: 1.2887 - val_accuracy: 0.6968\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2771 - accuracy: 0.6933 - val_loss: 1.2853 - val_accuracy: 0.6912\n","Epoch 72/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.2713 - accuracy: 0.6935 - val_loss: 1.2785 - val_accuracy: 0.6855\n","Epoch 73/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.2671 - accuracy: 0.6947 - val_loss: 1.2771 - val_accuracy: 0.6957\n","Epoch 74/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2608 - accuracy: 0.6969 - val_loss: 1.2683 - val_accuracy: 0.6957\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2569 - accuracy: 0.6978 - val_loss: 1.2650 - val_accuracy: 0.6878\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2527 - accuracy: 0.7006 - val_loss: 1.2590 - val_accuracy: 0.6980\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2451 - accuracy: 0.7037 - val_loss: 1.2547 - val_accuracy: 0.6957\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2431 - accuracy: 0.7009 - val_loss: 1.2512 - val_accuracy: 0.6968\n","Epoch 79/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2385 - accuracy: 0.6969 - val_loss: 1.2492 - val_accuracy: 0.6867\n","Epoch 80/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2354 - accuracy: 0.6961 - val_loss: 1.2419 - val_accuracy: 0.6968\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2283 - accuracy: 0.6981 - val_loss: 1.2417 - val_accuracy: 0.6991\n","Epoch 82/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2258 - accuracy: 0.7071 - val_loss: 1.2365 - val_accuracy: 0.6867\n","Epoch 83/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2194 - accuracy: 0.7051 - val_loss: 1.2293 - val_accuracy: 0.6923\n","Epoch 84/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2193 - accuracy: 0.6978 - val_loss: 1.2275 - val_accuracy: 0.6946\n","Epoch 85/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2150 - accuracy: 0.6998 - val_loss: 1.2210 - val_accuracy: 0.6957\n","Epoch 86/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2068 - accuracy: 0.6964 - val_loss: 1.2288 - val_accuracy: 0.6957\n","Epoch 87/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2048 - accuracy: 0.7032 - val_loss: 1.2303 - val_accuracy: 0.6765\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2024 - accuracy: 0.7043 - val_loss: 1.2089 - val_accuracy: 0.6957\n","Epoch 89/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1968 - accuracy: 0.7049 - val_loss: 1.2130 - val_accuracy: 0.6968\n","Epoch 90/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1885 - accuracy: 0.7068 - val_loss: 1.2039 - val_accuracy: 0.6980\n","Epoch 91/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1844 - accuracy: 0.7083 - val_loss: 1.1976 - val_accuracy: 0.6957\n","Epoch 92/100\n","28/28 [==============================] - 2s 64ms/step - loss: 1.1840 - accuracy: 0.7018 - val_loss: 1.1969 - val_accuracy: 0.7025\n","Epoch 93/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.1800 - accuracy: 0.7054 - val_loss: 1.1895 - val_accuracy: 0.7014\n","Epoch 94/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.1729 - accuracy: 0.7100 - val_loss: 1.1881 - val_accuracy: 0.7002\n","Epoch 95/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.1712 - accuracy: 0.7035 - val_loss: 1.1832 - val_accuracy: 0.7002\n","Epoch 96/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1668 - accuracy: 0.7071 - val_loss: 1.1813 - val_accuracy: 0.6821\n","Epoch 97/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1608 - accuracy: 0.7091 - val_loss: 1.1780 - val_accuracy: 0.6833\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1585 - accuracy: 0.7060 - val_loss: 1.1730 - val_accuracy: 0.6912\n","Epoch 99/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1586 - accuracy: 0.7015 - val_loss: 1.1703 - val_accuracy: 0.6855\n","Epoch 100/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.1527 - accuracy: 0.6981 - val_loss: 1.1637 - val_accuracy: 0.7048\n","{'loss': [1.8184919357299805, 1.8077442646026611, 1.797669768333435, 1.7867114543914795, 1.7764298915863037, 1.7649675607681274, 1.7532931566238403, 1.7398796081542969, 1.7269002199172974, 1.7104076147079468, 1.696475625038147, 1.6758313179016113, 1.6595039367675781, 1.644257664680481, 1.6284574270248413, 1.6152913570404053, 1.60221529006958, 1.59336519241333, 1.5866798162460327, 1.5747958421707153, 1.5673160552978516, 1.5568857192993164, 1.5554741621017456, 1.5467530488967896, 1.5367717742919922, 1.5327000617980957, 1.5194895267486572, 1.5138331651687622, 1.5058897733688354, 1.5052815675735474, 1.4943724870681763, 1.493170976638794, 1.4862383604049683, 1.478559970855713, 1.4681272506713867, 1.46742582321167, 1.4574172496795654, 1.4492175579071045, 1.4435255527496338, 1.4420398473739624, 1.4318788051605225, 1.4278435707092285, 1.4185997247695923, 1.4171191453933716, 1.412506103515625, 1.4034721851348877, 1.4026601314544678, 1.3920176029205322, 1.387829065322876, 1.3803236484527588, 1.375489354133606, 1.3689631223678589, 1.3656398057937622, 1.3612335920333862, 1.3568795919418335, 1.3517568111419678, 1.3463081121444702, 1.3420817852020264, 1.3345093727111816, 1.3355132341384888, 1.3242847919464111, 1.321792483329773, 1.31205153465271, 1.3126314878463745, 1.3060551881790161, 1.3004485368728638, 1.2947262525558472, 1.2910645008087158, 1.285683274269104, 1.2807912826538086, 1.2771116495132446, 1.2713017463684082, 1.2670645713806152, 1.2607557773590088, 1.2568873167037964, 1.2527434825897217, 1.2450597286224365, 1.243131160736084, 1.2384929656982422, 1.2354165315628052, 1.2282698154449463, 1.2258256673812866, 1.2194374799728394, 1.219277024269104, 1.2149509191513062, 1.2067790031433105, 1.2047667503356934, 1.2024352550506592, 1.1968051195144653, 1.188528060913086, 1.1844348907470703, 1.183951497077942, 1.1800411939620972, 1.1729462146759033, 1.1711835861206055, 1.1668016910552979, 1.160767674446106, 1.1585341691970825, 1.1586103439331055, 1.1526854038238525], 'accuracy': [0.48613467812538147, 0.5138652920722961, 0.5302773118019104, 0.5393322110176086, 0.5540463924407959, 0.5863044857978821, 0.5922467708587646, 0.6233729720115662, 0.6148839592933655, 0.6321448683738708, 0.6287493109703064, 0.6587436199188232, 0.6561969518661499, 0.6658177971839905, 0.6649688482284546, 0.6655347943305969, 0.6743067502975464, 0.6683644652366638, 0.6689304113388062, 0.6782682538032532, 0.6757215857505798, 0.6805319786071777, 0.6723259687423706, 0.6782682538032532, 0.6825127601623535, 0.673740804195404, 0.6867572069168091, 0.6870402097702026, 0.6827957034111023, 0.6850594282150269, 0.6836445927619934, 0.6827957034111023, 0.6799660325050354, 0.676570475101471, 0.6901528239250183, 0.6876060962677002, 0.6929824352264404, 0.6960950493812561, 0.6867572069168091, 0.6819468140602112, 0.689586877822876, 0.6867572069168091, 0.6813808679580688, 0.6850594282150269, 0.6799660325050354, 0.6861912608146667, 0.6827957034111023, 0.6910017132759094, 0.693265438079834, 0.6907187104225159, 0.6876060962677002, 0.6926994919776917, 0.6935483813285828, 0.6921335458755493, 0.6833616495132446, 0.6963780522346497, 0.695246160030365, 0.6910017132759094, 0.6929824352264404, 0.6907187104225159, 0.6921335458755493, 0.6878890991210938, 0.6878890991210938, 0.6887379884719849, 0.6941143274307251, 0.6972269415855408, 0.6929824352264404, 0.6958121061325073, 0.6975098848342896, 0.6983587741851807, 0.693265438079834, 0.6935483813285828, 0.6946802735328674, 0.696943998336792, 0.6977928876876831, 0.7006224989891052, 0.7037351727485657, 0.7009055018424988, 0.696943998336792, 0.6960950493812561, 0.6980758309364319, 0.7071307301521301, 0.7051499485969543, 0.6977928876876831, 0.6997736096382141, 0.6963780522346497, 0.7031692266464233, 0.7043010592460632, 0.7048670053482056, 0.7068477869033813, 0.70826256275177, 0.7017543911933899, 0.7054329514503479, 0.709960401058197, 0.7034521698951721, 0.7071307301521301, 0.7091115117073059, 0.7059988975524902, 0.7014714479446411, 0.6980758309364319], 'val_loss': [1.8128342628479004, 1.8032037019729614, 1.7936339378356934, 1.7841953039169312, 1.7748301029205322, 1.7653844356536865, 1.7560731172561646, 1.7468088865280151, 1.7367795705795288, 1.7271308898925781, 1.7154169082641602, 1.7026230096817017, 1.6894233226776123, 1.6754233837127686, 1.6603556871414185, 1.6468396186828613, 1.6314986944198608, 1.6149719953536987, 1.6034409999847412, 1.5906215906143188, 1.5753363370895386, 1.5631284713745117, 1.5539904832839966, 1.5443353652954102, 1.5367324352264404, 1.5279269218444824, 1.520907998085022, 1.5172557830810547, 1.5127241611480713, 1.5028592348098755, 1.508805751800537, 1.4866628646850586, 1.4882265329360962, 1.4743599891662598, 1.4686496257781982, 1.4650036096572876, 1.4598841667175293, 1.4499316215515137, 1.4476803541183472, 1.4475046396255493, 1.4330612421035767, 1.4326483011245728, 1.4215861558914185, 1.416271686553955, 1.4108165502548218, 1.4048657417297363, 1.4002714157104492, 1.3948253393173218, 1.3884295225143433, 1.3836314678192139, 1.3791537284851074, 1.3727985620498657, 1.3742656707763672, 1.3623297214508057, 1.3587157726287842, 1.3610873222351074, 1.347406029701233, 1.3428983688354492, 1.337624430656433, 1.3451117277145386, 1.3283090591430664, 1.3233530521392822, 1.3216378688812256, 1.3130396604537964, 1.3106080293655396, 1.3067995309829712, 1.3077046871185303, 1.2939939498901367, 1.2895700931549072, 1.2887187004089355, 1.2853177785873413, 1.278469443321228, 1.277064561843872, 1.2682783603668213, 1.2649939060211182, 1.258996605873108, 1.2546635866165161, 1.2511796951293945, 1.2492321729660034, 1.2419309616088867, 1.241693377494812, 1.2365307807922363, 1.2292981147766113, 1.2274620532989502, 1.2210396528244019, 1.228787899017334, 1.2302970886230469, 1.208940029144287, 1.2130093574523926, 1.2038795948028564, 1.197590947151184, 1.196944236755371, 1.1894969940185547, 1.1881381273269653, 1.183210015296936, 1.181262493133545, 1.1780344247817993, 1.1730233430862427, 1.1702616214752197, 1.1637041568756104], 'val_accuracy': [0.557692289352417, 0.49095022678375244, 0.5780543088912964, 0.627828061580658, 0.5101810097694397, 0.5441176295280457, 0.564479649066925, 0.5, 0.6357465982437134, 0.516968309879303, 0.6617646813392639, 0.6753393411636353, 0.6527149081230164, 0.6753393411636353, 0.6866515874862671, 0.6809954643249512, 0.6787330508232117, 0.6776018142700195, 0.6753393411636353, 0.6821267008781433, 0.6843891143798828, 0.6911764740943909, 0.7002262473106384, 0.6911764740943909, 0.685520350933075, 0.6889140009880066, 0.6900452375411987, 0.6776018142700195, 0.6742081642150879, 0.6877828240394592, 0.6742081642150879, 0.692307710647583, 0.6821267008781433, 0.6945701241493225, 0.6900452375411987, 0.6957013607025146, 0.6911764740943909, 0.6945701241493225, 0.6934388875961304, 0.6787330508232117, 0.6900452375411987, 0.6866515874862671, 0.6900452375411987, 0.692307710647583, 0.6911764740943909, 0.6889140009880066, 0.6934388875961304, 0.6934388875961304, 0.6945701241493225, 0.6889140009880066, 0.6934388875961304, 0.6934388875961304, 0.685520350933075, 0.6945701241493225, 0.6957013607025146, 0.6911764740943909, 0.6911764740943909, 0.6945701241493225, 0.692307710647583, 0.685520350933075, 0.6945701241493225, 0.6968325972557068, 0.6877828240394592, 0.692307710647583, 0.692307710647583, 0.6911764740943909, 0.6934388875961304, 0.6934388875961304, 0.692307710647583, 0.6968325972557068, 0.6911764740943909, 0.685520350933075, 0.6957013607025146, 0.6957013607025146, 0.6877828240394592, 0.6979637742042542, 0.6957013607025146, 0.6968325972557068, 0.6866515874862671, 0.6968325972557068, 0.6990950107574463, 0.6866515874862671, 0.692307710647583, 0.6945701241493225, 0.6957013607025146, 0.6957013607025146, 0.6764705777168274, 0.6957013607025146, 0.6968325972557068, 0.6979637742042542, 0.6957013607025146, 0.7024886608123779, 0.7013574838638306, 0.7002262473106384, 0.7002262473106384, 0.6821267008781433, 0.6832579374313354, 0.6911764740943909, 0.685520350933075, 0.7047511339187622]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 1.8185 - accuracy: 0.4933"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 9s 56ms/step - loss: 1.8182 - accuracy: 0.4959 - val_loss: 1.8119 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.8061 - accuracy: 0.5106 - val_loss: 1.8013 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.7948 - accuracy: 0.5251 - val_loss: 1.7908 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.7833 - accuracy: 0.5571 - val_loss: 1.7803 - val_accuracy: 0.5558\n","Epoch 5/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.7722 - accuracy: 0.5587 - val_loss: 1.7702 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.7589 - accuracy: 0.5922 - val_loss: 1.7601 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.7456 - accuracy: 0.6067 - val_loss: 1.7495 - val_accuracy: 0.5888\n","Epoch 8/100\n","31/31 [==============================] - 1s 28ms/step - loss: 1.7294 - accuracy: 0.6403 - val_loss: 1.7387 - val_accuracy: 0.6653\n","Epoch 9/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.7140 - accuracy: 0.6173 - val_loss: 1.7283 - val_accuracy: 0.5486\n","Epoch 10/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.6970 - accuracy: 0.6351 - val_loss: 1.7175 - val_accuracy: 0.5320\n","Epoch 11/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.6787 - accuracy: 0.6432 - val_loss: 1.7042 - val_accuracy: 0.6260\n","Epoch 12/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.6540 - accuracy: 0.6804 - val_loss: 1.6899 - val_accuracy: 0.6395\n","Epoch 13/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.6358 - accuracy: 0.6646 - val_loss: 1.6751 - val_accuracy: 0.6395\n","Epoch 14/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.6170 - accuracy: 0.6757 - val_loss: 1.6614 - val_accuracy: 0.6322\n","Epoch 15/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.5990 - accuracy: 0.6853 - val_loss: 1.6405 - val_accuracy: 0.6570\n","Epoch 16/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.5895 - accuracy: 0.6791 - val_loss: 1.6314 - val_accuracy: 0.6395\n","Epoch 17/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.5861 - accuracy: 0.6705 - val_loss: 1.6200 - val_accuracy: 0.6374\n","Epoch 18/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.5711 - accuracy: 0.6819 - val_loss: 1.6047 - val_accuracy: 0.6436\n","Epoch 19/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5565 - accuracy: 0.6871 - val_loss: 1.5875 - val_accuracy: 0.6415\n","Epoch 20/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5518 - accuracy: 0.6827 - val_loss: 1.5758 - val_accuracy: 0.6581\n","Epoch 21/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5413 - accuracy: 0.6832 - val_loss: 1.5662 - val_accuracy: 0.6529\n","Epoch 22/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5346 - accuracy: 0.6814 - val_loss: 1.5643 - val_accuracy: 0.6622\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5269 - accuracy: 0.6902 - val_loss: 1.5704 - val_accuracy: 0.6508\n","Epoch 24/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5213 - accuracy: 0.6824 - val_loss: 1.5438 - val_accuracy: 0.6622\n","Epoch 25/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5118 - accuracy: 0.6910 - val_loss: 1.5379 - val_accuracy: 0.6612\n","Epoch 26/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4995 - accuracy: 0.6915 - val_loss: 1.5604 - val_accuracy: 0.6498\n","Epoch 27/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4976 - accuracy: 0.6922 - val_loss: 1.5264 - val_accuracy: 0.6591\n","Epoch 28/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4901 - accuracy: 0.6902 - val_loss: 1.5175 - val_accuracy: 0.6581\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4805 - accuracy: 0.6943 - val_loss: 1.5149 - val_accuracy: 0.6632\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4741 - accuracy: 0.6855 - val_loss: 1.5049 - val_accuracy: 0.6539\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4657 - accuracy: 0.6951 - val_loss: 1.4988 - val_accuracy: 0.6622\n","Epoch 32/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4607 - accuracy: 0.6930 - val_loss: 1.4916 - val_accuracy: 0.6601\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4553 - accuracy: 0.6886 - val_loss: 1.4845 - val_accuracy: 0.6622\n","Epoch 34/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4528 - accuracy: 0.6907 - val_loss: 1.4794 - val_accuracy: 0.6601\n","Epoch 35/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.4408 - accuracy: 0.6891 - val_loss: 1.4739 - val_accuracy: 0.6560\n","Epoch 36/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.4352 - accuracy: 0.6953 - val_loss: 1.4661 - val_accuracy: 0.6570\n","Epoch 37/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.4256 - accuracy: 0.6969 - val_loss: 1.4596 - val_accuracy: 0.6612\n","Epoch 38/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.4173 - accuracy: 0.6966 - val_loss: 1.4550 - val_accuracy: 0.6601\n","Epoch 39/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.4121 - accuracy: 0.6966 - val_loss: 1.4558 - val_accuracy: 0.6467\n","Epoch 40/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.4099 - accuracy: 0.6922 - val_loss: 1.4478 - val_accuracy: 0.6508\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4089 - accuracy: 0.6884 - val_loss: 1.4442 - val_accuracy: 0.6508\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3951 - accuracy: 0.6990 - val_loss: 1.4291 - val_accuracy: 0.6550\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3893 - accuracy: 0.6956 - val_loss: 1.4235 - val_accuracy: 0.6601\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3835 - accuracy: 0.6995 - val_loss: 1.4189 - val_accuracy: 0.6601\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3790 - accuracy: 0.6925 - val_loss: 1.4124 - val_accuracy: 0.6601\n","Epoch 46/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3749 - accuracy: 0.6910 - val_loss: 1.4059 - val_accuracy: 0.6591\n","Epoch 47/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3652 - accuracy: 0.6982 - val_loss: 1.3998 - val_accuracy: 0.6612\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3602 - accuracy: 0.6969 - val_loss: 1.3969 - val_accuracy: 0.6560\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3534 - accuracy: 0.6992 - val_loss: 1.3946 - val_accuracy: 0.6529\n","Epoch 50/100\n","31/31 [==============================] - 2s 54ms/step - loss: 1.3495 - accuracy: 0.6922 - val_loss: 1.3862 - val_accuracy: 0.6715\n","Epoch 51/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3451 - accuracy: 0.6938 - val_loss: 1.3789 - val_accuracy: 0.6591\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3324 - accuracy: 0.7028 - val_loss: 1.3719 - val_accuracy: 0.6653\n","Epoch 53/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.3305 - accuracy: 0.6992 - val_loss: 1.3721 - val_accuracy: 0.6736\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3257 - accuracy: 0.6979 - val_loss: 1.3777 - val_accuracy: 0.6426\n","Epoch 55/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.3212 - accuracy: 0.7016 - val_loss: 1.3581 - val_accuracy: 0.6674\n","Epoch 56/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.3172 - accuracy: 0.6943 - val_loss: 1.3512 - val_accuracy: 0.6632\n","Epoch 57/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.3065 - accuracy: 0.7031 - val_loss: 1.3454 - val_accuracy: 0.6643\n","Epoch 58/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.3016 - accuracy: 0.7041 - val_loss: 1.3435 - val_accuracy: 0.6581\n","Epoch 59/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.2957 - accuracy: 0.6990 - val_loss: 1.3348 - val_accuracy: 0.6612\n","Epoch 60/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2950 - accuracy: 0.6992 - val_loss: 1.3298 - val_accuracy: 0.6612\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2884 - accuracy: 0.6995 - val_loss: 1.3265 - val_accuracy: 0.6622\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2824 - accuracy: 0.6966 - val_loss: 1.3222 - val_accuracy: 0.6591\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2794 - accuracy: 0.6969 - val_loss: 1.3144 - val_accuracy: 0.6632\n","Epoch 64/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2723 - accuracy: 0.7023 - val_loss: 1.3108 - val_accuracy: 0.6632\n","Epoch 65/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2662 - accuracy: 0.7059 - val_loss: 1.3051 - val_accuracy: 0.6601\n","Epoch 66/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.2628 - accuracy: 0.7026 - val_loss: 1.3047 - val_accuracy: 0.6746\n","Epoch 67/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2608 - accuracy: 0.7034 - val_loss: 1.2936 - val_accuracy: 0.6601\n","Epoch 68/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2521 - accuracy: 0.6984 - val_loss: 1.2905 - val_accuracy: 0.6653\n","Epoch 69/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2469 - accuracy: 0.7054 - val_loss: 1.2923 - val_accuracy: 0.6622\n","Epoch 70/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2431 - accuracy: 0.7010 - val_loss: 1.2842 - val_accuracy: 0.6612\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2402 - accuracy: 0.6961 - val_loss: 1.2748 - val_accuracy: 0.6632\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2320 - accuracy: 0.7059 - val_loss: 1.2728 - val_accuracy: 0.6684\n","Epoch 73/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2310 - accuracy: 0.6953 - val_loss: 1.2704 - val_accuracy: 0.6632\n","Epoch 74/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2265 - accuracy: 0.6984 - val_loss: 1.2609 - val_accuracy: 0.6694\n","Epoch 75/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2195 - accuracy: 0.7036 - val_loss: 1.2568 - val_accuracy: 0.6632\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2152 - accuracy: 0.7028 - val_loss: 1.2548 - val_accuracy: 0.6715\n","Epoch 77/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2068 - accuracy: 0.7088 - val_loss: 1.2486 - val_accuracy: 0.6570\n","Epoch 78/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.2072 - accuracy: 0.7034 - val_loss: 1.2436 - val_accuracy: 0.6632\n","Epoch 79/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.2026 - accuracy: 0.7054 - val_loss: 1.2392 - val_accuracy: 0.6705\n","Epoch 80/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.2003 - accuracy: 0.7067 - val_loss: 1.2330 - val_accuracy: 0.6674\n","Epoch 81/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.1952 - accuracy: 0.6956 - val_loss: 1.2322 - val_accuracy: 0.6736\n","Epoch 82/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.1898 - accuracy: 0.7026 - val_loss: 1.2450 - val_accuracy: 0.6684\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1843 - accuracy: 0.7016 - val_loss: 1.2220 - val_accuracy: 0.6674\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1756 - accuracy: 0.7088 - val_loss: 1.2190 - val_accuracy: 0.6736\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1761 - accuracy: 0.7044 - val_loss: 1.2273 - val_accuracy: 0.6684\n","Epoch 86/100\n","31/31 [==============================] - 2s 54ms/step - loss: 1.1701 - accuracy: 0.7067 - val_loss: 1.2137 - val_accuracy: 0.6756\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1639 - accuracy: 0.7088 - val_loss: 1.2130 - val_accuracy: 0.6622\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1627 - accuracy: 0.7083 - val_loss: 1.2032 - val_accuracy: 0.6725\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1541 - accuracy: 0.7101 - val_loss: 1.1963 - val_accuracy: 0.6705\n","Epoch 90/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1552 - accuracy: 0.7101 - val_loss: 1.2133 - val_accuracy: 0.6550\n","Epoch 91/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1508 - accuracy: 0.7093 - val_loss: 1.1909 - val_accuracy: 0.6777\n","Epoch 92/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1552 - accuracy: 0.6935 - val_loss: 1.1898 - val_accuracy: 0.6725\n","Epoch 93/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1449 - accuracy: 0.7049 - val_loss: 1.1816 - val_accuracy: 0.6653\n","Epoch 94/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1392 - accuracy: 0.7085 - val_loss: 1.1803 - val_accuracy: 0.6622\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1330 - accuracy: 0.7041 - val_loss: 1.1796 - val_accuracy: 0.6601\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1316 - accuracy: 0.7023 - val_loss: 1.1716 - val_accuracy: 0.6767\n","Epoch 97/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.1238 - accuracy: 0.7155 - val_loss: 1.1692 - val_accuracy: 0.6622\n","Epoch 98/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.1208 - accuracy: 0.7085 - val_loss: 1.1804 - val_accuracy: 0.6560\n","Epoch 99/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1168 - accuracy: 0.7070 - val_loss: 1.1651 - val_accuracy: 0.6705\n","Epoch 100/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1139 - accuracy: 0.7090 - val_loss: 1.1616 - val_accuracy: 0.6653\n","{'loss': [1.8182427883148193, 1.8060685396194458, 1.7947778701782227, 1.783328652381897, 1.7722458839416504, 1.758853554725647, 1.7456392049789429, 1.7294042110443115, 1.7140283584594727, 1.6969826221466064, 1.6787251234054565, 1.6540448665618896, 1.6358487606048584, 1.6169636249542236, 1.598975419998169, 1.5895212888717651, 1.5860563516616821, 1.5710750818252563, 1.5564676523208618, 1.5517590045928955, 1.5413448810577393, 1.5346235036849976, 1.5268948078155518, 1.5213075876235962, 1.5118173360824585, 1.4995040893554688, 1.4975906610488892, 1.4900600910186768, 1.4805413484573364, 1.4740663766860962, 1.4657059907913208, 1.4607182741165161, 1.45533287525177, 1.452815055847168, 1.4408187866210938, 1.4351766109466553, 1.425601601600647, 1.4173489809036255, 1.4121012687683105, 1.4099496603012085, 1.4088695049285889, 1.3950892686843872, 1.3893498182296753, 1.3834933042526245, 1.378981351852417, 1.3748537302017212, 1.3651669025421143, 1.3602018356323242, 1.3533538579940796, 1.3494899272918701, 1.345078468322754, 1.332364797592163, 1.3304892778396606, 1.3256810903549194, 1.321187973022461, 1.3172202110290527, 1.3064755201339722, 1.3016189336776733, 1.295678734779358, 1.2950198650360107, 1.2884438037872314, 1.2823549509048462, 1.27943754196167, 1.2723132371902466, 1.2661954164505005, 1.2628391981124878, 1.2607861757278442, 1.2521142959594727, 1.2469007968902588, 1.2431045770645142, 1.2402480840682983, 1.2319778203964233, 1.231044054031372, 1.2264516353607178, 1.2195143699645996, 1.215219497680664, 1.2068308591842651, 1.207153081893921, 1.2026101350784302, 1.200260043144226, 1.1952184438705444, 1.1898157596588135, 1.1843205690383911, 1.1756234169006348, 1.1761308908462524, 1.1701281070709229, 1.1639435291290283, 1.1626951694488525, 1.1540743112564087, 1.1551722288131714, 1.1508066654205322, 1.1552116870880127, 1.1449280977249146, 1.1392358541488647, 1.1329559087753296, 1.1315642595291138, 1.1237993240356445, 1.1208415031433105, 1.1167649030685425, 1.1139494180679321], 'accuracy': [0.4958656430244446, 0.5105943083763123, 0.5250645875930786, 0.5571059584617615, 0.5586563348770142, 0.5922480821609497, 0.6067183613777161, 0.6403100490570068, 0.6173126697540283, 0.6351421475410461, 0.6431524753570557, 0.6803617477416992, 0.6645994782447815, 0.6757106184959412, 0.6852713227272034, 0.6790697574615479, 0.6705426573753357, 0.6819121241569519, 0.6870800852775574, 0.6826873421669006, 0.6832041144371033, 0.6813953518867493, 0.6901808977127075, 0.6824289560317993, 0.6909560561180115, 0.6914728879928589, 0.6922480463981628, 0.6901808977127075, 0.6943152546882629, 0.6855297088623047, 0.6950904130935669, 0.6930232644081116, 0.6886304616928101, 0.6906976699829102, 0.6891472935676575, 0.695348858833313, 0.6968992352485657, 0.6966408491134644, 0.6966408491134644, 0.6922480463981628, 0.6883720755577087, 0.698966383934021, 0.6956072449684143, 0.6994832158088684, 0.6925064325332642, 0.6909560561180115, 0.698191225528717, 0.6968992352485657, 0.6992248296737671, 0.6922480463981628, 0.6937984228134155, 0.7028423547744751, 0.6992248296737671, 0.6979328393936157, 0.7015503644943237, 0.6943152546882629, 0.7031008005142212, 0.7041343450546265, 0.698966383934021, 0.6992248296737671, 0.6994832158088684, 0.6966408491134644, 0.6968992352485657, 0.7023255825042725, 0.7059431672096252, 0.7025839686393738, 0.7033591866493225, 0.6984496116638184, 0.7054263353347778, 0.7010335922241211, 0.6961240172386169, 0.7059431672096252, 0.695348858833313, 0.6984496116638184, 0.7036175727844238, 0.7028423547744751, 0.7087855339050293, 0.7033591866493225, 0.7054263353347778, 0.7067183256149292, 0.6956072449684143, 0.7025839686393738, 0.7015503644943237, 0.7087855339050293, 0.7043927907943726, 0.7067183256149292, 0.7087855339050293, 0.7082687616348267, 0.7100775241851807, 0.7100775241851807, 0.7093023061752319, 0.6935400366783142, 0.7049095630645752, 0.708527147769928, 0.7041343450546265, 0.7023255825042725, 0.7155038714408875, 0.708527147769928, 0.7069767713546753, 0.7090439200401306], 'val_loss': [1.8119291067123413, 1.801293969154358, 1.7908450365066528, 1.7803441286087036, 1.7702137231826782, 1.7600929737091064, 1.7494912147521973, 1.738690972328186, 1.72830331325531, 1.7174887657165527, 1.7042346000671387, 1.6898999214172363, 1.675148606300354, 1.6613893508911133, 1.6404598951339722, 1.6313605308532715, 1.6199612617492676, 1.6046862602233887, 1.587483286857605, 1.575805902481079, 1.5661542415618896, 1.5642555952072144, 1.5704461336135864, 1.5438446998596191, 1.5379151105880737, 1.5603584051132202, 1.5263906717300415, 1.517496943473816, 1.5148688554763794, 1.50491464138031, 1.498764991760254, 1.4915632009506226, 1.4844988584518433, 1.4793508052825928, 1.473881483078003, 1.4660944938659668, 1.4596261978149414, 1.4550011157989502, 1.455769658088684, 1.4477996826171875, 1.4441992044448853, 1.4290738105773926, 1.4234654903411865, 1.4188662767410278, 1.4123615026474, 1.4059020280838013, 1.3998308181762695, 1.3968698978424072, 1.3945982456207275, 1.3861887454986572, 1.3788721561431885, 1.3718781471252441, 1.3720821142196655, 1.3776843547821045, 1.358052134513855, 1.3512248992919922, 1.3453930616378784, 1.3435087203979492, 1.3347513675689697, 1.3297673463821411, 1.3265204429626465, 1.322184681892395, 1.314361333847046, 1.3107775449752808, 1.3051116466522217, 1.3046692609786987, 1.2936376333236694, 1.290480613708496, 1.2923266887664795, 1.2841534614562988, 1.274815320968628, 1.2728499174118042, 1.2703900337219238, 1.2609282732009888, 1.2567936182022095, 1.2547876834869385, 1.2485764026641846, 1.243604063987732, 1.2392228841781616, 1.2329765558242798, 1.2322028875350952, 1.2449688911437988, 1.2219635248184204, 1.2190030813217163, 1.2273099422454834, 1.213721513748169, 1.2130404710769653, 1.203170657157898, 1.1962826251983643, 1.2132636308670044, 1.19086754322052, 1.1897627115249634, 1.1816251277923584, 1.1803292036056519, 1.1796303987503052, 1.1716303825378418, 1.1692107915878296, 1.1803759336471558, 1.1650718450546265, 1.1616263389587402], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.5557851195335388, 0.48553720116615295, 0.48553720116615295, 0.5888429880142212, 0.6652892827987671, 0.5485537052154541, 0.5320248007774353, 0.6260330677032471, 0.6394628286361694, 0.6394628286361694, 0.6322314143180847, 0.6570248007774353, 0.6394628286361694, 0.6373966932296753, 0.6435950398445129, 0.6415289044380188, 0.6580578684806824, 0.6528925895690918, 0.6621900796890259, 0.6508264541625977, 0.6621900796890259, 0.6611570119857788, 0.6497933864593506, 0.6590909361839294, 0.6580578684806824, 0.663223147392273, 0.6539255976676941, 0.6621900796890259, 0.6601239442825317, 0.6621900796890259, 0.6601239442825317, 0.6559917330741882, 0.6570248007774353, 0.6611570119857788, 0.6601239442825317, 0.6466942429542542, 0.6508264541625977, 0.6508264541625977, 0.6549586653709412, 0.6601239442825317, 0.6601239442825317, 0.6601239442825317, 0.6590909361839294, 0.6611570119857788, 0.6559917330741882, 0.6528925895690918, 0.6714876294136047, 0.6590909361839294, 0.6652892827987671, 0.6735537052154541, 0.6425619721412659, 0.6673553586006165, 0.663223147392273, 0.66425621509552, 0.6580578684806824, 0.6611570119857788, 0.6611570119857788, 0.6621900796890259, 0.6590909361839294, 0.663223147392273, 0.663223147392273, 0.6601239442825317, 0.6745867729187012, 0.6601239442825317, 0.6652892827987671, 0.6621900796890259, 0.6611570119857788, 0.663223147392273, 0.6683884263038635, 0.663223147392273, 0.6694214940071106, 0.663223147392273, 0.6714876294136047, 0.6570248007774353, 0.663223147392273, 0.6704545617103577, 0.6673553586006165, 0.6735537052154541, 0.6683884263038635, 0.6673553586006165, 0.6735537052154541, 0.6683884263038635, 0.6756198406219482, 0.6621900796890259, 0.672520637512207, 0.6704545617103577, 0.6549586653709412, 0.6776859760284424, 0.672520637512207, 0.6652892827987671, 0.6621900796890259, 0.6601239442825317, 0.6766529083251953, 0.6621900796890259, 0.6559917330741882, 0.6704545617103577, 0.6652892827987671]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 1.1469 - accuracy: 0.7001"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 6s 55ms/step - loss: 1.1468 - accuracy: 0.7004 - val_loss: 1.2518 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1355 - accuracy: 0.7066 - val_loss: 1.2484 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1299 - accuracy: 0.7042 - val_loss: 1.2436 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1258 - accuracy: 0.7064 - val_loss: 1.2377 - val_accuracy: 0.4838\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1223 - accuracy: 0.7047 - val_loss: 1.2342 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1157 - accuracy: 0.7080 - val_loss: 1.2295 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1108 - accuracy: 0.7055 - val_loss: 1.2257 - val_accuracy: 0.4838\n","Epoch 8/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1066 - accuracy: 0.7109 - val_loss: 1.2229 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0987 - accuracy: 0.7123 - val_loss: 1.2225 - val_accuracy: 0.4849\n","Epoch 10/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.0957 - accuracy: 0.7134 - val_loss: 1.2107 - val_accuracy: 0.4871\n","Epoch 11/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.0912 - accuracy: 0.7163 - val_loss: 1.1993 - val_accuracy: 0.5043\n","Epoch 12/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.0881 - accuracy: 0.7139 - val_loss: 1.1926 - val_accuracy: 0.5216\n","Epoch 13/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.0849 - accuracy: 0.7147 - val_loss: 1.1811 - val_accuracy: 0.5474\n","Epoch 14/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.0821 - accuracy: 0.7107 - val_loss: 1.1646 - val_accuracy: 0.5916\n","Epoch 15/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0750 - accuracy: 0.7169 - val_loss: 1.1634 - val_accuracy: 0.5733\n","Epoch 16/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.0721 - accuracy: 0.7077 - val_loss: 1.1384 - val_accuracy: 0.6379\n","Epoch 17/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0672 - accuracy: 0.7166 - val_loss: 1.1461 - val_accuracy: 0.5970\n","Epoch 18/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.0629 - accuracy: 0.7255 - val_loss: 1.1119 - val_accuracy: 0.6821\n","Epoch 19/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.0617 - accuracy: 0.7107 - val_loss: 1.0952 - val_accuracy: 0.6961\n","Epoch 20/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.0553 - accuracy: 0.7163 - val_loss: 1.0832 - val_accuracy: 0.7101\n","Epoch 21/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.0528 - accuracy: 0.7196 - val_loss: 1.0737 - val_accuracy: 0.7123\n","Epoch 22/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0534 - accuracy: 0.7128 - val_loss: 1.0752 - val_accuracy: 0.6940\n","Epoch 23/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.0441 - accuracy: 0.7212 - val_loss: 1.0626 - val_accuracy: 0.7188\n","Epoch 24/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0426 - accuracy: 0.7236 - val_loss: 1.0567 - val_accuracy: 0.7144\n","Epoch 25/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0432 - accuracy: 0.7174 - val_loss: 1.0544 - val_accuracy: 0.7123\n","Epoch 26/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0371 - accuracy: 0.7193 - val_loss: 1.0486 - val_accuracy: 0.7166\n","Epoch 27/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.0296 - accuracy: 0.7255 - val_loss: 1.0417 - val_accuracy: 0.7177\n","Epoch 28/100\n","29/29 [==============================] - 1s 31ms/step - loss: 1.0263 - accuracy: 0.7266 - val_loss: 1.0384 - val_accuracy: 0.7209\n","Epoch 29/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0222 - accuracy: 0.7217 - val_loss: 1.0356 - val_accuracy: 0.7177\n","Epoch 30/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.0208 - accuracy: 0.7228 - val_loss: 1.0350 - val_accuracy: 0.7231\n","Epoch 31/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0177 - accuracy: 0.7255 - val_loss: 1.0294 - val_accuracy: 0.7166\n","Epoch 32/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0159 - accuracy: 0.7295 - val_loss: 1.0270 - val_accuracy: 0.7220\n","Epoch 33/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.0085 - accuracy: 0.7274 - val_loss: 1.0232 - val_accuracy: 0.7241\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0126 - accuracy: 0.7150 - val_loss: 1.0230 - val_accuracy: 0.7241\n","Epoch 35/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0056 - accuracy: 0.7169 - val_loss: 1.0200 - val_accuracy: 0.7188\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0018 - accuracy: 0.7271 - val_loss: 1.0170 - val_accuracy: 0.7209\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9990 - accuracy: 0.7284 - val_loss: 1.0124 - val_accuracy: 0.7209\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9961 - accuracy: 0.7271 - val_loss: 1.0100 - val_accuracy: 0.7155\n","Epoch 39/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9979 - accuracy: 0.7223 - val_loss: 1.0101 - val_accuracy: 0.7209\n","Epoch 40/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9964 - accuracy: 0.7196 - val_loss: 1.0055 - val_accuracy: 0.7241\n","Epoch 41/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9914 - accuracy: 0.7287 - val_loss: 1.0004 - val_accuracy: 0.7209\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9923 - accuracy: 0.7150 - val_loss: 0.9981 - val_accuracy: 0.7209\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9847 - accuracy: 0.7196 - val_loss: 1.0005 - val_accuracy: 0.7209\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9840 - accuracy: 0.7236 - val_loss: 0.9937 - val_accuracy: 0.7123\n","Epoch 45/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9762 - accuracy: 0.7301 - val_loss: 1.0062 - val_accuracy: 0.7047\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9732 - accuracy: 0.7223 - val_loss: 0.9888 - val_accuracy: 0.7241\n","Epoch 47/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9721 - accuracy: 0.7185 - val_loss: 1.0008 - val_accuracy: 0.7080\n","Epoch 48/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9728 - accuracy: 0.7193 - val_loss: 0.9834 - val_accuracy: 0.7220\n","Epoch 49/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9630 - accuracy: 0.7231 - val_loss: 0.9829 - val_accuracy: 0.7198\n","Epoch 50/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.9588 - accuracy: 0.7295 - val_loss: 0.9833 - val_accuracy: 0.7231\n","Epoch 51/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.9630 - accuracy: 0.7220 - val_loss: 0.9774 - val_accuracy: 0.7188\n","Epoch 52/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9573 - accuracy: 0.7231 - val_loss: 0.9746 - val_accuracy: 0.7166\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9529 - accuracy: 0.7295 - val_loss: 0.9747 - val_accuracy: 0.7241\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9565 - accuracy: 0.7206 - val_loss: 0.9789 - val_accuracy: 0.7134\n","Epoch 55/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9532 - accuracy: 0.7301 - val_loss: 0.9734 - val_accuracy: 0.7166\n","Epoch 56/100\n","29/29 [==============================] - 2s 57ms/step - loss: 0.9460 - accuracy: 0.7336 - val_loss: 0.9653 - val_accuracy: 0.7306\n","Epoch 57/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9460 - accuracy: 0.7301 - val_loss: 0.9681 - val_accuracy: 0.7188\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9395 - accuracy: 0.7373 - val_loss: 0.9613 - val_accuracy: 0.7177\n","Epoch 59/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9456 - accuracy: 0.7255 - val_loss: 0.9581 - val_accuracy: 0.7209\n","Epoch 60/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9368 - accuracy: 0.7303 - val_loss: 0.9564 - val_accuracy: 0.7209\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9343 - accuracy: 0.7301 - val_loss: 0.9978 - val_accuracy: 0.6713\n","Epoch 62/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9336 - accuracy: 0.7295 - val_loss: 0.9521 - val_accuracy: 0.7306\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9325 - accuracy: 0.7279 - val_loss: 0.9497 - val_accuracy: 0.7274\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9264 - accuracy: 0.7333 - val_loss: 0.9476 - val_accuracy: 0.7274\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9246 - accuracy: 0.7295 - val_loss: 0.9492 - val_accuracy: 0.7231\n","Epoch 66/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9189 - accuracy: 0.7322 - val_loss: 0.9502 - val_accuracy: 0.7166\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9156 - accuracy: 0.7360 - val_loss: 0.9425 - val_accuracy: 0.7252\n","Epoch 68/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9133 - accuracy: 0.7371 - val_loss: 0.9488 - val_accuracy: 0.7134\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9114 - accuracy: 0.7349 - val_loss: 0.9381 - val_accuracy: 0.7209\n","Epoch 70/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9107 - accuracy: 0.7349 - val_loss: 0.9361 - val_accuracy: 0.7252\n","Epoch 71/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.9068 - accuracy: 0.7355 - val_loss: 0.9344 - val_accuracy: 0.7317\n","Epoch 72/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9089 - accuracy: 0.7398 - val_loss: 0.9361 - val_accuracy: 0.7263\n","Epoch 73/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9081 - accuracy: 0.7330 - val_loss: 0.9316 - val_accuracy: 0.7231\n","Epoch 74/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.8996 - accuracy: 0.7365 - val_loss: 0.9282 - val_accuracy: 0.7263\n","Epoch 75/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8979 - accuracy: 0.7357 - val_loss: 0.9299 - val_accuracy: 0.7188\n","Epoch 76/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8960 - accuracy: 0.7414 - val_loss: 0.9254 - val_accuracy: 0.7188\n","Epoch 77/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8937 - accuracy: 0.7400 - val_loss: 0.9223 - val_accuracy: 0.7231\n","Epoch 78/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.8916 - accuracy: 0.7384 - val_loss: 0.9188 - val_accuracy: 0.7338\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8944 - accuracy: 0.7379 - val_loss: 0.9300 - val_accuracy: 0.7155\n","Epoch 80/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8878 - accuracy: 0.7398 - val_loss: 0.9171 - val_accuracy: 0.7241\n","Epoch 81/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8824 - accuracy: 0.7400 - val_loss: 0.9161 - val_accuracy: 0.7241\n","Epoch 82/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8793 - accuracy: 0.7470 - val_loss: 0.9146 - val_accuracy: 0.7295\n","Epoch 83/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8774 - accuracy: 0.7446 - val_loss: 0.9105 - val_accuracy: 0.7263\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8801 - accuracy: 0.7422 - val_loss: 0.9131 - val_accuracy: 0.7166\n","Epoch 85/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8816 - accuracy: 0.7341 - val_loss: 0.9085 - val_accuracy: 0.7317\n","Epoch 86/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8716 - accuracy: 0.7462 - val_loss: 0.9061 - val_accuracy: 0.7241\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8779 - accuracy: 0.7403 - val_loss: 0.9047 - val_accuracy: 0.7231\n","Epoch 88/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8694 - accuracy: 0.7384 - val_loss: 0.9044 - val_accuracy: 0.7198\n","Epoch 89/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8740 - accuracy: 0.7384 - val_loss: 0.9017 - val_accuracy: 0.7306\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8642 - accuracy: 0.7503 - val_loss: 0.9010 - val_accuracy: 0.7328\n","Epoch 91/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8596 - accuracy: 0.7524 - val_loss: 0.9007 - val_accuracy: 0.7209\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8565 - accuracy: 0.7497 - val_loss: 0.9034 - val_accuracy: 0.7166\n","Epoch 93/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8573 - accuracy: 0.7470 - val_loss: 0.8954 - val_accuracy: 0.7241\n","Epoch 94/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8577 - accuracy: 0.7433 - val_loss: 0.8952 - val_accuracy: 0.7295\n","Epoch 95/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.8577 - accuracy: 0.7438 - val_loss: 0.8956 - val_accuracy: 0.7188\n","Epoch 96/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8515 - accuracy: 0.7470 - val_loss: 0.8919 - val_accuracy: 0.7177\n","Epoch 97/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8524 - accuracy: 0.7427 - val_loss: 0.9092 - val_accuracy: 0.7037\n","Epoch 98/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.8535 - accuracy: 0.7376 - val_loss: 0.8871 - val_accuracy: 0.7328\n","Epoch 99/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8459 - accuracy: 0.7495 - val_loss: 0.9135 - val_accuracy: 0.6929\n","Epoch 100/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8452 - accuracy: 0.7478 - val_loss: 0.8883 - val_accuracy: 0.7274\n","{'loss': [1.1467820405960083, 1.1355212926864624, 1.1298668384552002, 1.1258275508880615, 1.1222625970840454, 1.1157044172286987, 1.1108263731002808, 1.1066333055496216, 1.098655343055725, 1.09565269947052, 1.091209053993225, 1.0880576372146606, 1.0848848819732666, 1.0820987224578857, 1.0749751329421997, 1.0720570087432861, 1.0672214031219482, 1.0628738403320312, 1.0617117881774902, 1.0552761554718018, 1.0528322458267212, 1.053372859954834, 1.0441346168518066, 1.042602777481079, 1.0432026386260986, 1.037136197090149, 1.0296046733856201, 1.0262507200241089, 1.0222302675247192, 1.0207722187042236, 1.017683506011963, 1.0158714056015015, 1.008526086807251, 1.0126241445541382, 1.0056004524230957, 1.001821517944336, 0.9990195035934448, 0.9960694909095764, 0.9979305863380432, 0.9964490532875061, 0.9914200901985168, 0.9923288822174072, 0.9846996665000916, 0.9839664101600647, 0.9762211441993713, 0.9731850624084473, 0.9720526337623596, 0.9727610945701599, 0.9630330204963684, 0.9587842226028442, 0.9629782438278198, 0.9572936296463013, 0.9529272317886353, 0.956515908241272, 0.953213632106781, 0.9460213780403137, 0.9460017085075378, 0.9394721388816833, 0.945630669593811, 0.9368019700050354, 0.9342987537384033, 0.9336473941802979, 0.9324908256530762, 0.9264170527458191, 0.9246464967727661, 0.9188831448554993, 0.9156331419944763, 0.913348376750946, 0.9113885164260864, 0.9107139706611633, 0.9067676663398743, 0.9088966250419617, 0.9081206917762756, 0.8995607495307922, 0.897885262966156, 0.8960222005844116, 0.8936607837677002, 0.8916373252868652, 0.894400954246521, 0.8877879977226257, 0.8824288845062256, 0.8792954683303833, 0.8773925304412842, 0.8800761103630066, 0.8816189169883728, 0.8716282248497009, 0.8778544664382935, 0.869355320930481, 0.8739795684814453, 0.8641949892044067, 0.859551727771759, 0.8565386533737183, 0.8573228716850281, 0.8576982021331787, 0.8576816320419312, 0.8514925837516785, 0.8523691892623901, 0.8535400032997131, 0.845918595790863, 0.8452075719833374], 'accuracy': [0.7004310488700867, 0.7066271305084229, 0.7042025923728943, 0.7063577771186829, 0.704741358757019, 0.7079741358757019, 0.7055495977401733, 0.7109375, 0.712284505367279, 0.7133620977401733, 0.7163254022598267, 0.7139008641242981, 0.7147090435028076, 0.7106680870056152, 0.7168642282485962, 0.7077047228813171, 0.7165948152542114, 0.7254849076271057, 0.7106680870056152, 0.7163254022598267, 0.7195581793785095, 0.7128232717514038, 0.7211745977401733, 0.7235991358757019, 0.717402994632721, 0.7192887663841248, 0.7254849076271057, 0.7265625, 0.7217133641242981, 0.7227909564971924, 0.7254849076271057, 0.7295258641242981, 0.7273706793785095, 0.7149784564971924, 0.7168642282485962, 0.7271012663841248, 0.7284482717514038, 0.7271012663841248, 0.7222521305084229, 0.7195581793785095, 0.7287176847457886, 0.7149784564971924, 0.7195581793785095, 0.7235991358757019, 0.7300646305084229, 0.7222521305084229, 0.7184805870056152, 0.7192887663841248, 0.7230603694915771, 0.7295258641242981, 0.7219827771186829, 0.7230603694915771, 0.7295258641242981, 0.7206357717514038, 0.7300646305084229, 0.7335668206214905, 0.7300646305084229, 0.7373383641242981, 0.7254849076271057, 0.7303340435028076, 0.7300646305084229, 0.7295258641242981, 0.727909505367279, 0.7332974076271057, 0.7295258641242981, 0.7322198152542114, 0.735991358757019, 0.7370689511299133, 0.7349137663841248, 0.7349137663841248, 0.7354525923728943, 0.7397629022598267, 0.733027994632721, 0.7365301847457886, 0.735722005367279, 0.7413793206214905, 0.7400323152542114, 0.7384159564971924, 0.7378771305084229, 0.7397629022598267, 0.7400323152542114, 0.7470366358757019, 0.7446120977401733, 0.7421875, 0.7341055870056152, 0.7462284564971924, 0.7403017282485962, 0.7384159564971924, 0.7384159564971924, 0.7502694129943848, 0.7524245977401733, 0.7497305870056152, 0.7470366358757019, 0.7432650923728943, 0.743803858757019, 0.7470366358757019, 0.7427262663841248, 0.7376077771186829, 0.7494612336158752, 0.7478448152542114], 'val_loss': [1.2518056631088257, 1.2484114170074463, 1.2436188459396362, 1.2376515865325928, 1.2341746091842651, 1.2294831275939941, 1.2257143259048462, 1.222853660583496, 1.2225291728973389, 1.2106690406799316, 1.1992805004119873, 1.1925714015960693, 1.1811374425888062, 1.1645779609680176, 1.1634355783462524, 1.1383967399597168, 1.1460988521575928, 1.1118630170822144, 1.0951669216156006, 1.083241581916809, 1.0737457275390625, 1.0751553773880005, 1.0626407861709595, 1.0567094087600708, 1.0543972253799438, 1.0485777854919434, 1.0417373180389404, 1.0383617877960205, 1.0355889797210693, 1.035020351409912, 1.0294092893600464, 1.0270452499389648, 1.0232245922088623, 1.0230339765548706, 1.0199967622756958, 1.0169789791107178, 1.0124120712280273, 1.009958028793335, 1.0101284980773926, 1.0054841041564941, 1.0003584623336792, 0.9981280565261841, 1.0005244016647339, 0.9937070608139038, 1.0062134265899658, 0.9888114929199219, 1.0008231401443481, 0.9833641648292542, 0.9829148054122925, 0.9832557439804077, 0.9773557782173157, 0.9745811223983765, 0.9747134447097778, 0.978942334651947, 0.973419725894928, 0.9653477668762207, 0.9680876731872559, 0.9612693190574646, 0.9581036567687988, 0.9564425349235535, 0.9978177547454834, 0.952103316783905, 0.9497249722480774, 0.9476307034492493, 0.9492296576499939, 0.9501646757125854, 0.9425195455551147, 0.9488359093666077, 0.938086986541748, 0.9360795021057129, 0.934369683265686, 0.9361018538475037, 0.9315572381019592, 0.9282419681549072, 0.9299102425575256, 0.9253507852554321, 0.9223465323448181, 0.9187673926353455, 0.9299793243408203, 0.9171149730682373, 0.9160653948783875, 0.9145547747612, 0.9105130434036255, 0.9130615592002869, 0.9085018038749695, 0.9060593247413635, 0.9047492742538452, 0.9043845534324646, 0.9016985297203064, 0.9010370373725891, 0.9006731510162354, 0.9033960103988647, 0.8953831791877747, 0.8951575756072998, 0.8955807685852051, 0.8918824195861816, 0.9091792106628418, 0.8871126770973206, 0.913537859916687, 0.8883019089698792], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48383620381355286, 0.48491379618644714, 0.48491379618644714, 0.48383620381355286, 0.48491379618644714, 0.48491379618644714, 0.48706895112991333, 0.5043103694915771, 0.5215517282485962, 0.5474137663841248, 0.5915948152542114, 0.5732758641242981, 0.6379310488700867, 0.5969827771186829, 0.6821120977401733, 0.6961206793785095, 0.7101293206214905, 0.712284505367279, 0.693965494632721, 0.71875, 0.7144396305084229, 0.712284505367279, 0.7165948152542114, 0.7176724076271057, 0.7209051847457886, 0.7176724076271057, 0.7230603694915771, 0.7165948152542114, 0.7219827771186829, 0.7241379022598267, 0.7241379022598267, 0.71875, 0.7209051847457886, 0.7209051847457886, 0.7155172228813171, 0.7209051847457886, 0.7241379022598267, 0.7209051847457886, 0.7209051847457886, 0.7209051847457886, 0.712284505367279, 0.704741358757019, 0.7241379022598267, 0.7079741358757019, 0.7219827771186829, 0.7198275923728943, 0.7230603694915771, 0.71875, 0.7165948152542114, 0.7241379022598267, 0.7133620977401733, 0.7165948152542114, 0.7306034564971924, 0.71875, 0.7176724076271057, 0.7209051847457886, 0.7209051847457886, 0.6713362336158752, 0.7306034564971924, 0.7273706793785095, 0.7273706793785095, 0.7230603694915771, 0.7165948152542114, 0.725215494632721, 0.7133620977401733, 0.7209051847457886, 0.725215494632721, 0.7316810488700867, 0.7262930870056152, 0.7230603694915771, 0.7262930870056152, 0.71875, 0.71875, 0.7230603694915771, 0.7338362336158752, 0.7155172228813171, 0.7241379022598267, 0.7241379022598267, 0.7295258641242981, 0.7262930870056152, 0.7165948152542114, 0.7316810488700867, 0.7241379022598267, 0.7230603694915771, 0.7198275923728943, 0.7306034564971924, 0.732758641242981, 0.7209051847457886, 0.7165948152542114, 0.7241379022598267, 0.7295258641242981, 0.71875, 0.7176724076271057, 0.7036637663841248, 0.732758641242981, 0.6928879022598267, 0.7273706793785095]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 1.1555 - accuracy: 0.6969"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 7s 60ms/step - loss: 1.1546 - accuracy: 0.6978 - val_loss: 1.2507 - val_accuracy: 0.4966\n","Epoch 2/100\n","28/28 [==============================] - 1s 33ms/step - loss: 1.1487 - accuracy: 0.6856 - val_loss: 1.2458 - val_accuracy: 0.4977\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.1427 - accuracy: 0.6879 - val_loss: 1.2412 - val_accuracy: 0.4977\n","Epoch 4/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.1387 - accuracy: 0.6885 - val_loss: 1.2370 - val_accuracy: 0.4966\n","Epoch 5/100\n","28/28 [==============================] - 1s 33ms/step - loss: 1.1308 - accuracy: 0.6969 - val_loss: 1.2309 - val_accuracy: 0.5011\n","Epoch 6/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.1279 - accuracy: 0.6961 - val_loss: 1.2272 - val_accuracy: 0.4966\n","Epoch 7/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1204 - accuracy: 0.6964 - val_loss: 1.2221 - val_accuracy: 0.4989\n","Epoch 8/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.1165 - accuracy: 0.6958 - val_loss: 1.2164 - val_accuracy: 0.5034\n","Epoch 9/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.1150 - accuracy: 0.7012 - val_loss: 1.2090 - val_accuracy: 0.5181\n","Epoch 10/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1140 - accuracy: 0.6890 - val_loss: 1.2086 - val_accuracy: 0.5045\n","Epoch 11/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.1099 - accuracy: 0.7003 - val_loss: 1.1986 - val_accuracy: 0.5204\n","Epoch 12/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.1016 - accuracy: 0.7003 - val_loss: 1.1841 - val_accuracy: 0.5995\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0971 - accuracy: 0.7006 - val_loss: 1.1780 - val_accuracy: 0.5826\n","Epoch 14/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0936 - accuracy: 0.7006 - val_loss: 1.1728 - val_accuracy: 0.5735\n","Epoch 15/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.0881 - accuracy: 0.7040 - val_loss: 1.1601 - val_accuracy: 0.6165\n","Epoch 16/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.0846 - accuracy: 0.6995 - val_loss: 1.1439 - val_accuracy: 0.6640\n","Epoch 17/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0861 - accuracy: 0.6955 - val_loss: 1.1379 - val_accuracy: 0.6493\n","Epoch 18/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.0816 - accuracy: 0.7049 - val_loss: 1.1251 - val_accuracy: 0.6765\n","Epoch 19/100\n","28/28 [==============================] - 1s 33ms/step - loss: 1.0750 - accuracy: 0.7032 - val_loss: 1.1115 - val_accuracy: 0.6833\n","Epoch 20/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.0709 - accuracy: 0.7018 - val_loss: 1.0976 - val_accuracy: 0.7014\n","Epoch 21/100\n","28/28 [==============================] - 1s 33ms/step - loss: 1.0683 - accuracy: 0.7063 - val_loss: 1.0907 - val_accuracy: 0.7025\n","Epoch 22/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.0632 - accuracy: 0.7012 - val_loss: 1.0879 - val_accuracy: 0.6968\n","Epoch 23/100\n","28/28 [==============================] - 1s 32ms/step - loss: 1.0585 - accuracy: 0.7108 - val_loss: 1.0733 - val_accuracy: 0.7036\n","Epoch 24/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.0566 - accuracy: 0.7094 - val_loss: 1.0725 - val_accuracy: 0.7036\n","Epoch 25/100\n","28/28 [==============================] - 1s 31ms/step - loss: 1.0512 - accuracy: 0.7037 - val_loss: 1.0643 - val_accuracy: 0.7081\n","Epoch 26/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0473 - accuracy: 0.7156 - val_loss: 1.0617 - val_accuracy: 0.7070\n","Epoch 27/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0434 - accuracy: 0.7083 - val_loss: 1.0533 - val_accuracy: 0.7014\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0403 - accuracy: 0.7102 - val_loss: 1.0591 - val_accuracy: 0.6991\n","Epoch 29/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.0430 - accuracy: 0.7117 - val_loss: 1.0497 - val_accuracy: 0.7104\n","Epoch 30/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.0333 - accuracy: 0.7108 - val_loss: 1.0457 - val_accuracy: 0.7115\n","Epoch 31/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0312 - accuracy: 0.7097 - val_loss: 1.0429 - val_accuracy: 0.7115\n","Epoch 32/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.0365 - accuracy: 0.7029 - val_loss: 1.0387 - val_accuracy: 0.7161\n","Epoch 33/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0410 - accuracy: 0.6933 - val_loss: 1.0640 - val_accuracy: 0.6867\n","Epoch 34/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0204 - accuracy: 0.7165 - val_loss: 1.0436 - val_accuracy: 0.6968\n","Epoch 35/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0201 - accuracy: 0.7085 - val_loss: 1.0303 - val_accuracy: 0.7036\n","Epoch 36/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0185 - accuracy: 0.7105 - val_loss: 1.0306 - val_accuracy: 0.6946\n","Epoch 37/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0133 - accuracy: 0.7105 - val_loss: 1.0439 - val_accuracy: 0.6957\n","Epoch 38/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0136 - accuracy: 0.7094 - val_loss: 1.0274 - val_accuracy: 0.7048\n","Epoch 39/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0110 - accuracy: 0.7102 - val_loss: 1.0218 - val_accuracy: 0.6946\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0091 - accuracy: 0.7080 - val_loss: 1.0176 - val_accuracy: 0.6957\n","Epoch 41/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0000 - accuracy: 0.7153 - val_loss: 1.0158 - val_accuracy: 0.7149\n","Epoch 42/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9960 - accuracy: 0.7156 - val_loss: 1.0154 - val_accuracy: 0.7161\n","Epoch 43/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9987 - accuracy: 0.7134 - val_loss: 1.0119 - val_accuracy: 0.7127\n","Epoch 44/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9908 - accuracy: 0.7114 - val_loss: 1.0083 - val_accuracy: 0.7161\n","Epoch 45/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9912 - accuracy: 0.7136 - val_loss: 1.0049 - val_accuracy: 0.6991\n","Epoch 46/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.9877 - accuracy: 0.7165 - val_loss: 1.0014 - val_accuracy: 0.7036\n","Epoch 47/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.9844 - accuracy: 0.7125 - val_loss: 1.0008 - val_accuracy: 0.7036\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9861 - accuracy: 0.7142 - val_loss: 1.0022 - val_accuracy: 0.6946\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9777 - accuracy: 0.7204 - val_loss: 0.9980 - val_accuracy: 0.7149\n","Epoch 50/100\n","28/28 [==============================] - 2s 59ms/step - loss: 0.9735 - accuracy: 0.7244 - val_loss: 0.9956 - val_accuracy: 0.7172\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9738 - accuracy: 0.7176 - val_loss: 0.9898 - val_accuracy: 0.7149\n","Epoch 52/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9706 - accuracy: 0.7199 - val_loss: 0.9881 - val_accuracy: 0.7104\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9649 - accuracy: 0.7168 - val_loss: 0.9880 - val_accuracy: 0.6957\n","Epoch 54/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9666 - accuracy: 0.7207 - val_loss: 0.9935 - val_accuracy: 0.6900\n","Epoch 55/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9613 - accuracy: 0.7193 - val_loss: 0.9813 - val_accuracy: 0.7161\n","Epoch 56/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9632 - accuracy: 0.7235 - val_loss: 0.9879 - val_accuracy: 0.7059\n","Epoch 57/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9577 - accuracy: 0.7201 - val_loss: 0.9820 - val_accuracy: 0.7138\n","Epoch 58/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9543 - accuracy: 0.7221 - val_loss: 0.9745 - val_accuracy: 0.7036\n","Epoch 59/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9498 - accuracy: 0.7204 - val_loss: 0.9762 - val_accuracy: 0.7172\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9514 - accuracy: 0.7269 - val_loss: 0.9981 - val_accuracy: 0.6776\n","Epoch 61/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9470 - accuracy: 0.7187 - val_loss: 0.9678 - val_accuracy: 0.7014\n","Epoch 62/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9457 - accuracy: 0.7292 - val_loss: 0.9672 - val_accuracy: 0.7002\n","Epoch 63/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9451 - accuracy: 0.7187 - val_loss: 0.9756 - val_accuracy: 0.6968\n","Epoch 64/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9404 - accuracy: 0.7292 - val_loss: 0.9668 - val_accuracy: 0.7161\n","Epoch 65/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.9378 - accuracy: 0.7301 - val_loss: 0.9658 - val_accuracy: 0.7183\n","Epoch 66/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9358 - accuracy: 0.7216 - val_loss: 0.9629 - val_accuracy: 0.7138\n","Epoch 67/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9279 - accuracy: 0.7377 - val_loss: 0.9584 - val_accuracy: 0.7183\n","Epoch 68/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9249 - accuracy: 0.7326 - val_loss: 0.9608 - val_accuracy: 0.7115\n","Epoch 69/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9237 - accuracy: 0.7289 - val_loss: 0.9593 - val_accuracy: 0.7081\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9173 - accuracy: 0.7306 - val_loss: 0.9492 - val_accuracy: 0.7036\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9167 - accuracy: 0.7346 - val_loss: 0.9496 - val_accuracy: 0.7104\n","Epoch 72/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9133 - accuracy: 0.7360 - val_loss: 0.9478 - val_accuracy: 0.7059\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9172 - accuracy: 0.7218 - val_loss: 0.9543 - val_accuracy: 0.7014\n","Epoch 74/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9142 - accuracy: 0.7354 - val_loss: 0.9524 - val_accuracy: 0.6968\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9111 - accuracy: 0.7320 - val_loss: 0.9447 - val_accuracy: 0.7138\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8987 - accuracy: 0.7436 - val_loss: 0.9444 - val_accuracy: 0.7183\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8984 - accuracy: 0.7368 - val_loss: 0.9573 - val_accuracy: 0.6844\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9071 - accuracy: 0.7334 - val_loss: 0.9354 - val_accuracy: 0.7104\n","Epoch 79/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8980 - accuracy: 0.7383 - val_loss: 0.9371 - val_accuracy: 0.7070\n","Epoch 80/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8984 - accuracy: 0.7295 - val_loss: 0.9497 - val_accuracy: 0.6844\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8991 - accuracy: 0.7337 - val_loss: 0.9304 - val_accuracy: 0.6980\n","Epoch 82/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8870 - accuracy: 0.7450 - val_loss: 0.9291 - val_accuracy: 0.7081\n","Epoch 83/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8877 - accuracy: 0.7450 - val_loss: 0.9277 - val_accuracy: 0.7081\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8861 - accuracy: 0.7414 - val_loss: 0.9363 - val_accuracy: 0.7172\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8878 - accuracy: 0.7422 - val_loss: 0.9227 - val_accuracy: 0.7059\n","Epoch 86/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.8811 - accuracy: 0.7394 - val_loss: 0.9225 - val_accuracy: 0.7025\n","Epoch 87/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8850 - accuracy: 0.7374 - val_loss: 0.9274 - val_accuracy: 0.7149\n","Epoch 88/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8787 - accuracy: 0.7445 - val_loss: 0.9186 - val_accuracy: 0.7014\n","Epoch 89/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8698 - accuracy: 0.7459 - val_loss: 0.9273 - val_accuracy: 0.6980\n","Epoch 90/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8701 - accuracy: 0.7434 - val_loss: 0.9237 - val_accuracy: 0.6991\n","Epoch 91/100\n","28/28 [==============================] - 2s 57ms/step - loss: 0.8764 - accuracy: 0.7385 - val_loss: 0.9195 - val_accuracy: 0.7206\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8758 - accuracy: 0.7408 - val_loss: 0.9257 - val_accuracy: 0.6968\n","Epoch 93/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.8682 - accuracy: 0.7465 - val_loss: 0.9176 - val_accuracy: 0.7240\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8714 - accuracy: 0.7402 - val_loss: 0.9171 - val_accuracy: 0.7048\n","Epoch 95/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8641 - accuracy: 0.7425 - val_loss: 0.9232 - val_accuracy: 0.6900\n","Epoch 96/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8640 - accuracy: 0.7513 - val_loss: 0.9119 - val_accuracy: 0.7229\n","Epoch 97/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8582 - accuracy: 0.7510 - val_loss: 0.9078 - val_accuracy: 0.7002\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8518 - accuracy: 0.7555 - val_loss: 0.9119 - val_accuracy: 0.7025\n","Epoch 99/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8540 - accuracy: 0.7476 - val_loss: 0.9049 - val_accuracy: 0.7149\n","Epoch 100/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8524 - accuracy: 0.7439 - val_loss: 0.9147 - val_accuracy: 0.6889\n","{'loss': [1.1546140909194946, 1.1486786603927612, 1.1427305936813354, 1.1386843919754028, 1.1308451890945435, 1.1279242038726807, 1.1203898191452026, 1.1164755821228027, 1.1149721145629883, 1.1139891147613525, 1.1099131107330322, 1.1016461849212646, 1.0970911979675293, 1.0936155319213867, 1.0881370306015015, 1.0846260786056519, 1.0861480236053467, 1.0816165208816528, 1.075010061264038, 1.0709245204925537, 1.0682902336120605, 1.063179612159729, 1.0584726333618164, 1.0566389560699463, 1.0511598587036133, 1.047276496887207, 1.0433682203292847, 1.040318250656128, 1.0430480241775513, 1.0333079099655151, 1.0312329530715942, 1.0364683866500854, 1.0410053730010986, 1.0203804969787598, 1.0200611352920532, 1.01851224899292, 1.013318419456482, 1.013594388961792, 1.0110186338424683, 1.0090758800506592, 0.9999653100967407, 0.9960064888000488, 0.9987385869026184, 0.9907809495925903, 0.9912399649620056, 0.9876537919044495, 0.984420120716095, 0.9860642552375793, 0.9776508212089539, 0.9735007286071777, 0.9738272428512573, 0.9705666899681091, 0.9649077653884888, 0.9666153788566589, 0.9612637758255005, 0.9632154107093811, 0.9577081799507141, 0.954272985458374, 0.9497700929641724, 0.9514216780662537, 0.947041392326355, 0.9456872940063477, 0.945118248462677, 0.9404454231262207, 0.937804102897644, 0.9358329772949219, 0.9278509616851807, 0.9249324798583984, 0.923653781414032, 0.9172520041465759, 0.916706919670105, 0.9132550358772278, 0.9171877503395081, 0.9141793251037598, 0.9110842347145081, 0.8986846804618835, 0.8984326124191284, 0.907053530216217, 0.8979558348655701, 0.8983834981918335, 0.8990785479545593, 0.8869519829750061, 0.8876584768295288, 0.8860676884651184, 0.8877896666526794, 0.8811056613922119, 0.8849720358848572, 0.8786674737930298, 0.8698004484176636, 0.8701064586639404, 0.8764426112174988, 0.8758159875869751, 0.8682400584220886, 0.8713687658309937, 0.8640593886375427, 0.863957941532135, 0.858199954032898, 0.8518000245094299, 0.8539630174636841, 0.8524238467216492], 'accuracy': [0.6977928876876831, 0.6856253743171692, 0.6878890991210938, 0.6884549856185913, 0.696943998336792, 0.6960950493812561, 0.6963780522346497, 0.6958121061325073, 0.7011884450912476, 0.6890209317207336, 0.7003395557403564, 0.7003395557403564, 0.7006224989891052, 0.7006224989891052, 0.7040181159973145, 0.6994906663894653, 0.6955291628837585, 0.7048670053482056, 0.7031692266464233, 0.7017543911933899, 0.706281840801239, 0.7011884450912476, 0.7108092904090881, 0.7093944549560547, 0.7037351727485657, 0.715619683265686, 0.70826256275177, 0.7102433443069458, 0.7116581797599792, 0.7108092904090881, 0.7096773982048035, 0.7028862237930298, 0.693265438079834, 0.7164685726165771, 0.7085455656051636, 0.7105262875556946, 0.7105262875556946, 0.7093944549560547, 0.7102433443069458, 0.7079796195030212, 0.7153367400169373, 0.715619683265686, 0.7133559584617615, 0.7113752365112305, 0.713638961315155, 0.7164685726165771, 0.7125070691108704, 0.7142048478126526, 0.7204301357269287, 0.7243916392326355, 0.7176004648208618, 0.7198641896247864, 0.7167515754699707, 0.7207130789756775, 0.719298243522644, 0.7235427498817444, 0.7201471328735352, 0.7221279144287109, 0.7204301357269287, 0.7269383072853088, 0.7187322974205017, 0.7292020320892334, 0.7187322974205017, 0.7292020320892334, 0.7300509214401245, 0.7215619683265686, 0.7376909852027893, 0.7325976490974426, 0.7289190888404846, 0.7306168675422668, 0.7345783710479736, 0.7359932065010071, 0.7218449115753174, 0.7354272603988647, 0.7320317029953003, 0.7436332702636719, 0.7368420958518982, 0.7334465384483337, 0.7382569313049316, 0.7294849753379822, 0.7337294816970825, 0.7450481057167053, 0.7450481057167053, 0.7413695454597473, 0.7422184348106384, 0.7393888235092163, 0.7374080419540405, 0.744482159614563, 0.7458969950675964, 0.7433503270149231, 0.7385398745536804, 0.740803599357605, 0.7464629411697388, 0.7402377128601074, 0.742501437664032, 0.7512733340263367, 0.7509903907775879, 0.755517840385437, 0.7475947737693787, 0.7439162135124207], 'val_loss': [1.2506828308105469, 1.2458120584487915, 1.2412049770355225, 1.2370330095291138, 1.2308509349822998, 1.2271537780761719, 1.2221324443817139, 1.2163821458816528, 1.2090436220169067, 1.2085672616958618, 1.1985574960708618, 1.1841113567352295, 1.177978515625, 1.172783613204956, 1.1600611209869385, 1.1438539028167725, 1.1379458904266357, 1.1251018047332764, 1.1115423440933228, 1.0975910425186157, 1.0906826257705688, 1.0878504514694214, 1.0733447074890137, 1.0724698305130005, 1.0643409490585327, 1.0617116689682007, 1.053286075592041, 1.0590509176254272, 1.0497262477874756, 1.0456864833831787, 1.0429106950759888, 1.038713812828064, 1.0640356540679932, 1.0436118841171265, 1.030260443687439, 1.0305705070495605, 1.043934941291809, 1.0274308919906616, 1.021824836730957, 1.0175683498382568, 1.0158354043960571, 1.0154372453689575, 1.011925220489502, 1.0083056688308716, 1.004889726638794, 1.001389980316162, 1.000832438468933, 1.0021809339523315, 0.9980277419090271, 0.995598316192627, 0.9897709488868713, 0.9880784749984741, 0.9879977107048035, 0.9934942126274109, 0.9812512993812561, 0.9878532886505127, 0.9820206761360168, 0.9745427370071411, 0.9761500358581543, 0.9981366395950317, 0.9678299427032471, 0.9672249555587769, 0.9756177663803101, 0.9668365120887756, 0.9658098816871643, 0.9629295468330383, 0.9583518505096436, 0.9608116149902344, 0.9592934846878052, 0.9492170214653015, 0.949649453163147, 0.9477978348731995, 0.9543477892875671, 0.9523860812187195, 0.9446923732757568, 0.9443756937980652, 0.9572700262069702, 0.9354379773139954, 0.9371117353439331, 0.9496803879737854, 0.9303674697875977, 0.9291463494300842, 0.9277476072311401, 0.9363066554069519, 0.9227302670478821, 0.9225224256515503, 0.9274441003799438, 0.9185696244239807, 0.9272534847259521, 0.9237253069877625, 0.9195226430892944, 0.9257010221481323, 0.9175732135772705, 0.9171072244644165, 0.9231948256492615, 0.9118734002113342, 0.9077907204627991, 0.9119271039962769, 0.9049029350280762, 0.9146519303321838], 'val_accuracy': [0.49660632014274597, 0.4977375566959381, 0.4977375566959381, 0.49660632014274597, 0.5011312365531921, 0.49660632014274597, 0.49886876344680786, 0.5033936500549316, 0.5180995464324951, 0.5045248866081238, 0.5203620195388794, 0.5995475053787231, 0.5825791954994202, 0.5735294222831726, 0.6165158152580261, 0.6640271544456482, 0.6493212580680847, 0.6764705777168274, 0.6832579374313354, 0.7013574838638306, 0.7024886608123779, 0.6968325972557068, 0.7036198973655701, 0.7036198973655701, 0.7081447839736938, 0.7070135474205017, 0.7013574838638306, 0.6990950107574463, 0.7104072570800781, 0.7115384340286255, 0.7115384340286255, 0.7160633206367493, 0.6866515874862671, 0.6968325972557068, 0.7036198973655701, 0.6945701241493225, 0.6957013607025146, 0.7047511339187622, 0.6945701241493225, 0.6957013607025146, 0.7149321436882019, 0.7160633206367493, 0.7126696705818176, 0.7160633206367493, 0.6990950107574463, 0.7036198973655701, 0.7036198973655701, 0.6945701241493225, 0.7149321436882019, 0.7171945571899414, 0.7149321436882019, 0.7104072570800781, 0.6957013607025146, 0.6900452375411987, 0.7160633206367493, 0.7058823704719543, 0.7138009071350098, 0.7036198973655701, 0.7171945571899414, 0.6776018142700195, 0.7013574838638306, 0.7002262473106384, 0.6968325972557068, 0.7160633206367493, 0.7183257937431335, 0.7138009071350098, 0.7183257937431335, 0.7115384340286255, 0.7081447839736938, 0.7036198973655701, 0.7104072570800781, 0.7058823704719543, 0.7013574838638306, 0.6968325972557068, 0.7138009071350098, 0.7183257937431335, 0.6843891143798828, 0.7104072570800781, 0.7070135474205017, 0.6843891143798828, 0.6979637742042542, 0.7081447839736938, 0.7081447839736938, 0.7171945571899414, 0.7058823704719543, 0.7024886608123779, 0.7149321436882019, 0.7013574838638306, 0.6979637742042542, 0.6990950107574463, 0.720588207244873, 0.6968325972557068, 0.7239819169044495, 0.7047511339187622, 0.6900452375411987, 0.7228506803512573, 0.7002262473106384, 0.7024886608123779, 0.7149321436882019, 0.6889140009880066]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 1.1502 - accuracy: 0.6930"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 7s 59ms/step - loss: 1.1502 - accuracy: 0.6930 - val_loss: 1.2519 - val_accuracy: 0.4845\n","Epoch 2/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1360 - accuracy: 0.7018 - val_loss: 1.2470 - val_accuracy: 0.4835\n","Epoch 3/100\n","31/31 [==============================] - 1s 32ms/step - loss: 1.1319 - accuracy: 0.6984 - val_loss: 1.2411 - val_accuracy: 0.4876\n","Epoch 4/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1265 - accuracy: 0.6982 - val_loss: 1.2359 - val_accuracy: 0.4876\n","Epoch 5/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1209 - accuracy: 0.7010 - val_loss: 1.2327 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1179 - accuracy: 0.7036 - val_loss: 1.2293 - val_accuracy: 0.4824\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1093 - accuracy: 0.7062 - val_loss: 1.2286 - val_accuracy: 0.4845\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1098 - accuracy: 0.7062 - val_loss: 1.2180 - val_accuracy: 0.4876\n","Epoch 9/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.1028 - accuracy: 0.7023 - val_loss: 1.2155 - val_accuracy: 0.4886\n","Epoch 10/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.0994 - accuracy: 0.7072 - val_loss: 1.2065 - val_accuracy: 0.4928\n","Epoch 11/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0893 - accuracy: 0.7142 - val_loss: 1.2005 - val_accuracy: 0.5062\n","Epoch 12/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0879 - accuracy: 0.7090 - val_loss: 1.1940 - val_accuracy: 0.5124\n","Epoch 13/100\n","31/31 [==============================] - 1s 29ms/step - loss: 1.0849 - accuracy: 0.7090 - val_loss: 1.1828 - val_accuracy: 0.5444\n","Epoch 14/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.0832 - accuracy: 0.7044 - val_loss: 1.1713 - val_accuracy: 0.5754\n","Epoch 15/100\n","31/31 [==============================] - 1s 28ms/step - loss: 1.0736 - accuracy: 0.7093 - val_loss: 1.1647 - val_accuracy: 0.5868\n","Epoch 16/100\n","31/31 [==============================] - 1s 39ms/step - loss: 1.0729 - accuracy: 0.7132 - val_loss: 1.1442 - val_accuracy: 0.6395\n","Epoch 17/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.0667 - accuracy: 0.7096 - val_loss: 1.1291 - val_accuracy: 0.6529\n","Epoch 18/100\n","31/31 [==============================] - 1s 30ms/step - loss: 1.0633 - accuracy: 0.7116 - val_loss: 1.1129 - val_accuracy: 0.6684\n","Epoch 19/100\n","31/31 [==============================] - 1s 34ms/step - loss: 1.0627 - accuracy: 0.7085 - val_loss: 1.1041 - val_accuracy: 0.6725\n","Epoch 20/100\n","31/31 [==============================] - 1s 34ms/step - loss: 1.0556 - accuracy: 0.7124 - val_loss: 1.0966 - val_accuracy: 0.6746\n","Epoch 21/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.0503 - accuracy: 0.7109 - val_loss: 1.0933 - val_accuracy: 0.6653\n","Epoch 22/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0473 - accuracy: 0.7054 - val_loss: 1.0847 - val_accuracy: 0.6736\n","Epoch 23/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0445 - accuracy: 0.7080 - val_loss: 1.0831 - val_accuracy: 0.6663\n","Epoch 24/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.0477 - accuracy: 0.7036 - val_loss: 1.0772 - val_accuracy: 0.6880\n","Epoch 25/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0375 - accuracy: 0.7106 - val_loss: 1.0811 - val_accuracy: 0.6798\n","Epoch 26/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0394 - accuracy: 0.7109 - val_loss: 1.0706 - val_accuracy: 0.6839\n","Epoch 27/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0292 - accuracy: 0.7059 - val_loss: 1.0708 - val_accuracy: 0.6653\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0238 - accuracy: 0.7155 - val_loss: 1.0658 - val_accuracy: 0.6808\n","Epoch 29/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0220 - accuracy: 0.7196 - val_loss: 1.0635 - val_accuracy: 0.6715\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0182 - accuracy: 0.7124 - val_loss: 1.0653 - val_accuracy: 0.6798\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0163 - accuracy: 0.7186 - val_loss: 1.0563 - val_accuracy: 0.6777\n","Epoch 32/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0160 - accuracy: 0.7047 - val_loss: 1.0523 - val_accuracy: 0.6808\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0123 - accuracy: 0.7163 - val_loss: 1.0528 - val_accuracy: 0.6684\n","Epoch 34/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0110 - accuracy: 0.7189 - val_loss: 1.0508 - val_accuracy: 0.6663\n","Epoch 35/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0028 - accuracy: 0.7181 - val_loss: 1.0456 - val_accuracy: 0.6787\n","Epoch 36/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0194 - accuracy: 0.7000 - val_loss: 1.0401 - val_accuracy: 0.6767\n","Epoch 37/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9973 - accuracy: 0.7209 - val_loss: 1.0404 - val_accuracy: 0.6849\n","Epoch 38/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9962 - accuracy: 0.7152 - val_loss: 1.0366 - val_accuracy: 0.6777\n","Epoch 39/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9915 - accuracy: 0.7199 - val_loss: 1.0424 - val_accuracy: 0.6808\n","Epoch 40/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9925 - accuracy: 0.7168 - val_loss: 1.0399 - val_accuracy: 0.6808\n","Epoch 41/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9837 - accuracy: 0.7276 - val_loss: 1.0287 - val_accuracy: 0.6777\n","Epoch 42/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9822 - accuracy: 0.7194 - val_loss: 1.0317 - val_accuracy: 0.6860\n","Epoch 43/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9798 - accuracy: 0.7196 - val_loss: 1.0248 - val_accuracy: 0.6736\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9850 - accuracy: 0.7140 - val_loss: 1.0375 - val_accuracy: 0.6653\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9777 - accuracy: 0.7127 - val_loss: 1.0168 - val_accuracy: 0.6746\n","Epoch 46/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9699 - accuracy: 0.7240 - val_loss: 1.0181 - val_accuracy: 0.6694\n","Epoch 47/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9686 - accuracy: 0.7186 - val_loss: 1.0123 - val_accuracy: 0.6808\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9630 - accuracy: 0.7258 - val_loss: 1.0107 - val_accuracy: 0.6756\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9617 - accuracy: 0.7207 - val_loss: 1.0080 - val_accuracy: 0.6756\n","Epoch 50/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9606 - accuracy: 0.7191 - val_loss: 1.0214 - val_accuracy: 0.6663\n","Epoch 51/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9600 - accuracy: 0.7217 - val_loss: 1.0070 - val_accuracy: 0.6725\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9491 - accuracy: 0.7295 - val_loss: 0.9993 - val_accuracy: 0.6756\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9513 - accuracy: 0.7204 - val_loss: 1.0037 - val_accuracy: 0.6767\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9472 - accuracy: 0.7300 - val_loss: 0.9956 - val_accuracy: 0.6808\n","Epoch 55/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9429 - accuracy: 0.7235 - val_loss: 1.0161 - val_accuracy: 0.6632\n","Epoch 56/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9605 - accuracy: 0.7044 - val_loss: 1.0013 - val_accuracy: 0.6715\n","Epoch 57/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9437 - accuracy: 0.7253 - val_loss: 0.9881 - val_accuracy: 0.6808\n","Epoch 58/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9327 - accuracy: 0.7282 - val_loss: 0.9856 - val_accuracy: 0.6777\n","Epoch 59/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9316 - accuracy: 0.7346 - val_loss: 0.9850 - val_accuracy: 0.6756\n","Epoch 60/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9438 - accuracy: 0.7168 - val_loss: 0.9850 - val_accuracy: 0.6808\n","Epoch 61/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9327 - accuracy: 0.7264 - val_loss: 0.9790 - val_accuracy: 0.6767\n","Epoch 62/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9309 - accuracy: 0.7279 - val_loss: 0.9761 - val_accuracy: 0.6880\n","Epoch 63/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9271 - accuracy: 0.7287 - val_loss: 0.9753 - val_accuracy: 0.6777\n","Epoch 64/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9211 - accuracy: 0.7323 - val_loss: 0.9725 - val_accuracy: 0.6798\n","Epoch 65/100\n","31/31 [==============================] - 2s 56ms/step - loss: 0.9168 - accuracy: 0.7339 - val_loss: 0.9729 - val_accuracy: 0.6952\n","Epoch 66/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9125 - accuracy: 0.7328 - val_loss: 0.9715 - val_accuracy: 0.6787\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9099 - accuracy: 0.7305 - val_loss: 0.9678 - val_accuracy: 0.6746\n","Epoch 68/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9094 - accuracy: 0.7364 - val_loss: 0.9658 - val_accuracy: 0.6746\n","Epoch 69/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9069 - accuracy: 0.7364 - val_loss: 0.9630 - val_accuracy: 0.6767\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9150 - accuracy: 0.7240 - val_loss: 0.9641 - val_accuracy: 0.6901\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9056 - accuracy: 0.7315 - val_loss: 0.9725 - val_accuracy: 0.6839\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9005 - accuracy: 0.7367 - val_loss: 0.9541 - val_accuracy: 0.6860\n","Epoch 73/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9014 - accuracy: 0.7307 - val_loss: 0.9538 - val_accuracy: 0.6818\n","Epoch 74/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9034 - accuracy: 0.7339 - val_loss: 0.9498 - val_accuracy: 0.6880\n","Epoch 75/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8955 - accuracy: 0.7315 - val_loss: 0.9517 - val_accuracy: 0.6787\n","Epoch 76/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8898 - accuracy: 0.7357 - val_loss: 0.9454 - val_accuracy: 0.6860\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8888 - accuracy: 0.7382 - val_loss: 0.9574 - val_accuracy: 0.6777\n","Epoch 78/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8865 - accuracy: 0.7380 - val_loss: 0.9441 - val_accuracy: 0.6870\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8853 - accuracy: 0.7403 - val_loss: 0.9404 - val_accuracy: 0.6787\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8837 - accuracy: 0.7380 - val_loss: 0.9479 - val_accuracy: 0.6756\n","Epoch 81/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8799 - accuracy: 0.7429 - val_loss: 0.9470 - val_accuracy: 0.6890\n","Epoch 82/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8879 - accuracy: 0.7274 - val_loss: 0.9410 - val_accuracy: 0.6746\n","Epoch 83/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.8718 - accuracy: 0.7419 - val_loss: 0.9329 - val_accuracy: 0.6860\n","Epoch 84/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.8708 - accuracy: 0.7460 - val_loss: 0.9371 - val_accuracy: 0.6921\n","Epoch 85/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.8691 - accuracy: 0.7457 - val_loss: 0.9295 - val_accuracy: 0.6839\n","Epoch 86/100\n","31/31 [==============================] - 2s 57ms/step - loss: 0.8683 - accuracy: 0.7388 - val_loss: 0.9275 - val_accuracy: 0.6973\n","Epoch 87/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8657 - accuracy: 0.7452 - val_loss: 0.9273 - val_accuracy: 0.6860\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8628 - accuracy: 0.7506 - val_loss: 0.9300 - val_accuracy: 0.6870\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8579 - accuracy: 0.7499 - val_loss: 0.9323 - val_accuracy: 0.6860\n","Epoch 90/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8550 - accuracy: 0.7527 - val_loss: 0.9282 - val_accuracy: 0.6880\n","Epoch 91/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8570 - accuracy: 0.7434 - val_loss: 0.9407 - val_accuracy: 0.6942\n","Epoch 92/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8676 - accuracy: 0.7385 - val_loss: 0.9441 - val_accuracy: 0.6767\n","Epoch 93/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8540 - accuracy: 0.7375 - val_loss: 0.9196 - val_accuracy: 0.6880\n","Epoch 94/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8528 - accuracy: 0.7486 - val_loss: 0.9329 - val_accuracy: 0.6777\n","Epoch 95/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8560 - accuracy: 0.7362 - val_loss: 0.9141 - val_accuracy: 0.6890\n","Epoch 96/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8430 - accuracy: 0.7499 - val_loss: 0.9118 - val_accuracy: 0.6952\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8413 - accuracy: 0.7514 - val_loss: 0.9092 - val_accuracy: 0.6942\n","Epoch 98/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8496 - accuracy: 0.7439 - val_loss: 0.9089 - val_accuracy: 0.6901\n","Epoch 99/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8385 - accuracy: 0.7548 - val_loss: 0.9094 - val_accuracy: 0.6921\n","Epoch 100/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8354 - accuracy: 0.7496 - val_loss: 0.9147 - val_accuracy: 0.6860\n","{'loss': [1.150175929069519, 1.1360408067703247, 1.1318625211715698, 1.1264568567276, 1.120930552482605, 1.1179440021514893, 1.1092668771743774, 1.1097583770751953, 1.1028211116790771, 1.0993763208389282, 1.0893261432647705, 1.0878798961639404, 1.084873080253601, 1.083248496055603, 1.073649287223816, 1.0728623867034912, 1.0667105913162231, 1.0632954835891724, 1.062690258026123, 1.0556063652038574, 1.0503156185150146, 1.0473357439041138, 1.0444749593734741, 1.0477038621902466, 1.0375348329544067, 1.0393989086151123, 1.0292235612869263, 1.0238062143325806, 1.0219595432281494, 1.0181721448898315, 1.0162842273712158, 1.0160226821899414, 1.0122687816619873, 1.010987639427185, 1.0028468370437622, 1.0194056034088135, 0.9973171949386597, 0.9962165355682373, 0.9914888143539429, 0.9924695491790771, 0.983700692653656, 0.9822338223457336, 0.9798414707183838, 0.985027551651001, 0.9776782393455505, 0.9698741436004639, 0.9685859084129333, 0.9630383253097534, 0.9617359638214111, 0.9606385827064514, 0.9599999189376831, 0.949130117893219, 0.9513186812400818, 0.9471590518951416, 0.9429454207420349, 0.9605076313018799, 0.9436825513839722, 0.932701051235199, 0.9315876364707947, 0.9437930583953857, 0.9326584935188293, 0.9308964014053345, 0.927079975605011, 0.9210569262504578, 0.9168056845664978, 0.9125306010246277, 0.9098788499832153, 0.9094417691230774, 0.906890869140625, 0.9149500131607056, 0.905586302280426, 0.900459885597229, 0.9014461636543274, 0.9033983945846558, 0.8955427408218384, 0.8898370265960693, 0.8887613415718079, 0.886457085609436, 0.885336697101593, 0.8836742639541626, 0.8799368143081665, 0.8878907561302185, 0.8718121647834778, 0.8708148002624512, 0.8691157102584839, 0.8683397769927979, 0.8657238483428955, 0.8628152012825012, 0.8578623533248901, 0.855033814907074, 0.8569616079330444, 0.8675842881202698, 0.8539556264877319, 0.8528342247009277, 0.8559900522232056, 0.8430402874946594, 0.8412788510322571, 0.8495709300041199, 0.8384550213813782, 0.835415780544281], 'accuracy': [0.6930232644081116, 0.7018088102340698, 0.6984496116638184, 0.698191225528717, 0.7010335922241211, 0.7036175727844238, 0.7062015533447266, 0.7062015533447266, 0.7023255825042725, 0.7072351574897766, 0.7142118811607361, 0.7090439200401306, 0.7090439200401306, 0.7043927907943726, 0.7093023061752319, 0.713178277015686, 0.709560751914978, 0.7116279006004333, 0.708527147769928, 0.7124031186103821, 0.7108527421951294, 0.7054263353347778, 0.7080103158950806, 0.7036175727844238, 0.7105942964553833, 0.7108527421951294, 0.7059431672096252, 0.7155038714408875, 0.7196382284164429, 0.7124031186103821, 0.7186046242713928, 0.7046511769294739, 0.7162790894508362, 0.7188630700111389, 0.7180878520011902, 0.699999988079071, 0.7209302186965942, 0.7152454853057861, 0.7198966145515442, 0.7167958617210388, 0.7276485562324524, 0.7193798422813416, 0.7196382284164429, 0.7139534950256348, 0.7126615047454834, 0.7240310311317444, 0.7186046242713928, 0.7258397936820984, 0.7206718325614929, 0.7191214561462402, 0.721705436706543, 0.7294573783874512, 0.7204134464263916, 0.7299741506576538, 0.723514199256897, 0.7043927907943726, 0.7253230214118958, 0.7281653881072998, 0.7346253395080566, 0.7167958617210388, 0.726356565952301, 0.7279070019721985, 0.7286821603775024, 0.7322997450828552, 0.7338501214981079, 0.7328165173530579, 0.7304909825325012, 0.7364341020584106, 0.7364341020584106, 0.7240310311317444, 0.7315245270729065, 0.736692488193512, 0.7307493686676025, 0.7338501214981079, 0.7315245270729065, 0.7356589436531067, 0.7382428646087646, 0.7379844784736633, 0.7403100728988647, 0.7379844784736633, 0.7428940534591675, 0.7273901700973511, 0.7418604493141174, 0.7459948062896729, 0.7457364201545715, 0.7387596964836121, 0.7452196478843689, 0.7506459951400757, 0.749870777130127, 0.7527132034301758, 0.7434108257293701, 0.7385013103485107, 0.7374677062034607, 0.7485787868499756, 0.7361757159233093, 0.749870777130127, 0.7514212131500244, 0.7439276576042175, 0.7547803521156311, 0.7496123909950256], 'val_loss': [1.2519397735595703, 1.2470049858093262, 1.2410900592803955, 1.2359490394592285, 1.232747197151184, 1.2292990684509277, 1.2285736799240112, 1.2180469036102295, 1.2155301570892334, 1.2064915895462036, 1.2004588842391968, 1.193985104560852, 1.1827561855316162, 1.1713085174560547, 1.1647297143936157, 1.1441658735275269, 1.1291054487228394, 1.1128566265106201, 1.1041470766067505, 1.0966095924377441, 1.0932612419128418, 1.0846515893936157, 1.0831111669540405, 1.077244758605957, 1.0811073780059814, 1.0706055164337158, 1.070806622505188, 1.0657790899276733, 1.0634770393371582, 1.065315842628479, 1.0563336610794067, 1.0522539615631104, 1.0528286695480347, 1.0508471727371216, 1.0455647706985474, 1.0400948524475098, 1.0403999090194702, 1.036588191986084, 1.0424094200134277, 1.039872407913208, 1.0287309885025024, 1.0316994190216064, 1.0247877836227417, 1.0375241041183472, 1.0168209075927734, 1.0180960893630981, 1.01231849193573, 1.01065194606781, 1.0079678297042847, 1.0213695764541626, 1.0070246458053589, 0.999293327331543, 1.0036523342132568, 0.9955695271492004, 1.0160839557647705, 1.0012702941894531, 0.9880886077880859, 0.98558109998703, 0.9849615097045898, 0.9849676489830017, 0.9790261387825012, 0.9761071801185608, 0.9752597212791443, 0.9724565148353577, 0.9729228019714355, 0.9714730978012085, 0.9678402543067932, 0.9657831788063049, 0.9629711508750916, 0.964121401309967, 0.972500741481781, 0.9541187286376953, 0.9538495540618896, 0.9497750997543335, 0.9516956806182861, 0.9453823566436768, 0.9573501348495483, 0.9440893530845642, 0.9404440522193909, 0.9478615522384644, 0.9470406174659729, 0.9410357475280762, 0.9329334497451782, 0.9370934367179871, 0.9295152425765991, 0.9274889230728149, 0.9273415803909302, 0.930025577545166, 0.9322865009307861, 0.9282376766204834, 0.9406605362892151, 0.9440605044364929, 0.919572651386261, 0.9329265356063843, 0.9141234159469604, 0.911759614944458, 0.9092316627502441, 0.9088810682296753, 0.9094237089157104, 0.9147368669509888], 'val_accuracy': [0.4845041334629059, 0.4834710657596588, 0.4876033067703247, 0.4876033067703247, 0.48553720116615295, 0.48243802785873413, 0.4845041334629059, 0.4876033067703247, 0.4886363744735718, 0.4927685856819153, 0.5061983466148376, 0.5123966932296753, 0.5444214940071106, 0.5754132270812988, 0.586776852607727, 0.6394628286361694, 0.6528925895690918, 0.6683884263038635, 0.672520637512207, 0.6745867729187012, 0.6652892827987671, 0.6735537052154541, 0.6663222908973694, 0.6880165338516235, 0.6797520518302917, 0.68388432264328, 0.6652892827987671, 0.6807851195335388, 0.6714876294136047, 0.6797520518302917, 0.6776859760284424, 0.6807851195335388, 0.6683884263038635, 0.6663222908973694, 0.6787189841270447, 0.6766529083251953, 0.6849173307418823, 0.6776859760284424, 0.6807851195335388, 0.6807851195335388, 0.6776859760284424, 0.6859503984451294, 0.6735537052154541, 0.6652892827987671, 0.6745867729187012, 0.6694214940071106, 0.6807851195335388, 0.6756198406219482, 0.6756198406219482, 0.6663222908973694, 0.672520637512207, 0.6756198406219482, 0.6766529083251953, 0.6807851195335388, 0.663223147392273, 0.6714876294136047, 0.6807851195335388, 0.6776859760284424, 0.6756198406219482, 0.6807851195335388, 0.6766529083251953, 0.6880165338516235, 0.6776859760284424, 0.6797520518302917, 0.6952479481697083, 0.6787189841270447, 0.6745867729187012, 0.6745867729187012, 0.6766529083251953, 0.6900826692581177, 0.68388432264328, 0.6859503984451294, 0.6818181872367859, 0.6880165338516235, 0.6787189841270447, 0.6859503984451294, 0.6776859760284424, 0.6869834661483765, 0.6787189841270447, 0.6756198406219482, 0.6890496015548706, 0.6745867729187012, 0.6859503984451294, 0.692148745059967, 0.68388432264328, 0.6973140239715576, 0.6859503984451294, 0.6869834661483765, 0.6859503984451294, 0.6880165338516235, 0.6942148804664612, 0.6766529083251953, 0.6880165338516235, 0.6776859760284424, 0.6890496015548706, 0.6952479481697083, 0.6942148804664612, 0.6900826692581177, 0.692148745059967, 0.6859503984451294]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.8714 - accuracy: 0.7338"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 6s 56ms/step - loss: 0.8714 - accuracy: 0.7338 - val_loss: 1.0295 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8627 - accuracy: 0.7400 - val_loss: 1.0264 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8582 - accuracy: 0.7387 - val_loss: 1.0316 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8589 - accuracy: 0.7330 - val_loss: 1.0293 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8550 - accuracy: 0.7414 - val_loss: 1.0287 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8481 - accuracy: 0.7465 - val_loss: 1.0307 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8465 - accuracy: 0.7406 - val_loss: 1.0322 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8458 - accuracy: 0.7443 - val_loss: 1.0335 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8389 - accuracy: 0.7473 - val_loss: 1.0263 - val_accuracy: 0.4849\n","Epoch 10/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8409 - accuracy: 0.7462 - val_loss: 1.0347 - val_accuracy: 0.4849\n","Epoch 11/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8374 - accuracy: 0.7465 - val_loss: 1.0455 - val_accuracy: 0.4849\n","Epoch 12/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.8379 - accuracy: 0.7408 - val_loss: 1.0134 - val_accuracy: 0.4892\n","Epoch 13/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.8405 - accuracy: 0.7363 - val_loss: 1.0078 - val_accuracy: 0.4957\n","Epoch 14/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.8354 - accuracy: 0.7443 - val_loss: 0.9958 - val_accuracy: 0.5151\n","Epoch 15/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8331 - accuracy: 0.7454 - val_loss: 1.0410 - val_accuracy: 0.4946\n","Epoch 16/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.8296 - accuracy: 0.7468 - val_loss: 0.9788 - val_accuracy: 0.5528\n","Epoch 17/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.8333 - accuracy: 0.7419 - val_loss: 0.9800 - val_accuracy: 0.5625\n","Epoch 18/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.8239 - accuracy: 0.7489 - val_loss: 0.9113 - val_accuracy: 0.6713\n","Epoch 19/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8253 - accuracy: 0.7503 - val_loss: 0.9121 - val_accuracy: 0.6670\n","Epoch 20/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.8214 - accuracy: 0.7497 - val_loss: 0.8863 - val_accuracy: 0.7091\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8190 - accuracy: 0.7543 - val_loss: 0.8806 - val_accuracy: 0.7058\n","Epoch 22/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.8197 - accuracy: 0.7487 - val_loss: 0.8721 - val_accuracy: 0.7317\n","Epoch 23/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8245 - accuracy: 0.7427 - val_loss: 0.8711 - val_accuracy: 0.7317\n","Epoch 24/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.8135 - accuracy: 0.7484 - val_loss: 0.8616 - val_accuracy: 0.7371\n","Epoch 25/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8125 - accuracy: 0.7586 - val_loss: 0.8592 - val_accuracy: 0.7091\n","Epoch 26/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8155 - accuracy: 0.7443 - val_loss: 0.8494 - val_accuracy: 0.7371\n","Epoch 27/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.8081 - accuracy: 0.7592 - val_loss: 0.8468 - val_accuracy: 0.7489\n","Epoch 28/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.8129 - accuracy: 0.7503 - val_loss: 0.8429 - val_accuracy: 0.7446\n","Epoch 29/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8043 - accuracy: 0.7559 - val_loss: 0.8404 - val_accuracy: 0.7371\n","Epoch 30/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8023 - accuracy: 0.7575 - val_loss: 0.8572 - val_accuracy: 0.7338\n","Epoch 31/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8041 - accuracy: 0.7527 - val_loss: 0.8404 - val_accuracy: 0.7338\n","Epoch 32/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7993 - accuracy: 0.7538 - val_loss: 0.8426 - val_accuracy: 0.7435\n","Epoch 33/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7994 - accuracy: 0.7570 - val_loss: 0.8367 - val_accuracy: 0.7425\n","Epoch 34/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7930 - accuracy: 0.7567 - val_loss: 0.8353 - val_accuracy: 0.7435\n","Epoch 35/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8043 - accuracy: 0.7481 - val_loss: 0.8379 - val_accuracy: 0.7328\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7955 - accuracy: 0.7538 - val_loss: 0.8364 - val_accuracy: 0.7435\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7947 - accuracy: 0.7516 - val_loss: 0.8519 - val_accuracy: 0.7112\n","Epoch 38/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7915 - accuracy: 0.7578 - val_loss: 0.8333 - val_accuracy: 0.7381\n","Epoch 39/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7863 - accuracy: 0.7619 - val_loss: 0.8342 - val_accuracy: 0.7381\n","Epoch 40/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7874 - accuracy: 0.7559 - val_loss: 0.8324 - val_accuracy: 0.7338\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7983 - accuracy: 0.7484 - val_loss: 0.8294 - val_accuracy: 0.7446\n","Epoch 42/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7852 - accuracy: 0.7654 - val_loss: 0.8394 - val_accuracy: 0.7403\n","Epoch 43/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7771 - accuracy: 0.7619 - val_loss: 0.8311 - val_accuracy: 0.7392\n","Epoch 44/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7871 - accuracy: 0.7608 - val_loss: 0.8332 - val_accuracy: 0.7371\n","Epoch 45/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7764 - accuracy: 0.7654 - val_loss: 0.8421 - val_accuracy: 0.7317\n","Epoch 46/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7881 - accuracy: 0.7613 - val_loss: 0.8255 - val_accuracy: 0.7446\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7844 - accuracy: 0.7589 - val_loss: 0.8418 - val_accuracy: 0.7188\n","Epoch 48/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7848 - accuracy: 0.7589 - val_loss: 0.8312 - val_accuracy: 0.7381\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7757 - accuracy: 0.7624 - val_loss: 0.8253 - val_accuracy: 0.7435\n","Epoch 50/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7698 - accuracy: 0.7643 - val_loss: 0.8254 - val_accuracy: 0.7446\n","Epoch 51/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7647 - accuracy: 0.7724 - val_loss: 0.8318 - val_accuracy: 0.7371\n","Epoch 52/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7732 - accuracy: 0.7632 - val_loss: 0.8596 - val_accuracy: 0.7123\n","Epoch 53/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7746 - accuracy: 0.7675 - val_loss: 0.8263 - val_accuracy: 0.7403\n","Epoch 54/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7636 - accuracy: 0.7610 - val_loss: 0.8274 - val_accuracy: 0.7381\n","Epoch 55/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7621 - accuracy: 0.7740 - val_loss: 0.8276 - val_accuracy: 0.7306\n","Epoch 56/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7597 - accuracy: 0.7691 - val_loss: 0.8196 - val_accuracy: 0.7468\n","Epoch 57/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7687 - accuracy: 0.7659 - val_loss: 0.8267 - val_accuracy: 0.7392\n","Epoch 58/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.7578 - accuracy: 0.7664 - val_loss: 0.8504 - val_accuracy: 0.7058\n","Epoch 59/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7715 - accuracy: 0.7675 - val_loss: 0.8342 - val_accuracy: 0.7263\n","Epoch 60/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7587 - accuracy: 0.7648 - val_loss: 0.8371 - val_accuracy: 0.7188\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7593 - accuracy: 0.7645 - val_loss: 0.8170 - val_accuracy: 0.7381\n","Epoch 62/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7524 - accuracy: 0.7780 - val_loss: 0.8170 - val_accuracy: 0.7392\n","Epoch 63/100\n","29/29 [==============================] - 1s 52ms/step - loss: 0.7538 - accuracy: 0.7691 - val_loss: 0.8137 - val_accuracy: 0.7500\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7574 - accuracy: 0.7702 - val_loss: 0.8233 - val_accuracy: 0.7403\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7671 - accuracy: 0.7538 - val_loss: 0.8171 - val_accuracy: 0.7446\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7487 - accuracy: 0.7699 - val_loss: 0.8226 - val_accuracy: 0.7360\n","Epoch 67/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7478 - accuracy: 0.7740 - val_loss: 0.8125 - val_accuracy: 0.7403\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7521 - accuracy: 0.7761 - val_loss: 0.8149 - val_accuracy: 0.7478\n","Epoch 69/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7345 - accuracy: 0.7818 - val_loss: 0.8307 - val_accuracy: 0.7188\n","Epoch 70/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7416 - accuracy: 0.7764 - val_loss: 0.8217 - val_accuracy: 0.7306\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7397 - accuracy: 0.7791 - val_loss: 0.8110 - val_accuracy: 0.7446\n","Epoch 72/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7379 - accuracy: 0.7769 - val_loss: 0.8125 - val_accuracy: 0.7349\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7383 - accuracy: 0.7734 - val_loss: 0.8360 - val_accuracy: 0.7144\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7308 - accuracy: 0.7753 - val_loss: 0.8118 - val_accuracy: 0.7338\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7384 - accuracy: 0.7775 - val_loss: 0.8263 - val_accuracy: 0.7328\n","Epoch 76/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.7260 - accuracy: 0.7786 - val_loss: 0.8097 - val_accuracy: 0.7414\n","Epoch 77/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.7318 - accuracy: 0.7821 - val_loss: 0.8186 - val_accuracy: 0.7392\n","Epoch 78/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.7237 - accuracy: 0.7866 - val_loss: 0.8079 - val_accuracy: 0.7403\n","Epoch 79/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7291 - accuracy: 0.7780 - val_loss: 0.8137 - val_accuracy: 0.7381\n","Epoch 80/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7336 - accuracy: 0.7740 - val_loss: 0.8117 - val_accuracy: 0.7392\n","Epoch 81/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7301 - accuracy: 0.7713 - val_loss: 0.8107 - val_accuracy: 0.7457\n","Epoch 82/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7219 - accuracy: 0.7842 - val_loss: 0.8086 - val_accuracy: 0.7360\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7303 - accuracy: 0.7753 - val_loss: 0.8204 - val_accuracy: 0.7317\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7296 - accuracy: 0.7856 - val_loss: 0.8060 - val_accuracy: 0.7392\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7185 - accuracy: 0.7856 - val_loss: 0.8085 - val_accuracy: 0.7381\n","Epoch 86/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7242 - accuracy: 0.7748 - val_loss: 0.8621 - val_accuracy: 0.7134\n","Epoch 87/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7426 - accuracy: 0.7683 - val_loss: 0.8098 - val_accuracy: 0.7317\n","Epoch 88/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7158 - accuracy: 0.7883 - val_loss: 0.8243 - val_accuracy: 0.7349\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7182 - accuracy: 0.7839 - val_loss: 0.8311 - val_accuracy: 0.7231\n","Epoch 90/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7187 - accuracy: 0.7804 - val_loss: 0.8250 - val_accuracy: 0.7295\n","Epoch 91/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7123 - accuracy: 0.7866 - val_loss: 0.8334 - val_accuracy: 0.7295\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7112 - accuracy: 0.7874 - val_loss: 0.8087 - val_accuracy: 0.7414\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7110 - accuracy: 0.7864 - val_loss: 0.8053 - val_accuracy: 0.7457\n","Epoch 94/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7174 - accuracy: 0.7751 - val_loss: 0.8060 - val_accuracy: 0.7414\n","Epoch 95/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7160 - accuracy: 0.7834 - val_loss: 0.8045 - val_accuracy: 0.7317\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7110 - accuracy: 0.7856 - val_loss: 0.8184 - val_accuracy: 0.7306\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6998 - accuracy: 0.7920 - val_loss: 0.8049 - val_accuracy: 0.7371\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7026 - accuracy: 0.7928 - val_loss: 0.8030 - val_accuracy: 0.7360\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7054 - accuracy: 0.7880 - val_loss: 0.8174 - val_accuracy: 0.7338\n","Epoch 100/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6970 - accuracy: 0.7955 - val_loss: 0.8098 - val_accuracy: 0.7306\n","{'loss': [0.8713652491569519, 0.8627499341964722, 0.8582090735435486, 0.8588964939117432, 0.855003297328949, 0.848116934299469, 0.8464710712432861, 0.8457780480384827, 0.838904619216919, 0.8409273028373718, 0.8373698592185974, 0.8378665447235107, 0.840488851070404, 0.8353723883628845, 0.8330630660057068, 0.8296403288841248, 0.8332953453063965, 0.8238853812217712, 0.825259268283844, 0.821373462677002, 0.8189713954925537, 0.8197457790374756, 0.8244748711585999, 0.8135497570037842, 0.8124533295631409, 0.8154683709144592, 0.8081074357032776, 0.8128859996795654, 0.8042678236961365, 0.8022861480712891, 0.8041144609451294, 0.7992786169052124, 0.7993612885475159, 0.7929816246032715, 0.8042781352996826, 0.7955271005630493, 0.7947078347206116, 0.7914969325065613, 0.7863313555717468, 0.7873847484588623, 0.7982585430145264, 0.7851901054382324, 0.7771449685096741, 0.7871226668357849, 0.7764104008674622, 0.7880517244338989, 0.7844454646110535, 0.784833550453186, 0.775708794593811, 0.7698400020599365, 0.7646830081939697, 0.7731925249099731, 0.7745725512504578, 0.7635790109634399, 0.7621187567710876, 0.7596601843833923, 0.7687069177627563, 0.7577928900718689, 0.7714589834213257, 0.7586730718612671, 0.7593259215354919, 0.7524468898773193, 0.7538259625434875, 0.7574204206466675, 0.7670859098434448, 0.7486943602561951, 0.7477643489837646, 0.752101719379425, 0.7344738245010376, 0.7415979504585266, 0.7397050261497498, 0.7379412055015564, 0.7382785081863403, 0.73079913854599, 0.738380491733551, 0.7260221242904663, 0.7317593693733215, 0.7237381935119629, 0.729106068611145, 0.7335647344589233, 0.7301377654075623, 0.721870481967926, 0.7303111553192139, 0.7295961976051331, 0.7184725999832153, 0.7241834402084351, 0.7425973415374756, 0.7157778143882751, 0.7182340025901794, 0.7187235355377197, 0.7122563719749451, 0.7111581563949585, 0.7109723091125488, 0.717410147190094, 0.7160153388977051, 0.7110180258750916, 0.6997776031494141, 0.7025874853134155, 0.7053694128990173, 0.6970087289810181], 'accuracy': [0.7338362336158752, 0.7400323152542114, 0.7386853694915771, 0.733027994632721, 0.7413793206214905, 0.7464978694915771, 0.740571141242981, 0.7443426847457886, 0.7473060488700867, 0.7462284564971924, 0.7464978694915771, 0.740840494632721, 0.7362607717514038, 0.7443426847457886, 0.7454202771186829, 0.7467672228813171, 0.7419180870056152, 0.7489224076271057, 0.7502694129943848, 0.7497305870056152, 0.7543103694915771, 0.748652994632721, 0.7427262663841248, 0.748383641242981, 0.7586206793785095, 0.7443426847457886, 0.759159505367279, 0.7502694129943848, 0.7559267282485962, 0.7575430870056152, 0.7526939511299133, 0.7537715435028076, 0.7570043206214905, 0.7567349076271057, 0.7481142282485962, 0.7537715435028076, 0.751616358757019, 0.7578125, 0.7618534564971924, 0.7559267282485962, 0.748383641242981, 0.7653555870056152, 0.7618534564971924, 0.7607758641242981, 0.7653555870056152, 0.7613146305084229, 0.7588900923728943, 0.7588900923728943, 0.7623922228813171, 0.764277994632721, 0.7723599076271057, 0.7632004022598267, 0.7675107717514038, 0.7610452771186829, 0.7739762663841248, 0.7691271305084229, 0.7658944129943848, 0.7664331793785095, 0.7675107717514038, 0.7648168206214905, 0.7645474076271057, 0.7780172228813171, 0.7691271305084229, 0.7702047228813171, 0.7537715435028076, 0.7699353694915771, 0.7739762663841248, 0.7761314511299133, 0.7817887663841248, 0.7764008641242981, 0.7790948152542114, 0.7769396305084229, 0.7734375, 0.7753232717514038, 0.7774784564971924, 0.7785560488700867, 0.7820581793785095, 0.7866379022598267, 0.7780172228813171, 0.7739762663841248, 0.7712823152542114, 0.7842133641242981, 0.7753232717514038, 0.7855603694915771, 0.7855603694915771, 0.774784505367279, 0.7683189511299133, 0.7882543206214905, 0.7839439511299133, 0.7804418206214905, 0.7866379022598267, 0.787446141242981, 0.7863685488700867, 0.775053858757019, 0.7834051847457886, 0.7855603694915771, 0.7920258641242981, 0.7928340435028076, 0.7879849076271057, 0.795527994632721], 'val_loss': [1.0295279026031494, 1.0263869762420654, 1.0315638780593872, 1.0293220281600952, 1.028716802597046, 1.0306556224822998, 1.032172679901123, 1.0335195064544678, 1.026313304901123, 1.0346640348434448, 1.0454987287521362, 1.013441562652588, 1.007826566696167, 0.9958436489105225, 1.0410164594650269, 0.9788368344306946, 0.9799842834472656, 0.9112915396690369, 0.9121389985084534, 0.8863250613212585, 0.8805934190750122, 0.8720889687538147, 0.8710888624191284, 0.8615753650665283, 0.859179675579071, 0.849376916885376, 0.8467865586280823, 0.8428587317466736, 0.8403658866882324, 0.8572322726249695, 0.8403975367546082, 0.8426461219787598, 0.8366913795471191, 0.8353450298309326, 0.8378994464874268, 0.8363808989524841, 0.8519462943077087, 0.8332921862602234, 0.8341834545135498, 0.8323594331741333, 0.8293622136116028, 0.8394274711608887, 0.8310659527778625, 0.8331735730171204, 0.8420829772949219, 0.8255444765090942, 0.8417877554893494, 0.8311941623687744, 0.8253465890884399, 0.8254333734512329, 0.8318175077438354, 0.8595601320266724, 0.8262795805931091, 0.8273879289627075, 0.8275570869445801, 0.8196281790733337, 0.8266516923904419, 0.8504274487495422, 0.8342093825340271, 0.8371060490608215, 0.8169522881507874, 0.8170081377029419, 0.813728928565979, 0.8232817053794861, 0.8171128034591675, 0.8225528597831726, 0.8125099539756775, 0.8149380683898926, 0.8306728005409241, 0.8216656446456909, 0.8110038638114929, 0.8124915957450867, 0.8359752297401428, 0.8118252754211426, 0.8263221979141235, 0.8097286224365234, 0.8185677528381348, 0.8079023957252502, 0.8137228488922119, 0.8117422461509705, 0.8106797337532043, 0.8085988163948059, 0.8203694820404053, 0.8059828281402588, 0.8085264563560486, 0.8621090650558472, 0.8098429441452026, 0.8242889642715454, 0.8310924172401428, 0.8249520659446716, 0.8333846926689148, 0.8087226748466492, 0.8052968382835388, 0.8059971928596497, 0.8044638633728027, 0.8183798789978027, 0.8049472570419312, 0.8029805421829224, 0.8174366354942322, 0.8098129630088806], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.4892241358757019, 0.49568966031074524, 0.5150862336158752, 0.49461206793785095, 0.5528017282485962, 0.5625, 0.6713362336158752, 0.6670258641242981, 0.7090517282485962, 0.7058189511299133, 0.7316810488700867, 0.7316810488700867, 0.7370689511299133, 0.7090517282485962, 0.7370689511299133, 0.7489224076271057, 0.7446120977401733, 0.7370689511299133, 0.7338362336158752, 0.7338362336158752, 0.743534505367279, 0.7424569129943848, 0.743534505367279, 0.732758641242981, 0.743534505367279, 0.7112069129943848, 0.7381465435028076, 0.7381465435028076, 0.7338362336158752, 0.7446120977401733, 0.7403017282485962, 0.7392241358757019, 0.7370689511299133, 0.7316810488700867, 0.7446120977401733, 0.71875, 0.7381465435028076, 0.743534505367279, 0.7446120977401733, 0.7370689511299133, 0.712284505367279, 0.7403017282485962, 0.7381465435028076, 0.7306034564971924, 0.7467672228813171, 0.7392241358757019, 0.7058189511299133, 0.7262930870056152, 0.71875, 0.7381465435028076, 0.7392241358757019, 0.75, 0.7403017282485962, 0.7446120977401733, 0.735991358757019, 0.7403017282485962, 0.7478448152542114, 0.71875, 0.7306034564971924, 0.7446120977401733, 0.7349137663841248, 0.7144396305084229, 0.7338362336158752, 0.732758641242981, 0.7413793206214905, 0.7392241358757019, 0.7403017282485962, 0.7381465435028076, 0.7392241358757019, 0.7456896305084229, 0.735991358757019, 0.7316810488700867, 0.7392241358757019, 0.7381465435028076, 0.7133620977401733, 0.7316810488700867, 0.7349137663841248, 0.7230603694915771, 0.7295258641242981, 0.7295258641242981, 0.7413793206214905, 0.7456896305084229, 0.7413793206214905, 0.7316810488700867, 0.7306034564971924, 0.7370689511299133, 0.735991358757019, 0.7338362336158752, 0.7306034564971924]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.8777 - accuracy: 0.7254"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 10s 60ms/step - loss: 0.8762 - accuracy: 0.7264 - val_loss: 1.0264 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.8678 - accuracy: 0.7289 - val_loss: 1.0222 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8638 - accuracy: 0.7402 - val_loss: 1.0202 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8619 - accuracy: 0.7340 - val_loss: 1.0204 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8549 - accuracy: 0.7397 - val_loss: 1.0185 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8556 - accuracy: 0.7368 - val_loss: 1.0214 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8539 - accuracy: 0.7385 - val_loss: 1.0180 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8519 - accuracy: 0.7394 - val_loss: 1.0216 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8563 - accuracy: 0.7349 - val_loss: 1.0199 - val_accuracy: 0.4955\n","Epoch 10/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8459 - accuracy: 0.7467 - val_loss: 1.0204 - val_accuracy: 0.4955\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8451 - accuracy: 0.7434 - val_loss: 1.0234 - val_accuracy: 0.4955\n","Epoch 12/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.8476 - accuracy: 0.7400 - val_loss: 1.0038 - val_accuracy: 0.5068\n","Epoch 13/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.8396 - accuracy: 0.7450 - val_loss: 1.0003 - val_accuracy: 0.5158\n","Epoch 14/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.8362 - accuracy: 0.7450 - val_loss: 0.9827 - val_accuracy: 0.5452\n","Epoch 15/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.8347 - accuracy: 0.7482 - val_loss: 0.9835 - val_accuracy: 0.5486\n","Epoch 16/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.8353 - accuracy: 0.7513 - val_loss: 0.9777 - val_accuracy: 0.5633\n","Epoch 17/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.8321 - accuracy: 0.7428 - val_loss: 0.9584 - val_accuracy: 0.6018\n","Epoch 18/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.8363 - accuracy: 0.7442 - val_loss: 0.9112 - val_accuracy: 0.6991\n","Epoch 19/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8335 - accuracy: 0.7453 - val_loss: 0.9235 - val_accuracy: 0.6561\n","Epoch 20/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.8229 - accuracy: 0.7465 - val_loss: 0.8934 - val_accuracy: 0.7014\n","Epoch 21/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.8311 - accuracy: 0.7397 - val_loss: 0.8922 - val_accuracy: 0.7025\n","Epoch 22/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.8256 - accuracy: 0.7518 - val_loss: 0.8858 - val_accuracy: 0.7127\n","Epoch 23/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.8205 - accuracy: 0.7507 - val_loss: 0.8818 - val_accuracy: 0.7161\n","Epoch 24/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8235 - accuracy: 0.7459 - val_loss: 0.9118 - val_accuracy: 0.6934\n","Epoch 25/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8170 - accuracy: 0.7459 - val_loss: 0.8890 - val_accuracy: 0.7081\n","Epoch 26/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.8129 - accuracy: 0.7578 - val_loss: 0.8594 - val_accuracy: 0.7285\n","Epoch 27/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8150 - accuracy: 0.7552 - val_loss: 0.8635 - val_accuracy: 0.7217\n","Epoch 28/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8113 - accuracy: 0.7578 - val_loss: 0.8475 - val_accuracy: 0.7285\n","Epoch 29/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.8129 - accuracy: 0.7473 - val_loss: 0.8474 - val_accuracy: 0.7296\n","Epoch 30/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8078 - accuracy: 0.7558 - val_loss: 0.8727 - val_accuracy: 0.7217\n","Epoch 31/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8058 - accuracy: 0.7572 - val_loss: 0.8454 - val_accuracy: 0.7240\n","Epoch 32/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8056 - accuracy: 0.7507 - val_loss: 0.8835 - val_accuracy: 0.7138\n","Epoch 33/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8196 - accuracy: 0.7439 - val_loss: 0.8492 - val_accuracy: 0.7274\n","Epoch 34/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8013 - accuracy: 0.7572 - val_loss: 0.8487 - val_accuracy: 0.7149\n","Epoch 35/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8040 - accuracy: 0.7535 - val_loss: 0.8534 - val_accuracy: 0.7229\n","Epoch 36/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7997 - accuracy: 0.7555 - val_loss: 0.8405 - val_accuracy: 0.7206\n","Epoch 37/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7953 - accuracy: 0.7547 - val_loss: 0.8438 - val_accuracy: 0.7206\n","Epoch 38/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7971 - accuracy: 0.7649 - val_loss: 0.8403 - val_accuracy: 0.7274\n","Epoch 39/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7882 - accuracy: 0.7595 - val_loss: 0.8537 - val_accuracy: 0.7251\n","Epoch 40/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7948 - accuracy: 0.7586 - val_loss: 0.8363 - val_accuracy: 0.7240\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7859 - accuracy: 0.7600 - val_loss: 0.8375 - val_accuracy: 0.7240\n","Epoch 42/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7905 - accuracy: 0.7634 - val_loss: 0.8848 - val_accuracy: 0.6697\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7956 - accuracy: 0.7513 - val_loss: 0.8466 - val_accuracy: 0.7217\n","Epoch 44/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7857 - accuracy: 0.7663 - val_loss: 0.8483 - val_accuracy: 0.7217\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7816 - accuracy: 0.7666 - val_loss: 0.8355 - val_accuracy: 0.7251\n","Epoch 46/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7838 - accuracy: 0.7637 - val_loss: 0.8374 - val_accuracy: 0.7217\n","Epoch 47/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7799 - accuracy: 0.7600 - val_loss: 0.8346 - val_accuracy: 0.7206\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7772 - accuracy: 0.7649 - val_loss: 0.8377 - val_accuracy: 0.7206\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7736 - accuracy: 0.7705 - val_loss: 0.8443 - val_accuracy: 0.7296\n","Epoch 50/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7703 - accuracy: 0.7668 - val_loss: 0.8372 - val_accuracy: 0.7251\n","Epoch 51/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7707 - accuracy: 0.7714 - val_loss: 0.8401 - val_accuracy: 0.7070\n","Epoch 52/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7751 - accuracy: 0.7714 - val_loss: 0.8580 - val_accuracy: 0.7206\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7708 - accuracy: 0.7765 - val_loss: 0.8325 - val_accuracy: 0.7127\n","Epoch 54/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7690 - accuracy: 0.7668 - val_loss: 0.8312 - val_accuracy: 0.7195\n","Epoch 55/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7675 - accuracy: 0.7714 - val_loss: 0.8470 - val_accuracy: 0.7014\n","Epoch 56/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7691 - accuracy: 0.7640 - val_loss: 0.8325 - val_accuracy: 0.7149\n","Epoch 57/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7613 - accuracy: 0.7796 - val_loss: 0.8508 - val_accuracy: 0.7195\n","Epoch 58/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7644 - accuracy: 0.7722 - val_loss: 0.8391 - val_accuracy: 0.7036\n","Epoch 59/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7603 - accuracy: 0.7714 - val_loss: 0.8294 - val_accuracy: 0.7161\n","Epoch 60/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7649 - accuracy: 0.7649 - val_loss: 0.8308 - val_accuracy: 0.7093\n","Epoch 61/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7536 - accuracy: 0.7745 - val_loss: 0.8326 - val_accuracy: 0.7093\n","Epoch 62/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7646 - accuracy: 0.7677 - val_loss: 0.8558 - val_accuracy: 0.7262\n","Epoch 63/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7721 - accuracy: 0.7617 - val_loss: 0.8330 - val_accuracy: 0.7036\n","Epoch 64/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7608 - accuracy: 0.7731 - val_loss: 0.8340 - val_accuracy: 0.7262\n","Epoch 65/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7488 - accuracy: 0.7784 - val_loss: 0.8275 - val_accuracy: 0.7172\n","Epoch 66/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7460 - accuracy: 0.7883 - val_loss: 0.8691 - val_accuracy: 0.6640\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7519 - accuracy: 0.7745 - val_loss: 0.8281 - val_accuracy: 0.7093\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7607 - accuracy: 0.7660 - val_loss: 0.8227 - val_accuracy: 0.7251\n","Epoch 69/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7476 - accuracy: 0.7745 - val_loss: 0.8250 - val_accuracy: 0.7195\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7440 - accuracy: 0.7849 - val_loss: 0.8321 - val_accuracy: 0.6980\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7436 - accuracy: 0.7790 - val_loss: 0.8272 - val_accuracy: 0.7240\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7400 - accuracy: 0.7816 - val_loss: 0.8266 - val_accuracy: 0.7127\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7409 - accuracy: 0.7835 - val_loss: 0.8311 - val_accuracy: 0.6957\n","Epoch 74/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7332 - accuracy: 0.7804 - val_loss: 0.8215 - val_accuracy: 0.7217\n","Epoch 75/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7423 - accuracy: 0.7793 - val_loss: 0.8475 - val_accuracy: 0.7285\n","Epoch 76/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7323 - accuracy: 0.7832 - val_loss: 0.8329 - val_accuracy: 0.7240\n","Epoch 77/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7368 - accuracy: 0.7736 - val_loss: 0.8357 - val_accuracy: 0.6946\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7412 - accuracy: 0.7711 - val_loss: 0.8294 - val_accuracy: 0.7036\n","Epoch 79/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7252 - accuracy: 0.7889 - val_loss: 0.8214 - val_accuracy: 0.7183\n","Epoch 80/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7217 - accuracy: 0.7906 - val_loss: 0.8262 - val_accuracy: 0.7240\n","Epoch 81/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7295 - accuracy: 0.7883 - val_loss: 0.8416 - val_accuracy: 0.7285\n","Epoch 82/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7220 - accuracy: 0.7895 - val_loss: 0.8251 - val_accuracy: 0.7104\n","Epoch 83/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7172 - accuracy: 0.7864 - val_loss: 0.8260 - val_accuracy: 0.7229\n","Epoch 84/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7355 - accuracy: 0.7810 - val_loss: 0.8251 - val_accuracy: 0.7093\n","Epoch 85/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7219 - accuracy: 0.7821 - val_loss: 0.8241 - val_accuracy: 0.7206\n","Epoch 86/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7146 - accuracy: 0.7881 - val_loss: 0.8315 - val_accuracy: 0.7296\n","Epoch 87/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7281 - accuracy: 0.7832 - val_loss: 0.8239 - val_accuracy: 0.7206\n","Epoch 88/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7151 - accuracy: 0.7912 - val_loss: 0.8249 - val_accuracy: 0.7161\n","Epoch 89/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7185 - accuracy: 0.7932 - val_loss: 0.8271 - val_accuracy: 0.7025\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7149 - accuracy: 0.7912 - val_loss: 0.8236 - val_accuracy: 0.7048\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7277 - accuracy: 0.7813 - val_loss: 0.8779 - val_accuracy: 0.6606\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7285 - accuracy: 0.7765 - val_loss: 0.8233 - val_accuracy: 0.7104\n","Epoch 93/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7160 - accuracy: 0.7946 - val_loss: 0.8236 - val_accuracy: 0.7149\n","Epoch 94/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7040 - accuracy: 0.7943 - val_loss: 0.8257 - val_accuracy: 0.7115\n","Epoch 95/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7045 - accuracy: 0.7988 - val_loss: 0.8282 - val_accuracy: 0.7093\n","Epoch 96/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7042 - accuracy: 0.7895 - val_loss: 0.8249 - val_accuracy: 0.7138\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7066 - accuracy: 0.7982 - val_loss: 0.8235 - val_accuracy: 0.7059\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7135 - accuracy: 0.7903 - val_loss: 0.8219 - val_accuracy: 0.7149\n","Epoch 99/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6943 - accuracy: 0.8019 - val_loss: 0.8341 - val_accuracy: 0.6957\n","Epoch 100/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6973 - accuracy: 0.8016 - val_loss: 0.8282 - val_accuracy: 0.6980\n","{'loss': [0.8762173056602478, 0.8678075075149536, 0.8638182878494263, 0.8619347214698792, 0.8549018502235413, 0.855602502822876, 0.853936493396759, 0.8518964648246765, 0.8562594652175903, 0.845949113368988, 0.8450884819030762, 0.8476423025131226, 0.839615523815155, 0.8362323045730591, 0.8346639275550842, 0.8353114724159241, 0.8320515155792236, 0.8362641334533691, 0.833477795124054, 0.8228937983512878, 0.831098735332489, 0.8256006836891174, 0.8204690217971802, 0.8235294222831726, 0.8169653415679932, 0.8129456639289856, 0.8149722218513489, 0.8113232851028442, 0.8129144310951233, 0.8078022003173828, 0.8057664632797241, 0.8056173324584961, 0.8196134567260742, 0.8013126254081726, 0.8040301203727722, 0.7996810078620911, 0.7952625751495361, 0.7971476912498474, 0.7882310152053833, 0.7947608828544617, 0.785891592502594, 0.7905486822128296, 0.7955718636512756, 0.7857295870780945, 0.7816267609596252, 0.7837704420089722, 0.7798676490783691, 0.7771626114845276, 0.7736425995826721, 0.770310640335083, 0.7706730365753174, 0.775126039981842, 0.7707645297050476, 0.7689533233642578, 0.7675049901008606, 0.7690640687942505, 0.7612522840499878, 0.7643895149230957, 0.7602769136428833, 0.7648921608924866, 0.7535552978515625, 0.7645685076713562, 0.7720717787742615, 0.7608345746994019, 0.7487911581993103, 0.7459991574287415, 0.7518912553787231, 0.7606981992721558, 0.7475699186325073, 0.7439755201339722, 0.743574321269989, 0.7400093674659729, 0.7408627867698669, 0.7332137823104858, 0.7422533631324768, 0.7323046326637268, 0.7367515563964844, 0.7412204146385193, 0.7252193689346313, 0.7216930985450745, 0.7295293807983398, 0.7219651341438293, 0.7171859741210938, 0.7354944348335266, 0.7219489812850952, 0.7145525813102722, 0.7280883193016052, 0.7150856256484985, 0.7184627056121826, 0.7148506045341492, 0.7276668548583984, 0.7285333275794983, 0.7160042524337769, 0.7039961218833923, 0.7044730186462402, 0.7042333483695984, 0.7065517902374268, 0.713507890701294, 0.6943363547325134, 0.6973050236701965], 'accuracy': [0.7263723611831665, 0.7289190888404846, 0.7402377128601074, 0.7340124249458313, 0.7396717667579651, 0.7368420958518982, 0.7385398745536804, 0.7393888235092163, 0.7348613739013672, 0.7467458844184875, 0.7433503270149231, 0.7399547100067139, 0.7450481057167053, 0.7450481057167053, 0.748160719871521, 0.7512733340263367, 0.7427843809127808, 0.7441992163658142, 0.7453310489654541, 0.7464629411697388, 0.7396717667579651, 0.751839280128479, 0.7507073879241943, 0.7458969950675964, 0.7458969950675964, 0.7577815651893616, 0.7552348375320435, 0.7577815651893616, 0.7473118305206299, 0.7558007836341858, 0.7572156190872192, 0.7507073879241943, 0.7439162135124207, 0.7572156190872192, 0.7535370588302612, 0.755517840385437, 0.7546689510345459, 0.764855682849884, 0.7594793438911438, 0.7586304545402527, 0.7600452899932861, 0.7634408473968506, 0.7512733340263367, 0.7662705183029175, 0.7665534615516663, 0.7637238502502441, 0.7600452899932861, 0.764855682849884, 0.7705150246620178, 0.7668364644050598, 0.7713639140129089, 0.7713639140129089, 0.7764572501182556, 0.7668364644050598, 0.7713639140129089, 0.7640067934989929, 0.7795698642730713, 0.7722128033638, 0.7713639140129089, 0.764855682849884, 0.7744765281677246, 0.7676853537559509, 0.7617430686950684, 0.7730616927146912, 0.7784380316734314, 0.7883418202400208, 0.7744765281677246, 0.7659875750541687, 0.7744765281677246, 0.7849462628364563, 0.7790039777755737, 0.7815506458282471, 0.7835314273834229, 0.7804188132286072, 0.7792869210243225, 0.7832484245300293, 0.7736276388168335, 0.7710809111595154, 0.7889077663421631, 0.7906055450439453, 0.7883418202400208, 0.7894737124443054, 0.786361038684845, 0.7809846997261047, 0.7821165919303894, 0.788058876991272, 0.7832484245300293, 0.7911714911460876, 0.7931522130966187, 0.7911714911460876, 0.7812677025794983, 0.7764572501182556, 0.7945670485496521, 0.7942841053009033, 0.7988115549087524, 0.7894737124443054, 0.7982456088066101, 0.7903226017951965, 0.8019241690635681, 0.8016412258148193], 'val_loss': [1.0264235734939575, 1.0222413539886475, 1.0201674699783325, 1.0204322338104248, 1.0184855461120605, 1.0213732719421387, 1.0179812908172607, 1.0216147899627686, 1.0199024677276611, 1.0204046964645386, 1.023353934288025, 1.0037815570831299, 1.0003232955932617, 0.9827286601066589, 0.9834604263305664, 0.9777073860168457, 0.9584146738052368, 0.9112322330474854, 0.9235475063323975, 0.8933965563774109, 0.892191469669342, 0.8857578635215759, 0.8818105459213257, 0.9118350744247437, 0.8889790773391724, 0.8593592643737793, 0.8635493516921997, 0.8474946618080139, 0.8474222421646118, 0.872700572013855, 0.8453590273857117, 0.8834776282310486, 0.8492123484611511, 0.8487138748168945, 0.8533728122711182, 0.8404514193534851, 0.8437566161155701, 0.8402715921401978, 0.8537184596061707, 0.8362548351287842, 0.8375120759010315, 0.8848021626472473, 0.8466072082519531, 0.8482645153999329, 0.8355157971382141, 0.837419867515564, 0.8346120715141296, 0.837659478187561, 0.8442724347114563, 0.8371911644935608, 0.8400939106941223, 0.8580248951911926, 0.8324682116508484, 0.8311614990234375, 0.8469539284706116, 0.8325049877166748, 0.8507829904556274, 0.8390718102455139, 0.8293880820274353, 0.8307570219039917, 0.8326026797294617, 0.8558379411697388, 0.8330338001251221, 0.8340160250663757, 0.8275389075279236, 0.8690897822380066, 0.8280701637268066, 0.8227481245994568, 0.8250046968460083, 0.8320941925048828, 0.8272275328636169, 0.8265551328659058, 0.8310741186141968, 0.82145094871521, 0.8474916219711304, 0.8328600525856018, 0.8357235789299011, 0.8294434547424316, 0.8214069604873657, 0.826241672039032, 0.8416114449501038, 0.8250930309295654, 0.8259637355804443, 0.8250561356544495, 0.8241304159164429, 0.8315045833587646, 0.8238795399665833, 0.824910044670105, 0.8270905613899231, 0.8236023783683777, 0.8778768181800842, 0.8233141303062439, 0.823638916015625, 0.8257198929786682, 0.8281852602958679, 0.8249032497406006, 0.8235189914703369, 0.8218588829040527, 0.8341286778450012, 0.8281875252723694], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.5067873597145081, 0.5158371329307556, 0.5452488660812378, 0.5486425161361694, 0.5633484125137329, 0.6018099784851074, 0.6990950107574463, 0.6561086177825928, 0.7013574838638306, 0.7024886608123779, 0.7126696705818176, 0.7160633206367493, 0.6934388875961304, 0.7081447839736938, 0.7285068035125732, 0.7217194437980652, 0.7285068035125732, 0.7296379804611206, 0.7217194437980652, 0.7239819169044495, 0.7138009071350098, 0.7273755669593811, 0.7149321436882019, 0.7228506803512573, 0.720588207244873, 0.720588207244873, 0.7273755669593811, 0.7251130938529968, 0.7239819169044495, 0.7239819169044495, 0.6696832776069641, 0.7217194437980652, 0.7217194437980652, 0.7251130938529968, 0.7217194437980652, 0.720588207244873, 0.720588207244873, 0.7296379804611206, 0.7251130938529968, 0.7070135474205017, 0.720588207244873, 0.7126696705818176, 0.7194570302963257, 0.7013574838638306, 0.7149321436882019, 0.7194570302963257, 0.7036198973655701, 0.7160633206367493, 0.709276020526886, 0.709276020526886, 0.726244330406189, 0.7036198973655701, 0.726244330406189, 0.7171945571899414, 0.6640271544456482, 0.709276020526886, 0.7251130938529968, 0.7194570302963257, 0.6979637742042542, 0.7239819169044495, 0.7126696705818176, 0.6957013607025146, 0.7217194437980652, 0.7285068035125732, 0.7239819169044495, 0.6945701241493225, 0.7036198973655701, 0.7183257937431335, 0.7239819169044495, 0.7285068035125732, 0.7104072570800781, 0.7228506803512573, 0.709276020526886, 0.720588207244873, 0.7296379804611206, 0.720588207244873, 0.7160633206367493, 0.7024886608123779, 0.7047511339187622, 0.6606335043907166, 0.7104072570800781, 0.7149321436882019, 0.7115384340286255, 0.709276020526886, 0.7138009071350098, 0.7058823704719543, 0.7149321436882019, 0.6957013607025146, 0.6979637742042542]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.8706 - accuracy: 0.7244"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 63ms/step - loss: 0.8708 - accuracy: 0.7235 - val_loss: 1.0304 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8661 - accuracy: 0.7339 - val_loss: 1.0296 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8574 - accuracy: 0.7362 - val_loss: 1.0237 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8567 - accuracy: 0.7411 - val_loss: 1.0306 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8509 - accuracy: 0.7367 - val_loss: 1.0299 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8514 - accuracy: 0.7362 - val_loss: 1.0351 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8484 - accuracy: 0.7364 - val_loss: 1.0306 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8432 - accuracy: 0.7406 - val_loss: 1.0444 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8379 - accuracy: 0.7434 - val_loss: 1.0457 - val_accuracy: 0.4855\n","Epoch 10/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8396 - accuracy: 0.7452 - val_loss: 1.0275 - val_accuracy: 0.4866\n","Epoch 11/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8406 - accuracy: 0.7413 - val_loss: 1.0348 - val_accuracy: 0.4876\n","Epoch 12/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8297 - accuracy: 0.7525 - val_loss: 1.0324 - val_accuracy: 0.4886\n","Epoch 13/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8286 - accuracy: 0.7481 - val_loss: 1.0348 - val_accuracy: 0.4886\n","Epoch 14/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8284 - accuracy: 0.7455 - val_loss: 1.0384 - val_accuracy: 0.4938\n","Epoch 15/100\n","31/31 [==============================] - 1s 42ms/step - loss: 0.8243 - accuracy: 0.7475 - val_loss: 1.0045 - val_accuracy: 0.5248\n","Epoch 16/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.8228 - accuracy: 0.7455 - val_loss: 0.9817 - val_accuracy: 0.5713\n","Epoch 17/100\n","31/31 [==============================] - 1s 35ms/step - loss: 0.8195 - accuracy: 0.7455 - val_loss: 0.9326 - val_accuracy: 0.6508\n","Epoch 18/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.8200 - accuracy: 0.7496 - val_loss: 0.9138 - val_accuracy: 0.6643\n","Epoch 19/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8178 - accuracy: 0.7512 - val_loss: 0.9081 - val_accuracy: 0.6684\n","Epoch 20/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8168 - accuracy: 0.7452 - val_loss: 0.8978 - val_accuracy: 0.6870\n","Epoch 21/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.8183 - accuracy: 0.7463 - val_loss: 0.8893 - val_accuracy: 0.6932\n","Epoch 22/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8096 - accuracy: 0.7478 - val_loss: 0.8948 - val_accuracy: 0.6932\n","Epoch 23/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8102 - accuracy: 0.7545 - val_loss: 0.8744 - val_accuracy: 0.7004\n","Epoch 24/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.8106 - accuracy: 0.7519 - val_loss: 0.8982 - val_accuracy: 0.7056\n","Epoch 25/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8065 - accuracy: 0.7571 - val_loss: 0.8670 - val_accuracy: 0.7045\n","Epoch 26/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8053 - accuracy: 0.7517 - val_loss: 0.8713 - val_accuracy: 0.7025\n","Epoch 27/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8028 - accuracy: 0.7587 - val_loss: 0.8929 - val_accuracy: 0.7097\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8137 - accuracy: 0.7519 - val_loss: 0.8638 - val_accuracy: 0.6994\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8066 - accuracy: 0.7501 - val_loss: 0.8613 - val_accuracy: 0.7035\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7928 - accuracy: 0.7597 - val_loss: 0.8655 - val_accuracy: 0.7056\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7964 - accuracy: 0.7530 - val_loss: 0.8576 - val_accuracy: 0.7056\n","Epoch 32/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7911 - accuracy: 0.7643 - val_loss: 0.8584 - val_accuracy: 0.6994\n","Epoch 33/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7899 - accuracy: 0.7587 - val_loss: 0.8710 - val_accuracy: 0.7097\n","Epoch 34/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7933 - accuracy: 0.7561 - val_loss: 0.8527 - val_accuracy: 0.7076\n","Epoch 35/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7846 - accuracy: 0.7584 - val_loss: 0.8552 - val_accuracy: 0.7087\n","Epoch 36/100\n","31/31 [==============================] - 1s 38ms/step - loss: 0.7831 - accuracy: 0.7633 - val_loss: 0.8511 - val_accuracy: 0.7128\n","Epoch 37/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7828 - accuracy: 0.7615 - val_loss: 0.8743 - val_accuracy: 0.6839\n","Epoch 38/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7903 - accuracy: 0.7501 - val_loss: 0.8506 - val_accuracy: 0.7097\n","Epoch 39/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7804 - accuracy: 0.7597 - val_loss: 0.8633 - val_accuracy: 0.6890\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7799 - accuracy: 0.7643 - val_loss: 0.8500 - val_accuracy: 0.7076\n","Epoch 41/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.7746 - accuracy: 0.7656 - val_loss: 0.8481 - val_accuracy: 0.7149\n","Epoch 42/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7744 - accuracy: 0.7674 - val_loss: 0.8548 - val_accuracy: 0.7107\n","Epoch 43/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7813 - accuracy: 0.7558 - val_loss: 0.8448 - val_accuracy: 0.7180\n","Epoch 44/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7746 - accuracy: 0.7698 - val_loss: 0.8478 - val_accuracy: 0.7087\n","Epoch 45/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7699 - accuracy: 0.7674 - val_loss: 0.8562 - val_accuracy: 0.7087\n","Epoch 46/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7805 - accuracy: 0.7615 - val_loss: 0.8466 - val_accuracy: 0.7097\n","Epoch 47/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7699 - accuracy: 0.7698 - val_loss: 0.8472 - val_accuracy: 0.7118\n","Epoch 48/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7649 - accuracy: 0.7661 - val_loss: 0.8623 - val_accuracy: 0.6880\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7666 - accuracy: 0.7674 - val_loss: 0.8447 - val_accuracy: 0.7149\n","Epoch 50/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7654 - accuracy: 0.7695 - val_loss: 0.8413 - val_accuracy: 0.7149\n","Epoch 51/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7612 - accuracy: 0.7705 - val_loss: 0.8720 - val_accuracy: 0.6694\n","Epoch 52/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7664 - accuracy: 0.7687 - val_loss: 0.8433 - val_accuracy: 0.7118\n","Epoch 53/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7557 - accuracy: 0.7747 - val_loss: 0.8391 - val_accuracy: 0.7118\n","Epoch 54/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7529 - accuracy: 0.7708 - val_loss: 0.8398 - val_accuracy: 0.7159\n","Epoch 55/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7524 - accuracy: 0.7724 - val_loss: 0.8444 - val_accuracy: 0.7159\n","Epoch 56/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7476 - accuracy: 0.7729 - val_loss: 0.8402 - val_accuracy: 0.7159\n","Epoch 57/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.7523 - accuracy: 0.7744 - val_loss: 0.8520 - val_accuracy: 0.7200\n","Epoch 58/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7455 - accuracy: 0.7757 - val_loss: 0.8392 - val_accuracy: 0.7169\n","Epoch 59/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7511 - accuracy: 0.7762 - val_loss: 0.8348 - val_accuracy: 0.7211\n","Epoch 60/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7589 - accuracy: 0.7700 - val_loss: 0.8409 - val_accuracy: 0.7118\n","Epoch 61/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7472 - accuracy: 0.7762 - val_loss: 0.8419 - val_accuracy: 0.7014\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7470 - accuracy: 0.7760 - val_loss: 0.8341 - val_accuracy: 0.7200\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7463 - accuracy: 0.7729 - val_loss: 0.8321 - val_accuracy: 0.7180\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7442 - accuracy: 0.7752 - val_loss: 0.8311 - val_accuracy: 0.7169\n","Epoch 65/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7396 - accuracy: 0.7791 - val_loss: 0.8523 - val_accuracy: 0.6839\n","Epoch 66/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7388 - accuracy: 0.7765 - val_loss: 0.8644 - val_accuracy: 0.7169\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7522 - accuracy: 0.7674 - val_loss: 0.8365 - val_accuracy: 0.7169\n","Epoch 68/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7396 - accuracy: 0.7742 - val_loss: 0.8324 - val_accuracy: 0.7159\n","Epoch 69/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7414 - accuracy: 0.7734 - val_loss: 0.8323 - val_accuracy: 0.7149\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7351 - accuracy: 0.7760 - val_loss: 0.8671 - val_accuracy: 0.6612\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7356 - accuracy: 0.7791 - val_loss: 0.8330 - val_accuracy: 0.7066\n","Epoch 72/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.7317 - accuracy: 0.7796 - val_loss: 0.8282 - val_accuracy: 0.7252\n","Epoch 73/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7334 - accuracy: 0.7848 - val_loss: 0.8392 - val_accuracy: 0.7014\n","Epoch 74/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7363 - accuracy: 0.7711 - val_loss: 0.8347 - val_accuracy: 0.7097\n","Epoch 75/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7316 - accuracy: 0.7770 - val_loss: 0.8245 - val_accuracy: 0.7231\n","Epoch 76/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7255 - accuracy: 0.7889 - val_loss: 0.8469 - val_accuracy: 0.6890\n","Epoch 77/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7264 - accuracy: 0.7879 - val_loss: 0.8288 - val_accuracy: 0.7128\n","Epoch 78/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7209 - accuracy: 0.7894 - val_loss: 0.8297 - val_accuracy: 0.7159\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7295 - accuracy: 0.7827 - val_loss: 0.8815 - val_accuracy: 0.7138\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7479 - accuracy: 0.7628 - val_loss: 0.8412 - val_accuracy: 0.7169\n","Epoch 81/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7234 - accuracy: 0.7770 - val_loss: 0.8344 - val_accuracy: 0.7221\n","Epoch 82/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7285 - accuracy: 0.7822 - val_loss: 0.8330 - val_accuracy: 0.7076\n","Epoch 83/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7113 - accuracy: 0.7879 - val_loss: 0.8262 - val_accuracy: 0.7180\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7104 - accuracy: 0.7863 - val_loss: 0.8275 - val_accuracy: 0.7190\n","Epoch 85/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7082 - accuracy: 0.7928 - val_loss: 0.8272 - val_accuracy: 0.7293\n","Epoch 86/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7258 - accuracy: 0.7765 - val_loss: 0.8360 - val_accuracy: 0.7283\n","Epoch 87/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7133 - accuracy: 0.7912 - val_loss: 0.8369 - val_accuracy: 0.7262\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7095 - accuracy: 0.7925 - val_loss: 0.8868 - val_accuracy: 0.7107\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7259 - accuracy: 0.7695 - val_loss: 0.8366 - val_accuracy: 0.7180\n","Epoch 90/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7056 - accuracy: 0.7938 - val_loss: 0.8330 - val_accuracy: 0.7211\n","Epoch 91/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7114 - accuracy: 0.7884 - val_loss: 0.8577 - val_accuracy: 0.7169\n","Epoch 92/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7106 - accuracy: 0.7809 - val_loss: 0.8230 - val_accuracy: 0.7149\n","Epoch 93/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7021 - accuracy: 0.7964 - val_loss: 0.8299 - val_accuracy: 0.7076\n","Epoch 94/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7029 - accuracy: 0.7902 - val_loss: 0.8372 - val_accuracy: 0.7242\n","Epoch 95/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7225 - accuracy: 0.7798 - val_loss: 0.8320 - val_accuracy: 0.7252\n","Epoch 96/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6987 - accuracy: 0.7915 - val_loss: 0.8393 - val_accuracy: 0.7190\n","Epoch 97/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6973 - accuracy: 0.7953 - val_loss: 0.8221 - val_accuracy: 0.7221\n","Epoch 98/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6953 - accuracy: 0.7933 - val_loss: 0.8257 - val_accuracy: 0.7200\n","Epoch 99/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.7038 - accuracy: 0.7902 - val_loss: 0.8289 - val_accuracy: 0.7056\n","Epoch 100/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6947 - accuracy: 0.7966 - val_loss: 0.8282 - val_accuracy: 0.7169\n","{'loss': [0.8707996606826782, 0.8661462068557739, 0.8574365973472595, 0.8567025065422058, 0.8509455919265747, 0.8514212965965271, 0.8484449982643127, 0.8432077169418335, 0.837898313999176, 0.839579701423645, 0.8405905365943909, 0.8296754360198975, 0.8285871148109436, 0.8283941149711609, 0.8243101835250854, 0.8227863311767578, 0.8195154070854187, 0.8199759125709534, 0.8177838921546936, 0.8168472647666931, 0.8182942271232605, 0.8096466660499573, 0.8101745843887329, 0.8106326460838318, 0.8065053820610046, 0.805321216583252, 0.8027589917182922, 0.8137155771255493, 0.8066310286521912, 0.7928115129470825, 0.7964312434196472, 0.7911340594291687, 0.7899008393287659, 0.7933103442192078, 0.7845551371574402, 0.7831055521965027, 0.782799243927002, 0.7902544140815735, 0.7803810834884644, 0.7798636555671692, 0.774564802646637, 0.7744275331497192, 0.7812782526016235, 0.774645209312439, 0.7699424624443054, 0.7804834842681885, 0.7698684334754944, 0.7649138569831848, 0.766602635383606, 0.7654277682304382, 0.7612130641937256, 0.7663555145263672, 0.7556953430175781, 0.7528507113456726, 0.7523890733718872, 0.7475744485855103, 0.7522664666175842, 0.7454697489738464, 0.7511081099510193, 0.7588894963264465, 0.7471978068351746, 0.747006893157959, 0.746328592300415, 0.744204044342041, 0.73955237865448, 0.7387698292732239, 0.7522222995758057, 0.7395718097686768, 0.7413516044616699, 0.7351228594779968, 0.7356034517288208, 0.7316696643829346, 0.733399510383606, 0.7363125085830688, 0.7316157817840576, 0.7255040407180786, 0.7264362573623657, 0.7209014296531677, 0.7295027375221252, 0.7479109764099121, 0.7234483957290649, 0.728537380695343, 0.7113268971443176, 0.7103909254074097, 0.7081735134124756, 0.7257587313652039, 0.7133358716964722, 0.7094993591308594, 0.7259218692779541, 0.7056206464767456, 0.7113711833953857, 0.7105500102043152, 0.7020857930183411, 0.7028670907020569, 0.7224574089050293, 0.6987127065658569, 0.6973315477371216, 0.6953040957450867, 0.7038418650627136, 0.6947481036186218], 'accuracy': [0.723514199256897, 0.7338501214981079, 0.7361757159233093, 0.7410852909088135, 0.736692488193512, 0.7361757159233093, 0.7364341020584106, 0.7405684590339661, 0.7434108257293701, 0.7452196478843689, 0.7413436770439148, 0.7524547576904297, 0.748062014579773, 0.7454780340194702, 0.7475452423095703, 0.7454780340194702, 0.7454780340194702, 0.7496123909950256, 0.7511627674102783, 0.7452196478843689, 0.746253252029419, 0.7478036284446716, 0.7545219659805298, 0.751937985420227, 0.7571059465408325, 0.7516795992851257, 0.7586563229560852, 0.751937985420227, 0.750129222869873, 0.7596899271011353, 0.7529715895652771, 0.7643410563468933, 0.7586563229560852, 0.7560723423957825, 0.7583979368209839, 0.763307511806488, 0.7614986896514893, 0.750129222869873, 0.7596899271011353, 0.7643410563468933, 0.7656330466270447, 0.7674418687820435, 0.7558139562606812, 0.7697674632072449, 0.7674418687820435, 0.7614986896514893, 0.7697674632072449, 0.7661498785018921, 0.7674418687820435, 0.7695090174674988, 0.7705426216125488, 0.7687338590621948, 0.7746769785881042, 0.7708010077476501, 0.7723514437675476, 0.7728682160377502, 0.7744185924530029, 0.7757105827331543, 0.7762274146080017, 0.7700258493423462, 0.7762274146080017, 0.7759689688682556, 0.7728682160377502, 0.7751938104629517, 0.7790697813034058, 0.776485800743103, 0.7674418687820435, 0.7741602063179016, 0.7733849883079529, 0.7759689688682556, 0.7790697813034058, 0.7795865535736084, 0.7847545146942139, 0.7710594534873962, 0.7770025730133057, 0.7888888716697693, 0.7878552675247192, 0.7894057035446167, 0.7826873660087585, 0.7627906799316406, 0.7770025730133057, 0.7821705341339111, 0.7878552675247192, 0.7863048911094666, 0.7927648425102234, 0.776485800743103, 0.7912144660949707, 0.7925064563751221, 0.7695090174674988, 0.7937984466552734, 0.7883720993995667, 0.7808785438537598, 0.7963824272155762, 0.7901808619499207, 0.7798449397087097, 0.791472852230072, 0.7953488230705261, 0.7932816743850708, 0.7901808619499207, 0.7966408133506775], 'val_loss': [1.030409336090088, 1.0295616388320923, 1.0237233638763428, 1.030623435974121, 1.0298852920532227, 1.0350520610809326, 1.0305532217025757, 1.0444183349609375, 1.045685887336731, 1.02749502658844, 1.0348243713378906, 1.0323684215545654, 1.0347539186477661, 1.038350224494934, 1.0044865608215332, 0.9817026257514954, 0.9326435327529907, 0.9137567281723022, 0.9081448912620544, 0.897813618183136, 0.88930743932724, 0.8948103189468384, 0.874417245388031, 0.8981907367706299, 0.8670165538787842, 0.8712645173072815, 0.8929324746131897, 0.8637832403182983, 0.8612996935844421, 0.8655079007148743, 0.8576175570487976, 0.8583939075469971, 0.8710209727287292, 0.8526588678359985, 0.855178713798523, 0.8510971069335938, 0.8743210434913635, 0.8506165146827698, 0.8632843494415283, 0.8499566316604614, 0.8481259942054749, 0.8547984957695007, 0.8447808027267456, 0.8478071093559265, 0.8561657071113586, 0.8465532064437866, 0.8472146391868591, 0.8623445630073547, 0.8446999788284302, 0.8412527441978455, 0.8719750046730042, 0.8432937264442444, 0.8391428589820862, 0.8398362994194031, 0.8444194197654724, 0.8402428030967712, 0.8520345687866211, 0.8391808867454529, 0.8347550630569458, 0.8409247994422913, 0.8418765664100647, 0.8340880274772644, 0.8320789337158203, 0.8311018347740173, 0.8522558212280273, 0.8644073605537415, 0.836538553237915, 0.8324341177940369, 0.8323197960853577, 0.8670835494995117, 0.8330374360084534, 0.8281667232513428, 0.839174747467041, 0.834654688835144, 0.8244920372962952, 0.8468875288963318, 0.8287515044212341, 0.8296616673469543, 0.8815099000930786, 0.8411582708358765, 0.8343847393989563, 0.8329768180847168, 0.8261973261833191, 0.8275451064109802, 0.8272178769111633, 0.8360411524772644, 0.8368860483169556, 0.8867548108100891, 0.8365576863288879, 0.8330283164978027, 0.8576624989509583, 0.8229533433914185, 0.8298704028129578, 0.8372214436531067, 0.8320016264915466, 0.8393489122390747, 0.8220586776733398, 0.8256621956825256, 0.8288896679878235, 0.8282320499420166], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.4876033067703247, 0.4886363744735718, 0.4886363744735718, 0.49380165338516235, 0.5247933864593506, 0.5712810158729553, 0.6508264541625977, 0.66425621509552, 0.6683884263038635, 0.6869834661483765, 0.6931818127632141, 0.6931818127632141, 0.7004132270812988, 0.7055785059928894, 0.7045454382896423, 0.702479362487793, 0.7097107172012329, 0.6993801593780518, 0.7035123705863953, 0.7055785059928894, 0.7055785059928894, 0.6993801593780518, 0.7097107172012329, 0.7076446413993835, 0.7086777091026306, 0.7128099203109741, 0.68388432264328, 0.7097107172012329, 0.6890496015548706, 0.7076446413993835, 0.7148760557174683, 0.71074378490448, 0.7179751992225647, 0.7086777091026306, 0.7086777091026306, 0.7097107172012329, 0.711776852607727, 0.6880165338516235, 0.7148760557174683, 0.7148760557174683, 0.6694214940071106, 0.711776852607727, 0.711776852607727, 0.7159090638160706, 0.7159090638160706, 0.7159090638160706, 0.7200413346290588, 0.7169421315193176, 0.7210744023323059, 0.711776852607727, 0.7014462947845459, 0.7200413346290588, 0.7179751992225647, 0.7169421315193176, 0.68388432264328, 0.7169421315193176, 0.7169421315193176, 0.7159090638160706, 0.7148760557174683, 0.6611570119857788, 0.7066115736961365, 0.7252066135406494, 0.7014462947845459, 0.7097107172012329, 0.7231404781341553, 0.6890496015548706, 0.7128099203109741, 0.7159090638160706, 0.7138429880142212, 0.7169421315193176, 0.7221074104309082, 0.7076446413993835, 0.7179751992225647, 0.7190082669258118, 0.7293388247489929, 0.7283057570457458, 0.7262396812438965, 0.71074378490448, 0.7179751992225647, 0.7210744023323059, 0.7169421315193176, 0.7148760557174683, 0.7076446413993835, 0.7241735458374023, 0.7252066135406494, 0.7190082669258118, 0.7221074104309082, 0.7200413346290588, 0.7055785059928894, 0.7169421315193176]}\n","32/32 [==============================] - 1s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.7421 - accuracy: 0.7667"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 68ms/step - loss: 0.7446 - accuracy: 0.7664 - val_loss: 0.9624 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7399 - accuracy: 0.7648 - val_loss: 0.9595 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7385 - accuracy: 0.7629 - val_loss: 0.9672 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7215 - accuracy: 0.7759 - val_loss: 0.9706 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7364 - accuracy: 0.7705 - val_loss: 0.9786 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7257 - accuracy: 0.7721 - val_loss: 0.9810 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7305 - accuracy: 0.7697 - val_loss: 0.9923 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7253 - accuracy: 0.7654 - val_loss: 1.0074 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7215 - accuracy: 0.7796 - val_loss: 1.0205 - val_accuracy: 0.4849\n","Epoch 10/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7150 - accuracy: 0.7850 - val_loss: 1.0229 - val_accuracy: 0.4849\n","Epoch 11/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7088 - accuracy: 0.7880 - val_loss: 1.0527 - val_accuracy: 0.4849\n","Epoch 12/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7118 - accuracy: 0.7802 - val_loss: 1.0743 - val_accuracy: 0.4849\n","Epoch 13/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7095 - accuracy: 0.7804 - val_loss: 1.0607 - val_accuracy: 0.4849\n","Epoch 14/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.7147 - accuracy: 0.7724 - val_loss: 1.0328 - val_accuracy: 0.4903\n","Epoch 15/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.7168 - accuracy: 0.7767 - val_loss: 1.1066 - val_accuracy: 0.4914\n","Epoch 16/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.7105 - accuracy: 0.7823 - val_loss: 1.0076 - val_accuracy: 0.5269\n","Epoch 17/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.7060 - accuracy: 0.7823 - val_loss: 0.9094 - val_accuracy: 0.6056\n","Epoch 18/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7076 - accuracy: 0.7858 - val_loss: 0.9520 - val_accuracy: 0.5765\n","Epoch 19/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.7136 - accuracy: 0.7786 - val_loss: 0.8929 - val_accuracy: 0.6379\n","Epoch 20/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.7041 - accuracy: 0.7856 - val_loss: 0.8296 - val_accuracy: 0.7091\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7078 - accuracy: 0.7810 - val_loss: 0.8357 - val_accuracy: 0.6929\n","Epoch 22/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.6974 - accuracy: 0.7939 - val_loss: 0.8052 - val_accuracy: 0.7328\n","Epoch 23/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.7000 - accuracy: 0.7845 - val_loss: 0.8117 - val_accuracy: 0.7371\n","Epoch 24/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7034 - accuracy: 0.7858 - val_loss: 0.8279 - val_accuracy: 0.7349\n","Epoch 25/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.6881 - accuracy: 0.8001 - val_loss: 0.7879 - val_accuracy: 0.7575\n","Epoch 26/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.7047 - accuracy: 0.7848 - val_loss: 0.7737 - val_accuracy: 0.7597\n","Epoch 27/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7001 - accuracy: 0.7864 - val_loss: 0.7664 - val_accuracy: 0.7575\n","Epoch 28/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6939 - accuracy: 0.7977 - val_loss: 0.7661 - val_accuracy: 0.7651\n","Epoch 29/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6905 - accuracy: 0.7901 - val_loss: 0.7661 - val_accuracy: 0.7543\n","Epoch 30/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6919 - accuracy: 0.7874 - val_loss: 0.7623 - val_accuracy: 0.7662\n","Epoch 31/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6884 - accuracy: 0.7901 - val_loss: 0.7747 - val_accuracy: 0.7457\n","Epoch 32/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6868 - accuracy: 0.7974 - val_loss: 0.7603 - val_accuracy: 0.7619\n","Epoch 33/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6834 - accuracy: 0.7958 - val_loss: 0.7870 - val_accuracy: 0.7457\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6830 - accuracy: 0.7996 - val_loss: 0.7648 - val_accuracy: 0.7651\n","Epoch 35/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6793 - accuracy: 0.8004 - val_loss: 0.7646 - val_accuracy: 0.7608\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6883 - accuracy: 0.7966 - val_loss: 0.7588 - val_accuracy: 0.7651\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6804 - accuracy: 0.7931 - val_loss: 0.7641 - val_accuracy: 0.7629\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6822 - accuracy: 0.7885 - val_loss: 0.7759 - val_accuracy: 0.7511\n","Epoch 39/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6762 - accuracy: 0.8025 - val_loss: 0.7631 - val_accuracy: 0.7705\n","Epoch 40/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6739 - accuracy: 0.8050 - val_loss: 0.7811 - val_accuracy: 0.7414\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6859 - accuracy: 0.7877 - val_loss: 0.7744 - val_accuracy: 0.7500\n","Epoch 42/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6761 - accuracy: 0.7998 - val_loss: 0.7644 - val_accuracy: 0.7619\n","Epoch 43/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6753 - accuracy: 0.8015 - val_loss: 0.7617 - val_accuracy: 0.7629\n","Epoch 44/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6748 - accuracy: 0.7958 - val_loss: 0.8057 - val_accuracy: 0.7284\n","Epoch 45/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6775 - accuracy: 0.7958 - val_loss: 0.7593 - val_accuracy: 0.7662\n","Epoch 46/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6619 - accuracy: 0.8112 - val_loss: 0.7639 - val_accuracy: 0.7575\n","Epoch 47/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6697 - accuracy: 0.8023 - val_loss: 0.7862 - val_accuracy: 0.7425\n","Epoch 48/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6859 - accuracy: 0.7920 - val_loss: 0.7588 - val_accuracy: 0.7683\n","Epoch 49/100\n","29/29 [==============================] - 1s 35ms/step - loss: 0.6644 - accuracy: 0.8079 - val_loss: 0.7615 - val_accuracy: 0.7716\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6644 - accuracy: 0.8036 - val_loss: 0.7633 - val_accuracy: 0.7672\n","Epoch 51/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6606 - accuracy: 0.8106 - val_loss: 0.7619 - val_accuracy: 0.7608\n","Epoch 52/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6593 - accuracy: 0.8125 - val_loss: 0.7653 - val_accuracy: 0.7619\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6564 - accuracy: 0.8155 - val_loss: 0.8026 - val_accuracy: 0.7274\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6585 - accuracy: 0.8012 - val_loss: 0.7647 - val_accuracy: 0.7554\n","Epoch 55/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6672 - accuracy: 0.8079 - val_loss: 0.7679 - val_accuracy: 0.7629\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6509 - accuracy: 0.8079 - val_loss: 0.7709 - val_accuracy: 0.7608\n","Epoch 57/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6563 - accuracy: 0.8095 - val_loss: 0.8256 - val_accuracy: 0.7209\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6607 - accuracy: 0.8055 - val_loss: 0.7717 - val_accuracy: 0.7554\n","Epoch 59/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6606 - accuracy: 0.8001 - val_loss: 0.7630 - val_accuracy: 0.7694\n","Epoch 60/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6538 - accuracy: 0.8101 - val_loss: 0.7853 - val_accuracy: 0.7381\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6514 - accuracy: 0.8101 - val_loss: 0.7713 - val_accuracy: 0.7608\n","Epoch 62/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6438 - accuracy: 0.8117 - val_loss: 0.7662 - val_accuracy: 0.7640\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6488 - accuracy: 0.8093 - val_loss: 0.7676 - val_accuracy: 0.7651\n","Epoch 64/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6416 - accuracy: 0.8112 - val_loss: 0.7863 - val_accuracy: 0.7414\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6457 - accuracy: 0.8085 - val_loss: 0.7624 - val_accuracy: 0.7662\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6398 - accuracy: 0.8106 - val_loss: 0.7668 - val_accuracy: 0.7629\n","Epoch 67/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6390 - accuracy: 0.8173 - val_loss: 0.7688 - val_accuracy: 0.7629\n","Epoch 68/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6320 - accuracy: 0.8200 - val_loss: 0.7717 - val_accuracy: 0.7619\n","Epoch 69/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6475 - accuracy: 0.8144 - val_loss: 0.7683 - val_accuracy: 0.7565\n","Epoch 70/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6418 - accuracy: 0.8173 - val_loss: 0.7711 - val_accuracy: 0.7629\n","Epoch 71/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6398 - accuracy: 0.8112 - val_loss: 0.7663 - val_accuracy: 0.7608\n","Epoch 72/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6441 - accuracy: 0.8138 - val_loss: 0.7809 - val_accuracy: 0.7468\n","Epoch 73/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6340 - accuracy: 0.8230 - val_loss: 0.8052 - val_accuracy: 0.7263\n","Epoch 74/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6312 - accuracy: 0.8270 - val_loss: 0.7954 - val_accuracy: 0.7349\n","Epoch 75/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6307 - accuracy: 0.8147 - val_loss: 0.7867 - val_accuracy: 0.7457\n","Epoch 76/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6292 - accuracy: 0.8182 - val_loss: 0.7975 - val_accuracy: 0.7317\n","Epoch 77/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6324 - accuracy: 0.8190 - val_loss: 0.7908 - val_accuracy: 0.7425\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6324 - accuracy: 0.8141 - val_loss: 0.7691 - val_accuracy: 0.7543\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6253 - accuracy: 0.8295 - val_loss: 0.7646 - val_accuracy: 0.7683\n","Epoch 80/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6244 - accuracy: 0.8209 - val_loss: 0.7900 - val_accuracy: 0.7457\n","Epoch 81/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6288 - accuracy: 0.8192 - val_loss: 0.7631 - val_accuracy: 0.7662\n","Epoch 82/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6363 - accuracy: 0.8112 - val_loss: 0.7654 - val_accuracy: 0.7554\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6148 - accuracy: 0.8300 - val_loss: 0.7707 - val_accuracy: 0.7651\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6251 - accuracy: 0.8203 - val_loss: 0.7807 - val_accuracy: 0.7478\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6477 - accuracy: 0.8077 - val_loss: 0.7834 - val_accuracy: 0.7457\n","Epoch 86/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6240 - accuracy: 0.8292 - val_loss: 0.7697 - val_accuracy: 0.7565\n","Epoch 87/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6178 - accuracy: 0.8300 - val_loss: 0.7751 - val_accuracy: 0.7586\n","Epoch 88/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6117 - accuracy: 0.8314 - val_loss: 0.7689 - val_accuracy: 0.7575\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6077 - accuracy: 0.8289 - val_loss: 0.7743 - val_accuracy: 0.7554\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6119 - accuracy: 0.8270 - val_loss: 0.7802 - val_accuracy: 0.7457\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6072 - accuracy: 0.8359 - val_loss: 0.7878 - val_accuracy: 0.7381\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6065 - accuracy: 0.8265 - val_loss: 0.7818 - val_accuracy: 0.7392\n","Epoch 93/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6107 - accuracy: 0.8351 - val_loss: 0.7842 - val_accuracy: 0.7478\n","Epoch 94/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6438 - accuracy: 0.8058 - val_loss: 0.7696 - val_accuracy: 0.7662\n","Epoch 95/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6111 - accuracy: 0.8300 - val_loss: 0.7684 - val_accuracy: 0.7522\n","Epoch 96/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6239 - accuracy: 0.8209 - val_loss: 0.7808 - val_accuracy: 0.7511\n","Epoch 97/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6212 - accuracy: 0.8214 - val_loss: 0.7741 - val_accuracy: 0.7554\n","Epoch 98/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5964 - accuracy: 0.8378 - val_loss: 0.7749 - val_accuracy: 0.7478\n","Epoch 99/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5992 - accuracy: 0.8343 - val_loss: 0.7702 - val_accuracy: 0.7522\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5909 - accuracy: 0.8408 - val_loss: 0.7816 - val_accuracy: 0.7554\n","{'loss': [0.7446431517601013, 0.7399152517318726, 0.7385334968566895, 0.7215317487716675, 0.7364168763160706, 0.7256608009338379, 0.7304508090019226, 0.7253130078315735, 0.7214542031288147, 0.7150222659111023, 0.7088335156440735, 0.7118400931358337, 0.7094884514808655, 0.7146637439727783, 0.7168462872505188, 0.7105271816253662, 0.706034779548645, 0.7075914144515991, 0.7135658860206604, 0.7041353583335876, 0.7077723145484924, 0.6973584890365601, 0.7000207304954529, 0.7033636569976807, 0.6880845427513123, 0.70465087890625, 0.7000575065612793, 0.6939288973808289, 0.6905398368835449, 0.6919346451759338, 0.6884304285049438, 0.6868039965629578, 0.683363676071167, 0.6830216646194458, 0.679341733455658, 0.6883248686790466, 0.6803852319717407, 0.6822037100791931, 0.6762458682060242, 0.6739000082015991, 0.6859244704246521, 0.6760727167129517, 0.6752834916114807, 0.6748082637786865, 0.6774612069129944, 0.661949634552002, 0.6697490215301514, 0.6859431266784668, 0.6644400358200073, 0.664371907711029, 0.6606367230415344, 0.6593330502510071, 0.6564145088195801, 0.6584917306900024, 0.6671631932258606, 0.6509361863136292, 0.6563234925270081, 0.660702645778656, 0.6606451272964478, 0.6538158655166626, 0.6514016389846802, 0.643833577632904, 0.648758590221405, 0.6415812969207764, 0.6456940174102783, 0.6397718787193298, 0.6390131115913391, 0.6320419907569885, 0.6474931240081787, 0.6417580246925354, 0.6398321986198425, 0.6441448330879211, 0.6340057253837585, 0.631206750869751, 0.6307219862937927, 0.6291536688804626, 0.6323502659797668, 0.6323910355567932, 0.6252791285514832, 0.6243970394134521, 0.6288297772407532, 0.6362798810005188, 0.6147674322128296, 0.625085175037384, 0.6477146148681641, 0.6239720582962036, 0.6178169250488281, 0.6116732954978943, 0.6076990962028503, 0.6118850111961365, 0.6072361469268799, 0.6064594984054565, 0.6106509566307068, 0.6437636017799377, 0.6110542416572571, 0.6239497661590576, 0.6211775541305542, 0.5964289307594299, 0.5991551876068115, 0.5908673405647278], 'accuracy': [0.7664331793785095, 0.7648168206214905, 0.7629310488700867, 0.7758620977401733, 0.7704741358757019, 0.772090494632721, 0.7696659564971924, 0.7653555870056152, 0.779633641242981, 0.7850215435028076, 0.7879849076271057, 0.7801724076271057, 0.7804418206214905, 0.7723599076271057, 0.7766702771186829, 0.7823275923728943, 0.7823275923728943, 0.7858297228813171, 0.7785560488700867, 0.7855603694915771, 0.7809805870056152, 0.7939116358757019, 0.7844827771186829, 0.7858297228813171, 0.8001077771186829, 0.7847521305084229, 0.7863685488700867, 0.7976831793785095, 0.7901400923728943, 0.787446141242981, 0.7901400923728943, 0.7974137663841248, 0.7957974076271057, 0.7995689511299133, 0.8003771305084229, 0.7966055870056152, 0.7931034564971924, 0.7885237336158752, 0.8025323152542114, 0.8049569129943848, 0.787715494632721, 0.7998383641242981, 0.8014547228813171, 0.7957974076271057, 0.7957974076271057, 0.811152994632721, 0.8022629022598267, 0.7920258641242981, 0.8079202771186829, 0.8036099076271057, 0.8106142282485962, 0.8125, 0.8154633641242981, 0.8011853694915771, 0.8079202771186829, 0.8079202771186829, 0.8095366358757019, 0.8054956793785095, 0.8001077771186829, 0.8100754022598267, 0.8100754022598267, 0.8116918206214905, 0.8092672228813171, 0.811152994632721, 0.8084590435028076, 0.8106142282485962, 0.8173491358757019, 0.8200430870056152, 0.8143857717514038, 0.8173491358757019, 0.811152994632721, 0.813847005367279, 0.8230064511299133, 0.8270474076271057, 0.8146551847457886, 0.8181573152542114, 0.818965494632721, 0.814116358757019, 0.829472005367279, 0.8208512663841248, 0.8192349076271057, 0.811152994632721, 0.8300107717514038, 0.8203125, 0.8076508641242981, 0.8292025923728943, 0.8300107717514038, 0.8313577771186829, 0.8289331793785095, 0.8270474076271057, 0.8359375, 0.826508641242981, 0.8351293206214905, 0.8057650923728943, 0.8300107717514038, 0.8208512663841248, 0.8213900923728943, 0.8378232717514038, 0.834321141242981, 0.8407866358757019], 'val_loss': [0.9624031186103821, 0.9595139026641846, 0.9671566486358643, 0.9705822467803955, 0.9785760045051575, 0.9809581637382507, 0.9923310875892639, 1.0074135065078735, 1.0205280780792236, 1.0229424238204956, 1.0527193546295166, 1.074272632598877, 1.0607235431671143, 1.0328106880187988, 1.1065897941589355, 1.007646083831787, 0.9094087481498718, 0.9519668817520142, 0.8928686380386353, 0.8296459317207336, 0.835735559463501, 0.8052355647087097, 0.8117038607597351, 0.8279385566711426, 0.787940263748169, 0.773704469203949, 0.7663761377334595, 0.7661123871803284, 0.7660881280899048, 0.7622746229171753, 0.7747005820274353, 0.7603303790092468, 0.7870180606842041, 0.7648478150367737, 0.7646228075027466, 0.7587540149688721, 0.7641229033470154, 0.7758514285087585, 0.7630816102027893, 0.7811442017555237, 0.774384081363678, 0.7643750905990601, 0.7617440223693848, 0.8057001233100891, 0.7592586278915405, 0.7638906240463257, 0.7861906290054321, 0.758849561214447, 0.7614873051643372, 0.7633151412010193, 0.7618517875671387, 0.7652530074119568, 0.8025778532028198, 0.7647257447242737, 0.7679318785667419, 0.7709457278251648, 0.8255844712257385, 0.771685779094696, 0.7630198001861572, 0.7852658033370972, 0.7713290452957153, 0.7662001848220825, 0.7675760388374329, 0.786344587802887, 0.7624310851097107, 0.766811192035675, 0.7687804102897644, 0.7717228531837463, 0.7683324217796326, 0.7711220979690552, 0.7663083076477051, 0.7808760404586792, 0.805183470249176, 0.7954457402229309, 0.7867233157157898, 0.7975138425827026, 0.7907538414001465, 0.7691065073013306, 0.7646276354789734, 0.7900468111038208, 0.7630947232246399, 0.7653976678848267, 0.7707189917564392, 0.7806695699691772, 0.7833872437477112, 0.7696644067764282, 0.775129497051239, 0.7689011096954346, 0.7742998003959656, 0.7801856994628906, 0.7877509593963623, 0.7817531824111938, 0.7841989994049072, 0.7696192264556885, 0.7684346437454224, 0.780822217464447, 0.7740511298179626, 0.7749221920967102, 0.7702206373214722, 0.7815524935722351], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.4903017282485962, 0.4913793206214905, 0.5269396305084229, 0.6056034564971924, 0.576508641242981, 0.6379310488700867, 0.7090517282485962, 0.6928879022598267, 0.732758641242981, 0.7370689511299133, 0.7349137663841248, 0.7575430870056152, 0.7596982717514038, 0.7575430870056152, 0.7650862336158752, 0.7543103694915771, 0.7661637663841248, 0.7456896305084229, 0.7618534564971924, 0.7456896305084229, 0.7650862336158752, 0.7607758641242981, 0.7650862336158752, 0.7629310488700867, 0.7510775923728943, 0.7704741358757019, 0.7413793206214905, 0.75, 0.7618534564971924, 0.7629310488700867, 0.7284482717514038, 0.7661637663841248, 0.7575430870056152, 0.7424569129943848, 0.7683189511299133, 0.7715517282485962, 0.767241358757019, 0.7607758641242981, 0.7618534564971924, 0.7273706793785095, 0.7553879022598267, 0.7629310488700867, 0.7607758641242981, 0.7209051847457886, 0.7553879022598267, 0.7693965435028076, 0.7381465435028076, 0.7607758641242981, 0.764008641242981, 0.7650862336158752, 0.7413793206214905, 0.7661637663841248, 0.7629310488700867, 0.7629310488700867, 0.7618534564971924, 0.756465494632721, 0.7629310488700867, 0.7607758641242981, 0.7467672228813171, 0.7262930870056152, 0.7349137663841248, 0.7456896305084229, 0.7316810488700867, 0.7424569129943848, 0.7543103694915771, 0.7683189511299133, 0.7456896305084229, 0.7661637663841248, 0.7553879022598267, 0.7650862336158752, 0.7478448152542114, 0.7456896305084229, 0.756465494632721, 0.7586206793785095, 0.7575430870056152, 0.7553879022598267, 0.7456896305084229, 0.7381465435028076, 0.7392241358757019, 0.7478448152542114, 0.7661637663841248, 0.7521551847457886, 0.7510775923728943, 0.7553879022598267, 0.7478448152542114, 0.7521551847457886, 0.7553879022598267]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.7665 - accuracy: 0.7476"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 59ms/step - loss: 0.7692 - accuracy: 0.7467 - val_loss: 0.9538 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7409 - accuracy: 0.7725 - val_loss: 0.9545 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7297 - accuracy: 0.7779 - val_loss: 0.9585 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7292 - accuracy: 0.7784 - val_loss: 0.9606 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7249 - accuracy: 0.7835 - val_loss: 0.9670 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7247 - accuracy: 0.7816 - val_loss: 0.9721 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7224 - accuracy: 0.7824 - val_loss: 0.9766 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7228 - accuracy: 0.7824 - val_loss: 0.9719 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7209 - accuracy: 0.7864 - val_loss: 0.9915 - val_accuracy: 0.4955\n","Epoch 10/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7164 - accuracy: 0.7844 - val_loss: 1.0031 - val_accuracy: 0.4955\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7138 - accuracy: 0.7816 - val_loss: 0.9961 - val_accuracy: 0.4955\n","Epoch 12/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.7148 - accuracy: 0.7835 - val_loss: 1.0071 - val_accuracy: 0.4966\n","Epoch 13/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.7175 - accuracy: 0.7855 - val_loss: 1.0279 - val_accuracy: 0.4977\n","Epoch 14/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.7168 - accuracy: 0.7807 - val_loss: 0.9824 - val_accuracy: 0.5192\n","Epoch 15/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.7183 - accuracy: 0.7855 - val_loss: 0.9991 - val_accuracy: 0.5226\n","Epoch 16/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.7052 - accuracy: 0.7926 - val_loss: 0.9717 - val_accuracy: 0.5475\n","Epoch 17/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.7057 - accuracy: 0.7946 - val_loss: 0.8931 - val_accuracy: 0.6301\n","Epoch 18/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.7084 - accuracy: 0.7892 - val_loss: 0.8880 - val_accuracy: 0.6369\n","Epoch 19/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6993 - accuracy: 0.7999 - val_loss: 0.8647 - val_accuracy: 0.6561\n","Epoch 20/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.7035 - accuracy: 0.7951 - val_loss: 0.8312 - val_accuracy: 0.6912\n","Epoch 21/100\n","28/28 [==============================] - 2s 56ms/step - loss: 0.7055 - accuracy: 0.7844 - val_loss: 0.8221 - val_accuracy: 0.7127\n","Epoch 22/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.6934 - accuracy: 0.7943 - val_loss: 0.8136 - val_accuracy: 0.7138\n","Epoch 23/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7058 - accuracy: 0.7909 - val_loss: 0.8423 - val_accuracy: 0.7138\n","Epoch 24/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6965 - accuracy: 0.7898 - val_loss: 0.8112 - val_accuracy: 0.7296\n","Epoch 25/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7017 - accuracy: 0.7912 - val_loss: 0.8152 - val_accuracy: 0.7262\n","Epoch 26/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6930 - accuracy: 0.7980 - val_loss: 0.8638 - val_accuracy: 0.7036\n","Epoch 27/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7051 - accuracy: 0.7900 - val_loss: 0.8416 - val_accuracy: 0.7172\n","Epoch 28/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6915 - accuracy: 0.7949 - val_loss: 0.8758 - val_accuracy: 0.6957\n","Epoch 29/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6949 - accuracy: 0.7917 - val_loss: 0.7756 - val_accuracy: 0.7477\n","Epoch 30/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6883 - accuracy: 0.8028 - val_loss: 0.7701 - val_accuracy: 0.7398\n","Epoch 31/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6898 - accuracy: 0.7974 - val_loss: 0.7685 - val_accuracy: 0.7410\n","Epoch 32/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6780 - accuracy: 0.8090 - val_loss: 0.7874 - val_accuracy: 0.7455\n","Epoch 33/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6795 - accuracy: 0.8093 - val_loss: 0.7737 - val_accuracy: 0.7466\n","Epoch 34/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6897 - accuracy: 0.7957 - val_loss: 0.8032 - val_accuracy: 0.7432\n","Epoch 35/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6777 - accuracy: 0.8025 - val_loss: 0.7922 - val_accuracy: 0.7025\n","Epoch 36/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6780 - accuracy: 0.7971 - val_loss: 0.7743 - val_accuracy: 0.7376\n","Epoch 37/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6815 - accuracy: 0.8011 - val_loss: 0.7753 - val_accuracy: 0.7342\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6826 - accuracy: 0.7994 - val_loss: 0.7932 - val_accuracy: 0.7093\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6799 - accuracy: 0.7968 - val_loss: 0.7785 - val_accuracy: 0.7274\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6670 - accuracy: 0.8070 - val_loss: 0.7759 - val_accuracy: 0.7353\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6746 - accuracy: 0.8033 - val_loss: 0.7787 - val_accuracy: 0.7251\n","Epoch 42/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6690 - accuracy: 0.8011 - val_loss: 0.7791 - val_accuracy: 0.7410\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6684 - accuracy: 0.8079 - val_loss: 0.7805 - val_accuracy: 0.7149\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6692 - accuracy: 0.8079 - val_loss: 0.7788 - val_accuracy: 0.7262\n","Epoch 45/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6705 - accuracy: 0.8011 - val_loss: 0.7897 - val_accuracy: 0.7455\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6642 - accuracy: 0.8107 - val_loss: 0.7826 - val_accuracy: 0.7172\n","Epoch 47/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6672 - accuracy: 0.8090 - val_loss: 0.7723 - val_accuracy: 0.7432\n","Epoch 48/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6623 - accuracy: 0.8053 - val_loss: 0.7772 - val_accuracy: 0.7455\n","Epoch 49/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6762 - accuracy: 0.7991 - val_loss: 0.7916 - val_accuracy: 0.7489\n","Epoch 50/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6624 - accuracy: 0.8098 - val_loss: 0.7906 - val_accuracy: 0.7070\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6647 - accuracy: 0.8065 - val_loss: 0.7815 - val_accuracy: 0.7455\n","Epoch 52/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6573 - accuracy: 0.8118 - val_loss: 0.7854 - val_accuracy: 0.7477\n","Epoch 53/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6551 - accuracy: 0.8149 - val_loss: 0.7848 - val_accuracy: 0.7093\n","Epoch 54/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6500 - accuracy: 0.8141 - val_loss: 0.7827 - val_accuracy: 0.7387\n","Epoch 55/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6609 - accuracy: 0.8065 - val_loss: 0.7864 - val_accuracy: 0.7206\n","Epoch 56/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6633 - accuracy: 0.8096 - val_loss: 0.7787 - val_accuracy: 0.7251\n","Epoch 57/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6483 - accuracy: 0.8158 - val_loss: 0.7811 - val_accuracy: 0.7262\n","Epoch 58/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6483 - accuracy: 0.8135 - val_loss: 0.7797 - val_accuracy: 0.7285\n","Epoch 59/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6472 - accuracy: 0.8149 - val_loss: 0.7854 - val_accuracy: 0.7195\n","Epoch 60/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6515 - accuracy: 0.8093 - val_loss: 0.8279 - val_accuracy: 0.7398\n","Epoch 61/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6620 - accuracy: 0.8073 - val_loss: 0.7800 - val_accuracy: 0.7296\n","Epoch 62/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6619 - accuracy: 0.8053 - val_loss: 0.8012 - val_accuracy: 0.7048\n","Epoch 63/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6468 - accuracy: 0.8195 - val_loss: 0.7837 - val_accuracy: 0.7342\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6428 - accuracy: 0.8178 - val_loss: 0.7914 - val_accuracy: 0.7477\n","Epoch 65/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6475 - accuracy: 0.8164 - val_loss: 0.7740 - val_accuracy: 0.7443\n","Epoch 66/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6351 - accuracy: 0.8229 - val_loss: 0.7979 - val_accuracy: 0.7364\n","Epoch 67/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6433 - accuracy: 0.8178 - val_loss: 0.7822 - val_accuracy: 0.7443\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6324 - accuracy: 0.8243 - val_loss: 0.7914 - val_accuracy: 0.7443\n","Epoch 69/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6420 - accuracy: 0.8175 - val_loss: 0.8195 - val_accuracy: 0.7319\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6371 - accuracy: 0.8214 - val_loss: 0.7963 - val_accuracy: 0.7443\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6366 - accuracy: 0.8175 - val_loss: 0.7906 - val_accuracy: 0.7489\n","Epoch 72/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6267 - accuracy: 0.8294 - val_loss: 0.7856 - val_accuracy: 0.7376\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6301 - accuracy: 0.8246 - val_loss: 0.8207 - val_accuracy: 0.7353\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6270 - accuracy: 0.8243 - val_loss: 0.7924 - val_accuracy: 0.7387\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6278 - accuracy: 0.8285 - val_loss: 0.7860 - val_accuracy: 0.7387\n","Epoch 76/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6237 - accuracy: 0.8192 - val_loss: 0.7904 - val_accuracy: 0.7421\n","Epoch 77/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6127 - accuracy: 0.8350 - val_loss: 0.7862 - val_accuracy: 0.7229\n","Epoch 78/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6218 - accuracy: 0.8305 - val_loss: 0.8001 - val_accuracy: 0.7432\n","Epoch 79/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6350 - accuracy: 0.8149 - val_loss: 0.7926 - val_accuracy: 0.7342\n","Epoch 80/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6143 - accuracy: 0.8251 - val_loss: 0.7931 - val_accuracy: 0.7195\n","Epoch 81/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6183 - accuracy: 0.8265 - val_loss: 0.7924 - val_accuracy: 0.7262\n","Epoch 82/100\n","28/28 [==============================] - 2s 55ms/step - loss: 0.6116 - accuracy: 0.8347 - val_loss: 0.7978 - val_accuracy: 0.7500\n","Epoch 83/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6148 - accuracy: 0.8263 - val_loss: 0.7975 - val_accuracy: 0.7274\n","Epoch 84/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6436 - accuracy: 0.8050 - val_loss: 0.8233 - val_accuracy: 0.6968\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6286 - accuracy: 0.8206 - val_loss: 0.8178 - val_accuracy: 0.6934\n","Epoch 86/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6096 - accuracy: 0.8359 - val_loss: 0.7957 - val_accuracy: 0.7376\n","Epoch 87/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6092 - accuracy: 0.8387 - val_loss: 0.8093 - val_accuracy: 0.7455\n","Epoch 88/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6059 - accuracy: 0.8387 - val_loss: 0.8016 - val_accuracy: 0.7455\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6243 - accuracy: 0.8214 - val_loss: 0.8111 - val_accuracy: 0.7070\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6068 - accuracy: 0.8393 - val_loss: 0.8122 - val_accuracy: 0.7014\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6206 - accuracy: 0.8285 - val_loss: 0.7925 - val_accuracy: 0.7172\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6013 - accuracy: 0.8350 - val_loss: 0.7951 - val_accuracy: 0.7195\n","Epoch 93/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6006 - accuracy: 0.8401 - val_loss: 0.8323 - val_accuracy: 0.7342\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6012 - accuracy: 0.8370 - val_loss: 0.7999 - val_accuracy: 0.7330\n","Epoch 95/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5915 - accuracy: 0.8427 - val_loss: 0.7991 - val_accuracy: 0.7217\n","Epoch 96/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5907 - accuracy: 0.8449 - val_loss: 0.8079 - val_accuracy: 0.7330\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5947 - accuracy: 0.8336 - val_loss: 0.8041 - val_accuracy: 0.7149\n","Epoch 98/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6011 - accuracy: 0.8356 - val_loss: 0.7991 - val_accuracy: 0.7251\n","Epoch 99/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5945 - accuracy: 0.8359 - val_loss: 0.8055 - val_accuracy: 0.7149\n","Epoch 100/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5835 - accuracy: 0.8489 - val_loss: 0.7994 - val_accuracy: 0.7296\n","{'loss': [0.7692317962646484, 0.7408665418624878, 0.7296651601791382, 0.7292066216468811, 0.72486412525177, 0.7246738076210022, 0.7223999500274658, 0.7227786779403687, 0.7208999395370483, 0.7164179682731628, 0.7137925624847412, 0.7147874236106873, 0.7174614667892456, 0.716818630695343, 0.7183147668838501, 0.705166220664978, 0.7057192325592041, 0.7084082961082458, 0.6992971301078796, 0.703453004360199, 0.705507755279541, 0.693364679813385, 0.7058231234550476, 0.6964668035507202, 0.7016721963882446, 0.69304358959198, 0.7050520777702332, 0.6915021538734436, 0.6949224472045898, 0.6882891654968262, 0.6898484230041504, 0.6780275702476501, 0.6794854402542114, 0.6896847486495972, 0.6776759028434753, 0.6779971122741699, 0.6815466284751892, 0.6826088428497314, 0.6798984408378601, 0.6670365929603577, 0.6745505928993225, 0.6689872741699219, 0.668437123298645, 0.6692396998405457, 0.6705394983291626, 0.6641789078712463, 0.6672424674034119, 0.6622666716575623, 0.6761723160743713, 0.662409245967865, 0.6646720170974731, 0.6572657823562622, 0.6550684571266174, 0.6500487327575684, 0.6609483361244202, 0.6633397936820984, 0.6482760310173035, 0.6482885479927063, 0.6472268104553223, 0.6514915227890015, 0.6620423793792725, 0.6618508100509644, 0.6467679142951965, 0.6427976489067078, 0.6474875211715698, 0.6351354122161865, 0.6432968974113464, 0.6324097514152527, 0.6419662833213806, 0.6371466517448425, 0.6365879774093628, 0.626713752746582, 0.6301021575927734, 0.6269713044166565, 0.6278266310691833, 0.623690128326416, 0.6127491593360901, 0.6217697262763977, 0.6350489258766174, 0.6142599582672119, 0.6183287501335144, 0.6115936636924744, 0.6147761344909668, 0.6435765624046326, 0.6286376714706421, 0.6096333265304565, 0.6091976761817932, 0.6059412956237793, 0.6243054270744324, 0.6068227887153625, 0.6205655932426453, 0.6013141870498657, 0.6005733013153076, 0.6012396812438965, 0.5914778709411621, 0.5907003879547119, 0.5947387218475342, 0.6011192798614502, 0.5944709777832031, 0.5834935307502747], 'accuracy': [0.7467458844184875, 0.7724957466125488, 0.7778720855712891, 0.7784380316734314, 0.7835314273834229, 0.7815506458282471, 0.7823995351791382, 0.7823995351791382, 0.786361038684845, 0.784380316734314, 0.7815506458282471, 0.7835314273834229, 0.7855121493339539, 0.780701756477356, 0.7855121493339539, 0.7925863265991211, 0.7945670485496521, 0.7891907095909119, 0.7999433875083923, 0.7951329946517944, 0.784380316734314, 0.7942841053009033, 0.7908884882926941, 0.7897566556930542, 0.7911714911460876, 0.7979626655578613, 0.790039598941803, 0.7948500514030457, 0.79173743724823, 0.8027730584144592, 0.797396719455719, 0.8089982867240906, 0.8092812895774841, 0.7956989407539368, 0.8024901151657104, 0.7971137762069702, 0.801075279712677, 0.7993775010108948, 0.7968307733535767, 0.8070175647735596, 0.8033390045166016, 0.801075279712677, 0.8078664541244507, 0.8078664541244507, 0.801075279712677, 0.8106960654258728, 0.8089982867240906, 0.8053197264671326, 0.7990944981575012, 0.8098471760749817, 0.8064516186714172, 0.8118279576301575, 0.8149405717849731, 0.814091682434082, 0.8064516186714172, 0.8095642328262329, 0.8157894611358643, 0.8135257363319397, 0.8149405717849731, 0.8092812895774841, 0.8073005080223083, 0.8053197264671326, 0.8194680213928223, 0.81777024269104, 0.8163554072380066, 0.8228636384010315, 0.81777024269104, 0.8242784142494202, 0.8174872398376465, 0.821448802947998, 0.8174872398376465, 0.8293718099594116, 0.8245614171028137, 0.8242784142494202, 0.8285229206085205, 0.8191850781440735, 0.8350311517715454, 0.8305037021636963, 0.8149405717849731, 0.825127363204956, 0.8265421390533447, 0.8347481489181519, 0.826259195804596, 0.8050367832183838, 0.8205999135971069, 0.8358800411224365, 0.8387096524238586, 0.8387096524238586, 0.821448802947998, 0.839275598526001, 0.8285229206085205, 0.8350311517715454, 0.8401244878768921, 0.8370118737220764, 0.8426712155342102, 0.8449349403381348, 0.833616316318512, 0.835597038269043, 0.8358800411224365, 0.8488964438438416], 'val_loss': [0.9537955522537231, 0.954495370388031, 0.9584883451461792, 0.9606293439865112, 0.9669821858406067, 0.9720775485038757, 0.9765802025794983, 0.971903383731842, 0.9915465116500854, 1.0030555725097656, 0.9960858821868896, 1.0071436166763306, 1.027892827987671, 0.9824296832084656, 0.999119222164154, 0.971656322479248, 0.8931208848953247, 0.8879692554473877, 0.8646968603134155, 0.8311517238616943, 0.8220837712287903, 0.8136287331581116, 0.8423037528991699, 0.8112086057662964, 0.8152469992637634, 0.8637645840644836, 0.8416416049003601, 0.8758207559585571, 0.7756025195121765, 0.7700678706169128, 0.7684635519981384, 0.7874243259429932, 0.7736673355102539, 0.803249180316925, 0.7922242879867554, 0.7743154168128967, 0.7752624750137329, 0.7931684255599976, 0.778458833694458, 0.7758792042732239, 0.7786580920219421, 0.779072642326355, 0.7804660201072693, 0.7787607908248901, 0.7896703481674194, 0.7826003432273865, 0.7723140716552734, 0.7772013545036316, 0.7916011214256287, 0.7906066179275513, 0.7814728021621704, 0.7853572964668274, 0.7848092913627625, 0.7826700806617737, 0.7864387035369873, 0.7786923050880432, 0.7811071276664734, 0.7796570062637329, 0.7854070067405701, 0.8279322981834412, 0.7799661755561829, 0.801207959651947, 0.7837042212486267, 0.7914131879806519, 0.7740176916122437, 0.7979361414909363, 0.7821810841560364, 0.7913944125175476, 0.8194783926010132, 0.7962533831596375, 0.7906309366226196, 0.785569965839386, 0.8206944465637207, 0.7924063205718994, 0.7859833240509033, 0.7903711795806885, 0.7861701846122742, 0.800078809261322, 0.7926223278045654, 0.7930871844291687, 0.7923716306686401, 0.7977709174156189, 0.797477662563324, 0.8233286142349243, 0.8178292512893677, 0.7957157492637634, 0.8092826008796692, 0.8015576601028442, 0.8110758662223816, 0.8121817708015442, 0.7924561500549316, 0.7951399087905884, 0.8322955965995789, 0.7999057769775391, 0.7990584969520569, 0.8079009652137756, 0.8040680885314941, 0.799142062664032, 0.8054850101470947, 0.799443781375885], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.4977375566959381, 0.5192307829856873, 0.5226244330406189, 0.5475113391876221, 0.6300904750823975, 0.6368778347969055, 0.6561086177825928, 0.6911764740943909, 0.7126696705818176, 0.7138009071350098, 0.7138009071350098, 0.7296379804611206, 0.726244330406189, 0.7036198973655701, 0.7171945571899414, 0.6957013607025146, 0.7477375268936157, 0.7398189902305603, 0.7409502267837524, 0.7454751133918762, 0.7466063499450684, 0.7432126402854919, 0.7024886608123779, 0.7375565767288208, 0.7341628670692444, 0.709276020526886, 0.7273755669593811, 0.7352941036224365, 0.7251130938529968, 0.7409502267837524, 0.7149321436882019, 0.726244330406189, 0.7454751133918762, 0.7171945571899414, 0.7432126402854919, 0.7454751133918762, 0.7488687634468079, 0.7070135474205017, 0.7454751133918762, 0.7477375268936157, 0.709276020526886, 0.7386877536773682, 0.720588207244873, 0.7251130938529968, 0.726244330406189, 0.7285068035125732, 0.7194570302963257, 0.7398189902305603, 0.7296379804611206, 0.7047511339187622, 0.7341628670692444, 0.7477375268936157, 0.7443438768386841, 0.7364253401756287, 0.7443438768386841, 0.7443438768386841, 0.7319004535675049, 0.7443438768386841, 0.7488687634468079, 0.7375565767288208, 0.7352941036224365, 0.7386877536773682, 0.7386877536773682, 0.7420814633369446, 0.7228506803512573, 0.7432126402854919, 0.7341628670692444, 0.7194570302963257, 0.726244330406189, 0.75, 0.7273755669593811, 0.6968325972557068, 0.6934388875961304, 0.7375565767288208, 0.7454751133918762, 0.7454751133918762, 0.7070135474205017, 0.7013574838638306, 0.7171945571899414, 0.7194570302963257, 0.7341628670692444, 0.733031690120697, 0.7217194437980652, 0.733031690120697, 0.7149321436882019, 0.7251130938529968, 0.7149321436882019, 0.7296379804611206]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.7377 - accuracy: 0.7682"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 58ms/step - loss: 0.7384 - accuracy: 0.7677 - val_loss: 0.9612 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7280 - accuracy: 0.7755 - val_loss: 0.9643 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7252 - accuracy: 0.7765 - val_loss: 0.9687 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7230 - accuracy: 0.7747 - val_loss: 0.9682 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7222 - accuracy: 0.7788 - val_loss: 0.9811 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7136 - accuracy: 0.7806 - val_loss: 0.9872 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7150 - accuracy: 0.7840 - val_loss: 0.9934 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.7350 - accuracy: 0.7618 - val_loss: 1.0057 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7118 - accuracy: 0.7804 - val_loss: 1.0262 - val_accuracy: 0.4855\n","Epoch 10/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7094 - accuracy: 0.7879 - val_loss: 1.0293 - val_accuracy: 0.4855\n","Epoch 11/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7094 - accuracy: 0.7827 - val_loss: 1.0557 - val_accuracy: 0.4855\n","Epoch 12/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.7121 - accuracy: 0.7853 - val_loss: 1.0509 - val_accuracy: 0.4886\n","Epoch 13/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7017 - accuracy: 0.7855 - val_loss: 1.0887 - val_accuracy: 0.4886\n","Epoch 14/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7237 - accuracy: 0.7713 - val_loss: 1.0527 - val_accuracy: 0.4979\n","Epoch 15/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7075 - accuracy: 0.7850 - val_loss: 0.9789 - val_accuracy: 0.5382\n","Epoch 16/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7026 - accuracy: 0.7853 - val_loss: 0.9287 - val_accuracy: 0.6043\n","Epoch 17/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.7023 - accuracy: 0.7832 - val_loss: 0.8710 - val_accuracy: 0.6539\n","Epoch 18/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6991 - accuracy: 0.7868 - val_loss: 0.8662 - val_accuracy: 0.6622\n","Epoch 19/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6954 - accuracy: 0.7941 - val_loss: 0.8537 - val_accuracy: 0.6715\n","Epoch 20/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7137 - accuracy: 0.7783 - val_loss: 0.8337 - val_accuracy: 0.6942\n","Epoch 21/100\n","31/31 [==============================] - 3s 114ms/step - loss: 0.7001 - accuracy: 0.7891 - val_loss: 0.8309 - val_accuracy: 0.7066\n","Epoch 22/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6896 - accuracy: 0.7938 - val_loss: 0.8483 - val_accuracy: 0.7025\n","Epoch 23/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6999 - accuracy: 0.7866 - val_loss: 0.8256 - val_accuracy: 0.7107\n","Epoch 24/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7035 - accuracy: 0.7770 - val_loss: 0.8362 - val_accuracy: 0.7159\n","Epoch 25/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6928 - accuracy: 0.7897 - val_loss: 0.7931 - val_accuracy: 0.7221\n","Epoch 26/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6929 - accuracy: 0.7897 - val_loss: 0.8143 - val_accuracy: 0.7231\n","Epoch 27/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6882 - accuracy: 0.7987 - val_loss: 0.8028 - val_accuracy: 0.7304\n","Epoch 28/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6834 - accuracy: 0.7990 - val_loss: 0.7831 - val_accuracy: 0.7417\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6843 - accuracy: 0.7977 - val_loss: 0.7972 - val_accuracy: 0.7335\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6896 - accuracy: 0.7894 - val_loss: 0.7890 - val_accuracy: 0.7407\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6754 - accuracy: 0.7979 - val_loss: 0.7822 - val_accuracy: 0.7335\n","Epoch 32/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6797 - accuracy: 0.7982 - val_loss: 0.7904 - val_accuracy: 0.7459\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6813 - accuracy: 0.8003 - val_loss: 0.7936 - val_accuracy: 0.7438\n","Epoch 34/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6812 - accuracy: 0.7904 - val_loss: 0.7845 - val_accuracy: 0.7417\n","Epoch 35/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6824 - accuracy: 0.7922 - val_loss: 0.8543 - val_accuracy: 0.6829\n","Epoch 36/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6960 - accuracy: 0.7853 - val_loss: 0.7776 - val_accuracy: 0.7386\n","Epoch 37/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6810 - accuracy: 0.7982 - val_loss: 0.7950 - val_accuracy: 0.7397\n","Epoch 38/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6746 - accuracy: 0.7979 - val_loss: 0.8031 - val_accuracy: 0.7355\n","Epoch 39/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6796 - accuracy: 0.8028 - val_loss: 0.7834 - val_accuracy: 0.7386\n","Epoch 40/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6752 - accuracy: 0.8016 - val_loss: 0.8499 - val_accuracy: 0.6705\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6771 - accuracy: 0.7941 - val_loss: 0.7823 - val_accuracy: 0.7448\n","Epoch 42/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6703 - accuracy: 0.7992 - val_loss: 0.7838 - val_accuracy: 0.7417\n","Epoch 43/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6686 - accuracy: 0.7987 - val_loss: 0.7975 - val_accuracy: 0.7397\n","Epoch 44/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6846 - accuracy: 0.7902 - val_loss: 0.7817 - val_accuracy: 0.7242\n","Epoch 45/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6910 - accuracy: 0.7853 - val_loss: 0.7777 - val_accuracy: 0.7345\n","Epoch 46/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6592 - accuracy: 0.8109 - val_loss: 0.7867 - val_accuracy: 0.7376\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6599 - accuracy: 0.8090 - val_loss: 0.7871 - val_accuracy: 0.7211\n","Epoch 48/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6679 - accuracy: 0.8047 - val_loss: 0.7890 - val_accuracy: 0.7200\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6616 - accuracy: 0.8057 - val_loss: 0.7852 - val_accuracy: 0.7366\n","Epoch 50/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6570 - accuracy: 0.8059 - val_loss: 0.7810 - val_accuracy: 0.7293\n","Epoch 51/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6594 - accuracy: 0.8088 - val_loss: 0.7913 - val_accuracy: 0.7428\n","Epoch 52/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6610 - accuracy: 0.8085 - val_loss: 0.7920 - val_accuracy: 0.7200\n","Epoch 53/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6563 - accuracy: 0.8124 - val_loss: 0.7863 - val_accuracy: 0.7262\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6528 - accuracy: 0.8137 - val_loss: 0.7809 - val_accuracy: 0.7304\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6547 - accuracy: 0.8106 - val_loss: 0.7996 - val_accuracy: 0.7128\n","Epoch 56/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6585 - accuracy: 0.8059 - val_loss: 0.7963 - val_accuracy: 0.7190\n","Epoch 57/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6527 - accuracy: 0.8083 - val_loss: 0.7895 - val_accuracy: 0.7459\n","Epoch 58/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6543 - accuracy: 0.8101 - val_loss: 0.7882 - val_accuracy: 0.7314\n","Epoch 59/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6516 - accuracy: 0.8106 - val_loss: 0.8060 - val_accuracy: 0.7448\n","Epoch 60/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6693 - accuracy: 0.7992 - val_loss: 0.7813 - val_accuracy: 0.7221\n","Epoch 61/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6515 - accuracy: 0.8072 - val_loss: 0.7852 - val_accuracy: 0.7211\n","Epoch 62/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6493 - accuracy: 0.8072 - val_loss: 0.8006 - val_accuracy: 0.7417\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6554 - accuracy: 0.8047 - val_loss: 0.7828 - val_accuracy: 0.7407\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6499 - accuracy: 0.8106 - val_loss: 0.8142 - val_accuracy: 0.7366\n","Epoch 65/100\n","31/31 [==============================] - 2s 57ms/step - loss: 0.6470 - accuracy: 0.8065 - val_loss: 0.8001 - val_accuracy: 0.7479\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6557 - accuracy: 0.8031 - val_loss: 0.7861 - val_accuracy: 0.7469\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6522 - accuracy: 0.8101 - val_loss: 0.7895 - val_accuracy: 0.7417\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6393 - accuracy: 0.8152 - val_loss: 0.8464 - val_accuracy: 0.6725\n","Epoch 69/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6664 - accuracy: 0.7948 - val_loss: 0.8006 - val_accuracy: 0.7087\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6329 - accuracy: 0.8282 - val_loss: 0.7895 - val_accuracy: 0.7428\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6456 - accuracy: 0.8165 - val_loss: 0.7841 - val_accuracy: 0.7335\n","Epoch 72/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6326 - accuracy: 0.8129 - val_loss: 0.7849 - val_accuracy: 0.7355\n","Epoch 73/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6301 - accuracy: 0.8158 - val_loss: 0.8084 - val_accuracy: 0.6983\n","Epoch 74/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6309 - accuracy: 0.8207 - val_loss: 0.8071 - val_accuracy: 0.7025\n","Epoch 75/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6338 - accuracy: 0.8222 - val_loss: 0.7967 - val_accuracy: 0.7159\n","Epoch 76/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6417 - accuracy: 0.8119 - val_loss: 0.7878 - val_accuracy: 0.7490\n","Epoch 77/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6198 - accuracy: 0.8264 - val_loss: 0.7859 - val_accuracy: 0.7335\n","Epoch 78/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6308 - accuracy: 0.8137 - val_loss: 0.7905 - val_accuracy: 0.7448\n","Epoch 79/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6305 - accuracy: 0.8173 - val_loss: 0.7887 - val_accuracy: 0.7335\n","Epoch 80/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6238 - accuracy: 0.8233 - val_loss: 0.7843 - val_accuracy: 0.7366\n","Epoch 81/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6220 - accuracy: 0.8276 - val_loss: 0.8030 - val_accuracy: 0.7459\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6146 - accuracy: 0.8274 - val_loss: 0.7863 - val_accuracy: 0.7324\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6109 - accuracy: 0.8276 - val_loss: 0.7869 - val_accuracy: 0.7376\n","Epoch 84/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6153 - accuracy: 0.8282 - val_loss: 0.7950 - val_accuracy: 0.7242\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6332 - accuracy: 0.8132 - val_loss: 0.7950 - val_accuracy: 0.7355\n","Epoch 86/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6183 - accuracy: 0.8220 - val_loss: 0.7874 - val_accuracy: 0.7386\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6145 - accuracy: 0.8199 - val_loss: 0.8193 - val_accuracy: 0.7376\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6196 - accuracy: 0.8168 - val_loss: 0.8051 - val_accuracy: 0.7345\n","Epoch 89/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6234 - accuracy: 0.8178 - val_loss: 0.8148 - val_accuracy: 0.7376\n","Epoch 90/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6139 - accuracy: 0.8258 - val_loss: 0.7914 - val_accuracy: 0.7355\n","Epoch 91/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6111 - accuracy: 0.8227 - val_loss: 0.8002 - val_accuracy: 0.7459\n","Epoch 92/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6232 - accuracy: 0.8168 - val_loss: 0.8026 - val_accuracy: 0.7159\n","Epoch 93/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6202 - accuracy: 0.8207 - val_loss: 0.7838 - val_accuracy: 0.7376\n","Epoch 94/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6068 - accuracy: 0.8313 - val_loss: 0.7977 - val_accuracy: 0.7469\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6066 - accuracy: 0.8284 - val_loss: 0.7955 - val_accuracy: 0.7231\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5964 - accuracy: 0.8362 - val_loss: 0.7878 - val_accuracy: 0.7459\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6025 - accuracy: 0.8292 - val_loss: 0.7922 - val_accuracy: 0.7335\n","Epoch 98/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6002 - accuracy: 0.8364 - val_loss: 0.8037 - val_accuracy: 0.7097\n","Epoch 99/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5969 - accuracy: 0.8385 - val_loss: 0.8187 - val_accuracy: 0.7397\n","Epoch 100/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6122 - accuracy: 0.8209 - val_loss: 0.7895 - val_accuracy: 0.7448\n","{'loss': [0.738388180732727, 0.7280337810516357, 0.7252492308616638, 0.723039984703064, 0.7222006916999817, 0.713641345500946, 0.7150112390518188, 0.7349509596824646, 0.7117598652839661, 0.7094265222549438, 0.7093754410743713, 0.7121016383171082, 0.7016612887382507, 0.7236998677253723, 0.7074679136276245, 0.7026142477989197, 0.7022525072097778, 0.6990775465965271, 0.6953533291816711, 0.7136886119842529, 0.7001060843467712, 0.6896445751190186, 0.6999402046203613, 0.7034672498703003, 0.6928119659423828, 0.6928666830062866, 0.6881767511367798, 0.6834402680397034, 0.6843124032020569, 0.6895869374275208, 0.675449550151825, 0.6797167062759399, 0.681272029876709, 0.681184709072113, 0.6824252009391785, 0.6959846019744873, 0.6810296177864075, 0.6746382117271423, 0.679570198059082, 0.6752310395240784, 0.6771454215049744, 0.6702983975410461, 0.6686493158340454, 0.6846181750297546, 0.6909940242767334, 0.6592121124267578, 0.6599413156509399, 0.6679380536079407, 0.6615590453147888, 0.6570497155189514, 0.6593677401542664, 0.6609748005867004, 0.6562893390655518, 0.6527832746505737, 0.6547145247459412, 0.6585065126419067, 0.6527177691459656, 0.6543403267860413, 0.6515864133834839, 0.6693112254142761, 0.6515285968780518, 0.6492964625358582, 0.6553966999053955, 0.6498783230781555, 0.6469773054122925, 0.6557196974754333, 0.6522180438041687, 0.6393428444862366, 0.6663801670074463, 0.632923424243927, 0.6455724239349365, 0.632592499256134, 0.6301042437553406, 0.6308555006980896, 0.6337764263153076, 0.6417092084884644, 0.6198237538337708, 0.6307809352874756, 0.6305095553398132, 0.623812198638916, 0.6220244765281677, 0.6146112084388733, 0.6109349727630615, 0.6153109073638916, 0.6331977844238281, 0.6183329820632935, 0.6145012974739075, 0.6195758581161499, 0.6233972907066345, 0.6138591766357422, 0.6111229658126831, 0.6231964230537415, 0.6201920509338379, 0.6068063974380493, 0.6066450476646423, 0.5963749885559082, 0.602505624294281, 0.600175142288208, 0.5969385504722595, 0.6121643781661987], 'accuracy': [0.7677002549171448, 0.775452196598053, 0.776485800743103, 0.7746769785881042, 0.7788113951683044, 0.7806201577186584, 0.7839793562889099, 0.7617571353912354, 0.7803617715835571, 0.7878552675247192, 0.7826873660087585, 0.7852713465690613, 0.7855297327041626, 0.7713178396224976, 0.7850129008293152, 0.7852713465690613, 0.7832041382789612, 0.786821722984314, 0.7940568327903748, 0.778294563293457, 0.7891472578048706, 0.7937984466552734, 0.7865633368492126, 0.7770025730133057, 0.789664089679718, 0.789664089679718, 0.7987080216407776, 0.7989664077758789, 0.7976744174957275, 0.7894057035446167, 0.7979328036308289, 0.7981911897659302, 0.8002583980560303, 0.790439248085022, 0.7922480702400208, 0.7852713465690613, 0.7981911897659302, 0.7979328036308289, 0.802842378616333, 0.8015503883361816, 0.7940568327903748, 0.7992247939109802, 0.7987080216407776, 0.7901808619499207, 0.7852713465690613, 0.8108527064323425, 0.8090439438819885, 0.804651141166687, 0.8056847453117371, 0.8059431314468384, 0.8087855577468872, 0.8085271120071411, 0.8124030828475952, 0.8136950731277466, 0.8105943202972412, 0.8059431314468384, 0.8082687258720398, 0.8100775480270386, 0.8105943202972412, 0.7992247939109802, 0.8072351217269897, 0.8072351217269897, 0.804651141166687, 0.8105943202972412, 0.8064599633216858, 0.8031007647514343, 0.8100775480270386, 0.8152454495429993, 0.7948320508003235, 0.8281653523445129, 0.8165374398231506, 0.8129199147224426, 0.8157622814178467, 0.8206718564033508, 0.8222222328186035, 0.8118863105773926, 0.8263565897941589, 0.8136950731277466, 0.8173126578330994, 0.8232558369636536, 0.8276485800743103, 0.827390193939209, 0.8276485800743103, 0.8281653523445129, 0.813178300857544, 0.8219638466835022, 0.8198966383934021, 0.8167958855628967, 0.817829430103302, 0.8258398175239563, 0.8227390050888062, 0.8167958855628967, 0.8206718564033508, 0.8312661647796631, 0.828423798084259, 0.8361757397651672, 0.829198956489563, 0.8364341259002686, 0.8385012745857239, 0.8209302425384521], 'val_loss': [0.9612413644790649, 0.9642972946166992, 0.9687427878379822, 0.968161940574646, 0.9811007976531982, 0.9872226715087891, 0.9934219717979431, 1.0056877136230469, 1.0262351036071777, 1.0292530059814453, 1.0557136535644531, 1.0509005784988403, 1.0886988639831543, 1.052747130393982, 0.9789429903030396, 0.9287427663803101, 0.871009886264801, 0.8661571145057678, 0.8536821603775024, 0.8336518406867981, 0.8309112787246704, 0.848274827003479, 0.8255892395973206, 0.8361698985099792, 0.793130099773407, 0.8143039345741272, 0.8028459548950195, 0.7830686569213867, 0.7972086071968079, 0.7890095114707947, 0.7821504473686218, 0.7903921604156494, 0.7936034798622131, 0.7844836711883545, 0.8543027639389038, 0.7776016592979431, 0.7950472235679626, 0.803065299987793, 0.7833644151687622, 0.8498506546020508, 0.7822640538215637, 0.7838143110275269, 0.7974821329116821, 0.7817478179931641, 0.7777350544929504, 0.7866958975791931, 0.7870513200759888, 0.7889678478240967, 0.7852367758750916, 0.7809581160545349, 0.7912676334381104, 0.7920436859130859, 0.7863128781318665, 0.7809457182884216, 0.79963618516922, 0.7963274717330933, 0.7895375490188599, 0.7881979942321777, 0.8060353398323059, 0.7812895774841309, 0.7851858735084534, 0.8006162047386169, 0.7828363180160522, 0.814156711101532, 0.8001232147216797, 0.786065936088562, 0.7894600629806519, 0.8463751673698425, 0.8006044626235962, 0.7895270586013794, 0.7841107845306396, 0.7849262356758118, 0.8083802461624146, 0.8071001172065735, 0.796686589717865, 0.7878097295761108, 0.7859064340591431, 0.7905381321907043, 0.7887013554573059, 0.7842584848403931, 0.8030273914337158, 0.7862828373908997, 0.7868844866752625, 0.7950462698936462, 0.7950252890586853, 0.7873926162719727, 0.819313645362854, 0.805065929889679, 0.8148337602615356, 0.7914104461669922, 0.8002480864524841, 0.8026040196418762, 0.78380286693573, 0.7976772785186768, 0.7955008149147034, 0.787774384021759, 0.7921693325042725, 0.8037043809890747, 0.8187091946601868, 0.7894688248634338], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4886363744735718, 0.4886363744735718, 0.49793389439582825, 0.538223147392273, 0.6043388247489929, 0.6539255976676941, 0.6621900796890259, 0.6714876294136047, 0.6942148804664612, 0.7066115736961365, 0.702479362487793, 0.71074378490448, 0.7159090638160706, 0.7221074104309082, 0.7231404781341553, 0.73037189245224, 0.7417355179786682, 0.7334710955619812, 0.7407024502754211, 0.7334710955619812, 0.7458677887916565, 0.7438016533851624, 0.7417355179786682, 0.682851254940033, 0.7386363744735718, 0.7396694421768188, 0.7355371713638306, 0.7386363744735718, 0.6704545617103577, 0.7448347210884094, 0.7417355179786682, 0.7396694421768188, 0.7241735458374023, 0.7345041036605835, 0.7376033067703247, 0.7210744023323059, 0.7200413346290588, 0.7365702390670776, 0.7293388247489929, 0.7427685856819153, 0.7200413346290588, 0.7262396812438965, 0.73037189245224, 0.7128099203109741, 0.7190082669258118, 0.7458677887916565, 0.7314049601554871, 0.7448347210884094, 0.7221074104309082, 0.7210744023323059, 0.7417355179786682, 0.7407024502754211, 0.7365702390670776, 0.7479338645935059, 0.7469007968902588, 0.7417355179786682, 0.672520637512207, 0.7086777091026306, 0.7427685856819153, 0.7334710955619812, 0.7355371713638306, 0.6983470916748047, 0.702479362487793, 0.7159090638160706, 0.7489669322967529, 0.7334710955619812, 0.7448347210884094, 0.7334710955619812, 0.7365702390670776, 0.7458677887916565, 0.7324380278587341, 0.7376033067703247, 0.7241735458374023, 0.7355371713638306, 0.7386363744735718, 0.7376033067703247, 0.7345041036605835, 0.7376033067703247, 0.7355371713638306, 0.7458677887916565, 0.7159090638160706, 0.7376033067703247, 0.7469007968902588, 0.7231404781341553, 0.7458677887916565, 0.7334710955619812, 0.7097107172012329, 0.7396694421768188, 0.7448347210884094]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.6795 - accuracy: 0.7848"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 59ms/step - loss: 0.6795 - accuracy: 0.7848 - val_loss: 0.9401 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6455 - accuracy: 0.8074 - val_loss: 0.9441 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6360 - accuracy: 0.8165 - val_loss: 0.9509 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6419 - accuracy: 0.8098 - val_loss: 0.9530 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6348 - accuracy: 0.8141 - val_loss: 0.9712 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6281 - accuracy: 0.8195 - val_loss: 0.9872 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6310 - accuracy: 0.8165 - val_loss: 1.0031 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6403 - accuracy: 0.8101 - val_loss: 1.0231 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6356 - accuracy: 0.8149 - val_loss: 1.0414 - val_accuracy: 0.4849\n","Epoch 10/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6241 - accuracy: 0.8209 - val_loss: 1.0551 - val_accuracy: 0.4849\n","Epoch 11/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6234 - accuracy: 0.8214 - val_loss: 1.0938 - val_accuracy: 0.4849\n","Epoch 12/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6339 - accuracy: 0.8160 - val_loss: 1.1236 - val_accuracy: 0.4849\n","Epoch 13/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.6226 - accuracy: 0.8246 - val_loss: 1.1752 - val_accuracy: 0.4860\n","Epoch 14/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6401 - accuracy: 0.8103 - val_loss: 1.2050 - val_accuracy: 0.4860\n","Epoch 15/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.6391 - accuracy: 0.8060 - val_loss: 1.1601 - val_accuracy: 0.4957\n","Epoch 16/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.6353 - accuracy: 0.8117 - val_loss: 1.1126 - val_accuracy: 0.5065\n","Epoch 17/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.6390 - accuracy: 0.8147 - val_loss: 1.0189 - val_accuracy: 0.5550\n","Epoch 18/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.6109 - accuracy: 0.8265 - val_loss: 0.9909 - val_accuracy: 0.5830\n","Epoch 19/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6157 - accuracy: 0.8314 - val_loss: 0.8595 - val_accuracy: 0.6767\n","Epoch 20/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6144 - accuracy: 0.8192 - val_loss: 0.8623 - val_accuracy: 0.6767\n","Epoch 21/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6083 - accuracy: 0.8295 - val_loss: 0.8076 - val_accuracy: 0.7252\n","Epoch 22/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.6089 - accuracy: 0.8300 - val_loss: 0.7961 - val_accuracy: 0.7349\n","Epoch 23/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6045 - accuracy: 0.8354 - val_loss: 0.8126 - val_accuracy: 0.7489\n","Epoch 24/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.6120 - accuracy: 0.8192 - val_loss: 0.7847 - val_accuracy: 0.7586\n","Epoch 25/100\n","29/29 [==============================] - 4s 127ms/step - loss: 0.6118 - accuracy: 0.8281 - val_loss: 0.7492 - val_accuracy: 0.7672\n","Epoch 26/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6027 - accuracy: 0.8289 - val_loss: 0.7855 - val_accuracy: 0.7457\n","Epoch 27/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6106 - accuracy: 0.8303 - val_loss: 0.7336 - val_accuracy: 0.7780\n","Epoch 28/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.5959 - accuracy: 0.8381 - val_loss: 0.7279 - val_accuracy: 0.7812\n","Epoch 29/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5977 - accuracy: 0.8311 - val_loss: 0.7346 - val_accuracy: 0.7748\n","Epoch 30/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.6040 - accuracy: 0.8316 - val_loss: 0.7258 - val_accuracy: 0.7823\n","Epoch 31/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6021 - accuracy: 0.8330 - val_loss: 0.7332 - val_accuracy: 0.7748\n","Epoch 32/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.6127 - accuracy: 0.8273 - val_loss: 0.7290 - val_accuracy: 0.7888\n","Epoch 33/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6011 - accuracy: 0.8284 - val_loss: 0.7642 - val_accuracy: 0.7457\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5981 - accuracy: 0.8289 - val_loss: 0.7228 - val_accuracy: 0.7823\n","Epoch 35/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6014 - accuracy: 0.8289 - val_loss: 0.7554 - val_accuracy: 0.7683\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6022 - accuracy: 0.8324 - val_loss: 0.7277 - val_accuracy: 0.7802\n","Epoch 37/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5854 - accuracy: 0.8448 - val_loss: 0.7287 - val_accuracy: 0.7856\n","Epoch 38/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5882 - accuracy: 0.8421 - val_loss: 0.7438 - val_accuracy: 0.7791\n","Epoch 39/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5918 - accuracy: 0.8300 - val_loss: 0.7454 - val_accuracy: 0.7726\n","Epoch 40/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5942 - accuracy: 0.8319 - val_loss: 0.7276 - val_accuracy: 0.7802\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5909 - accuracy: 0.8419 - val_loss: 0.7368 - val_accuracy: 0.7780\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5887 - accuracy: 0.8389 - val_loss: 0.7325 - val_accuracy: 0.7748\n","Epoch 43/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5755 - accuracy: 0.8467 - val_loss: 0.7301 - val_accuracy: 0.7780\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5759 - accuracy: 0.8456 - val_loss: 0.7592 - val_accuracy: 0.7543\n","Epoch 45/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5741 - accuracy: 0.8456 - val_loss: 0.7390 - val_accuracy: 0.7737\n","Epoch 46/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5746 - accuracy: 0.8448 - val_loss: 0.7450 - val_accuracy: 0.7769\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5788 - accuracy: 0.8475 - val_loss: 0.7292 - val_accuracy: 0.7802\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5775 - accuracy: 0.8365 - val_loss: 0.7384 - val_accuracy: 0.7726\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5761 - accuracy: 0.8491 - val_loss: 0.7468 - val_accuracy: 0.7672\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5739 - accuracy: 0.8499 - val_loss: 0.7440 - val_accuracy: 0.7672\n","Epoch 51/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5726 - accuracy: 0.8467 - val_loss: 0.7369 - val_accuracy: 0.7812\n","Epoch 52/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5611 - accuracy: 0.8556 - val_loss: 0.7434 - val_accuracy: 0.7802\n","Epoch 53/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5722 - accuracy: 0.8389 - val_loss: 0.7389 - val_accuracy: 0.7683\n","Epoch 54/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5806 - accuracy: 0.8332 - val_loss: 0.8136 - val_accuracy: 0.7360\n","Epoch 55/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5770 - accuracy: 0.8462 - val_loss: 0.7372 - val_accuracy: 0.7737\n","Epoch 56/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5648 - accuracy: 0.8559 - val_loss: 0.7737 - val_accuracy: 0.7543\n","Epoch 57/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5581 - accuracy: 0.8564 - val_loss: 0.7332 - val_accuracy: 0.7856\n","Epoch 58/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5666 - accuracy: 0.8505 - val_loss: 0.7344 - val_accuracy: 0.7856\n","Epoch 59/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5578 - accuracy: 0.8508 - val_loss: 0.7397 - val_accuracy: 0.7737\n","Epoch 60/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5541 - accuracy: 0.8570 - val_loss: 0.7347 - val_accuracy: 0.7748\n","Epoch 61/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5537 - accuracy: 0.8602 - val_loss: 0.7435 - val_accuracy: 0.7780\n","Epoch 62/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5633 - accuracy: 0.8483 - val_loss: 0.7476 - val_accuracy: 0.7823\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5469 - accuracy: 0.8618 - val_loss: 0.7496 - val_accuracy: 0.7683\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5560 - accuracy: 0.8532 - val_loss: 0.7455 - val_accuracy: 0.7748\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5511 - accuracy: 0.8583 - val_loss: 0.7465 - val_accuracy: 0.7705\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5817 - accuracy: 0.8386 - val_loss: 0.8634 - val_accuracy: 0.7241\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6065 - accuracy: 0.8235 - val_loss: 0.7444 - val_accuracy: 0.7640\n","Epoch 68/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5756 - accuracy: 0.8384 - val_loss: 0.7391 - val_accuracy: 0.7737\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5544 - accuracy: 0.8502 - val_loss: 0.7521 - val_accuracy: 0.7716\n","Epoch 70/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5476 - accuracy: 0.8572 - val_loss: 0.7361 - val_accuracy: 0.7759\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5458 - accuracy: 0.8602 - val_loss: 0.7547 - val_accuracy: 0.7716\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5415 - accuracy: 0.8591 - val_loss: 0.7963 - val_accuracy: 0.7457\n","Epoch 73/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5526 - accuracy: 0.8556 - val_loss: 0.7407 - val_accuracy: 0.7759\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5509 - accuracy: 0.8570 - val_loss: 0.8166 - val_accuracy: 0.7317\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5437 - accuracy: 0.8575 - val_loss: 0.7492 - val_accuracy: 0.7651\n","Epoch 76/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5425 - accuracy: 0.8599 - val_loss: 0.7510 - val_accuracy: 0.7640\n","Epoch 77/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5369 - accuracy: 0.8615 - val_loss: 0.7642 - val_accuracy: 0.7662\n","Epoch 78/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5337 - accuracy: 0.8648 - val_loss: 0.7491 - val_accuracy: 0.7716\n","Epoch 79/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5360 - accuracy: 0.8580 - val_loss: 0.7881 - val_accuracy: 0.7608\n","Epoch 80/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5271 - accuracy: 0.8766 - val_loss: 0.7649 - val_accuracy: 0.7640\n","Epoch 81/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5302 - accuracy: 0.8618 - val_loss: 0.7595 - val_accuracy: 0.7629\n","Epoch 82/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5294 - accuracy: 0.8712 - val_loss: 0.7636 - val_accuracy: 0.7619\n","Epoch 83/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5243 - accuracy: 0.8677 - val_loss: 0.7520 - val_accuracy: 0.7705\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5297 - accuracy: 0.8602 - val_loss: 0.7731 - val_accuracy: 0.7586\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5351 - accuracy: 0.8561 - val_loss: 0.7665 - val_accuracy: 0.7565\n","Epoch 86/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5276 - accuracy: 0.8720 - val_loss: 0.7555 - val_accuracy: 0.7716\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5263 - accuracy: 0.8702 - val_loss: 0.8175 - val_accuracy: 0.7435\n","Epoch 88/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5514 - accuracy: 0.8553 - val_loss: 0.7539 - val_accuracy: 0.7769\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5268 - accuracy: 0.8685 - val_loss: 0.7552 - val_accuracy: 0.7737\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5328 - accuracy: 0.8645 - val_loss: 0.7772 - val_accuracy: 0.7619\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5232 - accuracy: 0.8723 - val_loss: 0.7920 - val_accuracy: 0.7575\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5183 - accuracy: 0.8739 - val_loss: 0.7616 - val_accuracy: 0.7726\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5205 - accuracy: 0.8648 - val_loss: 0.7571 - val_accuracy: 0.7672\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5110 - accuracy: 0.8798 - val_loss: 0.7670 - val_accuracy: 0.7575\n","Epoch 95/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5265 - accuracy: 0.8677 - val_loss: 0.8102 - val_accuracy: 0.7457\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5280 - accuracy: 0.8685 - val_loss: 0.7612 - val_accuracy: 0.7694\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5254 - accuracy: 0.8658 - val_loss: 0.7685 - val_accuracy: 0.7597\n","Epoch 98/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5006 - accuracy: 0.8831 - val_loss: 0.7625 - val_accuracy: 0.7554\n","Epoch 99/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5139 - accuracy: 0.8720 - val_loss: 0.8037 - val_accuracy: 0.7446\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5047 - accuracy: 0.8796 - val_loss: 0.8093 - val_accuracy: 0.7457\n","{'loss': [0.6794577240943909, 0.6455158591270447, 0.6360490322113037, 0.6418654322624207, 0.6347888708114624, 0.6281473636627197, 0.6309749484062195, 0.6402895450592041, 0.635575532913208, 0.6241216063499451, 0.6233506202697754, 0.6339194178581238, 0.6225578784942627, 0.6401197910308838, 0.6390832662582397, 0.6353204250335693, 0.638982355594635, 0.610864520072937, 0.6156620383262634, 0.6144176721572876, 0.6083143949508667, 0.6088589429855347, 0.6044884324073792, 0.6119825839996338, 0.6118292212486267, 0.6027266383171082, 0.6105895638465881, 0.5958653092384338, 0.5976697206497192, 0.6039558053016663, 0.6021155118942261, 0.6127416491508484, 0.6011316776275635, 0.5980535745620728, 0.6014111638069153, 0.6021771430969238, 0.5853706002235413, 0.5882373452186584, 0.591754674911499, 0.5942069292068481, 0.5909411907196045, 0.5886967182159424, 0.5755169987678528, 0.5759024024009705, 0.5741399526596069, 0.57463139295578, 0.5787606835365295, 0.5775001049041748, 0.5760802030563354, 0.57391756772995, 0.5725880265235901, 0.5610912442207336, 0.5722264051437378, 0.5805581212043762, 0.5770365595817566, 0.5648364424705505, 0.5580615997314453, 0.5666435956954956, 0.5578036904335022, 0.5540686845779419, 0.5536524057388306, 0.5633078813552856, 0.5468500256538391, 0.556003212928772, 0.5510568618774414, 0.5816551446914673, 0.606500506401062, 0.5756067037582397, 0.554431676864624, 0.5476122498512268, 0.5457833409309387, 0.5415075421333313, 0.5525676012039185, 0.5508611798286438, 0.5437363386154175, 0.5424518585205078, 0.536871612071991, 0.5337416529655457, 0.5360093712806702, 0.5270726680755615, 0.5302478075027466, 0.529427170753479, 0.5242651104927063, 0.529665470123291, 0.5351489782333374, 0.5275706648826599, 0.5262653231620789, 0.5514190196990967, 0.5268453359603882, 0.5327796936035156, 0.5232008695602417, 0.5182589292526245, 0.5205339789390564, 0.5109665989875793, 0.5265465378761292, 0.5280436277389526, 0.525361180305481, 0.5006093978881836, 0.5139217972755432, 0.5047012567520142], 'accuracy': [0.7847521305084229, 0.8073814511299133, 0.8165409564971924, 0.8098060488700867, 0.814116358757019, 0.8195043206214905, 0.8165409564971924, 0.8100754022598267, 0.8149245977401733, 0.8208512663841248, 0.8213900923728943, 0.8160021305084229, 0.8246228694915771, 0.8103448152542114, 0.806034505367279, 0.8116918206214905, 0.8146551847457886, 0.826508641242981, 0.8313577771186829, 0.8192349076271057, 0.829472005367279, 0.8300107717514038, 0.8353987336158752, 0.8192349076271057, 0.828125, 0.8289331793785095, 0.8302801847457886, 0.8380926847457886, 0.8310883641242981, 0.8316271305084229, 0.8329741358757019, 0.8273168206214905, 0.8283944129943848, 0.8289331793785095, 0.8289331793785095, 0.8324353694915771, 0.8448275923728943, 0.842133641242981, 0.8300107717514038, 0.8318965435028076, 0.8418642282485962, 0.8389008641242981, 0.8467133641242981, 0.8456357717514038, 0.8456357717514038, 0.8448275923728943, 0.8475215435028076, 0.8364762663841248, 0.8491379022598267, 0.849946141242981, 0.8467133641242981, 0.8556034564971924, 0.8389008641242981, 0.8332435488700867, 0.8461745977401733, 0.8558728694915771, 0.8564116358757019, 0.8504849076271057, 0.8507543206214905, 0.8569504022598267, 0.8601831793785095, 0.8483297228813171, 0.8617995977401733, 0.853178858757019, 0.8582974076271057, 0.8386314511299133, 0.8235452771186829, 0.8383620977401733, 0.850215494632721, 0.8572198152542114, 0.8601831793785095, 0.8591055870056152, 0.8556034564971924, 0.8569504022598267, 0.8574892282485962, 0.8599137663841248, 0.8615301847457886, 0.8647629022598267, 0.858027994632721, 0.876616358757019, 0.8617995977401733, 0.8712284564971924, 0.8677262663841248, 0.8601831793785095, 0.8561422228813171, 0.8720366358757019, 0.8701508641242981, 0.8553340435028076, 0.868534505367279, 0.8644935488700867, 0.8723060488700867, 0.8739224076271057, 0.8647629022598267, 0.8798491358757019, 0.8677262663841248, 0.868534505367279, 0.865840494632721, 0.8830819129943848, 0.8720366358757019, 0.8795797228813171], 'val_loss': [0.9401071667671204, 0.9441118836402893, 0.9508967995643616, 0.9529958367347717, 0.971169114112854, 0.9872122406959534, 1.0030674934387207, 1.0230906009674072, 1.041398286819458, 1.0551238059997559, 1.0937985181808472, 1.123579740524292, 1.1752279996871948, 1.2049553394317627, 1.1600514650344849, 1.1125569343566895, 1.0189108848571777, 0.9908896088600159, 0.8594661951065063, 0.8622959852218628, 0.8075905442237854, 0.796129047870636, 0.8126385807991028, 0.7846934795379639, 0.7492258548736572, 0.7854694724082947, 0.7336366772651672, 0.7279264330863953, 0.7346239686012268, 0.725750207901001, 0.7331922054290771, 0.7289642691612244, 0.7641997337341309, 0.722823977470398, 0.755426287651062, 0.7277212738990784, 0.728710949420929, 0.7437889575958252, 0.7453503012657166, 0.7275820970535278, 0.736765444278717, 0.7325296998023987, 0.7301037907600403, 0.7592158317565918, 0.7389960885047913, 0.74498450756073, 0.7291738986968994, 0.7384135127067566, 0.7467637658119202, 0.743985652923584, 0.736857533454895, 0.7434033155441284, 0.7388619780540466, 0.8136051297187805, 0.7371709942817688, 0.773687481880188, 0.7332300543785095, 0.7343557476997375, 0.7396509051322937, 0.7347408533096313, 0.7434791922569275, 0.7475683093070984, 0.7496327757835388, 0.7454968094825745, 0.7464739680290222, 0.8634067177772522, 0.7444210648536682, 0.7391378879547119, 0.7521478533744812, 0.7361476421356201, 0.7547442317008972, 0.7962660789489746, 0.7407090663909912, 0.8166264295578003, 0.7491779923439026, 0.7509986162185669, 0.7642039060592651, 0.7490844130516052, 0.7881460785865784, 0.764864981174469, 0.7595177888870239, 0.7636100053787231, 0.7519935965538025, 0.7731284499168396, 0.7665063738822937, 0.7554692029953003, 0.8174794316291809, 0.7538979053497314, 0.7552268505096436, 0.7772233486175537, 0.7919909954071045, 0.7615970373153687, 0.757133960723877, 0.7670111656188965, 0.8102211952209473, 0.7611889839172363, 0.768542468547821, 0.7624620795249939, 0.803661584854126, 0.8092731237411499], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.48599138855934143, 0.49568966031074524, 0.506465494632721, 0.5549569129943848, 0.5829741358757019, 0.6767241358757019, 0.6767241358757019, 0.725215494632721, 0.7349137663841248, 0.7489224076271057, 0.7586206793785095, 0.767241358757019, 0.7456896305084229, 0.7780172228813171, 0.78125, 0.774784505367279, 0.7823275923728943, 0.774784505367279, 0.7887930870056152, 0.7456896305084229, 0.7823275923728943, 0.7683189511299133, 0.7801724076271057, 0.7855603694915771, 0.7790948152542114, 0.7726293206214905, 0.7801724076271057, 0.7780172228813171, 0.774784505367279, 0.7780172228813171, 0.7543103694915771, 0.7737069129943848, 0.7769396305084229, 0.7801724076271057, 0.7726293206214905, 0.767241358757019, 0.767241358757019, 0.78125, 0.7801724076271057, 0.7683189511299133, 0.735991358757019, 0.7737069129943848, 0.7543103694915771, 0.7855603694915771, 0.7855603694915771, 0.7737069129943848, 0.774784505367279, 0.7780172228813171, 0.7823275923728943, 0.7683189511299133, 0.774784505367279, 0.7704741358757019, 0.7241379022598267, 0.764008641242981, 0.7737069129943848, 0.7715517282485962, 0.7758620977401733, 0.7715517282485962, 0.7456896305084229, 0.7758620977401733, 0.7316810488700867, 0.7650862336158752, 0.764008641242981, 0.7661637663841248, 0.7715517282485962, 0.7607758641242981, 0.764008641242981, 0.7629310488700867, 0.7618534564971924, 0.7704741358757019, 0.7586206793785095, 0.756465494632721, 0.7715517282485962, 0.743534505367279, 0.7769396305084229, 0.7737069129943848, 0.7618534564971924, 0.7575430870056152, 0.7726293206214905, 0.767241358757019, 0.7575430870056152, 0.7456896305084229, 0.7693965435028076, 0.7596982717514038, 0.7553879022598267, 0.7446120977401733, 0.7456896305084229]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.6668 - accuracy: 0.8033"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 64ms/step - loss: 0.6668 - accuracy: 0.8033 - val_loss: 0.9362 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6597 - accuracy: 0.8011 - val_loss: 0.9347 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6387 - accuracy: 0.8206 - val_loss: 0.9411 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6531 - accuracy: 0.8062 - val_loss: 0.9507 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6517 - accuracy: 0.8132 - val_loss: 0.9491 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6359 - accuracy: 0.8149 - val_loss: 0.9630 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6273 - accuracy: 0.8231 - val_loss: 0.9803 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6234 - accuracy: 0.8288 - val_loss: 0.9904 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6349 - accuracy: 0.8110 - val_loss: 1.0136 - val_accuracy: 0.4955\n","Epoch 10/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6216 - accuracy: 0.8237 - val_loss: 1.0249 - val_accuracy: 0.4955\n","Epoch 11/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6246 - accuracy: 0.8220 - val_loss: 1.0496 - val_accuracy: 0.4955\n","Epoch 12/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6189 - accuracy: 0.8311 - val_loss: 1.0612 - val_accuracy: 0.4977\n","Epoch 13/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6221 - accuracy: 0.8234 - val_loss: 1.0571 - val_accuracy: 0.5011\n","Epoch 14/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6165 - accuracy: 0.8243 - val_loss: 1.0716 - val_accuracy: 0.5090\n","Epoch 15/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.6299 - accuracy: 0.8189 - val_loss: 1.0206 - val_accuracy: 0.5271\n","Epoch 16/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6222 - accuracy: 0.8189 - val_loss: 1.0637 - val_accuracy: 0.5249\n","Epoch 17/100\n","28/28 [==============================] - 2s 75ms/step - loss: 0.6118 - accuracy: 0.8288 - val_loss: 0.9891 - val_accuracy: 0.5814\n","Epoch 18/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.6031 - accuracy: 0.8435 - val_loss: 0.9256 - val_accuracy: 0.6176\n","Epoch 19/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6023 - accuracy: 0.8350 - val_loss: 0.8367 - val_accuracy: 0.6855\n","Epoch 20/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6014 - accuracy: 0.8393 - val_loss: 0.8115 - val_accuracy: 0.6991\n","Epoch 21/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6009 - accuracy: 0.8356 - val_loss: 0.7963 - val_accuracy: 0.7104\n","Epoch 22/100\n","28/28 [==============================] - 3s 103ms/step - loss: 0.5960 - accuracy: 0.8376 - val_loss: 0.8033 - val_accuracy: 0.7376\n","Epoch 23/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6189 - accuracy: 0.8243 - val_loss: 0.8915 - val_accuracy: 0.7048\n","Epoch 24/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6267 - accuracy: 0.8206 - val_loss: 0.8580 - val_accuracy: 0.7195\n","Epoch 25/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.5964 - accuracy: 0.8342 - val_loss: 0.7847 - val_accuracy: 0.7489\n","Epoch 26/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5998 - accuracy: 0.8339 - val_loss: 0.8567 - val_accuracy: 0.7195\n","Epoch 27/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.6023 - accuracy: 0.8319 - val_loss: 0.7675 - val_accuracy: 0.7534\n","Epoch 28/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.5894 - accuracy: 0.8418 - val_loss: 0.7414 - val_accuracy: 0.7579\n","Epoch 29/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6042 - accuracy: 0.8350 - val_loss: 0.7386 - val_accuracy: 0.7557\n","Epoch 30/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5894 - accuracy: 0.8387 - val_loss: 0.7831 - val_accuracy: 0.7455\n","Epoch 31/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.5916 - accuracy: 0.8415 - val_loss: 0.7323 - val_accuracy: 0.7613\n","Epoch 32/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5932 - accuracy: 0.8373 - val_loss: 0.7366 - val_accuracy: 0.7545\n","Epoch 33/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5895 - accuracy: 0.8401 - val_loss: 0.7433 - val_accuracy: 0.7421\n","Epoch 34/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5969 - accuracy: 0.8322 - val_loss: 0.7668 - val_accuracy: 0.7455\n","Epoch 35/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5872 - accuracy: 0.8384 - val_loss: 0.7603 - val_accuracy: 0.7568\n","Epoch 36/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5835 - accuracy: 0.8413 - val_loss: 0.7572 - val_accuracy: 0.7568\n","Epoch 37/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5920 - accuracy: 0.8475 - val_loss: 0.7431 - val_accuracy: 0.7500\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5756 - accuracy: 0.8480 - val_loss: 0.7551 - val_accuracy: 0.7511\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5739 - accuracy: 0.8492 - val_loss: 0.7525 - val_accuracy: 0.7557\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5777 - accuracy: 0.8458 - val_loss: 0.7419 - val_accuracy: 0.7466\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5783 - accuracy: 0.8506 - val_loss: 0.7529 - val_accuracy: 0.7410\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5828 - accuracy: 0.8415 - val_loss: 0.7450 - val_accuracy: 0.7579\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5722 - accuracy: 0.8500 - val_loss: 0.7533 - val_accuracy: 0.7421\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5680 - accuracy: 0.8512 - val_loss: 0.7528 - val_accuracy: 0.7557\n","Epoch 45/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5749 - accuracy: 0.8432 - val_loss: 0.7587 - val_accuracy: 0.7511\n","Epoch 46/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.5756 - accuracy: 0.8466 - val_loss: 0.7744 - val_accuracy: 0.7624\n","Epoch 47/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5734 - accuracy: 0.8506 - val_loss: 0.7470 - val_accuracy: 0.7647\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5678 - accuracy: 0.8469 - val_loss: 0.7512 - val_accuracy: 0.7511\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5647 - accuracy: 0.8495 - val_loss: 0.8028 - val_accuracy: 0.7477\n","Epoch 50/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5784 - accuracy: 0.8362 - val_loss: 0.7486 - val_accuracy: 0.7534\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5753 - accuracy: 0.8466 - val_loss: 0.7507 - val_accuracy: 0.7387\n","Epoch 52/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5564 - accuracy: 0.8546 - val_loss: 0.7527 - val_accuracy: 0.7579\n","Epoch 53/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5600 - accuracy: 0.8548 - val_loss: 0.7719 - val_accuracy: 0.7545\n","Epoch 54/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5502 - accuracy: 0.8645 - val_loss: 0.7681 - val_accuracy: 0.7545\n","Epoch 55/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5550 - accuracy: 0.8551 - val_loss: 0.7734 - val_accuracy: 0.7466\n","Epoch 56/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5656 - accuracy: 0.8548 - val_loss: 0.7606 - val_accuracy: 0.7466\n","Epoch 57/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5661 - accuracy: 0.8520 - val_loss: 0.7761 - val_accuracy: 0.7319\n","Epoch 58/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5610 - accuracy: 0.8580 - val_loss: 0.7613 - val_accuracy: 0.7534\n","Epoch 59/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5534 - accuracy: 0.8580 - val_loss: 0.7727 - val_accuracy: 0.7500\n","Epoch 60/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5473 - accuracy: 0.8602 - val_loss: 0.8565 - val_accuracy: 0.7274\n","Epoch 61/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5695 - accuracy: 0.8503 - val_loss: 0.7769 - val_accuracy: 0.7376\n","Epoch 62/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5534 - accuracy: 0.8514 - val_loss: 0.7554 - val_accuracy: 0.7398\n","Epoch 63/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5434 - accuracy: 0.8630 - val_loss: 0.7888 - val_accuracy: 0.7319\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5682 - accuracy: 0.8509 - val_loss: 0.7684 - val_accuracy: 0.7500\n","Epoch 65/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5472 - accuracy: 0.8605 - val_loss: 0.7924 - val_accuracy: 0.7410\n","Epoch 66/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5578 - accuracy: 0.8410 - val_loss: 0.7674 - val_accuracy: 0.7489\n","Epoch 67/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5492 - accuracy: 0.8591 - val_loss: 0.7661 - val_accuracy: 0.7421\n","Epoch 68/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5365 - accuracy: 0.8664 - val_loss: 0.7781 - val_accuracy: 0.7557\n","Epoch 69/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5531 - accuracy: 0.8506 - val_loss: 0.7901 - val_accuracy: 0.7274\n","Epoch 70/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5680 - accuracy: 0.8478 - val_loss: 0.8359 - val_accuracy: 0.7376\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5541 - accuracy: 0.8557 - val_loss: 0.7912 - val_accuracy: 0.7330\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5353 - accuracy: 0.8642 - val_loss: 0.7705 - val_accuracy: 0.7432\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5331 - accuracy: 0.8713 - val_loss: 0.7715 - val_accuracy: 0.7353\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5404 - accuracy: 0.8591 - val_loss: 0.7835 - val_accuracy: 0.7545\n","Epoch 75/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5268 - accuracy: 0.8696 - val_loss: 0.8189 - val_accuracy: 0.7353\n","Epoch 76/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5305 - accuracy: 0.8713 - val_loss: 0.7638 - val_accuracy: 0.7534\n","Epoch 77/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5240 - accuracy: 0.8679 - val_loss: 0.7896 - val_accuracy: 0.7500\n","Epoch 78/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5187 - accuracy: 0.8744 - val_loss: 0.7743 - val_accuracy: 0.7421\n","Epoch 79/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5243 - accuracy: 0.8752 - val_loss: 0.7758 - val_accuracy: 0.7489\n","Epoch 80/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5244 - accuracy: 0.8698 - val_loss: 0.8029 - val_accuracy: 0.7477\n","Epoch 81/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5222 - accuracy: 0.8732 - val_loss: 0.7854 - val_accuracy: 0.7443\n","Epoch 82/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5166 - accuracy: 0.8766 - val_loss: 0.8030 - val_accuracy: 0.7511\n","Epoch 83/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5320 - accuracy: 0.8613 - val_loss: 0.7888 - val_accuracy: 0.7342\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5081 - accuracy: 0.8763 - val_loss: 0.7950 - val_accuracy: 0.7466\n","Epoch 85/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5194 - accuracy: 0.8639 - val_loss: 0.7895 - val_accuracy: 0.7421\n","Epoch 86/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5187 - accuracy: 0.8761 - val_loss: 0.7983 - val_accuracy: 0.7489\n","Epoch 87/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5220 - accuracy: 0.8693 - val_loss: 0.8749 - val_accuracy: 0.7036\n","Epoch 88/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5227 - accuracy: 0.8681 - val_loss: 0.7908 - val_accuracy: 0.7443\n","Epoch 89/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5198 - accuracy: 0.8729 - val_loss: 0.7959 - val_accuracy: 0.7523\n","Epoch 90/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5139 - accuracy: 0.8766 - val_loss: 0.7846 - val_accuracy: 0.7443\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4980 - accuracy: 0.8837 - val_loss: 0.7930 - val_accuracy: 0.7534\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5002 - accuracy: 0.8860 - val_loss: 0.8018 - val_accuracy: 0.7410\n","Epoch 93/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5085 - accuracy: 0.8758 - val_loss: 0.7963 - val_accuracy: 0.7455\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4918 - accuracy: 0.8891 - val_loss: 0.7947 - val_accuracy: 0.7410\n","Epoch 95/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5014 - accuracy: 0.8780 - val_loss: 0.7916 - val_accuracy: 0.7523\n","Epoch 96/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5110 - accuracy: 0.8786 - val_loss: 0.7903 - val_accuracy: 0.7455\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5202 - accuracy: 0.8679 - val_loss: 0.7963 - val_accuracy: 0.7410\n","Epoch 98/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4962 - accuracy: 0.8879 - val_loss: 0.7993 - val_accuracy: 0.7353\n","Epoch 99/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4985 - accuracy: 0.8826 - val_loss: 0.8014 - val_accuracy: 0.7387\n","Epoch 100/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5062 - accuracy: 0.8795 - val_loss: 0.7980 - val_accuracy: 0.7466\n","{'loss': [0.6667852997779846, 0.659682035446167, 0.6386910676956177, 0.6531398892402649, 0.6516574621200562, 0.6358974575996399, 0.6272584795951843, 0.6234179735183716, 0.6349000334739685, 0.6216332316398621, 0.6246117949485779, 0.6189230680465698, 0.6221223473548889, 0.6165282130241394, 0.6298696398735046, 0.6221758723258972, 0.6118159294128418, 0.6031295657157898, 0.6022934913635254, 0.601399302482605, 0.600853681564331, 0.596013605594635, 0.6189245581626892, 0.6267001628875732, 0.5963613390922546, 0.5997902154922485, 0.602306067943573, 0.589431643486023, 0.6042329668998718, 0.5893637537956238, 0.5916075706481934, 0.5931553244590759, 0.5894514322280884, 0.596920907497406, 0.5872164964675903, 0.5835478901863098, 0.5919955372810364, 0.5756376385688782, 0.5739147663116455, 0.5776726603507996, 0.5783222913742065, 0.5827949047088623, 0.5721595883369446, 0.5679693818092346, 0.5749306082725525, 0.5756205320358276, 0.573360025882721, 0.5677623152732849, 0.5647332072257996, 0.5783952474594116, 0.5753231048583984, 0.5563700795173645, 0.560005247592926, 0.5502076745033264, 0.5549733638763428, 0.5656358599662781, 0.5660748481750488, 0.56097811460495, 0.5533849596977234, 0.5472583770751953, 0.5695074200630188, 0.5534059405326843, 0.5434412956237793, 0.5682429075241089, 0.5471611022949219, 0.5577749609947205, 0.5491833686828613, 0.5365392565727234, 0.5530857443809509, 0.5680135488510132, 0.5541489720344543, 0.535347044467926, 0.5331071615219116, 0.5404327511787415, 0.5267791152000427, 0.5304936170578003, 0.5240267515182495, 0.5186896920204163, 0.5242837071418762, 0.5243954658508301, 0.5221962928771973, 0.5166172385215759, 0.5319890379905701, 0.5080732703208923, 0.5194088816642761, 0.5187053680419922, 0.5220023989677429, 0.5227465033531189, 0.5198187232017517, 0.5139109492301941, 0.4979602098464966, 0.5002205967903137, 0.5084854960441589, 0.49183014035224915, 0.5013503432273865, 0.510962963104248, 0.5201753377914429, 0.4961816966533661, 0.498455673456192, 0.5061997175216675], 'accuracy': [0.8033390045166016, 0.801075279712677, 0.8205999135971069, 0.8061686754226685, 0.8132427930831909, 0.8149405717849731, 0.8231465816497803, 0.8288058638572693, 0.8109790682792664, 0.8237125277519226, 0.8220146894454956, 0.8310695886611938, 0.823429524898529, 0.8242784142494202, 0.8189020752906799, 0.8189020752906799, 0.8288058638572693, 0.8435201048851013, 0.8350311517715454, 0.839275598526001, 0.835597038269043, 0.8375778198242188, 0.8242784142494202, 0.8205999135971069, 0.8341822028160095, 0.8338992595672607, 0.831918478012085, 0.8418223261833191, 0.8350311517715454, 0.8387096524238586, 0.8415393233299255, 0.83729487657547, 0.8401244878768921, 0.8322014808654785, 0.8384267091751099, 0.8412563800811768, 0.8474816083908081, 0.8480475544929504, 0.8491793870925903, 0.8457838296890259, 0.8505942225456238, 0.8415393233299255, 0.8500282764434814, 0.8511601686477661, 0.8432371020317078, 0.846632719039917, 0.8505942225456238, 0.8469156622886658, 0.8494623899459839, 0.8361629843711853, 0.846632719039917, 0.8545557260513306, 0.8548387289047241, 0.8644595146179199, 0.8551216721534729, 0.8548387289047241, 0.8520090579986572, 0.8579513430595398, 0.8579513430595398, 0.8602150678634644, 0.850311279296875, 0.8514431118965149, 0.8630446791648865, 0.8508771657943726, 0.8604980111122131, 0.8409733772277832, 0.8590831756591797, 0.8664402961730957, 0.8505942225456238, 0.8477645516395569, 0.8556876182556152, 0.8641765713691711, 0.8712506890296936, 0.8590831756591797, 0.8695529103279114, 0.8712506890296936, 0.8678551316261292, 0.8743633031845093, 0.8752122521400452, 0.8698358535766602, 0.8732314705848694, 0.8766270279884338, 0.8613469004631042, 0.8763440847396851, 0.8638936281204224, 0.8760611414909363, 0.8692699670791626, 0.8681380748748779, 0.8729485273361206, 0.8766270279884338, 0.8837012052536011, 0.8859649300575256, 0.8757781386375427, 0.8890775442123413, 0.8780418634414673, 0.8786078095436096, 0.8678551316261292, 0.8879456520080566, 0.8825693130493164, 0.8794566988945007], 'val_loss': [0.9362385869026184, 0.9347171187400818, 0.941107988357544, 0.9507257342338562, 0.9490721225738525, 0.9629718065261841, 0.9802809357643127, 0.9904090166091919, 1.0135985612869263, 1.0248697996139526, 1.0496066808700562, 1.0611677169799805, 1.0571086406707764, 1.071616291999817, 1.020578384399414, 1.0636842250823975, 0.9890876412391663, 0.9255738258361816, 0.8367200493812561, 0.8114919066429138, 0.7963165044784546, 0.8033037185668945, 0.8915436863899231, 0.8579603433609009, 0.7846881151199341, 0.8566868901252747, 0.7674567699432373, 0.7414271831512451, 0.7385782599449158, 0.7830696105957031, 0.7323347926139832, 0.7365636825561523, 0.7433387637138367, 0.7668161392211914, 0.7602732181549072, 0.7572113275527954, 0.7431257367134094, 0.755060613155365, 0.7524698376655579, 0.7419050335884094, 0.7528873682022095, 0.7450318336486816, 0.7532749772071838, 0.7528141140937805, 0.7586997747421265, 0.7744333744049072, 0.7469886541366577, 0.7512030005455017, 0.8028304576873779, 0.7485970854759216, 0.7507182955741882, 0.7526879906654358, 0.7718873620033264, 0.7680637836456299, 0.7733950614929199, 0.7605908513069153, 0.776096522808075, 0.7613208889961243, 0.7726919054985046, 0.8564537763595581, 0.7768788933753967, 0.7553820013999939, 0.7887973785400391, 0.7683606147766113, 0.792396605014801, 0.7674262523651123, 0.7660612463951111, 0.7781067490577698, 0.7900583148002625, 0.8359473943710327, 0.7912317514419556, 0.770458996295929, 0.7714994549751282, 0.7834657430648804, 0.8189396262168884, 0.7638258934020996, 0.7895687222480774, 0.7742636799812317, 0.775782585144043, 0.8028741478919983, 0.7853781580924988, 0.8029542565345764, 0.7887699604034424, 0.7950395941734314, 0.7894859910011292, 0.7982692122459412, 0.8748725652694702, 0.7907801270484924, 0.7959420680999756, 0.7846008539199829, 0.7930379509925842, 0.8018162250518799, 0.7963343858718872, 0.7946879267692566, 0.7916090488433838, 0.7902610898017883, 0.7963085174560547, 0.7992592453956604, 0.8013833165168762, 0.7979668378829956], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4977375566959381, 0.5011312365531921, 0.5090497732162476, 0.5271493196487427, 0.5248869061470032, 0.581447958946228, 0.6176470518112183, 0.685520350933075, 0.6990950107574463, 0.7104072570800781, 0.7375565767288208, 0.7047511339187622, 0.7194570302963257, 0.7488687634468079, 0.7194570302963257, 0.7533936500549316, 0.7579185366630554, 0.7556561231613159, 0.7454751133918762, 0.7613122463226318, 0.7545248866081238, 0.7420814633369446, 0.7454751133918762, 0.7567873597145081, 0.7567873597145081, 0.75, 0.7511312365531921, 0.7556561231613159, 0.7466063499450684, 0.7409502267837524, 0.7579185366630554, 0.7420814633369446, 0.7556561231613159, 0.7511312365531921, 0.7624434232711792, 0.7647058963775635, 0.7511312365531921, 0.7477375268936157, 0.7533936500549316, 0.7386877536773682, 0.7579185366630554, 0.7545248866081238, 0.7545248866081238, 0.7466063499450684, 0.7466063499450684, 0.7319004535675049, 0.7533936500549316, 0.75, 0.7273755669593811, 0.7375565767288208, 0.7398189902305603, 0.7319004535675049, 0.75, 0.7409502267837524, 0.7488687634468079, 0.7420814633369446, 0.7556561231613159, 0.7273755669593811, 0.7375565767288208, 0.733031690120697, 0.7432126402854919, 0.7352941036224365, 0.7545248866081238, 0.7352941036224365, 0.7533936500549316, 0.75, 0.7420814633369446, 0.7488687634468079, 0.7477375268936157, 0.7443438768386841, 0.7511312365531921, 0.7341628670692444, 0.7466063499450684, 0.7420814633369446, 0.7488687634468079, 0.7036198973655701, 0.7443438768386841, 0.7522624731063843, 0.7443438768386841, 0.7533936500549316, 0.7409502267837524, 0.7454751133918762, 0.7409502267837524, 0.7522624731063843, 0.7454751133918762, 0.7409502267837524, 0.7352941036224365, 0.7386877536773682, 0.7466063499450684]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.6680 - accuracy: 0.7948"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 57ms/step - loss: 0.6671 - accuracy: 0.7951 - val_loss: 0.9390 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6475 - accuracy: 0.8057 - val_loss: 0.9434 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6337 - accuracy: 0.8165 - val_loss: 0.9533 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6330 - accuracy: 0.8217 - val_loss: 0.9581 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6245 - accuracy: 0.8173 - val_loss: 0.9686 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6451 - accuracy: 0.8036 - val_loss: 0.9806 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6266 - accuracy: 0.8158 - val_loss: 1.0063 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6378 - accuracy: 0.8096 - val_loss: 1.0296 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6212 - accuracy: 0.8178 - val_loss: 1.0756 - val_accuracy: 0.4855\n","Epoch 10/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6287 - accuracy: 0.8150 - val_loss: 1.1040 - val_accuracy: 0.4855\n","Epoch 11/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6244 - accuracy: 0.8155 - val_loss: 1.1116 - val_accuracy: 0.4855\n","Epoch 12/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6236 - accuracy: 0.8165 - val_loss: 1.1447 - val_accuracy: 0.4876\n","Epoch 13/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.6127 - accuracy: 0.8230 - val_loss: 1.0968 - val_accuracy: 0.4959\n","Epoch 14/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6123 - accuracy: 0.8302 - val_loss: 1.0834 - val_accuracy: 0.5062\n","Epoch 15/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.6131 - accuracy: 0.8253 - val_loss: 1.0642 - val_accuracy: 0.5238\n","Epoch 16/100\n","31/31 [==============================] - 1s 41ms/step - loss: 0.6423 - accuracy: 0.8039 - val_loss: 1.0303 - val_accuracy: 0.5579\n","Epoch 17/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6220 - accuracy: 0.8202 - val_loss: 0.8945 - val_accuracy: 0.6488\n","Epoch 18/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6144 - accuracy: 0.8266 - val_loss: 0.8989 - val_accuracy: 0.6539\n","Epoch 19/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6130 - accuracy: 0.8258 - val_loss: 0.8456 - val_accuracy: 0.6901\n","Epoch 20/100\n","31/31 [==============================] - 4s 144ms/step - loss: 0.6029 - accuracy: 0.8274 - val_loss: 0.8473 - val_accuracy: 0.6983\n","Epoch 21/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6325 - accuracy: 0.8067 - val_loss: 0.8401 - val_accuracy: 0.7025\n","Epoch 22/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6140 - accuracy: 0.8222 - val_loss: 0.8304 - val_accuracy: 0.7097\n","Epoch 23/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6179 - accuracy: 0.8235 - val_loss: 0.8206 - val_accuracy: 0.7200\n","Epoch 24/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6087 - accuracy: 0.8264 - val_loss: 0.7838 - val_accuracy: 0.7283\n","Epoch 25/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5987 - accuracy: 0.8336 - val_loss: 0.7836 - val_accuracy: 0.7407\n","Epoch 26/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5953 - accuracy: 0.8344 - val_loss: 0.8217 - val_accuracy: 0.7376\n","Epoch 27/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6113 - accuracy: 0.8191 - val_loss: 0.7379 - val_accuracy: 0.7459\n","Epoch 28/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6008 - accuracy: 0.8367 - val_loss: 0.7406 - val_accuracy: 0.7459\n","Epoch 29/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5983 - accuracy: 0.8328 - val_loss: 0.7420 - val_accuracy: 0.7655\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5990 - accuracy: 0.8230 - val_loss: 0.7367 - val_accuracy: 0.7531\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6002 - accuracy: 0.8292 - val_loss: 0.7595 - val_accuracy: 0.7593\n","Epoch 32/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5911 - accuracy: 0.8367 - val_loss: 0.7466 - val_accuracy: 0.7490\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5934 - accuracy: 0.8388 - val_loss: 0.7410 - val_accuracy: 0.7583\n","Epoch 34/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5875 - accuracy: 0.8382 - val_loss: 0.7724 - val_accuracy: 0.7283\n","Epoch 35/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6010 - accuracy: 0.8253 - val_loss: 0.7446 - val_accuracy: 0.7438\n","Epoch 36/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6153 - accuracy: 0.8181 - val_loss: 0.7622 - val_accuracy: 0.7541\n","Epoch 37/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5993 - accuracy: 0.8341 - val_loss: 0.7929 - val_accuracy: 0.7045\n","Epoch 38/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5841 - accuracy: 0.8426 - val_loss: 0.7440 - val_accuracy: 0.7459\n","Epoch 39/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5773 - accuracy: 0.8465 - val_loss: 0.7832 - val_accuracy: 0.7138\n","Epoch 40/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5832 - accuracy: 0.8372 - val_loss: 0.7587 - val_accuracy: 0.7624\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5896 - accuracy: 0.8346 - val_loss: 0.7488 - val_accuracy: 0.7304\n","Epoch 42/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5850 - accuracy: 0.8416 - val_loss: 0.7432 - val_accuracy: 0.7541\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5786 - accuracy: 0.8388 - val_loss: 0.7481 - val_accuracy: 0.7603\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5938 - accuracy: 0.8292 - val_loss: 0.7922 - val_accuracy: 0.7138\n","Epoch 45/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6144 - accuracy: 0.8199 - val_loss: 0.7629 - val_accuracy: 0.7572\n","Epoch 46/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5915 - accuracy: 0.8310 - val_loss: 0.7626 - val_accuracy: 0.7293\n","Epoch 47/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5904 - accuracy: 0.8380 - val_loss: 0.7778 - val_accuracy: 0.7479\n","Epoch 48/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5973 - accuracy: 0.8264 - val_loss: 0.7449 - val_accuracy: 0.7510\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5819 - accuracy: 0.8426 - val_loss: 0.7580 - val_accuracy: 0.7603\n","Epoch 50/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5745 - accuracy: 0.8416 - val_loss: 0.7688 - val_accuracy: 0.7583\n","Epoch 51/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5714 - accuracy: 0.8442 - val_loss: 0.7518 - val_accuracy: 0.7438\n","Epoch 52/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5712 - accuracy: 0.8437 - val_loss: 0.7725 - val_accuracy: 0.7614\n","Epoch 53/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5796 - accuracy: 0.8359 - val_loss: 0.7363 - val_accuracy: 0.7676\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5863 - accuracy: 0.8284 - val_loss: 0.7523 - val_accuracy: 0.7448\n","Epoch 55/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5721 - accuracy: 0.8465 - val_loss: 0.7609 - val_accuracy: 0.7242\n","Epoch 56/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5676 - accuracy: 0.8481 - val_loss: 0.7500 - val_accuracy: 0.7552\n","Epoch 57/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5599 - accuracy: 0.8473 - val_loss: 0.7571 - val_accuracy: 0.7614\n","Epoch 58/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5690 - accuracy: 0.8437 - val_loss: 0.7589 - val_accuracy: 0.7438\n","Epoch 59/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5653 - accuracy: 0.8486 - val_loss: 0.7792 - val_accuracy: 0.7572\n","Epoch 60/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5840 - accuracy: 0.8333 - val_loss: 0.8392 - val_accuracy: 0.6890\n","Epoch 61/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5751 - accuracy: 0.8424 - val_loss: 0.7504 - val_accuracy: 0.7479\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5539 - accuracy: 0.8592 - val_loss: 0.7464 - val_accuracy: 0.7645\n","Epoch 63/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5523 - accuracy: 0.8605 - val_loss: 0.7594 - val_accuracy: 0.7386\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5584 - accuracy: 0.8540 - val_loss: 0.7555 - val_accuracy: 0.7603\n","Epoch 65/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5473 - accuracy: 0.8568 - val_loss: 0.7549 - val_accuracy: 0.7645\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5538 - accuracy: 0.8548 - val_loss: 0.7706 - val_accuracy: 0.7634\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5440 - accuracy: 0.8605 - val_loss: 0.7531 - val_accuracy: 0.7500\n","Epoch 68/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5562 - accuracy: 0.8530 - val_loss: 0.7638 - val_accuracy: 0.7614\n","Epoch 69/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5723 - accuracy: 0.8362 - val_loss: 0.7895 - val_accuracy: 0.7231\n","Epoch 70/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5571 - accuracy: 0.8494 - val_loss: 0.7504 - val_accuracy: 0.7634\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5715 - accuracy: 0.8385 - val_loss: 0.7942 - val_accuracy: 0.7521\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5621 - accuracy: 0.8416 - val_loss: 0.7589 - val_accuracy: 0.7459\n","Epoch 73/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5510 - accuracy: 0.8584 - val_loss: 0.7711 - val_accuracy: 0.7572\n","Epoch 74/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5388 - accuracy: 0.8623 - val_loss: 0.7543 - val_accuracy: 0.7428\n","Epoch 75/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5393 - accuracy: 0.8592 - val_loss: 0.7806 - val_accuracy: 0.7283\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5701 - accuracy: 0.8408 - val_loss: 0.7804 - val_accuracy: 0.7355\n","Epoch 77/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5430 - accuracy: 0.8649 - val_loss: 0.7954 - val_accuracy: 0.7159\n","Epoch 78/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5348 - accuracy: 0.8716 - val_loss: 0.7744 - val_accuracy: 0.7324\n","Epoch 79/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5482 - accuracy: 0.8530 - val_loss: 0.8132 - val_accuracy: 0.7490\n","Epoch 80/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5403 - accuracy: 0.8563 - val_loss: 0.7656 - val_accuracy: 0.7552\n","Epoch 81/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5322 - accuracy: 0.8667 - val_loss: 0.8351 - val_accuracy: 0.7076\n","Epoch 82/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5442 - accuracy: 0.8571 - val_loss: 0.7677 - val_accuracy: 0.7634\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5460 - accuracy: 0.8574 - val_loss: 0.7955 - val_accuracy: 0.7304\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5248 - accuracy: 0.8677 - val_loss: 0.7647 - val_accuracy: 0.7614\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5344 - accuracy: 0.8589 - val_loss: 0.7776 - val_accuracy: 0.7386\n","Epoch 86/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5389 - accuracy: 0.8574 - val_loss: 0.7685 - val_accuracy: 0.7624\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5332 - accuracy: 0.8651 - val_loss: 0.8116 - val_accuracy: 0.7583\n","Epoch 88/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5314 - accuracy: 0.8636 - val_loss: 0.7690 - val_accuracy: 0.7459\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5353 - accuracy: 0.8558 - val_loss: 0.8821 - val_accuracy: 0.6839\n","Epoch 90/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5357 - accuracy: 0.8579 - val_loss: 0.7707 - val_accuracy: 0.7459\n","Epoch 91/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5452 - accuracy: 0.8561 - val_loss: 0.8130 - val_accuracy: 0.7531\n","Epoch 92/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5335 - accuracy: 0.8687 - val_loss: 0.7747 - val_accuracy: 0.7417\n","Epoch 93/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5253 - accuracy: 0.8677 - val_loss: 0.7868 - val_accuracy: 0.7231\n","Epoch 94/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5260 - accuracy: 0.8638 - val_loss: 0.7645 - val_accuracy: 0.7676\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5343 - accuracy: 0.8610 - val_loss: 0.7715 - val_accuracy: 0.7541\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5103 - accuracy: 0.8749 - val_loss: 0.7656 - val_accuracy: 0.7386\n","Epoch 97/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5281 - accuracy: 0.8674 - val_loss: 0.7584 - val_accuracy: 0.7510\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5190 - accuracy: 0.8700 - val_loss: 0.8119 - val_accuracy: 0.7128\n","Epoch 99/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5208 - accuracy: 0.8695 - val_loss: 0.8464 - val_accuracy: 0.7118\n","Epoch 100/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5234 - accuracy: 0.8713 - val_loss: 0.7705 - val_accuracy: 0.7572\n","{'loss': [0.6671146750450134, 0.6475487947463989, 0.6336900591850281, 0.6330254673957825, 0.6244936585426331, 0.6451030969619751, 0.6265954375267029, 0.6377593278884888, 0.621201753616333, 0.6287320852279663, 0.6243736147880554, 0.6235690712928772, 0.6127183437347412, 0.6122522354125977, 0.6131037473678589, 0.6423375010490417, 0.6220171451568604, 0.6144092082977295, 0.613042950630188, 0.6028545498847961, 0.6324991583824158, 0.614048421382904, 0.617922842502594, 0.6086910367012024, 0.5986728072166443, 0.5953477025032043, 0.6112883687019348, 0.6008336544036865, 0.5982627272605896, 0.5989903807640076, 0.6001644134521484, 0.5911040902137756, 0.5933817625045776, 0.5874570608139038, 0.6010222434997559, 0.6153199076652527, 0.5992535352706909, 0.5840996503829956, 0.5773473381996155, 0.5831692814826965, 0.5896382927894592, 0.5849729180335999, 0.5785910487174988, 0.5938379764556885, 0.614429235458374, 0.5915334224700928, 0.5903662443161011, 0.5973401665687561, 0.581855297088623, 0.5745378732681274, 0.5714125037193298, 0.5712153911590576, 0.5795942544937134, 0.5862797498703003, 0.5721009373664856, 0.567592203617096, 0.5599326491355896, 0.569006621837616, 0.565259575843811, 0.5839804410934448, 0.575053334236145, 0.5539122223854065, 0.5522782802581787, 0.5584176182746887, 0.5473387837409973, 0.5538422465324402, 0.5439653396606445, 0.5561859011650085, 0.5722734332084656, 0.5570911169052124, 0.5715289115905762, 0.5621499419212341, 0.5510120987892151, 0.5388157963752747, 0.5393026471138, 0.5701353549957275, 0.5429636240005493, 0.534828245639801, 0.5481504797935486, 0.5402585864067078, 0.5322082042694092, 0.5441844463348389, 0.5459557175636292, 0.5247816443443298, 0.5344124436378479, 0.5389498472213745, 0.5331711769104004, 0.5313530564308167, 0.5353305339813232, 0.5357410311698914, 0.5451655983924866, 0.5334895849227905, 0.5252750515937805, 0.5260356664657593, 0.5343015789985657, 0.5102517604827881, 0.5281111001968384, 0.5189751982688904, 0.5208160877227783, 0.523361086845398], 'accuracy': [0.7950904369354248, 0.8056847453117371, 0.8165374398231506, 0.8217054009437561, 0.8173126578330994, 0.8036175966262817, 0.8157622814178467, 0.8095607161521912, 0.817829430103302, 0.814987063407898, 0.8155038952827454, 0.8165374398231506, 0.8229973912239075, 0.830232560634613, 0.8253229856491089, 0.8038759827613831, 0.8201550245285034, 0.8266149759292603, 0.8258398175239563, 0.827390193939209, 0.8067183494567871, 0.8222222328186035, 0.8235142230987549, 0.8263565897941589, 0.8335917592048645, 0.8343669176101685, 0.8191214203834534, 0.8366925120353699, 0.8328165411949158, 0.8229973912239075, 0.829198956489563, 0.8366925120353699, 0.8387596607208252, 0.8382428884506226, 0.8253229856491089, 0.8180878758430481, 0.8341085314750671, 0.8426356315612793, 0.8465116024017334, 0.8372092843055725, 0.8346253037452698, 0.841602087020874, 0.8387596607208252, 0.829198956489563, 0.8198966383934021, 0.8310077786445618, 0.8379845023155212, 0.8263565897941589, 0.8426356315612793, 0.841602087020874, 0.8441860675811768, 0.8436692357063293, 0.8359172940254211, 0.828423798084259, 0.8465116024017334, 0.8480620384216309, 0.8472868204116821, 0.8436692357063293, 0.8485788106918335, 0.8333333134651184, 0.842377245426178, 0.8591731190681458, 0.8604651093482971, 0.8540051579475403, 0.8568475246429443, 0.854780375957489, 0.8604651093482971, 0.8529715538024902, 0.8361757397651672, 0.8493540287017822, 0.8385012745857239, 0.841602087020874, 0.8583979606628418, 0.8622739315032959, 0.8591731190681458, 0.8408268690109253, 0.8648578524589539, 0.8715762495994568, 0.8529715538024902, 0.8563307523727417, 0.8666666746139526, 0.8571059703826904, 0.8573643565177917, 0.8677002787590027, 0.8589147329330444, 0.8573643565177917, 0.8651162981987, 0.8635658621788025, 0.8558139801025391, 0.8578811287879944, 0.8560723662376404, 0.868733823299408, 0.8677002787590027, 0.8638243079185486, 0.8609819412231445, 0.8749353885650635, 0.8674418330192566, 0.8700258135795593, 0.8695090413093567, 0.8713178038597107], 'val_loss': [0.9390021562576294, 0.9434422254562378, 0.9532904624938965, 0.9580723643302917, 0.9686355590820312, 0.9806362986564636, 1.0062981843948364, 1.0296376943588257, 1.0755945444107056, 1.1040105819702148, 1.111556887626648, 1.1447291374206543, 1.0968401432037354, 1.0833512544631958, 1.064154863357544, 1.0302687883377075, 0.8945220708847046, 0.8989247679710388, 0.8456071615219116, 0.8472523093223572, 0.8401337265968323, 0.8303865194320679, 0.8205808401107788, 0.7838200330734253, 0.7836204767227173, 0.8216665387153625, 0.7379140257835388, 0.7405717968940735, 0.7419542670249939, 0.7367435693740845, 0.7594826817512512, 0.7466108798980713, 0.7409701943397522, 0.7723528146743774, 0.7445608973503113, 0.7621708512306213, 0.79289710521698, 0.7439541220664978, 0.783191978931427, 0.7586648464202881, 0.7488486170768738, 0.7431877851486206, 0.7481082677841187, 0.7921635508537292, 0.7628878355026245, 0.7626156210899353, 0.7777905464172363, 0.7449309825897217, 0.7580475211143494, 0.7687828540802002, 0.7518025636672974, 0.7724968791007996, 0.7363307476043701, 0.752348780632019, 0.7609104514122009, 0.749983549118042, 0.7570725083351135, 0.7589382529258728, 0.7791802287101746, 0.8392335176467896, 0.7503518462181091, 0.746443510055542, 0.7593554854393005, 0.7554794549942017, 0.7548734545707703, 0.7705750465393066, 0.753133237361908, 0.7638185024261475, 0.7894600033760071, 0.7504457831382751, 0.7941865921020508, 0.7589157819747925, 0.771113395690918, 0.7542746067047119, 0.780634880065918, 0.7804294228553772, 0.7954246401786804, 0.7744444608688354, 0.8132094144821167, 0.7655556797981262, 0.8350580930709839, 0.767690896987915, 0.7954800128936768, 0.7647120952606201, 0.7775529026985168, 0.7684743404388428, 0.8115658760070801, 0.7690045237541199, 0.882148027420044, 0.7706531882286072, 0.8129519820213318, 0.7746626138687134, 0.7867925763130188, 0.7645204663276672, 0.7714858055114746, 0.7656089067459106, 0.7583565711975098, 0.8118624687194824, 0.8463700413703918, 0.7704535126686096], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4876033067703247, 0.4958677589893341, 0.5061983466148376, 0.5237603187561035, 0.557851254940033, 0.6487603187561035, 0.6539255976676941, 0.6900826692581177, 0.6983470916748047, 0.702479362487793, 0.7097107172012329, 0.7200413346290588, 0.7283057570457458, 0.7407024502754211, 0.7376033067703247, 0.7458677887916565, 0.7458677887916565, 0.7654958963394165, 0.7530992031097412, 0.7592975497245789, 0.7489669322967529, 0.7582644820213318, 0.7283057570457458, 0.7438016533851624, 0.7541322112083435, 0.7045454382896423, 0.7458677887916565, 0.7138429880142212, 0.7623966932296753, 0.73037189245224, 0.7541322112083435, 0.7603305578231812, 0.7138429880142212, 0.7572314143180847, 0.7293388247489929, 0.7479338645935059, 0.7510330677032471, 0.7603305578231812, 0.7582644820213318, 0.7438016533851624, 0.7613636255264282, 0.7675619721412659, 0.7448347210884094, 0.7241735458374023, 0.7551652789115906, 0.7613636255264282, 0.7438016533851624, 0.7572314143180847, 0.6890496015548706, 0.7479338645935059, 0.7644628286361694, 0.7386363744735718, 0.7603305578231812, 0.7644628286361694, 0.7634297609329224, 0.75, 0.7613636255264282, 0.7231404781341553, 0.7634297609329224, 0.7520661354064941, 0.7458677887916565, 0.7572314143180847, 0.7427685856819153, 0.7283057570457458, 0.7355371713638306, 0.7159090638160706, 0.7324380278587341, 0.7489669322967529, 0.7551652789115906, 0.7076446413993835, 0.7634297609329224, 0.73037189245224, 0.7613636255264282, 0.7386363744735718, 0.7623966932296753, 0.7582644820213318, 0.7458677887916565, 0.68388432264328, 0.7458677887916565, 0.7530992031097412, 0.7417355179786682, 0.7231404781341553, 0.7675619721412659, 0.7541322112083435, 0.7386363744735718, 0.7510330677032471, 0.7128099203109741, 0.711776852607727, 0.7572314143180847]}\n","32/32 [==============================] - 1s 4ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_gru"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":519},"collapsed":true,"id":"kleLoWSV5B7Y","executionInfo":{"status":"ok","timestamp":1717531573757,"user_tz":-360,"elapsed":31,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}},"outputId":"a77ac3a0-0962-4550-b766-2456b01ea3ce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision    Recall        F1  Sensitivity  Specificity  \\\n","0        0  0.603015   0.592481  0.659966  0.624406     0.659966     0.546064   \n","1        1  0.661017   0.670149  0.634181  0.651669     0.634181     0.687853   \n","2        2  0.658635   0.670259  0.624498  0.646570     0.624498     0.692771   \n","3        0  0.621441   0.610350  0.671692  0.639553     0.671692     0.571189   \n","4        1  0.673023   0.699837  0.605932  0.649508     0.605932     0.740113   \n","5        2  0.669679   0.661568  0.694779  0.677767     0.694779     0.644578   \n","6        0  0.647404   0.639683  0.675042  0.656887     0.675042     0.619765   \n","7        1  0.695621   0.720191  0.639831  0.677636     0.639831     0.751412   \n","8        2  0.695783   0.682927  0.730924  0.706111     0.730924     0.660643   \n","9        0  0.670854   0.658879  0.708543  0.682809     0.708543     0.633166   \n","10       1  0.699859   0.715373  0.663842  0.688645     0.663842     0.735876   \n","11       2  0.701807   0.687850  0.738956  0.712488     0.738956     0.664659   \n","12       0  0.705193   0.716814  0.678392  0.697074     0.678392     0.731993   \n","13       1  0.730226   0.744745  0.700565  0.721980     0.700565     0.759887   \n","14       2  0.715863   0.692308  0.777108  0.732261     0.777108     0.654618   \n","\n","       Kappa  \n","0   0.206030  \n","1   0.322034  \n","2   0.317269  \n","3   0.242881  \n","4   0.346045  \n","5   0.339357  \n","6   0.294807  \n","7   0.391243  \n","8   0.391566  \n","9   0.341709  \n","10  0.399718  \n","11  0.403614  \n","12  0.410385  \n","13  0.460452  \n","14  0.431727  "],"text/html":["\n","  <div id=\"df-45554f1b-02da-460f-a503-39db64f611a0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.603015</td>\n","      <td>0.592481</td>\n","      <td>0.659966</td>\n","      <td>0.624406</td>\n","      <td>0.659966</td>\n","      <td>0.546064</td>\n","      <td>0.206030</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.661017</td>\n","      <td>0.670149</td>\n","      <td>0.634181</td>\n","      <td>0.651669</td>\n","      <td>0.634181</td>\n","      <td>0.687853</td>\n","      <td>0.322034</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.658635</td>\n","      <td>0.670259</td>\n","      <td>0.624498</td>\n","      <td>0.646570</td>\n","      <td>0.624498</td>\n","      <td>0.692771</td>\n","      <td>0.317269</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.621441</td>\n","      <td>0.610350</td>\n","      <td>0.671692</td>\n","      <td>0.639553</td>\n","      <td>0.671692</td>\n","      <td>0.571189</td>\n","      <td>0.242881</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.673023</td>\n","      <td>0.699837</td>\n","      <td>0.605932</td>\n","      <td>0.649508</td>\n","      <td>0.605932</td>\n","      <td>0.740113</td>\n","      <td>0.346045</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.669679</td>\n","      <td>0.661568</td>\n","      <td>0.694779</td>\n","      <td>0.677767</td>\n","      <td>0.694779</td>\n","      <td>0.644578</td>\n","      <td>0.339357</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.647404</td>\n","      <td>0.639683</td>\n","      <td>0.675042</td>\n","      <td>0.656887</td>\n","      <td>0.675042</td>\n","      <td>0.619765</td>\n","      <td>0.294807</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.695621</td>\n","      <td>0.720191</td>\n","      <td>0.639831</td>\n","      <td>0.677636</td>\n","      <td>0.639831</td>\n","      <td>0.751412</td>\n","      <td>0.391243</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.695783</td>\n","      <td>0.682927</td>\n","      <td>0.730924</td>\n","      <td>0.706111</td>\n","      <td>0.730924</td>\n","      <td>0.660643</td>\n","      <td>0.391566</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.670854</td>\n","      <td>0.658879</td>\n","      <td>0.708543</td>\n","      <td>0.682809</td>\n","      <td>0.708543</td>\n","      <td>0.633166</td>\n","      <td>0.341709</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.699859</td>\n","      <td>0.715373</td>\n","      <td>0.663842</td>\n","      <td>0.688645</td>\n","      <td>0.663842</td>\n","      <td>0.735876</td>\n","      <td>0.399718</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.701807</td>\n","      <td>0.687850</td>\n","      <td>0.738956</td>\n","      <td>0.712488</td>\n","      <td>0.738956</td>\n","      <td>0.664659</td>\n","      <td>0.403614</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.705193</td>\n","      <td>0.716814</td>\n","      <td>0.678392</td>\n","      <td>0.697074</td>\n","      <td>0.678392</td>\n","      <td>0.731993</td>\n","      <td>0.410385</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.730226</td>\n","      <td>0.744745</td>\n","      <td>0.700565</td>\n","      <td>0.721980</td>\n","      <td>0.700565</td>\n","      <td>0.759887</td>\n","      <td>0.460452</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.715863</td>\n","      <td>0.692308</td>\n","      <td>0.777108</td>\n","      <td>0.732261</td>\n","      <td>0.777108</td>\n","      <td>0.654618</td>\n","      <td>0.431727</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45554f1b-02da-460f-a503-39db64f611a0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-45554f1b-02da-460f-a503-39db64f611a0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-45554f1b-02da-460f-a503-39db64f611a0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9c1a1cdb-b8fc-4f6f-89ec-4060cb89abfd\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c1a1cdb-b8fc-4f6f-89ec-4060cb89abfd')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9c1a1cdb-b8fc-4f6f-89ec-4060cb89abfd button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_1a811240-6812-4ed9-8ca7-b94ffa52ccd9\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metrics_df_gru')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_1a811240-6812-4ed9-8ca7-b94ffa52ccd9 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('metrics_df_gru');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"metrics_df_gru","summary":"{\n  \"name\": \"metrics_df_gru\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.034959274620692635,\n        \"min\": 0.6030150753768844,\n        \"max\": 0.730225988700565,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6708542713567839,\n          0.7018072289156626,\n          0.6030150753768844\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.041450125936160494,\n        \"min\": 0.5924812030075188,\n        \"max\": 0.7447447447447447,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6588785046728972,\n          0.6878504672897197,\n          0.5924812030075188\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.046284836341458496,\n        \"min\": 0.6059322033898306,\n        \"max\": 0.7771084337349398,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7085427135678392,\n          0.7389558232931727,\n          0.6599664991624791\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03234450526686257,\n        \"min\": 0.624405705229794,\n        \"max\": 0.7322611163670766,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6828087167070218,\n          0.712487899322362,\n          0.624405705229794\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.046284836341458496,\n        \"min\": 0.6059322033898306,\n        \"max\": 0.7771084337349398,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7085427135678392,\n          0.7389558232931727,\n          0.6599664991624791\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0646495874848575,\n        \"min\": 0.5460636515912898,\n        \"max\": 0.7598870056497176,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6331658291457286,\n          0.6646586345381527,\n          0.5460636515912898\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06991854924138527,\n        \"min\": 0.20603015075376885,\n        \"max\": 0.46045197740113,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.3417085427135679,\n          0.4036144578313253,\n          0.20603015075376885\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["metrics_df_gru.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/DWT/CNN_GRU/Beta_DWT_GRU.csv', index = False)"],"metadata":{"id":"QWSx6aHR5Bwr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('hello')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5lZgATCgsgVz","executionInfo":{"status":"ok","timestamp":1717532140530,"user_tz":-360,"elapsed":655,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}},"outputId":"9eda2223-8bab-4339-d87c-730b191b4ae8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["hello\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"mbkFOFhA5J5x"},"execution_count":null,"outputs":[]}]}