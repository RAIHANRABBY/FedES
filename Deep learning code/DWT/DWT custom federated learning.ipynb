{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Mbfw8uvdftFM"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"INiFJfLjgOkx"},"outputs":[],"source":["from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lYo2Uq77gQSH"},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score, cross_val_predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g66575_xgVzz"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPool1D, Flatten, Dropout,LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19894,"status":"ok","timestamp":1717679159573,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"MOCNWlamfr3v","outputId":"8ca605dc-09c4-484f-971a-621f64b6c398"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iNy9eOGMf2qO"},"outputs":[],"source":["# Raw_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/only data/raw_data.npz'\n","\n","Theta_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/DWT/Raw/DWT.npz'\n","\n","\n","\n","# RAW = np.load(Raw_data, allow_pickle=True)  # Allow loading pickled object arrays\n","# X = RAW['X'].astype('float64')\n","# Y = RAW['Y'].astype('float64')\n","# group = RAW['Group'].astype('float64')"]},{"cell_type":"markdown","metadata":{"id":"PzeABzSyHgKg"},"source":["This is a good performing model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Os2jd5SO1jf"},"outputs":[],"source":["# %%capture\n","# !pip install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tbr8rHq9PnM4"},"outputs":[],"source":["# import wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iwbCosHcPohF"},"outputs":[],"source":["# !wandb login"]},{"cell_type":"markdown","metadata":{"id":"6DhAYwXUSE9z"},"source":["# CNN-LSTM"]},{"cell_type":"code","source":["%%capture\n","!pip install tensorflow_addons"],"metadata":{"id":"DRQggaNe8Ahn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow_addons as tfa\n","from keras.optimizers import RMSprop, Adam"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5fe9OzBN8RY6","executionInfo":{"status":"ok","timestamp":1717679166654,"user_tz":-360,"elapsed":574,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"c333018f-113b-4222-df4f-bc5d666a6b90"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VvjC2xCQNHLP"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Total/CNN_LSTM/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Total/CNN_LSTM/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVURUnmYNNNg","outputId":"5774515f-6408-46b1-d4e3-b7b1d5c483e4","executionInfo":{"status":"ok","timestamp":1717680504004,"user_tz":-360,"elapsed":1332821,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 1.8182 - accuracy: 0.5677"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 18s 66ms/step - loss: 1.8177 - accuracy: 0.5735 - val_loss: 1.8124 - val_accuracy: 0.4860\n","Epoch 2/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.8011 - accuracy: 0.6818 - val_loss: 1.8002 - val_accuracy: 0.4817\n","Epoch 3/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.7804 - accuracy: 0.7147 - val_loss: 1.7878 - val_accuracy: 0.6519\n","Epoch 4/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.7508 - accuracy: 0.7400 - val_loss: 1.7750 - val_accuracy: 0.6832\n","Epoch 5/100\n","29/29 [==============================] - 1s 31ms/step - loss: 1.7073 - accuracy: 0.7470 - val_loss: 1.7602 - val_accuracy: 0.7220\n","Epoch 6/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.6550 - accuracy: 0.7543 - val_loss: 1.7426 - val_accuracy: 0.7220\n","Epoch 7/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.6024 - accuracy: 0.7627 - val_loss: 1.7197 - val_accuracy: 0.7651\n","Epoch 8/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.5663 - accuracy: 0.7605 - val_loss: 1.6985 - val_accuracy: 0.7425\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.5461 - accuracy: 0.7672 - val_loss: 1.6770 - val_accuracy: 0.7435\n","Epoch 10/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.5279 - accuracy: 0.7680 - val_loss: 1.6535 - val_accuracy: 0.7640\n","Epoch 11/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.5119 - accuracy: 0.7748 - val_loss: 1.6345 - val_accuracy: 0.7457\n","Epoch 12/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.5030 - accuracy: 0.7737 - val_loss: 1.6078 - val_accuracy: 0.7683\n","Epoch 13/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.4918 - accuracy: 0.7721 - val_loss: 1.5841 - val_accuracy: 0.7737\n","Epoch 14/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4790 - accuracy: 0.7796 - val_loss: 1.5600 - val_accuracy: 0.7737\n","Epoch 15/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.4667 - accuracy: 0.7807 - val_loss: 1.5356 - val_accuracy: 0.7791\n","Epoch 16/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4560 - accuracy: 0.7834 - val_loss: 1.5098 - val_accuracy: 0.7748\n","Epoch 17/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.4439 - accuracy: 0.7880 - val_loss: 1.4946 - val_accuracy: 0.7716\n","Epoch 18/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.4366 - accuracy: 0.7880 - val_loss: 1.4677 - val_accuracy: 0.7845\n","Epoch 19/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4256 - accuracy: 0.7904 - val_loss: 1.4573 - val_accuracy: 0.7726\n","Epoch 20/100\n","29/29 [==============================] - 1s 31ms/step - loss: 1.4190 - accuracy: 0.7942 - val_loss: 1.4324 - val_accuracy: 0.7899\n","Epoch 21/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.4105 - accuracy: 0.7909 - val_loss: 1.4216 - val_accuracy: 0.7877\n","Epoch 22/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3992 - accuracy: 0.7969 - val_loss: 1.4090 - val_accuracy: 0.7856\n","Epoch 23/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.3937 - accuracy: 0.7966 - val_loss: 1.4004 - val_accuracy: 0.7877\n","Epoch 24/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3842 - accuracy: 0.7923 - val_loss: 1.3998 - val_accuracy: 0.7802\n","Epoch 25/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3756 - accuracy: 0.7958 - val_loss: 1.3874 - val_accuracy: 0.7888\n","Epoch 26/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3671 - accuracy: 0.7993 - val_loss: 1.3771 - val_accuracy: 0.7899\n","Epoch 27/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3584 - accuracy: 0.7963 - val_loss: 1.3716 - val_accuracy: 0.7866\n","Epoch 28/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3507 - accuracy: 0.7961 - val_loss: 1.3657 - val_accuracy: 0.7856\n","Epoch 29/100\n","29/29 [==============================] - 1s 31ms/step - loss: 1.3427 - accuracy: 0.7990 - val_loss: 1.3597 - val_accuracy: 0.7866\n","Epoch 30/100\n","29/29 [==============================] - 1s 36ms/step - loss: 1.3378 - accuracy: 0.7958 - val_loss: 1.3578 - val_accuracy: 0.7845\n","Epoch 31/100\n","29/29 [==============================] - 1s 52ms/step - loss: 1.3313 - accuracy: 0.8052 - val_loss: 1.3462 - val_accuracy: 0.7931\n","Epoch 32/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3218 - accuracy: 0.8033 - val_loss: 1.3401 - val_accuracy: 0.7899\n","Epoch 33/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.3161 - accuracy: 0.8028 - val_loss: 1.3343 - val_accuracy: 0.7942\n","Epoch 34/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.3132 - accuracy: 0.7988 - val_loss: 1.3303 - val_accuracy: 0.7845\n","Epoch 35/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.3005 - accuracy: 0.8031 - val_loss: 1.3225 - val_accuracy: 0.7877\n","Epoch 36/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.2937 - accuracy: 0.8028 - val_loss: 1.3157 - val_accuracy: 0.7931\n","Epoch 37/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.2842 - accuracy: 0.8066 - val_loss: 1.3119 - val_accuracy: 0.7856\n","Epoch 38/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.2795 - accuracy: 0.8055 - val_loss: 1.3037 - val_accuracy: 0.7877\n","Epoch 39/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.2725 - accuracy: 0.8066 - val_loss: 1.2971 - val_accuracy: 0.7942\n","Epoch 40/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.2702 - accuracy: 0.8017 - val_loss: 1.2937 - val_accuracy: 0.7856\n","Epoch 41/100\n","29/29 [==============================] - 1s 39ms/step - loss: 1.2607 - accuracy: 0.8058 - val_loss: 1.2862 - val_accuracy: 0.7985\n","Epoch 42/100\n","29/29 [==============================] - 1s 31ms/step - loss: 1.2575 - accuracy: 0.8044 - val_loss: 1.2816 - val_accuracy: 0.7845\n","Epoch 43/100\n","29/29 [==============================] - 1s 41ms/step - loss: 1.2495 - accuracy: 0.8071 - val_loss: 1.2735 - val_accuracy: 0.7996\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2412 - accuracy: 0.8028 - val_loss: 1.2669 - val_accuracy: 0.7985\n","Epoch 45/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.2355 - accuracy: 0.8074 - val_loss: 1.2615 - val_accuracy: 0.7985\n","Epoch 46/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2292 - accuracy: 0.8079 - val_loss: 1.2553 - val_accuracy: 0.7963\n","Epoch 47/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2203 - accuracy: 0.8060 - val_loss: 1.2506 - val_accuracy: 0.7931\n","Epoch 48/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.2185 - accuracy: 0.8055 - val_loss: 1.2504 - val_accuracy: 0.7942\n","Epoch 49/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2088 - accuracy: 0.8098 - val_loss: 1.2447 - val_accuracy: 0.7759\n","Epoch 50/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2063 - accuracy: 0.8025 - val_loss: 1.2342 - val_accuracy: 0.7953\n","Epoch 51/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.1978 - accuracy: 0.8055 - val_loss: 1.2270 - val_accuracy: 0.7942\n","Epoch 52/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1870 - accuracy: 0.8130 - val_loss: 1.2243 - val_accuracy: 0.7888\n","Epoch 53/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.1839 - accuracy: 0.8055 - val_loss: 1.2171 - val_accuracy: 0.7931\n","Epoch 54/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.1771 - accuracy: 0.8122 - val_loss: 1.2113 - val_accuracy: 0.7920\n","Epoch 55/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.1702 - accuracy: 0.8120 - val_loss: 1.2087 - val_accuracy: 0.7909\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1660 - accuracy: 0.8133 - val_loss: 1.2012 - val_accuracy: 0.7899\n","Epoch 57/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1563 - accuracy: 0.8155 - val_loss: 1.1989 - val_accuracy: 0.7963\n","Epoch 58/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1548 - accuracy: 0.8187 - val_loss: 1.1916 - val_accuracy: 0.7963\n","Epoch 59/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1472 - accuracy: 0.8133 - val_loss: 1.1861 - val_accuracy: 0.7920\n","Epoch 60/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1443 - accuracy: 0.8144 - val_loss: 1.1797 - val_accuracy: 0.7931\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1367 - accuracy: 0.8147 - val_loss: 1.1742 - val_accuracy: 0.7931\n","Epoch 62/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1323 - accuracy: 0.8112 - val_loss: 1.1700 - val_accuracy: 0.7931\n","Epoch 63/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.1227 - accuracy: 0.8147 - val_loss: 1.1657 - val_accuracy: 0.7909\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1178 - accuracy: 0.8157 - val_loss: 1.1611 - val_accuracy: 0.7931\n","Epoch 65/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1099 - accuracy: 0.8214 - val_loss: 1.1556 - val_accuracy: 0.7942\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1051 - accuracy: 0.8190 - val_loss: 1.1580 - val_accuracy: 0.7953\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1014 - accuracy: 0.8214 - val_loss: 1.1480 - val_accuracy: 0.7931\n","Epoch 68/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.0980 - accuracy: 0.8209 - val_loss: 1.1441 - val_accuracy: 0.7953\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0928 - accuracy: 0.8173 - val_loss: 1.1355 - val_accuracy: 0.7931\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0850 - accuracy: 0.8225 - val_loss: 1.1313 - val_accuracy: 0.7909\n","Epoch 71/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0786 - accuracy: 0.8206 - val_loss: 1.1265 - val_accuracy: 0.7909\n","Epoch 72/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0712 - accuracy: 0.8222 - val_loss: 1.1197 - val_accuracy: 0.7888\n","Epoch 73/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.0670 - accuracy: 0.8230 - val_loss: 1.1185 - val_accuracy: 0.7931\n","Epoch 74/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0579 - accuracy: 0.8262 - val_loss: 1.1132 - val_accuracy: 0.7877\n","Epoch 75/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.0523 - accuracy: 0.8281 - val_loss: 1.1083 - val_accuracy: 0.7899\n","Epoch 76/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.0472 - accuracy: 0.8289 - val_loss: 1.1085 - val_accuracy: 0.7931\n","Epoch 77/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0442 - accuracy: 0.8222 - val_loss: 1.1004 - val_accuracy: 0.7877\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0361 - accuracy: 0.8305 - val_loss: 1.0962 - val_accuracy: 0.7866\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0308 - accuracy: 0.8322 - val_loss: 1.0955 - val_accuracy: 0.7899\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0287 - accuracy: 0.8292 - val_loss: 1.0842 - val_accuracy: 0.7888\n","Epoch 81/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0165 - accuracy: 0.8330 - val_loss: 1.0826 - val_accuracy: 0.7931\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0130 - accuracy: 0.8330 - val_loss: 1.0781 - val_accuracy: 0.7909\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0085 - accuracy: 0.8319 - val_loss: 1.0919 - val_accuracy: 0.7920\n","Epoch 84/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9989 - accuracy: 0.8303 - val_loss: 1.0704 - val_accuracy: 0.7963\n","Epoch 85/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9893 - accuracy: 0.8411 - val_loss: 1.0669 - val_accuracy: 0.7931\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9850 - accuracy: 0.8440 - val_loss: 1.0720 - val_accuracy: 0.7953\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9851 - accuracy: 0.8389 - val_loss: 1.0644 - val_accuracy: 0.7963\n","Epoch 88/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9741 - accuracy: 0.8413 - val_loss: 1.0535 - val_accuracy: 0.7953\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9673 - accuracy: 0.8486 - val_loss: 1.0559 - val_accuracy: 0.7866\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9709 - accuracy: 0.8341 - val_loss: 1.0584 - val_accuracy: 0.7823\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9785 - accuracy: 0.8273 - val_loss: 1.0581 - val_accuracy: 0.7769\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9528 - accuracy: 0.8491 - val_loss: 1.0365 - val_accuracy: 0.7920\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9434 - accuracy: 0.8491 - val_loss: 1.0312 - val_accuracy: 0.7931\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9365 - accuracy: 0.8545 - val_loss: 1.0278 - val_accuracy: 0.7899\n","Epoch 95/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9317 - accuracy: 0.8518 - val_loss: 1.0261 - val_accuracy: 0.7942\n","Epoch 96/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9321 - accuracy: 0.8510 - val_loss: 1.0229 - val_accuracy: 0.7953\n","Epoch 97/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9259 - accuracy: 0.8508 - val_loss: 1.0220 - val_accuracy: 0.7963\n","Epoch 98/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9185 - accuracy: 0.8537 - val_loss: 1.0165 - val_accuracy: 0.7931\n","Epoch 99/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9211 - accuracy: 0.8497 - val_loss: 1.0249 - val_accuracy: 0.7877\n","Epoch 100/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9069 - accuracy: 0.8524 - val_loss: 1.0032 - val_accuracy: 0.7888\n","{'loss': [1.8176608085632324, 1.8011115789413452, 1.7803773880004883, 1.7507660388946533, 1.7073365449905396, 1.6550313234329224, 1.6024245023727417, 1.5663260221481323, 1.5460742712020874, 1.527908444404602, 1.5118727684020996, 1.5029724836349487, 1.4917746782302856, 1.4789628982543945, 1.4667245149612427, 1.4559873342514038, 1.4438750743865967, 1.4365864992141724, 1.4255869388580322, 1.4189584255218506, 1.4104523658752441, 1.3992395401000977, 1.393721580505371, 1.3841861486434937, 1.3756345510482788, 1.3671261072158813, 1.3584407567977905, 1.3507269620895386, 1.3427414894104004, 1.3378106355667114, 1.3312588930130005, 1.321842074394226, 1.3160780668258667, 1.3131709098815918, 1.3005318641662598, 1.2937085628509521, 1.2842382192611694, 1.2795265913009644, 1.2724963426589966, 1.2702237367630005, 1.26066255569458, 1.2575395107269287, 1.249492883682251, 1.2411787509918213, 1.2355024814605713, 1.229201078414917, 1.2203269004821777, 1.2184994220733643, 1.208766222000122, 1.2063394784927368, 1.1978200674057007, 1.1869852542877197, 1.1839133501052856, 1.1771125793457031, 1.1701823472976685, 1.166008710861206, 1.1562916040420532, 1.1547929048538208, 1.1471896171569824, 1.1442534923553467, 1.1366512775421143, 1.13229238986969, 1.12274968624115, 1.1178491115570068, 1.1098661422729492, 1.1051372289657593, 1.1013963222503662, 1.0980215072631836, 1.092834234237671, 1.0849535465240479, 1.0786144733428955, 1.07120680809021, 1.0669822692871094, 1.0579400062561035, 1.0523136854171753, 1.0471779108047485, 1.0441771745681763, 1.0361400842666626, 1.0307912826538086, 1.028746485710144, 1.016548752784729, 1.01303231716156, 1.0084816217422485, 0.9989141225814819, 0.9893375635147095, 0.98497474193573, 0.9850825071334839, 0.9740696549415588, 0.967309296131134, 0.970912754535675, 0.9785166382789612, 0.9528253078460693, 0.9434023499488831, 0.9364829659461975, 0.9316931366920471, 0.9321126341819763, 0.9258526563644409, 0.9185062050819397, 0.9211006760597229, 0.9068713784217834], 'accuracy': [0.5735452771186829, 0.6818426847457886, 0.7147090435028076, 0.7400323152542114, 0.7470366358757019, 0.7543103694915771, 0.7626616358757019, 0.7605064511299133, 0.767241358757019, 0.7680495977401733, 0.774784505367279, 0.7737069129943848, 0.772090494632721, 0.779633641242981, 0.7807112336158752, 0.7834051847457886, 0.7879849076271057, 0.7879849076271057, 0.790409505367279, 0.7941810488700867, 0.7909482717514038, 0.796875, 0.7966055870056152, 0.7922952771186829, 0.7957974076271057, 0.7992995977401733, 0.7963362336158752, 0.7960668206214905, 0.7990301847457886, 0.7957974076271057, 0.8052262663841248, 0.803340494632721, 0.8028017282485962, 0.7987607717514038, 0.803071141242981, 0.8028017282485962, 0.8065732717514038, 0.8054956793785095, 0.8065732717514038, 0.8017241358757019, 0.8057650923728943, 0.8044180870056152, 0.8071120977401733, 0.8028017282485962, 0.8073814511299133, 0.8079202771186829, 0.806034505367279, 0.8054956793785095, 0.8098060488700867, 0.8025323152542114, 0.8054956793785095, 0.8130387663841248, 0.8054956793785095, 0.8122305870056152, 0.8119612336158752, 0.8133081793785095, 0.8154633641242981, 0.818696141242981, 0.8133081793785095, 0.8143857717514038, 0.8146551847457886, 0.811152994632721, 0.8146551847457886, 0.8157327771186829, 0.8213900923728943, 0.818965494632721, 0.8213900923728943, 0.8208512663841248, 0.8173491358757019, 0.8224676847457886, 0.8205819129943848, 0.8221982717514038, 0.8230064511299133, 0.8262392282485962, 0.828125, 0.8289331793785095, 0.8221982717514038, 0.8305495977401733, 0.8321659564971924, 0.8292025923728943, 0.8329741358757019, 0.8329741358757019, 0.8318965435028076, 0.8302801847457886, 0.8410560488700867, 0.8440194129943848, 0.8389008641242981, 0.8413254022598267, 0.8485991358757019, 0.8340517282485962, 0.8273168206214905, 0.8491379022598267, 0.8491379022598267, 0.8545258641242981, 0.8518319129943848, 0.8510237336158752, 0.8507543206214905, 0.8537176847457886, 0.8496767282485962, 0.8523706793785095], 'val_loss': [1.812376618385315, 1.8001734018325806, 1.787782907485962, 1.7750060558319092, 1.7602086067199707, 1.742634654045105, 1.719720721244812, 1.698521375656128, 1.677022099494934, 1.653477430343628, 1.6344891786575317, 1.607753872871399, 1.584082007408142, 1.560033917427063, 1.5356236696243286, 1.5098271369934082, 1.4945720434188843, 1.4676975011825562, 1.4573405981063843, 1.432367205619812, 1.4216121435165405, 1.4090293645858765, 1.4003798961639404, 1.3998346328735352, 1.3874413967132568, 1.3771185874938965, 1.3716117143630981, 1.3656971454620361, 1.3597304821014404, 1.3578373193740845, 1.3461681604385376, 1.3401341438293457, 1.3343496322631836, 1.3302501440048218, 1.3225347995758057, 1.3157497644424438, 1.3118847608566284, 1.303716778755188, 1.2970753908157349, 1.2937045097351074, 1.2862358093261719, 1.2815653085708618, 1.2735434770584106, 1.2668629884719849, 1.2614959478378296, 1.2553396224975586, 1.2505621910095215, 1.250422716140747, 1.2446560859680176, 1.2342177629470825, 1.2270240783691406, 1.22426176071167, 1.217132329940796, 1.2113112211227417, 1.2086576223373413, 1.201218605041504, 1.1989156007766724, 1.1915513277053833, 1.1860758066177368, 1.1797271966934204, 1.1742339134216309, 1.1700003147125244, 1.165679693222046, 1.161143183708191, 1.1556063890457153, 1.1579669713974, 1.1479560136795044, 1.144058346748352, 1.1355490684509277, 1.1312767267227173, 1.1264708042144775, 1.119693398475647, 1.1184799671173096, 1.113154411315918, 1.108278512954712, 1.1084883213043213, 1.1004457473754883, 1.0962224006652832, 1.0955188274383545, 1.08423912525177, 1.082617998123169, 1.0781359672546387, 1.0919435024261475, 1.070420503616333, 1.0668975114822388, 1.0720305442810059, 1.0643702745437622, 1.0534507036209106, 1.05594003200531, 1.0584477186203003, 1.0580945014953613, 1.0364878177642822, 1.0312401056289673, 1.027823567390442, 1.0261280536651611, 1.022908091545105, 1.0220338106155396, 1.0164539813995361, 1.0248998403549194, 1.0032386779785156], 'val_accuracy': [0.48599138855934143, 0.48168104887008667, 0.6519396305084229, 0.6831896305084229, 0.7219827771186829, 0.7219827771186829, 0.7650862336158752, 0.7424569129943848, 0.743534505367279, 0.764008641242981, 0.7456896305084229, 0.7683189511299133, 0.7737069129943848, 0.7737069129943848, 0.7790948152542114, 0.774784505367279, 0.7715517282485962, 0.7844827771186829, 0.7726293206214905, 0.7898706793785095, 0.787715494632721, 0.7855603694915771, 0.787715494632721, 0.7801724076271057, 0.7887930870056152, 0.7898706793785095, 0.7866379022598267, 0.7855603694915771, 0.7866379022598267, 0.7844827771186829, 0.7931034564971924, 0.7898706793785095, 0.7941810488700867, 0.7844827771186829, 0.787715494632721, 0.7931034564971924, 0.7855603694915771, 0.787715494632721, 0.7941810488700867, 0.7855603694915771, 0.798491358757019, 0.7844827771186829, 0.7995689511299133, 0.798491358757019, 0.798491358757019, 0.7963362336158752, 0.7931034564971924, 0.7941810488700867, 0.7758620977401733, 0.795258641242981, 0.7941810488700867, 0.7887930870056152, 0.7931034564971924, 0.7920258641242981, 0.7909482717514038, 0.7898706793785095, 0.7963362336158752, 0.7963362336158752, 0.7920258641242981, 0.7931034564971924, 0.7931034564971924, 0.7931034564971924, 0.7909482717514038, 0.7931034564971924, 0.7941810488700867, 0.795258641242981, 0.7931034564971924, 0.795258641242981, 0.7931034564971924, 0.7909482717514038, 0.7909482717514038, 0.7887930870056152, 0.7931034564971924, 0.787715494632721, 0.7898706793785095, 0.7931034564971924, 0.787715494632721, 0.7866379022598267, 0.7898706793785095, 0.7887930870056152, 0.7931034564971924, 0.7909482717514038, 0.7920258641242981, 0.7963362336158752, 0.7931034564971924, 0.795258641242981, 0.7963362336158752, 0.795258641242981, 0.7866379022598267, 0.7823275923728943, 0.7769396305084229, 0.7920258641242981, 0.7931034564971924, 0.7898706793785095, 0.7941810488700867, 0.795258641242981, 0.7963362336158752, 0.7931034564971924, 0.787715494632721, 0.7887930870056152]}\n","38/38 [==============================] - 1s 11ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 1.8182 - accuracy: 0.5767"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 9s 101ms/step - loss: 1.8182 - accuracy: 0.5767 - val_loss: 1.8128 - val_accuracy: 0.6210\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.8030 - accuracy: 0.6848 - val_loss: 1.8009 - val_accuracy: 0.6109\n","Epoch 3/100\n","28/28 [==============================] - 1s 33ms/step - loss: 1.7853 - accuracy: 0.7071 - val_loss: 1.7891 - val_accuracy: 0.6459\n","Epoch 4/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.7618 - accuracy: 0.7210 - val_loss: 1.7771 - val_accuracy: 0.6414\n","Epoch 5/100\n","28/28 [==============================] - 1s 36ms/step - loss: 1.7292 - accuracy: 0.7323 - val_loss: 1.7637 - val_accuracy: 0.6923\n","Epoch 6/100\n","28/28 [==============================] - 1s 30ms/step - loss: 1.6891 - accuracy: 0.7383 - val_loss: 1.7487 - val_accuracy: 0.6934\n","Epoch 7/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.6459 - accuracy: 0.7360 - val_loss: 1.7316 - val_accuracy: 0.6934\n","Epoch 8/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.6078 - accuracy: 0.7442 - val_loss: 1.7123 - val_accuracy: 0.7127\n","Epoch 9/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.5815 - accuracy: 0.7484 - val_loss: 1.6913 - val_accuracy: 0.7455\n","Epoch 10/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.5639 - accuracy: 0.7453 - val_loss: 1.6717 - val_accuracy: 0.7319\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5485 - accuracy: 0.7510 - val_loss: 1.6523 - val_accuracy: 0.7330\n","Epoch 12/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5311 - accuracy: 0.7533 - val_loss: 1.6314 - val_accuracy: 0.7421\n","Epoch 13/100\n","28/28 [==============================] - 1s 36ms/step - loss: 1.5258 - accuracy: 0.7538 - val_loss: 1.6141 - val_accuracy: 0.7466\n","Epoch 14/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.5110 - accuracy: 0.7623 - val_loss: 1.5929 - val_accuracy: 0.7477\n","Epoch 15/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.5008 - accuracy: 0.7649 - val_loss: 1.5708 - val_accuracy: 0.7489\n","Epoch 16/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.4881 - accuracy: 0.7674 - val_loss: 1.5538 - val_accuracy: 0.7579\n","Epoch 17/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4794 - accuracy: 0.7649 - val_loss: 1.5349 - val_accuracy: 0.7568\n","Epoch 18/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4708 - accuracy: 0.7691 - val_loss: 1.5114 - val_accuracy: 0.7579\n","Epoch 19/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.4597 - accuracy: 0.7753 - val_loss: 1.4907 - val_accuracy: 0.7602\n","Epoch 20/100\n","28/28 [==============================] - 1s 30ms/step - loss: 1.4524 - accuracy: 0.7697 - val_loss: 1.4796 - val_accuracy: 0.7636\n","Epoch 21/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.4423 - accuracy: 0.7776 - val_loss: 1.4860 - val_accuracy: 0.7455\n","Epoch 22/100\n","28/28 [==============================] - 1s 32ms/step - loss: 1.4364 - accuracy: 0.7654 - val_loss: 1.4537 - val_accuracy: 0.7658\n","Epoch 23/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.4244 - accuracy: 0.7739 - val_loss: 1.4424 - val_accuracy: 0.7647\n","Epoch 24/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.4152 - accuracy: 0.7748 - val_loss: 1.4351 - val_accuracy: 0.7579\n","Epoch 25/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.4117 - accuracy: 0.7702 - val_loss: 1.4277 - val_accuracy: 0.7590\n","Epoch 26/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4027 - accuracy: 0.7782 - val_loss: 1.4172 - val_accuracy: 0.7613\n","Epoch 27/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3966 - accuracy: 0.7722 - val_loss: 1.4080 - val_accuracy: 0.7624\n","Epoch 28/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3847 - accuracy: 0.7832 - val_loss: 1.4013 - val_accuracy: 0.7636\n","Epoch 29/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3827 - accuracy: 0.7728 - val_loss: 1.3993 - val_accuracy: 0.7590\n","Epoch 30/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3718 - accuracy: 0.7793 - val_loss: 1.3955 - val_accuracy: 0.7613\n","Epoch 31/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.3652 - accuracy: 0.7835 - val_loss: 1.3810 - val_accuracy: 0.7670\n","Epoch 32/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3581 - accuracy: 0.7810 - val_loss: 1.3859 - val_accuracy: 0.7602\n","Epoch 33/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3497 - accuracy: 0.7813 - val_loss: 1.3685 - val_accuracy: 0.7670\n","Epoch 34/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3419 - accuracy: 0.7841 - val_loss: 1.3719 - val_accuracy: 0.7602\n","Epoch 35/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.3380 - accuracy: 0.7790 - val_loss: 1.3558 - val_accuracy: 0.7692\n","Epoch 36/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3319 - accuracy: 0.7816 - val_loss: 1.3570 - val_accuracy: 0.7681\n","Epoch 37/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.3226 - accuracy: 0.7852 - val_loss: 1.3457 - val_accuracy: 0.7715\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3180 - accuracy: 0.7813 - val_loss: 1.3404 - val_accuracy: 0.7670\n","Epoch 39/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.3114 - accuracy: 0.7807 - val_loss: 1.3315 - val_accuracy: 0.7726\n","Epoch 40/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.3027 - accuracy: 0.7830 - val_loss: 1.3281 - val_accuracy: 0.7681\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2977 - accuracy: 0.7849 - val_loss: 1.3203 - val_accuracy: 0.7670\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2920 - accuracy: 0.7852 - val_loss: 1.3262 - val_accuracy: 0.7613\n","Epoch 43/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.2840 - accuracy: 0.7875 - val_loss: 1.3080 - val_accuracy: 0.7681\n","Epoch 44/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.2780 - accuracy: 0.7855 - val_loss: 1.3022 - val_accuracy: 0.7726\n","Epoch 45/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.2726 - accuracy: 0.7799 - val_loss: 1.3052 - val_accuracy: 0.7636\n","Epoch 46/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.2695 - accuracy: 0.7830 - val_loss: 1.2908 - val_accuracy: 0.7692\n","Epoch 47/100\n","28/28 [==============================] - 1s 33ms/step - loss: 1.2574 - accuracy: 0.7875 - val_loss: 1.2859 - val_accuracy: 0.7749\n","Epoch 48/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.2535 - accuracy: 0.7878 - val_loss: 1.2784 - val_accuracy: 0.7738\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2476 - accuracy: 0.7900 - val_loss: 1.2739 - val_accuracy: 0.7726\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2434 - accuracy: 0.7872 - val_loss: 1.2678 - val_accuracy: 0.7738\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2328 - accuracy: 0.7883 - val_loss: 1.2589 - val_accuracy: 0.7726\n","Epoch 52/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2289 - accuracy: 0.7900 - val_loss: 1.2546 - val_accuracy: 0.7738\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2189 - accuracy: 0.7889 - val_loss: 1.2549 - val_accuracy: 0.7658\n","Epoch 54/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2184 - accuracy: 0.7858 - val_loss: 1.2568 - val_accuracy: 0.7658\n","Epoch 55/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2112 - accuracy: 0.7909 - val_loss: 1.2374 - val_accuracy: 0.7715\n","Epoch 56/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2019 - accuracy: 0.7920 - val_loss: 1.2302 - val_accuracy: 0.7749\n","Epoch 57/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2001 - accuracy: 0.7892 - val_loss: 1.2236 - val_accuracy: 0.7726\n","Epoch 58/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1918 - accuracy: 0.7932 - val_loss: 1.2314 - val_accuracy: 0.7658\n","Epoch 59/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.1854 - accuracy: 0.7923 - val_loss: 1.2128 - val_accuracy: 0.7760\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1780 - accuracy: 0.7968 - val_loss: 1.2180 - val_accuracy: 0.7670\n","Epoch 61/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.1743 - accuracy: 0.7985 - val_loss: 1.2004 - val_accuracy: 0.7817\n","Epoch 62/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1671 - accuracy: 0.7929 - val_loss: 1.1928 - val_accuracy: 0.7817\n","Epoch 63/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1608 - accuracy: 0.7954 - val_loss: 1.1971 - val_accuracy: 0.7670\n","Epoch 64/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.1557 - accuracy: 0.7980 - val_loss: 1.1823 - val_accuracy: 0.7839\n","Epoch 65/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1474 - accuracy: 0.8008 - val_loss: 1.1772 - val_accuracy: 0.7839\n","Epoch 66/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1489 - accuracy: 0.7898 - val_loss: 1.1726 - val_accuracy: 0.7817\n","Epoch 67/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1355 - accuracy: 0.8002 - val_loss: 1.1653 - val_accuracy: 0.7805\n","Epoch 68/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1295 - accuracy: 0.8087 - val_loss: 1.1681 - val_accuracy: 0.7738\n","Epoch 69/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1215 - accuracy: 0.8011 - val_loss: 1.1571 - val_accuracy: 0.7828\n","Epoch 70/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.1110 - accuracy: 0.8093 - val_loss: 1.1542 - val_accuracy: 0.7828\n","Epoch 71/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.1091 - accuracy: 0.7999 - val_loss: 1.1479 - val_accuracy: 0.7839\n","Epoch 72/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1040 - accuracy: 0.8016 - val_loss: 1.1406 - val_accuracy: 0.7839\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0958 - accuracy: 0.8076 - val_loss: 1.1366 - val_accuracy: 0.7771\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0935 - accuracy: 0.8059 - val_loss: 1.1292 - val_accuracy: 0.7839\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0845 - accuracy: 0.8036 - val_loss: 1.1327 - val_accuracy: 0.7805\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0806 - accuracy: 0.8093 - val_loss: 1.1227 - val_accuracy: 0.7839\n","Epoch 77/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0689 - accuracy: 0.8158 - val_loss: 1.1173 - val_accuracy: 0.7839\n","Epoch 78/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.0659 - accuracy: 0.8155 - val_loss: 1.1111 - val_accuracy: 0.7851\n","Epoch 79/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.0576 - accuracy: 0.8189 - val_loss: 1.1129 - val_accuracy: 0.7919\n","Epoch 80/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0570 - accuracy: 0.8169 - val_loss: 1.1031 - val_accuracy: 0.7907\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0453 - accuracy: 0.8226 - val_loss: 1.0985 - val_accuracy: 0.7907\n","Epoch 82/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0331 - accuracy: 0.8299 - val_loss: 1.0971 - val_accuracy: 0.7896\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0312 - accuracy: 0.8246 - val_loss: 1.0986 - val_accuracy: 0.7873\n","Epoch 84/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0271 - accuracy: 0.8271 - val_loss: 1.0886 - val_accuracy: 0.7907\n","Epoch 85/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.0273 - accuracy: 0.8243 - val_loss: 1.0880 - val_accuracy: 0.7941\n","Epoch 86/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0144 - accuracy: 0.8285 - val_loss: 1.0896 - val_accuracy: 0.7873\n","Epoch 87/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.0100 - accuracy: 0.8285 - val_loss: 1.0758 - val_accuracy: 0.7952\n","Epoch 88/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0061 - accuracy: 0.8322 - val_loss: 1.0721 - val_accuracy: 0.7907\n","Epoch 89/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9968 - accuracy: 0.8325 - val_loss: 1.0746 - val_accuracy: 0.7907\n","Epoch 90/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9993 - accuracy: 0.8282 - val_loss: 1.0717 - val_accuracy: 0.7907\n","Epoch 91/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.9945 - accuracy: 0.8288 - val_loss: 1.0599 - val_accuracy: 0.7975\n","Epoch 92/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9812 - accuracy: 0.8404 - val_loss: 1.0614 - val_accuracy: 0.7919\n","Epoch 93/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9743 - accuracy: 0.8404 - val_loss: 1.0552 - val_accuracy: 0.7930\n","Epoch 94/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9717 - accuracy: 0.8362 - val_loss: 1.0500 - val_accuracy: 0.7941\n","Epoch 95/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.9634 - accuracy: 0.8370 - val_loss: 1.0444 - val_accuracy: 0.7998\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9610 - accuracy: 0.8407 - val_loss: 1.0440 - val_accuracy: 0.7952\n","Epoch 97/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.9552 - accuracy: 0.8418 - val_loss: 1.0366 - val_accuracy: 0.8032\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9539 - accuracy: 0.8387 - val_loss: 1.0397 - val_accuracy: 0.7986\n","Epoch 99/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9434 - accuracy: 0.8438 - val_loss: 1.0464 - val_accuracy: 0.7941\n","Epoch 100/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9418 - accuracy: 0.8418 - val_loss: 1.0388 - val_accuracy: 0.7941\n","{'loss': [1.8182114362716675, 1.8029855489730835, 1.7852754592895508, 1.7618341445922852, 1.729198694229126, 1.6890937089920044, 1.6459259986877441, 1.607825756072998, 1.581510305404663, 1.5638529062271118, 1.5485016107559204, 1.5311367511749268, 1.5257612466812134, 1.5110063552856445, 1.5008323192596436, 1.4881168603897095, 1.4794070720672607, 1.4707967042922974, 1.4597184658050537, 1.4524141550064087, 1.4423494338989258, 1.4363524913787842, 1.4244284629821777, 1.4152295589447021, 1.41170334815979, 1.402683973312378, 1.3965537548065186, 1.384671688079834, 1.3827452659606934, 1.3717931509017944, 1.3652132749557495, 1.3581461906433105, 1.3497394323349, 1.3418503999710083, 1.3379600048065186, 1.331895351409912, 1.3226277828216553, 1.317971110343933, 1.311392903327942, 1.3026530742645264, 1.2976711988449097, 1.2920371294021606, 1.2840205430984497, 1.2779533863067627, 1.2725775241851807, 1.2694796323776245, 1.2574169635772705, 1.2535419464111328, 1.2476013898849487, 1.2434487342834473, 1.2327851057052612, 1.2288581132888794, 1.2188979387283325, 1.2184436321258545, 1.211214542388916, 1.201930284500122, 1.2000627517700195, 1.191760778427124, 1.1853877305984497, 1.1779873371124268, 1.1742517948150635, 1.167060136795044, 1.1607736349105835, 1.1557375192642212, 1.147411823272705, 1.1488771438598633, 1.13546884059906, 1.1294702291488647, 1.1214518547058105, 1.111046552658081, 1.109054446220398, 1.1039901971817017, 1.0958192348480225, 1.093502163887024, 1.0844675302505493, 1.0806267261505127, 1.068922519683838, 1.0659090280532837, 1.0576179027557373, 1.057031273841858, 1.0452677011489868, 1.0330920219421387, 1.0311894416809082, 1.0271230936050415, 1.0272523164749146, 1.0143975019454956, 1.0100220441818237, 1.0061466693878174, 0.9968135356903076, 0.9993040561676025, 0.9945491552352905, 0.9811697602272034, 0.9743040204048157, 0.9716655015945435, 0.9634153246879578, 0.9609626531600952, 0.9552302956581116, 0.9539481401443481, 0.9433895349502563, 0.9417744874954224], 'accuracy': [0.5766836404800415, 0.6847764849662781, 0.7071307301521301, 0.7209960222244263, 0.7323146462440491, 0.7382569313049316, 0.7359932065010071, 0.7441992163658142, 0.7484436631202698, 0.7453310489654541, 0.7509903907775879, 0.7532541155815125, 0.7538200616836548, 0.7623090147972107, 0.764855682849884, 0.7674023509025574, 0.764855682849884, 0.7691001892089844, 0.7753254175186157, 0.7696660757064819, 0.7775891423225403, 0.7654216289520264, 0.7739105820655823, 0.7747594714164734, 0.7702320218086243, 0.7781550884246826, 0.7722128033638, 0.7832484245300293, 0.7727787494659424, 0.7792869210243225, 0.7835314273834229, 0.7809846997261047, 0.7812677025794983, 0.7840973138809204, 0.7790039777755737, 0.7815506458282471, 0.7852292060852051, 0.7812677025794983, 0.780701756477356, 0.7829654812812805, 0.7849462628364563, 0.7852292060852051, 0.7874929308891296, 0.7855121493339539, 0.7798528671264648, 0.7829654812812805, 0.7874929308891296, 0.7877758741378784, 0.790039598941803, 0.7872099876403809, 0.7883418202400208, 0.790039598941803, 0.7889077663421631, 0.7857951521873474, 0.7908884882926941, 0.7920203804969788, 0.7891907095909119, 0.7931522130966187, 0.7923033237457275, 0.7968307733535767, 0.7985285520553589, 0.7928692698478699, 0.7954159379005432, 0.7979626655578613, 0.8007922768592834, 0.7897566556930542, 0.8002263903617859, 0.8087153434753418, 0.801075279712677, 0.8092812895774841, 0.7999433875083923, 0.8016412258148193, 0.8075834512710571, 0.8058856725692749, 0.8036219477653503, 0.8092812895774841, 0.8157894611358643, 0.8155065178871155, 0.8189020752906799, 0.8169213533401489, 0.8225806355476379, 0.829937756061554, 0.8245614171028137, 0.8271080851554871, 0.8242784142494202, 0.8285229206085205, 0.8285229206085205, 0.8322014808654785, 0.8324844241142273, 0.8282399773597717, 0.8288058638572693, 0.8404074907302856, 0.8404074907302856, 0.8361629843711853, 0.8370118737220764, 0.8406904339790344, 0.8418223261833191, 0.8387096524238586, 0.8438030481338501, 0.8418223261833191], 'val_loss': [1.8127851486206055, 1.800948143005371, 1.7891007661819458, 1.7770614624023438, 1.7636997699737549, 1.748685359954834, 1.7316151857376099, 1.712341547012329, 1.6913363933563232, 1.6717214584350586, 1.65232253074646, 1.631394386291504, 1.6140644550323486, 1.5929433107376099, 1.5707981586456299, 1.5537911653518677, 1.5348789691925049, 1.5114257335662842, 1.4906617403030396, 1.479593276977539, 1.485973596572876, 1.4537391662597656, 1.4424210786819458, 1.4351164102554321, 1.4277303218841553, 1.4171595573425293, 1.408030390739441, 1.4012826681137085, 1.3993455171585083, 1.3954895734786987, 1.380961537361145, 1.3858503103256226, 1.368512511253357, 1.3718507289886475, 1.355847954750061, 1.3570284843444824, 1.3456918001174927, 1.3404306173324585, 1.3314932584762573, 1.3280614614486694, 1.3203307390213013, 1.3261876106262207, 1.3079615831375122, 1.3021634817123413, 1.3051860332489014, 1.29081392288208, 1.2858787775039673, 1.2784003019332886, 1.2738561630249023, 1.267760992050171, 1.258911371231079, 1.2546474933624268, 1.2549426555633545, 1.2567790746688843, 1.2373920679092407, 1.2301629781723022, 1.2235631942749023, 1.2313627004623413, 1.2127549648284912, 1.2179776430130005, 1.2003610134124756, 1.192839503288269, 1.1971137523651123, 1.1823315620422363, 1.1772023439407349, 1.1726292371749878, 1.1653249263763428, 1.1680583953857422, 1.1570745706558228, 1.1541650295257568, 1.1478959321975708, 1.1406469345092773, 1.1366057395935059, 1.129166603088379, 1.1327438354492188, 1.1227360963821411, 1.1173070669174194, 1.1111317873001099, 1.1129182577133179, 1.103100299835205, 1.098492980003357, 1.0970641374588013, 1.0985770225524902, 1.0885955095291138, 1.0879511833190918, 1.0895558595657349, 1.0758274793624878, 1.0721462965011597, 1.0745868682861328, 1.071706771850586, 1.0598976612091064, 1.0614030361175537, 1.0552074909210205, 1.0499824285507202, 1.044403314590454, 1.0439693927764893, 1.036596417427063, 1.0396937131881714, 1.046403169631958, 1.0387823581695557], 'val_accuracy': [0.6210407018661499, 0.610859751701355, 0.6459276080131531, 0.6414027214050293, 0.692307710647583, 0.6934388875961304, 0.6934388875961304, 0.7126696705818176, 0.7454751133918762, 0.7319004535675049, 0.733031690120697, 0.7420814633369446, 0.7466063499450684, 0.7477375268936157, 0.7488687634468079, 0.7579185366630554, 0.7567873597145081, 0.7579185366630554, 0.7601810097694397, 0.7635746598243713, 0.7454751133918762, 0.7658371329307556, 0.7647058963775635, 0.7579185366630554, 0.7590497732162476, 0.7613122463226318, 0.7624434232711792, 0.7635746598243713, 0.7590497732162476, 0.7613122463226318, 0.766968309879303, 0.7601810097694397, 0.766968309879303, 0.7601810097694397, 0.7692307829856873, 0.7680995464324951, 0.7714931964874268, 0.766968309879303, 0.7726244330406189, 0.7680995464324951, 0.766968309879303, 0.7613122463226318, 0.7680995464324951, 0.7726244330406189, 0.7635746598243713, 0.7692307829856873, 0.7748869061470032, 0.773755669593811, 0.7726244330406189, 0.773755669593811, 0.7726244330406189, 0.773755669593811, 0.7658371329307556, 0.7658371329307556, 0.7714931964874268, 0.7748869061470032, 0.7726244330406189, 0.7658371329307556, 0.7760180830955505, 0.766968309879303, 0.7816742062568665, 0.7816742062568665, 0.766968309879303, 0.7839366793632507, 0.7839366793632507, 0.7816742062568665, 0.7805429697036743, 0.773755669593811, 0.7828054428100586, 0.7828054428100586, 0.7839366793632507, 0.7839366793632507, 0.7771493196487427, 0.7839366793632507, 0.7805429697036743, 0.7839366793632507, 0.7839366793632507, 0.7850678563117981, 0.7918552160263062, 0.790723979473114, 0.790723979473114, 0.7895927429199219, 0.7873303294181824, 0.790723979473114, 0.7941176295280457, 0.7873303294181824, 0.7952488660812378, 0.790723979473114, 0.790723979473114, 0.790723979473114, 0.7975113391876221, 0.7918552160263062, 0.7929864525794983, 0.7941176295280457, 0.7997737526893616, 0.7952488660812378, 0.8031674027442932, 0.7986425161361694, 0.7941176295280457, 0.7941176295280457]}\n","45/45 [==============================] - 1s 6ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 1.8173 - accuracy: 0.5855"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 9s 76ms/step - loss: 1.8173 - accuracy: 0.5855 - val_loss: 1.8115 - val_accuracy: 0.7314\n","Epoch 2/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.8002 - accuracy: 0.6977 - val_loss: 1.7986 - val_accuracy: 0.5992\n","Epoch 3/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.7791 - accuracy: 0.7315 - val_loss: 1.7858 - val_accuracy: 0.5847\n","Epoch 4/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.7522 - accuracy: 0.7336 - val_loss: 1.7724 - val_accuracy: 0.6560\n","Epoch 5/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.7140 - accuracy: 0.7323 - val_loss: 1.7581 - val_accuracy: 0.6312\n","Epoch 6/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.6649 - accuracy: 0.7488 - val_loss: 1.7395 - val_accuracy: 0.7407\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.6130 - accuracy: 0.7501 - val_loss: 1.7197 - val_accuracy: 0.6983\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.5718 - accuracy: 0.7594 - val_loss: 1.6969 - val_accuracy: 0.7014\n","Epoch 9/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.5453 - accuracy: 0.7674 - val_loss: 1.6704 - val_accuracy: 0.7531\n","Epoch 10/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.5190 - accuracy: 0.7811 - val_loss: 1.6498 - val_accuracy: 0.7242\n","Epoch 11/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.5051 - accuracy: 0.7729 - val_loss: 1.6231 - val_accuracy: 0.7510\n","Epoch 12/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.4897 - accuracy: 0.7814 - val_loss: 1.5970 - val_accuracy: 0.7645\n","Epoch 13/100\n","31/31 [==============================] - 1s 37ms/step - loss: 1.4732 - accuracy: 0.7860 - val_loss: 1.5697 - val_accuracy: 0.7686\n","Epoch 14/100\n","31/31 [==============================] - 2s 76ms/step - loss: 1.4622 - accuracy: 0.7933 - val_loss: 1.5429 - val_accuracy: 0.7738\n","Epoch 15/100\n","31/31 [==============================] - 1s 33ms/step - loss: 1.4509 - accuracy: 0.7886 - val_loss: 1.5185 - val_accuracy: 0.7820\n","Epoch 16/100\n","31/31 [==============================] - 1s 32ms/step - loss: 1.4365 - accuracy: 0.7977 - val_loss: 1.4917 - val_accuracy: 0.7841\n","Epoch 17/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.4269 - accuracy: 0.7959 - val_loss: 1.4709 - val_accuracy: 0.7903\n","Epoch 18/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4156 - accuracy: 0.7966 - val_loss: 1.4518 - val_accuracy: 0.7893\n","Epoch 19/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4048 - accuracy: 0.8018 - val_loss: 1.4529 - val_accuracy: 0.7769\n","Epoch 20/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.3990 - accuracy: 0.7977 - val_loss: 1.4200 - val_accuracy: 0.7913\n","Epoch 21/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3899 - accuracy: 0.7992 - val_loss: 1.4221 - val_accuracy: 0.7841\n","Epoch 22/100\n","31/31 [==============================] - 1s 28ms/step - loss: 1.3819 - accuracy: 0.7987 - val_loss: 1.4006 - val_accuracy: 0.7975\n","Epoch 23/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3718 - accuracy: 0.8028 - val_loss: 1.3904 - val_accuracy: 0.7934\n","Epoch 24/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3610 - accuracy: 0.8028 - val_loss: 1.3860 - val_accuracy: 0.7955\n","Epoch 25/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3536 - accuracy: 0.8005 - val_loss: 1.3809 - val_accuracy: 0.7810\n","Epoch 26/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3455 - accuracy: 0.8010 - val_loss: 1.3731 - val_accuracy: 0.7955\n","Epoch 27/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3432 - accuracy: 0.8034 - val_loss: 1.3617 - val_accuracy: 0.7893\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3301 - accuracy: 0.8031 - val_loss: 1.3626 - val_accuracy: 0.7934\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3258 - accuracy: 0.8054 - val_loss: 1.3470 - val_accuracy: 0.7955\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3181 - accuracy: 0.8041 - val_loss: 1.3418 - val_accuracy: 0.7913\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3093 - accuracy: 0.8070 - val_loss: 1.3342 - val_accuracy: 0.7975\n","Epoch 32/100\n","31/31 [==============================] - 1s 30ms/step - loss: 1.3020 - accuracy: 0.8070 - val_loss: 1.3283 - val_accuracy: 0.7996\n","Epoch 33/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.2936 - accuracy: 0.8044 - val_loss: 1.3215 - val_accuracy: 0.7955\n","Epoch 34/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2834 - accuracy: 0.8137 - val_loss: 1.3198 - val_accuracy: 0.7851\n","Epoch 35/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2816 - accuracy: 0.8072 - val_loss: 1.3111 - val_accuracy: 0.7975\n","Epoch 36/100\n","31/31 [==============================] - 1s 30ms/step - loss: 1.2709 - accuracy: 0.8116 - val_loss: 1.3017 - val_accuracy: 0.8027\n","Epoch 37/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2629 - accuracy: 0.8103 - val_loss: 1.2984 - val_accuracy: 0.7893\n","Epoch 38/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2588 - accuracy: 0.8106 - val_loss: 1.2892 - val_accuracy: 0.7996\n","Epoch 39/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2509 - accuracy: 0.8101 - val_loss: 1.2830 - val_accuracy: 0.8027\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2397 - accuracy: 0.8119 - val_loss: 1.2763 - val_accuracy: 0.8027\n","Epoch 41/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2334 - accuracy: 0.8140 - val_loss: 1.2707 - val_accuracy: 0.8017\n","Epoch 42/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2266 - accuracy: 0.8129 - val_loss: 1.2638 - val_accuracy: 0.7986\n","Epoch 43/100\n","31/31 [==============================] - 1s 31ms/step - loss: 1.2207 - accuracy: 0.8150 - val_loss: 1.2565 - val_accuracy: 0.8058\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2151 - accuracy: 0.8140 - val_loss: 1.2528 - val_accuracy: 0.8027\n","Epoch 45/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2047 - accuracy: 0.8160 - val_loss: 1.2445 - val_accuracy: 0.8058\n","Epoch 46/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1997 - accuracy: 0.8189 - val_loss: 1.2378 - val_accuracy: 0.8048\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1917 - accuracy: 0.8160 - val_loss: 1.2329 - val_accuracy: 0.8017\n","Epoch 48/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1846 - accuracy: 0.8160 - val_loss: 1.2269 - val_accuracy: 0.8037\n","Epoch 49/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.1771 - accuracy: 0.8194 - val_loss: 1.2202 - val_accuracy: 0.8089\n","Epoch 50/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1707 - accuracy: 0.8191 - val_loss: 1.2162 - val_accuracy: 0.7986\n","Epoch 51/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1642 - accuracy: 0.8171 - val_loss: 1.2094 - val_accuracy: 0.8048\n","Epoch 52/100\n","31/31 [==============================] - 1s 29ms/step - loss: 1.1559 - accuracy: 0.8251 - val_loss: 1.2035 - val_accuracy: 0.8099\n","Epoch 53/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1511 - accuracy: 0.8233 - val_loss: 1.1956 - val_accuracy: 0.8037\n","Epoch 54/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1435 - accuracy: 0.8217 - val_loss: 1.1900 - val_accuracy: 0.8079\n","Epoch 55/100\n","31/31 [==============================] - 1s 32ms/step - loss: 1.1360 - accuracy: 0.8271 - val_loss: 1.1866 - val_accuracy: 0.8110\n","Epoch 56/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1318 - accuracy: 0.8212 - val_loss: 1.1760 - val_accuracy: 0.8089\n","Epoch 57/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.1238 - accuracy: 0.8266 - val_loss: 1.1838 - val_accuracy: 0.8037\n","Epoch 58/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1235 - accuracy: 0.8137 - val_loss: 1.1673 - val_accuracy: 0.7996\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1132 - accuracy: 0.8222 - val_loss: 1.1594 - val_accuracy: 0.7986\n","Epoch 60/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1039 - accuracy: 0.8307 - val_loss: 1.1532 - val_accuracy: 0.8068\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0995 - accuracy: 0.8323 - val_loss: 1.1503 - val_accuracy: 0.8110\n","Epoch 62/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0881 - accuracy: 0.8318 - val_loss: 1.1438 - val_accuracy: 0.8017\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0815 - accuracy: 0.8302 - val_loss: 1.1406 - val_accuracy: 0.8006\n","Epoch 64/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.0755 - accuracy: 0.8346 - val_loss: 1.1340 - val_accuracy: 0.8130\n","Epoch 65/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0709 - accuracy: 0.8349 - val_loss: 1.1275 - val_accuracy: 0.8110\n","Epoch 66/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0656 - accuracy: 0.8326 - val_loss: 1.1214 - val_accuracy: 0.8130\n","Epoch 67/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0548 - accuracy: 0.8385 - val_loss: 1.1309 - val_accuracy: 0.8048\n","Epoch 68/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0546 - accuracy: 0.8354 - val_loss: 1.1189 - val_accuracy: 0.8079\n","Epoch 69/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0434 - accuracy: 0.8377 - val_loss: 1.1076 - val_accuracy: 0.8089\n","Epoch 70/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0374 - accuracy: 0.8380 - val_loss: 1.1055 - val_accuracy: 0.8079\n","Epoch 71/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0346 - accuracy: 0.8390 - val_loss: 1.0960 - val_accuracy: 0.8089\n","Epoch 72/100\n","31/31 [==============================] - 1s 34ms/step - loss: 1.0232 - accuracy: 0.8455 - val_loss: 1.0939 - val_accuracy: 0.8182\n","Epoch 73/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.0140 - accuracy: 0.8450 - val_loss: 1.0955 - val_accuracy: 0.8120\n","Epoch 74/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0094 - accuracy: 0.8444 - val_loss: 1.0830 - val_accuracy: 0.8110\n","Epoch 75/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0035 - accuracy: 0.8486 - val_loss: 1.0801 - val_accuracy: 0.8140\n","Epoch 76/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9944 - accuracy: 0.8475 - val_loss: 1.0733 - val_accuracy: 0.8151\n","Epoch 77/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9907 - accuracy: 0.8473 - val_loss: 1.0676 - val_accuracy: 0.8151\n","Epoch 78/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9834 - accuracy: 0.8517 - val_loss: 1.0738 - val_accuracy: 0.8130\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9953 - accuracy: 0.8388 - val_loss: 1.0646 - val_accuracy: 0.8079\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9753 - accuracy: 0.8540 - val_loss: 1.0568 - val_accuracy: 0.8151\n","Epoch 81/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9704 - accuracy: 0.8543 - val_loss: 1.0512 - val_accuracy: 0.8192\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9675 - accuracy: 0.8494 - val_loss: 1.0469 - val_accuracy: 0.8151\n","Epoch 83/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9565 - accuracy: 0.8501 - val_loss: 1.0420 - val_accuracy: 0.8151\n","Epoch 84/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.9536 - accuracy: 0.8514 - val_loss: 1.0352 - val_accuracy: 0.8213\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9413 - accuracy: 0.8576 - val_loss: 1.0348 - val_accuracy: 0.8192\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9424 - accuracy: 0.8504 - val_loss: 1.0327 - val_accuracy: 0.8171\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9337 - accuracy: 0.8550 - val_loss: 1.0248 - val_accuracy: 0.8192\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9329 - accuracy: 0.8581 - val_loss: 1.0206 - val_accuracy: 0.8202\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9275 - accuracy: 0.8607 - val_loss: 1.0166 - val_accuracy: 0.8202\n","Epoch 90/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9189 - accuracy: 0.8543 - val_loss: 1.0281 - val_accuracy: 0.8048\n","Epoch 91/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9220 - accuracy: 0.8501 - val_loss: 1.0164 - val_accuracy: 0.8171\n","Epoch 92/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.9085 - accuracy: 0.8641 - val_loss: 1.0031 - val_accuracy: 0.8264\n","Epoch 93/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9019 - accuracy: 0.8623 - val_loss: 1.0016 - val_accuracy: 0.8182\n","Epoch 94/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8950 - accuracy: 0.8638 - val_loss: 0.9987 - val_accuracy: 0.8182\n","Epoch 95/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8924 - accuracy: 0.8636 - val_loss: 1.0357 - val_accuracy: 0.7903\n","Epoch 96/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8972 - accuracy: 0.8636 - val_loss: 0.9979 - val_accuracy: 0.8068\n","Epoch 97/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8851 - accuracy: 0.8669 - val_loss: 0.9838 - val_accuracy: 0.8233\n","Epoch 98/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.8793 - accuracy: 0.8630 - val_loss: 0.9823 - val_accuracy: 0.8192\n","Epoch 99/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8771 - accuracy: 0.8667 - val_loss: 0.9852 - val_accuracy: 0.8089\n","Epoch 100/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8695 - accuracy: 0.8646 - val_loss: 0.9760 - val_accuracy: 0.8213\n","{'loss': [1.8173093795776367, 1.8002147674560547, 1.7791097164154053, 1.7521758079528809, 1.7139517068862915, 1.6648695468902588, 1.6130262613296509, 1.571786642074585, 1.5453221797943115, 1.5189933776855469, 1.5051000118255615, 1.4897316694259644, 1.4731965065002441, 1.4622423648834229, 1.4508997201919556, 1.4365339279174805, 1.4268568754196167, 1.415608286857605, 1.4047514200210571, 1.3989819288253784, 1.3898571729660034, 1.3818871974945068, 1.37180495262146, 1.3609731197357178, 1.3536179065704346, 1.3454827070236206, 1.343222737312317, 1.3300799131393433, 1.3258367776870728, 1.3180824518203735, 1.3092637062072754, 1.3020001649856567, 1.2936328649520874, 1.2834173440933228, 1.2816424369812012, 1.2708666324615479, 1.262929081916809, 1.2587697505950928, 1.2509244680404663, 1.239667296409607, 1.2333660125732422, 1.2266358137130737, 1.2206850051879883, 1.215108871459961, 1.2046905755996704, 1.1996586322784424, 1.1917425394058228, 1.1845537424087524, 1.1771398782730103, 1.170685887336731, 1.1642192602157593, 1.1558619737625122, 1.151136040687561, 1.1435296535491943, 1.1360002756118774, 1.1317793130874634, 1.1237906217575073, 1.1234813928604126, 1.113226056098938, 1.1038999557495117, 1.0994510650634766, 1.088070034980774, 1.0815128087997437, 1.0754932165145874, 1.0709418058395386, 1.0655921697616577, 1.0547959804534912, 1.0545709133148193, 1.0434015989303589, 1.037353754043579, 1.0345885753631592, 1.0231502056121826, 1.0140007734298706, 1.009416103363037, 1.0035277605056763, 0.9943763017654419, 0.9906768202781677, 0.9834088683128357, 0.9952616691589355, 0.9752529263496399, 0.9703933596611023, 0.9675478935241699, 0.9565252065658569, 0.9535962343215942, 0.9413304328918457, 0.9423998594284058, 0.9337353110313416, 0.932935357093811, 0.9275175929069519, 0.9189008474349976, 0.9219564199447632, 0.9084689021110535, 0.901935875415802, 0.8950012922286987, 0.8924450874328613, 0.8971989154815674, 0.8850719332695007, 0.8792516589164734, 0.8770580291748047, 0.8694936037063599], 'accuracy': [0.5855297446250916, 0.6976743936538696, 0.7315245270729065, 0.7335917353630066, 0.7322997450828552, 0.7488372325897217, 0.750129222869873, 0.7594315409660339, 0.7674418687820435, 0.7811369299888611, 0.7728682160377502, 0.7813953757286072, 0.7860465049743652, 0.7932816743850708, 0.788630485534668, 0.7976744174957275, 0.7958656549453735, 0.7966408133506775, 0.801808774471283, 0.7976744174957275, 0.7992247939109802, 0.7987080216407776, 0.802842378616333, 0.802842378616333, 0.8005167841911316, 0.801033616065979, 0.8033591508865356, 0.8031007647514343, 0.8054263591766357, 0.8041343688964844, 0.8069767355918884, 0.8069767355918884, 0.8043927550315857, 0.8136950731277466, 0.8072351217269897, 0.8116279244422913, 0.8103359341621399, 0.8105943202972412, 0.8100775480270386, 0.8118863105773926, 0.8139534592628479, 0.8129199147224426, 0.814987063407898, 0.8139534592628479, 0.816020667552948, 0.818863034248352, 0.816020667552948, 0.816020667552948, 0.8193798661231995, 0.8191214203834534, 0.817054271697998, 0.8250645995140076, 0.8232558369636536, 0.8217054009437561, 0.8271318078041077, 0.8211886286735535, 0.8266149759292603, 0.8136950731277466, 0.8222222328186035, 0.8307493329048157, 0.8322997689247131, 0.8317829370498657, 0.830232560634613, 0.8346253037452698, 0.8348837494850159, 0.8325581550598145, 0.8385012745857239, 0.8354005217552185, 0.8377261161804199, 0.8379845023155212, 0.8390181064605713, 0.8454780578613281, 0.8449612259864807, 0.8444444537162781, 0.8485788106918335, 0.8475452065467834, 0.8472868204116821, 0.8516795635223389, 0.8387596607208252, 0.8540051579475403, 0.8542635440826416, 0.8493540287017822, 0.8501291871070862, 0.8514211773872375, 0.8576227426528931, 0.8503875732421875, 0.8550387620925903, 0.8581395149230957, 0.8607234954833984, 0.8542635440826416, 0.8501291871070862, 0.8640826940536499, 0.8622739315032959, 0.8638243079185486, 0.8635658621788025, 0.8635658621788025, 0.866925060749054, 0.8630490899085999, 0.8666666746139526, 0.8645994663238525], 'val_loss': [1.8115204572677612, 1.7985739707946777, 1.7857675552368164, 1.7723926305770874, 1.7580578327178955, 1.739516019821167, 1.7196893692016602, 1.6968884468078613, 1.6703790426254272, 1.6498392820358276, 1.6231136322021484, 1.5970304012298584, 1.569693684577942, 1.5429282188415527, 1.5185189247131348, 1.4916859865188599, 1.470923662185669, 1.4518133401870728, 1.4529139995574951, 1.4199824333190918, 1.4220519065856934, 1.4006203413009644, 1.3903523683547974, 1.3860206604003906, 1.3808666467666626, 1.373073935508728, 1.3616909980773926, 1.3626266717910767, 1.3470381498336792, 1.3417789936065674, 1.3341941833496094, 1.3282674551010132, 1.3215328454971313, 1.3198180198669434, 1.3111464977264404, 1.3016815185546875, 1.2983630895614624, 1.2892194986343384, 1.282997965812683, 1.2762924432754517, 1.270652413368225, 1.263750433921814, 1.2565343379974365, 1.2528252601623535, 1.244462251663208, 1.237825632095337, 1.2329214811325073, 1.2269468307495117, 1.2202181816101074, 1.2161650657653809, 1.209391474723816, 1.2035167217254639, 1.195555329322815, 1.1899834871292114, 1.1866135597229004, 1.1759586334228516, 1.1838428974151611, 1.1672626733779907, 1.1594116687774658, 1.15316903591156, 1.1502940654754639, 1.1437686681747437, 1.1406477689743042, 1.1340177059173584, 1.1275081634521484, 1.1214003562927246, 1.1308635473251343, 1.1189182996749878, 1.1075608730316162, 1.105459451675415, 1.095993161201477, 1.0938974618911743, 1.0955373048782349, 1.0830309391021729, 1.0800765752792358, 1.0733023881912231, 1.0676168203353882, 1.0737621784210205, 1.0645794868469238, 1.0568455457687378, 1.0512312650680542, 1.046858549118042, 1.0419915914535522, 1.0351753234863281, 1.034822702407837, 1.0326764583587646, 1.0248212814331055, 1.020633578300476, 1.0165935754776, 1.028102159500122, 1.0163989067077637, 1.0030885934829712, 1.0015876293182373, 0.9986971020698547, 1.0356770753860474, 0.9978978633880615, 0.9838279485702515, 0.9822730422019958, 0.985203742980957, 0.975989580154419], 'val_accuracy': [0.7314049601554871, 0.5991735458374023, 0.5847107172012329, 0.6559917330741882, 0.6311983466148376, 0.7407024502754211, 0.6983470916748047, 0.7014462947845459, 0.7530992031097412, 0.7241735458374023, 0.7510330677032471, 0.7644628286361694, 0.7685950398445129, 0.7737603187561035, 0.7820248007774353, 0.7840909361839294, 0.7902892827987671, 0.78925621509552, 0.7768595218658447, 0.7913222908973694, 0.7840909361839294, 0.797520637512207, 0.7933884263038635, 0.7954545617103577, 0.7809917330741882, 0.7954545617103577, 0.78925621509552, 0.7933884263038635, 0.7954545617103577, 0.7913222908973694, 0.797520637512207, 0.7995867729187012, 0.7954545617103577, 0.7851239442825317, 0.797520637512207, 0.8026859760284424, 0.78925621509552, 0.7995867729187012, 0.8026859760284424, 0.8026859760284424, 0.8016529083251953, 0.7985537052154541, 0.8057851195335388, 0.8026859760284424, 0.8057851195335388, 0.8047520518302917, 0.8016529083251953, 0.8037189841270447, 0.80888432264328, 0.7985537052154541, 0.8047520518302917, 0.8099173307418823, 0.8037189841270447, 0.807851254940033, 0.8109503984451294, 0.80888432264328, 0.8037189841270447, 0.7995867729187012, 0.7985537052154541, 0.8068181872367859, 0.8109503984451294, 0.8016529083251953, 0.8006198406219482, 0.8130165338516235, 0.8109503984451294, 0.8130165338516235, 0.8047520518302917, 0.807851254940033, 0.80888432264328, 0.807851254940033, 0.80888432264328, 0.8181818127632141, 0.8119834661483765, 0.8109503984451294, 0.8140496015548706, 0.8150826692581177, 0.8150826692581177, 0.8130165338516235, 0.807851254940033, 0.8150826692581177, 0.8192148804664612, 0.8150826692581177, 0.8150826692581177, 0.8212810158729553, 0.8192148804664612, 0.817148745059967, 0.8192148804664612, 0.8202479481697083, 0.8202479481697083, 0.8047520518302917, 0.817148745059967, 0.8264462947845459, 0.8181818127632141, 0.8181818127632141, 0.7902892827987671, 0.8068181872367859, 0.8233470916748047, 0.8192148804664612, 0.80888432264328, 0.8212810158729553]}\n","32/32 [==============================] - 1s 11ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.9424 - accuracy: 0.8319"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 60ms/step - loss: 0.9452 - accuracy: 0.8303 - val_loss: 1.2279 - val_accuracy: 0.7629\n","Epoch 2/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9352 - accuracy: 0.8362 - val_loss: 1.2215 - val_accuracy: 0.7317\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9249 - accuracy: 0.8346 - val_loss: 1.2136 - val_accuracy: 0.7543\n","Epoch 4/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.9161 - accuracy: 0.8427 - val_loss: 1.2056 - val_accuracy: 0.7662\n","Epoch 5/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.9072 - accuracy: 0.8459 - val_loss: 1.1966 - val_accuracy: 0.7737\n","Epoch 6/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.9041 - accuracy: 0.8464 - val_loss: 1.1862 - val_accuracy: 0.7812\n","Epoch 7/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.8999 - accuracy: 0.8424 - val_loss: 1.1755 - val_accuracy: 0.7899\n","Epoch 8/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8881 - accuracy: 0.8513 - val_loss: 1.1643 - val_accuracy: 0.7834\n","Epoch 9/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.8811 - accuracy: 0.8464 - val_loss: 1.1490 - val_accuracy: 0.7931\n","Epoch 10/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.8748 - accuracy: 0.8561 - val_loss: 1.1348 - val_accuracy: 0.7974\n","Epoch 11/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8696 - accuracy: 0.8559 - val_loss: 1.1147 - val_accuracy: 0.7974\n","Epoch 12/100\n","29/29 [==============================] - 2s 69ms/step - loss: 0.8680 - accuracy: 0.8516 - val_loss: 1.0961 - val_accuracy: 0.8060\n","Epoch 13/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.8635 - accuracy: 0.8521 - val_loss: 1.0711 - val_accuracy: 0.8093\n","Epoch 14/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8539 - accuracy: 0.8570 - val_loss: 1.0514 - val_accuracy: 0.8082\n","Epoch 15/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8519 - accuracy: 0.8545 - val_loss: 1.0222 - val_accuracy: 0.8093\n","Epoch 16/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8427 - accuracy: 0.8626 - val_loss: 0.9950 - val_accuracy: 0.8093\n","Epoch 17/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8375 - accuracy: 0.8596 - val_loss: 0.9687 - val_accuracy: 0.8093\n","Epoch 18/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8370 - accuracy: 0.8543 - val_loss: 0.9439 - val_accuracy: 0.8093\n","Epoch 19/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8312 - accuracy: 0.8599 - val_loss: 0.9253 - val_accuracy: 0.8082\n","Epoch 20/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.8258 - accuracy: 0.8607 - val_loss: 0.9036 - val_accuracy: 0.8147\n","Epoch 21/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8208 - accuracy: 0.8626 - val_loss: 0.8919 - val_accuracy: 0.8103\n","Epoch 22/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8219 - accuracy: 0.8578 - val_loss: 0.8850 - val_accuracy: 0.8093\n","Epoch 23/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8081 - accuracy: 0.8661 - val_loss: 0.8934 - val_accuracy: 0.7953\n","Epoch 24/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8083 - accuracy: 0.8631 - val_loss: 0.8665 - val_accuracy: 0.8125\n","Epoch 25/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8042 - accuracy: 0.8629 - val_loss: 0.8769 - val_accuracy: 0.8082\n","Epoch 26/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.7901 - accuracy: 0.8677 - val_loss: 0.8620 - val_accuracy: 0.8168\n","Epoch 27/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.7900 - accuracy: 0.8699 - val_loss: 0.8528 - val_accuracy: 0.8276\n","Epoch 28/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.7884 - accuracy: 0.8712 - val_loss: 0.8507 - val_accuracy: 0.8308\n","Epoch 29/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7830 - accuracy: 0.8726 - val_loss: 0.8498 - val_accuracy: 0.8276\n","Epoch 30/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7774 - accuracy: 0.8737 - val_loss: 0.8550 - val_accuracy: 0.8265\n","Epoch 31/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7754 - accuracy: 0.8707 - val_loss: 0.8621 - val_accuracy: 0.8179\n","Epoch 32/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7718 - accuracy: 0.8712 - val_loss: 0.8547 - val_accuracy: 0.8233\n","Epoch 33/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.7688 - accuracy: 0.8763 - val_loss: 0.8417 - val_accuracy: 0.8319\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7681 - accuracy: 0.8685 - val_loss: 0.8478 - val_accuracy: 0.8190\n","Epoch 35/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7614 - accuracy: 0.8696 - val_loss: 0.8544 - val_accuracy: 0.8168\n","Epoch 36/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.7541 - accuracy: 0.8753 - val_loss: 0.8349 - val_accuracy: 0.8362\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7481 - accuracy: 0.8769 - val_loss: 0.8351 - val_accuracy: 0.8308\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7425 - accuracy: 0.8798 - val_loss: 0.8370 - val_accuracy: 0.8287\n","Epoch 39/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7417 - accuracy: 0.8747 - val_loss: 0.8326 - val_accuracy: 0.8351\n","Epoch 40/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7366 - accuracy: 0.8766 - val_loss: 0.8282 - val_accuracy: 0.8276\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7410 - accuracy: 0.8772 - val_loss: 0.8335 - val_accuracy: 0.8254\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7398 - accuracy: 0.8753 - val_loss: 0.8190 - val_accuracy: 0.8330\n","Epoch 43/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7301 - accuracy: 0.8798 - val_loss: 0.8267 - val_accuracy: 0.8211\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7173 - accuracy: 0.8844 - val_loss: 0.8250 - val_accuracy: 0.8200\n","Epoch 45/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7169 - accuracy: 0.8825 - val_loss: 0.8163 - val_accuracy: 0.8276\n","Epoch 46/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7164 - accuracy: 0.8842 - val_loss: 0.8176 - val_accuracy: 0.8308\n","Epoch 47/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7089 - accuracy: 0.8879 - val_loss: 0.8103 - val_accuracy: 0.8330\n","Epoch 48/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.7067 - accuracy: 0.8798 - val_loss: 0.8184 - val_accuracy: 0.8190\n","Epoch 49/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7044 - accuracy: 0.8890 - val_loss: 0.8069 - val_accuracy: 0.8308\n","Epoch 50/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6982 - accuracy: 0.8860 - val_loss: 0.8181 - val_accuracy: 0.8222\n","Epoch 51/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6942 - accuracy: 0.8893 - val_loss: 0.8095 - val_accuracy: 0.8222\n","Epoch 52/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6902 - accuracy: 0.8879 - val_loss: 0.8082 - val_accuracy: 0.8200\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6868 - accuracy: 0.8925 - val_loss: 0.8023 - val_accuracy: 0.8330\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6851 - accuracy: 0.8882 - val_loss: 0.7968 - val_accuracy: 0.8276\n","Epoch 55/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6944 - accuracy: 0.8844 - val_loss: 0.8181 - val_accuracy: 0.8179\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6833 - accuracy: 0.8887 - val_loss: 0.8171 - val_accuracy: 0.8157\n","Epoch 57/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6749 - accuracy: 0.8925 - val_loss: 0.7957 - val_accuracy: 0.8341\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6755 - accuracy: 0.8906 - val_loss: 0.7877 - val_accuracy: 0.8351\n","Epoch 59/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6662 - accuracy: 0.8957 - val_loss: 0.7892 - val_accuracy: 0.8265\n","Epoch 60/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6713 - accuracy: 0.8904 - val_loss: 0.8017 - val_accuracy: 0.8233\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6623 - accuracy: 0.8976 - val_loss: 0.7855 - val_accuracy: 0.8351\n","Epoch 62/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6638 - accuracy: 0.8941 - val_loss: 0.8039 - val_accuracy: 0.8244\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6537 - accuracy: 0.8982 - val_loss: 0.7842 - val_accuracy: 0.8276\n","Epoch 64/100\n","29/29 [==============================] - 1s 47ms/step - loss: 0.6523 - accuracy: 0.8971 - val_loss: 0.7803 - val_accuracy: 0.8416\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6477 - accuracy: 0.8995 - val_loss: 0.7803 - val_accuracy: 0.8319\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6366 - accuracy: 0.9049 - val_loss: 0.7815 - val_accuracy: 0.8265\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6421 - accuracy: 0.9003 - val_loss: 0.8309 - val_accuracy: 0.8071\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6391 - accuracy: 0.9009 - val_loss: 0.7951 - val_accuracy: 0.8254\n","Epoch 69/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6367 - accuracy: 0.9006 - val_loss: 0.8080 - val_accuracy: 0.8179\n","Epoch 70/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6393 - accuracy: 0.8966 - val_loss: 0.7786 - val_accuracy: 0.8362\n","Epoch 71/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6373 - accuracy: 0.8979 - val_loss: 0.7811 - val_accuracy: 0.8373\n","Epoch 72/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6278 - accuracy: 0.9006 - val_loss: 0.7734 - val_accuracy: 0.8362\n","Epoch 73/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6339 - accuracy: 0.8955 - val_loss: 0.7704 - val_accuracy: 0.8319\n","Epoch 74/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6209 - accuracy: 0.9054 - val_loss: 0.7739 - val_accuracy: 0.8384\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6214 - accuracy: 0.9079 - val_loss: 0.7676 - val_accuracy: 0.8330\n","Epoch 76/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6182 - accuracy: 0.9087 - val_loss: 0.8141 - val_accuracy: 0.8168\n","Epoch 77/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6147 - accuracy: 0.9052 - val_loss: 0.7724 - val_accuracy: 0.8276\n","Epoch 78/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6054 - accuracy: 0.9130 - val_loss: 0.7700 - val_accuracy: 0.8362\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6056 - accuracy: 0.9076 - val_loss: 0.7762 - val_accuracy: 0.8287\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5986 - accuracy: 0.9114 - val_loss: 0.7699 - val_accuracy: 0.8265\n","Epoch 81/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6026 - accuracy: 0.9114 - val_loss: 0.7976 - val_accuracy: 0.8168\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5998 - accuracy: 0.9098 - val_loss: 0.7611 - val_accuracy: 0.8308\n","Epoch 83/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5994 - accuracy: 0.9081 - val_loss: 0.7722 - val_accuracy: 0.8276\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5901 - accuracy: 0.9122 - val_loss: 0.7658 - val_accuracy: 0.8362\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5828 - accuracy: 0.9143 - val_loss: 0.7579 - val_accuracy: 0.8362\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5824 - accuracy: 0.9157 - val_loss: 0.7596 - val_accuracy: 0.8287\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5778 - accuracy: 0.9189 - val_loss: 0.7593 - val_accuracy: 0.8330\n","Epoch 88/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5780 - accuracy: 0.9162 - val_loss: 0.7572 - val_accuracy: 0.8373\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5745 - accuracy: 0.9178 - val_loss: 0.7568 - val_accuracy: 0.8373\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5665 - accuracy: 0.9200 - val_loss: 0.7584 - val_accuracy: 0.8319\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5650 - accuracy: 0.9219 - val_loss: 0.7586 - val_accuracy: 0.8330\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5663 - accuracy: 0.9146 - val_loss: 0.7714 - val_accuracy: 0.8276\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5645 - accuracy: 0.9181 - val_loss: 0.7755 - val_accuracy: 0.8265\n","Epoch 94/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5559 - accuracy: 0.9227 - val_loss: 0.8084 - val_accuracy: 0.8125\n","Epoch 95/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5533 - accuracy: 0.9232 - val_loss: 0.7577 - val_accuracy: 0.8373\n","Epoch 96/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5503 - accuracy: 0.9246 - val_loss: 0.7958 - val_accuracy: 0.8114\n","Epoch 97/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5514 - accuracy: 0.9235 - val_loss: 0.7646 - val_accuracy: 0.8276\n","Epoch 98/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5399 - accuracy: 0.9300 - val_loss: 0.7535 - val_accuracy: 0.8384\n","Epoch 99/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5510 - accuracy: 0.9246 - val_loss: 0.7581 - val_accuracy: 0.8384\n","Epoch 100/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5467 - accuracy: 0.9246 - val_loss: 0.7581 - val_accuracy: 0.8222\n","{'loss': [0.9451980590820312, 0.9352432489395142, 0.9249486327171326, 0.9161306023597717, 0.9071846604347229, 0.9040534496307373, 0.8999272584915161, 0.8881046175956726, 0.8811365365982056, 0.8747718930244446, 0.8696167469024658, 0.868047297000885, 0.8635050654411316, 0.8539035320281982, 0.8518530130386353, 0.8426528573036194, 0.8374627232551575, 0.83696049451828, 0.8311976194381714, 0.8258286118507385, 0.8208244442939758, 0.8218899369239807, 0.8080840110778809, 0.8083401322364807, 0.8042290210723877, 0.7901085615158081, 0.789972186088562, 0.7884362936019897, 0.7830201983451843, 0.7774295806884766, 0.7754093408584595, 0.7718035578727722, 0.7688330411911011, 0.768120288848877, 0.7613787055015564, 0.754062294960022, 0.7481247186660767, 0.7424857020378113, 0.741715133190155, 0.7365769147872925, 0.7409659028053284, 0.739817202091217, 0.7300878167152405, 0.7173418998718262, 0.7168513536453247, 0.7163739204406738, 0.7088878750801086, 0.7066656947135925, 0.7043667435646057, 0.6981542706489563, 0.6942492723464966, 0.6901513934135437, 0.6868310570716858, 0.6850973963737488, 0.6944200396537781, 0.6832786202430725, 0.6748681664466858, 0.6754859685897827, 0.6662032604217529, 0.6713374853134155, 0.6623080968856812, 0.6637641191482544, 0.6536502242088318, 0.6522530913352966, 0.647676944732666, 0.6365997791290283, 0.6421392560005188, 0.6390945315361023, 0.6367285251617432, 0.6393435001373291, 0.6372762322425842, 0.6278082132339478, 0.6338711380958557, 0.6208907961845398, 0.6213645935058594, 0.6182277202606201, 0.614681601524353, 0.6053741574287415, 0.6056389808654785, 0.5985831022262573, 0.6025582551956177, 0.599759578704834, 0.5993842482566833, 0.5900550484657288, 0.5828014612197876, 0.5823574066162109, 0.577760636806488, 0.5779805183410645, 0.5745498538017273, 0.566465437412262, 0.5649862885475159, 0.566344678401947, 0.5644516944885254, 0.5559190511703491, 0.5533360838890076, 0.5502587556838989, 0.5514339804649353, 0.5399068593978882, 0.5509780645370483, 0.5467126369476318], 'accuracy': [0.8302801847457886, 0.8362069129943848, 0.834590494632721, 0.8426724076271057, 0.8459051847457886, 0.8464439511299133, 0.842402994632721, 0.8512930870056152, 0.8464439511299133, 0.8561422228813171, 0.8558728694915771, 0.8515625, 0.8521012663841248, 0.8569504022598267, 0.8545258641242981, 0.8626077771186829, 0.8596444129943848, 0.8542564511299133, 0.8599137663841248, 0.860722005367279, 0.8626077771186829, 0.857758641242981, 0.8661099076271057, 0.8631465435028076, 0.8628771305084229, 0.8677262663841248, 0.8698814511299133, 0.8712284564971924, 0.8725754022598267, 0.873652994632721, 0.8706896305084229, 0.8712284564971924, 0.876347005367279, 0.868534505367279, 0.8696120977401733, 0.8752694129943848, 0.8768857717514038, 0.8798491358757019, 0.8747305870056152, 0.876616358757019, 0.8771551847457886, 0.8752694129943848, 0.8798491358757019, 0.884428858757019, 0.8825430870056152, 0.884159505367279, 0.8879310488700867, 0.8798491358757019, 0.889008641242981, 0.8860452771186829, 0.889277994632721, 0.8879310488700867, 0.8925107717514038, 0.8882004022598267, 0.884428858757019, 0.8887392282485962, 0.8925107717514038, 0.890625, 0.8957435488700867, 0.8903555870056152, 0.8976293206214905, 0.8941271305084229, 0.8981680870056152, 0.897090494632721, 0.8995150923728943, 0.904902994632721, 0.9003232717514038, 0.9008620977401733, 0.9005926847457886, 0.8965517282485962, 0.8978987336158752, 0.9005926847457886, 0.8954741358757019, 0.9054418206214905, 0.907866358757019, 0.9086745977401733, 0.9051724076271057, 0.9129849076271057, 0.907597005367279, 0.9113685488700867, 0.9113685488700867, 0.9097521305084229, 0.9081357717514038, 0.9121767282485962, 0.9143319129943848, 0.915678858757019, 0.9189116358757019, 0.9162176847457886, 0.9178340435028076, 0.9199892282485962, 0.921875, 0.9146012663841248, 0.9181034564971924, 0.9226831793785095, 0.923222005367279, 0.9245689511299133, 0.923491358757019, 0.9299569129943848, 0.9245689511299133, 0.9245689511299133], 'val_loss': [1.2278861999511719, 1.2215449810028076, 1.2136337757110596, 1.2056392431259155, 1.196636438369751, 1.1862037181854248, 1.175490379333496, 1.1642512083053589, 1.148990511894226, 1.1347646713256836, 1.1146825551986694, 1.09610116481781, 1.071060299873352, 1.051361322402954, 1.0222301483154297, 0.9949941039085388, 0.9687179923057556, 0.9438895583152771, 0.9253215193748474, 0.9035821557044983, 0.8919476866722107, 0.8849990963935852, 0.8934370875358582, 0.866481363773346, 0.8768673539161682, 0.8620217442512512, 0.8527513742446899, 0.8507333397865295, 0.8498292565345764, 0.8550392389297485, 0.8620808124542236, 0.8547311425209045, 0.8416789770126343, 0.8478341102600098, 0.8544266223907471, 0.8348898887634277, 0.8351447582244873, 0.8370215892791748, 0.8326157331466675, 0.8282122611999512, 0.8335297703742981, 0.8190074563026428, 0.8266544342041016, 0.8249897360801697, 0.8162893056869507, 0.8175523281097412, 0.810257077217102, 0.8183547258377075, 0.8069299459457397, 0.8181334137916565, 0.8095085620880127, 0.8082050681114197, 0.8023157715797424, 0.7967947125434875, 0.8180611729621887, 0.8171172738075256, 0.7956875562667847, 0.7876600623130798, 0.7891629338264465, 0.8017449975013733, 0.7854694724082947, 0.8038808703422546, 0.7842181921005249, 0.7803148031234741, 0.7803098559379578, 0.7815156579017639, 0.830901026725769, 0.7951082587242126, 0.8079780340194702, 0.77864670753479, 0.7811011672019958, 0.7734032273292542, 0.7703811526298523, 0.7739336490631104, 0.7676153779029846, 0.8141282796859741, 0.7724006772041321, 0.7700480222702026, 0.7762014865875244, 0.7698623538017273, 0.7976234555244446, 0.7611351609230042, 0.7721554040908813, 0.7658068537712097, 0.7579435110092163, 0.7595537900924683, 0.7593190670013428, 0.7572222948074341, 0.7567529082298279, 0.7583984136581421, 0.7585627436637878, 0.7714070081710815, 0.775508463382721, 0.8084365129470825, 0.7577389478683472, 0.7957793474197388, 0.7645992636680603, 0.7534804344177246, 0.7581153512001038, 0.7580746412277222], 'val_accuracy': [0.7629310488700867, 0.7316810488700867, 0.7543103694915771, 0.7661637663841248, 0.7737069129943848, 0.78125, 0.7898706793785095, 0.7834051847457886, 0.7931034564971924, 0.7974137663841248, 0.7974137663841248, 0.806034505367279, 0.8092672228813171, 0.8081896305084229, 0.8092672228813171, 0.8092672228813171, 0.8092672228813171, 0.8092672228813171, 0.8081896305084229, 0.8146551847457886, 0.8103448152542114, 0.8092672228813171, 0.795258641242981, 0.8125, 0.8081896305084229, 0.8168103694915771, 0.8275862336158752, 0.8308189511299133, 0.8275862336158752, 0.826508641242981, 0.8178879022598267, 0.8232758641242981, 0.8318965435028076, 0.818965494632721, 0.8168103694915771, 0.8362069129943848, 0.8308189511299133, 0.8286637663841248, 0.8351293206214905, 0.8275862336158752, 0.8254310488700867, 0.8329741358757019, 0.8211206793785095, 0.8200430870056152, 0.8275862336158752, 0.8308189511299133, 0.8329741358757019, 0.818965494632721, 0.8308189511299133, 0.8221982717514038, 0.8221982717514038, 0.8200430870056152, 0.8329741358757019, 0.8275862336158752, 0.8178879022598267, 0.8157327771186829, 0.8340517282485962, 0.8351293206214905, 0.826508641242981, 0.8232758641242981, 0.8351293206214905, 0.8243534564971924, 0.8275862336158752, 0.8415948152542114, 0.8318965435028076, 0.826508641242981, 0.8071120977401733, 0.8254310488700867, 0.8178879022598267, 0.8362069129943848, 0.837284505367279, 0.8362069129943848, 0.8318965435028076, 0.8383620977401733, 0.8329741358757019, 0.8168103694915771, 0.8275862336158752, 0.8362069129943848, 0.8286637663841248, 0.826508641242981, 0.8168103694915771, 0.8308189511299133, 0.8275862336158752, 0.8362069129943848, 0.8362069129943848, 0.8286637663841248, 0.8329741358757019, 0.837284505367279, 0.837284505367279, 0.8318965435028076, 0.8329741358757019, 0.8275862336158752, 0.826508641242981, 0.8125, 0.837284505367279, 0.8114224076271057, 0.8275862336158752, 0.8383620977401733, 0.8383620977401733, 0.8221982717514038]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.9724 - accuracy: 0.8173"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 80ms/step - loss: 0.9753 - accuracy: 0.8147 - val_loss: 1.2299 - val_accuracy: 0.7489\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9597 - accuracy: 0.8186 - val_loss: 1.2241 - val_accuracy: 0.7104\n","Epoch 3/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9490 - accuracy: 0.8277 - val_loss: 1.2166 - val_accuracy: 0.7421\n","Epoch 4/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9441 - accuracy: 0.8226 - val_loss: 1.2095 - val_accuracy: 0.7262\n","Epoch 5/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.9425 - accuracy: 0.8251 - val_loss: 1.2014 - val_accuracy: 0.7783\n","Epoch 6/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.9295 - accuracy: 0.8234 - val_loss: 1.1923 - val_accuracy: 0.7907\n","Epoch 7/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9245 - accuracy: 0.8333 - val_loss: 1.1841 - val_accuracy: 0.7794\n","Epoch 8/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9205 - accuracy: 0.8305 - val_loss: 1.1738 - val_accuracy: 0.7828\n","Epoch 9/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.9103 - accuracy: 0.8345 - val_loss: 1.1611 - val_accuracy: 0.8020\n","Epoch 10/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9014 - accuracy: 0.8379 - val_loss: 1.1479 - val_accuracy: 0.8020\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8979 - accuracy: 0.8345 - val_loss: 1.1341 - val_accuracy: 0.7930\n","Epoch 12/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.8998 - accuracy: 0.8294 - val_loss: 1.1169 - val_accuracy: 0.8043\n","Epoch 13/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.8868 - accuracy: 0.8373 - val_loss: 1.0971 - val_accuracy: 0.8088\n","Epoch 14/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8818 - accuracy: 0.8404 - val_loss: 1.0773 - val_accuracy: 0.8032\n","Epoch 15/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.8846 - accuracy: 0.8387 - val_loss: 1.0529 - val_accuracy: 0.8122\n","Epoch 16/100\n","28/28 [==============================] - 1s 42ms/step - loss: 0.8796 - accuracy: 0.8401 - val_loss: 1.0307 - val_accuracy: 0.8145\n","Epoch 17/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8695 - accuracy: 0.8401 - val_loss: 1.0064 - val_accuracy: 0.8111\n","Epoch 18/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8666 - accuracy: 0.8384 - val_loss: 0.9879 - val_accuracy: 0.8054\n","Epoch 19/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8644 - accuracy: 0.8404 - val_loss: 0.9595 - val_accuracy: 0.8133\n","Epoch 20/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8678 - accuracy: 0.8396 - val_loss: 0.9391 - val_accuracy: 0.8088\n","Epoch 21/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.8527 - accuracy: 0.8469 - val_loss: 0.9271 - val_accuracy: 0.8156\n","Epoch 22/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8495 - accuracy: 0.8379 - val_loss: 0.9138 - val_accuracy: 0.8133\n","Epoch 23/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.8425 - accuracy: 0.8492 - val_loss: 0.9084 - val_accuracy: 0.8167\n","Epoch 24/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8381 - accuracy: 0.8514 - val_loss: 0.9139 - val_accuracy: 0.8066\n","Epoch 25/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8297 - accuracy: 0.8529 - val_loss: 0.9008 - val_accuracy: 0.8145\n","Epoch 26/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8325 - accuracy: 0.8503 - val_loss: 0.8874 - val_accuracy: 0.8145\n","Epoch 27/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8317 - accuracy: 0.8415 - val_loss: 0.8851 - val_accuracy: 0.8133\n","Epoch 28/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8254 - accuracy: 0.8463 - val_loss: 0.8906 - val_accuracy: 0.8133\n","Epoch 29/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8152 - accuracy: 0.8565 - val_loss: 0.8988 - val_accuracy: 0.8156\n","Epoch 30/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8168 - accuracy: 0.8503 - val_loss: 0.9268 - val_accuracy: 0.8020\n","Epoch 31/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8097 - accuracy: 0.8514 - val_loss: 0.8891 - val_accuracy: 0.8167\n","Epoch 32/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8023 - accuracy: 0.8540 - val_loss: 0.8790 - val_accuracy: 0.8122\n","Epoch 33/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7988 - accuracy: 0.8563 - val_loss: 0.8816 - val_accuracy: 0.8156\n","Epoch 34/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7927 - accuracy: 0.8563 - val_loss: 0.8783 - val_accuracy: 0.8111\n","Epoch 35/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7996 - accuracy: 0.8531 - val_loss: 0.8767 - val_accuracy: 0.8145\n","Epoch 36/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7879 - accuracy: 0.8580 - val_loss: 0.8715 - val_accuracy: 0.8156\n","Epoch 37/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.7846 - accuracy: 0.8568 - val_loss: 0.8699 - val_accuracy: 0.8179\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7804 - accuracy: 0.8585 - val_loss: 0.8688 - val_accuracy: 0.8133\n","Epoch 39/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7730 - accuracy: 0.8647 - val_loss: 0.8741 - val_accuracy: 0.8111\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7876 - accuracy: 0.8444 - val_loss: 0.8780 - val_accuracy: 0.8167\n","Epoch 41/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7750 - accuracy: 0.8588 - val_loss: 0.8699 - val_accuracy: 0.8088\n","Epoch 42/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7653 - accuracy: 0.8580 - val_loss: 0.8604 - val_accuracy: 0.8100\n","Epoch 43/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7587 - accuracy: 0.8673 - val_loss: 0.8638 - val_accuracy: 0.8145\n","Epoch 44/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7556 - accuracy: 0.8647 - val_loss: 0.8587 - val_accuracy: 0.8066\n","Epoch 45/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7543 - accuracy: 0.8625 - val_loss: 0.8562 - val_accuracy: 0.8100\n","Epoch 46/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7631 - accuracy: 0.8543 - val_loss: 0.9225 - val_accuracy: 0.7998\n","Epoch 47/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7478 - accuracy: 0.8684 - val_loss: 0.8516 - val_accuracy: 0.8133\n","Epoch 48/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7434 - accuracy: 0.8662 - val_loss: 0.8498 - val_accuracy: 0.8100\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7429 - accuracy: 0.8667 - val_loss: 0.8494 - val_accuracy: 0.8100\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7323 - accuracy: 0.8704 - val_loss: 0.8709 - val_accuracy: 0.8111\n","Epoch 51/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7335 - accuracy: 0.8670 - val_loss: 0.8435 - val_accuracy: 0.8122\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7313 - accuracy: 0.8755 - val_loss: 0.8424 - val_accuracy: 0.8100\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7236 - accuracy: 0.8721 - val_loss: 0.8464 - val_accuracy: 0.8167\n","Epoch 54/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7183 - accuracy: 0.8729 - val_loss: 0.8404 - val_accuracy: 0.8088\n","Epoch 55/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7231 - accuracy: 0.8633 - val_loss: 0.8476 - val_accuracy: 0.8088\n","Epoch 56/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7224 - accuracy: 0.8676 - val_loss: 0.8409 - val_accuracy: 0.8088\n","Epoch 57/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7110 - accuracy: 0.8738 - val_loss: 0.8373 - val_accuracy: 0.8111\n","Epoch 58/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7115 - accuracy: 0.8701 - val_loss: 0.8510 - val_accuracy: 0.8066\n","Epoch 59/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7076 - accuracy: 0.8741 - val_loss: 0.8325 - val_accuracy: 0.8066\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7081 - accuracy: 0.8729 - val_loss: 0.8332 - val_accuracy: 0.8179\n","Epoch 61/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6967 - accuracy: 0.8786 - val_loss: 0.8314 - val_accuracy: 0.8066\n","Epoch 62/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6964 - accuracy: 0.8812 - val_loss: 0.8430 - val_accuracy: 0.8054\n","Epoch 63/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6983 - accuracy: 0.8755 - val_loss: 0.8287 - val_accuracy: 0.8077\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6895 - accuracy: 0.8778 - val_loss: 0.8356 - val_accuracy: 0.8054\n","Epoch 65/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6896 - accuracy: 0.8766 - val_loss: 0.8275 - val_accuracy: 0.8133\n","Epoch 66/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6740 - accuracy: 0.8882 - val_loss: 0.8258 - val_accuracy: 0.8054\n","Epoch 67/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6771 - accuracy: 0.8829 - val_loss: 0.8322 - val_accuracy: 0.8054\n","Epoch 68/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6799 - accuracy: 0.8758 - val_loss: 0.8202 - val_accuracy: 0.8100\n","Epoch 69/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6758 - accuracy: 0.8820 - val_loss: 0.8336 - val_accuracy: 0.8122\n","Epoch 70/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6717 - accuracy: 0.8809 - val_loss: 0.8207 - val_accuracy: 0.8077\n","Epoch 71/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6641 - accuracy: 0.8840 - val_loss: 0.8262 - val_accuracy: 0.8088\n","Epoch 72/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6596 - accuracy: 0.8834 - val_loss: 0.8349 - val_accuracy: 0.8145\n","Epoch 73/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6584 - accuracy: 0.8882 - val_loss: 0.8216 - val_accuracy: 0.8077\n","Epoch 74/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6541 - accuracy: 0.8868 - val_loss: 0.8195 - val_accuracy: 0.8066\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6537 - accuracy: 0.8843 - val_loss: 0.8183 - val_accuracy: 0.8133\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6517 - accuracy: 0.8882 - val_loss: 0.8216 - val_accuracy: 0.8145\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6514 - accuracy: 0.8874 - val_loss: 0.8316 - val_accuracy: 0.8009\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6466 - accuracy: 0.8888 - val_loss: 0.8168 - val_accuracy: 0.8122\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6416 - accuracy: 0.8913 - val_loss: 0.8144 - val_accuracy: 0.8133\n","Epoch 80/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6376 - accuracy: 0.8905 - val_loss: 0.8168 - val_accuracy: 0.8111\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6320 - accuracy: 0.8945 - val_loss: 0.8672 - val_accuracy: 0.7952\n","Epoch 82/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6603 - accuracy: 0.8789 - val_loss: 0.8359 - val_accuracy: 0.8179\n","Epoch 83/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6312 - accuracy: 0.8902 - val_loss: 0.8102 - val_accuracy: 0.8032\n","Epoch 84/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6244 - accuracy: 0.9010 - val_loss: 0.8100 - val_accuracy: 0.8054\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6224 - accuracy: 0.8990 - val_loss: 0.8092 - val_accuracy: 0.8111\n","Epoch 86/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6264 - accuracy: 0.8899 - val_loss: 0.8103 - val_accuracy: 0.8077\n","Epoch 87/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6125 - accuracy: 0.8990 - val_loss: 0.8106 - val_accuracy: 0.8100\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6070 - accuracy: 0.9010 - val_loss: 0.8285 - val_accuracy: 0.8032\n","Epoch 89/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6129 - accuracy: 0.9010 - val_loss: 0.8278 - val_accuracy: 0.8133\n","Epoch 90/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6142 - accuracy: 0.8993 - val_loss: 0.8114 - val_accuracy: 0.8122\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6045 - accuracy: 0.9004 - val_loss: 0.8130 - val_accuracy: 0.8088\n","Epoch 92/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5978 - accuracy: 0.9027 - val_loss: 0.8314 - val_accuracy: 0.8088\n","Epoch 93/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6104 - accuracy: 0.8998 - val_loss: 0.8281 - val_accuracy: 0.8122\n","Epoch 94/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6005 - accuracy: 0.9015 - val_loss: 0.8096 - val_accuracy: 0.7998\n","Epoch 95/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5932 - accuracy: 0.9055 - val_loss: 0.8080 - val_accuracy: 0.8066\n","Epoch 96/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5936 - accuracy: 0.9041 - val_loss: 0.8173 - val_accuracy: 0.8122\n","Epoch 97/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5912 - accuracy: 0.9044 - val_loss: 0.8152 - val_accuracy: 0.8122\n","Epoch 98/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5851 - accuracy: 0.9078 - val_loss: 0.8239 - val_accuracy: 0.8054\n","Epoch 99/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5766 - accuracy: 0.9095 - val_loss: 0.8130 - val_accuracy: 0.8054\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5720 - accuracy: 0.9123 - val_loss: 0.8130 - val_accuracy: 0.8077\n","{'loss': [0.9752863645553589, 0.9596928358078003, 0.9489781856536865, 0.9440565705299377, 0.9424624443054199, 0.9295453429222107, 0.9244509935379028, 0.9204530715942383, 0.9103164076805115, 0.9014458656311035, 0.8979150056838989, 0.8998205661773682, 0.8868048191070557, 0.881759762763977, 0.8846423029899597, 0.8796425461769104, 0.8694906234741211, 0.8665629625320435, 0.8643680810928345, 0.867762565612793, 0.8527213335037231, 0.8494632840156555, 0.8425439596176147, 0.8380951881408691, 0.8297284841537476, 0.8324691653251648, 0.8316781520843506, 0.8254449963569641, 0.8152022361755371, 0.8168458938598633, 0.8096935749053955, 0.8023234009742737, 0.798826277256012, 0.7927038073539734, 0.799564003944397, 0.7879133224487305, 0.7845913767814636, 0.780396044254303, 0.7729846835136414, 0.7875611186027527, 0.7750015258789062, 0.7653334140777588, 0.758660078048706, 0.7555913925170898, 0.7542685270309448, 0.763072669506073, 0.7478106021881104, 0.7433786392211914, 0.7428892254829407, 0.7322723865509033, 0.7334743738174438, 0.7313458919525146, 0.7235821485519409, 0.7182921767234802, 0.7231441736221313, 0.7224018573760986, 0.7110499143600464, 0.7114558219909668, 0.7075778245925903, 0.7081206440925598, 0.6966937780380249, 0.6964101791381836, 0.698313295841217, 0.6895444989204407, 0.6896073222160339, 0.6739944815635681, 0.6771237254142761, 0.6798791885375977, 0.6758015155792236, 0.6717047691345215, 0.6640859842300415, 0.6596490144729614, 0.6584110260009766, 0.654098391532898, 0.653691291809082, 0.651674211025238, 0.6514258980751038, 0.6465534567832947, 0.6415979266166687, 0.6375507116317749, 0.631997287273407, 0.6603291034698486, 0.6312312483787537, 0.6244387626647949, 0.6223617196083069, 0.6263853907585144, 0.6125310659408569, 0.606963038444519, 0.6128759384155273, 0.6142387390136719, 0.6045053005218506, 0.597832977771759, 0.6104045510292053, 0.600523054599762, 0.5932468175888062, 0.5935632586479187, 0.5912359952926636, 0.5851109027862549, 0.5766327381134033, 0.5720165371894836], 'accuracy': [0.8146576285362244, 0.8186191320419312, 0.8276740312576294, 0.8225806355476379, 0.825127363204956, 0.823429524898529, 0.8333333134651184, 0.8305037021636963, 0.8344652056694031, 0.8378607630729675, 0.8344652056694031, 0.8293718099594116, 0.83729487657547, 0.8404074907302856, 0.8387096524238586, 0.8401244878768921, 0.8401244878768921, 0.8384267091751099, 0.8404074907302856, 0.8395586013793945, 0.8469156622886658, 0.8378607630729675, 0.8491793870925903, 0.8514431118965149, 0.8528579473495483, 0.850311279296875, 0.8415393233299255, 0.8463497161865234, 0.8565365076065063, 0.850311279296875, 0.8514431118965149, 0.853989839553833, 0.8562535643577576, 0.8562535643577576, 0.8531408905982971, 0.8579513430595398, 0.8568194508552551, 0.8585172891616821, 0.8647425174713135, 0.8443689942359924, 0.8588002324104309, 0.8579513430595398, 0.8672891855239868, 0.8647425174713135, 0.8624787926673889, 0.8542727828025818, 0.8684210777282715, 0.8661573529243469, 0.8667232394218445, 0.8704017996788025, 0.867006242275238, 0.875495195388794, 0.8720995783805847, 0.8729485273361206, 0.86332768201828, 0.8675721287727356, 0.8737974166870117, 0.8701188564300537, 0.8740803599357605, 0.8729485273361206, 0.8786078095436096, 0.881154477596283, 0.875495195388794, 0.8777589201927185, 0.8766270279884338, 0.8882286548614502, 0.88285231590271, 0.8757781386375427, 0.8820033669471741, 0.8808715343475342, 0.8839841485023499, 0.8834182024002075, 0.8882286548614502, 0.8868138194084167, 0.8842670917510986, 0.8882286548614502, 0.8873797655105591, 0.8887945413589478, 0.8913412690162659, 0.8904923796653748, 0.8944538831710815, 0.8788907527923584, 0.8902093768119812, 0.9009620547294617, 0.8989813327789307, 0.8899264335632324, 0.8989813327789307, 0.9009620547294617, 0.9009620547294617, 0.8992642760276794, 0.9003961682319641, 0.9026598930358887, 0.8998302221298218, 0.901528000831604, 0.9054895043373108, 0.9040747284889221, 0.9043576717376709, 0.9077532291412354, 0.9094510674476624, 0.9122806787490845], 'val_loss': [1.2299333810806274, 1.2240983247756958, 1.216639757156372, 1.2095134258270264, 1.2013578414916992, 1.1923067569732666, 1.184140682220459, 1.173840045928955, 1.161051869392395, 1.1479270458221436, 1.1340571641921997, 1.11686372756958, 1.097090244293213, 1.077256202697754, 1.0528621673583984, 1.0307015180587769, 1.0063917636871338, 0.987914502620697, 0.9594878554344177, 0.9390770196914673, 0.92706698179245, 0.9137625694274902, 0.9083603620529175, 0.913905918598175, 0.9008041024208069, 0.8874099254608154, 0.8851434588432312, 0.89055997133255, 0.8988397717475891, 0.9268069863319397, 0.8890830874443054, 0.8789739012718201, 0.88157057762146, 0.8783437609672546, 0.8767363429069519, 0.8714930415153503, 0.8699131011962891, 0.8688450455665588, 0.8740625381469727, 0.8779975175857544, 0.8699452877044678, 0.8603519201278687, 0.8638294339179993, 0.8586584329605103, 0.8561522960662842, 0.9224828481674194, 0.8515954613685608, 0.8497805595397949, 0.8494023680686951, 0.8708597421646118, 0.8435285091400146, 0.842384934425354, 0.8463557958602905, 0.840385377407074, 0.8476373553276062, 0.8409311175346375, 0.8372820019721985, 0.851033627986908, 0.83246910572052, 0.8332324624061584, 0.8313775658607483, 0.8430029153823853, 0.8287269473075867, 0.8356024026870728, 0.8274952173233032, 0.8257791996002197, 0.8321784734725952, 0.8201942443847656, 0.8336077332496643, 0.8206901550292969, 0.8261674642562866, 0.8349404335021973, 0.8215808272361755, 0.8194646239280701, 0.8183115124702454, 0.8216317892074585, 0.8316130638122559, 0.8168137073516846, 0.8144303560256958, 0.8167917728424072, 0.867246687412262, 0.8358643651008606, 0.8102205991744995, 0.8099574446678162, 0.8092334270477295, 0.8102814555168152, 0.8105866312980652, 0.8285439610481262, 0.8277738690376282, 0.8113634586334229, 0.812974750995636, 0.831353485584259, 0.8281338810920715, 0.8096445202827454, 0.8079806566238403, 0.8173052072525024, 0.8151833415031433, 0.8238621950149536, 0.8129868507385254, 0.8129822015762329], 'val_accuracy': [0.7488687634468079, 0.7104072570800781, 0.7420814633369446, 0.726244330406189, 0.7782805562019348, 0.790723979473114, 0.779411792755127, 0.7828054428100586, 0.8020362257957458, 0.8020362257957458, 0.7929864525794983, 0.8042986392974854, 0.8088235259056091, 0.8031674027442932, 0.8122171759605408, 0.814479649066925, 0.8110859990119934, 0.8054298758506775, 0.8133484125137329, 0.8088235259056091, 0.8156108856201172, 0.8133484125137329, 0.8167420625686646, 0.8065611124038696, 0.814479649066925, 0.814479649066925, 0.8133484125137329, 0.8133484125137329, 0.8156108856201172, 0.8020362257957458, 0.8167420625686646, 0.8122171759605408, 0.8156108856201172, 0.8110859990119934, 0.814479649066925, 0.8156108856201172, 0.8178732991218567, 0.8133484125137329, 0.8110859990119934, 0.8167420625686646, 0.8088235259056091, 0.8099547624588013, 0.814479649066925, 0.8065611124038696, 0.8099547624588013, 0.7997737526893616, 0.8133484125137329, 0.8099547624588013, 0.8099547624588013, 0.8110859990119934, 0.8122171759605408, 0.8099547624588013, 0.8167420625686646, 0.8088235259056091, 0.8088235259056091, 0.8088235259056091, 0.8110859990119934, 0.8065611124038696, 0.8065611124038696, 0.8178732991218567, 0.8065611124038696, 0.8054298758506775, 0.807692289352417, 0.8054298758506775, 0.8133484125137329, 0.8054298758506775, 0.8054298758506775, 0.8099547624588013, 0.8122171759605408, 0.807692289352417, 0.8088235259056091, 0.814479649066925, 0.807692289352417, 0.8065611124038696, 0.8133484125137329, 0.814479649066925, 0.8009049892425537, 0.8122171759605408, 0.8133484125137329, 0.8110859990119934, 0.7952488660812378, 0.8178732991218567, 0.8031674027442932, 0.8054298758506775, 0.8110859990119934, 0.807692289352417, 0.8099547624588013, 0.8031674027442932, 0.8133484125137329, 0.8122171759605408, 0.8088235259056091, 0.8088235259056091, 0.8122171759605408, 0.7997737526893616, 0.8065611124038696, 0.8122171759605408, 0.8122171759605408, 0.8054298758506775, 0.8054298758506775, 0.807692289352417]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.9361 - accuracy: 0.8408"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 9s 76ms/step - loss: 0.9361 - accuracy: 0.8408 - val_loss: 1.2284 - val_accuracy: 0.7159\n","Epoch 2/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9200 - accuracy: 0.8442 - val_loss: 1.2202 - val_accuracy: 0.7231\n","Epoch 3/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.9117 - accuracy: 0.8442 - val_loss: 1.2117 - val_accuracy: 0.7562\n","Epoch 4/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9055 - accuracy: 0.8439 - val_loss: 1.2025 - val_accuracy: 0.7738\n","Epoch 5/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.8926 - accuracy: 0.8486 - val_loss: 1.1932 - val_accuracy: 0.7748\n","Epoch 6/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8861 - accuracy: 0.8486 - val_loss: 1.1806 - val_accuracy: 0.8037\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8827 - accuracy: 0.8519 - val_loss: 1.1684 - val_accuracy: 0.7924\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8748 - accuracy: 0.8504 - val_loss: 1.1542 - val_accuracy: 0.7924\n","Epoch 9/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.8675 - accuracy: 0.8540 - val_loss: 1.1372 - val_accuracy: 0.8068\n","Epoch 10/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8740 - accuracy: 0.8486 - val_loss: 1.1206 - val_accuracy: 0.8068\n","Epoch 11/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.8563 - accuracy: 0.8605 - val_loss: 1.0974 - val_accuracy: 0.8140\n","Epoch 12/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8548 - accuracy: 0.8597 - val_loss: 1.0736 - val_accuracy: 0.8161\n","Epoch 13/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8537 - accuracy: 0.8514 - val_loss: 1.0478 - val_accuracy: 0.8171\n","Epoch 14/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.8395 - accuracy: 0.8610 - val_loss: 1.0197 - val_accuracy: 0.8213\n","Epoch 15/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8395 - accuracy: 0.8599 - val_loss: 0.9891 - val_accuracy: 0.8182\n","Epoch 16/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8301 - accuracy: 0.8633 - val_loss: 0.9663 - val_accuracy: 0.8192\n","Epoch 17/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.8245 - accuracy: 0.8625 - val_loss: 0.9341 - val_accuracy: 0.8316\n","Epoch 18/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8235 - accuracy: 0.8605 - val_loss: 0.9127 - val_accuracy: 0.8295\n","Epoch 19/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8202 - accuracy: 0.8615 - val_loss: 0.8918 - val_accuracy: 0.8337\n","Epoch 20/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8135 - accuracy: 0.8628 - val_loss: 0.8907 - val_accuracy: 0.8254\n","Epoch 21/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8067 - accuracy: 0.8680 - val_loss: 0.8676 - val_accuracy: 0.8337\n","Epoch 22/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8050 - accuracy: 0.8628 - val_loss: 0.8605 - val_accuracy: 0.8337\n","Epoch 23/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.7998 - accuracy: 0.8646 - val_loss: 0.8567 - val_accuracy: 0.8368\n","Epoch 24/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7902 - accuracy: 0.8739 - val_loss: 0.8795 - val_accuracy: 0.8295\n","Epoch 25/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7891 - accuracy: 0.8705 - val_loss: 0.8653 - val_accuracy: 0.8316\n","Epoch 26/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7879 - accuracy: 0.8711 - val_loss: 0.8517 - val_accuracy: 0.8357\n","Epoch 27/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7866 - accuracy: 0.8687 - val_loss: 0.8494 - val_accuracy: 0.8357\n","Epoch 28/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7757 - accuracy: 0.8757 - val_loss: 0.8566 - val_accuracy: 0.8326\n","Epoch 29/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7729 - accuracy: 0.8669 - val_loss: 0.8532 - val_accuracy: 0.8347\n","Epoch 30/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7664 - accuracy: 0.8747 - val_loss: 0.8452 - val_accuracy: 0.8368\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7641 - accuracy: 0.8734 - val_loss: 0.8511 - val_accuracy: 0.8285\n","Epoch 32/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7660 - accuracy: 0.8724 - val_loss: 0.8409 - val_accuracy: 0.8347\n","Epoch 33/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7533 - accuracy: 0.8770 - val_loss: 0.8398 - val_accuracy: 0.8357\n","Epoch 34/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7479 - accuracy: 0.8804 - val_loss: 0.8406 - val_accuracy: 0.8316\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7450 - accuracy: 0.8806 - val_loss: 0.8376 - val_accuracy: 0.8295\n","Epoch 36/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7442 - accuracy: 0.8775 - val_loss: 0.8466 - val_accuracy: 0.8275\n","Epoch 37/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7432 - accuracy: 0.8783 - val_loss: 0.8374 - val_accuracy: 0.8316\n","Epoch 38/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7396 - accuracy: 0.8788 - val_loss: 0.8281 - val_accuracy: 0.8326\n","Epoch 39/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.7301 - accuracy: 0.8783 - val_loss: 0.8259 - val_accuracy: 0.8326\n","Epoch 40/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7291 - accuracy: 0.8783 - val_loss: 0.8441 - val_accuracy: 0.8347\n","Epoch 41/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7295 - accuracy: 0.8742 - val_loss: 0.8251 - val_accuracy: 0.8347\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7198 - accuracy: 0.8855 - val_loss: 0.8217 - val_accuracy: 0.8337\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7171 - accuracy: 0.8837 - val_loss: 0.8228 - val_accuracy: 0.8316\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7131 - accuracy: 0.8840 - val_loss: 0.8251 - val_accuracy: 0.8357\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7142 - accuracy: 0.8791 - val_loss: 0.8185 - val_accuracy: 0.8306\n","Epoch 46/100\n","31/31 [==============================] - 1s 42ms/step - loss: 0.7096 - accuracy: 0.8832 - val_loss: 0.8149 - val_accuracy: 0.8409\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7008 - accuracy: 0.8835 - val_loss: 0.8174 - val_accuracy: 0.8326\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6991 - accuracy: 0.8866 - val_loss: 0.8136 - val_accuracy: 0.8316\n","Epoch 49/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6922 - accuracy: 0.8922 - val_loss: 0.8112 - val_accuracy: 0.8326\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6868 - accuracy: 0.8915 - val_loss: 0.8204 - val_accuracy: 0.8295\n","Epoch 51/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6856 - accuracy: 0.8917 - val_loss: 0.8092 - val_accuracy: 0.8316\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6808 - accuracy: 0.8915 - val_loss: 0.8055 - val_accuracy: 0.8337\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6762 - accuracy: 0.8938 - val_loss: 0.8151 - val_accuracy: 0.8357\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6743 - accuracy: 0.8894 - val_loss: 0.8060 - val_accuracy: 0.8306\n","Epoch 55/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6768 - accuracy: 0.8881 - val_loss: 0.8140 - val_accuracy: 0.8388\n","Epoch 56/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6697 - accuracy: 0.8917 - val_loss: 0.8159 - val_accuracy: 0.8378\n","Epoch 57/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6710 - accuracy: 0.8910 - val_loss: 0.7969 - val_accuracy: 0.8337\n","Epoch 58/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6648 - accuracy: 0.8897 - val_loss: 0.7965 - val_accuracy: 0.8378\n","Epoch 59/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6595 - accuracy: 0.8959 - val_loss: 0.8017 - val_accuracy: 0.8337\n","Epoch 60/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6531 - accuracy: 0.8969 - val_loss: 0.7915 - val_accuracy: 0.8357\n","Epoch 61/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6476 - accuracy: 0.8990 - val_loss: 0.7943 - val_accuracy: 0.8316\n","Epoch 62/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6482 - accuracy: 0.8979 - val_loss: 0.7915 - val_accuracy: 0.8326\n","Epoch 63/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6462 - accuracy: 0.9005 - val_loss: 0.7911 - val_accuracy: 0.8368\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6457 - accuracy: 0.8964 - val_loss: 0.7906 - val_accuracy: 0.8337\n","Epoch 65/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6354 - accuracy: 0.8972 - val_loss: 0.7904 - val_accuracy: 0.8357\n","Epoch 66/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6323 - accuracy: 0.9005 - val_loss: 0.7905 - val_accuracy: 0.8306\n","Epoch 67/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6375 - accuracy: 0.8987 - val_loss: 0.7885 - val_accuracy: 0.8368\n","Epoch 68/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6287 - accuracy: 0.9003 - val_loss: 0.7858 - val_accuracy: 0.8347\n","Epoch 69/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6265 - accuracy: 0.8997 - val_loss: 0.7852 - val_accuracy: 0.8378\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6395 - accuracy: 0.8938 - val_loss: 0.7881 - val_accuracy: 0.8306\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6294 - accuracy: 0.9008 - val_loss: 0.7913 - val_accuracy: 0.8295\n","Epoch 72/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6185 - accuracy: 0.9005 - val_loss: 0.7999 - val_accuracy: 0.8337\n","Epoch 73/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6197 - accuracy: 0.8997 - val_loss: 0.7831 - val_accuracy: 0.8337\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6181 - accuracy: 0.9036 - val_loss: 0.7893 - val_accuracy: 0.8275\n","Epoch 75/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6114 - accuracy: 0.9059 - val_loss: 0.7781 - val_accuracy: 0.8306\n","Epoch 76/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6063 - accuracy: 0.9047 - val_loss: 0.7833 - val_accuracy: 0.8306\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6044 - accuracy: 0.9062 - val_loss: 0.7748 - val_accuracy: 0.8368\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6112 - accuracy: 0.9036 - val_loss: 0.7898 - val_accuracy: 0.8295\n","Epoch 79/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6058 - accuracy: 0.9008 - val_loss: 0.7746 - val_accuracy: 0.8378\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5961 - accuracy: 0.9067 - val_loss: 0.7737 - val_accuracy: 0.8357\n","Epoch 81/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6009 - accuracy: 0.9026 - val_loss: 0.7676 - val_accuracy: 0.8378\n","Epoch 82/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5926 - accuracy: 0.9078 - val_loss: 0.7754 - val_accuracy: 0.8368\n","Epoch 83/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5848 - accuracy: 0.9101 - val_loss: 0.7722 - val_accuracy: 0.8357\n","Epoch 84/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5888 - accuracy: 0.9088 - val_loss: 0.7779 - val_accuracy: 0.8347\n","Epoch 85/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5788 - accuracy: 0.9152 - val_loss: 0.7999 - val_accuracy: 0.8316\n","Epoch 86/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5919 - accuracy: 0.9049 - val_loss: 0.7721 - val_accuracy: 0.8357\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5909 - accuracy: 0.9005 - val_loss: 0.7723 - val_accuracy: 0.8347\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5800 - accuracy: 0.9121 - val_loss: 0.7839 - val_accuracy: 0.8295\n","Epoch 89/100\n","31/31 [==============================] - 1s 43ms/step - loss: 0.5740 - accuracy: 0.9142 - val_loss: 0.7649 - val_accuracy: 0.8419\n","Epoch 90/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5660 - accuracy: 0.9155 - val_loss: 0.7805 - val_accuracy: 0.8326\n","Epoch 91/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5688 - accuracy: 0.9142 - val_loss: 0.7675 - val_accuracy: 0.8409\n","Epoch 92/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5665 - accuracy: 0.9114 - val_loss: 0.7662 - val_accuracy: 0.8388\n","Epoch 93/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5612 - accuracy: 0.9158 - val_loss: 0.7712 - val_accuracy: 0.8357\n","Epoch 94/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5599 - accuracy: 0.9165 - val_loss: 0.7719 - val_accuracy: 0.8378\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5577 - accuracy: 0.9173 - val_loss: 0.7725 - val_accuracy: 0.8388\n","Epoch 96/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5514 - accuracy: 0.9171 - val_loss: 0.7795 - val_accuracy: 0.8368\n","Epoch 97/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5524 - accuracy: 0.9168 - val_loss: 0.7892 - val_accuracy: 0.8285\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5530 - accuracy: 0.9158 - val_loss: 0.7743 - val_accuracy: 0.8326\n","Epoch 99/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5410 - accuracy: 0.9207 - val_loss: 0.7725 - val_accuracy: 0.8357\n","Epoch 100/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5414 - accuracy: 0.9222 - val_loss: 0.7663 - val_accuracy: 0.8368\n","{'loss': [0.936083197593689, 0.919965922832489, 0.9116520881652832, 0.9055420160293579, 0.8925645351409912, 0.886091411113739, 0.8827349543571472, 0.8748366236686707, 0.8675353527069092, 0.8740139007568359, 0.8562595844268799, 0.8547526001930237, 0.8537319302558899, 0.8394577503204346, 0.8395010232925415, 0.8301259875297546, 0.8244686126708984, 0.8235471844673157, 0.8201709985733032, 0.8135164976119995, 0.8067010641098022, 0.8050154447555542, 0.7998350858688354, 0.7901788353919983, 0.7890914082527161, 0.7879214286804199, 0.7865926027297974, 0.775718629360199, 0.7729150652885437, 0.7663509249687195, 0.7640820741653442, 0.7660331726074219, 0.7533406019210815, 0.7479392886161804, 0.7449584007263184, 0.7442415952682495, 0.7431803941726685, 0.7396215200424194, 0.7301496863365173, 0.7291345596313477, 0.729511022567749, 0.7197777628898621, 0.7171282172203064, 0.7130990624427795, 0.7141684889793396, 0.709606409072876, 0.7008302211761475, 0.6991416811943054, 0.6921570897102356, 0.6867839694023132, 0.6856142282485962, 0.6808461546897888, 0.6762364506721497, 0.6743364334106445, 0.6767845153808594, 0.6697157025337219, 0.6709538698196411, 0.6648097038269043, 0.6595446467399597, 0.6530516743659973, 0.6475945711135864, 0.648164689540863, 0.646227240562439, 0.6456966400146484, 0.6353855133056641, 0.6323350667953491, 0.6375407576560974, 0.6287276148796082, 0.6264936923980713, 0.6394765377044678, 0.6294158101081848, 0.6185182332992554, 0.6197120547294617, 0.6181156039237976, 0.611440122127533, 0.6062950491905212, 0.6043933033943176, 0.6111745834350586, 0.6057907342910767, 0.5960804224014282, 0.6008886098861694, 0.5926052331924438, 0.5847723484039307, 0.5888367891311646, 0.5787643194198608, 0.5919180512428284, 0.5908868312835693, 0.580005943775177, 0.5739981532096863, 0.5660208463668823, 0.5687811374664307, 0.5665414929389954, 0.5612289905548096, 0.5598616600036621, 0.5577149987220764, 0.5513666272163391, 0.5523822903633118, 0.5530453324317932, 0.5409510731697083, 0.5414209365844727], 'accuracy': [0.8408268690109253, 0.8441860675811768, 0.8441860675811768, 0.8439276218414307, 0.8485788106918335, 0.8485788106918335, 0.851938009262085, 0.8503875732421875, 0.8540051579475403, 0.8485788106918335, 0.8604651093482971, 0.8596899509429932, 0.8514211773872375, 0.8609819412231445, 0.8599483370780945, 0.8633074760437012, 0.8625323176383972, 0.8604651093482971, 0.8614987134933472, 0.8627907037734985, 0.867958664894104, 0.8627907037734985, 0.8645994663238525, 0.8739017844200134, 0.8705426454544067, 0.8710594177246094, 0.868733823299408, 0.8757106065750122, 0.866925060749054, 0.8746770024299622, 0.8733850121498108, 0.8723514080047607, 0.8770025968551636, 0.8803617358207703, 0.8806201815605164, 0.8775193691253662, 0.8782945871353149, 0.8788113594055176, 0.8782945871353149, 0.8782945871353149, 0.8741602301597595, 0.8855296969413757, 0.8837209343910217, 0.883979320526123, 0.8790697455406189, 0.8832041621208191, 0.8834625482559204, 0.8865633010864258, 0.8922480344772339, 0.8914728760719299, 0.8917312622070312, 0.8914728760719299, 0.8937984704971313, 0.8894056677818298, 0.8881136775016785, 0.8917312622070312, 0.8909560441970825, 0.8896640539169312, 0.8958656191825867, 0.8968992233276367, 0.8989664316177368, 0.8979328274726868, 0.9005168080329895, 0.8963824510574341, 0.897157609462738, 0.9005168080329895, 0.8987079858779907, 0.9002584218978882, 0.8997415900230408, 0.8937984704971313, 0.9007751941680908, 0.9005168080329895, 0.8997415900230408, 0.9036175608634949, 0.9059431552886963, 0.9046511650085449, 0.9062015414237976, 0.9036175608634949, 0.9007751941680908, 0.906718373298645, 0.9025839567184448, 0.9077519178390503, 0.9100775122642517, 0.9087855219841003, 0.9152454733848572, 0.9049095511436462, 0.9005168080329895, 0.9121447205543518, 0.9142118692398071, 0.9155038595199585, 0.9142118692398071, 0.9113695025444031, 0.9157622456550598, 0.9165374636650085, 0.9173126816749573, 0.9170542359352112, 0.9167958498001099, 0.9157622456550598, 0.920671820640564, 0.9222221970558167], 'val_loss': [1.2284209728240967, 1.2202482223510742, 1.2116895914077759, 1.2024558782577515, 1.1931681632995605, 1.1805533170700073, 1.1684397459030151, 1.1542247533798218, 1.1371574401855469, 1.12064790725708, 1.0974078178405762, 1.0736230611801147, 1.0477710962295532, 1.019677996635437, 0.9890753030776978, 0.9662735462188721, 0.9340605735778809, 0.9127386808395386, 0.8917647004127502, 0.8907244801521301, 0.8675712943077087, 0.8605158925056458, 0.8566834926605225, 0.879470944404602, 0.8653143048286438, 0.851737916469574, 0.8493670225143433, 0.856600284576416, 0.8531623482704163, 0.8451528549194336, 0.8511421084403992, 0.8409050107002258, 0.8397711515426636, 0.8405971527099609, 0.8375799655914307, 0.8466199636459351, 0.8374130129814148, 0.828111469745636, 0.825869083404541, 0.8441122174263, 0.8250976800918579, 0.821734607219696, 0.8228331804275513, 0.8251202702522278, 0.8184847235679626, 0.8148609399795532, 0.8173897862434387, 0.8135924935340881, 0.8111720085144043, 0.8203588724136353, 0.8092076182365417, 0.8054720163345337, 0.8150932788848877, 0.8060243725776672, 0.8139880299568176, 0.8159067630767822, 0.7969045042991638, 0.7965108156204224, 0.801735520362854, 0.7914605140686035, 0.7942655682563782, 0.7914881706237793, 0.791100025177002, 0.7905997037887573, 0.7904188632965088, 0.7905034422874451, 0.7885278463363647, 0.7858002781867981, 0.785241961479187, 0.7881491780281067, 0.7913164496421814, 0.799901008605957, 0.783054530620575, 0.7893481254577637, 0.7780542969703674, 0.7832912802696228, 0.7747673392295837, 0.7898235321044922, 0.7745832204818726, 0.773650050163269, 0.7676372528076172, 0.7753669023513794, 0.7722482085227966, 0.777855634689331, 0.7999221086502075, 0.7720521092414856, 0.7723210453987122, 0.7838581800460815, 0.7648983001708984, 0.7805178761482239, 0.7675157785415649, 0.7661773562431335, 0.7711824178695679, 0.7719240188598633, 0.7724707722663879, 0.7794638872146606, 0.7891711592674255, 0.774306058883667, 0.7724623084068298, 0.7663441896438599], 'val_accuracy': [0.7159090638160706, 0.7231404781341553, 0.7561983466148376, 0.7737603187561035, 0.7747933864593506, 0.8037189841270447, 0.7923553586006165, 0.7923553586006165, 0.8068181872367859, 0.8068181872367859, 0.8140496015548706, 0.81611567735672, 0.817148745059967, 0.8212810158729553, 0.8181818127632141, 0.8192148804664612, 0.8316115736961365, 0.8295454382896423, 0.8336777091026306, 0.8254132270812988, 0.8336777091026306, 0.8336777091026306, 0.836776852607727, 0.8295454382896423, 0.8316115736961365, 0.83574378490448, 0.83574378490448, 0.8326446413993835, 0.8347107172012329, 0.836776852607727, 0.8285123705863953, 0.8347107172012329, 0.83574378490448, 0.8316115736961365, 0.8295454382896423, 0.827479362487793, 0.8316115736961365, 0.8326446413993835, 0.8326446413993835, 0.8347107172012329, 0.8347107172012329, 0.8336777091026306, 0.8316115736961365, 0.83574378490448, 0.8305785059928894, 0.8409090638160706, 0.8326446413993835, 0.8316115736961365, 0.8326446413993835, 0.8295454382896423, 0.8316115736961365, 0.8336777091026306, 0.83574378490448, 0.8305785059928894, 0.8388429880142212, 0.8378099203109741, 0.8336777091026306, 0.8378099203109741, 0.8336777091026306, 0.83574378490448, 0.8316115736961365, 0.8326446413993835, 0.836776852607727, 0.8336777091026306, 0.83574378490448, 0.8305785059928894, 0.836776852607727, 0.8347107172012329, 0.8378099203109741, 0.8305785059928894, 0.8295454382896423, 0.8336777091026306, 0.8336777091026306, 0.827479362487793, 0.8305785059928894, 0.8305785059928894, 0.836776852607727, 0.8295454382896423, 0.8378099203109741, 0.83574378490448, 0.8378099203109741, 0.836776852607727, 0.83574378490448, 0.8347107172012329, 0.8316115736961365, 0.83574378490448, 0.8347107172012329, 0.8295454382896423, 0.8419421315193176, 0.8326446413993835, 0.8409090638160706, 0.8388429880142212, 0.83574378490448, 0.8378099203109741, 0.8388429880142212, 0.836776852607727, 0.8285123705863953, 0.8326446413993835, 0.83574378490448, 0.836776852607727]}\n","32/32 [==============================] - 1s 6ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.6042 - accuracy: 0.8931"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 72ms/step - loss: 0.6052 - accuracy: 0.8925 - val_loss: 1.0128 - val_accuracy: 0.8351\n","Epoch 2/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5901 - accuracy: 0.9001 - val_loss: 1.0083 - val_accuracy: 0.8147\n","Epoch 3/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5977 - accuracy: 0.8941 - val_loss: 1.0030 - val_accuracy: 0.8050\n","Epoch 4/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5861 - accuracy: 0.9054 - val_loss: 0.9964 - val_accuracy: 0.8362\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5840 - accuracy: 0.9022 - val_loss: 0.9886 - val_accuracy: 0.8319\n","Epoch 6/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5717 - accuracy: 0.9084 - val_loss: 0.9825 - val_accuracy: 0.8341\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5713 - accuracy: 0.9071 - val_loss: 0.9702 - val_accuracy: 0.8319\n","Epoch 8/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5664 - accuracy: 0.9060 - val_loss: 0.9616 - val_accuracy: 0.8308\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5703 - accuracy: 0.9052 - val_loss: 0.9448 - val_accuracy: 0.8297\n","Epoch 10/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5627 - accuracy: 0.9100 - val_loss: 0.9323 - val_accuracy: 0.8254\n","Epoch 11/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.5681 - accuracy: 0.9052 - val_loss: 0.9098 - val_accuracy: 0.8373\n","Epoch 12/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5633 - accuracy: 0.9071 - val_loss: 0.8901 - val_accuracy: 0.8416\n","Epoch 13/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5591 - accuracy: 0.9133 - val_loss: 0.8652 - val_accuracy: 0.8438\n","Epoch 14/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.5634 - accuracy: 0.9103 - val_loss: 0.8391 - val_accuracy: 0.8481\n","Epoch 15/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5496 - accuracy: 0.9130 - val_loss: 0.8110 - val_accuracy: 0.8448\n","Epoch 16/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.5443 - accuracy: 0.9176 - val_loss: 0.7738 - val_accuracy: 0.8502\n","Epoch 17/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5429 - accuracy: 0.9138 - val_loss: 0.7429 - val_accuracy: 0.8502\n","Epoch 18/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5454 - accuracy: 0.9176 - val_loss: 0.7233 - val_accuracy: 0.8362\n","Epoch 19/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5297 - accuracy: 0.9192 - val_loss: 0.6862 - val_accuracy: 0.8502\n","Epoch 20/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.5458 - accuracy: 0.9119 - val_loss: 0.6734 - val_accuracy: 0.8513\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5438 - accuracy: 0.9159 - val_loss: 0.6755 - val_accuracy: 0.8416\n","Epoch 22/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.5339 - accuracy: 0.9192 - val_loss: 0.6503 - val_accuracy: 0.8556\n","Epoch 23/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.5329 - accuracy: 0.9162 - val_loss: 0.6296 - val_accuracy: 0.8599\n","Epoch 24/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5263 - accuracy: 0.9200 - val_loss: 0.6281 - val_accuracy: 0.8631\n","Epoch 25/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.5246 - accuracy: 0.9178 - val_loss: 0.6360 - val_accuracy: 0.8664\n","Epoch 26/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5147 - accuracy: 0.9273 - val_loss: 0.6433 - val_accuracy: 0.8642\n","Epoch 27/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5154 - accuracy: 0.9305 - val_loss: 0.6292 - val_accuracy: 0.8631\n","Epoch 28/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5137 - accuracy: 0.9262 - val_loss: 0.6290 - val_accuracy: 0.8664\n","Epoch 29/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5105 - accuracy: 0.9235 - val_loss: 0.6376 - val_accuracy: 0.8545\n","Epoch 30/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5040 - accuracy: 0.9302 - val_loss: 0.6324 - val_accuracy: 0.8610\n","Epoch 31/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5055 - accuracy: 0.9262 - val_loss: 0.6414 - val_accuracy: 0.8545\n","Epoch 32/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5087 - accuracy: 0.9262 - val_loss: 0.6361 - val_accuracy: 0.8653\n","Epoch 33/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5056 - accuracy: 0.9240 - val_loss: 0.6401 - val_accuracy: 0.8588\n","Epoch 34/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5096 - accuracy: 0.9235 - val_loss: 0.6381 - val_accuracy: 0.8610\n","Epoch 35/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4954 - accuracy: 0.9289 - val_loss: 0.6369 - val_accuracy: 0.8610\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4912 - accuracy: 0.9329 - val_loss: 0.6381 - val_accuracy: 0.8621\n","Epoch 37/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4899 - accuracy: 0.9318 - val_loss: 0.6408 - val_accuracy: 0.8718\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4879 - accuracy: 0.9332 - val_loss: 0.6428 - val_accuracy: 0.8675\n","Epoch 39/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5063 - accuracy: 0.9221 - val_loss: 0.6411 - val_accuracy: 0.8621\n","Epoch 40/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4886 - accuracy: 0.9302 - val_loss: 0.6405 - val_accuracy: 0.8685\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4855 - accuracy: 0.9337 - val_loss: 0.6398 - val_accuracy: 0.8621\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4765 - accuracy: 0.9378 - val_loss: 0.6366 - val_accuracy: 0.8653\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4815 - accuracy: 0.9327 - val_loss: 0.6409 - val_accuracy: 0.8578\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4804 - accuracy: 0.9367 - val_loss: 0.6486 - val_accuracy: 0.8718\n","Epoch 45/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4728 - accuracy: 0.9378 - val_loss: 0.6404 - val_accuracy: 0.8664\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4715 - accuracy: 0.9359 - val_loss: 0.6527 - val_accuracy: 0.8534\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4621 - accuracy: 0.9391 - val_loss: 0.6436 - val_accuracy: 0.8588\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4724 - accuracy: 0.9353 - val_loss: 0.6412 - val_accuracy: 0.8675\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4636 - accuracy: 0.9426 - val_loss: 0.6602 - val_accuracy: 0.8524\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4698 - accuracy: 0.9335 - val_loss: 0.6404 - val_accuracy: 0.8621\n","Epoch 51/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4667 - accuracy: 0.9397 - val_loss: 0.7120 - val_accuracy: 0.8254\n","Epoch 52/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4554 - accuracy: 0.9453 - val_loss: 0.6512 - val_accuracy: 0.8556\n","Epoch 53/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4545 - accuracy: 0.9440 - val_loss: 0.6638 - val_accuracy: 0.8513\n","Epoch 54/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4531 - accuracy: 0.9485 - val_loss: 0.6642 - val_accuracy: 0.8470\n","Epoch 55/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4537 - accuracy: 0.9445 - val_loss: 0.6417 - val_accuracy: 0.8642\n","Epoch 56/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4499 - accuracy: 0.9429 - val_loss: 0.6509 - val_accuracy: 0.8631\n","Epoch 57/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4605 - accuracy: 0.9375 - val_loss: 0.6776 - val_accuracy: 0.8405\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4448 - accuracy: 0.9469 - val_loss: 0.6543 - val_accuracy: 0.8588\n","Epoch 59/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4454 - accuracy: 0.9448 - val_loss: 0.6687 - val_accuracy: 0.8481\n","Epoch 60/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4471 - accuracy: 0.9423 - val_loss: 0.7046 - val_accuracy: 0.8319\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4438 - accuracy: 0.9472 - val_loss: 0.6854 - val_accuracy: 0.8362\n","Epoch 62/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4350 - accuracy: 0.9475 - val_loss: 0.6511 - val_accuracy: 0.8642\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4386 - accuracy: 0.9483 - val_loss: 0.6457 - val_accuracy: 0.8685\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4399 - accuracy: 0.9423 - val_loss: 0.6496 - val_accuracy: 0.8621\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4291 - accuracy: 0.9537 - val_loss: 0.6458 - val_accuracy: 0.8642\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4384 - accuracy: 0.9461 - val_loss: 0.6798 - val_accuracy: 0.8567\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4402 - accuracy: 0.9440 - val_loss: 0.6614 - val_accuracy: 0.8567\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4285 - accuracy: 0.9534 - val_loss: 0.6438 - val_accuracy: 0.8642\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4233 - accuracy: 0.9529 - val_loss: 0.6542 - val_accuracy: 0.8642\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4235 - accuracy: 0.9507 - val_loss: 0.6524 - val_accuracy: 0.8653\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4323 - accuracy: 0.9464 - val_loss: 0.6529 - val_accuracy: 0.8621\n","Epoch 72/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4139 - accuracy: 0.9588 - val_loss: 0.6541 - val_accuracy: 0.8610\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4181 - accuracy: 0.9542 - val_loss: 0.6638 - val_accuracy: 0.8642\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4296 - accuracy: 0.9448 - val_loss: 0.6472 - val_accuracy: 0.8599\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4151 - accuracy: 0.9539 - val_loss: 0.6491 - val_accuracy: 0.8621\n","Epoch 76/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4171 - accuracy: 0.9534 - val_loss: 0.6923 - val_accuracy: 0.8373\n","Epoch 77/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4231 - accuracy: 0.9507 - val_loss: 0.6538 - val_accuracy: 0.8718\n","Epoch 78/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4177 - accuracy: 0.9534 - val_loss: 0.6714 - val_accuracy: 0.8567\n","Epoch 79/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4113 - accuracy: 0.9569 - val_loss: 0.6546 - val_accuracy: 0.8642\n","Epoch 80/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4069 - accuracy: 0.9591 - val_loss: 0.6508 - val_accuracy: 0.8675\n","Epoch 81/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4065 - accuracy: 0.9572 - val_loss: 0.6987 - val_accuracy: 0.8384\n","Epoch 82/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4025 - accuracy: 0.9572 - val_loss: 0.6525 - val_accuracy: 0.8653\n","Epoch 83/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4055 - accuracy: 0.9558 - val_loss: 0.6533 - val_accuracy: 0.8621\n","Epoch 84/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3957 - accuracy: 0.9623 - val_loss: 0.6613 - val_accuracy: 0.8685\n","Epoch 85/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4057 - accuracy: 0.9550 - val_loss: 0.6640 - val_accuracy: 0.8599\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4134 - accuracy: 0.9523 - val_loss: 0.6625 - val_accuracy: 0.8588\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3925 - accuracy: 0.9620 - val_loss: 0.7021 - val_accuracy: 0.8384\n","Epoch 88/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3918 - accuracy: 0.9623 - val_loss: 0.6720 - val_accuracy: 0.8556\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3928 - accuracy: 0.9604 - val_loss: 0.6869 - val_accuracy: 0.8448\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3843 - accuracy: 0.9642 - val_loss: 0.6622 - val_accuracy: 0.8599\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3862 - accuracy: 0.9617 - val_loss: 0.6660 - val_accuracy: 0.8664\n","Epoch 92/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3842 - accuracy: 0.9639 - val_loss: 0.6645 - val_accuracy: 0.8675\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3934 - accuracy: 0.9601 - val_loss: 0.6960 - val_accuracy: 0.8405\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3986 - accuracy: 0.9553 - val_loss: 0.6638 - val_accuracy: 0.8631\n","Epoch 95/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3892 - accuracy: 0.9609 - val_loss: 0.6674 - val_accuracy: 0.8653\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3894 - accuracy: 0.9599 - val_loss: 0.6622 - val_accuracy: 0.8696\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3925 - accuracy: 0.9569 - val_loss: 0.7075 - val_accuracy: 0.8394\n","Epoch 98/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3734 - accuracy: 0.9696 - val_loss: 0.6948 - val_accuracy: 0.8459\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3724 - accuracy: 0.9674 - val_loss: 0.6671 - val_accuracy: 0.8675\n","Epoch 100/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3762 - accuracy: 0.9682 - val_loss: 0.7248 - val_accuracy: 0.8319\n","{'loss': [0.6052398681640625, 0.5901018381118774, 0.5976763367652893, 0.5861350297927856, 0.5840233564376831, 0.5717138051986694, 0.5713077187538147, 0.5664263367652893, 0.5703463554382324, 0.5627468228340149, 0.5680897831916809, 0.5632731318473816, 0.5590793490409851, 0.5633761882781982, 0.5496031045913696, 0.5443176031112671, 0.5429078936576843, 0.5453515648841858, 0.5297451019287109, 0.5458123683929443, 0.5437803864479065, 0.5338771939277649, 0.5329235792160034, 0.5263235569000244, 0.5246299505233765, 0.5146914720535278, 0.5154281258583069, 0.5137057900428772, 0.5104570984840393, 0.5039618611335754, 0.5054749250411987, 0.5087381601333618, 0.5056012868881226, 0.5095886588096619, 0.4953950047492981, 0.49118614196777344, 0.489872008562088, 0.4878566265106201, 0.5063225030899048, 0.48855090141296387, 0.48552262783050537, 0.4764952063560486, 0.48146820068359375, 0.4803556799888611, 0.47280991077423096, 0.47152358293533325, 0.4621146321296692, 0.4724196195602417, 0.46357905864715576, 0.469779908657074, 0.46673452854156494, 0.4554300904273987, 0.45447859168052673, 0.4530801475048065, 0.45373988151550293, 0.44994476437568665, 0.4604910910129547, 0.444774866104126, 0.4454379677772522, 0.4470757246017456, 0.4438340365886688, 0.4349779784679413, 0.43860045075416565, 0.4398973286151886, 0.42905163764953613, 0.4383590519428253, 0.4401979148387909, 0.42849037051200867, 0.42333486676216125, 0.42345839738845825, 0.43225279450416565, 0.41389110684394836, 0.4180622100830078, 0.4295612871646881, 0.4151223599910736, 0.41712164878845215, 0.4231441617012024, 0.41769644618034363, 0.4113420844078064, 0.4068743884563446, 0.4065447747707367, 0.40253326296806335, 0.4054902195930481, 0.39574939012527466, 0.40569666028022766, 0.41335394978523254, 0.39245858788490295, 0.3917883038520813, 0.3927965462207794, 0.3843178153038025, 0.38624870777130127, 0.38423120975494385, 0.3934449851512909, 0.39860665798187256, 0.38923513889312744, 0.3893708288669586, 0.392543226480484, 0.3733697831630707, 0.3723875880241394, 0.376186728477478], 'accuracy': [0.8925107717514038, 0.900053858757019, 0.8941271305084229, 0.9054418206214905, 0.9022090435028076, 0.9084051847457886, 0.9070581793785095, 0.9059805870056152, 0.9051724076271057, 0.9100215435028076, 0.9051724076271057, 0.9070581793785095, 0.9132543206214905, 0.9102909564971924, 0.9129849076271057, 0.9175646305084229, 0.9137930870056152, 0.9175646305084229, 0.9191810488700867, 0.9119073152542114, 0.9159482717514038, 0.9191810488700867, 0.9162176847457886, 0.9199892282485962, 0.9178340435028076, 0.9272629022598267, 0.9304956793785095, 0.9261853694915771, 0.923491358757019, 0.9302262663841248, 0.9261853694915771, 0.9261853694915771, 0.9240301847457886, 0.923491358757019, 0.9288793206214905, 0.9329202771186829, 0.9318426847457886, 0.9331896305084229, 0.9221444129943848, 0.9302262663841248, 0.9337284564971924, 0.9377694129943848, 0.9326508641242981, 0.9366918206214905, 0.9377694129943848, 0.935883641242981, 0.939116358757019, 0.9353448152542114, 0.9426185488700867, 0.9334590435028076, 0.9396551847457886, 0.9453125, 0.943965494632721, 0.9485452771186829, 0.9445043206214905, 0.9428879022598267, 0.9375, 0.946928858757019, 0.9447737336158752, 0.9423491358757019, 0.9471982717514038, 0.9474676847457886, 0.9482758641242981, 0.9423491358757019, 0.9536637663841248, 0.9461206793785095, 0.943965494632721, 0.9533944129943848, 0.9528555870056152, 0.9507004022598267, 0.9463900923728943, 0.9587823152542114, 0.9542025923728943, 0.9447737336158752, 0.9539331793785095, 0.9533944129943848, 0.9507004022598267, 0.9533944129943848, 0.9568965435028076, 0.9590517282485962, 0.9571659564971924, 0.9571659564971924, 0.9558189511299133, 0.962284505367279, 0.9550107717514038, 0.9523168206214905, 0.9620150923728943, 0.962284505367279, 0.9603987336158752, 0.9641702771186829, 0.9617456793785095, 0.9639008641242981, 0.9601293206214905, 0.9552801847457886, 0.9609375, 0.9598599076271057, 0.9568965435028076, 0.9695581793785095, 0.967402994632721, 0.9682112336158752], 'val_loss': [1.0127625465393066, 1.0082848072052002, 1.002966046333313, 0.9963873624801636, 0.9886258840560913, 0.9824938178062439, 0.9701716899871826, 0.9615740776062012, 0.944792628288269, 0.9323017001152039, 0.9098032116889954, 0.890059769153595, 0.8652300834655762, 0.8390917181968689, 0.8109550476074219, 0.7737705707550049, 0.7429291009902954, 0.7233023047447205, 0.6862322688102722, 0.6733754277229309, 0.6755077838897705, 0.6503416895866394, 0.6295625567436218, 0.6281483769416809, 0.6359780430793762, 0.6433478593826294, 0.6292093396186829, 0.6289862990379333, 0.6376481652259827, 0.6324411630630493, 0.6413695216178894, 0.6361318230628967, 0.6401287317276001, 0.6380951404571533, 0.6369307041168213, 0.6381351947784424, 0.6407598257064819, 0.6428131461143494, 0.6410567164421082, 0.6405421495437622, 0.6397938132286072, 0.6365876793861389, 0.6408634185791016, 0.6486460566520691, 0.6403515338897705, 0.652675986289978, 0.6435734033584595, 0.6411588191986084, 0.6601957678794861, 0.6404045820236206, 0.711978018283844, 0.6512046456336975, 0.6637858748435974, 0.664153516292572, 0.6416563987731934, 0.6508848667144775, 0.6775844097137451, 0.6542618274688721, 0.6686930060386658, 0.7045787572860718, 0.6854370832443237, 0.6511269211769104, 0.6457296013832092, 0.6496068835258484, 0.6458104252815247, 0.6797735095024109, 0.6613820195198059, 0.6438487768173218, 0.6542354226112366, 0.6524369716644287, 0.6528753638267517, 0.6541010141372681, 0.6638450622558594, 0.6471675634384155, 0.649131178855896, 0.6922968626022339, 0.6538354158401489, 0.6713533997535706, 0.6546279191970825, 0.6508414149284363, 0.6987285017967224, 0.6525226831436157, 0.6533487439155579, 0.6612730622291565, 0.6640253663063049, 0.6624855399131775, 0.7021130323410034, 0.6720424294471741, 0.6869331002235413, 0.6621982455253601, 0.6660141348838806, 0.664479672908783, 0.6959676146507263, 0.66377192735672, 0.6674389839172363, 0.6622125506401062, 0.7074527144432068, 0.6948002576828003, 0.6670904755592346, 0.724786102771759], 'val_accuracy': [0.8351293206214905, 0.8146551847457886, 0.8049569129943848, 0.8362069129943848, 0.8318965435028076, 0.8340517282485962, 0.8318965435028076, 0.8308189511299133, 0.829741358757019, 0.8254310488700867, 0.837284505367279, 0.8415948152542114, 0.84375, 0.8480603694915771, 0.8448275923728943, 0.850215494632721, 0.850215494632721, 0.8362069129943848, 0.850215494632721, 0.8512930870056152, 0.8415948152542114, 0.8556034564971924, 0.8599137663841248, 0.8631465435028076, 0.8663793206214905, 0.8642241358757019, 0.8631465435028076, 0.8663793206214905, 0.8545258641242981, 0.860991358757019, 0.8545258641242981, 0.8653017282485962, 0.8588362336158752, 0.860991358757019, 0.860991358757019, 0.8620689511299133, 0.8717672228813171, 0.8674569129943848, 0.8620689511299133, 0.868534505367279, 0.8620689511299133, 0.8653017282485962, 0.857758641242981, 0.8717672228813171, 0.8663793206214905, 0.8534482717514038, 0.8588362336158752, 0.8674569129943848, 0.8523706793785095, 0.8620689511299133, 0.8254310488700867, 0.8556034564971924, 0.8512930870056152, 0.8469827771186829, 0.8642241358757019, 0.8631465435028076, 0.8405172228813171, 0.8588362336158752, 0.8480603694915771, 0.8318965435028076, 0.8362069129943848, 0.8642241358757019, 0.868534505367279, 0.8620689511299133, 0.8642241358757019, 0.8566810488700867, 0.8566810488700867, 0.8642241358757019, 0.8642241358757019, 0.8653017282485962, 0.8620689511299133, 0.860991358757019, 0.8642241358757019, 0.8599137663841248, 0.8620689511299133, 0.837284505367279, 0.8717672228813171, 0.8566810488700867, 0.8642241358757019, 0.8674569129943848, 0.8383620977401733, 0.8653017282485962, 0.8620689511299133, 0.868534505367279, 0.8599137663841248, 0.8588362336158752, 0.8383620977401733, 0.8556034564971924, 0.8448275923728943, 0.8599137663841248, 0.8663793206214905, 0.8674569129943848, 0.8405172228813171, 0.8631465435028076, 0.8653017282485962, 0.8696120977401733, 0.8394396305084229, 0.8459051847457886, 0.8674569129943848, 0.8318965435028076]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.6227 - accuracy: 0.8864"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 63ms/step - loss: 0.6272 - accuracy: 0.8837 - val_loss: 1.0155 - val_accuracy: 0.7805\n","Epoch 2/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6231 - accuracy: 0.8795 - val_loss: 1.0110 - val_accuracy: 0.8292\n","Epoch 3/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6104 - accuracy: 0.8928 - val_loss: 1.0063 - val_accuracy: 0.8077\n","Epoch 4/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6101 - accuracy: 0.8882 - val_loss: 1.0013 - val_accuracy: 0.8043\n","Epoch 5/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6154 - accuracy: 0.8888 - val_loss: 0.9948 - val_accuracy: 0.8224\n","Epoch 6/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6048 - accuracy: 0.8939 - val_loss: 0.9891 - val_accuracy: 0.7941\n","Epoch 7/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6076 - accuracy: 0.8891 - val_loss: 0.9792 - val_accuracy: 0.8326\n","Epoch 8/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5864 - accuracy: 0.9007 - val_loss: 0.9695 - val_accuracy: 0.8371\n","Epoch 9/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5906 - accuracy: 0.8913 - val_loss: 0.9593 - val_accuracy: 0.8235\n","Epoch 10/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5890 - accuracy: 0.8925 - val_loss: 0.9445 - val_accuracy: 0.8314\n","Epoch 11/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5867 - accuracy: 0.8956 - val_loss: 0.9315 - val_accuracy: 0.8247\n","Epoch 12/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5871 - accuracy: 0.8959 - val_loss: 0.9128 - val_accuracy: 0.8224\n","Epoch 13/100\n","28/28 [==============================] - 2s 66ms/step - loss: 0.5768 - accuracy: 0.9001 - val_loss: 0.8937 - val_accuracy: 0.8054\n","Epoch 14/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5954 - accuracy: 0.8916 - val_loss: 0.8686 - val_accuracy: 0.8247\n","Epoch 15/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5759 - accuracy: 0.9015 - val_loss: 0.8441 - val_accuracy: 0.8235\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5698 - accuracy: 0.9063 - val_loss: 0.8165 - val_accuracy: 0.8360\n","Epoch 17/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5684 - accuracy: 0.9010 - val_loss: 0.7889 - val_accuracy: 0.8337\n","Epoch 18/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5676 - accuracy: 0.8981 - val_loss: 0.7634 - val_accuracy: 0.8337\n","Epoch 19/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5634 - accuracy: 0.9063 - val_loss: 0.7349 - val_accuracy: 0.8371\n","Epoch 20/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5679 - accuracy: 0.9001 - val_loss: 0.7190 - val_accuracy: 0.8371\n","Epoch 21/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5736 - accuracy: 0.8998 - val_loss: 0.7006 - val_accuracy: 0.8348\n","Epoch 22/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5613 - accuracy: 0.9032 - val_loss: 0.7303 - val_accuracy: 0.8190\n","Epoch 23/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5541 - accuracy: 0.9134 - val_loss: 0.6831 - val_accuracy: 0.8360\n","Epoch 24/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5550 - accuracy: 0.9055 - val_loss: 0.7197 - val_accuracy: 0.8190\n","Epoch 25/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5503 - accuracy: 0.9134 - val_loss: 0.6808 - val_accuracy: 0.8360\n","Epoch 26/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5421 - accuracy: 0.9111 - val_loss: 0.6875 - val_accuracy: 0.8337\n","Epoch 27/100\n","28/28 [==============================] - 1s 45ms/step - loss: 0.5396 - accuracy: 0.9148 - val_loss: 0.6886 - val_accuracy: 0.8394\n","Epoch 28/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5461 - accuracy: 0.9055 - val_loss: 0.6886 - val_accuracy: 0.8382\n","Epoch 29/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5386 - accuracy: 0.9157 - val_loss: 0.6939 - val_accuracy: 0.8360\n","Epoch 30/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5397 - accuracy: 0.9095 - val_loss: 0.7004 - val_accuracy: 0.8281\n","Epoch 31/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5312 - accuracy: 0.9182 - val_loss: 0.7273 - val_accuracy: 0.8258\n","Epoch 32/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5294 - accuracy: 0.9137 - val_loss: 0.7059 - val_accuracy: 0.8314\n","Epoch 33/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5206 - accuracy: 0.9191 - val_loss: 0.7097 - val_accuracy: 0.8326\n","Epoch 34/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5230 - accuracy: 0.9123 - val_loss: 0.7088 - val_accuracy: 0.8326\n","Epoch 35/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5253 - accuracy: 0.9154 - val_loss: 0.7174 - val_accuracy: 0.8303\n","Epoch 36/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5227 - accuracy: 0.9222 - val_loss: 0.7105 - val_accuracy: 0.8360\n","Epoch 37/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5188 - accuracy: 0.9188 - val_loss: 0.7144 - val_accuracy: 0.8382\n","Epoch 38/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5174 - accuracy: 0.9228 - val_loss: 0.7133 - val_accuracy: 0.8382\n","Epoch 39/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5200 - accuracy: 0.9157 - val_loss: 0.7459 - val_accuracy: 0.8235\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5214 - accuracy: 0.9174 - val_loss: 0.7121 - val_accuracy: 0.8314\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5009 - accuracy: 0.9293 - val_loss: 0.7144 - val_accuracy: 0.8337\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5020 - accuracy: 0.9264 - val_loss: 0.7306 - val_accuracy: 0.8269\n","Epoch 43/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5003 - accuracy: 0.9295 - val_loss: 0.7145 - val_accuracy: 0.8337\n","Epoch 44/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5087 - accuracy: 0.9213 - val_loss: 0.7403 - val_accuracy: 0.8235\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5070 - accuracy: 0.9205 - val_loss: 0.7177 - val_accuracy: 0.8292\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4896 - accuracy: 0.9307 - val_loss: 0.7174 - val_accuracy: 0.8337\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4942 - accuracy: 0.9278 - val_loss: 0.7433 - val_accuracy: 0.8247\n","Epoch 48/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5045 - accuracy: 0.9242 - val_loss: 0.7179 - val_accuracy: 0.8292\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4851 - accuracy: 0.9332 - val_loss: 0.7226 - val_accuracy: 0.8326\n","Epoch 50/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4880 - accuracy: 0.9259 - val_loss: 0.7383 - val_accuracy: 0.8224\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4861 - accuracy: 0.9298 - val_loss: 0.7616 - val_accuracy: 0.8224\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4954 - accuracy: 0.9242 - val_loss: 0.7335 - val_accuracy: 0.8201\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4801 - accuracy: 0.9366 - val_loss: 0.7237 - val_accuracy: 0.8326\n","Epoch 54/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4821 - accuracy: 0.9327 - val_loss: 0.7270 - val_accuracy: 0.8303\n","Epoch 55/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4789 - accuracy: 0.9307 - val_loss: 0.7241 - val_accuracy: 0.8348\n","Epoch 56/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4778 - accuracy: 0.9312 - val_loss: 0.7230 - val_accuracy: 0.8281\n","Epoch 57/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4694 - accuracy: 0.9355 - val_loss: 0.7343 - val_accuracy: 0.8314\n","Epoch 58/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4777 - accuracy: 0.9324 - val_loss: 0.7288 - val_accuracy: 0.8337\n","Epoch 59/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4698 - accuracy: 0.9358 - val_loss: 0.7495 - val_accuracy: 0.8337\n","Epoch 60/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4754 - accuracy: 0.9312 - val_loss: 0.7249 - val_accuracy: 0.8314\n","Epoch 61/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4687 - accuracy: 0.9335 - val_loss: 0.7364 - val_accuracy: 0.8292\n","Epoch 62/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4624 - accuracy: 0.9369 - val_loss: 0.7349 - val_accuracy: 0.8292\n","Epoch 63/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4579 - accuracy: 0.9397 - val_loss: 0.7328 - val_accuracy: 0.8303\n","Epoch 64/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4645 - accuracy: 0.9332 - val_loss: 0.7373 - val_accuracy: 0.8314\n","Epoch 65/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4512 - accuracy: 0.9437 - val_loss: 0.7279 - val_accuracy: 0.8258\n","Epoch 66/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4620 - accuracy: 0.9360 - val_loss: 0.7535 - val_accuracy: 0.8201\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4505 - accuracy: 0.9431 - val_loss: 0.7402 - val_accuracy: 0.8258\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4509 - accuracy: 0.9400 - val_loss: 0.7422 - val_accuracy: 0.8269\n","Epoch 69/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4594 - accuracy: 0.9346 - val_loss: 0.7412 - val_accuracy: 0.8281\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4532 - accuracy: 0.9403 - val_loss: 0.7391 - val_accuracy: 0.8213\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4474 - accuracy: 0.9386 - val_loss: 0.7675 - val_accuracy: 0.8303\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4486 - accuracy: 0.9397 - val_loss: 0.7456 - val_accuracy: 0.8269\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4531 - accuracy: 0.9352 - val_loss: 0.7429 - val_accuracy: 0.8258\n","Epoch 74/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4560 - accuracy: 0.9372 - val_loss: 0.7329 - val_accuracy: 0.8292\n","Epoch 75/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4546 - accuracy: 0.9383 - val_loss: 0.7262 - val_accuracy: 0.8281\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4345 - accuracy: 0.9457 - val_loss: 0.7383 - val_accuracy: 0.8269\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4380 - accuracy: 0.9392 - val_loss: 0.7340 - val_accuracy: 0.8247\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4548 - accuracy: 0.9344 - val_loss: 0.7394 - val_accuracy: 0.8326\n","Epoch 79/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4263 - accuracy: 0.9488 - val_loss: 0.7352 - val_accuracy: 0.8247\n","Epoch 80/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4224 - accuracy: 0.9553 - val_loss: 0.7407 - val_accuracy: 0.8247\n","Epoch 81/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4287 - accuracy: 0.9460 - val_loss: 0.7607 - val_accuracy: 0.8201\n","Epoch 82/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4302 - accuracy: 0.9434 - val_loss: 0.7501 - val_accuracy: 0.8269\n","Epoch 83/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4182 - accuracy: 0.9544 - val_loss: 0.7494 - val_accuracy: 0.8235\n","Epoch 84/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4248 - accuracy: 0.9460 - val_loss: 0.7528 - val_accuracy: 0.8235\n","Epoch 85/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4276 - accuracy: 0.9485 - val_loss: 0.7478 - val_accuracy: 0.8247\n","Epoch 86/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4154 - accuracy: 0.9542 - val_loss: 0.7494 - val_accuracy: 0.8258\n","Epoch 87/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4188 - accuracy: 0.9479 - val_loss: 0.7712 - val_accuracy: 0.8156\n","Epoch 88/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4179 - accuracy: 0.9491 - val_loss: 0.7682 - val_accuracy: 0.8145\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4093 - accuracy: 0.9547 - val_loss: 0.7637 - val_accuracy: 0.8258\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4086 - accuracy: 0.9530 - val_loss: 0.7541 - val_accuracy: 0.8303\n","Epoch 91/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4083 - accuracy: 0.9519 - val_loss: 0.7614 - val_accuracy: 0.8258\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4017 - accuracy: 0.9578 - val_loss: 0.7611 - val_accuracy: 0.8213\n","Epoch 93/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4041 - accuracy: 0.9556 - val_loss: 0.7655 - val_accuracy: 0.8269\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4017 - accuracy: 0.9530 - val_loss: 0.7684 - val_accuracy: 0.8247\n","Epoch 95/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4013 - accuracy: 0.9559 - val_loss: 0.7650 - val_accuracy: 0.8258\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3976 - accuracy: 0.9573 - val_loss: 0.7799 - val_accuracy: 0.8201\n","Epoch 97/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3936 - accuracy: 0.9610 - val_loss: 0.7734 - val_accuracy: 0.8213\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3959 - accuracy: 0.9556 - val_loss: 0.7771 - val_accuracy: 0.8235\n","Epoch 99/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4021 - accuracy: 0.9527 - val_loss: 0.7693 - val_accuracy: 0.8201\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3913 - accuracy: 0.9578 - val_loss: 0.7834 - val_accuracy: 0.8258\n","{'loss': [0.6272234916687012, 0.6230542063713074, 0.6103747487068176, 0.6101436614990234, 0.6154413223266602, 0.6047636270523071, 0.6076099276542664, 0.5864025950431824, 0.5905790328979492, 0.5890406966209412, 0.5867473483085632, 0.587112545967102, 0.5767837166786194, 0.5953704714775085, 0.5759032964706421, 0.5697920918464661, 0.5684277415275574, 0.5676237940788269, 0.5634427666664124, 0.5678784251213074, 0.5736260414123535, 0.5613167881965637, 0.5540942549705505, 0.5550299286842346, 0.5502620935440063, 0.5420804023742676, 0.5395593047142029, 0.5460513234138489, 0.5386112332344055, 0.5397461652755737, 0.5312497019767761, 0.5294296741485596, 0.5205822587013245, 0.5229885578155518, 0.5252606868743896, 0.522693395614624, 0.5188290476799011, 0.5173805356025696, 0.5200038552284241, 0.5213623046875, 0.5009046196937561, 0.5019713044166565, 0.5002628564834595, 0.5086732506752014, 0.5070021748542786, 0.48963212966918945, 0.494231253862381, 0.5044516921043396, 0.48511016368865967, 0.4879504442214966, 0.4861376881599426, 0.4953671395778656, 0.4800989329814911, 0.48213645815849304, 0.47888147830963135, 0.47775405645370483, 0.469426691532135, 0.4776836931705475, 0.4698190987110138, 0.4754346013069153, 0.46871790289878845, 0.46242183446884155, 0.45794811844825745, 0.46451836824417114, 0.45122095942497253, 0.4619572162628174, 0.4505235254764557, 0.4509495794773102, 0.45941510796546936, 0.45315584540367126, 0.4474298655986786, 0.44860130548477173, 0.4531450569629669, 0.4559907615184784, 0.4546474516391754, 0.4344842731952667, 0.4379867613315582, 0.4548374116420746, 0.42631804943084717, 0.4224070906639099, 0.42867010831832886, 0.430159330368042, 0.41819947957992554, 0.4248127341270447, 0.427606463432312, 0.41542574763298035, 0.41879335045814514, 0.41793394088745117, 0.4092533588409424, 0.4085753262042999, 0.4082517921924591, 0.40166324377059937, 0.4041323661804199, 0.40173640847206116, 0.40129223465919495, 0.39763665199279785, 0.39360547065734863, 0.3958868384361267, 0.4020662307739258, 0.39128199219703674], 'accuracy': [0.8837012052536011, 0.8794566988945007, 0.8927561044692993, 0.8882286548614502, 0.8887945413589478, 0.8938879370689392, 0.8890775442123413, 0.9006791114807129, 0.8913412690162659, 0.8924731016159058, 0.8955857157707214, 0.895868718624115, 0.9001131653785706, 0.8916242122650146, 0.901528000831604, 0.9063384532928467, 0.9009620547294617, 0.8981324434280396, 0.9063384532928467, 0.9001131653785706, 0.8998302221298218, 0.9032257795333862, 0.9134125709533691, 0.9054895043373108, 0.9134125709533691, 0.9111488461494446, 0.9148274064064026, 0.9054895043373108, 0.9156762957572937, 0.9094510674476624, 0.918222963809967, 0.9136955142021179, 0.9190718531608582, 0.9122806787490845, 0.9153932929039001, 0.9221844673156738, 0.9187889099121094, 0.9227504134178162, 0.9156762957572937, 0.9173740744590759, 0.9292586445808411, 0.9264289736747742, 0.9295415878295898, 0.9213355779647827, 0.9204866886138916, 0.9306734800338745, 0.9278438091278076, 0.9241652488708496, 0.9332201480865479, 0.9258630275726318, 0.9298245906829834, 0.9241652488708496, 0.9366157054901123, 0.9326542019844055, 0.9306734800338745, 0.9312393665313721, 0.9354838728904724, 0.9323712587356567, 0.9357668161392212, 0.9312393665313721, 0.9335030913352966, 0.9368987083435059, 0.9397283792495728, 0.9332201480865479, 0.9436898827552795, 0.9360498189926147, 0.9431239366531372, 0.9400113224983215, 0.9346349835395813, 0.9402942657470703, 0.9385964870452881, 0.9397283792495728, 0.9352009296417236, 0.9371816515922546, 0.9383135437965393, 0.9456706047058105, 0.9391624331474304, 0.9343519806861877, 0.9487832188606262, 0.9552914500236511, 0.9459536075592041, 0.943406879901886, 0.95444256067276, 0.9459536075592041, 0.9485002756118774, 0.9541596174240112, 0.9479343295097351, 0.9490662217140198, 0.9547255039215088, 0.9530277252197266, 0.9518958926200867, 0.9578381180763245, 0.9555743932723999, 0.9530277252197266, 0.9558573961257935, 0.9572722315788269, 0.9609507918357849, 0.9555743932723999, 0.9527447819709778, 0.9578381180763245], 'val_loss': [1.0154926776885986, 1.01096773147583, 1.0062525272369385, 1.0012574195861816, 0.9947983622550964, 0.9891247153282166, 0.9791653156280518, 0.9695483446121216, 0.9592874646186829, 0.94449782371521, 0.9314759969711304, 0.9127560257911682, 0.8936755657196045, 0.8686023950576782, 0.8441070914268494, 0.8165340423583984, 0.7888965010643005, 0.7634040713310242, 0.7348951697349548, 0.7189737558364868, 0.7005998492240906, 0.7303037047386169, 0.683092474937439, 0.7197418808937073, 0.6807846426963806, 0.6875343918800354, 0.6886369585990906, 0.6886067390441895, 0.6939270496368408, 0.7004224061965942, 0.7272817492485046, 0.7059174180030823, 0.7097222805023193, 0.7087743282318115, 0.7173981666564941, 0.7105083465576172, 0.7143642902374268, 0.7132828831672668, 0.7458958625793457, 0.7120728492736816, 0.7144124507904053, 0.7305877208709717, 0.7144742012023926, 0.7402515411376953, 0.717719554901123, 0.7174093127250671, 0.7432893514633179, 0.7178616523742676, 0.7226168513298035, 0.7383466362953186, 0.7615869641304016, 0.7335130572319031, 0.7236794829368591, 0.7270227074623108, 0.7240695357322693, 0.7229575514793396, 0.7343060374259949, 0.7288259267807007, 0.7495266795158386, 0.7249462604522705, 0.7364322543144226, 0.734872043132782, 0.7328364849090576, 0.7373439073562622, 0.7279305458068848, 0.7535339593887329, 0.7402422428131104, 0.7421796917915344, 0.741237223148346, 0.7390710711479187, 0.7674505710601807, 0.745642364025116, 0.7428879141807556, 0.7328932881355286, 0.7261654734611511, 0.7383358478546143, 0.7339964509010315, 0.7393987774848938, 0.7352400422096252, 0.7407238483428955, 0.7607311010360718, 0.7500734925270081, 0.7493512630462646, 0.7528294324874878, 0.74776291847229, 0.7494314312934875, 0.771188497543335, 0.7682073712348938, 0.7637385725975037, 0.7541337013244629, 0.7614345550537109, 0.7611039876937866, 0.7654780149459839, 0.7683566808700562, 0.7649896144866943, 0.779940664768219, 0.7734254598617554, 0.7770730257034302, 0.769280195236206, 0.7834208011627197], 'val_accuracy': [0.7805429697036743, 0.8291855454444885, 0.807692289352417, 0.8042986392974854, 0.8223981857299805, 0.7941176295280457, 0.8325791954994202, 0.837104082107544, 0.8235294222831726, 0.831447958946228, 0.8246606588363647, 0.8223981857299805, 0.8054298758506775, 0.8246606588363647, 0.8235294222831726, 0.8359728455543518, 0.8337104320526123, 0.8337104320526123, 0.837104082107544, 0.837104082107544, 0.8348416090011597, 0.8190045356750488, 0.8359728455543518, 0.8190045356750488, 0.8359728455543518, 0.8337104320526123, 0.8393664956092834, 0.8382353186607361, 0.8359728455543518, 0.8280543088912964, 0.8257918357849121, 0.831447958946228, 0.8325791954994202, 0.8325791954994202, 0.8303167223930359, 0.8359728455543518, 0.8382353186607361, 0.8382353186607361, 0.8235294222831726, 0.831447958946228, 0.8337104320526123, 0.8269230723381042, 0.8337104320526123, 0.8235294222831726, 0.8291855454444885, 0.8337104320526123, 0.8246606588363647, 0.8291855454444885, 0.8325791954994202, 0.8223981857299805, 0.8223981857299805, 0.820135772228241, 0.8325791954994202, 0.8303167223930359, 0.8348416090011597, 0.8280543088912964, 0.831447958946228, 0.8337104320526123, 0.8337104320526123, 0.831447958946228, 0.8291855454444885, 0.8291855454444885, 0.8303167223930359, 0.831447958946228, 0.8257918357849121, 0.820135772228241, 0.8257918357849121, 0.8269230723381042, 0.8280543088912964, 0.8212669491767883, 0.8303167223930359, 0.8269230723381042, 0.8257918357849121, 0.8291855454444885, 0.8280543088912964, 0.8269230723381042, 0.8246606588363647, 0.8325791954994202, 0.8246606588363647, 0.8246606588363647, 0.820135772228241, 0.8269230723381042, 0.8235294222831726, 0.8235294222831726, 0.8246606588363647, 0.8257918357849121, 0.8156108856201172, 0.814479649066925, 0.8257918357849121, 0.8303167223930359, 0.8257918357849121, 0.8212669491767883, 0.8269230723381042, 0.8246606588363647, 0.8257918357849121, 0.820135772228241, 0.8212669491767883, 0.8235294222831726, 0.820135772228241, 0.8257918357849121]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.5896 - accuracy: 0.9007"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 56ms/step - loss: 0.5953 - accuracy: 0.8972 - val_loss: 1.0126 - val_accuracy: 0.8233\n","Epoch 2/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5919 - accuracy: 0.9000 - val_loss: 1.0072 - val_accuracy: 0.8337\n","Epoch 3/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5878 - accuracy: 0.9000 - val_loss: 1.0012 - val_accuracy: 0.8254\n","Epoch 4/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5791 - accuracy: 0.9065 - val_loss: 0.9943 - val_accuracy: 0.8368\n","Epoch 5/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5792 - accuracy: 0.9031 - val_loss: 0.9871 - val_accuracy: 0.8171\n","Epoch 6/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5733 - accuracy: 0.9036 - val_loss: 0.9783 - val_accuracy: 0.8347\n","Epoch 7/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5703 - accuracy: 0.9054 - val_loss: 0.9672 - val_accuracy: 0.8388\n","Epoch 8/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5618 - accuracy: 0.9088 - val_loss: 0.9512 - val_accuracy: 0.8450\n","Epoch 9/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5668 - accuracy: 0.9114 - val_loss: 0.9373 - val_accuracy: 0.8430\n","Epoch 10/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.5603 - accuracy: 0.9096 - val_loss: 0.9130 - val_accuracy: 0.8461\n","Epoch 11/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5561 - accuracy: 0.9090 - val_loss: 0.8950 - val_accuracy: 0.8399\n","Epoch 12/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5532 - accuracy: 0.9134 - val_loss: 0.8682 - val_accuracy: 0.8419\n","Epoch 13/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5529 - accuracy: 0.9085 - val_loss: 0.8381 - val_accuracy: 0.8440\n","Epoch 14/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5515 - accuracy: 0.9059 - val_loss: 0.8033 - val_accuracy: 0.8368\n","Epoch 15/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5445 - accuracy: 0.9142 - val_loss: 0.7701 - val_accuracy: 0.8440\n","Epoch 16/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5404 - accuracy: 0.9168 - val_loss: 0.7354 - val_accuracy: 0.8430\n","Epoch 17/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.5427 - accuracy: 0.9132 - val_loss: 0.7047 - val_accuracy: 0.8481\n","Epoch 18/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5403 - accuracy: 0.9121 - val_loss: 0.6847 - val_accuracy: 0.8450\n","Epoch 19/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5295 - accuracy: 0.9189 - val_loss: 0.6668 - val_accuracy: 0.8471\n","Epoch 20/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5236 - accuracy: 0.9204 - val_loss: 0.6611 - val_accuracy: 0.8461\n","Epoch 21/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5243 - accuracy: 0.9220 - val_loss: 0.6613 - val_accuracy: 0.8533\n","Epoch 22/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5210 - accuracy: 0.9217 - val_loss: 0.6561 - val_accuracy: 0.8512\n","Epoch 23/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5226 - accuracy: 0.9212 - val_loss: 0.6499 - val_accuracy: 0.8523\n","Epoch 24/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5245 - accuracy: 0.9142 - val_loss: 0.6856 - val_accuracy: 0.8450\n","Epoch 25/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5257 - accuracy: 0.9140 - val_loss: 0.6773 - val_accuracy: 0.8533\n","Epoch 26/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5125 - accuracy: 0.9245 - val_loss: 0.6616 - val_accuracy: 0.8512\n","Epoch 27/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5125 - accuracy: 0.9199 - val_loss: 0.6857 - val_accuracy: 0.8564\n","Epoch 28/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5153 - accuracy: 0.9214 - val_loss: 0.6750 - val_accuracy: 0.8543\n","Epoch 29/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5073 - accuracy: 0.9282 - val_loss: 0.6711 - val_accuracy: 0.8492\n","Epoch 30/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5028 - accuracy: 0.9276 - val_loss: 0.6754 - val_accuracy: 0.8502\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4997 - accuracy: 0.9276 - val_loss: 0.6748 - val_accuracy: 0.8471\n","Epoch 32/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5012 - accuracy: 0.9261 - val_loss: 0.6791 - val_accuracy: 0.8450\n","Epoch 33/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4958 - accuracy: 0.9271 - val_loss: 0.6890 - val_accuracy: 0.8481\n","Epoch 34/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4948 - accuracy: 0.9269 - val_loss: 0.6795 - val_accuracy: 0.8512\n","Epoch 35/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5062 - accuracy: 0.9194 - val_loss: 0.6783 - val_accuracy: 0.8502\n","Epoch 36/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4863 - accuracy: 0.9318 - val_loss: 0.6894 - val_accuracy: 0.8481\n","Epoch 37/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4999 - accuracy: 0.9266 - val_loss: 0.7033 - val_accuracy: 0.8440\n","Epoch 38/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4987 - accuracy: 0.9217 - val_loss: 0.6829 - val_accuracy: 0.8523\n","Epoch 39/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4816 - accuracy: 0.9310 - val_loss: 0.6996 - val_accuracy: 0.8492\n","Epoch 40/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4804 - accuracy: 0.9331 - val_loss: 0.6938 - val_accuracy: 0.8430\n","Epoch 41/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4809 - accuracy: 0.9287 - val_loss: 0.6819 - val_accuracy: 0.8492\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4807 - accuracy: 0.9318 - val_loss: 0.6850 - val_accuracy: 0.8492\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4712 - accuracy: 0.9331 - val_loss: 0.6860 - val_accuracy: 0.8502\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4805 - accuracy: 0.9282 - val_loss: 0.6837 - val_accuracy: 0.8481\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4726 - accuracy: 0.9344 - val_loss: 0.7162 - val_accuracy: 0.8430\n","Epoch 46/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4865 - accuracy: 0.9191 - val_loss: 0.7145 - val_accuracy: 0.8378\n","Epoch 47/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4792 - accuracy: 0.9282 - val_loss: 0.6830 - val_accuracy: 0.8481\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4649 - accuracy: 0.9341 - val_loss: 0.6985 - val_accuracy: 0.8461\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4634 - accuracy: 0.9393 - val_loss: 0.7061 - val_accuracy: 0.8430\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4584 - accuracy: 0.9382 - val_loss: 0.7019 - val_accuracy: 0.8430\n","Epoch 51/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4588 - accuracy: 0.9382 - val_loss: 0.6880 - val_accuracy: 0.8471\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4623 - accuracy: 0.9364 - val_loss: 0.6858 - val_accuracy: 0.8471\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4486 - accuracy: 0.9424 - val_loss: 0.6935 - val_accuracy: 0.8440\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4606 - accuracy: 0.9364 - val_loss: 0.6932 - val_accuracy: 0.8543\n","Epoch 55/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4574 - accuracy: 0.9370 - val_loss: 0.6918 - val_accuracy: 0.8492\n","Epoch 56/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4435 - accuracy: 0.9434 - val_loss: 0.6973 - val_accuracy: 0.8523\n","Epoch 57/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4542 - accuracy: 0.9367 - val_loss: 0.7065 - val_accuracy: 0.8409\n","Epoch 58/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4483 - accuracy: 0.9406 - val_loss: 0.6958 - val_accuracy: 0.8430\n","Epoch 59/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4370 - accuracy: 0.9486 - val_loss: 0.6990 - val_accuracy: 0.8471\n","Epoch 60/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4358 - accuracy: 0.9473 - val_loss: 0.7076 - val_accuracy: 0.8430\n","Epoch 61/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4348 - accuracy: 0.9455 - val_loss: 0.6966 - val_accuracy: 0.8492\n","Epoch 62/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4338 - accuracy: 0.9483 - val_loss: 0.7190 - val_accuracy: 0.8399\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4351 - accuracy: 0.9460 - val_loss: 0.7002 - val_accuracy: 0.8481\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4363 - accuracy: 0.9439 - val_loss: 0.7137 - val_accuracy: 0.8523\n","Epoch 65/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4362 - accuracy: 0.9403 - val_loss: 0.7030 - val_accuracy: 0.8554\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4361 - accuracy: 0.9455 - val_loss: 0.7008 - val_accuracy: 0.8512\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4278 - accuracy: 0.9460 - val_loss: 0.7063 - val_accuracy: 0.8450\n","Epoch 68/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4309 - accuracy: 0.9483 - val_loss: 0.7093 - val_accuracy: 0.8523\n","Epoch 69/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4196 - accuracy: 0.9499 - val_loss: 0.7104 - val_accuracy: 0.8533\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4349 - accuracy: 0.9450 - val_loss: 0.6983 - val_accuracy: 0.8492\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4289 - accuracy: 0.9460 - val_loss: 0.7101 - val_accuracy: 0.8419\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4237 - accuracy: 0.9481 - val_loss: 0.7422 - val_accuracy: 0.8388\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4206 - accuracy: 0.9496 - val_loss: 0.6979 - val_accuracy: 0.8512\n","Epoch 74/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4176 - accuracy: 0.9509 - val_loss: 0.7037 - val_accuracy: 0.8481\n","Epoch 75/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4121 - accuracy: 0.9530 - val_loss: 0.7190 - val_accuracy: 0.8440\n","Epoch 76/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4109 - accuracy: 0.9553 - val_loss: 0.7348 - val_accuracy: 0.8357\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4181 - accuracy: 0.9488 - val_loss: 0.7120 - val_accuracy: 0.8461\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4109 - accuracy: 0.9568 - val_loss: 0.7257 - val_accuracy: 0.8564\n","Epoch 79/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4159 - accuracy: 0.9514 - val_loss: 0.7142 - val_accuracy: 0.8440\n","Epoch 80/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4075 - accuracy: 0.9491 - val_loss: 0.7356 - val_accuracy: 0.8388\n","Epoch 81/100\n","31/31 [==============================] - 2s 54ms/step - loss: 0.4131 - accuracy: 0.9501 - val_loss: 0.7125 - val_accuracy: 0.8585\n","Epoch 82/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3968 - accuracy: 0.9594 - val_loss: 0.7169 - val_accuracy: 0.8440\n","Epoch 83/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4135 - accuracy: 0.9486 - val_loss: 0.7503 - val_accuracy: 0.8409\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4037 - accuracy: 0.9558 - val_loss: 0.7097 - val_accuracy: 0.8461\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4027 - accuracy: 0.9543 - val_loss: 0.7825 - val_accuracy: 0.8357\n","Epoch 86/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4082 - accuracy: 0.9494 - val_loss: 0.7061 - val_accuracy: 0.8492\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3905 - accuracy: 0.9584 - val_loss: 0.7098 - val_accuracy: 0.8450\n","Epoch 88/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3974 - accuracy: 0.9563 - val_loss: 0.7169 - val_accuracy: 0.8450\n","Epoch 89/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3938 - accuracy: 0.9594 - val_loss: 0.7101 - val_accuracy: 0.8595\n","Epoch 90/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3865 - accuracy: 0.9625 - val_loss: 0.7160 - val_accuracy: 0.8564\n","Epoch 91/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3820 - accuracy: 0.9636 - val_loss: 0.7280 - val_accuracy: 0.8481\n","Epoch 92/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3799 - accuracy: 0.9649 - val_loss: 0.7197 - val_accuracy: 0.8543\n","Epoch 93/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3873 - accuracy: 0.9599 - val_loss: 0.7350 - val_accuracy: 0.8450\n","Epoch 94/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3943 - accuracy: 0.9553 - val_loss: 0.7191 - val_accuracy: 0.8543\n","Epoch 95/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3889 - accuracy: 0.9566 - val_loss: 0.7635 - val_accuracy: 0.8368\n","Epoch 96/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3869 - accuracy: 0.9589 - val_loss: 0.7172 - val_accuracy: 0.8554\n","Epoch 97/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3875 - accuracy: 0.9589 - val_loss: 0.7165 - val_accuracy: 0.8523\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4052 - accuracy: 0.9491 - val_loss: 0.7315 - val_accuracy: 0.8440\n","Epoch 99/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3813 - accuracy: 0.9561 - val_loss: 0.7041 - val_accuracy: 0.8461\n","Epoch 100/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3849 - accuracy: 0.9579 - val_loss: 0.7193 - val_accuracy: 0.8585\n","{'loss': [0.5953260064125061, 0.5918752551078796, 0.5877813100814819, 0.5791277885437012, 0.5792329907417297, 0.5733394026756287, 0.5702860951423645, 0.5617963075637817, 0.5667505860328674, 0.5602803230285645, 0.5560823082923889, 0.5532130599021912, 0.5528934597969055, 0.5514748096466064, 0.5444641709327698, 0.5404171347618103, 0.5426870584487915, 0.5403186082839966, 0.5295332670211792, 0.5235961079597473, 0.5243162512779236, 0.520965576171875, 0.5226022005081177, 0.5244991183280945, 0.5256786942481995, 0.5125158429145813, 0.5125187039375305, 0.5152841210365295, 0.5073004961013794, 0.5028064250946045, 0.49965357780456543, 0.5012471675872803, 0.4958149194717407, 0.49479198455810547, 0.5062312483787537, 0.486346960067749, 0.499896764755249, 0.49867260456085205, 0.4815739095211029, 0.480436235666275, 0.48094117641448975, 0.480694442987442, 0.47118860483169556, 0.4804694354534149, 0.4725739061832428, 0.486492782831192, 0.4792383015155792, 0.4649040102958679, 0.4633736312389374, 0.4584008753299713, 0.4587628245353699, 0.4622979760169983, 0.4485572874546051, 0.46056175231933594, 0.4573569595813751, 0.4435271918773651, 0.4542212188243866, 0.44828125834465027, 0.4370025396347046, 0.4357501268386841, 0.434814989566803, 0.43377840518951416, 0.43510258197784424, 0.4363078474998474, 0.43622127175331116, 0.4361191689968109, 0.42783981561660767, 0.4309066832065582, 0.41963431239128113, 0.4349443316459656, 0.4288637042045593, 0.42374029755592346, 0.42058613896369934, 0.4175843894481659, 0.41207826137542725, 0.4109485447406769, 0.4181329607963562, 0.4108733832836151, 0.4159109592437744, 0.40748676657676697, 0.4130556881427765, 0.3968484103679657, 0.4135380983352661, 0.403706818819046, 0.4027051329612732, 0.40819787979125977, 0.3905238211154938, 0.3974067270755768, 0.39381176233291626, 0.3864845633506775, 0.3820320665836334, 0.37990453839302063, 0.38727161288261414, 0.3942948281764984, 0.38888323307037354, 0.38685140013694763, 0.3875049650669098, 0.4051917791366577, 0.38127243518829346, 0.3849324584007263], 'accuracy': [0.897157609462738, 0.8999999761581421, 0.8999999761581421, 0.9064599275588989, 0.9031007885932922, 0.9036175608634949, 0.9054263830184937, 0.9087855219841003, 0.9113695025444031, 0.9095607399940491, 0.9090439081192017, 0.9134367108345032, 0.908527135848999, 0.9059431552886963, 0.9142118692398071, 0.9167958498001099, 0.9131782650947571, 0.9121447205543518, 0.91886305809021, 0.9204134345054626, 0.9219638109207153, 0.921705424785614, 0.9211886525154114, 0.9142118692398071, 0.9139534831047058, 0.9245477914810181, 0.91989666223526, 0.9214470386505127, 0.9281653761863708, 0.9276486039161682, 0.9276486039161682, 0.9260981678962708, 0.9271317720413208, 0.9268733859062195, 0.9193798303604126, 0.9317829608917236, 0.9266149997711182, 0.921705424785614, 0.9310077428817749, 0.933074951171875, 0.9286821484565735, 0.9317829608917236, 0.933074951171875, 0.9281653761863708, 0.9343669414520264, 0.9191214442253113, 0.9281653761863708, 0.934108555316925, 0.9392764568328857, 0.9382429122924805, 0.9382429122924805, 0.9364340901374817, 0.9423772692680359, 0.9364340901374817, 0.9369509220123291, 0.9434108734130859, 0.9366925358772278, 0.9405684471130371, 0.9485788345336914, 0.94728684425354, 0.9454780220985413, 0.9483203887939453, 0.9459948539733887, 0.9439276456832886, 0.9403100609779358, 0.9454780220985413, 0.9459948539733887, 0.9483203887939453, 0.9498708248138428, 0.9449612498283386, 0.9459948539733887, 0.948062002658844, 0.9496123790740967, 0.950904369354248, 0.9529715776443481, 0.9552971720695496, 0.9488372206687927, 0.9568475484848022, 0.9514212012290955, 0.949095606803894, 0.9501292109489441, 0.959431529045105, 0.9485788345336914, 0.9558139443397522, 0.9542635679244995, 0.9493539929389954, 0.9583979249000549, 0.9563307762145996, 0.959431529045105, 0.9625322818756104, 0.9635658860206604, 0.9648578763008118, 0.9599483013153076, 0.9552971720695496, 0.9565891623497009, 0.9589147567749023, 0.9589147567749023, 0.949095606803894, 0.9560723304748535, 0.9578811526298523], 'val_loss': [1.0125641822814941, 1.0072072744369507, 1.001173973083496, 0.9942610263824463, 0.9870619773864746, 0.9782881736755371, 0.9672147035598755, 0.9512072205543518, 0.9373335242271423, 0.9129607081413269, 0.8950173854827881, 0.8682215213775635, 0.8381321430206299, 0.8032639026641846, 0.7701176404953003, 0.7353668212890625, 0.7047156691551208, 0.6847299337387085, 0.6668381094932556, 0.661148726940155, 0.6612648367881775, 0.6560798287391663, 0.6499164700508118, 0.6856426000595093, 0.6773097515106201, 0.6616476774215698, 0.6857410073280334, 0.6749539971351624, 0.6711416244506836, 0.6754416823387146, 0.674828290939331, 0.679121196269989, 0.6889848113059998, 0.6795170903205872, 0.6783292293548584, 0.6893924474716187, 0.7032537460327148, 0.6828657388687134, 0.6996428966522217, 0.6938264966011047, 0.6818632483482361, 0.6850165128707886, 0.6859856843948364, 0.6837385296821594, 0.7162414193153381, 0.7144977450370789, 0.6830441355705261, 0.6985098123550415, 0.7061102986335754, 0.7019143104553223, 0.6880128383636475, 0.6858053803443909, 0.6935259103775024, 0.6932055354118347, 0.691763699054718, 0.6973363161087036, 0.7064539194107056, 0.6957552433013916, 0.6989859342575073, 0.7075514793395996, 0.696614682674408, 0.7189984917640686, 0.7001835107803345, 0.7137122750282288, 0.7029886841773987, 0.7008140683174133, 0.7063457369804382, 0.7093132138252258, 0.7104376554489136, 0.6983028054237366, 0.7101224660873413, 0.7421894073486328, 0.6979410648345947, 0.7037091851234436, 0.7189603447914124, 0.734819769859314, 0.7120143175125122, 0.7257354259490967, 0.7141847610473633, 0.7356484532356262, 0.7124524116516113, 0.7168611884117126, 0.7503277063369751, 0.7096589803695679, 0.7824987173080444, 0.7061244249343872, 0.7098315358161926, 0.7168534994125366, 0.7101160883903503, 0.7159714102745056, 0.7280414700508118, 0.7196921110153198, 0.735032856464386, 0.7190666794776917, 0.7635421752929688, 0.7171610593795776, 0.7165206670761108, 0.7314685583114624, 0.7041420340538025, 0.7193183302879333], 'val_accuracy': [0.8233470916748047, 0.8336777091026306, 0.8254132270812988, 0.836776852607727, 0.817148745059967, 0.8347107172012329, 0.8388429880142212, 0.8450413346290588, 0.8429751992225647, 0.8460744023323059, 0.8398760557174683, 0.8419421315193176, 0.8440082669258118, 0.836776852607727, 0.8440082669258118, 0.8429751992225647, 0.8481404781341553, 0.8450413346290588, 0.8471074104309082, 0.8460744023323059, 0.8533057570457458, 0.8512396812438965, 0.8522727489471436, 0.8450413346290588, 0.8533057570457458, 0.8512396812438965, 0.8564049601554871, 0.8543388247489929, 0.8491735458374023, 0.8502066135406494, 0.8471074104309082, 0.8450413346290588, 0.8481404781341553, 0.8512396812438965, 0.8502066135406494, 0.8481404781341553, 0.8440082669258118, 0.8522727489471436, 0.8491735458374023, 0.8429751992225647, 0.8491735458374023, 0.8491735458374023, 0.8502066135406494, 0.8481404781341553, 0.8429751992225647, 0.8378099203109741, 0.8481404781341553, 0.8460744023323059, 0.8429751992225647, 0.8429751992225647, 0.8471074104309082, 0.8471074104309082, 0.8440082669258118, 0.8543388247489929, 0.8491735458374023, 0.8522727489471436, 0.8409090638160706, 0.8429751992225647, 0.8471074104309082, 0.8429751992225647, 0.8491735458374023, 0.8398760557174683, 0.8481404781341553, 0.8522727489471436, 0.85537189245224, 0.8512396812438965, 0.8450413346290588, 0.8522727489471436, 0.8533057570457458, 0.8491735458374023, 0.8419421315193176, 0.8388429880142212, 0.8512396812438965, 0.8481404781341553, 0.8440082669258118, 0.83574378490448, 0.8460744023323059, 0.8564049601554871, 0.8440082669258118, 0.8388429880142212, 0.8584710955619812, 0.8440082669258118, 0.8409090638160706, 0.8460744023323059, 0.83574378490448, 0.8491735458374023, 0.8450413346290588, 0.8450413346290588, 0.8595041036605835, 0.8564049601554871, 0.8481404781341553, 0.8543388247489929, 0.8450413346290588, 0.8543388247489929, 0.836776852607727, 0.85537189245224, 0.8522727489471436, 0.8440082669258118, 0.8460744023323059, 0.8584710955619812]}\n","32/32 [==============================] - 1s 7ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.4514 - accuracy: 0.9340"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 75ms/step - loss: 0.4514 - accuracy: 0.9340 - val_loss: 0.9312 - val_accuracy: 0.8491\n","Epoch 2/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4369 - accuracy: 0.9367 - val_loss: 0.9282 - val_accuracy: 0.8276\n","Epoch 3/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.4459 - accuracy: 0.9340 - val_loss: 0.9222 - val_accuracy: 0.8513\n","Epoch 4/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4266 - accuracy: 0.9450 - val_loss: 0.9172 - val_accuracy: 0.8416\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4262 - accuracy: 0.9423 - val_loss: 0.9081 - val_accuracy: 0.8491\n","Epoch 6/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4310 - accuracy: 0.9388 - val_loss: 0.9011 - val_accuracy: 0.8373\n","Epoch 7/100\n","29/29 [==============================] - 1s 37ms/step - loss: 0.4167 - accuracy: 0.9480 - val_loss: 0.8871 - val_accuracy: 0.8534\n","Epoch 8/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4120 - accuracy: 0.9507 - val_loss: 0.8780 - val_accuracy: 0.8384\n","Epoch 9/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4073 - accuracy: 0.9502 - val_loss: 0.8567 - val_accuracy: 0.8599\n","Epoch 10/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4103 - accuracy: 0.9461 - val_loss: 0.8439 - val_accuracy: 0.8265\n","Epoch 11/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4133 - accuracy: 0.9483 - val_loss: 0.8205 - val_accuracy: 0.8481\n","Epoch 12/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3997 - accuracy: 0.9531 - val_loss: 0.7960 - val_accuracy: 0.8491\n","Epoch 13/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4009 - accuracy: 0.9520 - val_loss: 0.7596 - val_accuracy: 0.8578\n","Epoch 14/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4032 - accuracy: 0.9494 - val_loss: 0.7258 - val_accuracy: 0.8578\n","Epoch 15/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3938 - accuracy: 0.9531 - val_loss: 0.6941 - val_accuracy: 0.8578\n","Epoch 16/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3982 - accuracy: 0.9526 - val_loss: 0.6561 - val_accuracy: 0.8610\n","Epoch 17/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3915 - accuracy: 0.9566 - val_loss: 0.6207 - val_accuracy: 0.8653\n","Epoch 18/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3886 - accuracy: 0.9572 - val_loss: 0.5902 - val_accuracy: 0.8675\n","Epoch 19/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3891 - accuracy: 0.9539 - val_loss: 0.5665 - val_accuracy: 0.8728\n","Epoch 20/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3886 - accuracy: 0.9564 - val_loss: 0.5553 - val_accuracy: 0.8750\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3949 - accuracy: 0.9518 - val_loss: 0.5680 - val_accuracy: 0.8588\n","Epoch 22/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4167 - accuracy: 0.9402 - val_loss: 0.5261 - val_accuracy: 0.8815\n","Epoch 23/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3935 - accuracy: 0.9523 - val_loss: 0.5299 - val_accuracy: 0.8804\n","Epoch 24/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.3791 - accuracy: 0.9599 - val_loss: 0.5195 - val_accuracy: 0.8912\n","Epoch 25/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3759 - accuracy: 0.9593 - val_loss: 0.5194 - val_accuracy: 0.8847\n","Epoch 26/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3778 - accuracy: 0.9572 - val_loss: 0.5439 - val_accuracy: 0.8750\n","Epoch 27/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.3809 - accuracy: 0.9591 - val_loss: 0.5223 - val_accuracy: 0.8922\n","Epoch 28/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3704 - accuracy: 0.9639 - val_loss: 0.5245 - val_accuracy: 0.8879\n","Epoch 29/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3719 - accuracy: 0.9596 - val_loss: 0.5319 - val_accuracy: 0.8901\n","Epoch 30/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3681 - accuracy: 0.9647 - val_loss: 0.5698 - val_accuracy: 0.8685\n","Epoch 31/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3694 - accuracy: 0.9636 - val_loss: 0.5459 - val_accuracy: 0.8772\n","Epoch 32/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3628 - accuracy: 0.9647 - val_loss: 0.5824 - val_accuracy: 0.8664\n","Epoch 33/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3866 - accuracy: 0.9534 - val_loss: 0.5961 - val_accuracy: 0.8599\n","Epoch 34/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3731 - accuracy: 0.9617 - val_loss: 0.5673 - val_accuracy: 0.8707\n","Epoch 35/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3592 - accuracy: 0.9658 - val_loss: 0.5654 - val_accuracy: 0.8782\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3632 - accuracy: 0.9609 - val_loss: 0.5516 - val_accuracy: 0.8772\n","Epoch 37/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3620 - accuracy: 0.9634 - val_loss: 0.5399 - val_accuracy: 0.8976\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3541 - accuracy: 0.9658 - val_loss: 0.5380 - val_accuracy: 0.8976\n","Epoch 39/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3520 - accuracy: 0.9690 - val_loss: 0.5425 - val_accuracy: 0.8944\n","Epoch 40/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3644 - accuracy: 0.9623 - val_loss: 0.5451 - val_accuracy: 0.8890\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3707 - accuracy: 0.9572 - val_loss: 0.6062 - val_accuracy: 0.8642\n","Epoch 42/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3533 - accuracy: 0.9671 - val_loss: 0.5567 - val_accuracy: 0.8750\n","Epoch 43/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3533 - accuracy: 0.9636 - val_loss: 0.6207 - val_accuracy: 0.8578\n","Epoch 44/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3505 - accuracy: 0.9690 - val_loss: 0.5607 - val_accuracy: 0.8804\n","Epoch 45/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3477 - accuracy: 0.9720 - val_loss: 0.5538 - val_accuracy: 0.8933\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3499 - accuracy: 0.9679 - val_loss: 0.5526 - val_accuracy: 0.8890\n","Epoch 47/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3620 - accuracy: 0.9604 - val_loss: 0.5576 - val_accuracy: 0.8912\n","Epoch 48/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3454 - accuracy: 0.9690 - val_loss: 0.5445 - val_accuracy: 0.8922\n","Epoch 49/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3376 - accuracy: 0.9704 - val_loss: 0.5546 - val_accuracy: 0.8890\n","Epoch 50/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3396 - accuracy: 0.9741 - val_loss: 0.5868 - val_accuracy: 0.8696\n","Epoch 51/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3384 - accuracy: 0.9714 - val_loss: 0.5504 - val_accuracy: 0.8901\n","Epoch 52/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3435 - accuracy: 0.9679 - val_loss: 0.5627 - val_accuracy: 0.8912\n","Epoch 53/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3327 - accuracy: 0.9741 - val_loss: 0.5967 - val_accuracy: 0.8685\n","Epoch 54/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3326 - accuracy: 0.9728 - val_loss: 0.5612 - val_accuracy: 0.8847\n","Epoch 55/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3285 - accuracy: 0.9744 - val_loss: 0.5714 - val_accuracy: 0.8804\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3310 - accuracy: 0.9741 - val_loss: 0.5729 - val_accuracy: 0.8912\n","Epoch 57/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3427 - accuracy: 0.9661 - val_loss: 0.5632 - val_accuracy: 0.8922\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3352 - accuracy: 0.9720 - val_loss: 0.5656 - val_accuracy: 0.8869\n","Epoch 59/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3244 - accuracy: 0.9758 - val_loss: 0.5672 - val_accuracy: 0.8847\n","Epoch 60/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3206 - accuracy: 0.9793 - val_loss: 0.5924 - val_accuracy: 0.8718\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3235 - accuracy: 0.9755 - val_loss: 0.5938 - val_accuracy: 0.8685\n","Epoch 62/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3298 - accuracy: 0.9712 - val_loss: 0.5706 - val_accuracy: 0.8890\n","Epoch 63/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3373 - accuracy: 0.9661 - val_loss: 0.5678 - val_accuracy: 0.8922\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3348 - accuracy: 0.9688 - val_loss: 0.5825 - val_accuracy: 0.8772\n","Epoch 65/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3178 - accuracy: 0.9798 - val_loss: 0.5703 - val_accuracy: 0.8836\n","Epoch 66/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3156 - accuracy: 0.9782 - val_loss: 0.5687 - val_accuracy: 0.8869\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3170 - accuracy: 0.9776 - val_loss: 0.5666 - val_accuracy: 0.8944\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3218 - accuracy: 0.9731 - val_loss: 0.5698 - val_accuracy: 0.8922\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3114 - accuracy: 0.9795 - val_loss: 0.6040 - val_accuracy: 0.8707\n","Epoch 70/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3147 - accuracy: 0.9803 - val_loss: 0.6033 - val_accuracy: 0.8696\n","Epoch 71/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3114 - accuracy: 0.9793 - val_loss: 0.5956 - val_accuracy: 0.8901\n","Epoch 72/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3260 - accuracy: 0.9728 - val_loss: 0.5925 - val_accuracy: 0.8761\n","Epoch 73/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3182 - accuracy: 0.9733 - val_loss: 0.6046 - val_accuracy: 0.8685\n","Epoch 74/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3136 - accuracy: 0.9760 - val_loss: 0.6031 - val_accuracy: 0.8696\n","Epoch 75/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3126 - accuracy: 0.9768 - val_loss: 0.5799 - val_accuracy: 0.8847\n","Epoch 76/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3046 - accuracy: 0.9817 - val_loss: 0.5931 - val_accuracy: 0.8707\n","Epoch 77/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3066 - accuracy: 0.9793 - val_loss: 0.5907 - val_accuracy: 0.8728\n","Epoch 78/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3063 - accuracy: 0.9793 - val_loss: 0.5824 - val_accuracy: 0.8804\n","Epoch 79/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3009 - accuracy: 0.9814 - val_loss: 0.5779 - val_accuracy: 0.8922\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3010 - accuracy: 0.9801 - val_loss: 0.5991 - val_accuracy: 0.8685\n","Epoch 81/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3018 - accuracy: 0.9817 - val_loss: 0.5805 - val_accuracy: 0.8869\n","Epoch 82/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3189 - accuracy: 0.9704 - val_loss: 0.6412 - val_accuracy: 0.8588\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2998 - accuracy: 0.9814 - val_loss: 0.6546 - val_accuracy: 0.8588\n","Epoch 84/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3015 - accuracy: 0.9806 - val_loss: 0.6231 - val_accuracy: 0.8685\n","Epoch 85/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2969 - accuracy: 0.9801 - val_loss: 0.6022 - val_accuracy: 0.8772\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2989 - accuracy: 0.9798 - val_loss: 0.5867 - val_accuracy: 0.8804\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2914 - accuracy: 0.9857 - val_loss: 0.5939 - val_accuracy: 0.8772\n","Epoch 88/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3008 - accuracy: 0.9809 - val_loss: 0.6712 - val_accuracy: 0.8524\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2939 - accuracy: 0.9822 - val_loss: 0.6165 - val_accuracy: 0.8728\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2957 - accuracy: 0.9817 - val_loss: 0.5971 - val_accuracy: 0.8825\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2935 - accuracy: 0.9825 - val_loss: 0.5944 - val_accuracy: 0.8782\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2911 - accuracy: 0.9833 - val_loss: 0.5882 - val_accuracy: 0.8858\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2871 - accuracy: 0.9844 - val_loss: 0.6105 - val_accuracy: 0.8739\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2855 - accuracy: 0.9841 - val_loss: 0.6100 - val_accuracy: 0.8739\n","Epoch 95/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2865 - accuracy: 0.9846 - val_loss: 0.5990 - val_accuracy: 0.8804\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2883 - accuracy: 0.9841 - val_loss: 0.6033 - val_accuracy: 0.8825\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2944 - accuracy: 0.9803 - val_loss: 0.5948 - val_accuracy: 0.8901\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2848 - accuracy: 0.9825 - val_loss: 0.6022 - val_accuracy: 0.8879\n","Epoch 99/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2779 - accuracy: 0.9873 - val_loss: 0.6796 - val_accuracy: 0.8556\n","Epoch 100/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2838 - accuracy: 0.9836 - val_loss: 0.6091 - val_accuracy: 0.8761\n","{'loss': [0.45142310857772827, 0.4369291365146637, 0.4459264278411865, 0.4266054928302765, 0.42618030309677124, 0.43098920583724976, 0.41665589809417725, 0.41198673844337463, 0.40725916624069214, 0.41025879979133606, 0.4132673442363739, 0.39968734979629517, 0.4008792042732239, 0.40318357944488525, 0.3937745690345764, 0.39817458391189575, 0.39152202010154724, 0.38856613636016846, 0.3890979588031769, 0.3885800242424011, 0.3948539197444916, 0.41668057441711426, 0.3935107886791229, 0.3790689706802368, 0.3759017884731293, 0.3778224587440491, 0.3809356093406677, 0.3704227805137634, 0.37193700671195984, 0.368121862411499, 0.3694387376308441, 0.36281296610832214, 0.38657286763191223, 0.37314775586128235, 0.3591657280921936, 0.3631989061832428, 0.36203306913375854, 0.35408276319503784, 0.35199683904647827, 0.36439597606658936, 0.370676726102829, 0.3532896935939789, 0.35332444310188293, 0.350532591342926, 0.34768855571746826, 0.34989726543426514, 0.36203938722610474, 0.3454192578792572, 0.3376157283782959, 0.3396074175834656, 0.3384268879890442, 0.3434557318687439, 0.332658052444458, 0.3325832486152649, 0.3285195231437683, 0.3310336768627167, 0.3427218198776245, 0.33515867590904236, 0.3244301676750183, 0.32057085633277893, 0.32351553440093994, 0.329757422208786, 0.3372514545917511, 0.33484527468681335, 0.3177516460418701, 0.3155555725097656, 0.316958487033844, 0.3217603862285614, 0.3114090859889984, 0.31474992632865906, 0.31136956810951233, 0.3259846866130829, 0.3182069659233093, 0.31361207365989685, 0.3125900328159332, 0.3046096861362457, 0.30661436915397644, 0.3062872290611267, 0.3009262681007385, 0.30102452635765076, 0.3018397390842438, 0.31893157958984375, 0.299809068441391, 0.3014663755893707, 0.2969493865966797, 0.2988773286342621, 0.2914268970489502, 0.3007534146308899, 0.2938655614852905, 0.29567259550094604, 0.2935023009777069, 0.2910793423652649, 0.2871359586715698, 0.2855321764945984, 0.28647077083587646, 0.2883284389972687, 0.2944209575653076, 0.2847515940666199, 0.2778788208961487, 0.28380241990089417], 'accuracy': [0.9339978694915771, 0.9366918206214905, 0.9339978694915771, 0.9450430870056152, 0.9423491358757019, 0.938847005367279, 0.9480064511299133, 0.9507004022598267, 0.9501616358757019, 0.9461206793785095, 0.9482758641242981, 0.953125, 0.9520474076271057, 0.9493534564971924, 0.953125, 0.9525862336158752, 0.9566271305084229, 0.9571659564971924, 0.9539331793785095, 0.9563577771186829, 0.951777994632721, 0.9401939511299133, 0.9523168206214905, 0.9598599076271057, 0.959321141242981, 0.9571659564971924, 0.9590517282485962, 0.9639008641242981, 0.959590494632721, 0.9647090435028076, 0.9636314511299133, 0.9647090435028076, 0.9533944129943848, 0.9617456793785095, 0.9657866358757019, 0.9609375, 0.9633620977401733, 0.9657866358757019, 0.9690194129943848, 0.962284505367279, 0.9571659564971924, 0.967133641242981, 0.9636314511299133, 0.9690194129943848, 0.9719827771186829, 0.9679418206214905, 0.9603987336158752, 0.9690194129943848, 0.970366358757019, 0.9741379022598267, 0.9714439511299133, 0.9679418206214905, 0.9741379022598267, 0.9727909564971924, 0.9744073152542114, 0.9741379022598267, 0.9660560488700867, 0.9719827771186829, 0.9757543206214905, 0.9792564511299133, 0.9754849076271057, 0.9711745977401733, 0.9660560488700867, 0.96875, 0.9797952771186829, 0.978178858757019, 0.9776400923728943, 0.9730603694915771, 0.9795258641242981, 0.9803340435028076, 0.9792564511299133, 0.9727909564971924, 0.9733297228813171, 0.9760237336158752, 0.9768319129943848, 0.9816810488700867, 0.9792564511299133, 0.9792564511299133, 0.9814116358757019, 0.9800646305084229, 0.9816810488700867, 0.970366358757019, 0.9814116358757019, 0.9806034564971924, 0.9800646305084229, 0.9797952771186829, 0.985722005367279, 0.9808728694915771, 0.9822198152542114, 0.9816810488700867, 0.9824892282485962, 0.9832974076271057, 0.984375, 0.9841055870056152, 0.9846444129943848, 0.9841055870056152, 0.9803340435028076, 0.9824892282485962, 0.9873383641242981, 0.9835668206214905], 'val_loss': [0.9312471747398376, 0.9282436966896057, 0.9222196340560913, 0.9172489047050476, 0.9081024527549744, 0.9010805487632751, 0.8870686292648315, 0.8780255317687988, 0.8566552400588989, 0.8439306616783142, 0.8204845786094666, 0.7959771752357483, 0.7595599889755249, 0.725787878036499, 0.6941491961479187, 0.6561341881752014, 0.620678722858429, 0.5901868939399719, 0.5664693713188171, 0.5552725791931152, 0.5679892897605896, 0.526131272315979, 0.5299261212348938, 0.5194681882858276, 0.5193773508071899, 0.5439444184303284, 0.5223105549812317, 0.524452805519104, 0.53191077709198, 0.5697570443153381, 0.545947790145874, 0.5824318528175354, 0.5961099863052368, 0.5672664046287537, 0.5653678774833679, 0.5515637993812561, 0.5399219989776611, 0.5380285382270813, 0.5425109267234802, 0.5451130867004395, 0.6061503291130066, 0.5566638708114624, 0.6206948757171631, 0.5607131719589233, 0.5537700653076172, 0.5526409149169922, 0.5576112866401672, 0.5444541573524475, 0.5545949339866638, 0.5868008732795715, 0.5503956079483032, 0.562706708908081, 0.5967076420783997, 0.5612127184867859, 0.5714243650436401, 0.57286137342453, 0.5631715059280396, 0.565597414970398, 0.5672386288642883, 0.5923545956611633, 0.5938434600830078, 0.5706480145454407, 0.5678094029426575, 0.5824905037879944, 0.5703152418136597, 0.5686870813369751, 0.5665961503982544, 0.5698187351226807, 0.6040179133415222, 0.6032548546791077, 0.5955528020858765, 0.5924898386001587, 0.6046030521392822, 0.6031230688095093, 0.5799259543418884, 0.5930975675582886, 0.5906929969787598, 0.5824434757232666, 0.5778574347496033, 0.599141538143158, 0.580470860004425, 0.6412373185157776, 0.6545937061309814, 0.6231213808059692, 0.6021503210067749, 0.5866543054580688, 0.5939369201660156, 0.6712143421173096, 0.6165271401405334, 0.5971353650093079, 0.5944173336029053, 0.5882185101509094, 0.610511302947998, 0.6099603176116943, 0.5989817976951599, 0.6033308506011963, 0.59479820728302, 0.6021931171417236, 0.6795533299446106, 0.609148383140564], 'val_accuracy': [0.8491379022598267, 0.8275862336158752, 0.8512930870056152, 0.8415948152542114, 0.8491379022598267, 0.837284505367279, 0.8534482717514038, 0.8383620977401733, 0.8599137663841248, 0.826508641242981, 0.8480603694915771, 0.8491379022598267, 0.857758641242981, 0.857758641242981, 0.857758641242981, 0.860991358757019, 0.8653017282485962, 0.8674569129943848, 0.8728448152542114, 0.875, 0.8588362336158752, 0.881465494632721, 0.8803879022598267, 0.8911637663841248, 0.8846982717514038, 0.875, 0.892241358757019, 0.8879310488700867, 0.8900862336158752, 0.868534505367279, 0.8771551847457886, 0.8663793206214905, 0.8599137663841248, 0.8706896305084229, 0.8782327771186829, 0.8771551847457886, 0.8976293206214905, 0.8976293206214905, 0.8943965435028076, 0.889008641242981, 0.8642241358757019, 0.875, 0.857758641242981, 0.8803879022598267, 0.8933189511299133, 0.889008641242981, 0.8911637663841248, 0.892241358757019, 0.889008641242981, 0.8696120977401733, 0.8900862336158752, 0.8911637663841248, 0.868534505367279, 0.8846982717514038, 0.8803879022598267, 0.8911637663841248, 0.892241358757019, 0.8868534564971924, 0.8846982717514038, 0.8717672228813171, 0.868534505367279, 0.889008641242981, 0.892241358757019, 0.8771551847457886, 0.8836206793785095, 0.8868534564971924, 0.8943965435028076, 0.892241358757019, 0.8706896305084229, 0.8696120977401733, 0.8900862336158752, 0.8760775923728943, 0.868534505367279, 0.8696120977401733, 0.8846982717514038, 0.8706896305084229, 0.8728448152542114, 0.8803879022598267, 0.892241358757019, 0.868534505367279, 0.8868534564971924, 0.8588362336158752, 0.8588362336158752, 0.868534505367279, 0.8771551847457886, 0.8803879022598267, 0.8771551847457886, 0.8523706793785095, 0.8728448152542114, 0.8825430870056152, 0.8782327771186829, 0.8857758641242981, 0.8739224076271057, 0.8739224076271057, 0.8803879022598267, 0.8825430870056152, 0.8900862336158752, 0.8879310488700867, 0.8556034564971924, 0.8760775923728943]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.4614 - accuracy: 0.9270"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 9s 92ms/step - loss: 0.4593 - accuracy: 0.9281 - val_loss: 0.9334 - val_accuracy: 0.8371\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4431 - accuracy: 0.9372 - val_loss: 0.9298 - val_accuracy: 0.8348\n","Epoch 3/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4357 - accuracy: 0.9372 - val_loss: 0.9246 - val_accuracy: 0.8281\n","Epoch 4/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4373 - accuracy: 0.9366 - val_loss: 0.9197 - val_accuracy: 0.8303\n","Epoch 5/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4307 - accuracy: 0.9360 - val_loss: 0.9137 - val_accuracy: 0.8269\n","Epoch 6/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4237 - accuracy: 0.9440 - val_loss: 0.9038 - val_accuracy: 0.8416\n","Epoch 7/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4236 - accuracy: 0.9448 - val_loss: 0.8938 - val_accuracy: 0.8303\n","Epoch 8/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4246 - accuracy: 0.9414 - val_loss: 0.8815 - val_accuracy: 0.8314\n","Epoch 9/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4183 - accuracy: 0.9468 - val_loss: 0.8703 - val_accuracy: 0.8326\n","Epoch 10/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4337 - accuracy: 0.9375 - val_loss: 0.8529 - val_accuracy: 0.8405\n","Epoch 11/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4108 - accuracy: 0.9448 - val_loss: 0.8373 - val_accuracy: 0.8281\n","Epoch 12/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4207 - accuracy: 0.9389 - val_loss: 0.8106 - val_accuracy: 0.8303\n","Epoch 13/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4048 - accuracy: 0.9488 - val_loss: 0.7877 - val_accuracy: 0.8360\n","Epoch 14/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4140 - accuracy: 0.9465 - val_loss: 0.7602 - val_accuracy: 0.8247\n","Epoch 15/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4067 - accuracy: 0.9462 - val_loss: 0.7255 - val_accuracy: 0.8405\n","Epoch 16/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3955 - accuracy: 0.9499 - val_loss: 0.6948 - val_accuracy: 0.8360\n","Epoch 17/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4012 - accuracy: 0.9491 - val_loss: 0.6757 - val_accuracy: 0.8303\n","Epoch 18/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4027 - accuracy: 0.9496 - val_loss: 0.6463 - val_accuracy: 0.8303\n","Epoch 19/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3952 - accuracy: 0.9553 - val_loss: 0.6210 - val_accuracy: 0.8405\n","Epoch 20/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3921 - accuracy: 0.9513 - val_loss: 0.6002 - val_accuracy: 0.8439\n","Epoch 21/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3960 - accuracy: 0.9513 - val_loss: 0.5931 - val_accuracy: 0.8439\n","Epoch 22/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3893 - accuracy: 0.9519 - val_loss: 0.5960 - val_accuracy: 0.8439\n","Epoch 23/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3858 - accuracy: 0.9547 - val_loss: 0.5950 - val_accuracy: 0.8416\n","Epoch 24/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3896 - accuracy: 0.9502 - val_loss: 0.5990 - val_accuracy: 0.8439\n","Epoch 25/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3925 - accuracy: 0.9499 - val_loss: 0.6040 - val_accuracy: 0.8371\n","Epoch 26/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3835 - accuracy: 0.9553 - val_loss: 0.6732 - val_accuracy: 0.8473\n","Epoch 27/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3813 - accuracy: 0.9570 - val_loss: 0.6529 - val_accuracy: 0.8484\n","Epoch 28/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3781 - accuracy: 0.9564 - val_loss: 0.6567 - val_accuracy: 0.8518\n","Epoch 29/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3800 - accuracy: 0.9604 - val_loss: 0.6868 - val_accuracy: 0.8518\n","Epoch 30/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3709 - accuracy: 0.9593 - val_loss: 0.6811 - val_accuracy: 0.8563\n","Epoch 31/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3707 - accuracy: 0.9593 - val_loss: 0.6698 - val_accuracy: 0.8563\n","Epoch 32/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3717 - accuracy: 0.9581 - val_loss: 0.6464 - val_accuracy: 0.8507\n","Epoch 33/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3766 - accuracy: 0.9567 - val_loss: 0.6595 - val_accuracy: 0.8518\n","Epoch 34/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3658 - accuracy: 0.9590 - val_loss: 0.6577 - val_accuracy: 0.8495\n","Epoch 35/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3617 - accuracy: 0.9604 - val_loss: 0.6677 - val_accuracy: 0.8416\n","Epoch 36/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3738 - accuracy: 0.9544 - val_loss: 0.6649 - val_accuracy: 0.8428\n","Epoch 37/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3594 - accuracy: 0.9595 - val_loss: 0.6766 - val_accuracy: 0.8541\n","Epoch 38/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3556 - accuracy: 0.9641 - val_loss: 0.6681 - val_accuracy: 0.8428\n","Epoch 39/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3659 - accuracy: 0.9604 - val_loss: 0.6685 - val_accuracy: 0.8473\n","Epoch 40/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3603 - accuracy: 0.9641 - val_loss: 0.6742 - val_accuracy: 0.8495\n","Epoch 41/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3475 - accuracy: 0.9689 - val_loss: 0.6778 - val_accuracy: 0.8416\n","Epoch 42/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3606 - accuracy: 0.9601 - val_loss: 0.7154 - val_accuracy: 0.8552\n","Epoch 43/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3595 - accuracy: 0.9621 - val_loss: 0.6934 - val_accuracy: 0.8563\n","Epoch 44/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3476 - accuracy: 0.9646 - val_loss: 0.6861 - val_accuracy: 0.8462\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3626 - accuracy: 0.9587 - val_loss: 0.7577 - val_accuracy: 0.8473\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3597 - accuracy: 0.9612 - val_loss: 0.6848 - val_accuracy: 0.8439\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3533 - accuracy: 0.9632 - val_loss: 0.6712 - val_accuracy: 0.8473\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3497 - accuracy: 0.9655 - val_loss: 0.7189 - val_accuracy: 0.8552\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3712 - accuracy: 0.9525 - val_loss: 0.7175 - val_accuracy: 0.8529\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3573 - accuracy: 0.9604 - val_loss: 0.7111 - val_accuracy: 0.8507\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3521 - accuracy: 0.9621 - val_loss: 0.6882 - val_accuracy: 0.8529\n","Epoch 52/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3402 - accuracy: 0.9652 - val_loss: 0.7016 - val_accuracy: 0.8529\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3403 - accuracy: 0.9683 - val_loss: 0.6778 - val_accuracy: 0.8439\n","Epoch 54/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3338 - accuracy: 0.9700 - val_loss: 0.6832 - val_accuracy: 0.8439\n","Epoch 55/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3366 - accuracy: 0.9692 - val_loss: 0.7118 - val_accuracy: 0.8529\n","Epoch 56/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3346 - accuracy: 0.9680 - val_loss: 0.7153 - val_accuracy: 0.8450\n","Epoch 57/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3317 - accuracy: 0.9709 - val_loss: 0.7037 - val_accuracy: 0.8371\n","Epoch 58/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3303 - accuracy: 0.9709 - val_loss: 0.6960 - val_accuracy: 0.8428\n","Epoch 59/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3275 - accuracy: 0.9703 - val_loss: 0.7142 - val_accuracy: 0.8382\n","Epoch 60/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3435 - accuracy: 0.9632 - val_loss: 0.6928 - val_accuracy: 0.8462\n","Epoch 61/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3275 - accuracy: 0.9717 - val_loss: 0.7037 - val_accuracy: 0.8382\n","Epoch 62/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3289 - accuracy: 0.9694 - val_loss: 0.7298 - val_accuracy: 0.8473\n","Epoch 63/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3315 - accuracy: 0.9697 - val_loss: 0.7041 - val_accuracy: 0.8450\n","Epoch 64/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3315 - accuracy: 0.9703 - val_loss: 0.7046 - val_accuracy: 0.8462\n","Epoch 65/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3192 - accuracy: 0.9745 - val_loss: 0.7186 - val_accuracy: 0.8428\n","Epoch 66/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3111 - accuracy: 0.9793 - val_loss: 0.7370 - val_accuracy: 0.8507\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3244 - accuracy: 0.9711 - val_loss: 0.7445 - val_accuracy: 0.8507\n","Epoch 68/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3269 - accuracy: 0.9683 - val_loss: 0.7301 - val_accuracy: 0.8507\n","Epoch 69/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3148 - accuracy: 0.9754 - val_loss: 0.7160 - val_accuracy: 0.8473\n","Epoch 70/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3071 - accuracy: 0.9796 - val_loss: 0.7241 - val_accuracy: 0.8405\n","Epoch 71/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3273 - accuracy: 0.9663 - val_loss: 0.7383 - val_accuracy: 0.8405\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3176 - accuracy: 0.9754 - val_loss: 0.7237 - val_accuracy: 0.8416\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3111 - accuracy: 0.9771 - val_loss: 0.7202 - val_accuracy: 0.8405\n","Epoch 74/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3103 - accuracy: 0.9788 - val_loss: 0.7523 - val_accuracy: 0.8450\n","Epoch 75/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3211 - accuracy: 0.9709 - val_loss: 0.7427 - val_accuracy: 0.8394\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3062 - accuracy: 0.9791 - val_loss: 0.7279 - val_accuracy: 0.8450\n","Epoch 77/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3098 - accuracy: 0.9731 - val_loss: 0.7419 - val_accuracy: 0.8382\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3116 - accuracy: 0.9771 - val_loss: 0.7499 - val_accuracy: 0.8439\n","Epoch 79/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3076 - accuracy: 0.9771 - val_loss: 0.7457 - val_accuracy: 0.8439\n","Epoch 80/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3111 - accuracy: 0.9748 - val_loss: 0.7469 - val_accuracy: 0.8439\n","Epoch 81/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3030 - accuracy: 0.9805 - val_loss: 0.7772 - val_accuracy: 0.8507\n","Epoch 82/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3023 - accuracy: 0.9788 - val_loss: 0.7656 - val_accuracy: 0.8439\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3190 - accuracy: 0.9703 - val_loss: 0.8178 - val_accuracy: 0.8428\n","Epoch 84/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3056 - accuracy: 0.9782 - val_loss: 0.7409 - val_accuracy: 0.8473\n","Epoch 85/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2962 - accuracy: 0.9833 - val_loss: 0.7445 - val_accuracy: 0.8439\n","Epoch 86/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3068 - accuracy: 0.9757 - val_loss: 0.7602 - val_accuracy: 0.8382\n","Epoch 87/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3047 - accuracy: 0.9740 - val_loss: 0.7495 - val_accuracy: 0.8416\n","Epoch 88/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2924 - accuracy: 0.9822 - val_loss: 0.7527 - val_accuracy: 0.8428\n","Epoch 89/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3010 - accuracy: 0.9779 - val_loss: 0.7440 - val_accuracy: 0.8473\n","Epoch 90/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2921 - accuracy: 0.9813 - val_loss: 0.8500 - val_accuracy: 0.8462\n","Epoch 91/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3052 - accuracy: 0.9726 - val_loss: 0.7754 - val_accuracy: 0.8360\n","Epoch 92/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3105 - accuracy: 0.9734 - val_loss: 0.7709 - val_accuracy: 0.8371\n","Epoch 93/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2936 - accuracy: 0.9796 - val_loss: 0.7873 - val_accuracy: 0.8462\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2883 - accuracy: 0.9810 - val_loss: 0.7612 - val_accuracy: 0.8484\n","Epoch 95/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2860 - accuracy: 0.9830 - val_loss: 0.7682 - val_accuracy: 0.8394\n","Epoch 96/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2877 - accuracy: 0.9833 - val_loss: 0.7606 - val_accuracy: 0.8405\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2852 - accuracy: 0.9850 - val_loss: 0.7666 - val_accuracy: 0.8439\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2855 - accuracy: 0.9830 - val_loss: 0.7720 - val_accuracy: 0.8484\n","Epoch 99/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2818 - accuracy: 0.9867 - val_loss: 0.7853 - val_accuracy: 0.8462\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2891 - accuracy: 0.9813 - val_loss: 0.8083 - val_accuracy: 0.8348\n","{'loss': [0.45926809310913086, 0.4431406259536743, 0.43569809198379517, 0.43733787536621094, 0.43065905570983887, 0.42368608713150024, 0.42355549335479736, 0.42463383078575134, 0.4182882010936737, 0.4336872100830078, 0.4108455181121826, 0.42074739933013916, 0.404766708612442, 0.41396093368530273, 0.40673041343688965, 0.3954552114009857, 0.4012412428855896, 0.4026931822299957, 0.3952433168888092, 0.3920891284942627, 0.3959711492061615, 0.3893309235572815, 0.3858286142349243, 0.3896361291408539, 0.3924703299999237, 0.383517861366272, 0.3813264071941376, 0.3781072199344635, 0.38003572821617126, 0.37091511487960815, 0.37069448828697205, 0.3717159926891327, 0.3766380250453949, 0.36581701040267944, 0.3617139756679535, 0.3737817406654358, 0.35938912630081177, 0.3556413948535919, 0.3658722937107086, 0.3602730929851532, 0.34750038385391235, 0.36064839363098145, 0.359458863735199, 0.34762340784072876, 0.36257103085517883, 0.3597322404384613, 0.3532727062702179, 0.3497033715248108, 0.3712095320224762, 0.35733458399772644, 0.35211074352264404, 0.340187668800354, 0.3403055667877197, 0.3337886333465576, 0.3365752696990967, 0.33460932970046997, 0.3316827714443207, 0.33029013872146606, 0.32747969031333923, 0.3434920310974121, 0.32746365666389465, 0.32891345024108887, 0.33153194189071655, 0.3315223157405853, 0.3192029595375061, 0.31113091111183167, 0.3244176506996155, 0.3269279897212982, 0.3147898018360138, 0.3071485459804535, 0.32734549045562744, 0.31757453083992004, 0.31111183762550354, 0.3102850615978241, 0.3210882246494293, 0.30624356865882874, 0.3098248839378357, 0.3116176426410675, 0.30764296650886536, 0.3111467659473419, 0.303049236536026, 0.3023016154766083, 0.3189803957939148, 0.30562126636505127, 0.29615119099617004, 0.30684134364128113, 0.30465421080589294, 0.292449027299881, 0.30098623037338257, 0.2921294867992401, 0.3051983118057251, 0.3105175793170929, 0.2936077117919922, 0.28834566473960876, 0.2859971523284912, 0.28766772150993347, 0.28515249490737915, 0.2854829430580139, 0.2817847728729248, 0.28911450505256653], 'accuracy': [0.9281267523765564, 0.9371816515922546, 0.9371816515922546, 0.9366157054901123, 0.9360498189926147, 0.9439728260040283, 0.9448217153549194, 0.941426157951355, 0.9468024969100952, 0.9374646544456482, 0.9448217153549194, 0.9388794302940369, 0.9487832188606262, 0.9465195536613464, 0.9462365508079529, 0.9499151110649109, 0.9490662217140198, 0.9496321678161621, 0.9552914500236511, 0.9513299465179443, 0.9513299465179443, 0.9518958926200867, 0.9547255039215088, 0.9501980543136597, 0.9499151110649109, 0.9552914500236511, 0.9569892287254333, 0.9564233422279358, 0.9603848457336426, 0.9592529535293579, 0.9592529535293579, 0.958121120929718, 0.9567062854766846, 0.9589700102806091, 0.9603848457336426, 0.95444256067276, 0.9595359563827515, 0.9640634059906006, 0.9603848457336426, 0.9640634059906006, 0.9688737988471985, 0.960101842880249, 0.9620826244354248, 0.9646292924880981, 0.9586870670318604, 0.9612337350845337, 0.9632145166397095, 0.965478241443634, 0.9524617791175842, 0.9603848457336426, 0.9620826244354248, 0.9651952385902405, 0.9683078527450562, 0.9700056314468384, 0.9691567420959473, 0.9680249094963074, 0.9708545804023743, 0.9708545804023743, 0.9702886343002319, 0.9632145166397095, 0.9717034697532654, 0.9694397449493408, 0.9697226881980896, 0.9702886343002319, 0.9745330810546875, 0.9793435335159302, 0.971137523651123, 0.9683078527450562, 0.9753820300102234, 0.979626476764679, 0.9663271307945251, 0.9753820300102234, 0.9770798087120056, 0.9787775874137878, 0.9708545804023743, 0.9790605306625366, 0.9731183052062988, 0.9770798087120056, 0.9770798087120056, 0.974816083908081, 0.9804753661155701, 0.9787775874137878, 0.9702886343002319, 0.9782116413116455, 0.983305037021637, 0.9756649732589722, 0.9739671945571899, 0.9821732044219971, 0.9779286980628967, 0.9813242554664612, 0.9725523591041565, 0.9734012484550476, 0.979626476764679, 0.9810413122177124, 0.9830220937728882, 0.983305037021637, 0.9850028157234192, 0.9830220937728882, 0.9867005944252014, 0.9813242554664612], 'val_loss': [0.9334463477134705, 0.929821789264679, 0.9245844483375549, 0.9197301864624023, 0.9136985540390015, 0.9038485288619995, 0.8938353657722473, 0.8814780116081238, 0.8703281283378601, 0.8528608083724976, 0.8373391032218933, 0.8105642199516296, 0.7877236604690552, 0.7601744532585144, 0.7254613637924194, 0.6948291063308716, 0.6756547689437866, 0.6462737917900085, 0.6209993958473206, 0.6001559495925903, 0.5931236147880554, 0.5959511399269104, 0.5950107574462891, 0.599009096622467, 0.6039806604385376, 0.6731966733932495, 0.652867317199707, 0.6567305326461792, 0.6867725253105164, 0.6811299324035645, 0.6697832345962524, 0.646405816078186, 0.6594746708869934, 0.6576582193374634, 0.6677373051643372, 0.6649172902107239, 0.6765729784965515, 0.6680557727813721, 0.6684919595718384, 0.6741877198219299, 0.6777610778808594, 0.7153909206390381, 0.6934203505516052, 0.6861371397972107, 0.7576826810836792, 0.6847544312477112, 0.6712427139282227, 0.7189162373542786, 0.717456042766571, 0.7111096978187561, 0.6881728768348694, 0.7016323208808899, 0.6778128147125244, 0.6831961870193481, 0.7117907404899597, 0.7152965664863586, 0.7036634683609009, 0.6959604620933533, 0.7142142057418823, 0.6927508115768433, 0.703694224357605, 0.7298406362533569, 0.7041364908218384, 0.7045742869377136, 0.7185751795768738, 0.7369769215583801, 0.7444964647293091, 0.7301039099693298, 0.7159554958343506, 0.7240732312202454, 0.7382590174674988, 0.7237469553947449, 0.7201651930809021, 0.7522593140602112, 0.7426652312278748, 0.7279087901115417, 0.7419176697731018, 0.7499489188194275, 0.7456828951835632, 0.7469181418418884, 0.7772289514541626, 0.7656481266021729, 0.8177869915962219, 0.7409433722496033, 0.744537889957428, 0.760222852230072, 0.7494885921478271, 0.7526733875274658, 0.7440446615219116, 0.850036084651947, 0.775404155254364, 0.7708908915519714, 0.7872893810272217, 0.7611926794052124, 0.7681893706321716, 0.7606498003005981, 0.7665554881095886, 0.7720146179199219, 0.7852529883384705, 0.8082934021949768], 'val_accuracy': [0.837104082107544, 0.8348416090011597, 0.8280543088912964, 0.8303167223930359, 0.8269230723381042, 0.8416289687156677, 0.8303167223930359, 0.831447958946228, 0.8325791954994202, 0.8404977321624756, 0.8280543088912964, 0.8303167223930359, 0.8359728455543518, 0.8246606588363647, 0.8404977321624756, 0.8359728455543518, 0.8303167223930359, 0.8303167223930359, 0.8404977321624756, 0.8438913822174072, 0.8438913822174072, 0.8438913822174072, 0.8416289687156677, 0.8438913822174072, 0.837104082107544, 0.8472850918769836, 0.848416268825531, 0.8518099784851074, 0.8518099784851074, 0.8563348650932312, 0.8563348650932312, 0.8506787419319153, 0.8518099784851074, 0.8495475053787231, 0.8416289687156677, 0.8427602052688599, 0.8540723919868469, 0.8427602052688599, 0.8472850918769836, 0.8495475053787231, 0.8416289687156677, 0.8552036285400391, 0.8563348650932312, 0.8461538553237915, 0.8472850918769836, 0.8438913822174072, 0.8472850918769836, 0.8552036285400391, 0.8529411554336548, 0.8506787419319153, 0.8529411554336548, 0.8529411554336548, 0.8438913822174072, 0.8438913822174072, 0.8529411554336548, 0.8450226187705994, 0.837104082107544, 0.8427602052688599, 0.8382353186607361, 0.8461538553237915, 0.8382353186607361, 0.8472850918769836, 0.8450226187705994, 0.8461538553237915, 0.8427602052688599, 0.8506787419319153, 0.8506787419319153, 0.8506787419319153, 0.8472850918769836, 0.8404977321624756, 0.8404977321624756, 0.8416289687156677, 0.8404977321624756, 0.8450226187705994, 0.8393664956092834, 0.8450226187705994, 0.8382353186607361, 0.8438913822174072, 0.8438913822174072, 0.8438913822174072, 0.8506787419319153, 0.8438913822174072, 0.8427602052688599, 0.8472850918769836, 0.8438913822174072, 0.8382353186607361, 0.8416289687156677, 0.8427602052688599, 0.8472850918769836, 0.8461538553237915, 0.8359728455543518, 0.837104082107544, 0.8461538553237915, 0.848416268825531, 0.8393664956092834, 0.8404977321624756, 0.8438913822174072, 0.848416268825531, 0.8461538553237915, 0.8348416090011597]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.4668 - accuracy: 0.9258"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 56ms/step - loss: 0.4668 - accuracy: 0.9258 - val_loss: 0.9310 - val_accuracy: 0.8523\n","Epoch 2/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4302 - accuracy: 0.9401 - val_loss: 0.9256 - val_accuracy: 0.8450\n","Epoch 3/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4250 - accuracy: 0.9437 - val_loss: 0.9201 - val_accuracy: 0.8450\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4273 - accuracy: 0.9395 - val_loss: 0.9120 - val_accuracy: 0.8450\n","Epoch 5/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4227 - accuracy: 0.9437 - val_loss: 0.9043 - val_accuracy: 0.8388\n","Epoch 6/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4176 - accuracy: 0.9465 - val_loss: 0.8930 - val_accuracy: 0.8543\n","Epoch 7/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4189 - accuracy: 0.9452 - val_loss: 0.8776 - val_accuracy: 0.8450\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4287 - accuracy: 0.9403 - val_loss: 0.8632 - val_accuracy: 0.8523\n","Epoch 9/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4088 - accuracy: 0.9504 - val_loss: 0.8454 - val_accuracy: 0.8533\n","Epoch 10/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4045 - accuracy: 0.9450 - val_loss: 0.8222 - val_accuracy: 0.8502\n","Epoch 11/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4100 - accuracy: 0.9463 - val_loss: 0.7952 - val_accuracy: 0.8564\n","Epoch 12/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4168 - accuracy: 0.9419 - val_loss: 0.7659 - val_accuracy: 0.8461\n","Epoch 13/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4183 - accuracy: 0.9413 - val_loss: 0.7335 - val_accuracy: 0.8533\n","Epoch 14/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3984 - accuracy: 0.9517 - val_loss: 0.6943 - val_accuracy: 0.8512\n","Epoch 15/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.3910 - accuracy: 0.9558 - val_loss: 0.6556 - val_accuracy: 0.8585\n","Epoch 16/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3982 - accuracy: 0.9491 - val_loss: 0.6223 - val_accuracy: 0.8543\n","Epoch 17/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.3867 - accuracy: 0.9558 - val_loss: 0.5997 - val_accuracy: 0.8626\n","Epoch 18/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3911 - accuracy: 0.9519 - val_loss: 0.5939 - val_accuracy: 0.8605\n","Epoch 19/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.4047 - accuracy: 0.9463 - val_loss: 0.5643 - val_accuracy: 0.8698\n","Epoch 20/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3908 - accuracy: 0.9532 - val_loss: 0.6058 - val_accuracy: 0.8554\n","Epoch 21/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3883 - accuracy: 0.9535 - val_loss: 0.5667 - val_accuracy: 0.8709\n","Epoch 22/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3862 - accuracy: 0.9530 - val_loss: 0.5746 - val_accuracy: 0.8719\n","Epoch 23/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4005 - accuracy: 0.9447 - val_loss: 0.5716 - val_accuracy: 0.8750\n","Epoch 24/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3864 - accuracy: 0.9537 - val_loss: 0.5730 - val_accuracy: 0.8729\n","Epoch 25/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3762 - accuracy: 0.9571 - val_loss: 0.6086 - val_accuracy: 0.8574\n","Epoch 26/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3706 - accuracy: 0.9584 - val_loss: 0.5927 - val_accuracy: 0.8698\n","Epoch 27/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3689 - accuracy: 0.9597 - val_loss: 0.6006 - val_accuracy: 0.8709\n","Epoch 28/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3712 - accuracy: 0.9581 - val_loss: 0.6734 - val_accuracy: 0.8616\n","Epoch 29/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3839 - accuracy: 0.9512 - val_loss: 0.6134 - val_accuracy: 0.8750\n","Epoch 30/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3695 - accuracy: 0.9618 - val_loss: 0.6152 - val_accuracy: 0.8740\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3638 - accuracy: 0.9607 - val_loss: 0.6229 - val_accuracy: 0.8719\n","Epoch 32/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3679 - accuracy: 0.9584 - val_loss: 0.6198 - val_accuracy: 0.8802\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3604 - accuracy: 0.9646 - val_loss: 0.6277 - val_accuracy: 0.8688\n","Epoch 34/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3679 - accuracy: 0.9592 - val_loss: 0.6221 - val_accuracy: 0.8771\n","Epoch 35/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3585 - accuracy: 0.9654 - val_loss: 0.6229 - val_accuracy: 0.8781\n","Epoch 36/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3592 - accuracy: 0.9649 - val_loss: 0.6359 - val_accuracy: 0.8688\n","Epoch 37/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3588 - accuracy: 0.9620 - val_loss: 0.6308 - val_accuracy: 0.8771\n","Epoch 38/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3493 - accuracy: 0.9693 - val_loss: 0.6466 - val_accuracy: 0.8709\n","Epoch 39/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3572 - accuracy: 0.9636 - val_loss: 0.6416 - val_accuracy: 0.8709\n","Epoch 40/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3555 - accuracy: 0.9646 - val_loss: 0.6325 - val_accuracy: 0.8719\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3515 - accuracy: 0.9646 - val_loss: 0.6342 - val_accuracy: 0.8791\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3561 - accuracy: 0.9599 - val_loss: 0.6576 - val_accuracy: 0.8595\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3535 - accuracy: 0.9623 - val_loss: 0.6508 - val_accuracy: 0.8698\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3526 - accuracy: 0.9669 - val_loss: 0.6355 - val_accuracy: 0.8760\n","Epoch 45/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3435 - accuracy: 0.9695 - val_loss: 0.6401 - val_accuracy: 0.8740\n","Epoch 46/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3449 - accuracy: 0.9682 - val_loss: 0.6768 - val_accuracy: 0.8595\n","Epoch 47/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3475 - accuracy: 0.9651 - val_loss: 0.6494 - val_accuracy: 0.8678\n","Epoch 48/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3430 - accuracy: 0.9690 - val_loss: 0.6704 - val_accuracy: 0.8595\n","Epoch 49/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3493 - accuracy: 0.9651 - val_loss: 0.6517 - val_accuracy: 0.8647\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3529 - accuracy: 0.9630 - val_loss: 0.6613 - val_accuracy: 0.8750\n","Epoch 51/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3459 - accuracy: 0.9667 - val_loss: 0.6407 - val_accuracy: 0.8719\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3367 - accuracy: 0.9682 - val_loss: 0.6516 - val_accuracy: 0.8709\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3338 - accuracy: 0.9693 - val_loss: 0.6663 - val_accuracy: 0.8667\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3425 - accuracy: 0.9643 - val_loss: 0.6899 - val_accuracy: 0.8626\n","Epoch 55/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3399 - accuracy: 0.9667 - val_loss: 0.6479 - val_accuracy: 0.8740\n","Epoch 56/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3395 - accuracy: 0.9669 - val_loss: 0.6806 - val_accuracy: 0.8709\n","Epoch 57/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3303 - accuracy: 0.9716 - val_loss: 0.6601 - val_accuracy: 0.8678\n","Epoch 58/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3297 - accuracy: 0.9708 - val_loss: 0.6666 - val_accuracy: 0.8719\n","Epoch 59/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3232 - accuracy: 0.9742 - val_loss: 0.6584 - val_accuracy: 0.8698\n","Epoch 60/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3275 - accuracy: 0.9721 - val_loss: 0.6590 - val_accuracy: 0.8719\n","Epoch 61/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3330 - accuracy: 0.9685 - val_loss: 0.6509 - val_accuracy: 0.8709\n","Epoch 62/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3207 - accuracy: 0.9767 - val_loss: 0.6547 - val_accuracy: 0.8740\n","Epoch 63/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3275 - accuracy: 0.9698 - val_loss: 0.6585 - val_accuracy: 0.8760\n","Epoch 64/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3386 - accuracy: 0.9638 - val_loss: 0.6608 - val_accuracy: 0.8698\n","Epoch 65/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3299 - accuracy: 0.9682 - val_loss: 0.6915 - val_accuracy: 0.8667\n","Epoch 66/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3236 - accuracy: 0.9695 - val_loss: 0.6595 - val_accuracy: 0.8750\n","Epoch 67/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3178 - accuracy: 0.9757 - val_loss: 0.6636 - val_accuracy: 0.8740\n","Epoch 68/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3137 - accuracy: 0.9778 - val_loss: 0.6730 - val_accuracy: 0.8688\n","Epoch 69/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3156 - accuracy: 0.9752 - val_loss: 0.7150 - val_accuracy: 0.8595\n","Epoch 70/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3173 - accuracy: 0.9729 - val_loss: 0.7083 - val_accuracy: 0.8636\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3178 - accuracy: 0.9726 - val_loss: 0.6896 - val_accuracy: 0.8709\n","Epoch 72/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3116 - accuracy: 0.9749 - val_loss: 0.6781 - val_accuracy: 0.8667\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3211 - accuracy: 0.9705 - val_loss: 0.6677 - val_accuracy: 0.8760\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3081 - accuracy: 0.9786 - val_loss: 0.6710 - val_accuracy: 0.8667\n","Epoch 75/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3082 - accuracy: 0.9760 - val_loss: 0.7166 - val_accuracy: 0.8647\n","Epoch 76/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3050 - accuracy: 0.9778 - val_loss: 0.6822 - val_accuracy: 0.8719\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3027 - accuracy: 0.9786 - val_loss: 0.7132 - val_accuracy: 0.8616\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3022 - accuracy: 0.9788 - val_loss: 0.6837 - val_accuracy: 0.8688\n","Epoch 79/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3022 - accuracy: 0.9778 - val_loss: 0.6919 - val_accuracy: 0.8647\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3066 - accuracy: 0.9757 - val_loss: 0.6841 - val_accuracy: 0.8719\n","Epoch 81/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2984 - accuracy: 0.9793 - val_loss: 0.6921 - val_accuracy: 0.8657\n","Epoch 82/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2970 - accuracy: 0.9793 - val_loss: 0.7138 - val_accuracy: 0.8626\n","Epoch 83/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2954 - accuracy: 0.9809 - val_loss: 0.7220 - val_accuracy: 0.8574\n","Epoch 84/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3013 - accuracy: 0.9778 - val_loss: 0.7212 - val_accuracy: 0.8605\n","Epoch 85/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3015 - accuracy: 0.9780 - val_loss: 0.7107 - val_accuracy: 0.8688\n","Epoch 86/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2960 - accuracy: 0.9796 - val_loss: 0.7023 - val_accuracy: 0.8636\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3032 - accuracy: 0.9747 - val_loss: 0.7016 - val_accuracy: 0.8688\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2956 - accuracy: 0.9804 - val_loss: 0.6977 - val_accuracy: 0.8667\n","Epoch 89/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3152 - accuracy: 0.9724 - val_loss: 0.6951 - val_accuracy: 0.8698\n","Epoch 90/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3078 - accuracy: 0.9724 - val_loss: 0.6895 - val_accuracy: 0.8667\n","Epoch 91/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2888 - accuracy: 0.9824 - val_loss: 0.6846 - val_accuracy: 0.8740\n","Epoch 92/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2872 - accuracy: 0.9853 - val_loss: 0.7040 - val_accuracy: 0.8719\n","Epoch 93/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2879 - accuracy: 0.9817 - val_loss: 0.6947 - val_accuracy: 0.8657\n","Epoch 94/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2949 - accuracy: 0.9775 - val_loss: 0.7509 - val_accuracy: 0.8626\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2814 - accuracy: 0.9842 - val_loss: 0.7074 - val_accuracy: 0.8667\n","Epoch 96/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2972 - accuracy: 0.9765 - val_loss: 0.7515 - val_accuracy: 0.8616\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2834 - accuracy: 0.9829 - val_loss: 0.7320 - val_accuracy: 0.8626\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2883 - accuracy: 0.9817 - val_loss: 0.7113 - val_accuracy: 0.8688\n","Epoch 99/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2818 - accuracy: 0.9829 - val_loss: 0.6987 - val_accuracy: 0.8667\n","Epoch 100/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2799 - accuracy: 0.9848 - val_loss: 0.7130 - val_accuracy: 0.8740\n","{'loss': [0.46675506234169006, 0.43017303943634033, 0.42495793104171753, 0.4272904694080353, 0.4226601719856262, 0.4176064133644104, 0.4188823103904724, 0.42868128418922424, 0.40875211358070374, 0.4044540524482727, 0.41004088521003723, 0.4167662262916565, 0.4183237552642822, 0.39838624000549316, 0.39104393124580383, 0.3982480764389038, 0.38670244812965393, 0.3910832703113556, 0.40465399622917175, 0.3908403515815735, 0.38826826214790344, 0.38622599840164185, 0.4005112648010254, 0.38637325167655945, 0.37619879841804504, 0.3705745339393616, 0.36887410283088684, 0.3711554706096649, 0.38387367129325867, 0.3694763779640198, 0.3638300895690918, 0.3679385185241699, 0.36039111018180847, 0.3679426610469818, 0.3584756553173065, 0.35924312472343445, 0.35881680250167847, 0.34927046298980713, 0.3572215735912323, 0.3554782569408417, 0.3514575958251953, 0.35608258843421936, 0.35348883271217346, 0.3525523841381073, 0.34353742003440857, 0.3448549807071686, 0.3475092649459839, 0.342985600233078, 0.3492564558982849, 0.35287120938301086, 0.34591466188430786, 0.33668363094329834, 0.3337949812412262, 0.34254592657089233, 0.33992907404899597, 0.33945760130882263, 0.3302904963493347, 0.32969236373901367, 0.3231675326824188, 0.3275471329689026, 0.3330358862876892, 0.3207380175590515, 0.3274692893028259, 0.3385860025882721, 0.3298635184764862, 0.3236410319805145, 0.3177558481693268, 0.3136579096317291, 0.3155525326728821, 0.31725338101387024, 0.31776371598243713, 0.3115552067756653, 0.32105422019958496, 0.3081364035606384, 0.30823057889938354, 0.305013507604599, 0.30272969603538513, 0.30219051241874695, 0.3022185266017914, 0.30663397908210754, 0.29836681485176086, 0.297034353017807, 0.29544001817703247, 0.30129143595695496, 0.3014850914478302, 0.29599571228027344, 0.3032057583332062, 0.29555630683898926, 0.3151600658893585, 0.30776187777519226, 0.2887725830078125, 0.2871676981449127, 0.2878839671611786, 0.29493778944015503, 0.2813856303691864, 0.2972358465194702, 0.2833568751811981, 0.2882949411869049, 0.2818142771720886, 0.2799011766910553], 'accuracy': [0.9258397817611694, 0.9400516748428345, 0.9436692595481873, 0.9395349025726318, 0.9436692595481873, 0.9465116262435913, 0.9452196359634399, 0.9403100609779358, 0.9503875970840454, 0.9449612498283386, 0.94625324010849, 0.9418604373931885, 0.9413436651229858, 0.9516795873641968, 0.9558139443397522, 0.949095606803894, 0.9558139443397522, 0.9519379734992981, 0.94625324010849, 0.9532299637794495, 0.9534883499145508, 0.9529715776443481, 0.9447028636932373, 0.9537467956542969, 0.9571059346199036, 0.9583979249000549, 0.9596899151802063, 0.9581395387649536, 0.9511628150939941, 0.9617571234703064, 0.9607235193252563, 0.9583979249000549, 0.9645994901657104, 0.9591731429100037, 0.9653746485710144, 0.9648578763008118, 0.9620155096054077, 0.9692506194114685, 0.9635658860206604, 0.9645994901657104, 0.9645994901657104, 0.9599483013153076, 0.962273895740509, 0.9669250845909119, 0.9695090651512146, 0.9682170748710632, 0.9651162624359131, 0.9689922332763672, 0.9651162624359131, 0.9630491137504578, 0.9666666388511658, 0.9682170748710632, 0.9692506194114685, 0.9643411040306091, 0.9666666388511658, 0.9669250845909119, 0.9715762138366699, 0.970801055431366, 0.9741601943969727, 0.9720930457115173, 0.9684754610061646, 0.9767441749572754, 0.9697674512863159, 0.9638242721557617, 0.9682170748710632, 0.9695090651512146, 0.9757105708122253, 0.9777777791023254, 0.9751937985420227, 0.9728682041168213, 0.97260981798172, 0.9749354124069214, 0.9705426096916199, 0.9785529971122742, 0.9759690165519714, 0.9777777791023254, 0.9785529971122742, 0.9788113832473755, 0.9777777791023254, 0.9757105708122253, 0.9793281555175781, 0.9793281555175781, 0.9808785319328308, 0.9777777791023254, 0.9780361652374268, 0.9795865416526794, 0.9746770262718201, 0.9803617596626282, 0.9723514318466187, 0.9723514318466187, 0.9824289679527283, 0.9852713346481323, 0.9816537499427795, 0.9775193929672241, 0.9842377305030823, 0.9764857888221741, 0.9829457402229309, 0.9816537499427795, 0.9829457402229309, 0.9847545027732849], 'val_loss': [0.9309772849082947, 0.9256435632705688, 0.9200518727302551, 0.9119560122489929, 0.9043411612510681, 0.8929764032363892, 0.8776343464851379, 0.8631874322891235, 0.8454121947288513, 0.8222253918647766, 0.7952296733856201, 0.7659456133842468, 0.7334581017494202, 0.6943420171737671, 0.6556407809257507, 0.6223202347755432, 0.5997466444969177, 0.5938751101493835, 0.5643354058265686, 0.6057649254798889, 0.5666773915290833, 0.5745852589607239, 0.5716464519500732, 0.5730050802230835, 0.608595609664917, 0.5927180647850037, 0.6006365418434143, 0.6734225153923035, 0.6133539080619812, 0.6152318120002747, 0.6229450106620789, 0.6198469996452332, 0.6277338266372681, 0.6220977306365967, 0.622896671295166, 0.6359429955482483, 0.6308318972587585, 0.6466066837310791, 0.6415700912475586, 0.6325184106826782, 0.6342059969902039, 0.6575717926025391, 0.6508381962776184, 0.6354712247848511, 0.6400892734527588, 0.6767545938491821, 0.6494497656822205, 0.6704330444335938, 0.6516557931900024, 0.661289632320404, 0.6406755447387695, 0.6516019105911255, 0.6662774682044983, 0.6898810267448425, 0.6478807926177979, 0.6806031465530396, 0.6600921154022217, 0.666563868522644, 0.6584318280220032, 0.6589875221252441, 0.6508790254592896, 0.6546778678894043, 0.6584978699684143, 0.6607719659805298, 0.6915234923362732, 0.6595027446746826, 0.6635598540306091, 0.6730186343193054, 0.7149932980537415, 0.70831298828125, 0.6895851492881775, 0.678117573261261, 0.667678713798523, 0.6710091829299927, 0.7165875434875488, 0.6822125315666199, 0.713219404220581, 0.6837261319160461, 0.691851019859314, 0.6840984225273132, 0.6921001672744751, 0.7137930393218994, 0.7220351696014404, 0.7212450504302979, 0.7106560468673706, 0.7022733688354492, 0.7016432285308838, 0.6977245807647705, 0.6950604915618896, 0.689478874206543, 0.6845656037330627, 0.7039676904678345, 0.6946592926979065, 0.7509499788284302, 0.7074223756790161, 0.7515354752540588, 0.732015073299408, 0.7113081216812134, 0.6987205147743225, 0.712989866733551], 'val_accuracy': [0.8522727489471436, 0.8450413346290588, 0.8450413346290588, 0.8450413346290588, 0.8388429880142212, 0.8543388247489929, 0.8450413346290588, 0.8522727489471436, 0.8533057570457458, 0.8502066135406494, 0.8564049601554871, 0.8460744023323059, 0.8533057570457458, 0.8512396812438965, 0.8584710955619812, 0.8543388247489929, 0.8626033067703247, 0.8605371713638306, 0.8698347210884094, 0.85537189245224, 0.8708677887916565, 0.8719007968902588, 0.875, 0.8729338645935059, 0.8574380278587341, 0.8698347210884094, 0.8708677887916565, 0.8615702390670776, 0.875, 0.8739669322967529, 0.8719007968902588, 0.8801652789115906, 0.8688016533851624, 0.8770661354064941, 0.8780992031097412, 0.8688016533851624, 0.8770661354064941, 0.8708677887916565, 0.8708677887916565, 0.8719007968902588, 0.8791322112083435, 0.8595041036605835, 0.8698347210884094, 0.8760330677032471, 0.8739669322967529, 0.8595041036605835, 0.8677685856819153, 0.8595041036605835, 0.8646694421768188, 0.875, 0.8719007968902588, 0.8708677887916565, 0.8667355179786682, 0.8626033067703247, 0.8739669322967529, 0.8708677887916565, 0.8677685856819153, 0.8719007968902588, 0.8698347210884094, 0.8719007968902588, 0.8708677887916565, 0.8739669322967529, 0.8760330677032471, 0.8698347210884094, 0.8667355179786682, 0.875, 0.8739669322967529, 0.8688016533851624, 0.8595041036605835, 0.8636363744735718, 0.8708677887916565, 0.8667355179786682, 0.8760330677032471, 0.8667355179786682, 0.8646694421768188, 0.8719007968902588, 0.8615702390670776, 0.8688016533851624, 0.8646694421768188, 0.8719007968902588, 0.8657024502754211, 0.8626033067703247, 0.8574380278587341, 0.8605371713638306, 0.8688016533851624, 0.8636363744735718, 0.8688016533851624, 0.8667355179786682, 0.8698347210884094, 0.8667355179786682, 0.8739669322967529, 0.8719007968902588, 0.8657024502754211, 0.8626033067703247, 0.8667355179786682, 0.8615702390670776, 0.8626033067703247, 0.8688016533851624, 0.8667355179786682, 0.8739669322967529]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.3653 - accuracy: 0.9556"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 84ms/step - loss: 0.3632 - accuracy: 0.9561 - val_loss: 0.8865 - val_accuracy: 0.8621\n","Epoch 2/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3481 - accuracy: 0.9585 - val_loss: 0.8831 - val_accuracy: 0.8513\n","Epoch 3/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3255 - accuracy: 0.9696 - val_loss: 0.8765 - val_accuracy: 0.8578\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3311 - accuracy: 0.9634 - val_loss: 0.8666 - val_accuracy: 0.8567\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3242 - accuracy: 0.9688 - val_loss: 0.8601 - val_accuracy: 0.8459\n","Epoch 6/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3111 - accuracy: 0.9709 - val_loss: 0.8479 - val_accuracy: 0.8567\n","Epoch 7/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3140 - accuracy: 0.9706 - val_loss: 0.8340 - val_accuracy: 0.8438\n","Epoch 8/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3274 - accuracy: 0.9644 - val_loss: 0.8194 - val_accuracy: 0.8394\n","Epoch 9/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3112 - accuracy: 0.9709 - val_loss: 0.8061 - val_accuracy: 0.8287\n","Epoch 10/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3185 - accuracy: 0.9685 - val_loss: 0.7713 - val_accuracy: 0.8545\n","Epoch 11/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3066 - accuracy: 0.9723 - val_loss: 0.7546 - val_accuracy: 0.8427\n","Epoch 12/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3020 - accuracy: 0.9749 - val_loss: 0.7234 - val_accuracy: 0.8448\n","Epoch 13/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3055 - accuracy: 0.9739 - val_loss: 0.6936 - val_accuracy: 0.8438\n","Epoch 14/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2956 - accuracy: 0.9774 - val_loss: 0.6527 - val_accuracy: 0.8491\n","Epoch 15/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3028 - accuracy: 0.9733 - val_loss: 0.6121 - val_accuracy: 0.8621\n","Epoch 16/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3048 - accuracy: 0.9731 - val_loss: 0.5830 - val_accuracy: 0.8556\n","Epoch 17/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.2875 - accuracy: 0.9833 - val_loss: 0.5384 - val_accuracy: 0.8793\n","Epoch 18/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2981 - accuracy: 0.9752 - val_loss: 0.5243 - val_accuracy: 0.8675\n","Epoch 19/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.2874 - accuracy: 0.9822 - val_loss: 0.4953 - val_accuracy: 0.8847\n","Epoch 20/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2870 - accuracy: 0.9817 - val_loss: 0.4962 - val_accuracy: 0.8815\n","Epoch 21/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.2922 - accuracy: 0.9795 - val_loss: 0.4666 - val_accuracy: 0.8998\n","Epoch 22/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.2861 - accuracy: 0.9806 - val_loss: 0.4536 - val_accuracy: 0.9019\n","Epoch 23/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.2880 - accuracy: 0.9814 - val_loss: 0.4600 - val_accuracy: 0.9073\n","Epoch 24/100\n","29/29 [==============================] - 1s 35ms/step - loss: 0.2855 - accuracy: 0.9790 - val_loss: 0.4637 - val_accuracy: 0.9095\n","Epoch 25/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2826 - accuracy: 0.9841 - val_loss: 0.4545 - val_accuracy: 0.9073\n","Epoch 26/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2856 - accuracy: 0.9822 - val_loss: 0.4769 - val_accuracy: 0.8998\n","Epoch 27/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3046 - accuracy: 0.9698 - val_loss: 0.4734 - val_accuracy: 0.9030\n","Epoch 28/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.2939 - accuracy: 0.9755 - val_loss: 0.4703 - val_accuracy: 0.9116\n","Epoch 29/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.2758 - accuracy: 0.9855 - val_loss: 0.4799 - val_accuracy: 0.9138\n","Epoch 30/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2859 - accuracy: 0.9784 - val_loss: 0.4823 - val_accuracy: 0.9095\n","Epoch 31/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2811 - accuracy: 0.9820 - val_loss: 0.4701 - val_accuracy: 0.9116\n","Epoch 32/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2808 - accuracy: 0.9798 - val_loss: 0.4912 - val_accuracy: 0.9073\n","Epoch 33/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2719 - accuracy: 0.9857 - val_loss: 0.5436 - val_accuracy: 0.8966\n","Epoch 34/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2765 - accuracy: 0.9830 - val_loss: 0.5032 - val_accuracy: 0.9009\n","Epoch 35/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2760 - accuracy: 0.9822 - val_loss: 0.4876 - val_accuracy: 0.9116\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2798 - accuracy: 0.9801 - val_loss: 0.5259 - val_accuracy: 0.8955\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2751 - accuracy: 0.9841 - val_loss: 0.5043 - val_accuracy: 0.8998\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2695 - accuracy: 0.9857 - val_loss: 0.5293 - val_accuracy: 0.8998\n","Epoch 39/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2692 - accuracy: 0.9855 - val_loss: 0.5183 - val_accuracy: 0.9019\n","Epoch 40/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2628 - accuracy: 0.9898 - val_loss: 0.5051 - val_accuracy: 0.9106\n","Epoch 41/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2723 - accuracy: 0.9820 - val_loss: 0.4951 - val_accuracy: 0.9106\n","Epoch 42/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2669 - accuracy: 0.9844 - val_loss: 0.5001 - val_accuracy: 0.9073\n","Epoch 43/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2676 - accuracy: 0.9871 - val_loss: 0.5276 - val_accuracy: 0.8966\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2707 - accuracy: 0.9849 - val_loss: 0.5685 - val_accuracy: 0.8825\n","Epoch 45/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2742 - accuracy: 0.9798 - val_loss: 0.5634 - val_accuracy: 0.8922\n","Epoch 46/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2663 - accuracy: 0.9838 - val_loss: 0.5171 - val_accuracy: 0.9009\n","Epoch 47/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2648 - accuracy: 0.9860 - val_loss: 0.5220 - val_accuracy: 0.8998\n","Epoch 48/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2627 - accuracy: 0.9879 - val_loss: 0.5738 - val_accuracy: 0.8815\n","Epoch 49/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2651 - accuracy: 0.9855 - val_loss: 0.5376 - val_accuracy: 0.8955\n","Epoch 50/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2648 - accuracy: 0.9852 - val_loss: 0.5315 - val_accuracy: 0.8998\n","Epoch 51/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2605 - accuracy: 0.9873 - val_loss: 0.5146 - val_accuracy: 0.8998\n","Epoch 52/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2548 - accuracy: 0.9895 - val_loss: 0.5219 - val_accuracy: 0.8987\n","Epoch 53/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2611 - accuracy: 0.9868 - val_loss: 0.5075 - val_accuracy: 0.9095\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2682 - accuracy: 0.9811 - val_loss: 0.5290 - val_accuracy: 0.8998\n","Epoch 55/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2638 - accuracy: 0.9838 - val_loss: 0.5444 - val_accuracy: 0.8966\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2611 - accuracy: 0.9863 - val_loss: 0.6042 - val_accuracy: 0.8825\n","Epoch 57/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2598 - accuracy: 0.9855 - val_loss: 0.5276 - val_accuracy: 0.8987\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2651 - accuracy: 0.9836 - val_loss: 0.5755 - val_accuracy: 0.8966\n","Epoch 59/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2505 - accuracy: 0.9914 - val_loss: 0.5630 - val_accuracy: 0.8966\n","Epoch 60/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2494 - accuracy: 0.9922 - val_loss: 0.5515 - val_accuracy: 0.8912\n","Epoch 61/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2534 - accuracy: 0.9876 - val_loss: 0.5982 - val_accuracy: 0.8858\n","Epoch 62/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2521 - accuracy: 0.9884 - val_loss: 0.5311 - val_accuracy: 0.9019\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2532 - accuracy: 0.9887 - val_loss: 0.5333 - val_accuracy: 0.9030\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2499 - accuracy: 0.9903 - val_loss: 0.6068 - val_accuracy: 0.8858\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2518 - accuracy: 0.9898 - val_loss: 0.6822 - val_accuracy: 0.8815\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2568 - accuracy: 0.9873 - val_loss: 0.6696 - val_accuracy: 0.8761\n","Epoch 67/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2588 - accuracy: 0.9860 - val_loss: 0.5883 - val_accuracy: 0.8858\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2477 - accuracy: 0.9895 - val_loss: 0.5604 - val_accuracy: 0.8847\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2493 - accuracy: 0.9871 - val_loss: 0.5403 - val_accuracy: 0.9009\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2463 - accuracy: 0.9911 - val_loss: 0.5436 - val_accuracy: 0.8966\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2499 - accuracy: 0.9906 - val_loss: 0.5384 - val_accuracy: 0.8998\n","Epoch 72/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2400 - accuracy: 0.9925 - val_loss: 0.5440 - val_accuracy: 0.8955\n","Epoch 73/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2491 - accuracy: 0.9884 - val_loss: 0.5558 - val_accuracy: 0.8966\n","Epoch 74/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2415 - accuracy: 0.9922 - val_loss: 0.6216 - val_accuracy: 0.8750\n","Epoch 75/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2405 - accuracy: 0.9922 - val_loss: 0.5609 - val_accuracy: 0.8944\n","Epoch 76/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2404 - accuracy: 0.9935 - val_loss: 0.5646 - val_accuracy: 0.9009\n","Epoch 77/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2440 - accuracy: 0.9892 - val_loss: 0.5396 - val_accuracy: 0.9009\n","Epoch 78/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2473 - accuracy: 0.9868 - val_loss: 0.5653 - val_accuracy: 0.8922\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2409 - accuracy: 0.9930 - val_loss: 0.5391 - val_accuracy: 0.8998\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2366 - accuracy: 0.9919 - val_loss: 0.5504 - val_accuracy: 0.9030\n","Epoch 81/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2365 - accuracy: 0.9919 - val_loss: 0.5636 - val_accuracy: 0.9019\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2347 - accuracy: 0.9943 - val_loss: 0.5508 - val_accuracy: 0.9019\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2375 - accuracy: 0.9922 - val_loss: 0.5797 - val_accuracy: 0.8912\n","Epoch 84/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2376 - accuracy: 0.9927 - val_loss: 0.5542 - val_accuracy: 0.8998\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2370 - accuracy: 0.9925 - val_loss: 0.5535 - val_accuracy: 0.9030\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2372 - accuracy: 0.9925 - val_loss: 0.5865 - val_accuracy: 0.8901\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2358 - accuracy: 0.9922 - val_loss: 0.6232 - val_accuracy: 0.8858\n","Epoch 88/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2356 - accuracy: 0.9930 - val_loss: 0.5919 - val_accuracy: 0.8890\n","Epoch 89/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2295 - accuracy: 0.9952 - val_loss: 0.5960 - val_accuracy: 0.8912\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2343 - accuracy: 0.9927 - val_loss: 0.6024 - val_accuracy: 0.8912\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2337 - accuracy: 0.9925 - val_loss: 0.5574 - val_accuracy: 0.9019\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2358 - accuracy: 0.9919 - val_loss: 0.5868 - val_accuracy: 0.8869\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2303 - accuracy: 0.9943 - val_loss: 0.5780 - val_accuracy: 0.8922\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2300 - accuracy: 0.9941 - val_loss: 0.5502 - val_accuracy: 0.8976\n","Epoch 95/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2352 - accuracy: 0.9884 - val_loss: 0.5694 - val_accuracy: 0.8933\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2289 - accuracy: 0.9938 - val_loss: 0.5735 - val_accuracy: 0.9019\n","Epoch 97/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2430 - accuracy: 0.9871 - val_loss: 0.5580 - val_accuracy: 0.9062\n","Epoch 98/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2294 - accuracy: 0.9935 - val_loss: 0.5650 - val_accuracy: 0.8998\n","Epoch 99/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2462 - accuracy: 0.9857 - val_loss: 0.6212 - val_accuracy: 0.8782\n","Epoch 100/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2483 - accuracy: 0.9844 - val_loss: 0.5517 - val_accuracy: 0.8955\n","{'loss': [0.3631936311721802, 0.34807059168815613, 0.3254657983779907, 0.33107051253318787, 0.3241842985153198, 0.31114643812179565, 0.3140454590320587, 0.3274274468421936, 0.31122612953186035, 0.31851571798324585, 0.3066409230232239, 0.30203843116760254, 0.3054526746273041, 0.2955911159515381, 0.302776962518692, 0.3047997057437897, 0.2875336706638336, 0.29813352227211, 0.2874070405960083, 0.28695163130760193, 0.2922361493110657, 0.2860753536224365, 0.28801435232162476, 0.28548282384872437, 0.28255876898765564, 0.28555750846862793, 0.304625540971756, 0.29394617676734924, 0.27583688497543335, 0.2858530282974243, 0.28113648295402527, 0.2808126211166382, 0.27194857597351074, 0.2764756977558136, 0.2759777903556824, 0.279844731092453, 0.275145024061203, 0.26950082182884216, 0.2691580057144165, 0.2627811133861542, 0.27229106426239014, 0.2668735086917877, 0.2676007151603699, 0.2706546485424042, 0.2742158770561218, 0.2663266062736511, 0.2647745907306671, 0.2627430558204651, 0.265055388212204, 0.26479190587997437, 0.26050812005996704, 0.2547772526741028, 0.26109015941619873, 0.2681569457054138, 0.26384440064430237, 0.261101633310318, 0.25984489917755127, 0.2651425302028656, 0.2505180835723877, 0.249394029378891, 0.2533547580242157, 0.2520887553691864, 0.25318920612335205, 0.24988988041877747, 0.2517716884613037, 0.2568148374557495, 0.25878098607063293, 0.24769429862499237, 0.2493247538805008, 0.24632935225963593, 0.24989482760429382, 0.24003522098064423, 0.24908863008022308, 0.24154041707515717, 0.24051545560359955, 0.2403661161661148, 0.24403826892375946, 0.24726270139217377, 0.24089160561561584, 0.23661552369594574, 0.23649871349334717, 0.23467715084552765, 0.2374608963727951, 0.23757998645305634, 0.23703137040138245, 0.23719356954097748, 0.23580880463123322, 0.2356216460466385, 0.22950394451618195, 0.23432569205760956, 0.23370753228664398, 0.23579692840576172, 0.2303023636341095, 0.22999058663845062, 0.2351514846086502, 0.22891341149806976, 0.24304765462875366, 0.22943855822086334, 0.24620315432548523, 0.24831309914588928], 'accuracy': [0.9560883641242981, 0.9585129022598267, 0.9695581793785095, 0.9633620977401733, 0.96875, 0.9709051847457886, 0.9706357717514038, 0.9644396305084229, 0.9709051847457886, 0.9684805870056152, 0.9722521305084229, 0.974946141242981, 0.9738685488700867, 0.9773706793785095, 0.9733297228813171, 0.9730603694915771, 0.9832974076271057, 0.975215494632721, 0.9822198152542114, 0.9816810488700867, 0.9795258641242981, 0.9806034564971924, 0.9814116358757019, 0.9789870977401733, 0.9841055870056152, 0.9822198152542114, 0.9698275923728943, 0.9754849076271057, 0.9854525923728943, 0.9784482717514038, 0.9819504022598267, 0.9797952771186829, 0.985722005367279, 0.983027994632721, 0.9822198152542114, 0.9800646305084229, 0.9841055870056152, 0.985722005367279, 0.9854525923728943, 0.9897629022598267, 0.9819504022598267, 0.984375, 0.9870689511299133, 0.9849137663841248, 0.9797952771186829, 0.9838362336158752, 0.985991358757019, 0.9878771305084229, 0.9854525923728943, 0.9851831793785095, 0.9873383641242981, 0.9894935488700867, 0.9867995977401733, 0.9811422228813171, 0.9838362336158752, 0.9862607717514038, 0.9854525923728943, 0.9835668206214905, 0.9913793206214905, 0.9921875, 0.9876077771186829, 0.9884159564971924, 0.9886853694915771, 0.9903017282485962, 0.9897629022598267, 0.9873383641242981, 0.985991358757019, 0.9894935488700867, 0.9870689511299133, 0.9911099076271057, 0.990571141242981, 0.9924569129943848, 0.9884159564971924, 0.9921875, 0.9921875, 0.993534505367279, 0.9892241358757019, 0.9867995977401733, 0.9929956793785095, 0.9919180870056152, 0.9919180870056152, 0.9943426847457886, 0.9921875, 0.9927262663841248, 0.9924569129943848, 0.9924569129943848, 0.9921875, 0.9929956793785095, 0.9951508641242981, 0.9927262663841248, 0.9924569129943848, 0.9919180870056152, 0.9943426847457886, 0.9940732717514038, 0.9884159564971924, 0.993803858757019, 0.9870689511299133, 0.993534505367279, 0.985722005367279, 0.984375], 'val_loss': [0.8864761590957642, 0.8831058740615845, 0.8765170574188232, 0.8666270971298218, 0.8600768446922302, 0.847915768623352, 0.8340072631835938, 0.8194270730018616, 0.8061469793319702, 0.7712551355361938, 0.754605233669281, 0.7234295606613159, 0.6936327815055847, 0.6526996493339539, 0.6120848655700684, 0.583001971244812, 0.5383550524711609, 0.52425616979599, 0.495345801115036, 0.496196448802948, 0.4665924310684204, 0.4536011219024658, 0.45998522639274597, 0.46374520659446716, 0.45453524589538574, 0.476949006319046, 0.47336357831954956, 0.47026434540748596, 0.4798724353313446, 0.48231229186058044, 0.47009822726249695, 0.49121126532554626, 0.5435847640037537, 0.5032312870025635, 0.48758167028427124, 0.5259369015693665, 0.5042927861213684, 0.5292721390724182, 0.5182886719703674, 0.5050672888755798, 0.4950977563858032, 0.5001327395439148, 0.5276394486427307, 0.5685218572616577, 0.563382089138031, 0.5170830488204956, 0.5220295786857605, 0.573801577091217, 0.5376437902450562, 0.5314531922340393, 0.5145980715751648, 0.5218708515167236, 0.5074982047080994, 0.5289930105209351, 0.54438316822052, 0.604195773601532, 0.5276299118995667, 0.5755327939987183, 0.5629556179046631, 0.5515081286430359, 0.5982046723365784, 0.5311120748519897, 0.5333260297775269, 0.6067547798156738, 0.6821827292442322, 0.6696406602859497, 0.5883215069770813, 0.5604199171066284, 0.5402776598930359, 0.5435976386070251, 0.5383594632148743, 0.544035792350769, 0.5558304190635681, 0.6215537786483765, 0.5608631372451782, 0.5645954012870789, 0.5395633578300476, 0.5653495788574219, 0.5390602946281433, 0.5504114627838135, 0.5636172294616699, 0.5508114695549011, 0.5797366499900818, 0.5541694760322571, 0.5535284876823425, 0.5864818096160889, 0.6231761574745178, 0.591864824295044, 0.5960385799407959, 0.6023881435394287, 0.5574004650115967, 0.5868418216705322, 0.5780121088027954, 0.5501960515975952, 0.5693628191947937, 0.5734691023826599, 0.5579825639724731, 0.5649956464767456, 0.6211642622947693, 0.5516539812088013], 'val_accuracy': [0.8620689511299133, 0.8512930870056152, 0.857758641242981, 0.8566810488700867, 0.8459051847457886, 0.8566810488700867, 0.84375, 0.8394396305084229, 0.8286637663841248, 0.8545258641242981, 0.8426724076271057, 0.8448275923728943, 0.84375, 0.8491379022598267, 0.8620689511299133, 0.8556034564971924, 0.8793103694915771, 0.8674569129943848, 0.8846982717514038, 0.881465494632721, 0.899784505367279, 0.9019396305084229, 0.9073275923728943, 0.9094827771186829, 0.9073275923728943, 0.899784505367279, 0.9030172228813171, 0.9116379022598267, 0.9137930870056152, 0.9094827771186829, 0.9116379022598267, 0.9073275923728943, 0.8965517282485962, 0.9008620977401733, 0.9116379022598267, 0.8954741358757019, 0.899784505367279, 0.899784505367279, 0.9019396305084229, 0.9105603694915771, 0.9105603694915771, 0.9073275923728943, 0.8965517282485962, 0.8825430870056152, 0.892241358757019, 0.9008620977401733, 0.899784505367279, 0.881465494632721, 0.8954741358757019, 0.899784505367279, 0.899784505367279, 0.8987069129943848, 0.9094827771186829, 0.899784505367279, 0.8965517282485962, 0.8825430870056152, 0.8987069129943848, 0.8965517282485962, 0.8965517282485962, 0.8911637663841248, 0.8857758641242981, 0.9019396305084229, 0.9030172228813171, 0.8857758641242981, 0.881465494632721, 0.8760775923728943, 0.8857758641242981, 0.8846982717514038, 0.9008620977401733, 0.8965517282485962, 0.899784505367279, 0.8954741358757019, 0.8965517282485962, 0.875, 0.8943965435028076, 0.9008620977401733, 0.9008620977401733, 0.892241358757019, 0.899784505367279, 0.9030172228813171, 0.9019396305084229, 0.9019396305084229, 0.8911637663841248, 0.899784505367279, 0.9030172228813171, 0.8900862336158752, 0.8857758641242981, 0.889008641242981, 0.8911637663841248, 0.8911637663841248, 0.9019396305084229, 0.8868534564971924, 0.892241358757019, 0.8976293206214905, 0.8933189511299133, 0.9019396305084229, 0.90625, 0.899784505367279, 0.8782327771186829, 0.8954741358757019]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.3918 - accuracy: 0.9435"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 60ms/step - loss: 0.3908 - accuracy: 0.9440 - val_loss: 0.8900 - val_accuracy: 0.8213\n","Epoch 2/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3409 - accuracy: 0.9621 - val_loss: 0.8860 - val_accuracy: 0.8371\n","Epoch 3/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.3258 - accuracy: 0.9655 - val_loss: 0.8800 - val_accuracy: 0.8382\n","Epoch 4/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3182 - accuracy: 0.9675 - val_loss: 0.8719 - val_accuracy: 0.8326\n","Epoch 5/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3309 - accuracy: 0.9646 - val_loss: 0.8632 - val_accuracy: 0.8382\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3197 - accuracy: 0.9680 - val_loss: 0.8550 - val_accuracy: 0.8314\n","Epoch 7/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3337 - accuracy: 0.9604 - val_loss: 0.8413 - val_accuracy: 0.8247\n","Epoch 8/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3093 - accuracy: 0.9709 - val_loss: 0.8281 - val_accuracy: 0.8281\n","Epoch 9/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3202 - accuracy: 0.9669 - val_loss: 0.8081 - val_accuracy: 0.8303\n","Epoch 10/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3142 - accuracy: 0.9697 - val_loss: 0.7902 - val_accuracy: 0.8337\n","Epoch 11/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3153 - accuracy: 0.9669 - val_loss: 0.7711 - val_accuracy: 0.8122\n","Epoch 12/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3140 - accuracy: 0.9697 - val_loss: 0.7425 - val_accuracy: 0.8258\n","Epoch 13/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3166 - accuracy: 0.9666 - val_loss: 0.7178 - val_accuracy: 0.8224\n","Epoch 14/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.3093 - accuracy: 0.9723 - val_loss: 0.6791 - val_accuracy: 0.8541\n","Epoch 15/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3126 - accuracy: 0.9703 - val_loss: 0.6455 - val_accuracy: 0.8439\n","Epoch 16/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3039 - accuracy: 0.9709 - val_loss: 0.6118 - val_accuracy: 0.8563\n","Epoch 17/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3010 - accuracy: 0.9726 - val_loss: 0.5804 - val_accuracy: 0.8609\n","Epoch 18/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3010 - accuracy: 0.9754 - val_loss: 0.5718 - val_accuracy: 0.8326\n","Epoch 19/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3003 - accuracy: 0.9734 - val_loss: 0.5409 - val_accuracy: 0.8541\n","Epoch 20/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3028 - accuracy: 0.9728 - val_loss: 0.5514 - val_accuracy: 0.8518\n","Epoch 21/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3018 - accuracy: 0.9759 - val_loss: 0.5240 - val_accuracy: 0.8654\n","Epoch 22/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3002 - accuracy: 0.9731 - val_loss: 0.5274 - val_accuracy: 0.8575\n","Epoch 23/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2944 - accuracy: 0.9759 - val_loss: 0.5417 - val_accuracy: 0.8631\n","Epoch 24/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.2979 - accuracy: 0.9748 - val_loss: 0.5323 - val_accuracy: 0.8710\n","Epoch 25/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.2994 - accuracy: 0.9745 - val_loss: 0.5388 - val_accuracy: 0.8722\n","Epoch 26/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2881 - accuracy: 0.9782 - val_loss: 0.5624 - val_accuracy: 0.8699\n","Epoch 27/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2944 - accuracy: 0.9740 - val_loss: 0.5830 - val_accuracy: 0.8597\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2982 - accuracy: 0.9720 - val_loss: 0.5779 - val_accuracy: 0.8665\n","Epoch 29/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2970 - accuracy: 0.9720 - val_loss: 0.5861 - val_accuracy: 0.8676\n","Epoch 30/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2885 - accuracy: 0.9768 - val_loss: 0.6409 - val_accuracy: 0.8654\n","Epoch 31/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2805 - accuracy: 0.9842 - val_loss: 0.6175 - val_accuracy: 0.8665\n","Epoch 32/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2825 - accuracy: 0.9799 - val_loss: 0.6555 - val_accuracy: 0.8631\n","Epoch 33/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2852 - accuracy: 0.9776 - val_loss: 0.6274 - val_accuracy: 0.8665\n","Epoch 34/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2845 - accuracy: 0.9796 - val_loss: 0.6194 - val_accuracy: 0.8699\n","Epoch 35/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2872 - accuracy: 0.9768 - val_loss: 0.6781 - val_accuracy: 0.8643\n","Epoch 36/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2965 - accuracy: 0.9734 - val_loss: 0.6908 - val_accuracy: 0.8609\n","Epoch 37/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2856 - accuracy: 0.9796 - val_loss: 0.6337 - val_accuracy: 0.8676\n","Epoch 38/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2712 - accuracy: 0.9816 - val_loss: 0.6476 - val_accuracy: 0.8676\n","Epoch 39/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2980 - accuracy: 0.9714 - val_loss: 0.6814 - val_accuracy: 0.8620\n","Epoch 40/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2895 - accuracy: 0.9748 - val_loss: 0.6263 - val_accuracy: 0.8722\n","Epoch 41/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2765 - accuracy: 0.9819 - val_loss: 0.6078 - val_accuracy: 0.8710\n","Epoch 42/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2767 - accuracy: 0.9816 - val_loss: 0.6255 - val_accuracy: 0.8676\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2713 - accuracy: 0.9850 - val_loss: 0.6404 - val_accuracy: 0.8710\n","Epoch 44/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.2695 - accuracy: 0.9839 - val_loss: 0.6225 - val_accuracy: 0.8733\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2661 - accuracy: 0.9859 - val_loss: 0.6466 - val_accuracy: 0.8643\n","Epoch 46/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2712 - accuracy: 0.9836 - val_loss: 0.7186 - val_accuracy: 0.8631\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2685 - accuracy: 0.9825 - val_loss: 0.6450 - val_accuracy: 0.8710\n","Epoch 48/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2639 - accuracy: 0.9861 - val_loss: 0.6820 - val_accuracy: 0.8631\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2744 - accuracy: 0.9808 - val_loss: 0.6430 - val_accuracy: 0.8710\n","Epoch 50/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2765 - accuracy: 0.9785 - val_loss: 0.6396 - val_accuracy: 0.8688\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2835 - accuracy: 0.9779 - val_loss: 0.6353 - val_accuracy: 0.8688\n","Epoch 52/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2766 - accuracy: 0.9819 - val_loss: 0.6517 - val_accuracy: 0.8597\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2635 - accuracy: 0.9864 - val_loss: 0.6631 - val_accuracy: 0.8609\n","Epoch 54/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2605 - accuracy: 0.9870 - val_loss: 0.6621 - val_accuracy: 0.8643\n","Epoch 55/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2633 - accuracy: 0.9842 - val_loss: 0.6613 - val_accuracy: 0.8631\n","Epoch 56/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2574 - accuracy: 0.9881 - val_loss: 0.7233 - val_accuracy: 0.8609\n","Epoch 57/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2700 - accuracy: 0.9830 - val_loss: 0.6687 - val_accuracy: 0.8631\n","Epoch 58/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2580 - accuracy: 0.9884 - val_loss: 0.6846 - val_accuracy: 0.8654\n","Epoch 59/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2590 - accuracy: 0.9861 - val_loss: 0.6532 - val_accuracy: 0.8722\n","Epoch 60/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.2560 - accuracy: 0.9881 - val_loss: 0.6779 - val_accuracy: 0.8643\n","Epoch 61/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2538 - accuracy: 0.9909 - val_loss: 0.7032 - val_accuracy: 0.8620\n","Epoch 62/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2547 - accuracy: 0.9884 - val_loss: 0.6969 - val_accuracy: 0.8665\n","Epoch 63/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2558 - accuracy: 0.9870 - val_loss: 0.6834 - val_accuracy: 0.8688\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2554 - accuracy: 0.9881 - val_loss: 0.6914 - val_accuracy: 0.8609\n","Epoch 65/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2570 - accuracy: 0.9864 - val_loss: 0.7217 - val_accuracy: 0.8597\n","Epoch 66/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2534 - accuracy: 0.9881 - val_loss: 0.7012 - val_accuracy: 0.8631\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2547 - accuracy: 0.9864 - val_loss: 0.6993 - val_accuracy: 0.8620\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2499 - accuracy: 0.9898 - val_loss: 0.7005 - val_accuracy: 0.8665\n","Epoch 69/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2636 - accuracy: 0.9827 - val_loss: 0.6876 - val_accuracy: 0.8609\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2639 - accuracy: 0.9842 - val_loss: 0.6993 - val_accuracy: 0.8676\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2516 - accuracy: 0.9884 - val_loss: 0.6858 - val_accuracy: 0.8688\n","Epoch 72/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2512 - accuracy: 0.9867 - val_loss: 0.6974 - val_accuracy: 0.8597\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2468 - accuracy: 0.9904 - val_loss: 0.6945 - val_accuracy: 0.8620\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2647 - accuracy: 0.9813 - val_loss: 0.7487 - val_accuracy: 0.8541\n","Epoch 75/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2576 - accuracy: 0.9847 - val_loss: 0.7317 - val_accuracy: 0.8609\n","Epoch 76/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2509 - accuracy: 0.9873 - val_loss: 0.7003 - val_accuracy: 0.8609\n","Epoch 77/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2445 - accuracy: 0.9887 - val_loss: 0.6887 - val_accuracy: 0.8631\n","Epoch 78/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2464 - accuracy: 0.9909 - val_loss: 0.6968 - val_accuracy: 0.8643\n","Epoch 79/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2428 - accuracy: 0.9915 - val_loss: 0.6975 - val_accuracy: 0.8654\n","Epoch 80/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2483 - accuracy: 0.9887 - val_loss: 0.7314 - val_accuracy: 0.8575\n","Epoch 81/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2452 - accuracy: 0.9890 - val_loss: 0.7087 - val_accuracy: 0.8631\n","Epoch 82/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2426 - accuracy: 0.9907 - val_loss: 0.6929 - val_accuracy: 0.8620\n","Epoch 83/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2420 - accuracy: 0.9912 - val_loss: 0.7105 - val_accuracy: 0.8609\n","Epoch 84/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2417 - accuracy: 0.9924 - val_loss: 0.7283 - val_accuracy: 0.8609\n","Epoch 85/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2443 - accuracy: 0.9901 - val_loss: 0.7073 - val_accuracy: 0.8631\n","Epoch 86/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2439 - accuracy: 0.9890 - val_loss: 0.7043 - val_accuracy: 0.8609\n","Epoch 87/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2452 - accuracy: 0.9878 - val_loss: 0.7014 - val_accuracy: 0.8688\n","Epoch 88/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2496 - accuracy: 0.9864 - val_loss: 0.7173 - val_accuracy: 0.8631\n","Epoch 89/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2412 - accuracy: 0.9915 - val_loss: 0.7227 - val_accuracy: 0.8643\n","Epoch 90/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2358 - accuracy: 0.9912 - val_loss: 0.7077 - val_accuracy: 0.8643\n","Epoch 91/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2606 - accuracy: 0.9822 - val_loss: 0.7336 - val_accuracy: 0.8631\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2368 - accuracy: 0.9926 - val_loss: 0.7009 - val_accuracy: 0.8620\n","Epoch 93/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2353 - accuracy: 0.9915 - val_loss: 0.7062 - val_accuracy: 0.8676\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2382 - accuracy: 0.9924 - val_loss: 0.7219 - val_accuracy: 0.8631\n","Epoch 95/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2397 - accuracy: 0.9898 - val_loss: 0.7142 - val_accuracy: 0.8620\n","Epoch 96/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2398 - accuracy: 0.9904 - val_loss: 0.7249 - val_accuracy: 0.8665\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2322 - accuracy: 0.9926 - val_loss: 0.7289 - val_accuracy: 0.8529\n","Epoch 98/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2299 - accuracy: 0.9946 - val_loss: 0.7483 - val_accuracy: 0.8586\n","Epoch 99/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2453 - accuracy: 0.9844 - val_loss: 0.7706 - val_accuracy: 0.8575\n","Epoch 100/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2316 - accuracy: 0.9926 - val_loss: 0.7479 - val_accuracy: 0.8586\n","{'loss': [0.39080360531806946, 0.3409114480018616, 0.32580941915512085, 0.31816449761390686, 0.3308705687522888, 0.3197387158870697, 0.3337494134902954, 0.3093288242816925, 0.3201947808265686, 0.3142129182815552, 0.3152883052825928, 0.3139745891094208, 0.31656506657600403, 0.3093014061450958, 0.312614768743515, 0.30388087034225464, 0.3010357618331909, 0.3010129928588867, 0.3002830147743225, 0.3028407692909241, 0.3018427789211273, 0.3002076745033264, 0.2943743169307709, 0.29788175225257874, 0.2993660867214203, 0.2880726754665375, 0.29444900155067444, 0.2981884181499481, 0.29695776104927063, 0.2885194420814514, 0.2805440425872803, 0.2825406789779663, 0.2851549983024597, 0.2844644784927368, 0.28717905282974243, 0.29645970463752747, 0.28561273217201233, 0.27120956778526306, 0.29796507954597473, 0.28951501846313477, 0.27648481726646423, 0.2767373323440552, 0.27131977677345276, 0.26947221159935, 0.2661466896533966, 0.2711539566516876, 0.26848042011260986, 0.26392465829849243, 0.2743867337703705, 0.2765025496482849, 0.2834954559803009, 0.27664420008659363, 0.2634871304035187, 0.2604612708091736, 0.26329803466796875, 0.2573649287223816, 0.2700153589248657, 0.25803422927856445, 0.2590063512325287, 0.25604599714279175, 0.25375303626060486, 0.2547088861465454, 0.2557702958583832, 0.2554079592227936, 0.25702565908432007, 0.25341174006462097, 0.25470152497291565, 0.24992820620536804, 0.26361244916915894, 0.26385101675987244, 0.2515818774700165, 0.25115376710891724, 0.24684514105319977, 0.2647116780281067, 0.25764381885528564, 0.2509200870990753, 0.24447084963321686, 0.24636831879615784, 0.2427566796541214, 0.2482539862394333, 0.24520958960056305, 0.24258288741111755, 0.24196359515190125, 0.24168553948402405, 0.24432049691677094, 0.2438507378101349, 0.24521511793136597, 0.24958956241607666, 0.2411879003047943, 0.2358243465423584, 0.26058346033096313, 0.23680728673934937, 0.23532997071743011, 0.23824146389961243, 0.2397068738937378, 0.23977024853229523, 0.2321854531764984, 0.22993455827236176, 0.2452727109193802, 0.2316143661737442], 'accuracy': [0.9439728260040283, 0.9620826244354248, 0.965478241443634, 0.967458963394165, 0.9646292924880981, 0.9680249094963074, 0.9603848457336426, 0.9708545804023743, 0.9668930172920227, 0.9697226881980896, 0.9668930172920227, 0.9697226881980896, 0.9666100740432739, 0.9722693562507629, 0.9702886343002319, 0.9708545804023743, 0.9725523591041565, 0.9753820300102234, 0.9734012484550476, 0.9728353023529053, 0.975947916507721, 0.9731183052062988, 0.975947916507721, 0.974816083908081, 0.9745330810546875, 0.9782116413116455, 0.9739671945571899, 0.9719864130020142, 0.9719864130020142, 0.9767968058586121, 0.9841539263725281, 0.9799094796180725, 0.977645754814148, 0.979626476764679, 0.9767968058586121, 0.9734012484550476, 0.979626476764679, 0.9816072583198547, 0.9714204668998718, 0.974816083908081, 0.9818902015686035, 0.9816072583198547, 0.9850028157234192, 0.9838709831237793, 0.9858517050743103, 0.9835879802703857, 0.9824561476707458, 0.9861347079277039, 0.9807583689689636, 0.9784946441650391, 0.9779286980628967, 0.9818902015686035, 0.9864176511764526, 0.986983597278595, 0.9841539263725281, 0.9881154298782349, 0.9830220937728882, 0.9883984327316284, 0.9861347079277039, 0.9881154298782349, 0.9909451007843018, 0.9883984327316284, 0.986983597278595, 0.9881154298782349, 0.9864176511764526, 0.9881154298782349, 0.9864176511764526, 0.9898132681846619, 0.9827390909194946, 0.9841539263725281, 0.9883984327316284, 0.9867005944252014, 0.9903791546821594, 0.9813242554664612, 0.9847198724746704, 0.9872665405273438, 0.9886813759803772, 0.9909451007843018, 0.9915110468864441, 0.9886813759803772, 0.988964319229126, 0.990662157535553, 0.9912280440330505, 0.9923599362373352, 0.9900962114334106, 0.988964319229126, 0.9878324866294861, 0.9864176511764526, 0.9915110468864441, 0.9912280440330505, 0.9821732044219971, 0.992642879486084, 0.9915110468864441, 0.9923599362373352, 0.9898132681846619, 0.9903791546821594, 0.992642879486084, 0.9946236610412598, 0.9844368696212769, 0.992642879486084], 'val_loss': [0.8900185823440552, 0.8859699368476868, 0.8799795508384705, 0.8718876242637634, 0.8632427453994751, 0.8549678325653076, 0.8412728905677795, 0.8280958533287048, 0.8080788254737854, 0.7901895642280579, 0.7711005806922913, 0.742490828037262, 0.7178314924240112, 0.6791365742683411, 0.6454758644104004, 0.611779510974884, 0.580382764339447, 0.5717769861221313, 0.5409489870071411, 0.5514481067657471, 0.5239934325218201, 0.5274094343185425, 0.5416935086250305, 0.5322650074958801, 0.5388319492340088, 0.5623810887336731, 0.5830447673797607, 0.5779300332069397, 0.5860812664031982, 0.640920102596283, 0.6174960136413574, 0.6555360555648804, 0.6273732781410217, 0.619415283203125, 0.6780526638031006, 0.6908182501792908, 0.6336510181427002, 0.6475787162780762, 0.6813873648643494, 0.6263032555580139, 0.6078073978424072, 0.6254764795303345, 0.6403626203536987, 0.6225113272666931, 0.6466465592384338, 0.7185747027397156, 0.6450489163398743, 0.682021975517273, 0.6429675817489624, 0.6396302580833435, 0.635303258895874, 0.6516546607017517, 0.6630808115005493, 0.6620931029319763, 0.66133713722229, 0.7232568860054016, 0.6686894297599792, 0.6845857501029968, 0.6532265543937683, 0.6779206991195679, 0.7031878232955933, 0.6968705058097839, 0.6834292411804199, 0.6913823485374451, 0.7216823101043701, 0.7012110352516174, 0.6992911696434021, 0.700452983379364, 0.6875775456428528, 0.6992781162261963, 0.6857680082321167, 0.6973773837089539, 0.6945469379425049, 0.7487413883209229, 0.7317273020744324, 0.7002845406532288, 0.6886538863182068, 0.696782112121582, 0.6975154280662537, 0.7313539385795593, 0.7086591720581055, 0.6928670406341553, 0.7105395793914795, 0.7282575964927673, 0.7072950005531311, 0.7043150663375854, 0.7013500332832336, 0.7173336148262024, 0.7226854562759399, 0.7076833248138428, 0.7335648536682129, 0.700931966304779, 0.7061598896980286, 0.7218897342681885, 0.7141955494880676, 0.7248516082763672, 0.7289419174194336, 0.7482931017875671, 0.7706467509269714, 0.7479037642478943], 'val_accuracy': [0.8212669491767883, 0.837104082107544, 0.8382353186607361, 0.8325791954994202, 0.8382353186607361, 0.831447958946228, 0.8246606588363647, 0.8280543088912964, 0.8303167223930359, 0.8337104320526123, 0.8122171759605408, 0.8257918357849121, 0.8223981857299805, 0.8540723919868469, 0.8438913822174072, 0.8563348650932312, 0.860859751701355, 0.8325791954994202, 0.8540723919868469, 0.8518099784851074, 0.8653846383094788, 0.8574660420417786, 0.8631221652030945, 0.8710407018661499, 0.872171938419342, 0.8699095249176025, 0.8597285151481628, 0.8665158152580261, 0.8676470518112183, 0.8653846383094788, 0.8665158152580261, 0.8631221652030945, 0.8665158152580261, 0.8699095249176025, 0.8642534017562866, 0.860859751701355, 0.8676470518112183, 0.8676470518112183, 0.8619909286499023, 0.872171938419342, 0.8710407018661499, 0.8676470518112183, 0.8710407018661499, 0.8733031749725342, 0.8642534017562866, 0.8631221652030945, 0.8710407018661499, 0.8631221652030945, 0.8710407018661499, 0.8687782883644104, 0.8687782883644104, 0.8597285151481628, 0.860859751701355, 0.8642534017562866, 0.8631221652030945, 0.860859751701355, 0.8631221652030945, 0.8653846383094788, 0.872171938419342, 0.8642534017562866, 0.8619909286499023, 0.8665158152580261, 0.8687782883644104, 0.860859751701355, 0.8597285151481628, 0.8631221652030945, 0.8619909286499023, 0.8665158152580261, 0.860859751701355, 0.8676470518112183, 0.8687782883644104, 0.8597285151481628, 0.8619909286499023, 0.8540723919868469, 0.860859751701355, 0.860859751701355, 0.8631221652030945, 0.8642534017562866, 0.8653846383094788, 0.8574660420417786, 0.8631221652030945, 0.8619909286499023, 0.860859751701355, 0.860859751701355, 0.8631221652030945, 0.860859751701355, 0.8687782883644104, 0.8631221652030945, 0.8642534017562866, 0.8642534017562866, 0.8631221652030945, 0.8619909286499023, 0.8676470518112183, 0.8631221652030945, 0.8619909286499023, 0.8665158152580261, 0.8529411554336548, 0.8585972785949707, 0.8574660420417786, 0.8585972785949707]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.3517 - accuracy: 0.9547"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 9s 62ms/step - loss: 0.3542 - accuracy: 0.9537 - val_loss: 0.8857 - val_accuracy: 0.8523\n","Epoch 2/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3321 - accuracy: 0.9615 - val_loss: 0.8805 - val_accuracy: 0.8554\n","Epoch 3/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3403 - accuracy: 0.9618 - val_loss: 0.8727 - val_accuracy: 0.8616\n","Epoch 4/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3342 - accuracy: 0.9612 - val_loss: 0.8649 - val_accuracy: 0.8223\n","Epoch 5/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3219 - accuracy: 0.9667 - val_loss: 0.8541 - val_accuracy: 0.8502\n","Epoch 6/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3226 - accuracy: 0.9656 - val_loss: 0.8399 - val_accuracy: 0.8595\n","Epoch 7/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3205 - accuracy: 0.9693 - val_loss: 0.8251 - val_accuracy: 0.8471\n","Epoch 8/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3160 - accuracy: 0.9708 - val_loss: 0.8080 - val_accuracy: 0.8430\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3144 - accuracy: 0.9703 - val_loss: 0.7812 - val_accuracy: 0.8502\n","Epoch 10/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3117 - accuracy: 0.9708 - val_loss: 0.7589 - val_accuracy: 0.8368\n","Epoch 11/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3004 - accuracy: 0.9760 - val_loss: 0.7202 - val_accuracy: 0.8605\n","Epoch 12/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3138 - accuracy: 0.9690 - val_loss: 0.6921 - val_accuracy: 0.8347\n","Epoch 13/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3076 - accuracy: 0.9718 - val_loss: 0.6473 - val_accuracy: 0.8605\n","Epoch 14/100\n","31/31 [==============================] - 1s 36ms/step - loss: 0.3061 - accuracy: 0.9708 - val_loss: 0.6143 - val_accuracy: 0.8626\n","Epoch 15/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3058 - accuracy: 0.9726 - val_loss: 0.5938 - val_accuracy: 0.8399\n","Epoch 16/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.3148 - accuracy: 0.9690 - val_loss: 0.5504 - val_accuracy: 0.8647\n","Epoch 17/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3113 - accuracy: 0.9674 - val_loss: 0.5379 - val_accuracy: 0.8636\n","Epoch 18/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3035 - accuracy: 0.9724 - val_loss: 0.5347 - val_accuracy: 0.8585\n","Epoch 19/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.3013 - accuracy: 0.9713 - val_loss: 0.5238 - val_accuracy: 0.8709\n","Epoch 20/100\n","31/31 [==============================] - 1s 39ms/step - loss: 0.3034 - accuracy: 0.9729 - val_loss: 0.5207 - val_accuracy: 0.8771\n","Epoch 21/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.2951 - accuracy: 0.9752 - val_loss: 0.5334 - val_accuracy: 0.8781\n","Epoch 22/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2867 - accuracy: 0.9814 - val_loss: 0.5307 - val_accuracy: 0.8781\n","Epoch 23/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.2844 - accuracy: 0.9829 - val_loss: 0.5429 - val_accuracy: 0.8822\n","Epoch 24/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3025 - accuracy: 0.9726 - val_loss: 0.5565 - val_accuracy: 0.8812\n","Epoch 25/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3014 - accuracy: 0.9713 - val_loss: 0.5704 - val_accuracy: 0.8802\n","Epoch 26/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3093 - accuracy: 0.9672 - val_loss: 0.5972 - val_accuracy: 0.8760\n","Epoch 27/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3053 - accuracy: 0.9674 - val_loss: 0.5594 - val_accuracy: 0.8843\n","Epoch 28/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3032 - accuracy: 0.9700 - val_loss: 0.6460 - val_accuracy: 0.8667\n","Epoch 29/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3021 - accuracy: 0.9721 - val_loss: 0.5729 - val_accuracy: 0.8833\n","Epoch 30/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.2905 - accuracy: 0.9773 - val_loss: 0.5971 - val_accuracy: 0.8833\n","Epoch 31/100\n","31/31 [==============================] - 1s 36ms/step - loss: 0.2875 - accuracy: 0.9778 - val_loss: 0.5908 - val_accuracy: 0.8884\n","Epoch 32/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.2829 - accuracy: 0.9796 - val_loss: 0.5933 - val_accuracy: 0.8864\n","Epoch 33/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.2866 - accuracy: 0.9780 - val_loss: 0.5908 - val_accuracy: 0.8843\n","Epoch 34/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.2765 - accuracy: 0.9806 - val_loss: 0.5912 - val_accuracy: 0.8905\n","Epoch 35/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2716 - accuracy: 0.9848 - val_loss: 0.5932 - val_accuracy: 0.8884\n","Epoch 36/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2749 - accuracy: 0.9835 - val_loss: 0.6062 - val_accuracy: 0.8822\n","Epoch 37/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2801 - accuracy: 0.9814 - val_loss: 0.6014 - val_accuracy: 0.8853\n","Epoch 38/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2764 - accuracy: 0.9829 - val_loss: 0.6170 - val_accuracy: 0.8802\n","Epoch 39/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2741 - accuracy: 0.9824 - val_loss: 0.6122 - val_accuracy: 0.8874\n","Epoch 40/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2781 - accuracy: 0.9806 - val_loss: 0.6038 - val_accuracy: 0.8822\n","Epoch 41/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2682 - accuracy: 0.9837 - val_loss: 0.6397 - val_accuracy: 0.8812\n","Epoch 42/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2753 - accuracy: 0.9819 - val_loss: 0.6180 - val_accuracy: 0.8843\n","Epoch 43/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2804 - accuracy: 0.9798 - val_loss: 0.6226 - val_accuracy: 0.8853\n","Epoch 44/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2741 - accuracy: 0.9819 - val_loss: 0.6251 - val_accuracy: 0.8812\n","Epoch 45/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2769 - accuracy: 0.9796 - val_loss: 0.6217 - val_accuracy: 0.8833\n","Epoch 46/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2999 - accuracy: 0.9669 - val_loss: 0.6130 - val_accuracy: 0.8853\n","Epoch 47/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2708 - accuracy: 0.9835 - val_loss: 0.6087 - val_accuracy: 0.8822\n","Epoch 48/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2596 - accuracy: 0.9876 - val_loss: 0.6128 - val_accuracy: 0.8812\n","Epoch 49/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2660 - accuracy: 0.9842 - val_loss: 0.6350 - val_accuracy: 0.8791\n","Epoch 50/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2634 - accuracy: 0.9848 - val_loss: 0.6188 - val_accuracy: 0.8833\n","Epoch 51/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.2596 - accuracy: 0.9871 - val_loss: 0.6487 - val_accuracy: 0.8822\n","Epoch 52/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2667 - accuracy: 0.9814 - val_loss: 0.6470 - val_accuracy: 0.8812\n","Epoch 53/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.2754 - accuracy: 0.9770 - val_loss: 0.6335 - val_accuracy: 0.8822\n","Epoch 54/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2727 - accuracy: 0.9791 - val_loss: 0.6646 - val_accuracy: 0.8719\n","Epoch 55/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2729 - accuracy: 0.9804 - val_loss: 0.6298 - val_accuracy: 0.8822\n","Epoch 56/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2643 - accuracy: 0.9837 - val_loss: 0.6261 - val_accuracy: 0.8874\n","Epoch 57/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2588 - accuracy: 0.9850 - val_loss: 0.6312 - val_accuracy: 0.8833\n","Epoch 58/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2617 - accuracy: 0.9848 - val_loss: 0.6367 - val_accuracy: 0.8833\n","Epoch 59/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2620 - accuracy: 0.9848 - val_loss: 0.6376 - val_accuracy: 0.8791\n","Epoch 60/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2551 - accuracy: 0.9876 - val_loss: 0.6411 - val_accuracy: 0.8864\n","Epoch 61/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2565 - accuracy: 0.9863 - val_loss: 0.6466 - val_accuracy: 0.8802\n","Epoch 62/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2659 - accuracy: 0.9783 - val_loss: 0.6688 - val_accuracy: 0.8729\n","Epoch 63/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2577 - accuracy: 0.9840 - val_loss: 0.6681 - val_accuracy: 0.8740\n","Epoch 64/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2662 - accuracy: 0.9806 - val_loss: 0.6384 - val_accuracy: 0.8740\n","Epoch 65/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2582 - accuracy: 0.9837 - val_loss: 0.6473 - val_accuracy: 0.8864\n","Epoch 66/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2618 - accuracy: 0.9804 - val_loss: 0.6567 - val_accuracy: 0.8802\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2523 - accuracy: 0.9881 - val_loss: 0.6489 - val_accuracy: 0.8812\n","Epoch 68/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2568 - accuracy: 0.9855 - val_loss: 0.6484 - val_accuracy: 0.8802\n","Epoch 69/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2536 - accuracy: 0.9845 - val_loss: 0.6593 - val_accuracy: 0.8791\n","Epoch 70/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2445 - accuracy: 0.9915 - val_loss: 0.6612 - val_accuracy: 0.8791\n","Epoch 71/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2530 - accuracy: 0.9866 - val_loss: 0.6531 - val_accuracy: 0.8802\n","Epoch 72/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2466 - accuracy: 0.9897 - val_loss: 0.6637 - val_accuracy: 0.8802\n","Epoch 73/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2599 - accuracy: 0.9814 - val_loss: 0.6949 - val_accuracy: 0.8719\n","Epoch 74/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.2526 - accuracy: 0.9868 - val_loss: 0.6418 - val_accuracy: 0.8802\n","Epoch 75/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.2487 - accuracy: 0.9868 - val_loss: 0.6475 - val_accuracy: 0.8760\n","Epoch 76/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2462 - accuracy: 0.9881 - val_loss: 0.6699 - val_accuracy: 0.8822\n","Epoch 77/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2486 - accuracy: 0.9863 - val_loss: 0.6401 - val_accuracy: 0.8812\n","Epoch 78/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2389 - accuracy: 0.9917 - val_loss: 0.6476 - val_accuracy: 0.8740\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2433 - accuracy: 0.9894 - val_loss: 0.6846 - val_accuracy: 0.8791\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2493 - accuracy: 0.9866 - val_loss: 0.6602 - val_accuracy: 0.8802\n","Epoch 81/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2512 - accuracy: 0.9860 - val_loss: 0.6592 - val_accuracy: 0.8781\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2442 - accuracy: 0.9884 - val_loss: 0.6931 - val_accuracy: 0.8791\n","Epoch 83/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2395 - accuracy: 0.9891 - val_loss: 0.6742 - val_accuracy: 0.8750\n","Epoch 84/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2373 - accuracy: 0.9907 - val_loss: 0.6701 - val_accuracy: 0.8740\n","Epoch 85/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2361 - accuracy: 0.9912 - val_loss: 0.6682 - val_accuracy: 0.8812\n","Epoch 86/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2357 - accuracy: 0.9922 - val_loss: 0.6769 - val_accuracy: 0.8781\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2399 - accuracy: 0.9889 - val_loss: 0.7620 - val_accuracy: 0.8636\n","Epoch 88/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2610 - accuracy: 0.9780 - val_loss: 0.6771 - val_accuracy: 0.8771\n","Epoch 89/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2587 - accuracy: 0.9822 - val_loss: 0.6652 - val_accuracy: 0.8822\n","Epoch 90/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2599 - accuracy: 0.9788 - val_loss: 0.6961 - val_accuracy: 0.8802\n","Epoch 91/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2371 - accuracy: 0.9907 - val_loss: 0.6825 - val_accuracy: 0.8802\n","Epoch 92/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2304 - accuracy: 0.9925 - val_loss: 0.6773 - val_accuracy: 0.8864\n","Epoch 93/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2329 - accuracy: 0.9928 - val_loss: 0.6728 - val_accuracy: 0.8771\n","Epoch 94/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2462 - accuracy: 0.9863 - val_loss: 0.6663 - val_accuracy: 0.8760\n","Epoch 95/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2306 - accuracy: 0.9915 - val_loss: 0.6773 - val_accuracy: 0.8698\n","Epoch 96/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2303 - accuracy: 0.9920 - val_loss: 0.6813 - val_accuracy: 0.8771\n","Epoch 97/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2336 - accuracy: 0.9912 - val_loss: 0.6963 - val_accuracy: 0.8812\n","Epoch 98/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.2353 - accuracy: 0.9899 - val_loss: 0.6838 - val_accuracy: 0.8771\n","Epoch 99/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2281 - accuracy: 0.9933 - val_loss: 0.7079 - val_accuracy: 0.8781\n","Epoch 100/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2455 - accuracy: 0.9863 - val_loss: 0.7089 - val_accuracy: 0.8750\n","{'loss': [0.3542223572731018, 0.33207979798316956, 0.3403247892856598, 0.33423659205436707, 0.32187601923942566, 0.3225550651550293, 0.32052409648895264, 0.3160034716129303, 0.3143543601036072, 0.31169453263282776, 0.3003634214401245, 0.31378743052482605, 0.3075738847255707, 0.306065171957016, 0.3057812452316284, 0.3148355782032013, 0.3112695515155792, 0.30346035957336426, 0.3012841045856476, 0.30338624119758606, 0.2951103448867798, 0.2866939306259155, 0.28443852066993713, 0.30250173807144165, 0.3013814687728882, 0.3092544376850128, 0.30528661608695984, 0.3031677007675171, 0.30208620429039, 0.2904599905014038, 0.2874891459941864, 0.28293153643608093, 0.2866000533103943, 0.2764936089515686, 0.27159976959228516, 0.27489662170410156, 0.28007104992866516, 0.27639248967170715, 0.27408891916275024, 0.27813786268234253, 0.2682229280471802, 0.275276243686676, 0.28040480613708496, 0.2740935683250427, 0.2768675684928894, 0.2999311089515686, 0.2707928717136383, 0.2596197724342346, 0.2659527659416199, 0.26344093680381775, 0.2596278488636017, 0.2667069733142853, 0.27544793486595154, 0.272704541683197, 0.2728555500507355, 0.2643096148967743, 0.2587997317314148, 0.2617068290710449, 0.2619881331920624, 0.2550644278526306, 0.2564563751220703, 0.2659049928188324, 0.257711261510849, 0.2662203907966614, 0.25821131467819214, 0.26179754734039307, 0.25227466225624084, 0.2568042278289795, 0.2535909414291382, 0.24448741972446442, 0.2530488669872284, 0.24659040570259094, 0.25988343358039856, 0.25257349014282227, 0.24865378439426422, 0.24615812301635742, 0.24855709075927734, 0.2389136254787445, 0.24326062202453613, 0.2492736279964447, 0.25117987394332886, 0.24416841566562653, 0.2394576221704483, 0.23726020753383636, 0.23611994087696075, 0.23569582402706146, 0.2398654967546463, 0.2609526216983795, 0.2586537301540375, 0.2598651647567749, 0.23713339865207672, 0.23035965859889984, 0.2328745573759079, 0.2461858093738556, 0.2306356430053711, 0.2302708923816681, 0.2336307168006897, 0.23530465364456177, 0.22809544205665588, 0.24547135829925537], 'accuracy': [0.9537467956542969, 0.9614987373352051, 0.9617571234703064, 0.961240291595459, 0.9666666388511658, 0.9656330943107605, 0.9692506194114685, 0.970801055431366, 0.9702842235565186, 0.970801055431366, 0.9759690165519714, 0.9689922332763672, 0.9718345999717712, 0.970801055431366, 0.97260981798172, 0.9689922332763672, 0.9674418568611145, 0.9723514318466187, 0.9713178277015686, 0.9728682041168213, 0.9751937985420227, 0.9813953638076782, 0.9829457402229309, 0.97260981798172, 0.9713178277015686, 0.9671834707260132, 0.9674418568611145, 0.9700258374214172, 0.9720930457115173, 0.9772610068321228, 0.9777777791023254, 0.9795865416526794, 0.9780361652374268, 0.9806201457977295, 0.9847545027732849, 0.9834625124931335, 0.9813953638076782, 0.9829457402229309, 0.9824289679527283, 0.9806201457977295, 0.9837209582328796, 0.9819121360778809, 0.9798449873924255, 0.9819121360778809, 0.9795865416526794, 0.9669250845909119, 0.9834625124931335, 0.987596869468689, 0.9842377305030823, 0.9847545027732849, 0.9870800971984863, 0.9813953638076782, 0.9770025610923767, 0.9790697693824768, 0.9803617596626282, 0.9837209582328796, 0.985012948513031, 0.9847545027732849, 0.9847545027732849, 0.987596869468689, 0.9863049387931824, 0.9782945513725281, 0.983979344367981, 0.9806201457977295, 0.9837209582328796, 0.9803617596626282, 0.9881137013435364, 0.9855297207832336, 0.9844961166381836, 0.9914728403091431, 0.9865633249282837, 0.9896640777587891, 0.9813953638076782, 0.986821711063385, 0.986821711063385, 0.9881137013435364, 0.9863049387931824, 0.9917312860488892, 0.9894056916236877, 0.9865633249282837, 0.9860464930534363, 0.9883720874786377, 0.9891473054885864, 0.9906976819038391, 0.9912144541740417, 0.9922480583190918, 0.9888888597488403, 0.9780361652374268, 0.9821705222129822, 0.9788113832473755, 0.9906976819038391, 0.9925064444541931, 0.9927648305892944, 0.9863049387931824, 0.9914728403091431, 0.9919896721839905, 0.9912144541740417, 0.9899224638938904, 0.9932816624641418, 0.9863049387931824], 'val_loss': [0.8856743574142456, 0.8805273771286011, 0.8726947903633118, 0.8649329543113708, 0.8541452288627625, 0.8399001955986023, 0.825054407119751, 0.808007538318634, 0.7812118530273438, 0.7589209079742432, 0.7202329039573669, 0.6921160221099854, 0.647301435470581, 0.614258885383606, 0.5937548279762268, 0.5503790974617004, 0.5379147529602051, 0.5346637964248657, 0.5237607359886169, 0.520695686340332, 0.5333883762359619, 0.5306717157363892, 0.5429408550262451, 0.5565074682235718, 0.5703830718994141, 0.5972114205360413, 0.559380829334259, 0.6459579467773438, 0.5729091167449951, 0.5970995426177979, 0.5907567739486694, 0.5932663679122925, 0.5908142328262329, 0.5912380218505859, 0.5932173132896423, 0.6061695218086243, 0.6013991832733154, 0.6169891357421875, 0.6121801733970642, 0.6038058996200562, 0.6396559476852417, 0.6179602146148682, 0.6225908994674683, 0.6250503659248352, 0.6217321753501892, 0.613009512424469, 0.6087008118629456, 0.612832248210907, 0.6349862217903137, 0.618790328502655, 0.6486684083938599, 0.647021472454071, 0.633508026599884, 0.6646267771720886, 0.6297779083251953, 0.6260793805122375, 0.631181538105011, 0.6367032527923584, 0.637641429901123, 0.6411452293395996, 0.646594226360321, 0.6688295602798462, 0.6680955290794373, 0.6384297609329224, 0.6472694873809814, 0.6567162275314331, 0.6489198207855225, 0.6483701467514038, 0.6593180298805237, 0.6611727476119995, 0.6530875563621521, 0.66370689868927, 0.6948883533477783, 0.6417756676673889, 0.6474959850311279, 0.6699460744857788, 0.6400507092475891, 0.6476495862007141, 0.6845688223838806, 0.6602156162261963, 0.659156322479248, 0.6931124329566956, 0.6742438077926636, 0.670127272605896, 0.6681787967681885, 0.6769049167633057, 0.7619614005088806, 0.6771143078804016, 0.665194034576416, 0.696133553981781, 0.6824988126754761, 0.6772552728652954, 0.6727680563926697, 0.6663287878036499, 0.6773451566696167, 0.6813191771507263, 0.6962532997131348, 0.6837615370750427, 0.7079466581344604, 0.7088693380355835], 'val_accuracy': [0.8522727489471436, 0.85537189245224, 0.8615702390670776, 0.8223140239715576, 0.8502066135406494, 0.8595041036605835, 0.8471074104309082, 0.8429751992225647, 0.8502066135406494, 0.836776852607727, 0.8605371713638306, 0.8347107172012329, 0.8605371713638306, 0.8626033067703247, 0.8398760557174683, 0.8646694421768188, 0.8636363744735718, 0.8584710955619812, 0.8708677887916565, 0.8770661354064941, 0.8780992031097412, 0.8780992031097412, 0.8822314143180847, 0.8811983466148376, 0.8801652789115906, 0.8760330677032471, 0.8842975497245789, 0.8667355179786682, 0.8832644820213318, 0.8832644820213318, 0.8884297609329224, 0.8863636255264282, 0.8842975497245789, 0.8904958963394165, 0.8884297609329224, 0.8822314143180847, 0.8853305578231812, 0.8801652789115906, 0.8873966932296753, 0.8822314143180847, 0.8811983466148376, 0.8842975497245789, 0.8853305578231812, 0.8811983466148376, 0.8832644820213318, 0.8853305578231812, 0.8822314143180847, 0.8811983466148376, 0.8791322112083435, 0.8832644820213318, 0.8822314143180847, 0.8811983466148376, 0.8822314143180847, 0.8719007968902588, 0.8822314143180847, 0.8873966932296753, 0.8832644820213318, 0.8832644820213318, 0.8791322112083435, 0.8863636255264282, 0.8801652789115906, 0.8729338645935059, 0.8739669322967529, 0.8739669322967529, 0.8863636255264282, 0.8801652789115906, 0.8811983466148376, 0.8801652789115906, 0.8791322112083435, 0.8791322112083435, 0.8801652789115906, 0.8801652789115906, 0.8719007968902588, 0.8801652789115906, 0.8760330677032471, 0.8822314143180847, 0.8811983466148376, 0.8739669322967529, 0.8791322112083435, 0.8801652789115906, 0.8780992031097412, 0.8791322112083435, 0.875, 0.8739669322967529, 0.8811983466148376, 0.8780992031097412, 0.8636363744735718, 0.8770661354064941, 0.8822314143180847, 0.8801652789115906, 0.8801652789115906, 0.8863636255264282, 0.8770661354064941, 0.8760330677032471, 0.8698347210884094, 0.8770661354064941, 0.8811983466148376, 0.8770661354064941, 0.8780992031097412, 0.875]}\n","32/32 [==============================] - 1s 5ms/step\n"]}],"source":["global_model, metrics_df = federated_learning(Theta_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ik5JoVP2NPvY","executionInfo":{"status":"ok","timestamp":1717680504011,"user_tz":-360,"elapsed":18,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"colab":{"base_uri":"https://localhost:8080/","height":519},"outputId":"ceda0148-8ca6-47e8-ccc6-6fab32af2456"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.750      0.759   0.734  0.746        0.734        0.767   \n","1        1     0.785      0.783   0.787  0.785        0.787        0.782   \n","2        2     0.724      0.717   0.739  0.728        0.739        0.709   \n","3        0     0.778      0.782   0.771  0.776        0.771        0.786   \n","4        1     0.823      0.824   0.822  0.823        0.822        0.825   \n","5        2     0.733      0.713   0.779  0.745        0.779        0.687   \n","6        0     0.798      0.826   0.755  0.789        0.755        0.841   \n","7        1     0.854      0.860   0.845  0.852        0.845        0.863   \n","8        2     0.770      0.759   0.791  0.775        0.791        0.749   \n","9        0     0.808      0.815   0.797  0.806        0.797        0.819   \n","10       1     0.854      0.903   0.792  0.844        0.792        0.915   \n","11       2     0.815      0.804   0.833  0.819        0.833        0.797   \n","12       0     0.832      0.845   0.812  0.828        0.812        0.851   \n","13       1     0.874      0.856   0.900  0.877        0.900        0.849   \n","14       2     0.835      0.833   0.839  0.836        0.839        0.831   \n","\n","    Kappa  \n","0   0.501  \n","1   0.569  \n","2   0.448  \n","3   0.556  \n","4   0.647  \n","5   0.466  \n","6   0.596  \n","7   0.708  \n","8   0.540  \n","9   0.616  \n","10  0.708  \n","11  0.631  \n","12  0.663  \n","13  0.749  \n","14  0.671  "],"text/html":["\n","  <div id=\"df-5b741949-93ee-4fe8-add8-ea5f9f0cb3d3\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.750</td>\n","      <td>0.759</td>\n","      <td>0.734</td>\n","      <td>0.746</td>\n","      <td>0.734</td>\n","      <td>0.767</td>\n","      <td>0.501</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.785</td>\n","      <td>0.783</td>\n","      <td>0.787</td>\n","      <td>0.785</td>\n","      <td>0.787</td>\n","      <td>0.782</td>\n","      <td>0.569</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.724</td>\n","      <td>0.717</td>\n","      <td>0.739</td>\n","      <td>0.728</td>\n","      <td>0.739</td>\n","      <td>0.709</td>\n","      <td>0.448</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.778</td>\n","      <td>0.782</td>\n","      <td>0.771</td>\n","      <td>0.776</td>\n","      <td>0.771</td>\n","      <td>0.786</td>\n","      <td>0.556</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.823</td>\n","      <td>0.824</td>\n","      <td>0.822</td>\n","      <td>0.823</td>\n","      <td>0.822</td>\n","      <td>0.825</td>\n","      <td>0.647</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.733</td>\n","      <td>0.713</td>\n","      <td>0.779</td>\n","      <td>0.745</td>\n","      <td>0.779</td>\n","      <td>0.687</td>\n","      <td>0.466</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.798</td>\n","      <td>0.826</td>\n","      <td>0.755</td>\n","      <td>0.789</td>\n","      <td>0.755</td>\n","      <td>0.841</td>\n","      <td>0.596</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.854</td>\n","      <td>0.860</td>\n","      <td>0.845</td>\n","      <td>0.852</td>\n","      <td>0.845</td>\n","      <td>0.863</td>\n","      <td>0.708</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.770</td>\n","      <td>0.759</td>\n","      <td>0.791</td>\n","      <td>0.775</td>\n","      <td>0.791</td>\n","      <td>0.749</td>\n","      <td>0.540</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.808</td>\n","      <td>0.815</td>\n","      <td>0.797</td>\n","      <td>0.806</td>\n","      <td>0.797</td>\n","      <td>0.819</td>\n","      <td>0.616</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.854</td>\n","      <td>0.903</td>\n","      <td>0.792</td>\n","      <td>0.844</td>\n","      <td>0.792</td>\n","      <td>0.915</td>\n","      <td>0.708</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.815</td>\n","      <td>0.804</td>\n","      <td>0.833</td>\n","      <td>0.819</td>\n","      <td>0.833</td>\n","      <td>0.797</td>\n","      <td>0.631</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.832</td>\n","      <td>0.845</td>\n","      <td>0.812</td>\n","      <td>0.828</td>\n","      <td>0.812</td>\n","      <td>0.851</td>\n","      <td>0.663</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.874</td>\n","      <td>0.856</td>\n","      <td>0.900</td>\n","      <td>0.877</td>\n","      <td>0.900</td>\n","      <td>0.849</td>\n","      <td>0.749</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.835</td>\n","      <td>0.833</td>\n","      <td>0.839</td>\n","      <td>0.836</td>\n","      <td>0.839</td>\n","      <td>0.831</td>\n","      <td>0.671</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b741949-93ee-4fe8-add8-ea5f9f0cb3d3')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5b741949-93ee-4fe8-add8-ea5f9f0cb3d3 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5b741949-93ee-4fe8-add8-ea5f9f0cb3d3');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b525e53e-0464-452b-bcde-25c420ebde8e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b525e53e-0464-452b-bcde-25c420ebde8e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b525e53e-0464-452b-bcde-25c420ebde8e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04526146263655207,\n        \"min\": 0.724,\n        \"max\": 0.874,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.808,\n          0.832,\n          0.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.053431487060756684,\n        \"min\": 0.713,\n        \"max\": 0.903,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.903,\n          0.845,\n          0.759\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04389023104236728,\n        \"min\": 0.734,\n        \"max\": 0.9,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.797,\n          0.833,\n          0.734\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.043252525387322195,\n        \"min\": 0.728,\n        \"max\": 0.877,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.806,\n          0.819,\n          0.746\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04389023104236728,\n        \"min\": 0.734,\n        \"max\": 0.9,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.797,\n          0.833,\n          0.734\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06021208548202958,\n        \"min\": 0.687,\n        \"max\": 0.915,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.819,\n          0.797,\n          0.767\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09064120791024671,\n        \"min\": 0.448,\n        \"max\": 0.749,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.616,\n          0.663,\n          0.501\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":11}],"source":["\n","metrics_df.round(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ncf_cMAQF6g4"},"outputs":[],"source":["metrics_df.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/DWT/CNN_LSTM/DWT_CNN_LSTM.csv', index = False)"]},{"cell_type":"markdown","source":["#Draw CNN_LSTM"],"metadata":{"id":"VNy6-RxAKjH8"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re\n","import os\n","\n","# Function to read CSV logs and extract accuracy and validation accuracy\n","def read_logs(log_dir, num_clients, local_epochs):\n","    dataframes = []\n","    for epoch in range(local_epochs):\n","        for client in range(num_clients):\n","            log_file = os.path.join(log_dir, f'training_log_epoch_{epoch}_client_{client}.csv')\n","            if os.path.exists(log_file):\n","                df = pd.read_csv(log_file, sep=';')\n","                df['epoch_number'] = epoch\n","                df['client_number'] = client\n","                dataframes.append(df)\n","            else:\n","                print(f\"Log file not found: {log_file}\")\n","\n","    return pd.concat(dataframes) if dataframes else pd.DataFrame()\n","\n","# Function to plot the training and validation accuracy\n","def plot_accuracy(all_metrics_df, unique_epochs, output_dir):\n","    # Set the Seaborn style\n","    sns.set(style=\"whitegrid\")\n","\n","    # Create subplots for each epoch\n","    fig, axes = plt.subplots(2, len(unique_epochs), figsize=(len(unique_epochs) * 3, 4.5), sharex=True)\n","\n","    # Set the color palette\n","    palette = sns.color_palette(\"Set1\", n_colors=all_metrics_df['client_number'].nunique())\n","\n","    # Store the lines and labels for the legend\n","    lines = []\n","    labels = []\n","\n","    # Iterate through each epoch and plot the training and validation accuracy\n","    for i, epoch in enumerate(unique_epochs):\n","        epoch_df = all_metrics_df[all_metrics_df['epoch_number'] == epoch]\n","        for j, client in enumerate(epoch_df['client_number'].unique()):\n","            client_df = epoch_df[epoch_df['client_number'] == client].dropna(subset=['accuracy', 'val_accuracy'])\n","            if not client_df.empty:\n","                line, = axes[0, i].plot(client_df.index, client_df['accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","                axes[1, i].plot(client_df.index, client_df['val_accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","\n","                if i == 0:\n","                    lines.append(line)\n","                    labels.append(f'Client {client}')\n","\n","        axes[0, i].set_title(f'Epoch {epoch}', fontsize=12, fontweight='bold')\n","        axes[0, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","        axes[1, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","        axes[1, i].set_xlabel('Steps', fontsize=10, fontweight='bold')\n","        axes[0, i].grid(True)\n","        axes[1, i].grid(True)\n","        axes[0, i].tick_params(axis='both', which='major', labelsize=10)\n","        axes[1, i].tick_params(axis='both', which='major', labelsize=10)\n","\n","    # Add a single legend for the entire figure\n","    fig.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 1.0), ncol=len(labels), fontsize=10, frameon=True)\n","\n","    # Add row labels\n","    fig.text(0.04, 0.75, 'Training Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","    fig.text(0.04, 0.25, 'Validation Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","\n","    plt.tight_layout(rect=[0.05, 0, 1, 0.95])\n","    plt.subplots_adjust(hspace=0.2, top=0.88)  # Add some space between the rows and reduce space between the legend and plot\n","\n","    # Save the figure in high DPI PNG and PDF\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    fig.savefig(os.path.join(output_dir, 'accuracy_plot.png'), dpi=300, format='png')\n","    fig.savefig(os.path.join(output_dir, 'accuracy_plot.pdf'), dpi=300, format='pdf')\n","\n","    plt.show()\n","\n","# Directory where CSV logs are saved\n","log_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Total'\n","\n","# Output directory for saving plots\n","output_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Total/plots'\n","\n","# Number of clients and local epochs\n","num_clients = 3\n","local_epochs = 5\n","\n","# Read logs and generate the dataframe\n","all_metrics_df = read_logs(log_dir, num_clients, local_epochs)\n","\n","# Get unique epochs from the dataframe\n","unique_epochs = sorted(all_metrics_df['epoch_number'].unique())\n","\n","# Plot the accuracy\n","plot_accuracy(all_metrics_df, unique_epochs, output_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"e-S2thS6KnXT","executionInfo":{"status":"ok","timestamp":1716752271557,"user_tz":-360,"elapsed":5773,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"3941d26a-915f-4d07-fa63-4b562bbd151a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x450 with 10 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re\n","import os\n","\n","# Function to read CSV logs and extract accuracy and validation accuracy\n","def read_logs(log_dir, num_clients, local_epochs):\n","    dataframes = []\n","    for epoch in range(local_epochs):\n","        for client in range(num_clients):\n","            log_file = os.path.join(log_dir, f'training_log_epoch_{epoch}_client_{client}.csv')\n","            if os.path.exists(log_file):\n","                df = pd.read_csv(log_file, sep=';')\n","                df['epoch_number'] = epoch\n","                df['client_number'] = client\n","                dataframes.append(df)\n","            else:\n","                print(f\"Log file not found: {log_file}\")\n","\n","    return pd.concat(dataframes) if dataframes else pd.DataFrame()\n","\n","# Function to plot the training and validation accuracy for the final epoch\n","def plot_final_epoch_accuracy(all_metrics_df, output_dir):\n","    # Set the Seaborn style\n","    sns.set(style=\"whitegrid\")\n","\n","    # Get the final epoch number\n","    final_epoch = all_metrics_df['epoch_number'].max()\n","\n","    # Filter the data for the final epoch\n","    final_epoch_df = all_metrics_df[all_metrics_df['epoch_number'] == final_epoch]\n","\n","    # Calculate the average training and validation accuracy for the final epoch\n","    avg_train_accuracy = final_epoch_df['accuracy'].mean()\n","    avg_val_accuracy = final_epoch_df['val_accuracy'].mean()\n","\n","    print(f\"Final Epoch: {final_epoch}\")\n","    print(f\"Average Training Accuracy: {avg_train_accuracy:.4f}\")\n","    print(f\"Average Validation Accuracy: {avg_val_accuracy:.4f}\")\n","\n","    # Create subplots for the final epoch\n","    fig, axes = plt.subplots(1, 2, figsize=(12, 4.5), sharex=True)\n","\n","    # Set the color palette\n","    palette = sns.color_palette(\"Set1\", n_colors=final_epoch_df['client_number'].nunique())\n","\n","    # Store the lines and labels for the legend\n","    lines = []\n","    labels = []\n","\n","    # Plot the training and validation accuracy for the final epoch\n","    for client in final_epoch_df['client_number'].unique():\n","        client_df = final_epoch_df[final_epoch_df['client_number'] == client].dropna(subset=['accuracy', 'val_accuracy'])\n","        if not client_df.empty:\n","            line, = axes[0].plot(client_df.index, client_df['accuracy'], label=f'Client {client}', alpha=0.6, color=palette[client], linewidth=2.0)\n","            axes[1].plot(client_df.index, client_df['val_accuracy'], label=f'Client {client}', alpha=0.6, color=palette[client], linewidth=2.0)\n","\n","            if len(lines) < final_epoch_df['client_number'].nunique():\n","                lines.append(line)\n","                labels.append(f'Client {client}')\n","\n","    axes[0].set_title(f'Training Accuracy (Epoch {final_epoch})', fontsize=12, fontweight='bold')\n","    axes[0].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","\n","    axes[1].set_title(f'Validation Accuracy (Epoch {final_epoch})', fontsize=12, fontweight='bold')\n","\n","\n","    for ax in axes:\n","        ax.set_xlabel('Steps', fontsize=10, fontweight='bold')\n","        ax.grid(True)\n","        ax.tick_params(axis='both', which='major', labelsize=10)\n","\n","    # Add a single legend for the entire figure\n","    fig.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncol=len(labels), fontsize=10, frameon=True)\n","\n","    plt.tight_layout(rect=[0.05, 0.05, 1, 0.95])\n","    plt.subplots_adjust(hspace=0.2, top=0.85)  # Add some space between the rows and reduce space between the legend and plot\n","\n","    # Save the figure in high DPI PNG and PDF\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    fig.savefig(os.path.join(output_dir, 'final_epoch_accuracy_plot.png'), dpi=300, format='png')\n","    fig.savefig(os.path.join(output_dir, 'final_epoch_accuracy_plot.pdf'), dpi=300, format='pdf')\n","\n","    plt.show()\n","\n","# Directory where CSV logs are saved\n","log_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Total'\n","\n","# Output directory for saving plots\n","output_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Total/plots'\n","\n","# Number of clients and local epochs\n","num_clients = 3\n","local_epochs = 5\n","\n","# Read logs and generate the dataframe\n","all_metrics_df = read_logs(log_dir, num_clients, local_epochs)\n","\n","# Plot the accuracy for the final epoch\n","plot_final_epoch_accuracy(all_metrics_df, output_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NlC1cJDfRFjG","executionInfo":{"status":"ok","timestamp":1716752281801,"user_tz":-360,"elapsed":2941,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"b6781ded-06c4-4d66-98a9-0057144fec5f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Final Epoch: 4\n","Average Training Accuracy: 0.9972\n","Average Validation Accuracy: 0.9058\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x450 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"QUuWzfMHSNmi"},"source":["# CNN"]},{"cell_type":"code","source":["%%capture\n","!pip install tensorflow_addons"],"metadata":{"id":"rT8yrlvQG1Ox"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8xrx_fxBSWGd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717401725592,"user_tz":-360,"elapsed":5,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"outputId":"4c60a77d-9e29-489d-b571-c2d6e693f7bd"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    # model.add(Dropout(0.5))\n","    # model.add(LSTM(256, return_sequences=True))\n","    # model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Total/CNN/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Total/CNN/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1208459,"status":"ok","timestamp":1717402936579,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"},"user_tz":-360},"id":"H1TaNdIbSfkq","outputId":"b4a1aa89-90f4-44bd-dd8c-3ad436f64cd0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 1.9778 - accuracy: 0.6309"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 16s 49ms/step - loss: 1.9778 - accuracy: 0.6309 - val_loss: 2.0025 - val_accuracy: 0.7134\n","Epoch 2/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.9012 - accuracy: 0.7519 - val_loss: 1.9793 - val_accuracy: 0.7608\n","Epoch 3/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.8428 - accuracy: 0.7600 - val_loss: 1.9543 - val_accuracy: 0.7575\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.7917 - accuracy: 0.7686 - val_loss: 1.9291 - val_accuracy: 0.7683\n","Epoch 5/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.7530 - accuracy: 0.7707 - val_loss: 1.9056 - val_accuracy: 0.7694\n","Epoch 6/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.7197 - accuracy: 0.7804 - val_loss: 1.8804 - val_accuracy: 0.7716\n","Epoch 7/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.6921 - accuracy: 0.7842 - val_loss: 1.8563 - val_accuracy: 0.7759\n","Epoch 8/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.6673 - accuracy: 0.7877 - val_loss: 1.8330 - val_accuracy: 0.7737\n","Epoch 9/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.6425 - accuracy: 0.7880 - val_loss: 1.8083 - val_accuracy: 0.7802\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.6183 - accuracy: 0.7942 - val_loss: 1.7776 - val_accuracy: 0.7780\n","Epoch 11/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.5980 - accuracy: 0.7982 - val_loss: 1.7555 - val_accuracy: 0.7812\n","Epoch 12/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.5782 - accuracy: 0.8031 - val_loss: 1.7193 - val_accuracy: 0.7662\n","Epoch 13/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.5646 - accuracy: 0.8006 - val_loss: 1.6947 - val_accuracy: 0.7866\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5458 - accuracy: 0.7990 - val_loss: 1.6706 - val_accuracy: 0.7834\n","Epoch 15/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.5266 - accuracy: 0.8082 - val_loss: 1.6376 - val_accuracy: 0.7780\n","Epoch 16/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5050 - accuracy: 0.8141 - val_loss: 1.6040 - val_accuracy: 0.7780\n","Epoch 17/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.4908 - accuracy: 0.8128 - val_loss: 1.5778 - val_accuracy: 0.7823\n","Epoch 18/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.4738 - accuracy: 0.8187 - val_loss: 1.5618 - val_accuracy: 0.7737\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4591 - accuracy: 0.8130 - val_loss: 1.5241 - val_accuracy: 0.7791\n","Epoch 20/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.4427 - accuracy: 0.8173 - val_loss: 1.4946 - val_accuracy: 0.7856\n","Epoch 21/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4302 - accuracy: 0.8225 - val_loss: 1.4693 - val_accuracy: 0.7802\n","Epoch 22/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.4130 - accuracy: 0.8262 - val_loss: 1.4603 - val_accuracy: 0.7866\n","Epoch 23/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.4004 - accuracy: 0.8222 - val_loss: 1.4385 - val_accuracy: 0.8028\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3884 - accuracy: 0.8214 - val_loss: 1.4172 - val_accuracy: 0.7888\n","Epoch 25/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.3801 - accuracy: 0.8209 - val_loss: 1.4056 - val_accuracy: 0.7856\n","Epoch 26/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3685 - accuracy: 0.8225 - val_loss: 1.3868 - val_accuracy: 0.7920\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.3452 - accuracy: 0.8281 - val_loss: 1.3793 - val_accuracy: 0.7996\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.3335 - accuracy: 0.8281 - val_loss: 1.3644 - val_accuracy: 0.7909\n","Epoch 29/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3217 - accuracy: 0.8297 - val_loss: 1.3503 - val_accuracy: 0.8006\n","Epoch 30/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.3133 - accuracy: 0.8319 - val_loss: 1.3437 - val_accuracy: 0.8006\n","Epoch 31/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.2969 - accuracy: 0.8357 - val_loss: 1.3261 - val_accuracy: 0.8039\n","Epoch 32/100\n","29/29 [==============================] - 1s 32ms/step - loss: 1.2919 - accuracy: 0.8284 - val_loss: 1.3191 - val_accuracy: 0.8050\n","Epoch 33/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.2811 - accuracy: 0.8287 - val_loss: 1.3121 - val_accuracy: 0.8103\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2688 - accuracy: 0.8341 - val_loss: 1.2940 - val_accuracy: 0.8039\n","Epoch 35/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2521 - accuracy: 0.8419 - val_loss: 1.2982 - val_accuracy: 0.7909\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2451 - accuracy: 0.8386 - val_loss: 1.2753 - val_accuracy: 0.8071\n","Epoch 37/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.2310 - accuracy: 0.8427 - val_loss: 1.2729 - val_accuracy: 0.8157\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2207 - accuracy: 0.8419 - val_loss: 1.2641 - val_accuracy: 0.8050\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2107 - accuracy: 0.8427 - val_loss: 1.2446 - val_accuracy: 0.8114\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1983 - accuracy: 0.8459 - val_loss: 1.2372 - val_accuracy: 0.8136\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1898 - accuracy: 0.8427 - val_loss: 1.2276 - val_accuracy: 0.8050\n","Epoch 42/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1797 - accuracy: 0.8467 - val_loss: 1.2255 - val_accuracy: 0.8147\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1689 - accuracy: 0.8486 - val_loss: 1.2112 - val_accuracy: 0.8082\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1593 - accuracy: 0.8473 - val_loss: 1.2072 - val_accuracy: 0.8125\n","Epoch 45/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1516 - accuracy: 0.8497 - val_loss: 1.1934 - val_accuracy: 0.8093\n","Epoch 46/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1364 - accuracy: 0.8583 - val_loss: 1.1956 - val_accuracy: 0.8147\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1284 - accuracy: 0.8570 - val_loss: 1.1766 - val_accuracy: 0.8093\n","Epoch 48/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.1248 - accuracy: 0.8532 - val_loss: 1.1699 - val_accuracy: 0.8168\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1103 - accuracy: 0.8556 - val_loss: 1.1631 - val_accuracy: 0.8125\n","Epoch 50/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1022 - accuracy: 0.8564 - val_loss: 1.1622 - val_accuracy: 0.8103\n","Epoch 51/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0954 - accuracy: 0.8559 - val_loss: 1.1472 - val_accuracy: 0.8071\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0902 - accuracy: 0.8580 - val_loss: 1.1645 - val_accuracy: 0.8050\n","Epoch 53/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.0774 - accuracy: 0.8596 - val_loss: 1.1298 - val_accuracy: 0.8147\n","Epoch 54/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0662 - accuracy: 0.8618 - val_loss: 1.1366 - val_accuracy: 0.8168\n","Epoch 55/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.0598 - accuracy: 0.8602 - val_loss: 1.1208 - val_accuracy: 0.8157\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0500 - accuracy: 0.8626 - val_loss: 1.1106 - val_accuracy: 0.8136\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0443 - accuracy: 0.8634 - val_loss: 1.1048 - val_accuracy: 0.8136\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0348 - accuracy: 0.8640 - val_loss: 1.0974 - val_accuracy: 0.8114\n","Epoch 59/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.0247 - accuracy: 0.8680 - val_loss: 1.0886 - val_accuracy: 0.8211\n","Epoch 60/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.0175 - accuracy: 0.8685 - val_loss: 1.0828 - val_accuracy: 0.8179\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0091 - accuracy: 0.8669 - val_loss: 1.0786 - val_accuracy: 0.8190\n","Epoch 62/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.0051 - accuracy: 0.8710 - val_loss: 1.0711 - val_accuracy: 0.8200\n","Epoch 63/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9937 - accuracy: 0.8718 - val_loss: 1.0637 - val_accuracy: 0.8200\n","Epoch 64/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.9869 - accuracy: 0.8715 - val_loss: 1.0620 - val_accuracy: 0.8103\n","Epoch 65/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9783 - accuracy: 0.8742 - val_loss: 1.0536 - val_accuracy: 0.8179\n","Epoch 66/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.9773 - accuracy: 0.8658 - val_loss: 1.0653 - val_accuracy: 0.8082\n","Epoch 67/100\n","29/29 [==============================] - 1s 37ms/step - loss: 0.9672 - accuracy: 0.8704 - val_loss: 1.0418 - val_accuracy: 0.8233\n","Epoch 68/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.9548 - accuracy: 0.8801 - val_loss: 1.0362 - val_accuracy: 0.8190\n","Epoch 69/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9485 - accuracy: 0.8742 - val_loss: 1.0371 - val_accuracy: 0.8136\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9427 - accuracy: 0.8790 - val_loss: 1.0260 - val_accuracy: 0.8179\n","Epoch 71/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9365 - accuracy: 0.8793 - val_loss: 1.0221 - val_accuracy: 0.8211\n","Epoch 72/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9324 - accuracy: 0.8807 - val_loss: 1.0199 - val_accuracy: 0.8168\n","Epoch 73/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9228 - accuracy: 0.8804 - val_loss: 1.0194 - val_accuracy: 0.8147\n","Epoch 74/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9178 - accuracy: 0.8809 - val_loss: 1.0161 - val_accuracy: 0.8168\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9080 - accuracy: 0.8839 - val_loss: 1.0031 - val_accuracy: 0.8222\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8998 - accuracy: 0.8858 - val_loss: 1.0062 - val_accuracy: 0.8136\n","Epoch 77/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8941 - accuracy: 0.8869 - val_loss: 1.0019 - val_accuracy: 0.8125\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8974 - accuracy: 0.8796 - val_loss: 0.9951 - val_accuracy: 0.8168\n","Epoch 79/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8902 - accuracy: 0.8809 - val_loss: 0.9830 - val_accuracy: 0.8233\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8789 - accuracy: 0.8863 - val_loss: 0.9888 - val_accuracy: 0.8136\n","Epoch 81/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8705 - accuracy: 0.8874 - val_loss: 0.9755 - val_accuracy: 0.8244\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8793 - accuracy: 0.8850 - val_loss: 0.9960 - val_accuracy: 0.8028\n","Epoch 83/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8633 - accuracy: 0.8871 - val_loss: 0.9650 - val_accuracy: 0.8200\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8618 - accuracy: 0.8879 - val_loss: 0.9675 - val_accuracy: 0.8233\n","Epoch 85/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.8452 - accuracy: 0.8912 - val_loss: 0.9588 - val_accuracy: 0.8254\n","Epoch 86/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8371 - accuracy: 0.8933 - val_loss: 0.9600 - val_accuracy: 0.8211\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8382 - accuracy: 0.8936 - val_loss: 0.9589 - val_accuracy: 0.8125\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8291 - accuracy: 0.8960 - val_loss: 0.9494 - val_accuracy: 0.8222\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8212 - accuracy: 0.8974 - val_loss: 0.9497 - val_accuracy: 0.8211\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8185 - accuracy: 0.8990 - val_loss: 0.9519 - val_accuracy: 0.8190\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8108 - accuracy: 0.9001 - val_loss: 0.9391 - val_accuracy: 0.8200\n","Epoch 92/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8091 - accuracy: 0.8979 - val_loss: 0.9475 - val_accuracy: 0.8190\n","Epoch 93/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8093 - accuracy: 0.8971 - val_loss: 0.9370 - val_accuracy: 0.8190\n","Epoch 94/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7948 - accuracy: 0.9022 - val_loss: 0.9299 - val_accuracy: 0.8233\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7900 - accuracy: 0.9009 - val_loss: 0.9669 - val_accuracy: 0.8006\n","Epoch 96/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7845 - accuracy: 0.9025 - val_loss: 0.9296 - val_accuracy: 0.8179\n","Epoch 97/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7789 - accuracy: 0.9054 - val_loss: 0.9245 - val_accuracy: 0.8233\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7729 - accuracy: 0.9073 - val_loss: 0.9209 - val_accuracy: 0.8211\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7765 - accuracy: 0.9038 - val_loss: 0.9235 - val_accuracy: 0.8103\n","Epoch 100/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7674 - accuracy: 0.9057 - val_loss: 0.9128 - val_accuracy: 0.8265\n","{'loss': [1.9777600765228271, 1.9012339115142822, 1.842799186706543, 1.7916896343231201, 1.7529805898666382, 1.719700813293457, 1.6921041011810303, 1.6673251390457153, 1.6425331830978394, 1.6183445453643799, 1.5979584455490112, 1.5782326459884644, 1.564642071723938, 1.545810341835022, 1.5266443490982056, 1.5049947500228882, 1.4908075332641602, 1.4737730026245117, 1.4590895175933838, 1.4427237510681152, 1.43024480342865, 1.413009762763977, 1.4003729820251465, 1.3883705139160156, 1.3800917863845825, 1.3685494661331177, 1.345171570777893, 1.3334921598434448, 1.3216958045959473, 1.3132834434509277, 1.2968813180923462, 1.2919495105743408, 1.2810900211334229, 1.2688233852386475, 1.2521333694458008, 1.2450790405273438, 1.2309821844100952, 1.2206923961639404, 1.2107404470443726, 1.198328971862793, 1.189826488494873, 1.179667353630066, 1.1689279079437256, 1.1592702865600586, 1.1515710353851318, 1.1364178657531738, 1.1284477710723877, 1.1248458623886108, 1.1103039979934692, 1.1022025346755981, 1.0954402685165405, 1.0902169942855835, 1.0773863792419434, 1.0661592483520508, 1.0597658157348633, 1.0499905347824097, 1.0442782640457153, 1.0347810983657837, 1.024705410003662, 1.0174881219863892, 1.0091060400009155, 1.0050889253616333, 0.9936632513999939, 0.9868887066841125, 0.9783245325088501, 0.9772663712501526, 0.9671977758407593, 0.9548182487487793, 0.9485236406326294, 0.9426824450492859, 0.9364863634109497, 0.9324254393577576, 0.9228247404098511, 0.9178450107574463, 0.9080497026443481, 0.8998215794563293, 0.8941333889961243, 0.8973885774612427, 0.8901541233062744, 0.8788954019546509, 0.8705291748046875, 0.8793155550956726, 0.8633002042770386, 0.8617647290229797, 0.8452485799789429, 0.8370978236198425, 0.8382445573806763, 0.8291245102882385, 0.8211778402328491, 0.8184628486633301, 0.8107898235321045, 0.8090651035308838, 0.8092668652534485, 0.7947858572006226, 0.7900065183639526, 0.7845316529273987, 0.7789092659950256, 0.7729280591011047, 0.7765379548072815, 0.7674046754837036], 'accuracy': [0.6309267282485962, 0.7518857717514038, 0.7599676847457886, 0.7685883641242981, 0.7707435488700867, 0.7804418206214905, 0.7842133641242981, 0.787715494632721, 0.7879849076271057, 0.7941810488700867, 0.798222005367279, 0.803071141242981, 0.8006465435028076, 0.7990301847457886, 0.8081896305084229, 0.814116358757019, 0.8127694129943848, 0.818696141242981, 0.8130387663841248, 0.8173491358757019, 0.8224676847457886, 0.8262392282485962, 0.8221982717514038, 0.8213900923728943, 0.8208512663841248, 0.8224676847457886, 0.828125, 0.828125, 0.829741358757019, 0.8318965435028076, 0.8356680870056152, 0.8283944129943848, 0.8286637663841248, 0.8340517282485962, 0.8418642282485962, 0.8386314511299133, 0.8426724076271057, 0.8418642282485962, 0.8426724076271057, 0.8459051847457886, 0.8426724076271057, 0.8467133641242981, 0.8485991358757019, 0.8472521305084229, 0.8496767282485962, 0.8582974076271057, 0.8569504022598267, 0.853178858757019, 0.8556034564971924, 0.8564116358757019, 0.8558728694915771, 0.858027994632721, 0.8596444129943848, 0.8617995977401733, 0.8601831793785095, 0.8626077771186829, 0.8634159564971924, 0.8639547228813171, 0.8679956793785095, 0.868534505367279, 0.8669180870056152, 0.8709590435028076, 0.8717672228813171, 0.8714978694915771, 0.8741918206214905, 0.865840494632721, 0.8704202771186829, 0.8801185488700867, 0.8741918206214905, 0.8790409564971924, 0.8793103694915771, 0.8806573152542114, 0.8803879022598267, 0.8809267282485962, 0.8838900923728943, 0.8857758641242981, 0.8868534564971924, 0.8795797228813171, 0.8809267282485962, 0.8863146305084229, 0.8873922228813171, 0.8849676847457886, 0.8871228694915771, 0.8879310488700867, 0.8911637663841248, 0.8933189511299133, 0.8935883641242981, 0.8960129022598267, 0.8973599076271057, 0.8989762663841248, 0.900053858757019, 0.8978987336158752, 0.897090494632721, 0.9022090435028076, 0.9008620977401733, 0.9024784564971924, 0.9054418206214905, 0.9073275923728943, 0.9038254022598267, 0.9057112336158752], 'val_loss': [2.002532720565796, 1.9792917966842651, 1.9543228149414062, 1.9291385412216187, 1.90556001663208, 1.880394458770752, 1.8563034534454346, 1.8330316543579102, 1.8082793951034546, 1.777596354484558, 1.7555086612701416, 1.7193349599838257, 1.6946958303451538, 1.6705658435821533, 1.6376023292541504, 1.6040387153625488, 1.5778453350067139, 1.5617550611495972, 1.5241023302078247, 1.4945987462997437, 1.4692996740341187, 1.4602580070495605, 1.4385037422180176, 1.417243480682373, 1.405604600906372, 1.3867592811584473, 1.379298448562622, 1.3643909692764282, 1.350345253944397, 1.3436577320098877, 1.326063871383667, 1.3191399574279785, 1.3121325969696045, 1.2939988374710083, 1.2981750965118408, 1.2753268480300903, 1.2729175090789795, 1.2641130685806274, 1.2445592880249023, 1.2371795177459717, 1.227615237236023, 1.2254517078399658, 1.2111947536468506, 1.2072081565856934, 1.1934044361114502, 1.1956431865692139, 1.1765748262405396, 1.169941782951355, 1.1630604267120361, 1.1621936559677124, 1.1472468376159668, 1.1644930839538574, 1.1298092603683472, 1.136563777923584, 1.1208049058914185, 1.11064612865448, 1.1048126220703125, 1.0974175930023193, 1.0885690450668335, 1.082834243774414, 1.0786045789718628, 1.0711408853530884, 1.0636813640594482, 1.0620131492614746, 1.0536154508590698, 1.065259337425232, 1.0417594909667969, 1.0361939668655396, 1.0370968580245972, 1.026035189628601, 1.0220577716827393, 1.0199209451675415, 1.019448161125183, 1.0161244869232178, 1.0031280517578125, 1.0061869621276855, 1.00188148021698, 0.9951268434524536, 0.9830158352851868, 0.9887518882751465, 0.9755114316940308, 0.9960448741912842, 0.9649757742881775, 0.9675270318984985, 0.9587901830673218, 0.9600037336349487, 0.9588909149169922, 0.9493756294250488, 0.9496697783470154, 0.9518746733665466, 0.9391208291053772, 0.9475228786468506, 0.9370449185371399, 0.9299125075340271, 0.966901957988739, 0.9295913577079773, 0.9245240688323975, 0.9209479093551636, 0.923479437828064, 0.9127722978591919], 'val_accuracy': [0.7133620977401733, 0.7607758641242981, 0.7575430870056152, 0.7683189511299133, 0.7693965435028076, 0.7715517282485962, 0.7758620977401733, 0.7737069129943848, 0.7801724076271057, 0.7780172228813171, 0.78125, 0.7661637663841248, 0.7866379022598267, 0.7834051847457886, 0.7780172228813171, 0.7780172228813171, 0.7823275923728943, 0.7737069129943848, 0.7790948152542114, 0.7855603694915771, 0.7801724076271057, 0.7866379022598267, 0.8028017282485962, 0.7887930870056152, 0.7855603694915771, 0.7920258641242981, 0.7995689511299133, 0.7909482717514038, 0.8006465435028076, 0.8006465435028076, 0.8038793206214905, 0.8049569129943848, 0.8103448152542114, 0.8038793206214905, 0.7909482717514038, 0.8071120977401733, 0.8157327771186829, 0.8049569129943848, 0.8114224076271057, 0.8135775923728943, 0.8049569129943848, 0.8146551847457886, 0.8081896305084229, 0.8125, 0.8092672228813171, 0.8146551847457886, 0.8092672228813171, 0.8168103694915771, 0.8125, 0.8103448152542114, 0.8071120977401733, 0.8049569129943848, 0.8146551847457886, 0.8168103694915771, 0.8157327771186829, 0.8135775923728943, 0.8135775923728943, 0.8114224076271057, 0.8211206793785095, 0.8178879022598267, 0.818965494632721, 0.8200430870056152, 0.8200430870056152, 0.8103448152542114, 0.8178879022598267, 0.8081896305084229, 0.8232758641242981, 0.818965494632721, 0.8135775923728943, 0.8178879022598267, 0.8211206793785095, 0.8168103694915771, 0.8146551847457886, 0.8168103694915771, 0.8221982717514038, 0.8135775923728943, 0.8125, 0.8168103694915771, 0.8232758641242981, 0.8135775923728943, 0.8243534564971924, 0.8028017282485962, 0.8200430870056152, 0.8232758641242981, 0.8254310488700867, 0.8211206793785095, 0.8125, 0.8221982717514038, 0.8211206793785095, 0.818965494632721, 0.8200430870056152, 0.818965494632721, 0.818965494632721, 0.8232758641242981, 0.8006465435028076, 0.8178879022598267, 0.8232758641242981, 0.8211206793785095, 0.8103448152542114, 0.826508641242981]}\n","38/38 [==============================] - 0s 8ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 1.9850 - accuracy: 0.6214"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 5s 63ms/step - loss: 1.9850 - accuracy: 0.6214 - val_loss: 2.0041 - val_accuracy: 0.6787\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.9203 - accuracy: 0.7326 - val_loss: 1.9823 - val_accuracy: 0.7410\n","Epoch 3/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.8700 - accuracy: 0.7419 - val_loss: 1.9600 - val_accuracy: 0.7172\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.8259 - accuracy: 0.7439 - val_loss: 1.9384 - val_accuracy: 0.7557\n","Epoch 5/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.7862 - accuracy: 0.7518 - val_loss: 1.9165 - val_accuracy: 0.7545\n","Epoch 6/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.7487 - accuracy: 0.7595 - val_loss: 1.8934 - val_accuracy: 0.7602\n","Epoch 7/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.7176 - accuracy: 0.7649 - val_loss: 1.8721 - val_accuracy: 0.7726\n","Epoch 8/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.6892 - accuracy: 0.7705 - val_loss: 1.8467 - val_accuracy: 0.7738\n","Epoch 9/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6664 - accuracy: 0.7742 - val_loss: 1.8222 - val_accuracy: 0.7658\n","Epoch 10/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.6406 - accuracy: 0.7847 - val_loss: 1.7931 - val_accuracy: 0.7704\n","Epoch 11/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.6188 - accuracy: 0.7906 - val_loss: 1.7753 - val_accuracy: 0.7749\n","Epoch 12/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.5972 - accuracy: 0.7932 - val_loss: 1.7439 - val_accuracy: 0.7873\n","Epoch 13/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.5794 - accuracy: 0.7974 - val_loss: 1.7243 - val_accuracy: 0.7794\n","Epoch 14/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.5609 - accuracy: 0.7997 - val_loss: 1.7069 - val_accuracy: 0.7681\n","Epoch 15/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.5495 - accuracy: 0.7985 - val_loss: 1.6777 - val_accuracy: 0.7805\n","Epoch 16/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.5319 - accuracy: 0.7997 - val_loss: 1.6397 - val_accuracy: 0.7817\n","Epoch 17/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.5129 - accuracy: 0.8008 - val_loss: 1.6189 - val_accuracy: 0.7738\n","Epoch 18/100\n","28/28 [==============================] - 1s 34ms/step - loss: 1.4998 - accuracy: 0.8042 - val_loss: 1.5977 - val_accuracy: 0.7839\n","Epoch 19/100\n","28/28 [==============================] - 1s 30ms/step - loss: 1.4858 - accuracy: 0.7999 - val_loss: 1.5677 - val_accuracy: 0.7771\n","Epoch 20/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4711 - accuracy: 0.8045 - val_loss: 1.5396 - val_accuracy: 0.7851\n","Epoch 21/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4539 - accuracy: 0.8081 - val_loss: 1.5267 - val_accuracy: 0.7794\n","Epoch 22/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4444 - accuracy: 0.8050 - val_loss: 1.5074 - val_accuracy: 0.7794\n","Epoch 23/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4292 - accuracy: 0.8132 - val_loss: 1.4869 - val_accuracy: 0.7862\n","Epoch 24/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.4133 - accuracy: 0.8110 - val_loss: 1.4608 - val_accuracy: 0.7885\n","Epoch 25/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4020 - accuracy: 0.8135 - val_loss: 1.4550 - val_accuracy: 0.7805\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3910 - accuracy: 0.8183 - val_loss: 1.4559 - val_accuracy: 0.7749\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3829 - accuracy: 0.8062 - val_loss: 1.4314 - val_accuracy: 0.7817\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3725 - accuracy: 0.8113 - val_loss: 1.4161 - val_accuracy: 0.7885\n","Epoch 29/100\n","28/28 [==============================] - 1s 37ms/step - loss: 1.3537 - accuracy: 0.8149 - val_loss: 1.3993 - val_accuracy: 0.7907\n","Epoch 30/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3422 - accuracy: 0.8149 - val_loss: 1.3892 - val_accuracy: 0.7805\n","Epoch 31/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.3320 - accuracy: 0.8166 - val_loss: 1.3787 - val_accuracy: 0.7885\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3227 - accuracy: 0.8181 - val_loss: 1.3757 - val_accuracy: 0.7885\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3127 - accuracy: 0.8175 - val_loss: 1.4070 - val_accuracy: 0.7477\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3057 - accuracy: 0.8138 - val_loss: 1.3510 - val_accuracy: 0.7817\n","Epoch 35/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2882 - accuracy: 0.8223 - val_loss: 1.3454 - val_accuracy: 0.7885\n","Epoch 36/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.2787 - accuracy: 0.8226 - val_loss: 1.3339 - val_accuracy: 0.7930\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2686 - accuracy: 0.8226 - val_loss: 1.3250 - val_accuracy: 0.7783\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2546 - accuracy: 0.8257 - val_loss: 1.3091 - val_accuracy: 0.7885\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2470 - accuracy: 0.8240 - val_loss: 1.3004 - val_accuracy: 0.7919\n","Epoch 40/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.2396 - accuracy: 0.8240 - val_loss: 1.2946 - val_accuracy: 0.7941\n","Epoch 41/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2299 - accuracy: 0.8209 - val_loss: 1.2833 - val_accuracy: 0.7930\n","Epoch 42/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2209 - accuracy: 0.8237 - val_loss: 1.2745 - val_accuracy: 0.7941\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2100 - accuracy: 0.8277 - val_loss: 1.2669 - val_accuracy: 0.7885\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1980 - accuracy: 0.8285 - val_loss: 1.2712 - val_accuracy: 0.7805\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1949 - accuracy: 0.8248 - val_loss: 1.2531 - val_accuracy: 0.7885\n","Epoch 46/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.1781 - accuracy: 0.8342 - val_loss: 1.2423 - val_accuracy: 0.7952\n","Epoch 47/100\n","28/28 [==============================] - 1s 32ms/step - loss: 1.1714 - accuracy: 0.8294 - val_loss: 1.2417 - val_accuracy: 0.7975\n","Epoch 48/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.1591 - accuracy: 0.8367 - val_loss: 1.2285 - val_accuracy: 0.7998\n","Epoch 49/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1512 - accuracy: 0.8359 - val_loss: 1.2343 - val_accuracy: 0.7817\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1434 - accuracy: 0.8359 - val_loss: 1.2138 - val_accuracy: 0.7885\n","Epoch 51/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.1340 - accuracy: 0.8401 - val_loss: 1.2079 - val_accuracy: 0.8054\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1261 - accuracy: 0.8373 - val_loss: 1.1958 - val_accuracy: 0.7952\n","Epoch 53/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1177 - accuracy: 0.8410 - val_loss: 1.1936 - val_accuracy: 0.7919\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1099 - accuracy: 0.8410 - val_loss: 1.1859 - val_accuracy: 0.7919\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1052 - accuracy: 0.8413 - val_loss: 1.1797 - val_accuracy: 0.7919\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0940 - accuracy: 0.8430 - val_loss: 1.1765 - val_accuracy: 0.8032\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0900 - accuracy: 0.8404 - val_loss: 1.1629 - val_accuracy: 0.8009\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0769 - accuracy: 0.8455 - val_loss: 1.1581 - val_accuracy: 0.7896\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0676 - accuracy: 0.8447 - val_loss: 1.1533 - val_accuracy: 0.8009\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0617 - accuracy: 0.8503 - val_loss: 1.1437 - val_accuracy: 0.7998\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0527 - accuracy: 0.8466 - val_loss: 1.1372 - val_accuracy: 0.7986\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0456 - accuracy: 0.8512 - val_loss: 1.1316 - val_accuracy: 0.7896\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0371 - accuracy: 0.8497 - val_loss: 1.1272 - val_accuracy: 0.7885\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0296 - accuracy: 0.8497 - val_loss: 1.1203 - val_accuracy: 0.7907\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0237 - accuracy: 0.8483 - val_loss: 1.1156 - val_accuracy: 0.7941\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0221 - accuracy: 0.8466 - val_loss: 1.1160 - val_accuracy: 0.7896\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0142 - accuracy: 0.8529 - val_loss: 1.1096 - val_accuracy: 0.8043\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0059 - accuracy: 0.8531 - val_loss: 1.0984 - val_accuracy: 0.7964\n","Epoch 69/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9927 - accuracy: 0.8596 - val_loss: 1.0995 - val_accuracy: 0.7930\n","Epoch 70/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9891 - accuracy: 0.8560 - val_loss: 1.0928 - val_accuracy: 0.8043\n","Epoch 71/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.9766 - accuracy: 0.8577 - val_loss: 1.0827 - val_accuracy: 0.7952\n","Epoch 72/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.9716 - accuracy: 0.8594 - val_loss: 1.0807 - val_accuracy: 0.8043\n","Epoch 73/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.9655 - accuracy: 0.8650 - val_loss: 1.0924 - val_accuracy: 0.7930\n","Epoch 74/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.9604 - accuracy: 0.8596 - val_loss: 1.0767 - val_accuracy: 0.7986\n","Epoch 75/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.9528 - accuracy: 0.8585 - val_loss: 1.0657 - val_accuracy: 0.7952\n","Epoch 76/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.9480 - accuracy: 0.8596 - val_loss: 1.0607 - val_accuracy: 0.7941\n","Epoch 77/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9356 - accuracy: 0.8698 - val_loss: 1.0562 - val_accuracy: 0.7998\n","Epoch 78/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9316 - accuracy: 0.8673 - val_loss: 1.0657 - val_accuracy: 0.8020\n","Epoch 79/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9317 - accuracy: 0.8577 - val_loss: 1.0500 - val_accuracy: 0.7941\n","Epoch 80/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9201 - accuracy: 0.8701 - val_loss: 1.0480 - val_accuracy: 0.7885\n","Epoch 81/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9118 - accuracy: 0.8698 - val_loss: 1.0480 - val_accuracy: 0.7998\n","Epoch 82/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9089 - accuracy: 0.8690 - val_loss: 1.0374 - val_accuracy: 0.7907\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9007 - accuracy: 0.8721 - val_loss: 1.0336 - val_accuracy: 0.7952\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9036 - accuracy: 0.8707 - val_loss: 1.0329 - val_accuracy: 0.7975\n","Epoch 85/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8897 - accuracy: 0.8746 - val_loss: 1.0351 - val_accuracy: 0.7952\n","Epoch 86/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.8854 - accuracy: 0.8749 - val_loss: 1.0488 - val_accuracy: 0.8009\n","Epoch 87/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8767 - accuracy: 0.8735 - val_loss: 1.0298 - val_accuracy: 0.7986\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8697 - accuracy: 0.8786 - val_loss: 1.0327 - val_accuracy: 0.7885\n","Epoch 89/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8635 - accuracy: 0.8831 - val_loss: 1.0141 - val_accuracy: 0.7952\n","Epoch 90/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8670 - accuracy: 0.8755 - val_loss: 1.0189 - val_accuracy: 0.7907\n","Epoch 91/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8515 - accuracy: 0.8820 - val_loss: 1.0088 - val_accuracy: 0.7964\n","Epoch 92/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8507 - accuracy: 0.8803 - val_loss: 1.0318 - val_accuracy: 0.8032\n","Epoch 93/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8499 - accuracy: 0.8780 - val_loss: 1.0093 - val_accuracy: 0.7907\n","Epoch 94/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.8456 - accuracy: 0.8812 - val_loss: 1.0312 - val_accuracy: 0.7749\n","Epoch 95/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.8485 - accuracy: 0.8744 - val_loss: 1.0001 - val_accuracy: 0.8032\n","Epoch 96/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.8269 - accuracy: 0.8865 - val_loss: 0.9925 - val_accuracy: 0.7998\n","Epoch 97/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.8198 - accuracy: 0.8911 - val_loss: 0.9954 - val_accuracy: 0.7919\n","Epoch 98/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.8167 - accuracy: 0.8896 - val_loss: 0.9975 - val_accuracy: 0.7919\n","Epoch 99/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.8110 - accuracy: 0.8891 - val_loss: 0.9869 - val_accuracy: 0.8032\n","Epoch 100/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8093 - accuracy: 0.8905 - val_loss: 0.9906 - val_accuracy: 0.7919\n","{'loss': [1.985009789466858, 1.9202685356140137, 1.8700116872787476, 1.8259094953536987, 1.7861534357070923, 1.7487043142318726, 1.7176198959350586, 1.6892366409301758, 1.6663868427276611, 1.6405905485153198, 1.6188374757766724, 1.5971565246582031, 1.5794498920440674, 1.5608793497085571, 1.5495048761367798, 1.5318607091903687, 1.5129214525222778, 1.4998387098312378, 1.4858450889587402, 1.4711037874221802, 1.453855037689209, 1.4443674087524414, 1.4292281866073608, 1.4132895469665527, 1.4020297527313232, 1.3909657001495361, 1.3829118013381958, 1.3725343942642212, 1.3536510467529297, 1.3422261476516724, 1.3320075273513794, 1.3227159976959229, 1.3127155303955078, 1.3057301044464111, 1.2881516218185425, 1.278717041015625, 1.2686110734939575, 1.254562497138977, 1.246954083442688, 1.239586353302002, 1.2299174070358276, 1.2208530902862549, 1.2100105285644531, 1.198048710823059, 1.1949082612991333, 1.1780933141708374, 1.1714341640472412, 1.1590867042541504, 1.151213526725769, 1.1434059143066406, 1.1340042352676392, 1.1260679960250854, 1.1177254915237427, 1.10985267162323, 1.1052238941192627, 1.094002604484558, 1.0899678468704224, 1.0769050121307373, 1.067605972290039, 1.061668872833252, 1.0526894330978394, 1.0455607175827026, 1.0370864868164062, 1.0295966863632202, 1.023699402809143, 1.0221295356750488, 1.014224648475647, 1.0059492588043213, 0.9926781058311462, 0.9891086220741272, 0.9766268730163574, 0.9715957045555115, 0.9655196070671082, 0.9603834748268127, 0.9527927041053772, 0.9479935765266418, 0.9355855584144592, 0.9315693378448486, 0.9317148923873901, 0.920146107673645, 0.9118016362190247, 0.9088570475578308, 0.9006524085998535, 0.9036282300949097, 0.8897438645362854, 0.8853945732116699, 0.8767198324203491, 0.8696552515029907, 0.8634702563285828, 0.8670054078102112, 0.8514866232872009, 0.8506890535354614, 0.8499479293823242, 0.8456129431724548, 0.8485329151153564, 0.8269270062446594, 0.8198015093803406, 0.8167107701301575, 0.8110073804855347, 0.8092944025993347], 'accuracy': [0.6213921904563904, 0.7325976490974426, 0.7419354915618896, 0.7439162135124207, 0.751839280128479, 0.7594793438911438, 0.764855682849884, 0.7705150246620178, 0.774193525314331, 0.7846632599830627, 0.7906055450439453, 0.7931522130966187, 0.797396719455719, 0.7996604442596436, 0.7985285520553589, 0.7996604442596436, 0.8007922768592834, 0.8041878938674927, 0.7999433875083923, 0.8044708371162415, 0.8081493973731995, 0.8050367832183838, 0.8132427930831909, 0.8109790682792664, 0.8135257363319397, 0.8183361887931824, 0.8061686754226685, 0.8112620115280151, 0.8149405717849731, 0.8149405717849731, 0.8166383504867554, 0.8180531859397888, 0.8174872398376465, 0.8138087391853333, 0.8222976922988892, 0.8225806355476379, 0.8225806355476379, 0.8256932497024536, 0.8239954710006714, 0.8239954710006714, 0.8208828568458557, 0.8237125277519226, 0.8276740312576294, 0.8285229206085205, 0.8248443603515625, 0.8341822028160095, 0.8293718099594116, 0.8367289304733276, 0.8358800411224365, 0.8358800411224365, 0.8401244878768921, 0.83729487657547, 0.8409733772277832, 0.8409733772277832, 0.8412563800811768, 0.842954158782959, 0.8404074907302856, 0.8455008268356323, 0.8446519374847412, 0.850311279296875, 0.846632719039917, 0.8511601686477661, 0.8497453331947327, 0.8497453331947327, 0.8483304977416992, 0.846632719039917, 0.8528579473495483, 0.8531408905982971, 0.859649121761322, 0.855970561504364, 0.8576683402061462, 0.8593661785125732, 0.8650254607200623, 0.859649121761322, 0.8585172891616821, 0.859649121761322, 0.8698358535766602, 0.8672891855239868, 0.8576683402061462, 0.8701188564300537, 0.8698358535766602, 0.868986964225769, 0.8720995783805847, 0.870684802532196, 0.8746463060379028, 0.8749292492866516, 0.8735144138336182, 0.8786078095436096, 0.8831352591514587, 0.875495195388794, 0.8820033669471741, 0.8803055882453918, 0.8780418634414673, 0.881154477596283, 0.8743633031845093, 0.8865308165550232, 0.8910582661628723, 0.8896434903144836, 0.8890775442123413, 0.8904923796653748], 'val_loss': [2.004051685333252, 1.9823418855667114, 1.9600043296813965, 1.938369631767273, 1.916513204574585, 1.8933812379837036, 1.872145414352417, 1.8467252254486084, 1.8222310543060303, 1.7931445837020874, 1.7752941846847534, 1.7438539266586304, 1.7243467569351196, 1.7069380283355713, 1.6776608228683472, 1.639678716659546, 1.6189467906951904, 1.5977219343185425, 1.5676661729812622, 1.5395880937576294, 1.5266809463500977, 1.507427453994751, 1.4869134426116943, 1.4608079195022583, 1.454979419708252, 1.4559353590011597, 1.431444764137268, 1.4161133766174316, 1.3992698192596436, 1.3891876935958862, 1.3786646127700806, 1.375747561454773, 1.407033920288086, 1.3510386943817139, 1.3453569412231445, 1.3338621854782104, 1.3249653577804565, 1.3090888261795044, 1.3003898859024048, 1.2946316003799438, 1.2833173274993896, 1.274526596069336, 1.266940712928772, 1.2711955308914185, 1.253118634223938, 1.2422844171524048, 1.2417044639587402, 1.2284667491912842, 1.2343119382858276, 1.2138481140136719, 1.2079030275344849, 1.1958423852920532, 1.1936415433883667, 1.185854434967041, 1.1797363758087158, 1.1764566898345947, 1.162853717803955, 1.1580665111541748, 1.1532952785491943, 1.1436716318130493, 1.1372276544570923, 1.1316016912460327, 1.1271942853927612, 1.120265007019043, 1.1155506372451782, 1.1159553527832031, 1.1096298694610596, 1.0984280109405518, 1.0994571447372437, 1.0927923917770386, 1.0827254056930542, 1.0806654691696167, 1.092414140701294, 1.076722264289856, 1.0657453536987305, 1.060739517211914, 1.0561535358428955, 1.065712332725525, 1.0500437021255493, 1.0480029582977295, 1.0479930639266968, 1.0373690128326416, 1.0335711240768433, 1.0329420566558838, 1.0350654125213623, 1.04879891872406, 1.0297831296920776, 1.0327458381652832, 1.014102578163147, 1.0189273357391357, 1.008798360824585, 1.0317747592926025, 1.0092748403549194, 1.0312057733535767, 1.0000659227371216, 0.9924677014350891, 0.9953773617744446, 0.9975234270095825, 0.9868892431259155, 0.990638792514801], 'val_accuracy': [0.6787330508232117, 0.7409502267837524, 0.7171945571899414, 0.7556561231613159, 0.7545248866081238, 0.7601810097694397, 0.7726244330406189, 0.773755669593811, 0.7658371329307556, 0.7703620195388794, 0.7748869061470032, 0.7873303294181824, 0.779411792755127, 0.7680995464324951, 0.7805429697036743, 0.7816742062568665, 0.773755669593811, 0.7839366793632507, 0.7771493196487427, 0.7850678563117981, 0.779411792755127, 0.779411792755127, 0.7861990928649902, 0.7884615659713745, 0.7805429697036743, 0.7748869061470032, 0.7816742062568665, 0.7884615659713745, 0.790723979473114, 0.7805429697036743, 0.7884615659713745, 0.7884615659713745, 0.7477375268936157, 0.7816742062568665, 0.7884615659713745, 0.7929864525794983, 0.7782805562019348, 0.7884615659713745, 0.7918552160263062, 0.7941176295280457, 0.7929864525794983, 0.7941176295280457, 0.7884615659713745, 0.7805429697036743, 0.7884615659713745, 0.7952488660812378, 0.7975113391876221, 0.7997737526893616, 0.7816742062568665, 0.7884615659713745, 0.8054298758506775, 0.7952488660812378, 0.7918552160263062, 0.7918552160263062, 0.7918552160263062, 0.8031674027442932, 0.8009049892425537, 0.7895927429199219, 0.8009049892425537, 0.7997737526893616, 0.7986425161361694, 0.7895927429199219, 0.7884615659713745, 0.790723979473114, 0.7941176295280457, 0.7895927429199219, 0.8042986392974854, 0.7963801026344299, 0.7929864525794983, 0.8042986392974854, 0.7952488660812378, 0.8042986392974854, 0.7929864525794983, 0.7986425161361694, 0.7952488660812378, 0.7941176295280457, 0.7997737526893616, 0.8020362257957458, 0.7941176295280457, 0.7884615659713745, 0.7997737526893616, 0.790723979473114, 0.7952488660812378, 0.7975113391876221, 0.7952488660812378, 0.8009049892425537, 0.7986425161361694, 0.7884615659713745, 0.7952488660812378, 0.790723979473114, 0.7963801026344299, 0.8031674027442932, 0.790723979473114, 0.7748869061470032, 0.8031674027442932, 0.7997737526893616, 0.7918552160263062, 0.7918552160263062, 0.8031674027442932, 0.7918552160263062]}\n","45/45 [==============================] - 0s 7ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 1.9830 - accuracy: 0.6271"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 4s 51ms/step - loss: 1.9830 - accuracy: 0.6271 - val_loss: 2.0021 - val_accuracy: 0.6890\n","Epoch 2/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.9112 - accuracy: 0.7455 - val_loss: 1.9787 - val_accuracy: 0.7562\n","Epoch 3/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.8527 - accuracy: 0.7643 - val_loss: 1.9536 - val_accuracy: 0.7572\n","Epoch 4/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.7982 - accuracy: 0.7680 - val_loss: 1.9300 - val_accuracy: 0.7510\n","Epoch 5/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.7511 - accuracy: 0.7819 - val_loss: 1.9014 - val_accuracy: 0.7645\n","Epoch 6/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.7132 - accuracy: 0.7809 - val_loss: 1.8754 - val_accuracy: 0.7717\n","Epoch 7/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.6757 - accuracy: 0.8008 - val_loss: 1.8462 - val_accuracy: 0.7686\n","Epoch 8/100\n","31/31 [==============================] - 1s 33ms/step - loss: 1.6478 - accuracy: 0.8010 - val_loss: 1.8171 - val_accuracy: 0.7769\n","Epoch 9/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.6240 - accuracy: 0.8023 - val_loss: 1.7964 - val_accuracy: 0.7820\n","Epoch 10/100\n","31/31 [==============================] - 1s 29ms/step - loss: 1.5936 - accuracy: 0.8124 - val_loss: 1.7619 - val_accuracy: 0.7903\n","Epoch 11/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.5727 - accuracy: 0.8158 - val_loss: 1.7372 - val_accuracy: 0.7893\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.5537 - accuracy: 0.8183 - val_loss: 1.7005 - val_accuracy: 0.8037\n","Epoch 13/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.5366 - accuracy: 0.8199 - val_loss: 1.6690 - val_accuracy: 0.7975\n","Epoch 14/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.5172 - accuracy: 0.8230 - val_loss: 1.6404 - val_accuracy: 0.7955\n","Epoch 15/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.5010 - accuracy: 0.8233 - val_loss: 1.6042 - val_accuracy: 0.8058\n","Epoch 16/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4837 - accuracy: 0.8217 - val_loss: 1.5847 - val_accuracy: 0.7944\n","Epoch 17/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4687 - accuracy: 0.8186 - val_loss: 1.5550 - val_accuracy: 0.7965\n","Epoch 18/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.4502 - accuracy: 0.8276 - val_loss: 1.5182 - val_accuracy: 0.8089\n","Epoch 19/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.4360 - accuracy: 0.8271 - val_loss: 1.4921 - val_accuracy: 0.8079\n","Epoch 20/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.4171 - accuracy: 0.8336 - val_loss: 1.4751 - val_accuracy: 0.8017\n","Epoch 21/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4084 - accuracy: 0.8251 - val_loss: 1.4580 - val_accuracy: 0.8027\n","Epoch 22/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3895 - accuracy: 0.8289 - val_loss: 1.4382 - val_accuracy: 0.8089\n","Epoch 23/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.3798 - accuracy: 0.8318 - val_loss: 1.4177 - val_accuracy: 0.8140\n","Epoch 24/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3651 - accuracy: 0.8313 - val_loss: 1.4062 - val_accuracy: 0.8089\n","Epoch 25/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3513 - accuracy: 0.8326 - val_loss: 1.3910 - val_accuracy: 0.8120\n","Epoch 26/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3347 - accuracy: 0.8364 - val_loss: 1.3945 - val_accuracy: 0.8006\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3298 - accuracy: 0.8302 - val_loss: 1.3707 - val_accuracy: 0.8068\n","Epoch 28/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3105 - accuracy: 0.8367 - val_loss: 1.3546 - val_accuracy: 0.8130\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2992 - accuracy: 0.8382 - val_loss: 1.3431 - val_accuracy: 0.8110\n","Epoch 30/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2844 - accuracy: 0.8406 - val_loss: 1.3335 - val_accuracy: 0.8089\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2709 - accuracy: 0.8401 - val_loss: 1.3324 - val_accuracy: 0.7965\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2667 - accuracy: 0.8372 - val_loss: 1.3116 - val_accuracy: 0.8089\n","Epoch 33/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2535 - accuracy: 0.8395 - val_loss: 1.3149 - val_accuracy: 0.7924\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2414 - accuracy: 0.8432 - val_loss: 1.2968 - val_accuracy: 0.8068\n","Epoch 35/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2271 - accuracy: 0.8455 - val_loss: 1.2807 - val_accuracy: 0.8120\n","Epoch 36/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2213 - accuracy: 0.8439 - val_loss: 1.2813 - val_accuracy: 0.8079\n","Epoch 37/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2082 - accuracy: 0.8468 - val_loss: 1.2623 - val_accuracy: 0.8089\n","Epoch 38/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1967 - accuracy: 0.8478 - val_loss: 1.2526 - val_accuracy: 0.8110\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1854 - accuracy: 0.8496 - val_loss: 1.2485 - val_accuracy: 0.8027\n","Epoch 40/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1754 - accuracy: 0.8491 - val_loss: 1.2339 - val_accuracy: 0.8068\n","Epoch 41/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1630 - accuracy: 0.8509 - val_loss: 1.2260 - val_accuracy: 0.8120\n","Epoch 42/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1537 - accuracy: 0.8535 - val_loss: 1.2261 - val_accuracy: 0.8120\n","Epoch 43/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1436 - accuracy: 0.8509 - val_loss: 1.2082 - val_accuracy: 0.8110\n","Epoch 44/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1324 - accuracy: 0.8615 - val_loss: 1.2001 - val_accuracy: 0.8110\n","Epoch 45/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1230 - accuracy: 0.8571 - val_loss: 1.1925 - val_accuracy: 0.8048\n","Epoch 46/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1158 - accuracy: 0.8605 - val_loss: 1.1827 - val_accuracy: 0.8068\n","Epoch 47/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1067 - accuracy: 0.8574 - val_loss: 1.1760 - val_accuracy: 0.8089\n","Epoch 48/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0986 - accuracy: 0.8576 - val_loss: 1.1671 - val_accuracy: 0.8089\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0953 - accuracy: 0.8517 - val_loss: 1.1745 - val_accuracy: 0.8089\n","Epoch 50/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0851 - accuracy: 0.8530 - val_loss: 1.1515 - val_accuracy: 0.8068\n","Epoch 51/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0700 - accuracy: 0.8636 - val_loss: 1.1441 - val_accuracy: 0.8140\n","Epoch 52/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0611 - accuracy: 0.8610 - val_loss: 1.1373 - val_accuracy: 0.8130\n","Epoch 53/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0586 - accuracy: 0.8605 - val_loss: 1.1487 - val_accuracy: 0.8006\n","Epoch 54/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0508 - accuracy: 0.8556 - val_loss: 1.1252 - val_accuracy: 0.8079\n","Epoch 55/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0375 - accuracy: 0.8630 - val_loss: 1.1271 - val_accuracy: 0.8130\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0294 - accuracy: 0.8661 - val_loss: 1.1104 - val_accuracy: 0.8099\n","Epoch 57/100\n","31/31 [==============================] - 2s 52ms/step - loss: 1.0227 - accuracy: 0.8607 - val_loss: 1.1030 - val_accuracy: 0.8151\n","Epoch 58/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0126 - accuracy: 0.8669 - val_loss: 1.1007 - val_accuracy: 0.8110\n","Epoch 59/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.0046 - accuracy: 0.8682 - val_loss: 1.0956 - val_accuracy: 0.8223\n","Epoch 60/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9963 - accuracy: 0.8703 - val_loss: 1.0849 - val_accuracy: 0.8120\n","Epoch 61/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9884 - accuracy: 0.8682 - val_loss: 1.0872 - val_accuracy: 0.8089\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9827 - accuracy: 0.8724 - val_loss: 1.0809 - val_accuracy: 0.8099\n","Epoch 63/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9746 - accuracy: 0.8672 - val_loss: 1.0761 - val_accuracy: 0.8223\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9646 - accuracy: 0.8739 - val_loss: 1.0816 - val_accuracy: 0.8068\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9624 - accuracy: 0.8708 - val_loss: 1.0551 - val_accuracy: 0.8151\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9520 - accuracy: 0.8731 - val_loss: 1.0616 - val_accuracy: 0.8202\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9503 - accuracy: 0.8700 - val_loss: 1.0515 - val_accuracy: 0.8151\n","Epoch 68/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9398 - accuracy: 0.8773 - val_loss: 1.0518 - val_accuracy: 0.8161\n","Epoch 69/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9426 - accuracy: 0.8713 - val_loss: 1.0408 - val_accuracy: 0.8223\n","Epoch 70/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9335 - accuracy: 0.8731 - val_loss: 1.0312 - val_accuracy: 0.8099\n","Epoch 71/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9204 - accuracy: 0.8806 - val_loss: 1.0313 - val_accuracy: 0.8202\n","Epoch 72/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9119 - accuracy: 0.8811 - val_loss: 1.0213 - val_accuracy: 0.8130\n","Epoch 73/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9074 - accuracy: 0.8786 - val_loss: 1.0141 - val_accuracy: 0.8161\n","Epoch 74/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8992 - accuracy: 0.8793 - val_loss: 1.0096 - val_accuracy: 0.8151\n","Epoch 75/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8963 - accuracy: 0.8824 - val_loss: 1.0056 - val_accuracy: 0.8161\n","Epoch 76/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8867 - accuracy: 0.8850 - val_loss: 1.0057 - val_accuracy: 0.8233\n","Epoch 77/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.8882 - accuracy: 0.8780 - val_loss: 1.0064 - val_accuracy: 0.8182\n","Epoch 78/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8764 - accuracy: 0.8829 - val_loss: 0.9943 - val_accuracy: 0.8161\n","Epoch 79/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8693 - accuracy: 0.8860 - val_loss: 0.9908 - val_accuracy: 0.8171\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8640 - accuracy: 0.8866 - val_loss: 0.9851 - val_accuracy: 0.8202\n","Epoch 81/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8577 - accuracy: 0.8876 - val_loss: 0.9810 - val_accuracy: 0.8130\n","Epoch 82/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8539 - accuracy: 0.8850 - val_loss: 0.9802 - val_accuracy: 0.8223\n","Epoch 83/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8505 - accuracy: 0.8876 - val_loss: 0.9759 - val_accuracy: 0.8171\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8460 - accuracy: 0.8904 - val_loss: 0.9707 - val_accuracy: 0.8213\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8338 - accuracy: 0.8922 - val_loss: 0.9701 - val_accuracy: 0.8192\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8276 - accuracy: 0.8941 - val_loss: 0.9695 - val_accuracy: 0.8089\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8268 - accuracy: 0.8953 - val_loss: 0.9598 - val_accuracy: 0.8182\n","Epoch 88/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8246 - accuracy: 0.8912 - val_loss: 0.9802 - val_accuracy: 0.8110\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8169 - accuracy: 0.8938 - val_loss: 0.9590 - val_accuracy: 0.8202\n","Epoch 90/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8079 - accuracy: 0.8995 - val_loss: 0.9540 - val_accuracy: 0.8192\n","Epoch 91/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8056 - accuracy: 0.8938 - val_loss: 0.9539 - val_accuracy: 0.8171\n","Epoch 92/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8096 - accuracy: 0.8912 - val_loss: 0.9482 - val_accuracy: 0.8213\n","Epoch 93/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7944 - accuracy: 0.8987 - val_loss: 0.9444 - val_accuracy: 0.8213\n","Epoch 94/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7900 - accuracy: 0.9000 - val_loss: 0.9597 - val_accuracy: 0.8182\n","Epoch 95/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7891 - accuracy: 0.8972 - val_loss: 0.9348 - val_accuracy: 0.8213\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7800 - accuracy: 0.9000 - val_loss: 0.9534 - val_accuracy: 0.8079\n","Epoch 97/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7872 - accuracy: 0.8977 - val_loss: 0.9339 - val_accuracy: 0.8202\n","Epoch 98/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7685 - accuracy: 0.9041 - val_loss: 0.9347 - val_accuracy: 0.8161\n","Epoch 99/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7675 - accuracy: 0.9026 - val_loss: 0.9500 - val_accuracy: 0.8099\n","Epoch 100/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7675 - accuracy: 0.8987 - val_loss: 0.9254 - val_accuracy: 0.8161\n","{'loss': [1.9829844236373901, 1.911162257194519, 1.8527414798736572, 1.7981669902801514, 1.7511497735977173, 1.7131755352020264, 1.6756558418273926, 1.6477794647216797, 1.6239773035049438, 1.5936415195465088, 1.5726834535598755, 1.5536695718765259, 1.536606788635254, 1.5172425508499146, 1.5009911060333252, 1.4836533069610596, 1.468683123588562, 1.4502238035202026, 1.436002254486084, 1.4170951843261719, 1.4084103107452393, 1.3895435333251953, 1.3798457384109497, 1.3651026487350464, 1.351273775100708, 1.3347177505493164, 1.3297922611236572, 1.3105260133743286, 1.2992240190505981, 1.2844096422195435, 1.2708673477172852, 1.2666712999343872, 1.253504991531372, 1.2413687705993652, 1.2270793914794922, 1.2213068008422852, 1.208200216293335, 1.1966508626937866, 1.1853878498077393, 1.1753671169281006, 1.1629599332809448, 1.1536798477172852, 1.1435978412628174, 1.1324036121368408, 1.1230252981185913, 1.1157948970794678, 1.106682300567627, 1.0985758304595947, 1.095276117324829, 1.0850859880447388, 1.0700223445892334, 1.0611367225646973, 1.0585553646087646, 1.050847053527832, 1.0374983549118042, 1.0293831825256348, 1.022698163986206, 1.0126100778579712, 1.004640817642212, 0.9962654709815979, 0.9884011745452881, 0.9827332496643066, 0.9746119976043701, 0.9646254777908325, 0.9623798727989197, 0.9520155191421509, 0.9502597451210022, 0.9397849440574646, 0.9425545334815979, 0.9334691166877747, 0.920431911945343, 0.9118930697441101, 0.9073792099952698, 0.8992038369178772, 0.8962918519973755, 0.8867281079292297, 0.8882075548171997, 0.8764079809188843, 0.8692587018013, 0.8640022277832031, 0.8576862812042236, 0.8538806438446045, 0.8505187630653381, 0.846045732498169, 0.8338411450386047, 0.8276214599609375, 0.8267712593078613, 0.8246270418167114, 0.8169254064559937, 0.8078669309616089, 0.805607259273529, 0.8095574975013733, 0.7944037914276123, 0.7900199294090271, 0.7890564799308777, 0.7800156474113464, 0.7872160077095032, 0.7685145139694214, 0.7675410509109497, 0.7674781084060669], 'accuracy': [0.6271317601203918, 0.7454780340194702, 0.7643410563468933, 0.7679586410522461, 0.7819121479988098, 0.7808785438537598, 0.8007751703262329, 0.801033616065979, 0.8023256063461304, 0.8124030828475952, 0.8157622814178467, 0.8183462619781494, 0.8198966383934021, 0.8229973912239075, 0.8232558369636536, 0.8217054009437561, 0.8186046481132507, 0.8276485800743103, 0.8271318078041077, 0.8335917592048645, 0.8250645995140076, 0.8289405703544617, 0.8317829370498657, 0.8312661647796631, 0.8325581550598145, 0.8364341259002686, 0.830232560634613, 0.8366925120353699, 0.8382428884506226, 0.840568482875824, 0.8400516510009766, 0.8372092843055725, 0.8395348787307739, 0.8431524634361267, 0.8454780578613281, 0.8439276218414307, 0.8467700481414795, 0.8478035926818848, 0.8496124148368835, 0.8490955829620361, 0.8509044051170349, 0.8534883856773376, 0.8509044051170349, 0.8614987134933472, 0.8571059703826904, 0.8604651093482971, 0.8573643565177917, 0.8576227426528931, 0.8516795635223389, 0.8529715538024902, 0.8635658621788025, 0.8609819412231445, 0.8604651093482971, 0.855555534362793, 0.8630490899085999, 0.8661498427391052, 0.8607234954833984, 0.866925060749054, 0.8682170510292053, 0.8702842593193054, 0.8682170510292053, 0.8723514080047607, 0.8671834468841553, 0.8739017844200134, 0.8708010315895081, 0.8731266260147095, 0.8700258135795593, 0.8772609829902649, 0.8713178038597107, 0.8731266260147095, 0.8806201815605164, 0.881136953830719, 0.8785529732704163, 0.879328191280365, 0.8824289441108704, 0.8850129246711731, 0.8780362010002136, 0.882945716381073, 0.8860465288162231, 0.8865633010864258, 0.8875969052314758, 0.8850129246711731, 0.8875969052314758, 0.8904392719268799, 0.8922480344772339, 0.8940568566322327, 0.895348846912384, 0.8912144899368286, 0.8937984704971313, 0.8994832038879395, 0.8937984704971313, 0.8912144899368286, 0.8987079858779907, 0.8999999761581421, 0.897157609462738, 0.8999999761581421, 0.8976744413375854, 0.9041343927383423, 0.9025839567184448, 0.8987079858779907], 'val_loss': [2.002131700515747, 1.9787391424179077, 1.9536255598068237, 1.9300076961517334, 1.9013999700546265, 1.8753858804702759, 1.8462013006210327, 1.8170920610427856, 1.7964046001434326, 1.7618885040283203, 1.7371878623962402, 1.7005499601364136, 1.6689866781234741, 1.640382170677185, 1.6042428016662598, 1.5846641063690186, 1.5549565553665161, 1.5182167291641235, 1.4920687675476074, 1.4750562906265259, 1.4579983949661255, 1.4381778240203857, 1.4176660776138306, 1.4061899185180664, 1.3909579515457153, 1.3945499658584595, 1.3706825971603394, 1.3546063899993896, 1.3431353569030762, 1.3335070610046387, 1.3324265480041504, 1.3115988969802856, 1.3149083852767944, 1.2967618703842163, 1.2807420492172241, 1.2812508344650269, 1.2623094320297241, 1.2526353597640991, 1.248522400856018, 1.233898401260376, 1.226011037826538, 1.2260688543319702, 1.2081613540649414, 1.2001246213912964, 1.1925088167190552, 1.1826773881912231, 1.176006555557251, 1.167055368423462, 1.1744506359100342, 1.151548981666565, 1.1441138982772827, 1.1372686624526978, 1.148728609085083, 1.1252481937408447, 1.1271028518676758, 1.1103954315185547, 1.1030460596084595, 1.100682020187378, 1.095615267753601, 1.0849332809448242, 1.0872119665145874, 1.0809235572814941, 1.07608962059021, 1.081560492515564, 1.0550788640975952, 1.0616419315338135, 1.0514739751815796, 1.05178964138031, 1.0407718420028687, 1.031225562095642, 1.0312814712524414, 1.0213080644607544, 1.014052391052246, 1.0096410512924194, 1.0055644512176514, 1.0057326555252075, 1.006375789642334, 0.9943276643753052, 0.9907947778701782, 0.9851019382476807, 0.9810412526130676, 0.9801590442657471, 0.9759143590927124, 0.9706825613975525, 0.9701159000396729, 0.9694738984107971, 0.9597955942153931, 0.9801555275917053, 0.9590367674827576, 0.9540297389030457, 0.9538729190826416, 0.948211669921875, 0.9444145560264587, 0.9597041606903076, 0.9348109364509583, 0.9533504843711853, 0.9338924288749695, 0.934674084186554, 0.9500066637992859, 0.9253503084182739], 'val_accuracy': [0.6890496015548706, 0.7561983466148376, 0.7572314143180847, 0.7510330677032471, 0.7644628286361694, 0.7716942429542542, 0.7685950398445129, 0.7768595218658447, 0.7820248007774353, 0.7902892827987671, 0.78925621509552, 0.8037189841270447, 0.797520637512207, 0.7954545617103577, 0.8057851195335388, 0.7944214940071106, 0.7964876294136047, 0.80888432264328, 0.807851254940033, 0.8016529083251953, 0.8026859760284424, 0.80888432264328, 0.8140496015548706, 0.80888432264328, 0.8119834661483765, 0.8006198406219482, 0.8068181872367859, 0.8130165338516235, 0.8109503984451294, 0.80888432264328, 0.7964876294136047, 0.80888432264328, 0.7923553586006165, 0.8068181872367859, 0.8119834661483765, 0.807851254940033, 0.80888432264328, 0.8109503984451294, 0.8026859760284424, 0.8068181872367859, 0.8119834661483765, 0.8119834661483765, 0.8109503984451294, 0.8109503984451294, 0.8047520518302917, 0.8068181872367859, 0.80888432264328, 0.80888432264328, 0.80888432264328, 0.8068181872367859, 0.8140496015548706, 0.8130165338516235, 0.8006198406219482, 0.807851254940033, 0.8130165338516235, 0.8099173307418823, 0.8150826692581177, 0.8109503984451294, 0.8223140239715576, 0.8119834661483765, 0.80888432264328, 0.8099173307418823, 0.8223140239715576, 0.8068181872367859, 0.8150826692581177, 0.8202479481697083, 0.8150826692581177, 0.81611567735672, 0.8223140239715576, 0.8099173307418823, 0.8202479481697083, 0.8130165338516235, 0.81611567735672, 0.8150826692581177, 0.81611567735672, 0.8233470916748047, 0.8181818127632141, 0.81611567735672, 0.817148745059967, 0.8202479481697083, 0.8130165338516235, 0.8223140239715576, 0.817148745059967, 0.8212810158729553, 0.8192148804664612, 0.80888432264328, 0.8181818127632141, 0.8109503984451294, 0.8202479481697083, 0.8192148804664612, 0.817148745059967, 0.8212810158729553, 0.8212810158729553, 0.8181818127632141, 0.8212810158729553, 0.807851254940033, 0.8202479481697083, 0.81611567735672, 0.8099173307418823, 0.81611567735672]}\n","32/32 [==============================] - 1s 10ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.8456 - accuracy: 0.8605"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 5s 34ms/step - loss: 0.8431 - accuracy: 0.8621 - val_loss: 1.1707 - val_accuracy: 0.8330\n","Epoch 2/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8310 - accuracy: 0.8683 - val_loss: 1.1611 - val_accuracy: 0.8287\n","Epoch 3/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8231 - accuracy: 0.8648 - val_loss: 1.1481 - val_accuracy: 0.8222\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8104 - accuracy: 0.8737 - val_loss: 1.1366 - val_accuracy: 0.8351\n","Epoch 5/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8045 - accuracy: 0.8745 - val_loss: 1.1296 - val_accuracy: 0.8319\n","Epoch 6/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.7968 - accuracy: 0.8825 - val_loss: 1.1130 - val_accuracy: 0.8384\n","Epoch 7/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7931 - accuracy: 0.8812 - val_loss: 1.0956 - val_accuracy: 0.8341\n","Epoch 8/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7890 - accuracy: 0.8790 - val_loss: 1.0821 - val_accuracy: 0.8341\n","Epoch 9/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7798 - accuracy: 0.8855 - val_loss: 1.0628 - val_accuracy: 0.8244\n","Epoch 10/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7766 - accuracy: 0.8820 - val_loss: 1.0472 - val_accuracy: 0.8341\n","Epoch 11/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.7693 - accuracy: 0.8869 - val_loss: 1.0254 - val_accuracy: 0.8394\n","Epoch 12/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7655 - accuracy: 0.8871 - val_loss: 1.0121 - val_accuracy: 0.8373\n","Epoch 13/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.7562 - accuracy: 0.8922 - val_loss: 0.9831 - val_accuracy: 0.8405\n","Epoch 14/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7507 - accuracy: 0.8949 - val_loss: 0.9627 - val_accuracy: 0.8319\n","Epoch 15/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7544 - accuracy: 0.8874 - val_loss: 0.9351 - val_accuracy: 0.8362\n","Epoch 16/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7476 - accuracy: 0.8922 - val_loss: 0.9277 - val_accuracy: 0.8330\n","Epoch 17/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.7370 - accuracy: 0.8941 - val_loss: 0.8969 - val_accuracy: 0.8427\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7297 - accuracy: 0.9003 - val_loss: 0.8830 - val_accuracy: 0.8373\n","Epoch 19/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.7325 - accuracy: 0.8974 - val_loss: 0.8612 - val_accuracy: 0.8438\n","Epoch 20/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7368 - accuracy: 0.8860 - val_loss: 0.8747 - val_accuracy: 0.8190\n","Epoch 21/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7324 - accuracy: 0.8869 - val_loss: 0.8352 - val_accuracy: 0.8416\n","Epoch 22/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7175 - accuracy: 0.9006 - val_loss: 0.8250 - val_accuracy: 0.8405\n","Epoch 23/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7110 - accuracy: 0.9025 - val_loss: 0.8171 - val_accuracy: 0.8416\n","Epoch 24/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7073 - accuracy: 0.9011 - val_loss: 0.8228 - val_accuracy: 0.8330\n","Epoch 25/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7036 - accuracy: 0.9025 - val_loss: 0.8150 - val_accuracy: 0.8416\n","Epoch 26/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6980 - accuracy: 0.9089 - val_loss: 0.8011 - val_accuracy: 0.8438\n","Epoch 27/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7009 - accuracy: 0.9076 - val_loss: 0.7929 - val_accuracy: 0.8427\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6959 - accuracy: 0.9049 - val_loss: 0.7902 - val_accuracy: 0.8438\n","Epoch 29/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6858 - accuracy: 0.9114 - val_loss: 0.7913 - val_accuracy: 0.8416\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6858 - accuracy: 0.9076 - val_loss: 0.7915 - val_accuracy: 0.8394\n","Epoch 31/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6847 - accuracy: 0.9046 - val_loss: 0.7918 - val_accuracy: 0.8481\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6825 - accuracy: 0.9098 - val_loss: 0.7904 - val_accuracy: 0.8427\n","Epoch 33/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6698 - accuracy: 0.9157 - val_loss: 0.7854 - val_accuracy: 0.8524\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6810 - accuracy: 0.9062 - val_loss: 0.7802 - val_accuracy: 0.8481\n","Epoch 35/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6660 - accuracy: 0.9178 - val_loss: 0.7814 - val_accuracy: 0.8545\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6640 - accuracy: 0.9176 - val_loss: 0.7787 - val_accuracy: 0.8481\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6615 - accuracy: 0.9178 - val_loss: 0.7788 - val_accuracy: 0.8438\n","Epoch 38/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6553 - accuracy: 0.9203 - val_loss: 0.7751 - val_accuracy: 0.8502\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6498 - accuracy: 0.9221 - val_loss: 0.7769 - val_accuracy: 0.8438\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6462 - accuracy: 0.9235 - val_loss: 0.7718 - val_accuracy: 0.8534\n","Epoch 41/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6588 - accuracy: 0.9138 - val_loss: 0.7902 - val_accuracy: 0.8438\n","Epoch 42/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6518 - accuracy: 0.9154 - val_loss: 0.7776 - val_accuracy: 0.8491\n","Epoch 43/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6461 - accuracy: 0.9205 - val_loss: 0.7748 - val_accuracy: 0.8545\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6364 - accuracy: 0.9259 - val_loss: 0.8233 - val_accuracy: 0.8287\n","Epoch 45/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6374 - accuracy: 0.9238 - val_loss: 0.7742 - val_accuracy: 0.8416\n","Epoch 46/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6263 - accuracy: 0.9313 - val_loss: 0.7805 - val_accuracy: 0.8438\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6267 - accuracy: 0.9286 - val_loss: 0.7739 - val_accuracy: 0.8448\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6200 - accuracy: 0.9335 - val_loss: 0.7725 - val_accuracy: 0.8427\n","Epoch 49/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6203 - accuracy: 0.9294 - val_loss: 0.7738 - val_accuracy: 0.8524\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6216 - accuracy: 0.9289 - val_loss: 0.7687 - val_accuracy: 0.8459\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6093 - accuracy: 0.9375 - val_loss: 0.7683 - val_accuracy: 0.8448\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6092 - accuracy: 0.9351 - val_loss: 0.7754 - val_accuracy: 0.8427\n","Epoch 53/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6102 - accuracy: 0.9340 - val_loss: 0.7776 - val_accuracy: 0.8448\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6082 - accuracy: 0.9340 - val_loss: 0.7714 - val_accuracy: 0.8491\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6017 - accuracy: 0.9351 - val_loss: 0.7859 - val_accuracy: 0.8438\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6155 - accuracy: 0.9219 - val_loss: 0.7683 - val_accuracy: 0.8545\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6117 - accuracy: 0.9275 - val_loss: 0.7975 - val_accuracy: 0.8427\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5954 - accuracy: 0.9386 - val_loss: 0.7614 - val_accuracy: 0.8459\n","Epoch 59/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5871 - accuracy: 0.9415 - val_loss: 0.7660 - val_accuracy: 0.8599\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5847 - accuracy: 0.9467 - val_loss: 0.7704 - val_accuracy: 0.8448\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5808 - accuracy: 0.9437 - val_loss: 0.7625 - val_accuracy: 0.8502\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5797 - accuracy: 0.9459 - val_loss: 0.7594 - val_accuracy: 0.8513\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5748 - accuracy: 0.9467 - val_loss: 0.7741 - val_accuracy: 0.8416\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5785 - accuracy: 0.9434 - val_loss: 0.7627 - val_accuracy: 0.8513\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5705 - accuracy: 0.9434 - val_loss: 0.7742 - val_accuracy: 0.8416\n","Epoch 66/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5677 - accuracy: 0.9469 - val_loss: 0.7624 - val_accuracy: 0.8534\n","Epoch 67/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5629 - accuracy: 0.9518 - val_loss: 0.7653 - val_accuracy: 0.8481\n","Epoch 68/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5850 - accuracy: 0.9316 - val_loss: 0.7837 - val_accuracy: 0.8384\n","Epoch 69/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5609 - accuracy: 0.9496 - val_loss: 0.7608 - val_accuracy: 0.8524\n","Epoch 70/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5577 - accuracy: 0.9515 - val_loss: 0.7689 - val_accuracy: 0.8513\n","Epoch 71/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5555 - accuracy: 0.9480 - val_loss: 0.7619 - val_accuracy: 0.8556\n","Epoch 72/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5519 - accuracy: 0.9496 - val_loss: 0.7640 - val_accuracy: 0.8491\n","Epoch 73/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5487 - accuracy: 0.9520 - val_loss: 0.7674 - val_accuracy: 0.8556\n","Epoch 74/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5450 - accuracy: 0.9534 - val_loss: 0.7680 - val_accuracy: 0.8481\n","Epoch 75/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5523 - accuracy: 0.9499 - val_loss: 0.7860 - val_accuracy: 0.8351\n","Epoch 76/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5434 - accuracy: 0.9566 - val_loss: 0.7732 - val_accuracy: 0.8459\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5365 - accuracy: 0.9537 - val_loss: 0.7767 - val_accuracy: 0.8427\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5340 - accuracy: 0.9558 - val_loss: 0.7652 - val_accuracy: 0.8502\n","Epoch 79/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5307 - accuracy: 0.9612 - val_loss: 0.7638 - val_accuracy: 0.8534\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5342 - accuracy: 0.9529 - val_loss: 0.7646 - val_accuracy: 0.8534\n","Epoch 81/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5356 - accuracy: 0.9558 - val_loss: 0.7656 - val_accuracy: 0.8491\n","Epoch 82/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5263 - accuracy: 0.9626 - val_loss: 0.7686 - val_accuracy: 0.8481\n","Epoch 83/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5231 - accuracy: 0.9612 - val_loss: 0.7693 - val_accuracy: 0.8481\n","Epoch 84/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5209 - accuracy: 0.9617 - val_loss: 0.7943 - val_accuracy: 0.8341\n","Epoch 85/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5348 - accuracy: 0.9464 - val_loss: 0.7762 - val_accuracy: 0.8405\n","Epoch 86/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5356 - accuracy: 0.9467 - val_loss: 0.8013 - val_accuracy: 0.8233\n","Epoch 87/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5145 - accuracy: 0.9617 - val_loss: 0.7682 - val_accuracy: 0.8502\n","Epoch 88/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5102 - accuracy: 0.9650 - val_loss: 0.7668 - val_accuracy: 0.8481\n","Epoch 89/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5075 - accuracy: 0.9650 - val_loss: 0.7684 - val_accuracy: 0.8491\n","Epoch 90/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5076 - accuracy: 0.9658 - val_loss: 0.7677 - val_accuracy: 0.8556\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5028 - accuracy: 0.9652 - val_loss: 0.7710 - val_accuracy: 0.8438\n","Epoch 92/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5037 - accuracy: 0.9650 - val_loss: 0.7758 - val_accuracy: 0.8491\n","Epoch 93/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4961 - accuracy: 0.9690 - val_loss: 0.8569 - val_accuracy: 0.8103\n","Epoch 94/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5054 - accuracy: 0.9623 - val_loss: 0.7757 - val_accuracy: 0.8491\n","Epoch 95/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4932 - accuracy: 0.9704 - val_loss: 0.7740 - val_accuracy: 0.8470\n","Epoch 96/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4921 - accuracy: 0.9679 - val_loss: 0.7888 - val_accuracy: 0.8534\n","Epoch 97/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4962 - accuracy: 0.9688 - val_loss: 0.7909 - val_accuracy: 0.8556\n","Epoch 98/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4922 - accuracy: 0.9666 - val_loss: 0.7788 - val_accuracy: 0.8502\n","Epoch 99/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4840 - accuracy: 0.9736 - val_loss: 0.7794 - val_accuracy: 0.8502\n","Epoch 100/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4813 - accuracy: 0.9744 - val_loss: 0.7747 - val_accuracy: 0.8524\n","{'loss': [0.8431426286697388, 0.8310163617134094, 0.8231020569801331, 0.8104445338249207, 0.8044675588607788, 0.796789824962616, 0.7930508255958557, 0.7889541983604431, 0.779762864112854, 0.7766205072402954, 0.7693123817443848, 0.7654509544372559, 0.7561771273612976, 0.7506867051124573, 0.7544045448303223, 0.7475990056991577, 0.7369635105133057, 0.7297472953796387, 0.7324987053871155, 0.7368373274803162, 0.7323676347732544, 0.7174574136734009, 0.7109648585319519, 0.7073458433151245, 0.7036436796188354, 0.6979655027389526, 0.7008984684944153, 0.6958650946617126, 0.6858490109443665, 0.685798168182373, 0.6846961975097656, 0.6824766397476196, 0.6698354482650757, 0.6809836626052856, 0.6659933924674988, 0.6639736890792847, 0.661545991897583, 0.6553450226783752, 0.6497891545295715, 0.6462416648864746, 0.6588496565818787, 0.651840090751648, 0.6460702419281006, 0.636430025100708, 0.6374272108078003, 0.6262689828872681, 0.6266974210739136, 0.6199562549591064, 0.6203374266624451, 0.6216059923171997, 0.6093043088912964, 0.6091941595077515, 0.6101660132408142, 0.6081581115722656, 0.6017476916313171, 0.6154714226722717, 0.6116747856140137, 0.5953812003135681, 0.5871249437332153, 0.5847325325012207, 0.580826461315155, 0.5796599388122559, 0.5748357176780701, 0.5784912705421448, 0.5705254077911377, 0.5676553845405579, 0.5629153847694397, 0.5850099921226501, 0.5609023571014404, 0.5576834082603455, 0.5555098056793213, 0.5519166588783264, 0.5486918091773987, 0.5449605584144592, 0.5523245334625244, 0.5434237122535706, 0.5365003943443298, 0.5340492725372314, 0.5306534767150879, 0.5342136025428772, 0.5355915427207947, 0.5262596011161804, 0.5230965614318848, 0.5209447145462036, 0.5347504019737244, 0.535619854927063, 0.5144956707954407, 0.5102420449256897, 0.5075438618659973, 0.5076310634613037, 0.5028420090675354, 0.5036737322807312, 0.4961165189743042, 0.5054354071617126, 0.493150919675827, 0.49213099479675293, 0.496214896440506, 0.492159903049469, 0.4840392470359802, 0.48134076595306396], 'accuracy': [0.8620689511299133, 0.8682650923728943, 0.8647629022598267, 0.873652994632721, 0.8744612336158752, 0.8825430870056152, 0.881196141242981, 0.8790409564971924, 0.8855064511299133, 0.8820043206214905, 0.8868534564971924, 0.8871228694915771, 0.892241358757019, 0.8949353694915771, 0.8873922228813171, 0.892241358757019, 0.8941271305084229, 0.9003232717514038, 0.8973599076271057, 0.8860452771186829, 0.8868534564971924, 0.9005926847457886, 0.9024784564971924, 0.9011314511299133, 0.9024784564971924, 0.9089439511299133, 0.907597005367279, 0.904902994632721, 0.9113685488700867, 0.907597005367279, 0.904633641242981, 0.9097521305084229, 0.915678858757019, 0.90625, 0.9178340435028076, 0.9175646305084229, 0.9178340435028076, 0.920258641242981, 0.9221444129943848, 0.923491358757019, 0.9137930870056152, 0.915409505367279, 0.920527994632721, 0.9259159564971924, 0.9237607717514038, 0.931303858757019, 0.9286099076271057, 0.9334590435028076, 0.9294180870056152, 0.9288793206214905, 0.9375, 0.9350754022598267, 0.9339978694915771, 0.9339978694915771, 0.9350754022598267, 0.921875, 0.9275323152542114, 0.9385775923728943, 0.9415409564971924, 0.946659505367279, 0.943696141242981, 0.9458512663841248, 0.946659505367279, 0.9434267282485962, 0.9434267282485962, 0.946928858757019, 0.951777994632721, 0.9315732717514038, 0.9496228694915771, 0.951508641242981, 0.9480064511299133, 0.9496228694915771, 0.9520474076271057, 0.9533944129943848, 0.9498922228813171, 0.9566271305084229, 0.9536637663841248, 0.9558189511299133, 0.9612069129943848, 0.9528555870056152, 0.9558189511299133, 0.962553858757019, 0.9612069129943848, 0.9617456793785095, 0.9463900923728943, 0.946659505367279, 0.9617456793785095, 0.9649784564971924, 0.9649784564971924, 0.9657866358757019, 0.9652478694915771, 0.9649784564971924, 0.9690194129943848, 0.962284505367279, 0.970366358757019, 0.9679418206214905, 0.96875, 0.9665948152542114, 0.9735991358757019, 0.9744073152542114], 'val_loss': [1.1706948280334473, 1.1610852479934692, 1.1481420993804932, 1.1366188526153564, 1.1296398639678955, 1.1130493879318237, 1.0955771207809448, 1.0820531845092773, 1.0628325939178467, 1.0471938848495483, 1.0253846645355225, 1.0121145248413086, 0.9831264615058899, 0.9626545906066895, 0.935134768486023, 0.9277306795120239, 0.8969089388847351, 0.8830388188362122, 0.8612430095672607, 0.8747472167015076, 0.8352353572845459, 0.8249663710594177, 0.8171070218086243, 0.8228365182876587, 0.8149725198745728, 0.8011266589164734, 0.7929335832595825, 0.7902494072914124, 0.7913389801979065, 0.791536808013916, 0.7918108105659485, 0.7903956770896912, 0.7853558659553528, 0.7801737785339355, 0.781442403793335, 0.7787062525749207, 0.778784453868866, 0.7751253247261047, 0.7769064903259277, 0.7717998623847961, 0.7901589870452881, 0.7776379585266113, 0.7747616171836853, 0.8233415484428406, 0.7741943001747131, 0.7804549932479858, 0.77391117811203, 0.772521436214447, 0.7738448977470398, 0.7686935067176819, 0.7682794332504272, 0.775354266166687, 0.7776257991790771, 0.7714449167251587, 0.7859464287757874, 0.7682899832725525, 0.7974703311920166, 0.7614408731460571, 0.7659558057785034, 0.770363450050354, 0.7624725103378296, 0.7594159841537476, 0.7741418480873108, 0.7626897692680359, 0.7741685509681702, 0.7624025940895081, 0.7652697563171387, 0.783705472946167, 0.7607832551002502, 0.768864095211029, 0.761928915977478, 0.763992190361023, 0.7674463391304016, 0.7680311799049377, 0.7860084772109985, 0.7731792330741882, 0.7767274379730225, 0.7651934027671814, 0.7638477087020874, 0.7645725011825562, 0.76556396484375, 0.76864093542099, 0.7693385481834412, 0.7943087220191956, 0.7761998176574707, 0.8012690544128418, 0.7682252526283264, 0.7668179869651794, 0.768372118473053, 0.7676513195037842, 0.7709617614746094, 0.7757517695426941, 0.8569279909133911, 0.7757358551025391, 0.7740225195884705, 0.788798451423645, 0.7908750772476196, 0.7787954211235046, 0.7794176340103149, 0.7746810913085938], 'val_accuracy': [0.8329741358757019, 0.8286637663841248, 0.8221982717514038, 0.8351293206214905, 0.8318965435028076, 0.8383620977401733, 0.8340517282485962, 0.8340517282485962, 0.8243534564971924, 0.8340517282485962, 0.8394396305084229, 0.837284505367279, 0.8405172228813171, 0.8318965435028076, 0.8362069129943848, 0.8329741358757019, 0.8426724076271057, 0.837284505367279, 0.84375, 0.818965494632721, 0.8415948152542114, 0.8405172228813171, 0.8415948152542114, 0.8329741358757019, 0.8415948152542114, 0.84375, 0.8426724076271057, 0.84375, 0.8415948152542114, 0.8394396305084229, 0.8480603694915771, 0.8426724076271057, 0.8523706793785095, 0.8480603694915771, 0.8545258641242981, 0.8480603694915771, 0.84375, 0.850215494632721, 0.84375, 0.8534482717514038, 0.84375, 0.8491379022598267, 0.8545258641242981, 0.8286637663841248, 0.8415948152542114, 0.84375, 0.8448275923728943, 0.8426724076271057, 0.8523706793785095, 0.8459051847457886, 0.8448275923728943, 0.8426724076271057, 0.8448275923728943, 0.8491379022598267, 0.84375, 0.8545258641242981, 0.8426724076271057, 0.8459051847457886, 0.8599137663841248, 0.8448275923728943, 0.850215494632721, 0.8512930870056152, 0.8415948152542114, 0.8512930870056152, 0.8415948152542114, 0.8534482717514038, 0.8480603694915771, 0.8383620977401733, 0.8523706793785095, 0.8512930870056152, 0.8556034564971924, 0.8491379022598267, 0.8556034564971924, 0.8480603694915771, 0.8351293206214905, 0.8459051847457886, 0.8426724076271057, 0.850215494632721, 0.8534482717514038, 0.8534482717514038, 0.8491379022598267, 0.8480603694915771, 0.8480603694915771, 0.8340517282485962, 0.8405172228813171, 0.8232758641242981, 0.850215494632721, 0.8480603694915771, 0.8491379022598267, 0.8556034564971924, 0.84375, 0.8491379022598267, 0.8103448152542114, 0.8491379022598267, 0.8469827771186829, 0.8534482717514038, 0.8556034564971924, 0.850215494632721, 0.850215494632721, 0.8523706793785095]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.8723 - accuracy: 0.8484"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 4s 37ms/step - loss: 0.8697 - accuracy: 0.8497 - val_loss: 1.1754 - val_accuracy: 0.8122\n","Epoch 2/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.8511 - accuracy: 0.8568 - val_loss: 1.1662 - val_accuracy: 0.8224\n","Epoch 3/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8375 - accuracy: 0.8596 - val_loss: 1.1569 - val_accuracy: 0.8179\n","Epoch 4/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.8283 - accuracy: 0.8656 - val_loss: 1.1478 - val_accuracy: 0.8133\n","Epoch 5/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.8320 - accuracy: 0.8563 - val_loss: 1.1367 - val_accuracy: 0.8281\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8198 - accuracy: 0.8599 - val_loss: 1.1228 - val_accuracy: 0.8032\n","Epoch 7/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8153 - accuracy: 0.8613 - val_loss: 1.1105 - val_accuracy: 0.8201\n","Epoch 8/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8036 - accuracy: 0.8715 - val_loss: 1.1013 - val_accuracy: 0.8201\n","Epoch 9/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.7980 - accuracy: 0.8701 - val_loss: 1.0835 - val_accuracy: 0.8292\n","Epoch 10/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7930 - accuracy: 0.8715 - val_loss: 1.0653 - val_accuracy: 0.8066\n","Epoch 11/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7898 - accuracy: 0.8701 - val_loss: 1.0510 - val_accuracy: 0.8224\n","Epoch 12/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7818 - accuracy: 0.8732 - val_loss: 1.0361 - val_accuracy: 0.8201\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7776 - accuracy: 0.8752 - val_loss: 1.0255 - val_accuracy: 0.8077\n","Epoch 14/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7733 - accuracy: 0.8755 - val_loss: 0.9956 - val_accuracy: 0.8156\n","Epoch 15/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7728 - accuracy: 0.8797 - val_loss: 0.9760 - val_accuracy: 0.8258\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7653 - accuracy: 0.8710 - val_loss: 0.9611 - val_accuracy: 0.8133\n","Epoch 17/100\n","28/28 [==============================] - 1s 42ms/step - loss: 0.7610 - accuracy: 0.8846 - val_loss: 0.9391 - val_accuracy: 0.8303\n","Epoch 18/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7528 - accuracy: 0.8812 - val_loss: 0.9211 - val_accuracy: 0.8224\n","Epoch 19/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.7497 - accuracy: 0.8848 - val_loss: 0.9144 - val_accuracy: 0.8179\n","Epoch 20/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7449 - accuracy: 0.8846 - val_loss: 0.8977 - val_accuracy: 0.8043\n","Epoch 21/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.7439 - accuracy: 0.8800 - val_loss: 0.8823 - val_accuracy: 0.8326\n","Epoch 22/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7367 - accuracy: 0.8868 - val_loss: 0.8721 - val_accuracy: 0.8156\n","Epoch 23/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7539 - accuracy: 0.8755 - val_loss: 0.9160 - val_accuracy: 0.7896\n","Epoch 24/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7510 - accuracy: 0.8766 - val_loss: 0.8532 - val_accuracy: 0.8292\n","Epoch 25/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.7353 - accuracy: 0.8871 - val_loss: 0.8523 - val_accuracy: 0.8314\n","Epoch 26/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7206 - accuracy: 0.8942 - val_loss: 0.8482 - val_accuracy: 0.8235\n","Epoch 27/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.7265 - accuracy: 0.8843 - val_loss: 0.8446 - val_accuracy: 0.8258\n","Epoch 28/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7141 - accuracy: 0.8936 - val_loss: 0.8611 - val_accuracy: 0.8167\n","Epoch 29/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7194 - accuracy: 0.8908 - val_loss: 0.8464 - val_accuracy: 0.8314\n","Epoch 30/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7206 - accuracy: 0.8877 - val_loss: 0.8404 - val_accuracy: 0.8326\n","Epoch 31/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7111 - accuracy: 0.8888 - val_loss: 0.8515 - val_accuracy: 0.8281\n","Epoch 32/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7071 - accuracy: 0.8899 - val_loss: 0.8507 - val_accuracy: 0.8258\n","Epoch 33/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7044 - accuracy: 0.8973 - val_loss: 0.8446 - val_accuracy: 0.8247\n","Epoch 34/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7000 - accuracy: 0.8973 - val_loss: 0.8337 - val_accuracy: 0.8235\n","Epoch 35/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6890 - accuracy: 0.9046 - val_loss: 0.8322 - val_accuracy: 0.8303\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6825 - accuracy: 0.9027 - val_loss: 0.8441 - val_accuracy: 0.8247\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6901 - accuracy: 0.8993 - val_loss: 0.8297 - val_accuracy: 0.8303\n","Epoch 38/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6794 - accuracy: 0.9075 - val_loss: 0.8448 - val_accuracy: 0.8269\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6755 - accuracy: 0.9044 - val_loss: 0.8619 - val_accuracy: 0.8111\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6731 - accuracy: 0.9069 - val_loss: 0.8291 - val_accuracy: 0.8314\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6744 - accuracy: 0.9075 - val_loss: 0.8340 - val_accuracy: 0.8303\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6690 - accuracy: 0.9046 - val_loss: 0.8275 - val_accuracy: 0.8292\n","Epoch 43/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6616 - accuracy: 0.9117 - val_loss: 0.8294 - val_accuracy: 0.8326\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6625 - accuracy: 0.9089 - val_loss: 0.8549 - val_accuracy: 0.8122\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6672 - accuracy: 0.9046 - val_loss: 0.8390 - val_accuracy: 0.8303\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6636 - accuracy: 0.9055 - val_loss: 0.8350 - val_accuracy: 0.8303\n","Epoch 47/100\n","28/28 [==============================] - 1s 52ms/step - loss: 0.6516 - accuracy: 0.9171 - val_loss: 0.8226 - val_accuracy: 0.8337\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6474 - accuracy: 0.9171 - val_loss: 0.8357 - val_accuracy: 0.8213\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6470 - accuracy: 0.9151 - val_loss: 0.8338 - val_accuracy: 0.8201\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6374 - accuracy: 0.9250 - val_loss: 0.8281 - val_accuracy: 0.8213\n","Epoch 51/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6433 - accuracy: 0.9182 - val_loss: 0.8222 - val_accuracy: 0.8348\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6356 - accuracy: 0.9199 - val_loss: 0.8217 - val_accuracy: 0.8348\n","Epoch 53/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6328 - accuracy: 0.9194 - val_loss: 0.8370 - val_accuracy: 0.8235\n","Epoch 54/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6274 - accuracy: 0.9233 - val_loss: 0.8341 - val_accuracy: 0.8190\n","Epoch 55/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6251 - accuracy: 0.9239 - val_loss: 0.8247 - val_accuracy: 0.8247\n","Epoch 56/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6227 - accuracy: 0.9247 - val_loss: 0.8222 - val_accuracy: 0.8303\n","Epoch 57/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6219 - accuracy: 0.9261 - val_loss: 0.8221 - val_accuracy: 0.8303\n","Epoch 58/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6181 - accuracy: 0.9253 - val_loss: 0.8195 - val_accuracy: 0.8326\n","Epoch 59/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6123 - accuracy: 0.9321 - val_loss: 0.8278 - val_accuracy: 0.8269\n","Epoch 60/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6143 - accuracy: 0.9293 - val_loss: 0.8570 - val_accuracy: 0.8213\n","Epoch 61/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6060 - accuracy: 0.9318 - val_loss: 0.8277 - val_accuracy: 0.8213\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6059 - accuracy: 0.9332 - val_loss: 0.8275 - val_accuracy: 0.8190\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6083 - accuracy: 0.9293 - val_loss: 0.8207 - val_accuracy: 0.8303\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6012 - accuracy: 0.9310 - val_loss: 0.8192 - val_accuracy: 0.8281\n","Epoch 65/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5954 - accuracy: 0.9358 - val_loss: 0.8216 - val_accuracy: 0.8247\n","Epoch 66/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5962 - accuracy: 0.9360 - val_loss: 0.8419 - val_accuracy: 0.8133\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5947 - accuracy: 0.9341 - val_loss: 0.8335 - val_accuracy: 0.8258\n","Epoch 68/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5938 - accuracy: 0.9349 - val_loss: 0.8189 - val_accuracy: 0.8303\n","Epoch 69/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5839 - accuracy: 0.9400 - val_loss: 0.8180 - val_accuracy: 0.8292\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5797 - accuracy: 0.9389 - val_loss: 0.8226 - val_accuracy: 0.8292\n","Epoch 71/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5820 - accuracy: 0.9363 - val_loss: 0.8188 - val_accuracy: 0.8337\n","Epoch 72/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5797 - accuracy: 0.9417 - val_loss: 0.8319 - val_accuracy: 0.8269\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5780 - accuracy: 0.9400 - val_loss: 0.8204 - val_accuracy: 0.8258\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5681 - accuracy: 0.9479 - val_loss: 0.8174 - val_accuracy: 0.8303\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5698 - accuracy: 0.9397 - val_loss: 0.8192 - val_accuracy: 0.8303\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5670 - accuracy: 0.9426 - val_loss: 0.8226 - val_accuracy: 0.8213\n","Epoch 77/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5647 - accuracy: 0.9423 - val_loss: 0.8292 - val_accuracy: 0.8326\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5664 - accuracy: 0.9406 - val_loss: 0.8227 - val_accuracy: 0.8190\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5596 - accuracy: 0.9448 - val_loss: 0.8177 - val_accuracy: 0.8281\n","Epoch 80/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5535 - accuracy: 0.9502 - val_loss: 0.8206 - val_accuracy: 0.8247\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5561 - accuracy: 0.9471 - val_loss: 0.8205 - val_accuracy: 0.8326\n","Epoch 82/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5523 - accuracy: 0.9522 - val_loss: 0.8182 - val_accuracy: 0.8258\n","Epoch 83/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5471 - accuracy: 0.9505 - val_loss: 0.8218 - val_accuracy: 0.8258\n","Epoch 84/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5505 - accuracy: 0.9482 - val_loss: 0.8706 - val_accuracy: 0.7975\n","Epoch 85/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5483 - accuracy: 0.9493 - val_loss: 0.8171 - val_accuracy: 0.8281\n","Epoch 86/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5463 - accuracy: 0.9488 - val_loss: 0.8250 - val_accuracy: 0.8258\n","Epoch 87/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.5388 - accuracy: 0.9525 - val_loss: 0.8396 - val_accuracy: 0.8145\n","Epoch 88/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.5369 - accuracy: 0.9516 - val_loss: 0.8189 - val_accuracy: 0.8292\n","Epoch 89/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5340 - accuracy: 0.9556 - val_loss: 0.8257 - val_accuracy: 0.8281\n","Epoch 90/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5372 - accuracy: 0.9491 - val_loss: 0.8294 - val_accuracy: 0.8179\n","Epoch 91/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5263 - accuracy: 0.9581 - val_loss: 0.8268 - val_accuracy: 0.8247\n","Epoch 92/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5354 - accuracy: 0.9527 - val_loss: 0.8410 - val_accuracy: 0.8179\n","Epoch 93/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5303 - accuracy: 0.9527 - val_loss: 0.8302 - val_accuracy: 0.8190\n","Epoch 94/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5224 - accuracy: 0.9567 - val_loss: 0.8380 - val_accuracy: 0.8281\n","Epoch 95/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5272 - accuracy: 0.9533 - val_loss: 0.8249 - val_accuracy: 0.8247\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5544 - accuracy: 0.9369 - val_loss: 0.8345 - val_accuracy: 0.8224\n","Epoch 97/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5152 - accuracy: 0.9621 - val_loss: 0.8322 - val_accuracy: 0.8303\n","Epoch 98/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5162 - accuracy: 0.9593 - val_loss: 0.8237 - val_accuracy: 0.8247\n","Epoch 99/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5070 - accuracy: 0.9638 - val_loss: 0.8249 - val_accuracy: 0.8247\n","Epoch 100/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5066 - accuracy: 0.9646 - val_loss: 0.8306 - val_accuracy: 0.8213\n","{'loss': [0.8697266578674316, 0.8511103987693787, 0.8375127911567688, 0.828253448009491, 0.8320339322090149, 0.8198025226593018, 0.8153336048126221, 0.8036413788795471, 0.7979899644851685, 0.7930052280426025, 0.7897818088531494, 0.7818196415901184, 0.777621328830719, 0.7733449935913086, 0.772805392742157, 0.7652603983879089, 0.7609627842903137, 0.7527927160263062, 0.7496606111526489, 0.7448520660400391, 0.7438759803771973, 0.7367120981216431, 0.7538611888885498, 0.7509937882423401, 0.7352675795555115, 0.7205975651741028, 0.7265087366104126, 0.7140774130821228, 0.7193867564201355, 0.7205623984336853, 0.7110846042633057, 0.7070574760437012, 0.7044498920440674, 0.7000068426132202, 0.689038097858429, 0.6824559569358826, 0.6900657415390015, 0.6793690919876099, 0.6755295991897583, 0.6731448173522949, 0.6743908524513245, 0.6690448522567749, 0.6615937948226929, 0.662475049495697, 0.6672070622444153, 0.6636420488357544, 0.6516426205635071, 0.6473840475082397, 0.6469714045524597, 0.6373775005340576, 0.6432650685310364, 0.6356058716773987, 0.6327961087226868, 0.6274009943008423, 0.6250526905059814, 0.6226914525032043, 0.6219301223754883, 0.6181272268295288, 0.6123424768447876, 0.6143121123313904, 0.6059908270835876, 0.6058609485626221, 0.6083167195320129, 0.601244330406189, 0.5954227447509766, 0.5962265729904175, 0.5946955680847168, 0.5938007831573486, 0.5838922262191772, 0.5796975493431091, 0.5819870233535767, 0.5796948671340942, 0.5780319571495056, 0.5681456327438354, 0.5698292851448059, 0.5670105814933777, 0.5646920204162598, 0.5663779973983765, 0.5596482157707214, 0.553473711013794, 0.5561050772666931, 0.5522772073745728, 0.547082245349884, 0.5505384206771851, 0.5483006238937378, 0.5463052988052368, 0.5388484597206116, 0.5369390845298767, 0.5340355038642883, 0.5371541976928711, 0.5262534618377686, 0.5353736877441406, 0.5303067564964294, 0.5223922729492188, 0.5272228121757507, 0.5543560981750488, 0.5151633620262146, 0.51616370677948, 0.5069787502288818, 0.5066429376602173], 'accuracy': [0.8497453331947327, 0.8568194508552551, 0.859649121761322, 0.8655914068222046, 0.8562535643577576, 0.8599320650100708, 0.8613469004631042, 0.8715336918830872, 0.8701188564300537, 0.8715336918830872, 0.8701188564300537, 0.8732314705848694, 0.8752122521400452, 0.875495195388794, 0.8797396421432495, 0.8709677457809448, 0.8845500946044922, 0.881154477596283, 0.884833037853241, 0.8845500946044922, 0.8800226449966431, 0.8868138194084167, 0.875495195388794, 0.8766270279884338, 0.8870967626571655, 0.8941709399223328, 0.8842670917510986, 0.8936049938201904, 0.8907753229141235, 0.8876627087593079, 0.8887945413589478, 0.8899264335632324, 0.8972835540771484, 0.8972835540771484, 0.9046406149864197, 0.9026598930358887, 0.8992642760276794, 0.9074702858924866, 0.9043576717376709, 0.9069043397903442, 0.9074702858924866, 0.9046406149864197, 0.9117147922515869, 0.90888512134552, 0.9046406149864197, 0.9054895043373108, 0.9170911312103271, 0.9170911312103271, 0.9151103496551514, 0.9250141382217407, 0.918222963809967, 0.9199207425117493, 0.9193548560142517, 0.9233163595199585, 0.9238823056221008, 0.9247311949729919, 0.9261460304260254, 0.9252971410751343, 0.9320882558822632, 0.9292586445808411, 0.9318053126335144, 0.9332201480865479, 0.9292586445808411, 0.9309564232826233, 0.9357668161392212, 0.9360498189926147, 0.934069037437439, 0.9349179267883301, 0.9400113224983215, 0.9388794302940369, 0.9363327622413635, 0.9417091012001038, 0.9400113224983215, 0.9479343295097351, 0.9397283792495728, 0.9425579905509949, 0.9422750473022461, 0.9405772686004639, 0.9448217153549194, 0.9501980543136597, 0.947085440158844, 0.9521788358688354, 0.9504810571670532, 0.9482173323631287, 0.9493491649627686, 0.9487832188606262, 0.9524617791175842, 0.9516128897666931, 0.9555743932723999, 0.9490662217140198, 0.958121120929718, 0.9527447819709778, 0.9527447819709778, 0.9567062854766846, 0.9533106684684753, 0.9368987083435059, 0.9620826244354248, 0.9592529535293579, 0.963780403137207, 0.9646292924880981], 'val_loss': [1.175370454788208, 1.166222095489502, 1.1568623781204224, 1.1478402614593506, 1.1366612911224365, 1.1228137016296387, 1.1104527711868286, 1.101320743560791, 1.0835394859313965, 1.0652683973312378, 1.0510451793670654, 1.0360853672027588, 1.0254697799682617, 0.9956091046333313, 0.9759977459907532, 0.9610773921012878, 0.9390628933906555, 0.9211100339889526, 0.9144291281700134, 0.8976766467094421, 0.8822632431983948, 0.8721489310264587, 0.9160400629043579, 0.8531708717346191, 0.8523299098014832, 0.8482207655906677, 0.8446332812309265, 0.8611010909080505, 0.8463578224182129, 0.8403854966163635, 0.8515074849128723, 0.8507423996925354, 0.8446012735366821, 0.8336559534072876, 0.8321629166603088, 0.844109833240509, 0.8297098278999329, 0.8448281288146973, 0.8619070649147034, 0.8291396498680115, 0.83399498462677, 0.8274906277656555, 0.829380214214325, 0.8549059629440308, 0.8390156030654907, 0.8350394368171692, 0.8225616812705994, 0.8356580138206482, 0.8337991237640381, 0.8281230926513672, 0.8222374320030212, 0.8216792941093445, 0.8370083570480347, 0.8341234922409058, 0.8247431516647339, 0.8221840262413025, 0.8221138715744019, 0.8195421695709229, 0.8278077244758606, 0.8569506406784058, 0.8276959657669067, 0.8275264501571655, 0.8206520676612854, 0.8191505670547485, 0.8216394782066345, 0.8418879508972168, 0.8334604501724243, 0.8189148902893066, 0.8180141448974609, 0.8226017355918884, 0.8187886476516724, 0.8319016098976135, 0.8204156756401062, 0.8173655271530151, 0.8191546201705933, 0.8226441740989685, 0.8291696310043335, 0.8227414488792419, 0.8176814317703247, 0.8205999135971069, 0.820465624332428, 0.818224310874939, 0.8217926621437073, 0.8706322312355042, 0.8171451091766357, 0.8249642848968506, 0.8395774960517883, 0.8189491629600525, 0.8257037401199341, 0.8294299244880676, 0.8267941474914551, 0.8409776091575623, 0.8301787972450256, 0.8380365371704102, 0.8249141573905945, 0.8344986438751221, 0.8322416543960571, 0.8237139582633972, 0.8249465227127075, 0.8306025266647339], 'val_accuracy': [0.8122171759605408, 0.8223981857299805, 0.8178732991218567, 0.8133484125137329, 0.8280543088912964, 0.8031674027442932, 0.820135772228241, 0.820135772228241, 0.8291855454444885, 0.8065611124038696, 0.8223981857299805, 0.820135772228241, 0.807692289352417, 0.8156108856201172, 0.8257918357849121, 0.8133484125137329, 0.8303167223930359, 0.8223981857299805, 0.8178732991218567, 0.8042986392974854, 0.8325791954994202, 0.8156108856201172, 0.7895927429199219, 0.8291855454444885, 0.831447958946228, 0.8235294222831726, 0.8257918357849121, 0.8167420625686646, 0.831447958946228, 0.8325791954994202, 0.8280543088912964, 0.8257918357849121, 0.8246606588363647, 0.8235294222831726, 0.8303167223930359, 0.8246606588363647, 0.8303167223930359, 0.8269230723381042, 0.8110859990119934, 0.831447958946228, 0.8303167223930359, 0.8291855454444885, 0.8325791954994202, 0.8122171759605408, 0.8303167223930359, 0.8303167223930359, 0.8337104320526123, 0.8212669491767883, 0.820135772228241, 0.8212669491767883, 0.8348416090011597, 0.8348416090011597, 0.8235294222831726, 0.8190045356750488, 0.8246606588363647, 0.8303167223930359, 0.8303167223930359, 0.8325791954994202, 0.8269230723381042, 0.8212669491767883, 0.8212669491767883, 0.8190045356750488, 0.8303167223930359, 0.8280543088912964, 0.8246606588363647, 0.8133484125137329, 0.8257918357849121, 0.8303167223930359, 0.8291855454444885, 0.8291855454444885, 0.8337104320526123, 0.8269230723381042, 0.8257918357849121, 0.8303167223930359, 0.8303167223930359, 0.8212669491767883, 0.8325791954994202, 0.8190045356750488, 0.8280543088912964, 0.8246606588363647, 0.8325791954994202, 0.8257918357849121, 0.8257918357849121, 0.7975113391876221, 0.8280543088912964, 0.8257918357849121, 0.814479649066925, 0.8291855454444885, 0.8280543088912964, 0.8178732991218567, 0.8246606588363647, 0.8178732991218567, 0.8190045356750488, 0.8280543088912964, 0.8246606588363647, 0.8223981857299805, 0.8303167223930359, 0.8246606588363647, 0.8246606588363647, 0.8212669491767883]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.8426 - accuracy: 0.8656"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 5s 36ms/step - loss: 0.8409 - accuracy: 0.8651 - val_loss: 1.1676 - val_accuracy: 0.7965\n","Epoch 2/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8210 - accuracy: 0.8760 - val_loss: 1.1589 - val_accuracy: 0.8285\n","Epoch 3/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8147 - accuracy: 0.8780 - val_loss: 1.1449 - val_accuracy: 0.8151\n","Epoch 4/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8048 - accuracy: 0.8791 - val_loss: 1.1341 - val_accuracy: 0.8264\n","Epoch 5/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8003 - accuracy: 0.8824 - val_loss: 1.1200 - val_accuracy: 0.8254\n","Epoch 6/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7911 - accuracy: 0.8814 - val_loss: 1.1073 - val_accuracy: 0.8161\n","Epoch 7/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7832 - accuracy: 0.8886 - val_loss: 1.0874 - val_accuracy: 0.8161\n","Epoch 8/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7803 - accuracy: 0.8868 - val_loss: 1.0743 - val_accuracy: 0.8254\n","Epoch 9/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7718 - accuracy: 0.8886 - val_loss: 1.0557 - val_accuracy: 0.8233\n","Epoch 10/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7698 - accuracy: 0.8879 - val_loss: 1.0312 - val_accuracy: 0.8151\n","Epoch 11/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7624 - accuracy: 0.8907 - val_loss: 1.0105 - val_accuracy: 0.8171\n","Epoch 12/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7573 - accuracy: 0.8938 - val_loss: 0.9875 - val_accuracy: 0.8192\n","Epoch 13/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7514 - accuracy: 0.8964 - val_loss: 0.9764 - val_accuracy: 0.8233\n","Epoch 14/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7502 - accuracy: 0.8920 - val_loss: 0.9501 - val_accuracy: 0.8264\n","Epoch 15/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7654 - accuracy: 0.8791 - val_loss: 0.9268 - val_accuracy: 0.8140\n","Epoch 16/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7395 - accuracy: 0.8972 - val_loss: 0.9049 - val_accuracy: 0.8254\n","Epoch 17/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7330 - accuracy: 0.8979 - val_loss: 0.9034 - val_accuracy: 0.8120\n","Epoch 18/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7444 - accuracy: 0.8866 - val_loss: 0.8698 - val_accuracy: 0.8275\n","Epoch 19/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7258 - accuracy: 0.8997 - val_loss: 0.8611 - val_accuracy: 0.8254\n","Epoch 20/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7286 - accuracy: 0.8959 - val_loss: 0.8478 - val_accuracy: 0.8244\n","Epoch 21/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7179 - accuracy: 0.8997 - val_loss: 0.8367 - val_accuracy: 0.8233\n","Epoch 22/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7134 - accuracy: 0.9008 - val_loss: 0.8352 - val_accuracy: 0.8213\n","Epoch 23/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7098 - accuracy: 0.9023 - val_loss: 0.8229 - val_accuracy: 0.8295\n","Epoch 24/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7078 - accuracy: 0.9036 - val_loss: 0.8302 - val_accuracy: 0.8264\n","Epoch 25/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7020 - accuracy: 0.9057 - val_loss: 0.8278 - val_accuracy: 0.8275\n","Epoch 26/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7018 - accuracy: 0.9023 - val_loss: 0.8216 - val_accuracy: 0.8254\n","Epoch 27/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6948 - accuracy: 0.9052 - val_loss: 0.8203 - val_accuracy: 0.8223\n","Epoch 28/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6934 - accuracy: 0.9059 - val_loss: 0.8174 - val_accuracy: 0.8388\n","Epoch 29/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6848 - accuracy: 0.9096 - val_loss: 0.8147 - val_accuracy: 0.8388\n","Epoch 30/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6920 - accuracy: 0.9070 - val_loss: 0.8838 - val_accuracy: 0.7975\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6871 - accuracy: 0.9044 - val_loss: 0.8170 - val_accuracy: 0.8264\n","Epoch 32/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6752 - accuracy: 0.9132 - val_loss: 0.8114 - val_accuracy: 0.8337\n","Epoch 33/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6718 - accuracy: 0.9121 - val_loss: 0.8110 - val_accuracy: 0.8306\n","Epoch 34/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6703 - accuracy: 0.9127 - val_loss: 0.8107 - val_accuracy: 0.8347\n","Epoch 35/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6644 - accuracy: 0.9127 - val_loss: 0.8135 - val_accuracy: 0.8337\n","Epoch 36/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6639 - accuracy: 0.9168 - val_loss: 0.8079 - val_accuracy: 0.8347\n","Epoch 37/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6594 - accuracy: 0.9155 - val_loss: 0.8064 - val_accuracy: 0.8347\n","Epoch 38/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6760 - accuracy: 0.8992 - val_loss: 0.8079 - val_accuracy: 0.8337\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6561 - accuracy: 0.9171 - val_loss: 0.8139 - val_accuracy: 0.8316\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6595 - accuracy: 0.9080 - val_loss: 0.8090 - val_accuracy: 0.8378\n","Epoch 41/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6567 - accuracy: 0.9101 - val_loss: 0.8349 - val_accuracy: 0.8244\n","Epoch 42/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6492 - accuracy: 0.9171 - val_loss: 0.8148 - val_accuracy: 0.8295\n","Epoch 43/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6459 - accuracy: 0.9212 - val_loss: 0.8078 - val_accuracy: 0.8326\n","Epoch 44/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6421 - accuracy: 0.9204 - val_loss: 0.8041 - val_accuracy: 0.8357\n","Epoch 45/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6383 - accuracy: 0.9222 - val_loss: 0.8066 - val_accuracy: 0.8347\n","Epoch 46/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6326 - accuracy: 0.9245 - val_loss: 0.8026 - val_accuracy: 0.8326\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6298 - accuracy: 0.9235 - val_loss: 0.8049 - val_accuracy: 0.8326\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6267 - accuracy: 0.9256 - val_loss: 0.8047 - val_accuracy: 0.8357\n","Epoch 49/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6348 - accuracy: 0.9152 - val_loss: 0.8060 - val_accuracy: 0.8347\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6217 - accuracy: 0.9279 - val_loss: 0.8056 - val_accuracy: 0.8337\n","Epoch 51/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6176 - accuracy: 0.9310 - val_loss: 0.8208 - val_accuracy: 0.8285\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6114 - accuracy: 0.9344 - val_loss: 0.7979 - val_accuracy: 0.8347\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6090 - accuracy: 0.9333 - val_loss: 0.8106 - val_accuracy: 0.8357\n","Epoch 54/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6122 - accuracy: 0.9302 - val_loss: 0.8301 - val_accuracy: 0.8244\n","Epoch 55/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6071 - accuracy: 0.9370 - val_loss: 0.8029 - val_accuracy: 0.8357\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6050 - accuracy: 0.9339 - val_loss: 0.8088 - val_accuracy: 0.8316\n","Epoch 57/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6025 - accuracy: 0.9326 - val_loss: 0.8518 - val_accuracy: 0.8130\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6121 - accuracy: 0.9202 - val_loss: 0.8031 - val_accuracy: 0.8295\n","Epoch 59/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6077 - accuracy: 0.9209 - val_loss: 0.8135 - val_accuracy: 0.8275\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5908 - accuracy: 0.9398 - val_loss: 0.8310 - val_accuracy: 0.8171\n","Epoch 61/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5910 - accuracy: 0.9367 - val_loss: 0.7953 - val_accuracy: 0.8347\n","Epoch 62/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5883 - accuracy: 0.9382 - val_loss: 0.8118 - val_accuracy: 0.8326\n","Epoch 63/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5855 - accuracy: 0.9341 - val_loss: 0.8001 - val_accuracy: 0.8388\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5813 - accuracy: 0.9375 - val_loss: 0.8103 - val_accuracy: 0.8264\n","Epoch 65/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5805 - accuracy: 0.9393 - val_loss: 0.8247 - val_accuracy: 0.8275\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5822 - accuracy: 0.9351 - val_loss: 0.8195 - val_accuracy: 0.8264\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5802 - accuracy: 0.9367 - val_loss: 0.8027 - val_accuracy: 0.8337\n","Epoch 68/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5725 - accuracy: 0.9437 - val_loss: 0.8027 - val_accuracy: 0.8254\n","Epoch 69/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5687 - accuracy: 0.9460 - val_loss: 0.7964 - val_accuracy: 0.8347\n","Epoch 70/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5624 - accuracy: 0.9483 - val_loss: 0.8385 - val_accuracy: 0.8192\n","Epoch 71/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5658 - accuracy: 0.9401 - val_loss: 0.7955 - val_accuracy: 0.8337\n","Epoch 72/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5634 - accuracy: 0.9406 - val_loss: 0.8050 - val_accuracy: 0.8347\n","Epoch 73/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5573 - accuracy: 0.9468 - val_loss: 0.7954 - val_accuracy: 0.8347\n","Epoch 74/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5544 - accuracy: 0.9481 - val_loss: 0.8017 - val_accuracy: 0.8357\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5552 - accuracy: 0.9460 - val_loss: 0.7997 - val_accuracy: 0.8337\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5475 - accuracy: 0.9506 - val_loss: 0.7973 - val_accuracy: 0.8368\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5448 - accuracy: 0.9519 - val_loss: 0.8000 - val_accuracy: 0.8368\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5442 - accuracy: 0.9501 - val_loss: 0.7982 - val_accuracy: 0.8306\n","Epoch 79/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5605 - accuracy: 0.9395 - val_loss: 0.8014 - val_accuracy: 0.8337\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5457 - accuracy: 0.9460 - val_loss: 0.8097 - val_accuracy: 0.8378\n","Epoch 81/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5517 - accuracy: 0.9382 - val_loss: 0.7997 - val_accuracy: 0.8326\n","Epoch 82/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5370 - accuracy: 0.9525 - val_loss: 0.8306 - val_accuracy: 0.8223\n","Epoch 83/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5337 - accuracy: 0.9537 - val_loss: 0.8098 - val_accuracy: 0.8378\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5284 - accuracy: 0.9540 - val_loss: 0.8041 - val_accuracy: 0.8378\n","Epoch 85/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5274 - accuracy: 0.9589 - val_loss: 0.8318 - val_accuracy: 0.8182\n","Epoch 86/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5289 - accuracy: 0.9543 - val_loss: 0.8103 - val_accuracy: 0.8254\n","Epoch 87/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5268 - accuracy: 0.9568 - val_loss: 0.8278 - val_accuracy: 0.8244\n","Epoch 88/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5237 - accuracy: 0.9561 - val_loss: 0.8058 - val_accuracy: 0.8295\n","Epoch 89/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5183 - accuracy: 0.9571 - val_loss: 0.8321 - val_accuracy: 0.8223\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5190 - accuracy: 0.9525 - val_loss: 0.8082 - val_accuracy: 0.8388\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5151 - accuracy: 0.9584 - val_loss: 0.8121 - val_accuracy: 0.8264\n","Epoch 92/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5126 - accuracy: 0.9602 - val_loss: 0.8140 - val_accuracy: 0.8285\n","Epoch 93/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5236 - accuracy: 0.9496 - val_loss: 0.8179 - val_accuracy: 0.8233\n","Epoch 94/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5065 - accuracy: 0.9612 - val_loss: 0.8206 - val_accuracy: 0.8213\n","Epoch 95/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5088 - accuracy: 0.9618 - val_loss: 0.8053 - val_accuracy: 0.8326\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5021 - accuracy: 0.9625 - val_loss: 0.8110 - val_accuracy: 0.8275\n","Epoch 97/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5163 - accuracy: 0.9509 - val_loss: 0.8284 - val_accuracy: 0.8182\n","Epoch 98/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5125 - accuracy: 0.9519 - val_loss: 0.8594 - val_accuracy: 0.8213\n","Epoch 99/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5054 - accuracy: 0.9571 - val_loss: 0.8163 - val_accuracy: 0.8233\n","Epoch 100/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4946 - accuracy: 0.9649 - val_loss: 0.8125 - val_accuracy: 0.8337\n","{'loss': [0.8408510088920593, 0.8209619522094727, 0.8147207498550415, 0.8047817945480347, 0.8003078103065491, 0.7911421656608582, 0.7832180261611938, 0.7803123593330383, 0.771819531917572, 0.7698060274124146, 0.7624131441116333, 0.7572833895683289, 0.7514256834983826, 0.7501635551452637, 0.7653645873069763, 0.7395315170288086, 0.7329699993133545, 0.7443925738334656, 0.7257511615753174, 0.7286428809165955, 0.7179210782051086, 0.7134062051773071, 0.7098307013511658, 0.7078182697296143, 0.7019581198692322, 0.7018010020256042, 0.6947867274284363, 0.693415641784668, 0.6847603917121887, 0.6920179128646851, 0.6870999932289124, 0.6751737594604492, 0.671798050403595, 0.6703052520751953, 0.6643537282943726, 0.6638650894165039, 0.6594260931015015, 0.6760395765304565, 0.6561163663864136, 0.6595303416252136, 0.656703531742096, 0.6491811275482178, 0.6458986401557922, 0.6420656442642212, 0.6383458971977234, 0.6325847506523132, 0.6297556757926941, 0.6266978979110718, 0.6348142623901367, 0.621715247631073, 0.6175636053085327, 0.6114265322685242, 0.6089814305305481, 0.6122357845306396, 0.6071045398712158, 0.6049585342407227, 0.6024833917617798, 0.6120869517326355, 0.6076564192771912, 0.5907836556434631, 0.5910414457321167, 0.58829265832901, 0.5855212211608887, 0.5812835097312927, 0.5805178880691528, 0.5822402238845825, 0.5801774859428406, 0.5725306272506714, 0.5686987638473511, 0.562381386756897, 0.5657826662063599, 0.5634064674377441, 0.5573312044143677, 0.5543933510780334, 0.5552407503128052, 0.5474790930747986, 0.5447724461555481, 0.5441616177558899, 0.5605046153068542, 0.5456936359405518, 0.5517006516456604, 0.536952018737793, 0.5336724519729614, 0.5284295082092285, 0.5273522138595581, 0.5289204716682434, 0.5267586708068848, 0.5237426161766052, 0.5183050036430359, 0.5190061926841736, 0.5150585770606995, 0.512550413608551, 0.5235908627510071, 0.5064811110496521, 0.508841872215271, 0.5021080374717712, 0.516251802444458, 0.512517511844635, 0.5053836107254028, 0.49462640285491943], 'accuracy': [0.8651162981987, 0.8759689927101135, 0.8780362010002136, 0.8790697455406189, 0.8824289441108704, 0.8813953399658203, 0.8886305093765259, 0.8868216872215271, 0.8886305093765259, 0.8878552913665771, 0.8906976580619812, 0.8937984704971313, 0.8963824510574341, 0.8919896483421326, 0.8790697455406189, 0.897157609462738, 0.8979328274726868, 0.8865633010864258, 0.8997415900230408, 0.8958656191825867, 0.8997415900230408, 0.9007751941680908, 0.9023255705833435, 0.9036175608634949, 0.905684769153595, 0.9023255705833435, 0.9051679372787476, 0.9059431552886963, 0.9095607399940491, 0.9069767594337463, 0.9043927788734436, 0.9131782650947571, 0.9121447205543518, 0.9126614928245544, 0.9126614928245544, 0.9167958498001099, 0.9155038595199585, 0.8992248177528381, 0.9170542359352112, 0.9080103635787964, 0.9100775122642517, 0.9170542359352112, 0.9211886525154114, 0.9204134345054626, 0.9222221970558167, 0.9245477914810181, 0.923514187335968, 0.9255813956260681, 0.9152454733848572, 0.9279069900512695, 0.9310077428817749, 0.9343669414520264, 0.9333333373069763, 0.930232584476471, 0.9369509220123291, 0.933850109577179, 0.9325581192970276, 0.9201550483703613, 0.9209302067756653, 0.9397932887077332, 0.9366925358772278, 0.9382429122924805, 0.934108555316925, 0.9374676942825317, 0.9392764568328857, 0.9351420998573303, 0.9366925358772278, 0.9436692595481873, 0.9459948539733887, 0.9483203887939453, 0.9400516748428345, 0.9405684471130371, 0.9467700123786926, 0.948062002658844, 0.9459948539733887, 0.9506459832191467, 0.9519379734992981, 0.9501292109489441, 0.9395349025726318, 0.9459948539733887, 0.9382429122924805, 0.9524548053741455, 0.9537467956542969, 0.9540051817893982, 0.9589147567749023, 0.9542635679244995, 0.9568475484848022, 0.9560723304748535, 0.9571059346199036, 0.9524548053741455, 0.9583979249000549, 0.9602067470550537, 0.9496123790740967, 0.961240291595459, 0.9617571234703064, 0.9625322818756104, 0.950904369354248, 0.9519379734992981, 0.9571059346199036, 0.9648578763008118], 'val_loss': [1.1676231622695923, 1.1588529348373413, 1.144924521446228, 1.1340526342391968, 1.1200039386749268, 1.1072598695755005, 1.087367057800293, 1.0742805004119873, 1.0556546449661255, 1.0311734676361084, 1.0105414390563965, 0.9875441193580627, 0.9764001369476318, 0.9500827193260193, 0.9268158674240112, 0.9048917889595032, 0.9033955931663513, 0.8697735071182251, 0.8611228466033936, 0.847797691822052, 0.8366633653640747, 0.8352126479148865, 0.8228764533996582, 0.8302335143089294, 0.8277702927589417, 0.8216201066970825, 0.8203116655349731, 0.8173607587814331, 0.8146893978118896, 0.883825957775116, 0.8170416951179504, 0.8114123940467834, 0.8110348582267761, 0.8107162714004517, 0.8134647607803345, 0.8079018592834473, 0.80640709400177, 0.8079184293746948, 0.8139369487762451, 0.809015691280365, 0.8348575234413147, 0.8148082494735718, 0.8078096508979797, 0.8040544390678406, 0.8066348433494568, 0.8026455044746399, 0.8049417734146118, 0.8047479391098022, 0.8059626817703247, 0.8056138753890991, 0.8207831978797913, 0.7979302406311035, 0.810637354850769, 0.8301034569740295, 0.8029272556304932, 0.8088454008102417, 0.851773738861084, 0.8030832409858704, 0.8134863972663879, 0.8310045599937439, 0.7952682971954346, 0.8117722272872925, 0.8001208901405334, 0.8102672696113586, 0.8246693015098572, 0.8195280432701111, 0.8027271628379822, 0.8026846051216125, 0.7963805794715881, 0.838547945022583, 0.7954593896865845, 0.8050135374069214, 0.7954333424568176, 0.80169278383255, 0.7996964454650879, 0.7973028421401978, 0.8000126481056213, 0.7982207536697388, 0.801414430141449, 0.8096655011177063, 0.7997151613235474, 0.8305736184120178, 0.8097687363624573, 0.8040692210197449, 0.831766664981842, 0.8102826476097107, 0.8277837038040161, 0.8058363199234009, 0.8320915699005127, 0.8081834316253662, 0.8121330738067627, 0.8139565587043762, 0.8178985714912415, 0.8206053376197815, 0.8052615523338318, 0.8110448718070984, 0.8284034132957458, 0.8594031929969788, 0.8162816166877747, 0.8125131130218506], 'val_accuracy': [0.7964876294136047, 0.8285123705863953, 0.8150826692581177, 0.8264462947845459, 0.8254132270812988, 0.81611567735672, 0.81611567735672, 0.8254132270812988, 0.8233470916748047, 0.8150826692581177, 0.817148745059967, 0.8192148804664612, 0.8233470916748047, 0.8264462947845459, 0.8140496015548706, 0.8254132270812988, 0.8119834661483765, 0.827479362487793, 0.8254132270812988, 0.8243801593780518, 0.8233470916748047, 0.8212810158729553, 0.8295454382896423, 0.8264462947845459, 0.827479362487793, 0.8254132270812988, 0.8223140239715576, 0.8388429880142212, 0.8388429880142212, 0.797520637512207, 0.8264462947845459, 0.8336777091026306, 0.8305785059928894, 0.8347107172012329, 0.8336777091026306, 0.8347107172012329, 0.8347107172012329, 0.8336777091026306, 0.8316115736961365, 0.8378099203109741, 0.8243801593780518, 0.8295454382896423, 0.8326446413993835, 0.83574378490448, 0.8347107172012329, 0.8326446413993835, 0.8326446413993835, 0.83574378490448, 0.8347107172012329, 0.8336777091026306, 0.8285123705863953, 0.8347107172012329, 0.83574378490448, 0.8243801593780518, 0.83574378490448, 0.8316115736961365, 0.8130165338516235, 0.8295454382896423, 0.827479362487793, 0.817148745059967, 0.8347107172012329, 0.8326446413993835, 0.8388429880142212, 0.8264462947845459, 0.827479362487793, 0.8264462947845459, 0.8336777091026306, 0.8254132270812988, 0.8347107172012329, 0.8192148804664612, 0.8336777091026306, 0.8347107172012329, 0.8347107172012329, 0.83574378490448, 0.8336777091026306, 0.836776852607727, 0.836776852607727, 0.8305785059928894, 0.8336777091026306, 0.8378099203109741, 0.8326446413993835, 0.8223140239715576, 0.8378099203109741, 0.8378099203109741, 0.8181818127632141, 0.8254132270812988, 0.8243801593780518, 0.8295454382896423, 0.8223140239715576, 0.8388429880142212, 0.8264462947845459, 0.8285123705863953, 0.8233470916748047, 0.8212810158729553, 0.8326446413993835, 0.827479362487793, 0.8181818127632141, 0.8212810158729553, 0.8233470916748047, 0.8336777091026306]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.5884 - accuracy: 0.9166"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 4s 42ms/step - loss: 0.5873 - accuracy: 0.9176 - val_loss: 1.0062 - val_accuracy: 0.8545\n","Epoch 2/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5475 - accuracy: 0.9337 - val_loss: 0.9987 - val_accuracy: 0.8524\n","Epoch 3/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5388 - accuracy: 0.9402 - val_loss: 0.9868 - val_accuracy: 0.8491\n","Epoch 4/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5444 - accuracy: 0.9410 - val_loss: 0.9796 - val_accuracy: 0.8438\n","Epoch 5/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5387 - accuracy: 0.9397 - val_loss: 0.9675 - val_accuracy: 0.8308\n","Epoch 6/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5426 - accuracy: 0.9407 - val_loss: 0.9606 - val_accuracy: 0.8028\n","Epoch 7/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5345 - accuracy: 0.9432 - val_loss: 0.9294 - val_accuracy: 0.8481\n","Epoch 8/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5299 - accuracy: 0.9434 - val_loss: 0.9124 - val_accuracy: 0.8491\n","Epoch 9/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5235 - accuracy: 0.9459 - val_loss: 0.8943 - val_accuracy: 0.8502\n","Epoch 10/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5177 - accuracy: 0.9502 - val_loss: 0.8755 - val_accuracy: 0.8481\n","Epoch 11/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5141 - accuracy: 0.9539 - val_loss: 0.8483 - val_accuracy: 0.8470\n","Epoch 12/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5198 - accuracy: 0.9467 - val_loss: 0.8375 - val_accuracy: 0.8459\n","Epoch 13/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5167 - accuracy: 0.9518 - val_loss: 0.8064 - val_accuracy: 0.8502\n","Epoch 14/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5043 - accuracy: 0.9582 - val_loss: 0.8048 - val_accuracy: 0.8351\n","Epoch 15/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5013 - accuracy: 0.9617 - val_loss: 0.7770 - val_accuracy: 0.8416\n","Epoch 16/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5102 - accuracy: 0.9545 - val_loss: 0.7419 - val_accuracy: 0.8513\n","Epoch 17/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4992 - accuracy: 0.9596 - val_loss: 0.7289 - val_accuracy: 0.8545\n","Epoch 18/100\n","29/29 [==============================] - 2s 54ms/step - loss: 0.4959 - accuracy: 0.9607 - val_loss: 0.7190 - val_accuracy: 0.8556\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4957 - accuracy: 0.9604 - val_loss: 0.7003 - val_accuracy: 0.8545\n","Epoch 20/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4917 - accuracy: 0.9620 - val_loss: 0.6920 - val_accuracy: 0.8556\n","Epoch 21/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4883 - accuracy: 0.9636 - val_loss: 0.6864 - val_accuracy: 0.8567\n","Epoch 22/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.4873 - accuracy: 0.9642 - val_loss: 0.6770 - val_accuracy: 0.8664\n","Epoch 23/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4900 - accuracy: 0.9604 - val_loss: 0.7000 - val_accuracy: 0.8556\n","Epoch 24/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4818 - accuracy: 0.9679 - val_loss: 0.6694 - val_accuracy: 0.8653\n","Epoch 25/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4817 - accuracy: 0.9658 - val_loss: 0.6701 - val_accuracy: 0.8739\n","Epoch 26/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4740 - accuracy: 0.9685 - val_loss: 0.6705 - val_accuracy: 0.8718\n","Epoch 27/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4763 - accuracy: 0.9639 - val_loss: 0.6602 - val_accuracy: 0.8750\n","Epoch 28/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4714 - accuracy: 0.9720 - val_loss: 0.6596 - val_accuracy: 0.8782\n","Epoch 29/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4688 - accuracy: 0.9674 - val_loss: 0.6610 - val_accuracy: 0.8825\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4681 - accuracy: 0.9733 - val_loss: 0.6656 - val_accuracy: 0.8804\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4688 - accuracy: 0.9712 - val_loss: 0.6645 - val_accuracy: 0.8825\n","Epoch 32/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4638 - accuracy: 0.9733 - val_loss: 0.6629 - val_accuracy: 0.8836\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4590 - accuracy: 0.9760 - val_loss: 0.6697 - val_accuracy: 0.8825\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4594 - accuracy: 0.9731 - val_loss: 0.6717 - val_accuracy: 0.8782\n","Epoch 35/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4674 - accuracy: 0.9677 - val_loss: 0.6983 - val_accuracy: 0.8696\n","Epoch 36/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4534 - accuracy: 0.9758 - val_loss: 0.6686 - val_accuracy: 0.8847\n","Epoch 37/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4523 - accuracy: 0.9776 - val_loss: 0.6770 - val_accuracy: 0.8825\n","Epoch 38/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4514 - accuracy: 0.9752 - val_loss: 0.6766 - val_accuracy: 0.8815\n","Epoch 39/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4487 - accuracy: 0.9779 - val_loss: 0.6733 - val_accuracy: 0.8782\n","Epoch 40/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4530 - accuracy: 0.9712 - val_loss: 0.7355 - val_accuracy: 0.8481\n","Epoch 41/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4511 - accuracy: 0.9723 - val_loss: 0.6763 - val_accuracy: 0.8825\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4473 - accuracy: 0.9763 - val_loss: 0.6824 - val_accuracy: 0.8772\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4459 - accuracy: 0.9760 - val_loss: 0.6814 - val_accuracy: 0.8815\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4397 - accuracy: 0.9776 - val_loss: 0.6786 - val_accuracy: 0.8793\n","Epoch 45/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4376 - accuracy: 0.9798 - val_loss: 0.6764 - val_accuracy: 0.8815\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4442 - accuracy: 0.9758 - val_loss: 0.6875 - val_accuracy: 0.8772\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4330 - accuracy: 0.9806 - val_loss: 0.6894 - val_accuracy: 0.8804\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4336 - accuracy: 0.9803 - val_loss: 0.6780 - val_accuracy: 0.8825\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4299 - accuracy: 0.9855 - val_loss: 0.6984 - val_accuracy: 0.8761\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4280 - accuracy: 0.9846 - val_loss: 0.6849 - val_accuracy: 0.8772\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4307 - accuracy: 0.9830 - val_loss: 0.7168 - val_accuracy: 0.8631\n","Epoch 52/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4273 - accuracy: 0.9825 - val_loss: 0.6824 - val_accuracy: 0.8804\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4222 - accuracy: 0.9860 - val_loss: 0.6797 - val_accuracy: 0.8836\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4250 - accuracy: 0.9817 - val_loss: 0.6971 - val_accuracy: 0.8793\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4215 - accuracy: 0.9838 - val_loss: 0.6809 - val_accuracy: 0.8836\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4192 - accuracy: 0.9855 - val_loss: 0.6884 - val_accuracy: 0.8825\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4163 - accuracy: 0.9852 - val_loss: 0.6827 - val_accuracy: 0.8815\n","Epoch 58/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4147 - accuracy: 0.9865 - val_loss: 0.6878 - val_accuracy: 0.8793\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4414 - accuracy: 0.9647 - val_loss: 0.6999 - val_accuracy: 0.8750\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4212 - accuracy: 0.9836 - val_loss: 0.7044 - val_accuracy: 0.8728\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4259 - accuracy: 0.9760 - val_loss: 0.6858 - val_accuracy: 0.8815\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4075 - accuracy: 0.9890 - val_loss: 0.6946 - val_accuracy: 0.8815\n","Epoch 63/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4105 - accuracy: 0.9857 - val_loss: 0.7013 - val_accuracy: 0.8728\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4053 - accuracy: 0.9895 - val_loss: 0.6916 - val_accuracy: 0.8793\n","Epoch 65/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4038 - accuracy: 0.9884 - val_loss: 0.6956 - val_accuracy: 0.8782\n","Epoch 66/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4013 - accuracy: 0.9908 - val_loss: 0.7019 - val_accuracy: 0.8815\n","Epoch 67/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4002 - accuracy: 0.9900 - val_loss: 0.6969 - val_accuracy: 0.8804\n","Epoch 68/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3994 - accuracy: 0.9900 - val_loss: 0.6950 - val_accuracy: 0.8825\n","Epoch 69/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3978 - accuracy: 0.9906 - val_loss: 0.7014 - val_accuracy: 0.8782\n","Epoch 70/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.3957 - accuracy: 0.9919 - val_loss: 0.7129 - val_accuracy: 0.8718\n","Epoch 71/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3978 - accuracy: 0.9900 - val_loss: 0.6975 - val_accuracy: 0.8804\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3964 - accuracy: 0.9898 - val_loss: 0.6995 - val_accuracy: 0.8793\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3943 - accuracy: 0.9900 - val_loss: 0.7074 - val_accuracy: 0.8739\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3907 - accuracy: 0.9927 - val_loss: 0.7140 - val_accuracy: 0.8696\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3912 - accuracy: 0.9906 - val_loss: 0.7013 - val_accuracy: 0.8793\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3969 - accuracy: 0.9892 - val_loss: 0.7060 - val_accuracy: 0.8772\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3924 - accuracy: 0.9914 - val_loss: 0.7034 - val_accuracy: 0.8782\n","Epoch 78/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3926 - accuracy: 0.9919 - val_loss: 0.7223 - val_accuracy: 0.8621\n","Epoch 79/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3842 - accuracy: 0.9930 - val_loss: 0.7052 - val_accuracy: 0.8815\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3838 - accuracy: 0.9933 - val_loss: 0.7058 - val_accuracy: 0.8804\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3812 - accuracy: 0.9930 - val_loss: 0.7197 - val_accuracy: 0.8739\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3798 - accuracy: 0.9938 - val_loss: 0.7127 - val_accuracy: 0.8793\n","Epoch 83/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3784 - accuracy: 0.9952 - val_loss: 0.7120 - val_accuracy: 0.8815\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3803 - accuracy: 0.9943 - val_loss: 0.7335 - val_accuracy: 0.8631\n","Epoch 85/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3765 - accuracy: 0.9943 - val_loss: 0.7155 - val_accuracy: 0.8750\n","Epoch 86/100\n","29/29 [==============================] - 1s 49ms/step - loss: 0.3754 - accuracy: 0.9952 - val_loss: 0.7228 - val_accuracy: 0.8858\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3771 - accuracy: 0.9946 - val_loss: 0.7399 - val_accuracy: 0.8610\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3745 - accuracy: 0.9960 - val_loss: 0.7140 - val_accuracy: 0.8804\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3744 - accuracy: 0.9960 - val_loss: 0.7255 - val_accuracy: 0.8728\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3713 - accuracy: 0.9962 - val_loss: 0.7194 - val_accuracy: 0.8793\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3737 - accuracy: 0.9943 - val_loss: 0.7297 - val_accuracy: 0.8739\n","Epoch 92/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3696 - accuracy: 0.9960 - val_loss: 0.7340 - val_accuracy: 0.8793\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3703 - accuracy: 0.9954 - val_loss: 0.7577 - val_accuracy: 0.8578\n","Epoch 94/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3706 - accuracy: 0.9949 - val_loss: 0.7258 - val_accuracy: 0.8761\n","Epoch 95/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3664 - accuracy: 0.9968 - val_loss: 0.7264 - val_accuracy: 0.8761\n","Epoch 96/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3683 - accuracy: 0.9941 - val_loss: 0.7337 - val_accuracy: 0.8772\n","Epoch 97/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3653 - accuracy: 0.9957 - val_loss: 0.7305 - val_accuracy: 0.8804\n","Epoch 98/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3639 - accuracy: 0.9970 - val_loss: 0.7419 - val_accuracy: 0.8685\n","Epoch 99/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3655 - accuracy: 0.9965 - val_loss: 0.7273 - val_accuracy: 0.8772\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3619 - accuracy: 0.9973 - val_loss: 0.7403 - val_accuracy: 0.8707\n","{'loss': [0.5872564911842346, 0.5474968552589417, 0.5388044118881226, 0.5444244742393494, 0.538711428642273, 0.5425627827644348, 0.5345045328140259, 0.5299080610275269, 0.5235327482223511, 0.5176599025726318, 0.5141370892524719, 0.5197725892066956, 0.5167458057403564, 0.5042974352836609, 0.5013033151626587, 0.5102372765541077, 0.49915194511413574, 0.4958774745464325, 0.49569860100746155, 0.491658478975296, 0.48826271295547485, 0.48728787899017334, 0.4899679720401764, 0.4818412661552429, 0.48166272044181824, 0.4739779233932495, 0.47633305191993713, 0.4714317321777344, 0.4688156843185425, 0.46811702847480774, 0.4687905013561249, 0.4637717008590698, 0.4590197205543518, 0.4593743681907654, 0.46743741631507874, 0.45336365699768066, 0.45230633020401, 0.4514442980289459, 0.44868797063827515, 0.45300543308258057, 0.4510502219200134, 0.4472723603248596, 0.4458760917186737, 0.4397197663784027, 0.4376392662525177, 0.4441787004470825, 0.4330345690250397, 0.4336317181587219, 0.4298788607120514, 0.4280356466770172, 0.43071505427360535, 0.42725321650505066, 0.4221542179584503, 0.42502397298812866, 0.42152687907218933, 0.4192015826702118, 0.41629549860954285, 0.4147047698497772, 0.4413996636867523, 0.4212372601032257, 0.4258682429790497, 0.40753331780433655, 0.4105416238307953, 0.4052868187427521, 0.40375402569770813, 0.40133896470069885, 0.4002363085746765, 0.39941170811653137, 0.3978058397769928, 0.3957001566886902, 0.39781931042671204, 0.39635106921195984, 0.3942813575267792, 0.3906901180744171, 0.39121881127357483, 0.39689701795578003, 0.3923606872558594, 0.3925875723361969, 0.3841712772846222, 0.38379305601119995, 0.3812224268913269, 0.3798372745513916, 0.37843042612075806, 0.3803035616874695, 0.3765024244785309, 0.3753793239593506, 0.37708550691604614, 0.3744906485080719, 0.37439262866973877, 0.37134435772895813, 0.37365925312042236, 0.36959385871887207, 0.3702695667743683, 0.37058010697364807, 0.3664146065711975, 0.3682575523853302, 0.36528438329696655, 0.36386704444885254, 0.36552587151527405, 0.36189863085746765], 'accuracy': [0.9175646305084229, 0.9337284564971924, 0.9401939511299133, 0.9410021305084229, 0.9396551847457886, 0.9407327771186829, 0.9431573152542114, 0.9434267282485962, 0.9458512663841248, 0.9501616358757019, 0.9539331793785095, 0.946659505367279, 0.951777994632721, 0.9582435488700867, 0.9617456793785095, 0.954472005367279, 0.959590494632721, 0.9606680870056152, 0.9603987336158752, 0.9620150923728943, 0.9636314511299133, 0.9641702771186829, 0.9603987336158752, 0.9679418206214905, 0.9657866358757019, 0.9684805870056152, 0.9639008641242981, 0.9719827771186829, 0.967402994632721, 0.9733297228813171, 0.9711745977401733, 0.9733297228813171, 0.9760237336158752, 0.9730603694915771, 0.9676724076271057, 0.9757543206214905, 0.9776400923728943, 0.975215494632721, 0.977909505367279, 0.9711745977401733, 0.9722521305084229, 0.9762930870056152, 0.9760237336158752, 0.9776400923728943, 0.9797952771186829, 0.9757543206214905, 0.9806034564971924, 0.9803340435028076, 0.9854525923728943, 0.9846444129943848, 0.983027994632721, 0.9824892282485962, 0.985991358757019, 0.9816810488700867, 0.9838362336158752, 0.9854525923728943, 0.9851831793785095, 0.9865301847457886, 0.9647090435028076, 0.9835668206214905, 0.9760237336158752, 0.9889547228813171, 0.985722005367279, 0.9894935488700867, 0.9884159564971924, 0.990840494632721, 0.9900323152542114, 0.9900323152542114, 0.990571141242981, 0.9919180870056152, 0.9900323152542114, 0.9897629022598267, 0.9900323152542114, 0.9927262663841248, 0.990571141242981, 0.9892241358757019, 0.9913793206214905, 0.9919180870056152, 0.9929956793785095, 0.9932650923728943, 0.9929956793785095, 0.993803858757019, 0.9951508641242981, 0.9943426847457886, 0.9943426847457886, 0.9951508641242981, 0.9946120977401733, 0.9959590435028076, 0.9959590435028076, 0.9962284564971924, 0.9943426847457886, 0.9959590435028076, 0.9954202771186829, 0.9948814511299133, 0.9967672228813171, 0.9940732717514038, 0.9956896305084229, 0.9970366358757019, 0.9964978694915771, 0.9973060488700867], 'val_loss': [1.0062304735183716, 0.998714029788971, 0.9868049025535583, 0.9796233773231506, 0.9675006866455078, 0.960563063621521, 0.9294273853302002, 0.9123907685279846, 0.894326388835907, 0.8755320310592651, 0.8482938408851624, 0.8374590873718262, 0.8063787817955017, 0.8047657608985901, 0.7769875526428223, 0.7418984770774841, 0.7288778424263, 0.7190280556678772, 0.7003239989280701, 0.6920362114906311, 0.6864495277404785, 0.6769904494285583, 0.6999818086624146, 0.6693693995475769, 0.6700558066368103, 0.670461118221283, 0.6602134704589844, 0.6595920920372009, 0.6609714031219482, 0.6656156778335571, 0.6644859313964844, 0.6629289984703064, 0.6697128415107727, 0.6716926097869873, 0.6983259916305542, 0.6685530543327332, 0.6770122647285461, 0.6766009330749512, 0.6732850074768066, 0.7354795932769775, 0.6762591004371643, 0.682388424873352, 0.6813753247261047, 0.6786442399024963, 0.6763720512390137, 0.6875259280204773, 0.6893702745437622, 0.6779958009719849, 0.6983898878097534, 0.6848808526992798, 0.7167580723762512, 0.6823700070381165, 0.6796976327896118, 0.697066068649292, 0.6809159517288208, 0.6884494423866272, 0.6826660633087158, 0.6878405213356018, 0.6999446749687195, 0.7044481039047241, 0.685754656791687, 0.6946069002151489, 0.7012979984283447, 0.6916002631187439, 0.6956242322921753, 0.7019029259681702, 0.6968591213226318, 0.6950021982192993, 0.7014003396034241, 0.7128541469573975, 0.697539210319519, 0.6995422840118408, 0.7073824405670166, 0.7140007019042969, 0.7013036608695984, 0.7060195207595825, 0.7034183740615845, 0.7223292589187622, 0.7051838040351868, 0.7057978510856628, 0.719679594039917, 0.7126784324645996, 0.7119796276092529, 0.7334657311439514, 0.7155278325080872, 0.7227912545204163, 0.7399330139160156, 0.7139712572097778, 0.7255124449729919, 0.7194125056266785, 0.7296708226203918, 0.7340257167816162, 0.7576841115951538, 0.7258121967315674, 0.7263882160186768, 0.7337005138397217, 0.7304853200912476, 0.7419052720069885, 0.7272610068321228, 0.7402713298797607], 'val_accuracy': [0.8545258641242981, 0.8523706793785095, 0.8491379022598267, 0.84375, 0.8308189511299133, 0.8028017282485962, 0.8480603694915771, 0.8491379022598267, 0.850215494632721, 0.8480603694915771, 0.8469827771186829, 0.8459051847457886, 0.850215494632721, 0.8351293206214905, 0.8415948152542114, 0.8512930870056152, 0.8545258641242981, 0.8556034564971924, 0.8545258641242981, 0.8556034564971924, 0.8566810488700867, 0.8663793206214905, 0.8556034564971924, 0.8653017282485962, 0.8739224076271057, 0.8717672228813171, 0.875, 0.8782327771186829, 0.8825430870056152, 0.8803879022598267, 0.8825430870056152, 0.8836206793785095, 0.8825430870056152, 0.8782327771186829, 0.8696120977401733, 0.8846982717514038, 0.8825430870056152, 0.881465494632721, 0.8782327771186829, 0.8480603694915771, 0.8825430870056152, 0.8771551847457886, 0.881465494632721, 0.8793103694915771, 0.881465494632721, 0.8771551847457886, 0.8803879022598267, 0.8825430870056152, 0.8760775923728943, 0.8771551847457886, 0.8631465435028076, 0.8803879022598267, 0.8836206793785095, 0.8793103694915771, 0.8836206793785095, 0.8825430870056152, 0.881465494632721, 0.8793103694915771, 0.875, 0.8728448152542114, 0.881465494632721, 0.881465494632721, 0.8728448152542114, 0.8793103694915771, 0.8782327771186829, 0.881465494632721, 0.8803879022598267, 0.8825430870056152, 0.8782327771186829, 0.8717672228813171, 0.8803879022598267, 0.8793103694915771, 0.8739224076271057, 0.8696120977401733, 0.8793103694915771, 0.8771551847457886, 0.8782327771186829, 0.8620689511299133, 0.881465494632721, 0.8803879022598267, 0.8739224076271057, 0.8793103694915771, 0.881465494632721, 0.8631465435028076, 0.875, 0.8857758641242981, 0.860991358757019, 0.8803879022598267, 0.8728448152542114, 0.8793103694915771, 0.8739224076271057, 0.8793103694915771, 0.857758641242981, 0.8760775923728943, 0.8760775923728943, 0.8771551847457886, 0.8803879022598267, 0.868534505367279, 0.8771551847457886, 0.8706896305084229]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 5s 41ms/step - loss: 0.5735 - accuracy: 0.9244 - val_loss: 1.0172 - val_accuracy: 0.8122\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 1s 23ms/step - loss: 0.5643 - accuracy: 0.9281 - val_loss: 1.0079 - val_accuracy: 0.8179\n","Epoch 3/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5538 - accuracy: 0.9341 - val_loss: 0.9969 - val_accuracy: 0.8224\n","Epoch 4/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5482 - accuracy: 0.9355 - val_loss: 0.9873 - val_accuracy: 0.8179\n","Epoch 5/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5439 - accuracy: 0.9420 - val_loss: 0.9712 - val_accuracy: 0.8213\n","Epoch 6/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5486 - accuracy: 0.9369 - val_loss: 0.9578 - val_accuracy: 0.8235\n","Epoch 7/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5393 - accuracy: 0.9386 - val_loss: 0.9462 - val_accuracy: 0.8145\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5459 - accuracy: 0.9324 - val_loss: 0.9209 - val_accuracy: 0.8213\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5368 - accuracy: 0.9386 - val_loss: 0.9204 - val_accuracy: 0.8088\n","Epoch 10/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5280 - accuracy: 0.9499 - val_loss: 0.8942 - val_accuracy: 0.8167\n","Epoch 11/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5268 - accuracy: 0.9485 - val_loss: 0.8934 - val_accuracy: 0.8032\n","Epoch 12/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5245 - accuracy: 0.9462 - val_loss: 0.8589 - val_accuracy: 0.8133\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5256 - accuracy: 0.9460 - val_loss: 0.8401 - val_accuracy: 0.8156\n","Epoch 14/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5251 - accuracy: 0.9488 - val_loss: 0.8237 - val_accuracy: 0.8156\n","Epoch 15/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5152 - accuracy: 0.9533 - val_loss: 0.8072 - val_accuracy: 0.8122\n","Epoch 16/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5175 - accuracy: 0.9499 - val_loss: 0.7789 - val_accuracy: 0.8269\n","Epoch 17/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5125 - accuracy: 0.9539 - val_loss: 0.7634 - val_accuracy: 0.8326\n","Epoch 18/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5109 - accuracy: 0.9567 - val_loss: 0.7506 - val_accuracy: 0.8337\n","Epoch 19/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5072 - accuracy: 0.9539 - val_loss: 0.7375 - val_accuracy: 0.8360\n","Epoch 20/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4980 - accuracy: 0.9621 - val_loss: 0.7296 - val_accuracy: 0.8314\n","Epoch 21/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4967 - accuracy: 0.9632 - val_loss: 0.7201 - val_accuracy: 0.8360\n","Epoch 22/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4964 - accuracy: 0.9624 - val_loss: 0.7156 - val_accuracy: 0.8450\n","Epoch 23/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.4932 - accuracy: 0.9626 - val_loss: 0.7071 - val_accuracy: 0.8473\n","Epoch 24/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.4894 - accuracy: 0.9646 - val_loss: 0.7035 - val_accuracy: 0.8495\n","Epoch 25/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.4936 - accuracy: 0.9615 - val_loss: 0.7093 - val_accuracy: 0.8665\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4887 - accuracy: 0.9607 - val_loss: 0.7032 - val_accuracy: 0.8609\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4827 - accuracy: 0.9658 - val_loss: 0.6983 - val_accuracy: 0.8586\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4900 - accuracy: 0.9632 - val_loss: 0.6969 - val_accuracy: 0.8631\n","Epoch 29/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4814 - accuracy: 0.9666 - val_loss: 0.7175 - val_accuracy: 0.8473\n","Epoch 30/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4839 - accuracy: 0.9624 - val_loss: 0.7107 - val_accuracy: 0.8597\n","Epoch 31/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4771 - accuracy: 0.9689 - val_loss: 0.7073 - val_accuracy: 0.8586\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4775 - accuracy: 0.9649 - val_loss: 0.7209 - val_accuracy: 0.8665\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4781 - accuracy: 0.9641 - val_loss: 0.7032 - val_accuracy: 0.8654\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4715 - accuracy: 0.9700 - val_loss: 0.7082 - val_accuracy: 0.8654\n","Epoch 35/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4670 - accuracy: 0.9728 - val_loss: 0.7265 - val_accuracy: 0.8507\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4648 - accuracy: 0.9728 - val_loss: 0.7123 - val_accuracy: 0.8609\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4672 - accuracy: 0.9683 - val_loss: 0.7070 - val_accuracy: 0.8620\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4623 - accuracy: 0.9740 - val_loss: 0.7067 - val_accuracy: 0.8609\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4592 - accuracy: 0.9765 - val_loss: 0.7037 - val_accuracy: 0.8665\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4588 - accuracy: 0.9734 - val_loss: 0.7076 - val_accuracy: 0.8620\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4541 - accuracy: 0.9774 - val_loss: 0.7140 - val_accuracy: 0.8597\n","Epoch 42/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4581 - accuracy: 0.9731 - val_loss: 0.8143 - val_accuracy: 0.8518\n","Epoch 43/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4666 - accuracy: 0.9624 - val_loss: 0.7080 - val_accuracy: 0.8676\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4477 - accuracy: 0.9785 - val_loss: 0.7104 - val_accuracy: 0.8609\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4468 - accuracy: 0.9768 - val_loss: 0.7110 - val_accuracy: 0.8654\n","Epoch 46/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4446 - accuracy: 0.9785 - val_loss: 0.7406 - val_accuracy: 0.8620\n","Epoch 47/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4701 - accuracy: 0.9607 - val_loss: 0.7380 - val_accuracy: 0.8450\n","Epoch 48/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4597 - accuracy: 0.9669 - val_loss: 0.7250 - val_accuracy: 0.8654\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4447 - accuracy: 0.9768 - val_loss: 0.7244 - val_accuracy: 0.8609\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4417 - accuracy: 0.9785 - val_loss: 0.7179 - val_accuracy: 0.8609\n","Epoch 51/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4349 - accuracy: 0.9816 - val_loss: 0.7165 - val_accuracy: 0.8665\n","Epoch 52/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4358 - accuracy: 0.9788 - val_loss: 0.7289 - val_accuracy: 0.8597\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4372 - accuracy: 0.9791 - val_loss: 0.7718 - val_accuracy: 0.8541\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4467 - accuracy: 0.9737 - val_loss: 0.7308 - val_accuracy: 0.8541\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4308 - accuracy: 0.9816 - val_loss: 0.7190 - val_accuracy: 0.8665\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4285 - accuracy: 0.9844 - val_loss: 0.7259 - val_accuracy: 0.8586\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4322 - accuracy: 0.9779 - val_loss: 0.7303 - val_accuracy: 0.8597\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4276 - accuracy: 0.9839 - val_loss: 0.7221 - val_accuracy: 0.8643\n","Epoch 59/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4343 - accuracy: 0.9779 - val_loss: 0.7203 - val_accuracy: 0.8699\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4266 - accuracy: 0.9813 - val_loss: 0.7233 - val_accuracy: 0.8609\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4224 - accuracy: 0.9830 - val_loss: 0.7477 - val_accuracy: 0.8597\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4218 - accuracy: 0.9833 - val_loss: 0.7244 - val_accuracy: 0.8654\n","Epoch 63/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4176 - accuracy: 0.9864 - val_loss: 0.7260 - val_accuracy: 0.8654\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4200 - accuracy: 0.9833 - val_loss: 0.7791 - val_accuracy: 0.8552\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4151 - accuracy: 0.9859 - val_loss: 0.7393 - val_accuracy: 0.8563\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4137 - accuracy: 0.9867 - val_loss: 0.7474 - val_accuracy: 0.8609\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4119 - accuracy: 0.9875 - val_loss: 0.7306 - val_accuracy: 0.8620\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4101 - accuracy: 0.9878 - val_loss: 0.7321 - val_accuracy: 0.8609\n","Epoch 69/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4082 - accuracy: 0.9890 - val_loss: 0.7392 - val_accuracy: 0.8575\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4093 - accuracy: 0.9884 - val_loss: 0.7675 - val_accuracy: 0.8575\n","Epoch 71/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4062 - accuracy: 0.9875 - val_loss: 0.7329 - val_accuracy: 0.8654\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4050 - accuracy: 0.9898 - val_loss: 0.7505 - val_accuracy: 0.8631\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4050 - accuracy: 0.9892 - val_loss: 0.7345 - val_accuracy: 0.8631\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4014 - accuracy: 0.9895 - val_loss: 0.7378 - val_accuracy: 0.8609\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4088 - accuracy: 0.9844 - val_loss: 0.7428 - val_accuracy: 0.8552\n","Epoch 76/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4000 - accuracy: 0.9901 - val_loss: 0.7405 - val_accuracy: 0.8586\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4002 - accuracy: 0.9890 - val_loss: 0.7386 - val_accuracy: 0.8643\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4028 - accuracy: 0.9864 - val_loss: 0.7588 - val_accuracy: 0.8586\n","Epoch 79/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4024 - accuracy: 0.9870 - val_loss: 0.7347 - val_accuracy: 0.8609\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4094 - accuracy: 0.9827 - val_loss: 0.7606 - val_accuracy: 0.8620\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4036 - accuracy: 0.9842 - val_loss: 0.7582 - val_accuracy: 0.8473\n","Epoch 82/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3971 - accuracy: 0.9887 - val_loss: 0.7707 - val_accuracy: 0.8586\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3940 - accuracy: 0.9892 - val_loss: 0.7431 - val_accuracy: 0.8575\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3921 - accuracy: 0.9909 - val_loss: 0.7724 - val_accuracy: 0.8609\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3872 - accuracy: 0.9941 - val_loss: 0.7416 - val_accuracy: 0.8643\n","Epoch 86/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3868 - accuracy: 0.9918 - val_loss: 0.7480 - val_accuracy: 0.8586\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3865 - accuracy: 0.9918 - val_loss: 0.7471 - val_accuracy: 0.8541\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3866 - accuracy: 0.9935 - val_loss: 0.7484 - val_accuracy: 0.8586\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3834 - accuracy: 0.9918 - val_loss: 0.7652 - val_accuracy: 0.8609\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3854 - accuracy: 0.9921 - val_loss: 0.7668 - val_accuracy: 0.8462\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3814 - accuracy: 0.9932 - val_loss: 0.7550 - val_accuracy: 0.8597\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3800 - accuracy: 0.9938 - val_loss: 0.7573 - val_accuracy: 0.8575\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3768 - accuracy: 0.9955 - val_loss: 0.7526 - val_accuracy: 0.8597\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3778 - accuracy: 0.9949 - val_loss: 0.7663 - val_accuracy: 0.8495\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3766 - accuracy: 0.9952 - val_loss: 0.7748 - val_accuracy: 0.8575\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3776 - accuracy: 0.9941 - val_loss: 0.7566 - val_accuracy: 0.8529\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3830 - accuracy: 0.9881 - val_loss: 0.7800 - val_accuracy: 0.8586\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3774 - accuracy: 0.9926 - val_loss: 0.7986 - val_accuracy: 0.8620\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3742 - accuracy: 0.9941 - val_loss: 0.7592 - val_accuracy: 0.8597\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3716 - accuracy: 0.9963 - val_loss: 0.7600 - val_accuracy: 0.8631\n","{'loss': [0.5734934210777283, 0.5642747282981873, 0.5538340210914612, 0.5481605529785156, 0.5439102053642273, 0.5486099123954773, 0.5393462777137756, 0.5458744764328003, 0.5367524027824402, 0.5279592871665955, 0.526821494102478, 0.5244897603988647, 0.5255862474441528, 0.5251247882843018, 0.5151602029800415, 0.5175256133079529, 0.5124691128730774, 0.5108724236488342, 0.5072072148323059, 0.4980209469795227, 0.49669820070266724, 0.4964093565940857, 0.493197500705719, 0.48941856622695923, 0.4936307966709137, 0.488669753074646, 0.4826890528202057, 0.48998117446899414, 0.4813869297504425, 0.483946293592453, 0.4770689010620117, 0.4774751365184784, 0.47812962532043457, 0.47153910994529724, 0.4669691324234009, 0.4648355543613434, 0.46719786524772644, 0.4622758626937866, 0.45923325419425964, 0.45878466963768005, 0.4540661871433258, 0.45810866355895996, 0.46664151549339294, 0.44771379232406616, 0.4468371272087097, 0.44461721181869507, 0.47005903720855713, 0.45973876118659973, 0.444745808839798, 0.4416848421096802, 0.4348844587802887, 0.43576958775520325, 0.437226802110672, 0.4467194378376007, 0.43082427978515625, 0.4284655451774597, 0.4322432279586792, 0.42758411169052124, 0.43427014350891113, 0.4266417622566223, 0.42244964838027954, 0.42183220386505127, 0.417588472366333, 0.4200425148010254, 0.41509532928466797, 0.41369500756263733, 0.41190066933631897, 0.4101215600967407, 0.40824177861213684, 0.40934133529663086, 0.4062463939189911, 0.4049634039402008, 0.4049616754055023, 0.4013998210430145, 0.4087943732738495, 0.40003305673599243, 0.4002358019351959, 0.40280213952064514, 0.40235283970832825, 0.40935635566711426, 0.4036139249801636, 0.3970520794391632, 0.3939908742904663, 0.3920997679233551, 0.38722914457321167, 0.38678500056266785, 0.38651201128959656, 0.38658589124679565, 0.3834341764450073, 0.3854398727416992, 0.38135719299316406, 0.379978209733963, 0.37679216265678406, 0.37776029109954834, 0.37655067443847656, 0.37763556838035583, 0.3830229640007019, 0.37739473581314087, 0.37415122985839844, 0.371559202671051], 'accuracy': [0.9244481921195984, 0.9281267523765564, 0.934069037437439, 0.9354838728904724, 0.9419921040534973, 0.9368987083435059, 0.9385964870452881, 0.9323712587356567, 0.9385964870452881, 0.9499151110649109, 0.9485002756118774, 0.9462365508079529, 0.9459536075592041, 0.9487832188606262, 0.9533106684684753, 0.9499151110649109, 0.9538766145706177, 0.9567062854766846, 0.9538766145706177, 0.9620826244354248, 0.9632145166397095, 0.9623655676841736, 0.9626485705375671, 0.9646292924880981, 0.9615166783332825, 0.9606677889823914, 0.9657611846923828, 0.9632145166397095, 0.9666100740432739, 0.9623655676841736, 0.9688737988471985, 0.9649122953414917, 0.9640634059906006, 0.9700056314468384, 0.9728353023529053, 0.9728353023529053, 0.9683078527450562, 0.9739671945571899, 0.9765138626098633, 0.9734012484550476, 0.9773627519607544, 0.9731183052062988, 0.9623655676841736, 0.9784946441650391, 0.9767968058586121, 0.9784946441650391, 0.9606677889823914, 0.9668930172920227, 0.9767968058586121, 0.9784946441650391, 0.9816072583198547, 0.9787775874137878, 0.9790605306625366, 0.9736841917037964, 0.9816072583198547, 0.9844368696212769, 0.9779286980628967, 0.9838709831237793, 0.9779286980628967, 0.9813242554664612, 0.9830220937728882, 0.983305037021637, 0.9864176511764526, 0.983305037021637, 0.9858517050743103, 0.9867005944252014, 0.9875495433807373, 0.9878324866294861, 0.988964319229126, 0.9883984327316284, 0.9875495433807373, 0.9898132681846619, 0.9892473220825195, 0.9895302653312683, 0.9844368696212769, 0.9900962114334106, 0.988964319229126, 0.9864176511764526, 0.986983597278595, 0.9827390909194946, 0.9841539263725281, 0.9886813759803772, 0.9892473220825195, 0.9909451007843018, 0.9940577149391174, 0.9917939901351929, 0.9917939901351929, 0.9934917688369751, 0.9917939901351929, 0.9920769929885864, 0.9932088255882263, 0.9937747716903687, 0.9954725503921509, 0.9949066042900085, 0.9951896071434021, 0.9940577149391174, 0.9881154298782349, 0.992642879486084, 0.9940577149391174, 0.996321439743042], 'val_loss': [1.0172069072723389, 1.0079151391983032, 0.9968838691711426, 0.9872867465019226, 0.9711546301841736, 0.957842230796814, 0.9461904168128967, 0.9209463596343994, 0.9203768968582153, 0.894231379032135, 0.8933655619621277, 0.8589016795158386, 0.8400592803955078, 0.8236864805221558, 0.8071534037590027, 0.7789259552955627, 0.7633832693099976, 0.750598669052124, 0.7374791502952576, 0.7296366691589355, 0.7201293706893921, 0.7155640125274658, 0.7070521712303162, 0.7034851908683777, 0.7093397974967957, 0.7032340168952942, 0.6983214020729065, 0.6968832015991211, 0.7175490260124207, 0.7106965184211731, 0.7073473930358887, 0.720944344997406, 0.7031807899475098, 0.7081542015075684, 0.7264586687088013, 0.7123299837112427, 0.7069926261901855, 0.706674337387085, 0.7037147879600525, 0.707554042339325, 0.7139500379562378, 0.8142900466918945, 0.7080376148223877, 0.710363507270813, 0.7110389471054077, 0.7406467199325562, 0.7380337715148926, 0.7250205874443054, 0.7244030833244324, 0.7179304361343384, 0.7164579629898071, 0.7289197444915771, 0.7717629075050354, 0.7307762503623962, 0.7190243601799011, 0.7259108424186707, 0.7302637100219727, 0.7221363186836243, 0.720253050327301, 0.7233044505119324, 0.7477273344993591, 0.7243670225143433, 0.7259649634361267, 0.7790825366973877, 0.7393150925636292, 0.7474027872085571, 0.7306305766105652, 0.7320854663848877, 0.7392431497573853, 0.7675265669822693, 0.7329299449920654, 0.7504660487174988, 0.7344805002212524, 0.7378498315811157, 0.742824137210846, 0.7404579520225525, 0.7386197447776794, 0.7587554454803467, 0.7346644997596741, 0.7605859637260437, 0.7581883072853088, 0.770726203918457, 0.7430610060691833, 0.7724038362503052, 0.7415716052055359, 0.7480374574661255, 0.7470946907997131, 0.7483748197555542, 0.7651638388633728, 0.7667664289474487, 0.7549576163291931, 0.7572879791259766, 0.7525665163993835, 0.7663440704345703, 0.7747501730918884, 0.7566351294517517, 0.7800029516220093, 0.7986218929290771, 0.759175181388855, 0.7600485682487488], 'val_accuracy': [0.8122171759605408, 0.8178732991218567, 0.8223981857299805, 0.8178732991218567, 0.8212669491767883, 0.8235294222831726, 0.814479649066925, 0.8212669491767883, 0.8088235259056091, 0.8167420625686646, 0.8031674027442932, 0.8133484125137329, 0.8156108856201172, 0.8156108856201172, 0.8122171759605408, 0.8269230723381042, 0.8325791954994202, 0.8337104320526123, 0.8359728455543518, 0.831447958946228, 0.8359728455543518, 0.8450226187705994, 0.8472850918769836, 0.8495475053787231, 0.8665158152580261, 0.860859751701355, 0.8585972785949707, 0.8631221652030945, 0.8472850918769836, 0.8597285151481628, 0.8585972785949707, 0.8665158152580261, 0.8653846383094788, 0.8653846383094788, 0.8506787419319153, 0.860859751701355, 0.8619909286499023, 0.860859751701355, 0.8665158152580261, 0.8619909286499023, 0.8597285151481628, 0.8518099784851074, 0.8676470518112183, 0.860859751701355, 0.8653846383094788, 0.8619909286499023, 0.8450226187705994, 0.8653846383094788, 0.860859751701355, 0.860859751701355, 0.8665158152580261, 0.8597285151481628, 0.8540723919868469, 0.8540723919868469, 0.8665158152580261, 0.8585972785949707, 0.8597285151481628, 0.8642534017562866, 0.8699095249176025, 0.860859751701355, 0.8597285151481628, 0.8653846383094788, 0.8653846383094788, 0.8552036285400391, 0.8563348650932312, 0.860859751701355, 0.8619909286499023, 0.860859751701355, 0.8574660420417786, 0.8574660420417786, 0.8653846383094788, 0.8631221652030945, 0.8631221652030945, 0.860859751701355, 0.8552036285400391, 0.8585972785949707, 0.8642534017562866, 0.8585972785949707, 0.860859751701355, 0.8619909286499023, 0.8472850918769836, 0.8585972785949707, 0.8574660420417786, 0.860859751701355, 0.8642534017562866, 0.8585972785949707, 0.8540723919868469, 0.8585972785949707, 0.860859751701355, 0.8461538553237915, 0.8597285151481628, 0.8574660420417786, 0.8597285151481628, 0.8495475053787231, 0.8574660420417786, 0.8529411554336548, 0.8585972785949707, 0.8619909286499023, 0.8597285151481628, 0.8631221652030945]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 34ms/step - loss: 0.5746 - accuracy: 0.9235 - val_loss: 1.0064 - val_accuracy: 0.8409\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5532 - accuracy: 0.9380 - val_loss: 0.9999 - val_accuracy: 0.8430\n","Epoch 3/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5487 - accuracy: 0.9413 - val_loss: 0.9862 - val_accuracy: 0.8481\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5446 - accuracy: 0.9382 - val_loss: 0.9690 - val_accuracy: 0.8440\n","Epoch 5/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5395 - accuracy: 0.9424 - val_loss: 0.9541 - val_accuracy: 0.8409\n","Epoch 6/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5332 - accuracy: 0.9460 - val_loss: 0.9440 - val_accuracy: 0.8347\n","Epoch 7/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5324 - accuracy: 0.9452 - val_loss: 0.9166 - val_accuracy: 0.8388\n","Epoch 8/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5328 - accuracy: 0.9447 - val_loss: 0.9019 - val_accuracy: 0.8461\n","Epoch 9/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5280 - accuracy: 0.9457 - val_loss: 0.8866 - val_accuracy: 0.8337\n","Epoch 10/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5210 - accuracy: 0.9488 - val_loss: 0.8551 - val_accuracy: 0.8419\n","Epoch 11/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5188 - accuracy: 0.9519 - val_loss: 0.8289 - val_accuracy: 0.8409\n","Epoch 12/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5201 - accuracy: 0.9470 - val_loss: 0.8207 - val_accuracy: 0.8326\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5133 - accuracy: 0.9556 - val_loss: 0.7868 - val_accuracy: 0.8492\n","Epoch 14/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5235 - accuracy: 0.9478 - val_loss: 0.7717 - val_accuracy: 0.8450\n","Epoch 15/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5091 - accuracy: 0.9540 - val_loss: 0.7690 - val_accuracy: 0.8306\n","Epoch 16/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5120 - accuracy: 0.9509 - val_loss: 0.7297 - val_accuracy: 0.8523\n","Epoch 17/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5063 - accuracy: 0.9556 - val_loss: 0.7182 - val_accuracy: 0.8502\n","Epoch 18/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5071 - accuracy: 0.9540 - val_loss: 0.7069 - val_accuracy: 0.8574\n","Epoch 19/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5048 - accuracy: 0.9543 - val_loss: 0.7042 - val_accuracy: 0.8471\n","Epoch 20/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4975 - accuracy: 0.9589 - val_loss: 0.6974 - val_accuracy: 0.8492\n","Epoch 21/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4949 - accuracy: 0.9589 - val_loss: 0.7057 - val_accuracy: 0.8492\n","Epoch 22/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5010 - accuracy: 0.9553 - val_loss: 0.7007 - val_accuracy: 0.8512\n","Epoch 23/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5000 - accuracy: 0.9514 - val_loss: 0.6923 - val_accuracy: 0.8564\n","Epoch 24/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4867 - accuracy: 0.9633 - val_loss: 0.6993 - val_accuracy: 0.8564\n","Epoch 25/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4838 - accuracy: 0.9674 - val_loss: 0.6983 - val_accuracy: 0.8585\n","Epoch 26/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4876 - accuracy: 0.9599 - val_loss: 0.7048 - val_accuracy: 0.8533\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4799 - accuracy: 0.9646 - val_loss: 0.7065 - val_accuracy: 0.8554\n","Epoch 28/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4804 - accuracy: 0.9625 - val_loss: 0.7024 - val_accuracy: 0.8533\n","Epoch 29/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4845 - accuracy: 0.9584 - val_loss: 0.7114 - val_accuracy: 0.8595\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4737 - accuracy: 0.9672 - val_loss: 0.7104 - val_accuracy: 0.8554\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4825 - accuracy: 0.9628 - val_loss: 0.7151 - val_accuracy: 0.8595\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4753 - accuracy: 0.9680 - val_loss: 0.7169 - val_accuracy: 0.8585\n","Epoch 33/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4763 - accuracy: 0.9615 - val_loss: 0.7120 - val_accuracy: 0.8574\n","Epoch 34/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4710 - accuracy: 0.9656 - val_loss: 0.7214 - val_accuracy: 0.8585\n","Epoch 35/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4656 - accuracy: 0.9724 - val_loss: 0.7470 - val_accuracy: 0.8502\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4650 - accuracy: 0.9677 - val_loss: 0.7146 - val_accuracy: 0.8574\n","Epoch 37/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4628 - accuracy: 0.9700 - val_loss: 0.7229 - val_accuracy: 0.8564\n","Epoch 38/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4587 - accuracy: 0.9721 - val_loss: 0.7185 - val_accuracy: 0.8595\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4545 - accuracy: 0.9729 - val_loss: 0.7438 - val_accuracy: 0.8554\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4539 - accuracy: 0.9716 - val_loss: 0.7337 - val_accuracy: 0.8512\n","Epoch 41/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4515 - accuracy: 0.9721 - val_loss: 0.7232 - val_accuracy: 0.8605\n","Epoch 42/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4494 - accuracy: 0.9739 - val_loss: 0.7337 - val_accuracy: 0.8543\n","Epoch 43/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4504 - accuracy: 0.9700 - val_loss: 0.7812 - val_accuracy: 0.8450\n","Epoch 44/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4563 - accuracy: 0.9685 - val_loss: 0.7268 - val_accuracy: 0.8512\n","Epoch 45/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4431 - accuracy: 0.9791 - val_loss: 0.7316 - val_accuracy: 0.8574\n","Epoch 46/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4399 - accuracy: 0.9770 - val_loss: 0.7319 - val_accuracy: 0.8564\n","Epoch 47/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4451 - accuracy: 0.9749 - val_loss: 0.7558 - val_accuracy: 0.8440\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4518 - accuracy: 0.9690 - val_loss: 0.7314 - val_accuracy: 0.8574\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4382 - accuracy: 0.9775 - val_loss: 0.7370 - val_accuracy: 0.8543\n","Epoch 50/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4336 - accuracy: 0.9788 - val_loss: 0.7404 - val_accuracy: 0.8533\n","Epoch 51/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4348 - accuracy: 0.9783 - val_loss: 0.7550 - val_accuracy: 0.8461\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4354 - accuracy: 0.9749 - val_loss: 0.7382 - val_accuracy: 0.8533\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4292 - accuracy: 0.9819 - val_loss: 0.7410 - val_accuracy: 0.8564\n","Epoch 54/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4284 - accuracy: 0.9819 - val_loss: 0.7685 - val_accuracy: 0.8409\n","Epoch 55/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4313 - accuracy: 0.9780 - val_loss: 0.7463 - val_accuracy: 0.8564\n","Epoch 56/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4252 - accuracy: 0.9791 - val_loss: 0.7471 - val_accuracy: 0.8543\n","Epoch 57/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4258 - accuracy: 0.9809 - val_loss: 0.7657 - val_accuracy: 0.8430\n","Epoch 58/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4328 - accuracy: 0.9744 - val_loss: 0.7439 - val_accuracy: 0.8543\n","Epoch 59/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4210 - accuracy: 0.9783 - val_loss: 0.7532 - val_accuracy: 0.8512\n","Epoch 60/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4214 - accuracy: 0.9796 - val_loss: 0.7485 - val_accuracy: 0.8564\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4154 - accuracy: 0.9835 - val_loss: 0.7776 - val_accuracy: 0.8440\n","Epoch 62/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4202 - accuracy: 0.9809 - val_loss: 0.7511 - val_accuracy: 0.8502\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4196 - accuracy: 0.9809 - val_loss: 0.7587 - val_accuracy: 0.8512\n","Epoch 64/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4150 - accuracy: 0.9827 - val_loss: 0.7541 - val_accuracy: 0.8574\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4101 - accuracy: 0.9860 - val_loss: 0.7742 - val_accuracy: 0.8502\n","Epoch 66/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4132 - accuracy: 0.9832 - val_loss: 0.7615 - val_accuracy: 0.8492\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4092 - accuracy: 0.9842 - val_loss: 0.7571 - val_accuracy: 0.8461\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4045 - accuracy: 0.9855 - val_loss: 0.7577 - val_accuracy: 0.8543\n","Epoch 69/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4072 - accuracy: 0.9860 - val_loss: 0.7772 - val_accuracy: 0.8461\n","Epoch 70/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4092 - accuracy: 0.9827 - val_loss: 0.7552 - val_accuracy: 0.8523\n","Epoch 71/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4003 - accuracy: 0.9863 - val_loss: 0.7699 - val_accuracy: 0.8492\n","Epoch 72/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4010 - accuracy: 0.9866 - val_loss: 0.7682 - val_accuracy: 0.8461\n","Epoch 73/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3974 - accuracy: 0.9881 - val_loss: 0.7818 - val_accuracy: 0.8440\n","Epoch 74/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3989 - accuracy: 0.9873 - val_loss: 0.7751 - val_accuracy: 0.8523\n","Epoch 75/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3958 - accuracy: 0.9871 - val_loss: 0.7672 - val_accuracy: 0.8440\n","Epoch 76/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3944 - accuracy: 0.9884 - val_loss: 0.7678 - val_accuracy: 0.8492\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4001 - accuracy: 0.9855 - val_loss: 0.8145 - val_accuracy: 0.8368\n","Epoch 78/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3982 - accuracy: 0.9855 - val_loss: 0.7915 - val_accuracy: 0.8450\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3974 - accuracy: 0.9863 - val_loss: 0.7708 - val_accuracy: 0.8502\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3891 - accuracy: 0.9894 - val_loss: 0.7739 - val_accuracy: 0.8533\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3925 - accuracy: 0.9860 - val_loss: 0.7801 - val_accuracy: 0.8512\n","Epoch 82/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3830 - accuracy: 0.9922 - val_loss: 0.7795 - val_accuracy: 0.8554\n","Epoch 83/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3847 - accuracy: 0.9902 - val_loss: 0.7909 - val_accuracy: 0.8430\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3841 - accuracy: 0.9902 - val_loss: 0.7782 - val_accuracy: 0.8481\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3812 - accuracy: 0.9917 - val_loss: 0.7800 - val_accuracy: 0.8512\n","Epoch 86/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3811 - accuracy: 0.9915 - val_loss: 0.8242 - val_accuracy: 0.8419\n","Epoch 87/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3961 - accuracy: 0.9819 - val_loss: 0.8265 - val_accuracy: 0.8440\n","Epoch 88/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3991 - accuracy: 0.9811 - val_loss: 0.7929 - val_accuracy: 0.8430\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3815 - accuracy: 0.9912 - val_loss: 0.7954 - val_accuracy: 0.8533\n","Epoch 90/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3781 - accuracy: 0.9912 - val_loss: 0.7971 - val_accuracy: 0.8461\n","Epoch 91/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3768 - accuracy: 0.9910 - val_loss: 0.8039 - val_accuracy: 0.8492\n","Epoch 92/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3709 - accuracy: 0.9953 - val_loss: 0.7955 - val_accuracy: 0.8419\n","Epoch 93/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3803 - accuracy: 0.9894 - val_loss: 0.8019 - val_accuracy: 0.8512\n","Epoch 94/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3702 - accuracy: 0.9943 - val_loss: 0.7944 - val_accuracy: 0.8564\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3714 - accuracy: 0.9928 - val_loss: 0.7968 - val_accuracy: 0.8430\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3702 - accuracy: 0.9925 - val_loss: 0.8187 - val_accuracy: 0.8430\n","Epoch 97/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3683 - accuracy: 0.9935 - val_loss: 0.7997 - val_accuracy: 0.8461\n","Epoch 98/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3653 - accuracy: 0.9953 - val_loss: 0.8181 - val_accuracy: 0.8492\n","Epoch 99/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3737 - accuracy: 0.9884 - val_loss: 0.8046 - val_accuracy: 0.8461\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3721 - accuracy: 0.9920 - val_loss: 0.8481 - val_accuracy: 0.8409\n","{'loss': [0.5745834708213806, 0.553170919418335, 0.5487015247344971, 0.5446293950080872, 0.5394675731658936, 0.5331594347953796, 0.532364010810852, 0.5328445434570312, 0.5280038714408875, 0.5209501385688782, 0.5188076496124268, 0.5201064348220825, 0.5133084654808044, 0.523495614528656, 0.5090985298156738, 0.5120319128036499, 0.5062585473060608, 0.50713711977005, 0.5048138499259949, 0.49752911925315857, 0.49485504627227783, 0.5009678602218628, 0.4999755620956421, 0.4867089092731476, 0.48380425572395325, 0.48756885528564453, 0.47989434003829956, 0.48037609457969666, 0.48445162177085876, 0.47373834252357483, 0.4825229048728943, 0.4752817451953888, 0.47632330656051636, 0.4709535837173462, 0.46559998393058777, 0.4649874269962311, 0.4628273546695709, 0.4586721658706665, 0.45453524589538574, 0.45391911268234253, 0.45147374272346497, 0.44939184188842773, 0.45035284757614136, 0.45626166462898254, 0.44312238693237305, 0.43988028168678284, 0.44507238268852234, 0.451777845621109, 0.4381590187549591, 0.43359407782554626, 0.4348067343235016, 0.4353965222835541, 0.42922472953796387, 0.42835676670074463, 0.4313073456287384, 0.42519411444664, 0.4257586598396301, 0.43281814455986023, 0.420956015586853, 0.4214246869087219, 0.4153999090194702, 0.4201733469963074, 0.4195866286754608, 0.415021687746048, 0.41011521220207214, 0.4132493734359741, 0.4092022478580475, 0.40446338057518005, 0.407238245010376, 0.4091973602771759, 0.40025612711906433, 0.4009948968887329, 0.39741936326026917, 0.3988777697086334, 0.39582157135009766, 0.39443206787109375, 0.4000891447067261, 0.39823007583618164, 0.39741870760917664, 0.38910743594169617, 0.3925348222255707, 0.3829837441444397, 0.3847019672393799, 0.384065181016922, 0.3811936676502228, 0.38109928369522095, 0.3960796296596527, 0.3990604877471924, 0.3814750611782074, 0.37810903787612915, 0.3768391013145447, 0.370895653963089, 0.3802890181541443, 0.37016522884368896, 0.37140023708343506, 0.3701697885990143, 0.3682733178138733, 0.3652763366699219, 0.3737297058105469, 0.372144490480423], 'accuracy': [0.923514187335968, 0.9379844665527344, 0.9413436651229858, 0.9382429122924805, 0.9423772692680359, 0.9459948539733887, 0.9452196359634399, 0.9447028636932373, 0.9457364082336426, 0.9488372206687927, 0.9519379734992981, 0.947028398513794, 0.9555555582046509, 0.9478036165237427, 0.9540051817893982, 0.950904369354248, 0.9555555582046509, 0.9540051817893982, 0.9542635679244995, 0.9589147567749023, 0.9589147567749023, 0.9552971720695496, 0.9514212012290955, 0.9633074998855591, 0.9674418568611145, 0.9599483013153076, 0.9645994901657104, 0.9625322818756104, 0.9583979249000549, 0.9671834707260132, 0.9627906680107117, 0.9679586291313171, 0.9614987373352051, 0.9656330943107605, 0.9723514318466187, 0.9677002429962158, 0.9700258374214172, 0.9720930457115173, 0.9728682041168213, 0.9715762138366699, 0.9720930457115173, 0.9739018082618713, 0.9700258374214172, 0.9684754610061646, 0.9790697693824768, 0.9770025610923767, 0.9749354124069214, 0.9689922332763672, 0.9775193929672241, 0.9788113832473755, 0.9782945513725281, 0.9749354124069214, 0.9819121360778809, 0.9819121360778809, 0.9780361652374268, 0.9790697693824768, 0.9808785319328308, 0.974418580532074, 0.9782945513725281, 0.9795865416526794, 0.9834625124931335, 0.9808785319328308, 0.9808785319328308, 0.9826873540878296, 0.9860464930534363, 0.9832041263580322, 0.9842377305030823, 0.9855297207832336, 0.9860464930534363, 0.9826873540878296, 0.9863049387931824, 0.9865633249282837, 0.9881137013435364, 0.9873384833335876, 0.9870800971984863, 0.9883720874786377, 0.9855297207832336, 0.9855297207832336, 0.9863049387931824, 0.9894056916236877, 0.9860464930534363, 0.9922480583190918, 0.9901808500289917, 0.9901808500289917, 0.9917312860488892, 0.9914728403091431, 0.9819121360778809, 0.9811369776725769, 0.9912144541740417, 0.9912144541740417, 0.9909560680389404, 0.9953488111495972, 0.9894056916236877, 0.9943152666091919, 0.9927648305892944, 0.9925064444541931, 0.9935400485992432, 0.9953488111495972, 0.9883720874786377, 0.9919896721839905], 'val_loss': [1.0063581466674805, 0.9998888373374939, 0.9861575961112976, 0.9689640402793884, 0.9540941715240479, 0.9439761638641357, 0.9165803790092468, 0.9018536806106567, 0.886646568775177, 0.8551455140113831, 0.8288823366165161, 0.820694625377655, 0.7867966294288635, 0.7717060446739197, 0.7689530849456787, 0.7296760678291321, 0.718233048915863, 0.7068763375282288, 0.70424884557724, 0.697390079498291, 0.7057188749313354, 0.7007414102554321, 0.6923117637634277, 0.699347972869873, 0.6982908248901367, 0.7047735452651978, 0.7065229415893555, 0.7024046778678894, 0.7114391922950745, 0.7103749513626099, 0.7151336073875427, 0.7169007658958435, 0.7119883894920349, 0.7213628888130188, 0.7470335364341736, 0.71462482213974, 0.722943902015686, 0.7184568047523499, 0.7438333630561829, 0.7337290644645691, 0.7232338190078735, 0.7336793541908264, 0.7812190055847168, 0.726759672164917, 0.7316155433654785, 0.7319197654724121, 0.7558156251907349, 0.7313747406005859, 0.7369595170021057, 0.7403771281242371, 0.7550399303436279, 0.7381996512413025, 0.7410476207733154, 0.7685108780860901, 0.7463339567184448, 0.7471387982368469, 0.7656801342964172, 0.7439311146736145, 0.7532355189323425, 0.7484797239303589, 0.7776318192481995, 0.7511401176452637, 0.7587457895278931, 0.7540794014930725, 0.7741852402687073, 0.7614594101905823, 0.7571057677268982, 0.757695198059082, 0.7772371172904968, 0.7552059292793274, 0.7699283361434937, 0.7682010531425476, 0.7817611694335938, 0.7751011848449707, 0.7671509385108948, 0.767815113067627, 0.8144632577896118, 0.7915095686912537, 0.7708456516265869, 0.7739169001579285, 0.7800602316856384, 0.7794853448867798, 0.7909433245658875, 0.7782360911369324, 0.7800341248512268, 0.824217677116394, 0.8264724016189575, 0.7929423451423645, 0.7954418659210205, 0.7971444129943848, 0.8038514256477356, 0.7955055832862854, 0.8019487261772156, 0.7943757176399231, 0.7967739105224609, 0.8186691999435425, 0.7997081279754639, 0.818096399307251, 0.8045633435249329, 0.8481190800666809], 'val_accuracy': [0.8409090638160706, 0.8429751992225647, 0.8481404781341553, 0.8440082669258118, 0.8409090638160706, 0.8347107172012329, 0.8388429880142212, 0.8460744023323059, 0.8336777091026306, 0.8419421315193176, 0.8409090638160706, 0.8326446413993835, 0.8491735458374023, 0.8450413346290588, 0.8305785059928894, 0.8522727489471436, 0.8502066135406494, 0.8574380278587341, 0.8471074104309082, 0.8491735458374023, 0.8491735458374023, 0.8512396812438965, 0.8564049601554871, 0.8564049601554871, 0.8584710955619812, 0.8533057570457458, 0.85537189245224, 0.8533057570457458, 0.8595041036605835, 0.85537189245224, 0.8595041036605835, 0.8584710955619812, 0.8574380278587341, 0.8584710955619812, 0.8502066135406494, 0.8574380278587341, 0.8564049601554871, 0.8595041036605835, 0.85537189245224, 0.8512396812438965, 0.8605371713638306, 0.8543388247489929, 0.8450413346290588, 0.8512396812438965, 0.8574380278587341, 0.8564049601554871, 0.8440082669258118, 0.8574380278587341, 0.8543388247489929, 0.8533057570457458, 0.8460744023323059, 0.8533057570457458, 0.8564049601554871, 0.8409090638160706, 0.8564049601554871, 0.8543388247489929, 0.8429751992225647, 0.8543388247489929, 0.8512396812438965, 0.8564049601554871, 0.8440082669258118, 0.8502066135406494, 0.8512396812438965, 0.8574380278587341, 0.8502066135406494, 0.8491735458374023, 0.8460744023323059, 0.8543388247489929, 0.8460744023323059, 0.8522727489471436, 0.8491735458374023, 0.8460744023323059, 0.8440082669258118, 0.8522727489471436, 0.8440082669258118, 0.8491735458374023, 0.836776852607727, 0.8450413346290588, 0.8502066135406494, 0.8533057570457458, 0.8512396812438965, 0.85537189245224, 0.8429751992225647, 0.8481404781341553, 0.8512396812438965, 0.8419421315193176, 0.8440082669258118, 0.8429751992225647, 0.8533057570457458, 0.8460744023323059, 0.8491735458374023, 0.8419421315193176, 0.8512396812438965, 0.8564049601554871, 0.8429751992225647, 0.8429751992225647, 0.8460744023323059, 0.8491735458374023, 0.8460744023323059, 0.8409090638160706]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.4598 - accuracy: 0.9489"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 3s 33ms/step - loss: 0.4581 - accuracy: 0.9491 - val_loss: 0.9283 - val_accuracy: 0.8459\n","Epoch 2/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4158 - accuracy: 0.9725 - val_loss: 0.9289 - val_accuracy: 0.8060\n","Epoch 3/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4053 - accuracy: 0.9793 - val_loss: 0.9158 - val_accuracy: 0.8114\n","Epoch 4/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4011 - accuracy: 0.9817 - val_loss: 0.8887 - val_accuracy: 0.8362\n","Epoch 5/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4011 - accuracy: 0.9795 - val_loss: 0.8821 - val_accuracy: 0.8276\n","Epoch 6/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3921 - accuracy: 0.9863 - val_loss: 0.8560 - val_accuracy: 0.8373\n","Epoch 7/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3894 - accuracy: 0.9857 - val_loss: 0.8510 - val_accuracy: 0.8244\n","Epoch 8/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3937 - accuracy: 0.9855 - val_loss: 0.8492 - val_accuracy: 0.7823\n","Epoch 9/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3876 - accuracy: 0.9863 - val_loss: 0.7975 - val_accuracy: 0.8384\n","Epoch 10/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3922 - accuracy: 0.9841 - val_loss: 0.7955 - val_accuracy: 0.8233\n","Epoch 11/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3827 - accuracy: 0.9906 - val_loss: 0.7692 - val_accuracy: 0.8211\n","Epoch 12/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3805 - accuracy: 0.9892 - val_loss: 0.7486 - val_accuracy: 0.8287\n","Epoch 13/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3798 - accuracy: 0.9914 - val_loss: 0.7688 - val_accuracy: 0.7909\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3803 - accuracy: 0.9895 - val_loss: 0.6952 - val_accuracy: 0.8416\n","Epoch 15/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3751 - accuracy: 0.9906 - val_loss: 0.6768 - val_accuracy: 0.8502\n","Epoch 16/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3779 - accuracy: 0.9900 - val_loss: 0.7073 - val_accuracy: 0.8211\n","Epoch 17/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3725 - accuracy: 0.9919 - val_loss: 0.6531 - val_accuracy: 0.8567\n","Epoch 18/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3711 - accuracy: 0.9925 - val_loss: 0.6381 - val_accuracy: 0.8588\n","Epoch 19/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3732 - accuracy: 0.9914 - val_loss: 0.6818 - val_accuracy: 0.8481\n","Epoch 20/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3733 - accuracy: 0.9916 - val_loss: 0.6305 - val_accuracy: 0.8599\n","Epoch 21/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3668 - accuracy: 0.9938 - val_loss: 0.6219 - val_accuracy: 0.8653\n","Epoch 22/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3758 - accuracy: 0.9884 - val_loss: 0.6202 - val_accuracy: 0.8793\n","Epoch 23/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3684 - accuracy: 0.9916 - val_loss: 0.6160 - val_accuracy: 0.8825\n","Epoch 24/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3722 - accuracy: 0.9906 - val_loss: 0.6301 - val_accuracy: 0.8728\n","Epoch 25/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3686 - accuracy: 0.9906 - val_loss: 0.6007 - val_accuracy: 0.8933\n","Epoch 26/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3625 - accuracy: 0.9946 - val_loss: 0.6040 - val_accuracy: 0.8922\n","Epoch 27/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3599 - accuracy: 0.9949 - val_loss: 0.6073 - val_accuracy: 0.8987\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3605 - accuracy: 0.9941 - val_loss: 0.6734 - val_accuracy: 0.8685\n","Epoch 29/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3586 - accuracy: 0.9949 - val_loss: 0.6265 - val_accuracy: 0.8987\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3598 - accuracy: 0.9946 - val_loss: 0.6282 - val_accuracy: 0.8944\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3576 - accuracy: 0.9941 - val_loss: 0.6131 - val_accuracy: 0.8987\n","Epoch 32/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3553 - accuracy: 0.9960 - val_loss: 0.6147 - val_accuracy: 0.9052\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3535 - accuracy: 0.9960 - val_loss: 0.6281 - val_accuracy: 0.9009\n","Epoch 34/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3555 - accuracy: 0.9946 - val_loss: 0.6136 - val_accuracy: 0.9062\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3546 - accuracy: 0.9962 - val_loss: 0.6217 - val_accuracy: 0.9019\n","Epoch 36/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3496 - accuracy: 0.9962 - val_loss: 0.6201 - val_accuracy: 0.8987\n","Epoch 37/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3503 - accuracy: 0.9962 - val_loss: 0.6264 - val_accuracy: 0.9030\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3483 - accuracy: 0.9978 - val_loss: 0.6283 - val_accuracy: 0.9009\n","Epoch 39/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3495 - accuracy: 0.9957 - val_loss: 0.6270 - val_accuracy: 0.9009\n","Epoch 40/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3467 - accuracy: 0.9976 - val_loss: 0.6245 - val_accuracy: 0.9019\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3487 - accuracy: 0.9970 - val_loss: 0.6256 - val_accuracy: 0.9009\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3489 - accuracy: 0.9970 - val_loss: 0.6285 - val_accuracy: 0.9041\n","Epoch 43/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3445 - accuracy: 0.9968 - val_loss: 0.6391 - val_accuracy: 0.8922\n","Epoch 44/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3440 - accuracy: 0.9968 - val_loss: 0.6559 - val_accuracy: 0.8966\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3467 - accuracy: 0.9954 - val_loss: 0.6311 - val_accuracy: 0.9009\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3412 - accuracy: 0.9987 - val_loss: 0.6426 - val_accuracy: 0.9009\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3456 - accuracy: 0.9970 - val_loss: 0.6679 - val_accuracy: 0.8890\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3416 - accuracy: 0.9981 - val_loss: 0.6374 - val_accuracy: 0.8998\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3396 - accuracy: 0.9981 - val_loss: 0.6299 - val_accuracy: 0.8998\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3431 - accuracy: 0.9957 - val_loss: 0.6376 - val_accuracy: 0.8998\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3384 - accuracy: 0.9976 - val_loss: 0.6637 - val_accuracy: 0.8901\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3390 - accuracy: 0.9973 - val_loss: 0.6425 - val_accuracy: 0.8966\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3347 - accuracy: 0.9987 - val_loss: 0.6341 - val_accuracy: 0.8998\n","Epoch 54/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3408 - accuracy: 0.9970 - val_loss: 0.6457 - val_accuracy: 0.8976\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3358 - accuracy: 0.9992 - val_loss: 0.6475 - val_accuracy: 0.8987\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3333 - accuracy: 0.9989 - val_loss: 0.6536 - val_accuracy: 0.8933\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3315 - accuracy: 0.9992 - val_loss: 0.6439 - val_accuracy: 0.8998\n","Epoch 58/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3310 - accuracy: 0.9995 - val_loss: 0.6504 - val_accuracy: 0.8998\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3308 - accuracy: 0.9995 - val_loss: 0.6491 - val_accuracy: 0.9009\n","Epoch 60/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3326 - accuracy: 0.9989 - val_loss: 0.6461 - val_accuracy: 0.9009\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3297 - accuracy: 0.9989 - val_loss: 0.6460 - val_accuracy: 0.8966\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3287 - accuracy: 0.9987 - val_loss: 0.6587 - val_accuracy: 0.9009\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3271 - accuracy: 0.9992 - val_loss: 0.6513 - val_accuracy: 0.8966\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3261 - accuracy: 0.9995 - val_loss: 0.6482 - val_accuracy: 0.9041\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3264 - accuracy: 0.9995 - val_loss: 0.6491 - val_accuracy: 0.8976\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3247 - accuracy: 0.9997 - val_loss: 0.6470 - val_accuracy: 0.9019\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3269 - accuracy: 0.9987 - val_loss: 0.6542 - val_accuracy: 0.8966\n","Epoch 68/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3241 - accuracy: 0.9995 - val_loss: 0.6495 - val_accuracy: 0.8987\n","Epoch 69/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3237 - accuracy: 0.9995 - val_loss: 0.6675 - val_accuracy: 0.8944\n","Epoch 70/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3255 - accuracy: 0.9989 - val_loss: 0.6533 - val_accuracy: 0.9009\n","Epoch 71/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3247 - accuracy: 0.9992 - val_loss: 0.6547 - val_accuracy: 0.9009\n","Epoch 72/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3212 - accuracy: 0.9995 - val_loss: 0.6689 - val_accuracy: 0.8955\n","Epoch 73/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3210 - accuracy: 0.9995 - val_loss: 0.6551 - val_accuracy: 0.8998\n","Epoch 74/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3202 - accuracy: 0.9995 - val_loss: 0.6678 - val_accuracy: 0.8944\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3190 - accuracy: 0.9997 - val_loss: 0.6660 - val_accuracy: 0.8976\n","Epoch 76/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3188 - accuracy: 0.9995 - val_loss: 0.6588 - val_accuracy: 0.8966\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3185 - accuracy: 0.9992 - val_loss: 0.6802 - val_accuracy: 0.8944\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3180 - accuracy: 0.9997 - val_loss: 0.6626 - val_accuracy: 0.8998\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3167 - accuracy: 0.9995 - val_loss: 0.6663 - val_accuracy: 0.8987\n","Epoch 80/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3166 - accuracy: 0.9997 - val_loss: 0.6703 - val_accuracy: 0.8933\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3150 - accuracy: 0.9997 - val_loss: 0.6624 - val_accuracy: 0.8966\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3150 - accuracy: 0.9995 - val_loss: 0.6627 - val_accuracy: 0.8966\n","Epoch 83/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3139 - accuracy: 0.9997 - val_loss: 0.6677 - val_accuracy: 0.8955\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3138 - accuracy: 0.9997 - val_loss: 0.6631 - val_accuracy: 0.8966\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3119 - accuracy: 0.9997 - val_loss: 0.6733 - val_accuracy: 0.8912\n","Epoch 86/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3119 - accuracy: 0.9995 - val_loss: 0.6653 - val_accuracy: 0.9009\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3135 - accuracy: 0.9992 - val_loss: 0.6817 - val_accuracy: 0.8879\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3206 - accuracy: 0.9970 - val_loss: 0.6814 - val_accuracy: 0.8944\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3126 - accuracy: 0.9992 - val_loss: 0.6638 - val_accuracy: 0.8976\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3101 - accuracy: 0.9997 - val_loss: 0.6825 - val_accuracy: 0.8858\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3104 - accuracy: 0.9997 - val_loss: 0.6733 - val_accuracy: 0.8966\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3095 - accuracy: 0.9995 - val_loss: 0.6676 - val_accuracy: 0.8976\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3072 - accuracy: 0.9997 - val_loss: 0.6856 - val_accuracy: 0.8879\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3067 - accuracy: 0.9997 - val_loss: 0.6840 - val_accuracy: 0.8825\n","Epoch 95/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3066 - accuracy: 0.9997 - val_loss: 0.6799 - val_accuracy: 0.8955\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3052 - accuracy: 0.9995 - val_loss: 0.6706 - val_accuracy: 0.8966\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3047 - accuracy: 0.9997 - val_loss: 0.6724 - val_accuracy: 0.8922\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3039 - accuracy: 0.9997 - val_loss: 0.6764 - val_accuracy: 0.8944\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3040 - accuracy: 0.9997 - val_loss: 0.7111 - val_accuracy: 0.8955\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3039 - accuracy: 0.9997 - val_loss: 0.6731 - val_accuracy: 0.8966\n","{'loss': [0.45814162492752075, 0.4157848656177521, 0.4053419232368469, 0.40105998516082764, 0.40108197927474976, 0.39214572310447693, 0.38944751024246216, 0.3937278091907501, 0.38756245374679565, 0.39221152663230896, 0.382670134305954, 0.38049039244651794, 0.3798361122608185, 0.3802640438079834, 0.3751418888568878, 0.3779192566871643, 0.37247344851493835, 0.3711419999599457, 0.37315845489501953, 0.3733050227165222, 0.36681488156318665, 0.3757944107055664, 0.3684263229370117, 0.3721959590911865, 0.3685891926288605, 0.3624882400035858, 0.35985440015792847, 0.36045998334884644, 0.3585567772388458, 0.3598189055919647, 0.35759174823760986, 0.3552878797054291, 0.35349103808403015, 0.35547250509262085, 0.3546296954154968, 0.3495602309703827, 0.3502500355243683, 0.34825122356414795, 0.34953176975250244, 0.34668946266174316, 0.3486913740634918, 0.34894582629203796, 0.3445310592651367, 0.3439869284629822, 0.34672582149505615, 0.3412315845489502, 0.34562721848487854, 0.3416004776954651, 0.33963170647621155, 0.34312736988067627, 0.3383508026599884, 0.3390195965766907, 0.3346840739250183, 0.3408149480819702, 0.33578547835350037, 0.333347886800766, 0.3314778506755829, 0.33097678422927856, 0.3307570219039917, 0.3325882852077484, 0.32969072461128235, 0.3287384808063507, 0.3271293640136719, 0.326119989156723, 0.3264286518096924, 0.3246942460536957, 0.3269227147102356, 0.324139803647995, 0.32371360063552856, 0.3254959285259247, 0.32467055320739746, 0.3212112486362457, 0.32097989320755005, 0.320199191570282, 0.3189779222011566, 0.3187796175479889, 0.3184575140476227, 0.3180425763130188, 0.3167000114917755, 0.3165648877620697, 0.3150078058242798, 0.3150128722190857, 0.3139394521713257, 0.31380265951156616, 0.3118530809879303, 0.3119446635246277, 0.3135358989238739, 0.3205832839012146, 0.31255850195884705, 0.3100816607475281, 0.31041795015335083, 0.30950430035591125, 0.3072284162044525, 0.3066888749599457, 0.30664530396461487, 0.30520933866500854, 0.3046794533729553, 0.3039083778858185, 0.3039921522140503, 0.3039499819278717], 'accuracy': [0.9490840435028076, 0.9725215435028076, 0.9792564511299133, 0.9816810488700867, 0.9795258641242981, 0.9862607717514038, 0.985722005367279, 0.9854525923728943, 0.9862607717514038, 0.9841055870056152, 0.990571141242981, 0.9892241358757019, 0.9913793206214905, 0.9894935488700867, 0.990571141242981, 0.9900323152542114, 0.9919180870056152, 0.9924569129943848, 0.9913793206214905, 0.9916487336158752, 0.993803858757019, 0.9884159564971924, 0.9916487336158752, 0.990571141242981, 0.990571141242981, 0.9946120977401733, 0.9948814511299133, 0.9940732717514038, 0.9948814511299133, 0.9946120977401733, 0.9940732717514038, 0.9959590435028076, 0.9959590435028076, 0.9946120977401733, 0.9962284564971924, 0.9962284564971924, 0.9962284564971924, 0.9978448152542114, 0.9956896305084229, 0.9975754022598267, 0.9970366358757019, 0.9970366358757019, 0.9967672228813171, 0.9967672228813171, 0.9954202771186829, 0.998652994632721, 0.9970366358757019, 0.9981142282485962, 0.9981142282485962, 0.9956896305084229, 0.9975754022598267, 0.9973060488700867, 0.998652994632721, 0.9970366358757019, 0.9991918206214905, 0.9989224076271057, 0.9991918206214905, 0.9994612336158752, 0.9994612336158752, 0.9989224076271057, 0.9989224076271057, 0.998652994632721, 0.9991918206214905, 0.9994612336158752, 0.9994612336158752, 0.9997305870056152, 0.998652994632721, 0.9994612336158752, 0.9994612336158752, 0.9989224076271057, 0.9991918206214905, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9997305870056152, 0.9994612336158752, 0.9991918206214905, 0.9997305870056152, 0.9994612336158752, 0.9997305870056152, 0.9997305870056152, 0.9994612336158752, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152, 0.9994612336158752, 0.9991918206214905, 0.9970366358757019, 0.9991918206214905, 0.9997305870056152, 0.9997305870056152, 0.9994612336158752, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152, 0.9994612336158752, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152], 'val_loss': [0.9283098578453064, 0.9288628101348877, 0.915840208530426, 0.8886802792549133, 0.8820575475692749, 0.8559733629226685, 0.8509684801101685, 0.8491563200950623, 0.7974838018417358, 0.7955468893051147, 0.7692459225654602, 0.7486499547958374, 0.7688430547714233, 0.6951565146446228, 0.676811158657074, 0.707328736782074, 0.6531221270561218, 0.6381340026855469, 0.6818084716796875, 0.6305414438247681, 0.621917188167572, 0.6201981902122498, 0.615950882434845, 0.6301462054252625, 0.6007058620452881, 0.6039848327636719, 0.6073216795921326, 0.6733942627906799, 0.6265305280685425, 0.628182590007782, 0.6130782961845398, 0.6146805286407471, 0.6281342506408691, 0.6135609745979309, 0.6216806173324585, 0.6200584769248962, 0.6263577938079834, 0.6283313632011414, 0.6269527077674866, 0.6245326399803162, 0.6256023645401001, 0.6284781098365784, 0.6390724182128906, 0.6559127569198608, 0.6311359405517578, 0.642611026763916, 0.6678569316864014, 0.6374115347862244, 0.6298624277114868, 0.6376083493232727, 0.6636760830879211, 0.6425340175628662, 0.6340572237968445, 0.6456878185272217, 0.6475399136543274, 0.653645396232605, 0.6439041495323181, 0.6503787040710449, 0.6491148471832275, 0.6461166739463806, 0.6459818482398987, 0.6586968898773193, 0.6512865424156189, 0.6482467651367188, 0.6491259932518005, 0.6470164060592651, 0.6541926860809326, 0.6495417356491089, 0.667451798915863, 0.6533361673355103, 0.6547399759292603, 0.6688531041145325, 0.655089259147644, 0.6678098440170288, 0.6660080552101135, 0.6587644219398499, 0.6801783442497253, 0.6625675559043884, 0.6663418412208557, 0.6702916622161865, 0.6623942255973816, 0.6626706719398499, 0.6677401065826416, 0.6631357669830322, 0.6733436584472656, 0.6653378009796143, 0.6816735863685608, 0.6814184784889221, 0.6637820601463318, 0.6824759244918823, 0.6732661724090576, 0.6676055788993835, 0.685571551322937, 0.6839956641197205, 0.679864227771759, 0.6706410050392151, 0.6723899841308594, 0.6763931512832642, 0.7111462354660034, 0.6730537414550781], 'val_accuracy': [0.8459051847457886, 0.806034505367279, 0.8114224076271057, 0.8362069129943848, 0.8275862336158752, 0.837284505367279, 0.8243534564971924, 0.7823275923728943, 0.8383620977401733, 0.8232758641242981, 0.8211206793785095, 0.8286637663841248, 0.7909482717514038, 0.8415948152542114, 0.850215494632721, 0.8211206793785095, 0.8566810488700867, 0.8588362336158752, 0.8480603694915771, 0.8599137663841248, 0.8653017282485962, 0.8793103694915771, 0.8825430870056152, 0.8728448152542114, 0.8933189511299133, 0.892241358757019, 0.8987069129943848, 0.868534505367279, 0.8987069129943848, 0.8943965435028076, 0.8987069129943848, 0.9051724076271057, 0.9008620977401733, 0.90625, 0.9019396305084229, 0.8987069129943848, 0.9030172228813171, 0.9008620977401733, 0.9008620977401733, 0.9019396305084229, 0.9008620977401733, 0.9040948152542114, 0.892241358757019, 0.8965517282485962, 0.9008620977401733, 0.9008620977401733, 0.889008641242981, 0.899784505367279, 0.899784505367279, 0.899784505367279, 0.8900862336158752, 0.8965517282485962, 0.899784505367279, 0.8976293206214905, 0.8987069129943848, 0.8933189511299133, 0.899784505367279, 0.899784505367279, 0.9008620977401733, 0.9008620977401733, 0.8965517282485962, 0.9008620977401733, 0.8965517282485962, 0.9040948152542114, 0.8976293206214905, 0.9019396305084229, 0.8965517282485962, 0.8987069129943848, 0.8943965435028076, 0.9008620977401733, 0.9008620977401733, 0.8954741358757019, 0.899784505367279, 0.8943965435028076, 0.8976293206214905, 0.8965517282485962, 0.8943965435028076, 0.899784505367279, 0.8987069129943848, 0.8933189511299133, 0.8965517282485962, 0.8965517282485962, 0.8954741358757019, 0.8965517282485962, 0.8911637663841248, 0.9008620977401733, 0.8879310488700867, 0.8943965435028076, 0.8976293206214905, 0.8857758641242981, 0.8965517282485962, 0.8976293206214905, 0.8879310488700867, 0.8825430870056152, 0.8954741358757019, 0.8965517282485962, 0.892241358757019, 0.8943965435028076, 0.8954741358757019, 0.8965517282485962]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.4489 - accuracy: 0.9576"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 5s 39ms/step - loss: 0.4489 - accuracy: 0.9576 - val_loss: 0.9417 - val_accuracy: 0.8133\n","Epoch 2/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4142 - accuracy: 0.9745 - val_loss: 0.9269 - val_accuracy: 0.8201\n","Epoch 3/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4089 - accuracy: 0.9762 - val_loss: 0.9169 - val_accuracy: 0.8201\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4078 - accuracy: 0.9748 - val_loss: 0.9019 - val_accuracy: 0.8213\n","Epoch 5/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4053 - accuracy: 0.9782 - val_loss: 0.8991 - val_accuracy: 0.8043\n","Epoch 6/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4055 - accuracy: 0.9776 - val_loss: 0.8734 - val_accuracy: 0.8269\n","Epoch 7/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3969 - accuracy: 0.9825 - val_loss: 0.8675 - val_accuracy: 0.8054\n","Epoch 8/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4010 - accuracy: 0.9793 - val_loss: 0.8400 - val_accuracy: 0.8224\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3919 - accuracy: 0.9850 - val_loss: 0.8169 - val_accuracy: 0.8235\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3934 - accuracy: 0.9839 - val_loss: 0.7927 - val_accuracy: 0.8235\n","Epoch 11/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3919 - accuracy: 0.9853 - val_loss: 0.7973 - val_accuracy: 0.8054\n","Epoch 12/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3858 - accuracy: 0.9864 - val_loss: 0.7656 - val_accuracy: 0.8348\n","Epoch 13/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3854 - accuracy: 0.9884 - val_loss: 0.7437 - val_accuracy: 0.8326\n","Epoch 14/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3818 - accuracy: 0.9898 - val_loss: 0.7472 - val_accuracy: 0.8156\n","Epoch 15/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3824 - accuracy: 0.9907 - val_loss: 0.7145 - val_accuracy: 0.8405\n","Epoch 16/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3791 - accuracy: 0.9909 - val_loss: 0.7052 - val_accuracy: 0.8371\n","Epoch 17/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3814 - accuracy: 0.9884 - val_loss: 0.6956 - val_accuracy: 0.8326\n","Epoch 18/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3789 - accuracy: 0.9895 - val_loss: 0.6874 - val_accuracy: 0.8371\n","Epoch 19/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3783 - accuracy: 0.9895 - val_loss: 0.6630 - val_accuracy: 0.8450\n","Epoch 20/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3731 - accuracy: 0.9912 - val_loss: 0.6671 - val_accuracy: 0.8484\n","Epoch 21/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3813 - accuracy: 0.9878 - val_loss: 0.6634 - val_accuracy: 0.8495\n","Epoch 22/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3805 - accuracy: 0.9875 - val_loss: 0.6317 - val_accuracy: 0.8609\n","Epoch 23/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3710 - accuracy: 0.9915 - val_loss: 0.6412 - val_accuracy: 0.8575\n","Epoch 24/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3704 - accuracy: 0.9924 - val_loss: 0.6286 - val_accuracy: 0.8597\n","Epoch 25/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3668 - accuracy: 0.9929 - val_loss: 0.6233 - val_accuracy: 0.8688\n","Epoch 26/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3666 - accuracy: 0.9926 - val_loss: 0.6197 - val_accuracy: 0.8790\n","Epoch 27/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3646 - accuracy: 0.9941 - val_loss: 0.6137 - val_accuracy: 0.8824\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3645 - accuracy: 0.9946 - val_loss: 0.6155 - val_accuracy: 0.8812\n","Epoch 29/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3659 - accuracy: 0.9926 - val_loss: 0.6250 - val_accuracy: 0.8869\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3614 - accuracy: 0.9960 - val_loss: 0.6161 - val_accuracy: 0.8857\n","Epoch 31/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3604 - accuracy: 0.9955 - val_loss: 0.6158 - val_accuracy: 0.8891\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3594 - accuracy: 0.9958 - val_loss: 0.6205 - val_accuracy: 0.8891\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3581 - accuracy: 0.9958 - val_loss: 0.6384 - val_accuracy: 0.8812\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3627 - accuracy: 0.9924 - val_loss: 0.7054 - val_accuracy: 0.8654\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3723 - accuracy: 0.9856 - val_loss: 0.6932 - val_accuracy: 0.8824\n","Epoch 36/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3589 - accuracy: 0.9963 - val_loss: 0.6394 - val_accuracy: 0.8812\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3551 - accuracy: 0.9966 - val_loss: 0.6315 - val_accuracy: 0.8824\n","Epoch 38/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3585 - accuracy: 0.9938 - val_loss: 0.6578 - val_accuracy: 0.8880\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3544 - accuracy: 0.9963 - val_loss: 0.6352 - val_accuracy: 0.8824\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3568 - accuracy: 0.9949 - val_loss: 0.6547 - val_accuracy: 0.8812\n","Epoch 41/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3531 - accuracy: 0.9958 - val_loss: 0.6463 - val_accuracy: 0.8835\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3509 - accuracy: 0.9960 - val_loss: 0.6478 - val_accuracy: 0.8891\n","Epoch 43/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3499 - accuracy: 0.9972 - val_loss: 0.6419 - val_accuracy: 0.8812\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3463 - accuracy: 0.9980 - val_loss: 0.6374 - val_accuracy: 0.8824\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3498 - accuracy: 0.9966 - val_loss: 0.6653 - val_accuracy: 0.8812\n","Epoch 46/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3476 - accuracy: 0.9975 - val_loss: 0.6306 - val_accuracy: 0.8903\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3451 - accuracy: 0.9972 - val_loss: 0.6347 - val_accuracy: 0.8869\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3431 - accuracy: 0.9977 - val_loss: 0.6361 - val_accuracy: 0.8869\n","Epoch 49/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3422 - accuracy: 0.9989 - val_loss: 0.6339 - val_accuracy: 0.8891\n","Epoch 50/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3415 - accuracy: 0.9980 - val_loss: 0.6410 - val_accuracy: 0.8857\n","Epoch 51/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3404 - accuracy: 0.9989 - val_loss: 0.6366 - val_accuracy: 0.8857\n","Epoch 52/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3401 - accuracy: 0.9992 - val_loss: 0.6395 - val_accuracy: 0.8824\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3387 - accuracy: 0.9986 - val_loss: 0.6498 - val_accuracy: 0.8846\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3403 - accuracy: 0.9983 - val_loss: 0.6640 - val_accuracy: 0.8846\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3410 - accuracy: 0.9980 - val_loss: 0.6483 - val_accuracy: 0.8812\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3376 - accuracy: 0.9986 - val_loss: 0.6397 - val_accuracy: 0.8880\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3354 - accuracy: 0.9989 - val_loss: 0.6657 - val_accuracy: 0.8812\n","Epoch 58/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3370 - accuracy: 0.9992 - val_loss: 0.6481 - val_accuracy: 0.8824\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3336 - accuracy: 0.9992 - val_loss: 0.6402 - val_accuracy: 0.8835\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3471 - accuracy: 0.9926 - val_loss: 0.6533 - val_accuracy: 0.8869\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3346 - accuracy: 0.9989 - val_loss: 0.6366 - val_accuracy: 0.8880\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3332 - accuracy: 0.9986 - val_loss: 0.6631 - val_accuracy: 0.8801\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3330 - accuracy: 0.9980 - val_loss: 0.6467 - val_accuracy: 0.8869\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3307 - accuracy: 0.9992 - val_loss: 0.6479 - val_accuracy: 0.8835\n","Epoch 65/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3294 - accuracy: 0.9994 - val_loss: 0.6532 - val_accuracy: 0.8801\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3296 - accuracy: 0.9992 - val_loss: 0.6439 - val_accuracy: 0.8857\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3297 - accuracy: 0.9992 - val_loss: 0.6511 - val_accuracy: 0.8778\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3291 - accuracy: 0.9992 - val_loss: 0.6596 - val_accuracy: 0.8880\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3312 - accuracy: 0.9989 - val_loss: 0.6953 - val_accuracy: 0.8756\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3301 - accuracy: 0.9989 - val_loss: 0.6763 - val_accuracy: 0.8824\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3336 - accuracy: 0.9975 - val_loss: 0.6621 - val_accuracy: 0.8812\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3263 - accuracy: 0.9994 - val_loss: 0.6609 - val_accuracy: 0.8835\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3245 - accuracy: 0.9994 - val_loss: 0.6508 - val_accuracy: 0.8846\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3233 - accuracy: 0.9994 - val_loss: 0.6600 - val_accuracy: 0.8824\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3292 - accuracy: 0.9983 - val_loss: 0.6543 - val_accuracy: 0.8857\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3251 - accuracy: 0.9992 - val_loss: 0.6632 - val_accuracy: 0.8812\n","Epoch 77/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3252 - accuracy: 0.9977 - val_loss: 0.6632 - val_accuracy: 0.8812\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3221 - accuracy: 0.9992 - val_loss: 0.6697 - val_accuracy: 0.8812\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3276 - accuracy: 0.9966 - val_loss: 0.6733 - val_accuracy: 0.8824\n","Epoch 80/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3270 - accuracy: 0.9989 - val_loss: 0.6818 - val_accuracy: 0.8846\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3229 - accuracy: 0.9994 - val_loss: 0.6575 - val_accuracy: 0.8903\n","Epoch 82/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3189 - accuracy: 0.9994 - val_loss: 0.6604 - val_accuracy: 0.8846\n","Epoch 83/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3206 - accuracy: 0.9989 - val_loss: 0.6559 - val_accuracy: 0.8846\n","Epoch 84/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3175 - accuracy: 0.9994 - val_loss: 0.6725 - val_accuracy: 0.8778\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3164 - accuracy: 0.9994 - val_loss: 0.6740 - val_accuracy: 0.8846\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3178 - accuracy: 0.9992 - val_loss: 0.6702 - val_accuracy: 0.8812\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3164 - accuracy: 0.9994 - val_loss: 0.6629 - val_accuracy: 0.8857\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3149 - accuracy: 0.9994 - val_loss: 0.6598 - val_accuracy: 0.8857\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3131 - accuracy: 0.9994 - val_loss: 0.6874 - val_accuracy: 0.8767\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3138 - accuracy: 0.9997 - val_loss: 0.6679 - val_accuracy: 0.8824\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3123 - accuracy: 0.9994 - val_loss: 0.6646 - val_accuracy: 0.8824\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3133 - accuracy: 0.9994 - val_loss: 0.7119 - val_accuracy: 0.8756\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3115 - accuracy: 0.9992 - val_loss: 0.6639 - val_accuracy: 0.8824\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3103 - accuracy: 0.9994 - val_loss: 0.6764 - val_accuracy: 0.8778\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3115 - accuracy: 0.9994 - val_loss: 0.7208 - val_accuracy: 0.8767\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3118 - accuracy: 0.9994 - val_loss: 0.6678 - val_accuracy: 0.8835\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3074 - accuracy: 0.9997 - val_loss: 0.6739 - val_accuracy: 0.8756\n","Epoch 98/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3109 - accuracy: 0.9992 - val_loss: 0.6672 - val_accuracy: 0.8857\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3076 - accuracy: 0.9994 - val_loss: 0.6725 - val_accuracy: 0.8835\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3082 - accuracy: 0.9992 - val_loss: 0.6884 - val_accuracy: 0.8812\n","{'loss': [0.4488781988620758, 0.41421282291412354, 0.4088885486125946, 0.4077892005443573, 0.40531665086746216, 0.4054601788520813, 0.3969074487686157, 0.4009803533554077, 0.39185047149658203, 0.39339679479599, 0.39194393157958984, 0.38583487272262573, 0.38535600900650024, 0.3817591071128845, 0.3824407160282135, 0.3791356682777405, 0.38142767548561096, 0.3788791298866272, 0.3782893121242523, 0.37311699986457825, 0.38129425048828125, 0.38049471378326416, 0.3709619343280792, 0.37043488025665283, 0.3668483793735504, 0.3665701448917389, 0.36462756991386414, 0.36451447010040283, 0.36588606238365173, 0.3614441454410553, 0.3604396879673004, 0.35936182737350464, 0.35807380080223083, 0.36272159218788147, 0.37234967947006226, 0.35891276597976685, 0.3550823926925659, 0.35852086544036865, 0.3544252812862396, 0.3568122386932373, 0.3530513048171997, 0.3508622348308563, 0.3498772084712982, 0.34633737802505493, 0.34982195496559143, 0.3476404845714569, 0.3450759947299957, 0.3431414067745209, 0.3421633541584015, 0.3414817750453949, 0.34035319089889526, 0.34008708596229553, 0.33868125081062317, 0.3402549922466278, 0.34099116921424866, 0.3375575542449951, 0.3354145288467407, 0.3370249271392822, 0.33358919620513916, 0.3471129536628723, 0.3345889151096344, 0.33319923281669617, 0.33303263783454895, 0.3307148218154907, 0.32941606640815735, 0.3295668959617615, 0.329704225063324, 0.329139769077301, 0.3312159478664398, 0.3300628960132599, 0.33358725905418396, 0.32630717754364014, 0.3244911730289459, 0.3232736587524414, 0.3291579782962799, 0.3250856399536133, 0.32523685693740845, 0.3221361041069031, 0.3276109993457794, 0.32696834206581116, 0.32293596863746643, 0.318875253200531, 0.32056742906570435, 0.3174861669540405, 0.31637826561927795, 0.31776735186576843, 0.31638339161872864, 0.31491899490356445, 0.3131164610385895, 0.313777357339859, 0.31225091218948364, 0.31330129504203796, 0.31146857142448425, 0.31028062105178833, 0.31154686212539673, 0.31176695227622986, 0.3073761761188507, 0.31085848808288574, 0.3075576424598694, 0.3081842362880707], 'accuracy': [0.9575551748275757, 0.9745330810546875, 0.9762309193611145, 0.974816083908081, 0.9782116413116455, 0.977645754814148, 0.9824561476707458, 0.9793435335159302, 0.9850028157234192, 0.9838709831237793, 0.9852858185768127, 0.9864176511764526, 0.9883984327316284, 0.9898132681846619, 0.990662157535553, 0.9909451007843018, 0.9883984327316284, 0.9895302653312683, 0.9895302653312683, 0.9912280440330505, 0.9878324866294861, 0.9875495433807373, 0.9915110468864441, 0.9923599362373352, 0.9929258823394775, 0.992642879486084, 0.9940577149391174, 0.9946236610412598, 0.992642879486084, 0.9960384964942932, 0.9954725503921509, 0.9957554936408997, 0.9957554936408997, 0.9923599362373352, 0.9855687618255615, 0.996321439743042, 0.9966044425964355, 0.9937747716903687, 0.996321439743042, 0.9949066042900085, 0.9957554936408997, 0.9960384964942932, 0.9971703290939331, 0.9980192184448242, 0.9966044425964355, 0.9974533319473267, 0.9971703290939331, 0.9977362751960754, 0.9988681674003601, 0.9980192184448242, 0.9988681674003601, 0.9991511106491089, 0.9985851645469666, 0.9983022212982178, 0.9980192184448242, 0.9985851645469666, 0.9988681674003601, 0.9991511106491089, 0.9991511106491089, 0.992642879486084, 0.9988681674003601, 0.9985851645469666, 0.9980192184448242, 0.9991511106491089, 0.9994340538978577, 0.9991511106491089, 0.9991511106491089, 0.9991511106491089, 0.9988681674003601, 0.9988681674003601, 0.9974533319473267, 0.9994340538978577, 0.9994340538978577, 0.9994340538978577, 0.9983022212982178, 0.9991511106491089, 0.9977362751960754, 0.9991511106491089, 0.9966044425964355, 0.9988681674003601, 0.9994340538978577, 0.9994340538978577, 0.9988681674003601, 0.9994340538978577, 0.9994340538978577, 0.9991511106491089, 0.9994340538978577, 0.9994340538978577, 0.9994340538978577, 0.9997170567512512, 0.9994340538978577, 0.9994340538978577, 0.9991511106491089, 0.9994340538978577, 0.9994340538978577, 0.9994340538978577, 0.9997170567512512, 0.9991511106491089, 0.9994340538978577, 0.9991511106491089], 'val_loss': [0.9416777491569519, 0.9269065856933594, 0.916921854019165, 0.9019273519515991, 0.8990958333015442, 0.8734092712402344, 0.8675035238265991, 0.8399515748023987, 0.8169053196907043, 0.792680025100708, 0.7973161339759827, 0.7656184434890747, 0.7437078356742859, 0.7471692562103271, 0.714504599571228, 0.7052420973777771, 0.6955835223197937, 0.6873838901519775, 0.6630199551582336, 0.6670851707458496, 0.663379430770874, 0.6316702365875244, 0.6411755681037903, 0.6285978555679321, 0.6233000159263611, 0.6196545958518982, 0.6136670708656311, 0.6154624223709106, 0.6249721050262451, 0.6161207556724548, 0.6158331036567688, 0.6204921007156372, 0.6383819580078125, 0.7053716778755188, 0.6932197213172913, 0.6394259929656982, 0.6314884424209595, 0.6578165292739868, 0.635247528553009, 0.6547266244888306, 0.6463215947151184, 0.647798478603363, 0.6418763995170593, 0.6373996138572693, 0.6652749180793762, 0.6305642127990723, 0.6346758604049683, 0.6360822916030884, 0.6339448094367981, 0.6410061717033386, 0.6366315484046936, 0.6395349502563477, 0.6498154997825623, 0.6639991402626038, 0.6482675671577454, 0.6397202610969543, 0.6657158136367798, 0.6481453776359558, 0.6402063965797424, 0.6533204317092896, 0.6366273164749146, 0.6631191968917847, 0.6467358469963074, 0.6479464173316956, 0.6532478332519531, 0.6438730359077454, 0.6510894894599915, 0.6595824360847473, 0.6953483819961548, 0.6762906312942505, 0.6620769500732422, 0.660932183265686, 0.6508331298828125, 0.6599627733230591, 0.6542964577674866, 0.6631946563720703, 0.6632331609725952, 0.6697090268135071, 0.6733236908912659, 0.6818394660949707, 0.6575356125831604, 0.6603590250015259, 0.6558970212936401, 0.6725274920463562, 0.6739585995674133, 0.6701626181602478, 0.6629106402397156, 0.6598257422447205, 0.6874256134033203, 0.6678789854049683, 0.6645721197128296, 0.7118940353393555, 0.6638613343238831, 0.6763546466827393, 0.7208373546600342, 0.6677594780921936, 0.673879861831665, 0.6671514511108398, 0.6724514365196228, 0.6883546113967896], 'val_accuracy': [0.8133484125137329, 0.820135772228241, 0.820135772228241, 0.8212669491767883, 0.8042986392974854, 0.8269230723381042, 0.8054298758506775, 0.8223981857299805, 0.8235294222831726, 0.8235294222831726, 0.8054298758506775, 0.8348416090011597, 0.8325791954994202, 0.8156108856201172, 0.8404977321624756, 0.837104082107544, 0.8325791954994202, 0.837104082107544, 0.8450226187705994, 0.848416268825531, 0.8495475053787231, 0.860859751701355, 0.8574660420417786, 0.8597285151481628, 0.8687782883644104, 0.8789592981338501, 0.8823529481887817, 0.8812217116355896, 0.8868778347969055, 0.8857465982437134, 0.889140248298645, 0.889140248298645, 0.8812217116355896, 0.8653846383094788, 0.8823529481887817, 0.8812217116355896, 0.8823529481887817, 0.8880090713500977, 0.8823529481887817, 0.8812217116355896, 0.8834841847419739, 0.889140248298645, 0.8812217116355896, 0.8823529481887817, 0.8812217116355896, 0.8902714848518372, 0.8868778347969055, 0.8868778347969055, 0.889140248298645, 0.8857465982437134, 0.8857465982437134, 0.8823529481887817, 0.8846153616905212, 0.8846153616905212, 0.8812217116355896, 0.8880090713500977, 0.8812217116355896, 0.8823529481887817, 0.8834841847419739, 0.8868778347969055, 0.8880090713500977, 0.8800904750823975, 0.8868778347969055, 0.8834841847419739, 0.8800904750823975, 0.8857465982437134, 0.877828061580658, 0.8880090713500977, 0.8755655884742737, 0.8823529481887817, 0.8812217116355896, 0.8834841847419739, 0.8846153616905212, 0.8823529481887817, 0.8857465982437134, 0.8812217116355896, 0.8812217116355896, 0.8812217116355896, 0.8823529481887817, 0.8846153616905212, 0.8902714848518372, 0.8846153616905212, 0.8846153616905212, 0.877828061580658, 0.8846153616905212, 0.8812217116355896, 0.8857465982437134, 0.8857465982437134, 0.8766968250274658, 0.8823529481887817, 0.8823529481887817, 0.8755655884742737, 0.8823529481887817, 0.877828061580658, 0.8766968250274658, 0.8834841847419739, 0.8755655884742737, 0.8857465982437134, 0.8834841847419739, 0.8812217116355896]}\n","45/45 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.4703 - accuracy: 0.9490"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 4s 34ms/step - loss: 0.4697 - accuracy: 0.9491 - val_loss: 0.9341 - val_accuracy: 0.8316\n","Epoch 2/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4184 - accuracy: 0.9718 - val_loss: 0.9189 - val_accuracy: 0.8326\n","Epoch 3/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4243 - accuracy: 0.9672 - val_loss: 0.9075 - val_accuracy: 0.8275\n","Epoch 4/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4090 - accuracy: 0.9739 - val_loss: 0.8918 - val_accuracy: 0.8254\n","Epoch 5/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4109 - accuracy: 0.9744 - val_loss: 0.8807 - val_accuracy: 0.8140\n","Epoch 6/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4037 - accuracy: 0.9780 - val_loss: 0.8571 - val_accuracy: 0.8192\n","Epoch 7/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3980 - accuracy: 0.9814 - val_loss: 0.8346 - val_accuracy: 0.8244\n","Epoch 8/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4098 - accuracy: 0.9755 - val_loss: 0.8182 - val_accuracy: 0.8213\n","Epoch 9/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3979 - accuracy: 0.9798 - val_loss: 0.7908 - val_accuracy: 0.8295\n","Epoch 10/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3969 - accuracy: 0.9814 - val_loss: 0.7598 - val_accuracy: 0.8450\n","Epoch 11/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4012 - accuracy: 0.9778 - val_loss: 0.7889 - val_accuracy: 0.7851\n","Epoch 12/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4177 - accuracy: 0.9695 - val_loss: 0.7176 - val_accuracy: 0.8471\n","Epoch 13/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3872 - accuracy: 0.9842 - val_loss: 0.7243 - val_accuracy: 0.8182\n","Epoch 14/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3841 - accuracy: 0.9871 - val_loss: 0.7026 - val_accuracy: 0.8264\n","Epoch 15/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3840 - accuracy: 0.9879 - val_loss: 0.6731 - val_accuracy: 0.8543\n","Epoch 16/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3845 - accuracy: 0.9855 - val_loss: 0.7006 - val_accuracy: 0.8233\n","Epoch 17/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3880 - accuracy: 0.9837 - val_loss: 0.6553 - val_accuracy: 0.8564\n","Epoch 18/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3790 - accuracy: 0.9879 - val_loss: 0.6600 - val_accuracy: 0.8523\n","Epoch 19/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3773 - accuracy: 0.9894 - val_loss: 0.6457 - val_accuracy: 0.8616\n","Epoch 20/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3790 - accuracy: 0.9894 - val_loss: 0.6463 - val_accuracy: 0.8688\n","Epoch 21/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3815 - accuracy: 0.9853 - val_loss: 0.6614 - val_accuracy: 0.8574\n","Epoch 22/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3790 - accuracy: 0.9876 - val_loss: 0.6449 - val_accuracy: 0.8771\n","Epoch 23/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3747 - accuracy: 0.9899 - val_loss: 0.6523 - val_accuracy: 0.8781\n","Epoch 24/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3748 - accuracy: 0.9899 - val_loss: 0.6514 - val_accuracy: 0.8781\n","Epoch 25/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3693 - accuracy: 0.9910 - val_loss: 0.6500 - val_accuracy: 0.8822\n","Epoch 26/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3693 - accuracy: 0.9910 - val_loss: 0.6577 - val_accuracy: 0.8843\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3736 - accuracy: 0.9891 - val_loss: 0.6829 - val_accuracy: 0.8760\n","Epoch 28/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3664 - accuracy: 0.9933 - val_loss: 0.6767 - val_accuracy: 0.8781\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3659 - accuracy: 0.9899 - val_loss: 0.6747 - val_accuracy: 0.8709\n","Epoch 30/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3637 - accuracy: 0.9930 - val_loss: 0.6674 - val_accuracy: 0.8812\n","Epoch 31/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3633 - accuracy: 0.9928 - val_loss: 0.6773 - val_accuracy: 0.8771\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3690 - accuracy: 0.9889 - val_loss: 0.6799 - val_accuracy: 0.8771\n","Epoch 33/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3689 - accuracy: 0.9902 - val_loss: 0.7110 - val_accuracy: 0.8595\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3660 - accuracy: 0.9894 - val_loss: 0.6773 - val_accuracy: 0.8812\n","Epoch 35/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3583 - accuracy: 0.9959 - val_loss: 0.6779 - val_accuracy: 0.8802\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3589 - accuracy: 0.9930 - val_loss: 0.6805 - val_accuracy: 0.8802\n","Epoch 37/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3589 - accuracy: 0.9930 - val_loss: 0.7057 - val_accuracy: 0.8740\n","Epoch 38/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3636 - accuracy: 0.9910 - val_loss: 0.7113 - val_accuracy: 0.8667\n","Epoch 39/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3565 - accuracy: 0.9943 - val_loss: 0.6990 - val_accuracy: 0.8740\n","Epoch 40/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3543 - accuracy: 0.9951 - val_loss: 0.6889 - val_accuracy: 0.8822\n","Epoch 41/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3523 - accuracy: 0.9953 - val_loss: 0.6916 - val_accuracy: 0.8781\n","Epoch 42/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3561 - accuracy: 0.9946 - val_loss: 0.7308 - val_accuracy: 0.8616\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3515 - accuracy: 0.9959 - val_loss: 0.6936 - val_accuracy: 0.8771\n","Epoch 44/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3488 - accuracy: 0.9974 - val_loss: 0.6937 - val_accuracy: 0.8771\n","Epoch 45/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3464 - accuracy: 0.9977 - val_loss: 0.7095 - val_accuracy: 0.8678\n","Epoch 46/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3459 - accuracy: 0.9977 - val_loss: 0.7065 - val_accuracy: 0.8729\n","Epoch 47/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3452 - accuracy: 0.9974 - val_loss: 0.7008 - val_accuracy: 0.8740\n","Epoch 48/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3456 - accuracy: 0.9977 - val_loss: 0.7758 - val_accuracy: 0.8657\n","Epoch 49/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3456 - accuracy: 0.9964 - val_loss: 0.6950 - val_accuracy: 0.8771\n","Epoch 50/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3442 - accuracy: 0.9972 - val_loss: 0.7032 - val_accuracy: 0.8719\n","Epoch 51/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3480 - accuracy: 0.9948 - val_loss: 0.7063 - val_accuracy: 0.8688\n","Epoch 52/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3445 - accuracy: 0.9966 - val_loss: 0.7203 - val_accuracy: 0.8729\n","Epoch 53/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3422 - accuracy: 0.9972 - val_loss: 0.7101 - val_accuracy: 0.8740\n","Epoch 54/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3411 - accuracy: 0.9972 - val_loss: 0.7246 - val_accuracy: 0.8688\n","Epoch 55/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3414 - accuracy: 0.9979 - val_loss: 0.7428 - val_accuracy: 0.8667\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3399 - accuracy: 0.9979 - val_loss: 0.7091 - val_accuracy: 0.8740\n","Epoch 57/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3394 - accuracy: 0.9948 - val_loss: 0.7314 - val_accuracy: 0.8657\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3443 - accuracy: 0.9961 - val_loss: 0.7102 - val_accuracy: 0.8729\n","Epoch 59/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3435 - accuracy: 0.9953 - val_loss: 0.7327 - val_accuracy: 0.8636\n","Epoch 60/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3376 - accuracy: 0.9974 - val_loss: 0.7240 - val_accuracy: 0.8657\n","Epoch 61/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3382 - accuracy: 0.9961 - val_loss: 0.7155 - val_accuracy: 0.8729\n","Epoch 62/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3325 - accuracy: 0.9979 - val_loss: 0.7169 - val_accuracy: 0.8740\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3328 - accuracy: 0.9990 - val_loss: 0.7142 - val_accuracy: 0.8688\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3321 - accuracy: 0.9990 - val_loss: 0.7245 - val_accuracy: 0.8698\n","Epoch 65/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3368 - accuracy: 0.9964 - val_loss: 0.7150 - val_accuracy: 0.8750\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3324 - accuracy: 0.9972 - val_loss: 0.7404 - val_accuracy: 0.8554\n","Epoch 67/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3294 - accuracy: 0.9987 - val_loss: 0.7182 - val_accuracy: 0.8740\n","Epoch 68/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3270 - accuracy: 0.9995 - val_loss: 0.7218 - val_accuracy: 0.8709\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3285 - accuracy: 0.9992 - val_loss: 0.7274 - val_accuracy: 0.8709\n","Epoch 70/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3313 - accuracy: 0.9966 - val_loss: 0.7257 - val_accuracy: 0.8678\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3260 - accuracy: 0.9990 - val_loss: 0.7373 - val_accuracy: 0.8698\n","Epoch 72/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3291 - accuracy: 0.9984 - val_loss: 0.7435 - val_accuracy: 0.8626\n","Epoch 73/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3319 - accuracy: 0.9966 - val_loss: 0.7262 - val_accuracy: 0.8688\n","Epoch 74/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3238 - accuracy: 0.9995 - val_loss: 0.7573 - val_accuracy: 0.8626\n","Epoch 75/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3229 - accuracy: 0.9995 - val_loss: 0.7346 - val_accuracy: 0.8688\n","Epoch 76/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3262 - accuracy: 0.9979 - val_loss: 0.7425 - val_accuracy: 0.8647\n","Epoch 77/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3234 - accuracy: 0.9992 - val_loss: 0.7378 - val_accuracy: 0.8740\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3216 - accuracy: 0.9997 - val_loss: 0.7438 - val_accuracy: 0.8678\n","Epoch 79/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3221 - accuracy: 0.9982 - val_loss: 0.7355 - val_accuracy: 0.8709\n","Epoch 80/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3194 - accuracy: 0.9995 - val_loss: 0.7456 - val_accuracy: 0.8688\n","Epoch 81/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3193 - accuracy: 0.9997 - val_loss: 0.7419 - val_accuracy: 0.8719\n","Epoch 82/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3179 - accuracy: 0.9995 - val_loss: 0.7454 - val_accuracy: 0.8698\n","Epoch 83/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3198 - accuracy: 0.9987 - val_loss: 0.7514 - val_accuracy: 0.8740\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3174 - accuracy: 0.9997 - val_loss: 0.7475 - val_accuracy: 0.8709\n","Epoch 85/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3168 - accuracy: 0.9997 - val_loss: 0.7485 - val_accuracy: 0.8740\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3162 - accuracy: 1.0000 - val_loss: 0.7557 - val_accuracy: 0.8657\n","Epoch 87/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3151 - accuracy: 1.0000 - val_loss: 0.7531 - val_accuracy: 0.8647\n","Epoch 88/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3182 - accuracy: 0.9984 - val_loss: 0.7726 - val_accuracy: 0.8688\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3161 - accuracy: 0.9990 - val_loss: 0.7595 - val_accuracy: 0.8667\n","Epoch 90/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3149 - accuracy: 0.9990 - val_loss: 0.7685 - val_accuracy: 0.8667\n","Epoch 91/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3119 - accuracy: 1.0000 - val_loss: 0.7624 - val_accuracy: 0.8636\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3113 - accuracy: 1.0000 - val_loss: 0.7597 - val_accuracy: 0.8688\n","Epoch 93/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3115 - accuracy: 1.0000 - val_loss: 0.7567 - val_accuracy: 0.8667\n","Epoch 94/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3112 - accuracy: 0.9995 - val_loss: 0.7568 - val_accuracy: 0.8657\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3100 - accuracy: 0.9997 - val_loss: 0.8029 - val_accuracy: 0.8595\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3171 - accuracy: 0.9974 - val_loss: 0.8050 - val_accuracy: 0.8616\n","Epoch 97/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3108 - accuracy: 0.9990 - val_loss: 0.7606 - val_accuracy: 0.8678\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3107 - accuracy: 0.9995 - val_loss: 0.7648 - val_accuracy: 0.8657\n","Epoch 99/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3069 - accuracy: 1.0000 - val_loss: 0.7839 - val_accuracy: 0.8667\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3060 - accuracy: 1.0000 - val_loss: 0.7877 - val_accuracy: 0.8657\n","{'loss': [0.46971985697746277, 0.4183657765388489, 0.42434898018836975, 0.40900397300720215, 0.41091302037239075, 0.4037199020385742, 0.39796772599220276, 0.4097519814968109, 0.39794114232063293, 0.3968771696090698, 0.40117260813713074, 0.41768622398376465, 0.38719236850738525, 0.3841424286365509, 0.38400962948799133, 0.3844829201698303, 0.38797563314437866, 0.37904709577560425, 0.3773002028465271, 0.3789544105529785, 0.3814517855644226, 0.37903621792793274, 0.37471380829811096, 0.374836266040802, 0.36931726336479187, 0.369326651096344, 0.37355875968933105, 0.36639389395713806, 0.3658801317214966, 0.3637288808822632, 0.36333274841308594, 0.36896631121635437, 0.36885854601860046, 0.3660149872303009, 0.3583402633666992, 0.35887324810028076, 0.3588685095310211, 0.36355119943618774, 0.3564603626728058, 0.3542921841144562, 0.35227879881858826, 0.3560935854911804, 0.35150372982025146, 0.3488277196884155, 0.34642401337623596, 0.34589383006095886, 0.34523236751556396, 0.3456086218357086, 0.34555289149284363, 0.3442395329475403, 0.34800243377685547, 0.344521164894104, 0.3421768248081207, 0.3410519063472748, 0.34142065048217773, 0.33991289138793945, 0.3393760621547699, 0.3443479537963867, 0.34354403614997864, 0.3376464247703552, 0.33822205662727356, 0.3325052559375763, 0.33278530836105347, 0.3320657014846802, 0.3368125855922699, 0.3324347734451294, 0.3294484615325928, 0.32702645659446716, 0.32854774594306946, 0.33125463128089905, 0.3259994685649872, 0.32908034324645996, 0.3318803608417511, 0.32379427552223206, 0.3229218125343323, 0.32616305351257324, 0.32342955470085144, 0.3216359615325928, 0.3221171498298645, 0.31942206621170044, 0.3192976713180542, 0.3178807497024536, 0.3197968900203705, 0.3174123466014862, 0.31684955954551697, 0.31615132093429565, 0.3151492178440094, 0.3181706368923187, 0.316145658493042, 0.31491395831108093, 0.31191059947013855, 0.3113236129283905, 0.31153297424316406, 0.31123673915863037, 0.31002095341682434, 0.31707900762557983, 0.3107856214046478, 0.310707151889801, 0.3068733811378479, 0.3060128688812256], 'accuracy': [0.949095606803894, 0.9718345999717712, 0.9671834707260132, 0.9739018082618713, 0.974418580532074, 0.9780361652374268, 0.9813953638076782, 0.975452184677124, 0.9798449873924255, 0.9813953638076782, 0.9777777791023254, 0.9695090651512146, 0.9842377305030823, 0.9870800971984863, 0.9878553152084351, 0.9855297207832336, 0.9837209582328796, 0.9878553152084351, 0.9894056916236877, 0.9894056916236877, 0.9852713346481323, 0.987596869468689, 0.9899224638938904, 0.9899224638938904, 0.9909560680389404, 0.9909560680389404, 0.9891473054885864, 0.9932816624641418, 0.9899224638938904, 0.9930232763290405, 0.9927648305892944, 0.9888888597488403, 0.9901808500289917, 0.9894056916236877, 0.9958656430244446, 0.9930232763290405, 0.9930232763290405, 0.9909560680389404, 0.9943152666091919, 0.9950904250144958, 0.9953488111495972, 0.9945736527442932, 0.9958656430244446, 0.9974160194396973, 0.9976744055747986, 0.9976744055747986, 0.9974160194396973, 0.9976744055747986, 0.9963824152946472, 0.997157633304596, 0.9948320388793945, 0.9966408014297485, 0.997157633304596, 0.997157633304596, 0.9979327917098999, 0.9979327917098999, 0.9948320388793945, 0.9961240291595459, 0.9953488111495972, 0.9974160194396973, 0.9961240291595459, 0.9979327917098999, 0.99896639585495, 0.99896639585495, 0.9963824152946472, 0.997157633304596, 0.9987080097198486, 0.9994832277297974, 0.9992247819900513, 0.9966408014297485, 0.99896639585495, 0.9984496235847473, 0.9966408014297485, 0.9994832277297974, 0.9994832277297974, 0.9979327917098999, 0.9992247819900513, 0.9997416138648987, 0.998191237449646, 0.9994832277297974, 0.9997416138648987, 0.9994832277297974, 0.9987080097198486, 0.9997416138648987, 0.9997416138648987, 1.0, 1.0, 0.9984496235847473, 0.99896639585495, 0.99896639585495, 1.0, 1.0, 1.0, 0.9994832277297974, 0.9997416138648987, 0.9974160194396973, 0.99896639585495, 0.9994832277297974, 1.0, 1.0], 'val_loss': [0.9340615272521973, 0.918922483921051, 0.9074540734291077, 0.8917598724365234, 0.8807390332221985, 0.8571234345436096, 0.8345816731452942, 0.8182235956192017, 0.7908390760421753, 0.7597509622573853, 0.7888620495796204, 0.7175925374031067, 0.7242650985717773, 0.7026212215423584, 0.6731405854225159, 0.7005823850631714, 0.6553444862365723, 0.6599924564361572, 0.6457300782203674, 0.6463269591331482, 0.6613640189170837, 0.6448505520820618, 0.6522654294967651, 0.6513545513153076, 0.6499611139297485, 0.6576523184776306, 0.6829122304916382, 0.6767237186431885, 0.6747421622276306, 0.6673563122749329, 0.6773185133934021, 0.679889976978302, 0.7110393643379211, 0.6773112416267395, 0.6779323816299438, 0.6804560422897339, 0.7056558728218079, 0.7112581133842468, 0.6989660859107971, 0.6888988018035889, 0.6916182041168213, 0.7308079600334167, 0.6935766935348511, 0.6936787366867065, 0.7094553112983704, 0.7065137028694153, 0.7008101344108582, 0.7758010625839233, 0.694957971572876, 0.7032169699668884, 0.7062510848045349, 0.7202911972999573, 0.7101302146911621, 0.72456955909729, 0.7428039908409119, 0.7090755701065063, 0.731438159942627, 0.7101633548736572, 0.7327486872673035, 0.7239567041397095, 0.715476930141449, 0.7168710827827454, 0.7142069935798645, 0.724500298500061, 0.7149932384490967, 0.7404017448425293, 0.7181892991065979, 0.7217712998390198, 0.7274345755577087, 0.7256522178649902, 0.7373272180557251, 0.7435078620910645, 0.7261547446250916, 0.7572603821754456, 0.7346187829971313, 0.7424710988998413, 0.7378396391868591, 0.743787407875061, 0.7354865074157715, 0.7456013560295105, 0.7419037222862244, 0.7454476356506348, 0.7514327764511108, 0.7474842667579651, 0.7484708428382874, 0.7557317614555359, 0.7531113028526306, 0.7726059556007385, 0.7594538331031799, 0.7685023546218872, 0.7624284029006958, 0.7596682906150818, 0.756658136844635, 0.7567799687385559, 0.8029389977455139, 0.8049629330635071, 0.7606459856033325, 0.7648130655288696, 0.7838575839996338, 0.7876941561698914], 'val_accuracy': [0.8316115736961365, 0.8326446413993835, 0.827479362487793, 0.8254132270812988, 0.8140496015548706, 0.8192148804664612, 0.8243801593780518, 0.8212810158729553, 0.8295454382896423, 0.8450413346290588, 0.7851239442825317, 0.8471074104309082, 0.8181818127632141, 0.8264462947845459, 0.8543388247489929, 0.8233470916748047, 0.8564049601554871, 0.8522727489471436, 0.8615702390670776, 0.8688016533851624, 0.8574380278587341, 0.8770661354064941, 0.8780992031097412, 0.8780992031097412, 0.8822314143180847, 0.8842975497245789, 0.8760330677032471, 0.8780992031097412, 0.8708677887916565, 0.8811983466148376, 0.8770661354064941, 0.8770661354064941, 0.8595041036605835, 0.8811983466148376, 0.8801652789115906, 0.8801652789115906, 0.8739669322967529, 0.8667355179786682, 0.8739669322967529, 0.8822314143180847, 0.8780992031097412, 0.8615702390670776, 0.8770661354064941, 0.8770661354064941, 0.8677685856819153, 0.8729338645935059, 0.8739669322967529, 0.8657024502754211, 0.8770661354064941, 0.8719007968902588, 0.8688016533851624, 0.8729338645935059, 0.8739669322967529, 0.8688016533851624, 0.8667355179786682, 0.8739669322967529, 0.8657024502754211, 0.8729338645935059, 0.8636363744735718, 0.8657024502754211, 0.8729338645935059, 0.8739669322967529, 0.8688016533851624, 0.8698347210884094, 0.875, 0.85537189245224, 0.8739669322967529, 0.8708677887916565, 0.8708677887916565, 0.8677685856819153, 0.8698347210884094, 0.8626033067703247, 0.8688016533851624, 0.8626033067703247, 0.8688016533851624, 0.8646694421768188, 0.8739669322967529, 0.8677685856819153, 0.8708677887916565, 0.8688016533851624, 0.8719007968902588, 0.8698347210884094, 0.8739669322967529, 0.8708677887916565, 0.8739669322967529, 0.8657024502754211, 0.8646694421768188, 0.8688016533851624, 0.8667355179786682, 0.8667355179786682, 0.8636363744735718, 0.8688016533851624, 0.8667355179786682, 0.8657024502754211, 0.8595041036605835, 0.8615702390670776, 0.8677685856819153, 0.8657024502754211, 0.8667355179786682, 0.8657024502754211]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.3867 - accuracy: 0.9670"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 5s 34ms/step - loss: 0.3848 - accuracy: 0.9679 - val_loss: 0.8755 - val_accuracy: 0.8254\n","Epoch 2/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3391 - accuracy: 0.9871 - val_loss: 0.8576 - val_accuracy: 0.8394\n","Epoch 3/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3373 - accuracy: 0.9892 - val_loss: 0.8621 - val_accuracy: 0.7963\n","Epoch 4/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3264 - accuracy: 0.9925 - val_loss: 0.8336 - val_accuracy: 0.8287\n","Epoch 5/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3241 - accuracy: 0.9922 - val_loss: 0.8151 - val_accuracy: 0.8308\n","Epoch 6/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3226 - accuracy: 0.9943 - val_loss: 0.7977 - val_accuracy: 0.8341\n","Epoch 7/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3196 - accuracy: 0.9957 - val_loss: 0.7806 - val_accuracy: 0.8276\n","Epoch 8/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3180 - accuracy: 0.9968 - val_loss: 0.7541 - val_accuracy: 0.8351\n","Epoch 9/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3166 - accuracy: 0.9965 - val_loss: 0.7394 - val_accuracy: 0.8297\n","Epoch 10/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3163 - accuracy: 0.9965 - val_loss: 0.7279 - val_accuracy: 0.8200\n","Epoch 11/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3221 - accuracy: 0.9943 - val_loss: 0.6976 - val_accuracy: 0.8341\n","Epoch 12/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3135 - accuracy: 0.9978 - val_loss: 0.7124 - val_accuracy: 0.8125\n","Epoch 13/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3140 - accuracy: 0.9970 - val_loss: 0.6858 - val_accuracy: 0.8233\n","Epoch 14/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3162 - accuracy: 0.9965 - val_loss: 0.6426 - val_accuracy: 0.8448\n","Epoch 15/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3116 - accuracy: 0.9984 - val_loss: 0.6235 - val_accuracy: 0.8502\n","Epoch 16/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3097 - accuracy: 0.9987 - val_loss: 0.6323 - val_accuracy: 0.8502\n","Epoch 17/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3105 - accuracy: 0.9989 - val_loss: 0.6374 - val_accuracy: 0.8470\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3129 - accuracy: 0.9976 - val_loss: 0.6725 - val_accuracy: 0.8319\n","Epoch 19/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3109 - accuracy: 0.9987 - val_loss: 0.6283 - val_accuracy: 0.8578\n","Epoch 20/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3107 - accuracy: 0.9970 - val_loss: 0.5837 - val_accuracy: 0.8750\n","Epoch 21/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3103 - accuracy: 0.9981 - val_loss: 0.5745 - val_accuracy: 0.8825\n","Epoch 22/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3076 - accuracy: 0.9984 - val_loss: 0.6196 - val_accuracy: 0.8696\n","Epoch 23/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3063 - accuracy: 0.9987 - val_loss: 0.6058 - val_accuracy: 0.8815\n","Epoch 24/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3140 - accuracy: 0.9976 - val_loss: 0.5753 - val_accuracy: 0.9041\n","Epoch 25/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3061 - accuracy: 0.9981 - val_loss: 0.5634 - val_accuracy: 0.8987\n","Epoch 26/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3028 - accuracy: 0.9997 - val_loss: 0.5582 - val_accuracy: 0.9062\n","Epoch 27/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3036 - accuracy: 0.9995 - val_loss: 0.5570 - val_accuracy: 0.9106\n","Epoch 28/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3019 - accuracy: 0.9997 - val_loss: 0.5678 - val_accuracy: 0.9084\n","Epoch 29/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3010 - accuracy: 0.9997 - val_loss: 0.5561 - val_accuracy: 0.9159\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2995 - accuracy: 0.9997 - val_loss: 0.5584 - val_accuracy: 0.9138\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3002 - accuracy: 0.9992 - val_loss: 0.5830 - val_accuracy: 0.9095\n","Epoch 32/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3007 - accuracy: 0.9992 - val_loss: 0.5700 - val_accuracy: 0.9149\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2997 - accuracy: 0.9992 - val_loss: 0.5713 - val_accuracy: 0.9127\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2986 - accuracy: 0.9992 - val_loss: 0.5771 - val_accuracy: 0.9149\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2988 - accuracy: 0.9995 - val_loss: 0.5766 - val_accuracy: 0.9159\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2972 - accuracy: 0.9995 - val_loss: 0.5692 - val_accuracy: 0.9159\n","Epoch 37/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2951 - accuracy: 0.9997 - val_loss: 0.5657 - val_accuracy: 0.9170\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2956 - accuracy: 0.9997 - val_loss: 0.5722 - val_accuracy: 0.9149\n","Epoch 39/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2943 - accuracy: 0.9997 - val_loss: 0.5701 - val_accuracy: 0.9170\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2939 - accuracy: 0.9997 - val_loss: 0.5767 - val_accuracy: 0.9095\n","Epoch 41/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2934 - accuracy: 0.9997 - val_loss: 0.5739 - val_accuracy: 0.9203\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2929 - accuracy: 1.0000 - val_loss: 0.5815 - val_accuracy: 0.9170\n","Epoch 43/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2921 - accuracy: 0.9997 - val_loss: 0.5774 - val_accuracy: 0.9138\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2915 - accuracy: 1.0000 - val_loss: 0.5781 - val_accuracy: 0.9138\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2909 - accuracy: 1.0000 - val_loss: 0.5857 - val_accuracy: 0.9073\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2905 - accuracy: 0.9997 - val_loss: 0.5835 - val_accuracy: 0.9149\n","Epoch 47/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2900 - accuracy: 0.9997 - val_loss: 0.5849 - val_accuracy: 0.9106\n","Epoch 48/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2892 - accuracy: 1.0000 - val_loss: 0.5865 - val_accuracy: 0.9073\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2889 - accuracy: 0.9997 - val_loss: 0.5832 - val_accuracy: 0.9149\n","Epoch 50/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2885 - accuracy: 0.9997 - val_loss: 0.5944 - val_accuracy: 0.9127\n","Epoch 51/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2886 - accuracy: 1.0000 - val_loss: 0.5946 - val_accuracy: 0.9052\n","Epoch 52/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2903 - accuracy: 0.9997 - val_loss: 0.5981 - val_accuracy: 0.9073\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2884 - accuracy: 0.9997 - val_loss: 0.5894 - val_accuracy: 0.9127\n","Epoch 54/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2867 - accuracy: 1.0000 - val_loss: 0.5851 - val_accuracy: 0.9127\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2850 - accuracy: 1.0000 - val_loss: 0.5919 - val_accuracy: 0.9106\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2849 - accuracy: 1.0000 - val_loss: 0.5894 - val_accuracy: 0.9084\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2839 - accuracy: 1.0000 - val_loss: 0.5836 - val_accuracy: 0.9149\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2842 - accuracy: 1.0000 - val_loss: 0.5939 - val_accuracy: 0.9095\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2839 - accuracy: 1.0000 - val_loss: 0.6096 - val_accuracy: 0.9116\n","Epoch 60/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2830 - accuracy: 1.0000 - val_loss: 0.5939 - val_accuracy: 0.9127\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2828 - accuracy: 1.0000 - val_loss: 0.5955 - val_accuracy: 0.9073\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2819 - accuracy: 1.0000 - val_loss: 0.5939 - val_accuracy: 0.9138\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2812 - accuracy: 1.0000 - val_loss: 0.6112 - val_accuracy: 0.9062\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2800 - accuracy: 1.0000 - val_loss: 0.5937 - val_accuracy: 0.9106\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2796 - accuracy: 1.0000 - val_loss: 0.6055 - val_accuracy: 0.9084\n","Epoch 66/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2828 - accuracy: 0.9989 - val_loss: 0.5958 - val_accuracy: 0.9116\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2905 - accuracy: 0.9965 - val_loss: 0.6509 - val_accuracy: 0.8922\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2795 - accuracy: 0.9997 - val_loss: 0.5904 - val_accuracy: 0.9106\n","Epoch 69/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2772 - accuracy: 1.0000 - val_loss: 0.6008 - val_accuracy: 0.9062\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2768 - accuracy: 1.0000 - val_loss: 0.5952 - val_accuracy: 0.9106\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2756 - accuracy: 1.0000 - val_loss: 0.5948 - val_accuracy: 0.9052\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2754 - accuracy: 1.0000 - val_loss: 0.5909 - val_accuracy: 0.9106\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2761 - accuracy: 1.0000 - val_loss: 0.5910 - val_accuracy: 0.9138\n","Epoch 74/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2744 - accuracy: 1.0000 - val_loss: 0.5902 - val_accuracy: 0.9106\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2735 - accuracy: 1.0000 - val_loss: 0.5929 - val_accuracy: 0.9084\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2731 - accuracy: 1.0000 - val_loss: 0.5953 - val_accuracy: 0.9084\n","Epoch 77/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2734 - accuracy: 1.0000 - val_loss: 0.6226 - val_accuracy: 0.9116\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2740 - accuracy: 1.0000 - val_loss: 0.5999 - val_accuracy: 0.9041\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2715 - accuracy: 1.0000 - val_loss: 0.6090 - val_accuracy: 0.9019\n","Epoch 80/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2724 - accuracy: 0.9995 - val_loss: 0.5924 - val_accuracy: 0.9192\n","Epoch 81/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2714 - accuracy: 1.0000 - val_loss: 0.5983 - val_accuracy: 0.9084\n","Epoch 82/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2693 - accuracy: 1.0000 - val_loss: 0.6069 - val_accuracy: 0.9009\n","Epoch 83/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2697 - accuracy: 1.0000 - val_loss: 0.6017 - val_accuracy: 0.9030\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2689 - accuracy: 1.0000 - val_loss: 0.5987 - val_accuracy: 0.9019\n","Epoch 85/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2681 - accuracy: 1.0000 - val_loss: 0.6079 - val_accuracy: 0.9009\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2673 - accuracy: 1.0000 - val_loss: 0.6026 - val_accuracy: 0.9073\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2665 - accuracy: 1.0000 - val_loss: 0.6044 - val_accuracy: 0.9095\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2659 - accuracy: 1.0000 - val_loss: 0.6069 - val_accuracy: 0.9052\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2655 - accuracy: 1.0000 - val_loss: 0.5974 - val_accuracy: 0.9084\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2645 - accuracy: 1.0000 - val_loss: 0.5982 - val_accuracy: 0.9084\n","Epoch 91/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2648 - accuracy: 1.0000 - val_loss: 0.5995 - val_accuracy: 0.9041\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2648 - accuracy: 1.0000 - val_loss: 0.6075 - val_accuracy: 0.9030\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2634 - accuracy: 1.0000 - val_loss: 0.6088 - val_accuracy: 0.9106\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2628 - accuracy: 1.0000 - val_loss: 0.5983 - val_accuracy: 0.9116\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2616 - accuracy: 1.0000 - val_loss: 0.6012 - val_accuracy: 0.9019\n","Epoch 96/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2608 - accuracy: 1.0000 - val_loss: 0.5936 - val_accuracy: 0.9073\n","Epoch 97/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2600 - accuracy: 1.0000 - val_loss: 0.5996 - val_accuracy: 0.9095\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2594 - accuracy: 1.0000 - val_loss: 0.6056 - val_accuracy: 0.9073\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2588 - accuracy: 1.0000 - val_loss: 0.5961 - val_accuracy: 0.9073\n","Epoch 100/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2582 - accuracy: 1.0000 - val_loss: 0.6019 - val_accuracy: 0.9084\n","{'loss': [0.38480523228645325, 0.3390747010707855, 0.3372541666030884, 0.3263839781284332, 0.32409361004829407, 0.32256385684013367, 0.3196427524089813, 0.31802722811698914, 0.3165530264377594, 0.31632083654403687, 0.32208526134490967, 0.31347596645355225, 0.3139558434486389, 0.31618550419807434, 0.3116176724433899, 0.3097020387649536, 0.3105263113975525, 0.3129015564918518, 0.31087690591812134, 0.31066757440567017, 0.31032174825668335, 0.30763742327690125, 0.30630239844322205, 0.3139868974685669, 0.306118905544281, 0.30280399322509766, 0.3035716414451599, 0.3018665313720703, 0.3010134994983673, 0.2995379567146301, 0.30021196603775024, 0.30067864060401917, 0.2996501624584198, 0.2985716760158539, 0.29877498745918274, 0.2972247302532196, 0.295098215341568, 0.29564687609672546, 0.2942548096179962, 0.2939431369304657, 0.2934013307094574, 0.2929003834724426, 0.2921035587787628, 0.2914889454841614, 0.29091668128967285, 0.29053136706352234, 0.2900319993495941, 0.2892304062843323, 0.2888535261154175, 0.2885253429412842, 0.28864920139312744, 0.2903446853160858, 0.2884216010570526, 0.28674402832984924, 0.2850223481655121, 0.28490394353866577, 0.2838793396949768, 0.28418007493019104, 0.2839078903198242, 0.2829711139202118, 0.28276526927948, 0.28185805678367615, 0.28120648860931396, 0.27996358275413513, 0.2795858681201935, 0.2828051745891571, 0.2904755175113678, 0.2794947028160095, 0.2772158682346344, 0.27675163745880127, 0.27556970715522766, 0.275438517332077, 0.27611348032951355, 0.27438247203826904, 0.27349111437797546, 0.2731131315231323, 0.273438960313797, 0.2740122973918915, 0.27149298787117004, 0.2724371552467346, 0.2713766396045685, 0.2693081200122833, 0.2696562707424164, 0.26885899901390076, 0.26809749007225037, 0.26725900173187256, 0.2664548456668854, 0.26590463519096375, 0.2654990553855896, 0.26450932025909424, 0.26477232575416565, 0.2648097276687622, 0.26337918639183044, 0.2628289461135864, 0.2616017460823059, 0.26082858443260193, 0.26004889607429504, 0.2593986988067627, 0.2587738335132599, 0.25824040174484253], 'accuracy': [0.9679418206214905, 0.9870689511299133, 0.9892241358757019, 0.9924569129943848, 0.9921875, 0.9943426847457886, 0.9956896305084229, 0.9967672228813171, 0.9964978694915771, 0.9964978694915771, 0.9943426847457886, 0.9978448152542114, 0.9970366358757019, 0.9964978694915771, 0.998383641242981, 0.998652994632721, 0.9989224076271057, 0.9975754022598267, 0.998652994632721, 0.9970366358757019, 0.9981142282485962, 0.998383641242981, 0.998652994632721, 0.9975754022598267, 0.9981142282485962, 0.9997305870056152, 0.9994612336158752, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152, 0.9991918206214905, 0.9991918206214905, 0.9991918206214905, 0.9991918206214905, 0.9994612336158752, 0.9994612336158752, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152, 1.0, 0.9997305870056152, 1.0, 1.0, 0.9997305870056152, 0.9997305870056152, 1.0, 0.9997305870056152, 0.9997305870056152, 1.0, 0.9997305870056152, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9989224076271057, 0.9964978694915771, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9994612336158752, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.8755040168762207, 0.857611894607544, 0.8620819449424744, 0.8336250185966492, 0.8150598406791687, 0.7977155447006226, 0.7806442379951477, 0.754109799861908, 0.7393619418144226, 0.7278879880905151, 0.6976262331008911, 0.7124301195144653, 0.6857782602310181, 0.6426188945770264, 0.6235450506210327, 0.632332980632782, 0.637359619140625, 0.6725392937660217, 0.6283293962478638, 0.5836595296859741, 0.5745174884796143, 0.6196078658103943, 0.605787992477417, 0.5752950310707092, 0.5634391903877258, 0.5582088232040405, 0.5570066571235657, 0.5677935481071472, 0.5561359524726868, 0.5584034323692322, 0.5830294489860535, 0.5699888467788696, 0.5713106393814087, 0.5770837664604187, 0.5765993595123291, 0.5692369937896729, 0.5657011866569519, 0.5722268223762512, 0.5701051950454712, 0.5766540765762329, 0.5738879442214966, 0.5814804434776306, 0.5773813724517822, 0.5781279802322388, 0.5856640934944153, 0.5834661722183228, 0.5849446058273315, 0.5864957571029663, 0.5831944942474365, 0.5943706035614014, 0.5945578813552856, 0.5980899930000305, 0.589389443397522, 0.5851083397865295, 0.5919464826583862, 0.5893595218658447, 0.5835778713226318, 0.5938659906387329, 0.6095893979072571, 0.593899667263031, 0.5955398082733154, 0.5939186811447144, 0.6111526489257812, 0.5937269330024719, 0.6054821610450745, 0.5958008766174316, 0.6509354114532471, 0.5904350876808167, 0.600813090801239, 0.5951958298683167, 0.5947685241699219, 0.590859055519104, 0.590974748134613, 0.5902137756347656, 0.592854380607605, 0.5953084826469421, 0.6226093173027039, 0.5998744964599609, 0.6090301871299744, 0.5924274325370789, 0.5983496308326721, 0.6069007515907288, 0.601706862449646, 0.5986570119857788, 0.6079415082931519, 0.6026315093040466, 0.6044283509254456, 0.6069223880767822, 0.5974447727203369, 0.5982416272163391, 0.5994784235954285, 0.6074586510658264, 0.6087697148323059, 0.5983380079269409, 0.6012389063835144, 0.5936052203178406, 0.5995827317237854, 0.6056237816810608, 0.5961175560951233, 0.601920485496521], 'val_accuracy': [0.8254310488700867, 0.8394396305084229, 0.7963362336158752, 0.8286637663841248, 0.8308189511299133, 0.8340517282485962, 0.8275862336158752, 0.8351293206214905, 0.829741358757019, 0.8200430870056152, 0.8340517282485962, 0.8125, 0.8232758641242981, 0.8448275923728943, 0.850215494632721, 0.850215494632721, 0.8469827771186829, 0.8318965435028076, 0.857758641242981, 0.875, 0.8825430870056152, 0.8696120977401733, 0.881465494632721, 0.9040948152542114, 0.8987069129943848, 0.90625, 0.9105603694915771, 0.9084051847457886, 0.9159482717514038, 0.9137930870056152, 0.9094827771186829, 0.9148706793785095, 0.912715494632721, 0.9148706793785095, 0.9159482717514038, 0.9159482717514038, 0.9170258641242981, 0.9148706793785095, 0.9170258641242981, 0.9094827771186829, 0.920258641242981, 0.9170258641242981, 0.9137930870056152, 0.9137930870056152, 0.9073275923728943, 0.9148706793785095, 0.9105603694915771, 0.9073275923728943, 0.9148706793785095, 0.912715494632721, 0.9051724076271057, 0.9073275923728943, 0.912715494632721, 0.912715494632721, 0.9105603694915771, 0.9084051847457886, 0.9148706793785095, 0.9094827771186829, 0.9116379022598267, 0.912715494632721, 0.9073275923728943, 0.9137930870056152, 0.90625, 0.9105603694915771, 0.9084051847457886, 0.9116379022598267, 0.892241358757019, 0.9105603694915771, 0.90625, 0.9105603694915771, 0.9051724076271057, 0.9105603694915771, 0.9137930870056152, 0.9105603694915771, 0.9084051847457886, 0.9084051847457886, 0.9116379022598267, 0.9040948152542114, 0.9019396305084229, 0.9191810488700867, 0.9084051847457886, 0.9008620977401733, 0.9030172228813171, 0.9019396305084229, 0.9008620977401733, 0.9073275923728943, 0.9094827771186829, 0.9051724076271057, 0.9084051847457886, 0.9084051847457886, 0.9040948152542114, 0.9030172228813171, 0.9105603694915771, 0.9116379022598267, 0.9019396305084229, 0.9073275923728943, 0.9094827771186829, 0.9073275923728943, 0.9073275923728943, 0.9084051847457886]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.3768 - accuracy: 0.9705"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 3s 36ms/step - loss: 0.3753 - accuracy: 0.9711 - val_loss: 0.8732 - val_accuracy: 0.8450\n","Epoch 2/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3358 - accuracy: 0.9884 - val_loss: 0.8655 - val_accuracy: 0.8247\n","Epoch 3/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3316 - accuracy: 0.9921 - val_loss: 0.8555 - val_accuracy: 0.8224\n","Epoch 4/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3323 - accuracy: 0.9904 - val_loss: 0.8359 - val_accuracy: 0.8337\n","Epoch 5/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3283 - accuracy: 0.9918 - val_loss: 0.8243 - val_accuracy: 0.8281\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3218 - accuracy: 0.9958 - val_loss: 0.8133 - val_accuracy: 0.8281\n","Epoch 7/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3202 - accuracy: 0.9969 - val_loss: 0.7893 - val_accuracy: 0.8348\n","Epoch 8/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3259 - accuracy: 0.9938 - val_loss: 0.7601 - val_accuracy: 0.8360\n","Epoch 9/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3177 - accuracy: 0.9969 - val_loss: 0.7511 - val_accuracy: 0.8382\n","Epoch 10/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3182 - accuracy: 0.9966 - val_loss: 0.7338 - val_accuracy: 0.8326\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3184 - accuracy: 0.9960 - val_loss: 0.7347 - val_accuracy: 0.8156\n","Epoch 12/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3204 - accuracy: 0.9960 - val_loss: 0.6997 - val_accuracy: 0.8371\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3134 - accuracy: 0.9980 - val_loss: 0.6842 - val_accuracy: 0.8326\n","Epoch 14/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3145 - accuracy: 0.9975 - val_loss: 0.6521 - val_accuracy: 0.8462\n","Epoch 15/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3187 - accuracy: 0.9941 - val_loss: 0.6555 - val_accuracy: 0.8439\n","Epoch 16/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3123 - accuracy: 0.9986 - val_loss: 0.6577 - val_accuracy: 0.8348\n","Epoch 17/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3178 - accuracy: 0.9949 - val_loss: 0.6207 - val_accuracy: 0.8563\n","Epoch 18/100\n","28/28 [==============================] - 1s 39ms/step - loss: 0.3132 - accuracy: 0.9977 - val_loss: 0.6279 - val_accuracy: 0.8575\n","Epoch 19/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3098 - accuracy: 0.9994 - val_loss: 0.6146 - val_accuracy: 0.8665\n","Epoch 20/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3079 - accuracy: 0.9983 - val_loss: 0.5944 - val_accuracy: 0.8801\n","Epoch 21/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3116 - accuracy: 0.9989 - val_loss: 0.6024 - val_accuracy: 0.8756\n","Epoch 22/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3069 - accuracy: 0.9989 - val_loss: 0.5774 - val_accuracy: 0.8857\n","Epoch 23/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3081 - accuracy: 0.9983 - val_loss: 0.6018 - val_accuracy: 0.8744\n","Epoch 24/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3062 - accuracy: 0.9989 - val_loss: 0.5708 - val_accuracy: 0.8903\n","Epoch 25/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3069 - accuracy: 0.9997 - val_loss: 0.5575 - val_accuracy: 0.9005\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3040 - accuracy: 0.9989 - val_loss: 0.5553 - val_accuracy: 0.9005\n","Epoch 27/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3021 - accuracy: 0.9997 - val_loss: 0.5549 - val_accuracy: 0.9072\n","Epoch 28/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3026 - accuracy: 0.9997 - val_loss: 0.5582 - val_accuracy: 0.9027\n","Epoch 29/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3031 - accuracy: 0.9997 - val_loss: 0.5535 - val_accuracy: 0.9129\n","Epoch 30/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3063 - accuracy: 0.9986 - val_loss: 0.5899 - val_accuracy: 0.8971\n","Epoch 31/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3019 - accuracy: 0.9989 - val_loss: 0.5677 - val_accuracy: 0.9038\n","Epoch 32/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3006 - accuracy: 0.9997 - val_loss: 0.5706 - val_accuracy: 0.9027\n","Epoch 33/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.2991 - accuracy: 1.0000 - val_loss: 0.5664 - val_accuracy: 0.9140\n","Epoch 34/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2985 - accuracy: 0.9997 - val_loss: 0.5655 - val_accuracy: 0.9106\n","Epoch 35/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2982 - accuracy: 1.0000 - val_loss: 0.5550 - val_accuracy: 0.9106\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2969 - accuracy: 0.9997 - val_loss: 0.5585 - val_accuracy: 0.9084\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2973 - accuracy: 1.0000 - val_loss: 0.5699 - val_accuracy: 0.9129\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2956 - accuracy: 1.0000 - val_loss: 0.5699 - val_accuracy: 0.9095\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2948 - accuracy: 1.0000 - val_loss: 0.5632 - val_accuracy: 0.9061\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2943 - accuracy: 1.0000 - val_loss: 0.5758 - val_accuracy: 0.9095\n","Epoch 41/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2936 - accuracy: 0.9997 - val_loss: 0.5668 - val_accuracy: 0.9072\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2931 - accuracy: 1.0000 - val_loss: 0.5765 - val_accuracy: 0.9027\n","Epoch 43/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2931 - accuracy: 1.0000 - val_loss: 0.5637 - val_accuracy: 0.9061\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2922 - accuracy: 1.0000 - val_loss: 0.5771 - val_accuracy: 0.9005\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2921 - accuracy: 1.0000 - val_loss: 0.5942 - val_accuracy: 0.8982\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2937 - accuracy: 0.9994 - val_loss: 0.5920 - val_accuracy: 0.9095\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2931 - accuracy: 0.9994 - val_loss: 0.5692 - val_accuracy: 0.9072\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2902 - accuracy: 1.0000 - val_loss: 0.5723 - val_accuracy: 0.9050\n","Epoch 49/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2898 - accuracy: 1.0000 - val_loss: 0.6167 - val_accuracy: 0.8903\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2925 - accuracy: 1.0000 - val_loss: 0.5837 - val_accuracy: 0.9095\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2925 - accuracy: 0.9997 - val_loss: 0.6024 - val_accuracy: 0.8937\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2915 - accuracy: 0.9994 - val_loss: 0.5701 - val_accuracy: 0.9038\n","Epoch 53/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2874 - accuracy: 1.0000 - val_loss: 0.5711 - val_accuracy: 0.9106\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2897 - accuracy: 1.0000 - val_loss: 0.5980 - val_accuracy: 0.9061\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2870 - accuracy: 1.0000 - val_loss: 0.5974 - val_accuracy: 0.9005\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2858 - accuracy: 1.0000 - val_loss: 0.5785 - val_accuracy: 0.9084\n","Epoch 57/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2867 - accuracy: 1.0000 - val_loss: 0.6751 - val_accuracy: 0.8824\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2875 - accuracy: 1.0000 - val_loss: 0.5744 - val_accuracy: 0.9038\n","Epoch 59/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2838 - accuracy: 1.0000 - val_loss: 0.5926 - val_accuracy: 0.9005\n","Epoch 60/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2847 - accuracy: 1.0000 - val_loss: 0.5814 - val_accuracy: 0.9106\n","Epoch 61/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2851 - accuracy: 0.9997 - val_loss: 0.5811 - val_accuracy: 0.9072\n","Epoch 62/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2835 - accuracy: 1.0000 - val_loss: 0.5815 - val_accuracy: 0.9038\n","Epoch 63/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2818 - accuracy: 1.0000 - val_loss: 0.5781 - val_accuracy: 0.9027\n","Epoch 64/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2822 - accuracy: 1.0000 - val_loss: 0.6127 - val_accuracy: 0.8948\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2811 - accuracy: 1.0000 - val_loss: 0.5753 - val_accuracy: 0.9050\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2800 - accuracy: 1.0000 - val_loss: 0.6003 - val_accuracy: 0.8993\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2800 - accuracy: 1.0000 - val_loss: 0.5752 - val_accuracy: 0.9084\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2790 - accuracy: 1.0000 - val_loss: 0.5896 - val_accuracy: 0.9016\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2784 - accuracy: 1.0000 - val_loss: 0.5797 - val_accuracy: 0.9061\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2775 - accuracy: 1.0000 - val_loss: 0.5790 - val_accuracy: 0.9050\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2774 - accuracy: 1.0000 - val_loss: 0.5760 - val_accuracy: 0.9061\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2764 - accuracy: 1.0000 - val_loss: 0.5747 - val_accuracy: 0.9072\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2764 - accuracy: 1.0000 - val_loss: 0.5821 - val_accuracy: 0.9095\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2755 - accuracy: 1.0000 - val_loss: 0.5922 - val_accuracy: 0.9061\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2760 - accuracy: 1.0000 - val_loss: 0.5782 - val_accuracy: 0.9038\n","Epoch 76/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2742 - accuracy: 1.0000 - val_loss: 0.5760 - val_accuracy: 0.9027\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2747 - accuracy: 1.0000 - val_loss: 0.5812 - val_accuracy: 0.9050\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2735 - accuracy: 1.0000 - val_loss: 0.5806 - val_accuracy: 0.9084\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2727 - accuracy: 1.0000 - val_loss: 0.5878 - val_accuracy: 0.9016\n","Epoch 80/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2734 - accuracy: 1.0000 - val_loss: 0.5847 - val_accuracy: 0.9005\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2717 - accuracy: 1.0000 - val_loss: 0.5837 - val_accuracy: 0.9050\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2708 - accuracy: 1.0000 - val_loss: 0.5803 - val_accuracy: 0.9050\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2702 - accuracy: 1.0000 - val_loss: 0.5831 - val_accuracy: 0.9050\n","Epoch 84/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2719 - accuracy: 1.0000 - val_loss: 0.5895 - val_accuracy: 0.9016\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2700 - accuracy: 1.0000 - val_loss: 0.5939 - val_accuracy: 0.9016\n","Epoch 86/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2705 - accuracy: 1.0000 - val_loss: 0.5735 - val_accuracy: 0.9016\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2677 - accuracy: 1.0000 - val_loss: 0.5814 - val_accuracy: 0.9027\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2669 - accuracy: 1.0000 - val_loss: 0.5817 - val_accuracy: 0.9005\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2663 - accuracy: 1.0000 - val_loss: 0.5804 - val_accuracy: 0.8993\n","Epoch 90/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2679 - accuracy: 1.0000 - val_loss: 0.5936 - val_accuracy: 0.9005\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2703 - accuracy: 0.9997 - val_loss: 0.5916 - val_accuracy: 0.9050\n","Epoch 92/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2660 - accuracy: 1.0000 - val_loss: 0.5815 - val_accuracy: 0.9038\n","Epoch 93/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2645 - accuracy: 1.0000 - val_loss: 0.5829 - val_accuracy: 0.9050\n","Epoch 94/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2635 - accuracy: 1.0000 - val_loss: 0.5839 - val_accuracy: 0.9050\n","Epoch 95/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2627 - accuracy: 1.0000 - val_loss: 0.5912 - val_accuracy: 0.9038\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2622 - accuracy: 1.0000 - val_loss: 0.5792 - val_accuracy: 0.9027\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2617 - accuracy: 1.0000 - val_loss: 0.6176 - val_accuracy: 0.8903\n","Epoch 98/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2612 - accuracy: 1.0000 - val_loss: 0.5827 - val_accuracy: 0.9027\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2607 - accuracy: 1.0000 - val_loss: 0.5811 - val_accuracy: 0.9027\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2606 - accuracy: 1.0000 - val_loss: 0.5951 - val_accuracy: 0.8993\n","{'loss': [0.37534159421920776, 0.33577004075050354, 0.3315616250038147, 0.3322634994983673, 0.3283303380012512, 0.32180020213127136, 0.3201902508735657, 0.3259272575378418, 0.317725270986557, 0.31822669506073, 0.3184061348438263, 0.3204093277454376, 0.3133883476257324, 0.3144666254520416, 0.318666011095047, 0.3122553527355194, 0.31780073046684265, 0.3132475018501282, 0.3097791075706482, 0.3078641891479492, 0.3116336166858673, 0.30686643719673157, 0.3080716133117676, 0.30618348717689514, 0.30685117840766907, 0.30403265357017517, 0.3021320402622223, 0.302560418844223, 0.3031466603279114, 0.3062693774700165, 0.3018813729286194, 0.3006286323070526, 0.2991098165512085, 0.2984973192214966, 0.29822251200675964, 0.2969169020652771, 0.29726940393447876, 0.29556503891944885, 0.29483646154403687, 0.2942838668823242, 0.29361456632614136, 0.2931104004383087, 0.2930585443973541, 0.29215049743652344, 0.2921120524406433, 0.2937231957912445, 0.293145090341568, 0.2901538908481598, 0.28979602456092834, 0.29246851801872253, 0.29252904653549194, 0.29151827096939087, 0.2874305844306946, 0.28971415758132935, 0.28704264760017395, 0.2858169972896576, 0.2867315709590912, 0.28754255175590515, 0.2837730944156647, 0.28469330072402954, 0.2850542366504669, 0.2834635376930237, 0.28184783458709717, 0.28221502900123596, 0.2810988426208496, 0.2799517810344696, 0.2799653112888336, 0.27904215455055237, 0.27840694785118103, 0.27747970819473267, 0.2773592472076416, 0.27642321586608887, 0.27637144923210144, 0.2754519283771515, 0.2759619355201721, 0.2741951644420624, 0.2746695876121521, 0.2735210657119751, 0.2727384567260742, 0.273386687040329, 0.27170810103416443, 0.2708177864551544, 0.27019748091697693, 0.27190101146698, 0.27000394463539124, 0.27050724625587463, 0.2677408754825592, 0.2669312357902527, 0.2663404643535614, 0.2679106891155243, 0.27032288908958435, 0.26600271463394165, 0.2645374834537506, 0.2634526193141937, 0.2626689374446869, 0.26218733191490173, 0.2617489993572235, 0.2612178921699524, 0.26065656542778015, 0.2606370747089386], 'accuracy': [0.971137523651123, 0.9883984327316284, 0.9920769929885864, 0.9903791546821594, 0.9917939901351929, 0.9957554936408997, 0.9968873858451843, 0.9937747716903687, 0.9968873858451843, 0.9966044425964355, 0.9960384964942932, 0.9960384964942932, 0.9980192184448242, 0.9974533319473267, 0.9940577149391174, 0.9985851645469666, 0.9949066042900085, 0.9977362751960754, 0.9994340538978577, 0.9983022212982178, 0.9988681674003601, 0.9988681674003601, 0.9983022212982178, 0.9988681674003601, 0.9997170567512512, 0.9988681674003601, 0.9997170567512512, 0.9997170567512512, 0.9997170567512512, 0.9985851645469666, 0.9988681674003601, 0.9997170567512512, 1.0, 0.9997170567512512, 1.0, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 0.9994340538978577, 0.9994340538978577, 1.0, 1.0, 1.0, 0.9997170567512512, 0.9994340538978577, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.8731837272644043, 0.8654932379722595, 0.8555145263671875, 0.8359360098838806, 0.8243361711502075, 0.813270092010498, 0.7892822027206421, 0.7601099610328674, 0.7510651350021362, 0.7337578535079956, 0.7347316145896912, 0.6996924877166748, 0.6842237114906311, 0.6521139740943909, 0.6555260419845581, 0.6576904058456421, 0.6207395792007446, 0.6278694868087769, 0.6145552396774292, 0.5944225788116455, 0.6023539304733276, 0.5773545503616333, 0.6018213629722595, 0.5708119869232178, 0.5575181841850281, 0.5553150177001953, 0.5548866987228394, 0.5581883788108826, 0.5535224676132202, 0.5898627638816833, 0.5676746964454651, 0.5706197023391724, 0.5664193630218506, 0.5655043125152588, 0.555010974407196, 0.558480978012085, 0.5699324011802673, 0.5699253082275391, 0.5631891489028931, 0.5758016705513, 0.5668278932571411, 0.576470673084259, 0.5636893510818481, 0.5770519375801086, 0.5942373871803284, 0.591954231262207, 0.5692465305328369, 0.57234787940979, 0.6166675686836243, 0.5837080478668213, 0.6023503541946411, 0.5701331496238708, 0.5710737705230713, 0.5979521870613098, 0.5974257588386536, 0.578468918800354, 0.675108015537262, 0.5744314193725586, 0.5926178693771362, 0.5813896059989929, 0.5810787081718445, 0.5815457105636597, 0.5781449675559998, 0.6127276420593262, 0.5753063559532166, 0.6003090143203735, 0.575232744216919, 0.5895577669143677, 0.5796670317649841, 0.5790402293205261, 0.5760294198989868, 0.5746975541114807, 0.5820969343185425, 0.5921871662139893, 0.5781534314155579, 0.5759653449058533, 0.5812421441078186, 0.5806382298469543, 0.5877940058708191, 0.5847358107566833, 0.5837295055389404, 0.5802985429763794, 0.5830986499786377, 0.5894783735275269, 0.5938535928726196, 0.57347571849823, 0.5813673734664917, 0.5817325711250305, 0.5803624391555786, 0.5935532450675964, 0.5916343927383423, 0.5814849138259888, 0.5829235911369324, 0.583911120891571, 0.5911942720413208, 0.5792084336280823, 0.6175541877746582, 0.5827099680900574, 0.5810949206352234, 0.5950527787208557], 'val_accuracy': [0.8450226187705994, 0.8246606588363647, 0.8223981857299805, 0.8337104320526123, 0.8280543088912964, 0.8280543088912964, 0.8348416090011597, 0.8359728455543518, 0.8382353186607361, 0.8325791954994202, 0.8156108856201172, 0.837104082107544, 0.8325791954994202, 0.8461538553237915, 0.8438913822174072, 0.8348416090011597, 0.8563348650932312, 0.8574660420417786, 0.8665158152580261, 0.8800904750823975, 0.8755655884742737, 0.8857465982437134, 0.8744344115257263, 0.8902714848518372, 0.9004524946212769, 0.9004524946212769, 0.9072397947311401, 0.9027149081230164, 0.912895917892456, 0.8970588445663452, 0.9038461446762085, 0.9027149081230164, 0.9140271544456482, 0.9106335043907166, 0.9106335043907166, 0.9083710312843323, 0.912895917892456, 0.9095022678375244, 0.9061086177825928, 0.9095022678375244, 0.9072397947311401, 0.9027149081230164, 0.9061086177825928, 0.9004524946212769, 0.8981900215148926, 0.9095022678375244, 0.9072397947311401, 0.9049773812294006, 0.8902714848518372, 0.9095022678375244, 0.8936651349067688, 0.9038461446762085, 0.9106335043907166, 0.9061086177825928, 0.9004524946212769, 0.9083710312843323, 0.8823529481887817, 0.9038461446762085, 0.9004524946212769, 0.9106335043907166, 0.9072397947311401, 0.9038461446762085, 0.9027149081230164, 0.8947963714599609, 0.9049773812294006, 0.8993212580680847, 0.9083710312843323, 0.901583731174469, 0.9061086177825928, 0.9049773812294006, 0.9061086177825928, 0.9072397947311401, 0.9095022678375244, 0.9061086177825928, 0.9038461446762085, 0.9027149081230164, 0.9049773812294006, 0.9083710312843323, 0.901583731174469, 0.9004524946212769, 0.9049773812294006, 0.9049773812294006, 0.9049773812294006, 0.901583731174469, 0.901583731174469, 0.901583731174469, 0.9027149081230164, 0.9004524946212769, 0.8993212580680847, 0.9004524946212769, 0.9049773812294006, 0.9038461446762085, 0.9049773812294006, 0.9049773812294006, 0.9038461446762085, 0.9027149081230164, 0.8902714848518372, 0.9027149081230164, 0.9027149081230164, 0.8993212580680847]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.3826 - accuracy: 0.9704"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 4s 39ms/step - loss: 0.3806 - accuracy: 0.9713 - val_loss: 0.8727 - val_accuracy: 0.8378\n","Epoch 2/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3398 - accuracy: 0.9866 - val_loss: 0.8704 - val_accuracy: 0.8151\n","Epoch 3/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3347 - accuracy: 0.9881 - val_loss: 0.8495 - val_accuracy: 0.8223\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3285 - accuracy: 0.9920 - val_loss: 0.8258 - val_accuracy: 0.8337\n","Epoch 5/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3274 - accuracy: 0.9925 - val_loss: 0.8189 - val_accuracy: 0.8120\n","Epoch 6/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3236 - accuracy: 0.9938 - val_loss: 0.7955 - val_accuracy: 0.8151\n","Epoch 7/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3212 - accuracy: 0.9959 - val_loss: 0.7646 - val_accuracy: 0.8337\n","Epoch 8/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3204 - accuracy: 0.9959 - val_loss: 0.7749 - val_accuracy: 0.7862\n","Epoch 9/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3211 - accuracy: 0.9943 - val_loss: 0.7247 - val_accuracy: 0.8316\n","Epoch 10/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3194 - accuracy: 0.9959 - val_loss: 0.7194 - val_accuracy: 0.8151\n","Epoch 11/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3226 - accuracy: 0.9935 - val_loss: 0.7276 - val_accuracy: 0.7872\n","Epoch 12/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3258 - accuracy: 0.9920 - val_loss: 0.7057 - val_accuracy: 0.7986\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3174 - accuracy: 0.9964 - val_loss: 0.6442 - val_accuracy: 0.8512\n","Epoch 14/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3136 - accuracy: 0.9974 - val_loss: 0.6504 - val_accuracy: 0.8430\n","Epoch 15/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3144 - accuracy: 0.9966 - val_loss: 0.6262 - val_accuracy: 0.8616\n","Epoch 16/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3131 - accuracy: 0.9977 - val_loss: 0.6281 - val_accuracy: 0.8616\n","Epoch 17/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3102 - accuracy: 0.9987 - val_loss: 0.6297 - val_accuracy: 0.8616\n","Epoch 18/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3097 - accuracy: 0.9984 - val_loss: 0.6288 - val_accuracy: 0.8719\n","Epoch 19/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3093 - accuracy: 0.9987 - val_loss: 0.6262 - val_accuracy: 0.8709\n","Epoch 20/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3107 - accuracy: 0.9979 - val_loss: 0.6228 - val_accuracy: 0.8812\n","Epoch 21/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3093 - accuracy: 0.9974 - val_loss: 0.6265 - val_accuracy: 0.8843\n","Epoch 22/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3066 - accuracy: 0.9995 - val_loss: 0.6277 - val_accuracy: 0.8833\n","Epoch 23/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3067 - accuracy: 0.9990 - val_loss: 0.6290 - val_accuracy: 0.8822\n","Epoch 24/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3049 - accuracy: 0.9997 - val_loss: 0.6226 - val_accuracy: 0.8905\n","Epoch 25/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3037 - accuracy: 0.9992 - val_loss: 0.6754 - val_accuracy: 0.8864\n","Epoch 26/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3096 - accuracy: 0.9961 - val_loss: 0.6246 - val_accuracy: 0.8884\n","Epoch 27/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3023 - accuracy: 0.9997 - val_loss: 0.6474 - val_accuracy: 0.8791\n","Epoch 28/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3022 - accuracy: 0.9997 - val_loss: 0.6277 - val_accuracy: 0.8957\n","Epoch 29/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3012 - accuracy: 1.0000 - val_loss: 0.6411 - val_accuracy: 0.8988\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3018 - accuracy: 0.9995 - val_loss: 0.6725 - val_accuracy: 0.8791\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3013 - accuracy: 0.9992 - val_loss: 0.6428 - val_accuracy: 0.8915\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3063 - accuracy: 0.9961 - val_loss: 0.7646 - val_accuracy: 0.8688\n","Epoch 33/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3028 - accuracy: 0.9982 - val_loss: 0.6545 - val_accuracy: 0.8967\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3009 - accuracy: 0.9987 - val_loss: 0.6834 - val_accuracy: 0.8822\n","Epoch 35/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3153 - accuracy: 0.9925 - val_loss: 0.7191 - val_accuracy: 0.8802\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3025 - accuracy: 0.9977 - val_loss: 0.6662 - val_accuracy: 0.8833\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2974 - accuracy: 0.9997 - val_loss: 0.6604 - val_accuracy: 0.8946\n","Epoch 38/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2968 - accuracy: 0.9990 - val_loss: 0.7073 - val_accuracy: 0.8791\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3002 - accuracy: 0.9990 - val_loss: 0.6566 - val_accuracy: 0.8874\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2946 - accuracy: 1.0000 - val_loss: 0.6605 - val_accuracy: 0.8905\n","Epoch 41/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2937 - accuracy: 1.0000 - val_loss: 0.6643 - val_accuracy: 0.8843\n","Epoch 42/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2927 - accuracy: 1.0000 - val_loss: 0.6633 - val_accuracy: 0.8936\n","Epoch 43/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2927 - accuracy: 1.0000 - val_loss: 0.6679 - val_accuracy: 0.8853\n","Epoch 44/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2923 - accuracy: 1.0000 - val_loss: 0.6667 - val_accuracy: 0.8874\n","Epoch 45/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2927 - accuracy: 1.0000 - val_loss: 0.6583 - val_accuracy: 0.8926\n","Epoch 46/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2905 - accuracy: 1.0000 - val_loss: 0.6628 - val_accuracy: 0.8936\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2903 - accuracy: 1.0000 - val_loss: 0.6719 - val_accuracy: 0.8843\n","Epoch 48/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2923 - accuracy: 1.0000 - val_loss: 0.6661 - val_accuracy: 0.8833\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2906 - accuracy: 0.9997 - val_loss: 0.6655 - val_accuracy: 0.8915\n","Epoch 50/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2900 - accuracy: 1.0000 - val_loss: 0.6760 - val_accuracy: 0.8833\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2885 - accuracy: 0.9997 - val_loss: 0.6850 - val_accuracy: 0.8864\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2899 - accuracy: 0.9995 - val_loss: 0.6743 - val_accuracy: 0.8905\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2867 - accuracy: 1.0000 - val_loss: 0.6902 - val_accuracy: 0.8926\n","Epoch 54/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2880 - accuracy: 1.0000 - val_loss: 0.6790 - val_accuracy: 0.8864\n","Epoch 55/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2862 - accuracy: 1.0000 - val_loss: 0.6737 - val_accuracy: 0.8822\n","Epoch 56/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2854 - accuracy: 1.0000 - val_loss: 0.6836 - val_accuracy: 0.8802\n","Epoch 57/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2849 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.8864\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2842 - accuracy: 1.0000 - val_loss: 0.6720 - val_accuracy: 0.8864\n","Epoch 59/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2830 - accuracy: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.8926\n","Epoch 60/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2825 - accuracy: 1.0000 - val_loss: 0.6859 - val_accuracy: 0.8895\n","Epoch 61/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2842 - accuracy: 0.9995 - val_loss: 0.6811 - val_accuracy: 0.8853\n","Epoch 62/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2820 - accuracy: 1.0000 - val_loss: 0.6771 - val_accuracy: 0.8853\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2822 - accuracy: 1.0000 - val_loss: 0.6746 - val_accuracy: 0.8812\n","Epoch 64/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2810 - accuracy: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.8843\n","Epoch 65/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2809 - accuracy: 0.9997 - val_loss: 0.6904 - val_accuracy: 0.8874\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2793 - accuracy: 1.0000 - val_loss: 0.6788 - val_accuracy: 0.8791\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2787 - accuracy: 1.0000 - val_loss: 0.6799 - val_accuracy: 0.8853\n","Epoch 68/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2785 - accuracy: 1.0000 - val_loss: 0.6880 - val_accuracy: 0.8874\n","Epoch 69/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2776 - accuracy: 1.0000 - val_loss: 0.6851 - val_accuracy: 0.8864\n","Epoch 70/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2768 - accuracy: 1.0000 - val_loss: 0.6863 - val_accuracy: 0.8843\n","Epoch 71/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2782 - accuracy: 0.9997 - val_loss: 0.6850 - val_accuracy: 0.8833\n","Epoch 72/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2756 - accuracy: 1.0000 - val_loss: 0.6820 - val_accuracy: 0.8812\n","Epoch 73/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2757 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.8884\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2748 - accuracy: 1.0000 - val_loss: 0.7025 - val_accuracy: 0.8853\n","Epoch 75/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2772 - accuracy: 0.9992 - val_loss: 0.7012 - val_accuracy: 0.8884\n","Epoch 76/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2739 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.8833\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2723 - accuracy: 1.0000 - val_loss: 0.6895 - val_accuracy: 0.8843\n","Epoch 78/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2718 - accuracy: 1.0000 - val_loss: 0.6913 - val_accuracy: 0.8822\n","Epoch 79/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2716 - accuracy: 1.0000 - val_loss: 0.6994 - val_accuracy: 0.8781\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2716 - accuracy: 1.0000 - val_loss: 0.7062 - val_accuracy: 0.8833\n","Epoch 81/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2708 - accuracy: 1.0000 - val_loss: 0.6892 - val_accuracy: 0.8822\n","Epoch 82/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2716 - accuracy: 1.0000 - val_loss: 0.6988 - val_accuracy: 0.8853\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2693 - accuracy: 0.9997 - val_loss: 0.6939 - val_accuracy: 0.8833\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2688 - accuracy: 1.0000 - val_loss: 0.7192 - val_accuracy: 0.8833\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2694 - accuracy: 0.9997 - val_loss: 0.6892 - val_accuracy: 0.8812\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2672 - accuracy: 1.0000 - val_loss: 0.7351 - val_accuracy: 0.8802\n","Epoch 87/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2718 - accuracy: 0.9982 - val_loss: 0.9189 - val_accuracy: 0.8347\n","Epoch 88/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7953 - accuracy: 0.8770 - val_loss: 0.8798 - val_accuracy: 0.8533\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3068 - accuracy: 0.9850 - val_loss: 0.6467 - val_accuracy: 0.8833\n","Epoch 90/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2729 - accuracy: 0.9992 - val_loss: 0.6558 - val_accuracy: 0.8802\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2699 - accuracy: 0.9997 - val_loss: 0.6505 - val_accuracy: 0.8760\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2684 - accuracy: 1.0000 - val_loss: 0.6496 - val_accuracy: 0.8853\n","Epoch 93/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2680 - accuracy: 1.0000 - val_loss: 0.6582 - val_accuracy: 0.8760\n","Epoch 94/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2670 - accuracy: 1.0000 - val_loss: 0.6545 - val_accuracy: 0.8802\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2663 - accuracy: 0.9997 - val_loss: 0.6687 - val_accuracy: 0.8791\n","Epoch 96/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2677 - accuracy: 0.9997 - val_loss: 0.6571 - val_accuracy: 0.8791\n","Epoch 97/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2658 - accuracy: 1.0000 - val_loss: 0.6607 - val_accuracy: 0.8822\n","Epoch 98/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2652 - accuracy: 1.0000 - val_loss: 0.6620 - val_accuracy: 0.8791\n","Epoch 99/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2646 - accuracy: 1.0000 - val_loss: 0.6697 - val_accuracy: 0.8822\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2643 - accuracy: 1.0000 - val_loss: 0.6666 - val_accuracy: 0.8791\n","{'loss': [0.3806077837944031, 0.3397884666919708, 0.3346680700778961, 0.3284858763217926, 0.32741859555244446, 0.3236440420150757, 0.32121601700782776, 0.3204367160797119, 0.3211198151111603, 0.31937408447265625, 0.32255789637565613, 0.32577553391456604, 0.3173857629299164, 0.3135813772678375, 0.31440359354019165, 0.31309181451797485, 0.31018516421318054, 0.3096930980682373, 0.3093411326408386, 0.3106905519962311, 0.30929309129714966, 0.30662667751312256, 0.3066825866699219, 0.3049359917640686, 0.30372515320777893, 0.30961450934410095, 0.3023263216018677, 0.3021763563156128, 0.3012242019176483, 0.30178597569465637, 0.30131521821022034, 0.3063352108001709, 0.3028360903263092, 0.3008953034877777, 0.31527701020240784, 0.30247098207473755, 0.2974022328853607, 0.29681867361068726, 0.3001748323440552, 0.2946232557296753, 0.29367873072624207, 0.29273563623428345, 0.29267722368240356, 0.292292982339859, 0.29269322752952576, 0.29053211212158203, 0.2902998924255371, 0.29231351613998413, 0.2906039357185364, 0.2899685502052307, 0.2884974479675293, 0.28986304998397827, 0.28667762875556946, 0.2879634499549866, 0.28617995977401733, 0.28539809584617615, 0.28487902879714966, 0.2841876447200775, 0.28299856185913086, 0.28254616260528564, 0.28419747948646545, 0.2819998562335968, 0.2821645736694336, 0.2809576988220215, 0.2808639109134674, 0.2793005108833313, 0.2786623537540436, 0.2785186171531677, 0.27759960293769836, 0.2768484354019165, 0.27821245789527893, 0.2756167948246002, 0.2757346034049988, 0.2747841775417328, 0.27716994285583496, 0.273861825466156, 0.2722721993923187, 0.27175265550613403, 0.2715829312801361, 0.27157989144325256, 0.270805299282074, 0.27160507440567017, 0.2692788243293762, 0.2687830924987793, 0.26944369077682495, 0.2672246992588043, 0.2717534899711609, 0.7952703237533569, 0.30677300691604614, 0.2728988826274872, 0.2699446976184845, 0.26837190985679626, 0.26797860860824585, 0.267002671957016, 0.26627489924430847, 0.26766911149024963, 0.26577162742614746, 0.26524659991264343, 0.26457419991493225, 0.26429203152656555], 'accuracy': [0.9713178277015686, 0.9865633249282837, 0.9881137013435364, 0.9919896721839905, 0.9925064444541931, 0.9937984347343445, 0.9958656430244446, 0.9958656430244446, 0.9943152666091919, 0.9958656430244446, 0.9935400485992432, 0.9919896721839905, 0.9963824152946472, 0.9974160194396973, 0.9966408014297485, 0.9976744055747986, 0.9987080097198486, 0.9984496235847473, 0.9987080097198486, 0.9979327917098999, 0.9974160194396973, 0.9994832277297974, 0.99896639585495, 0.9997416138648987, 0.9992247819900513, 0.9961240291595459, 0.9997416138648987, 0.9997416138648987, 1.0, 0.9994832277297974, 0.9992247819900513, 0.9961240291595459, 0.998191237449646, 0.9987080097198486, 0.9925064444541931, 0.9976744055747986, 0.9997416138648987, 0.99896639585495, 0.99896639585495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0, 0.9997416138648987, 0.9994832277297974, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9994832277297974, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0, 1.0, 1.0, 0.9992247819900513, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0, 0.9997416138648987, 1.0, 0.998191237449646, 0.8770025968551636, 0.985012948513031, 0.9992247819900513, 0.9997416138648987, 1.0, 1.0, 1.0, 0.9997416138648987, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.872749388217926, 0.8703652620315552, 0.8495050072669983, 0.8258208632469177, 0.8189300298690796, 0.7955238223075867, 0.764583945274353, 0.7748705744743347, 0.724693238735199, 0.7193796038627625, 0.7276415824890137, 0.7057178020477295, 0.6441883444786072, 0.650428056716919, 0.6261643171310425, 0.6281492114067078, 0.629654049873352, 0.6288280487060547, 0.6261675357818604, 0.6227525472640991, 0.6265245079994202, 0.6276905536651611, 0.6290329694747925, 0.6225895285606384, 0.6753987073898315, 0.6245834827423096, 0.6473798751831055, 0.6276658773422241, 0.6411258578300476, 0.6724666357040405, 0.6428084373474121, 0.7645891308784485, 0.6545453071594238, 0.6833983659744263, 0.7191022634506226, 0.6662494540214539, 0.6604124903678894, 0.7072904706001282, 0.656558096408844, 0.660541296005249, 0.6643076539039612, 0.663303017616272, 0.6678578853607178, 0.6667317748069763, 0.6582798361778259, 0.6627882719039917, 0.6719377040863037, 0.6660610437393188, 0.6655400991439819, 0.6759909391403198, 0.6849949955940247, 0.6743050217628479, 0.6901831030845642, 0.6790043711662292, 0.6737435460090637, 0.6835718154907227, 0.6818281412124634, 0.6720009446144104, 0.68222975730896, 0.6859486699104309, 0.6811089515686035, 0.6770575046539307, 0.6745986938476562, 0.6869756579399109, 0.6904322504997253, 0.6788246631622314, 0.6799072623252869, 0.6880306005477905, 0.6851218938827515, 0.686337411403656, 0.6849848628044128, 0.6820383667945862, 0.7178158164024353, 0.7024619579315186, 0.7012012600898743, 0.6893066763877869, 0.6895095109939575, 0.6913416385650635, 0.6994080543518066, 0.706188976764679, 0.6892306804656982, 0.698832094669342, 0.693852424621582, 0.719228208065033, 0.6891544461250305, 0.7351102232933044, 0.9189426898956299, 0.8798071146011353, 0.646746814250946, 0.6558097004890442, 0.6504757404327393, 0.6496098041534424, 0.658243715763092, 0.6544767022132874, 0.6687375903129578, 0.6570903062820435, 0.6607444882392883, 0.6620479226112366, 0.6696505546569824, 0.6665787100791931], 'val_accuracy': [0.8378099203109741, 0.8150826692581177, 0.8223140239715576, 0.8336777091026306, 0.8119834661483765, 0.8150826692581177, 0.8336777091026306, 0.7861570119857788, 0.8316115736961365, 0.8150826692581177, 0.7871900796890259, 0.7985537052154541, 0.8512396812438965, 0.8429751992225647, 0.8615702390670776, 0.8615702390670776, 0.8615702390670776, 0.8719007968902588, 0.8708677887916565, 0.8811983466148376, 0.8842975497245789, 0.8832644820213318, 0.8822314143180847, 0.8904958963394165, 0.8863636255264282, 0.8884297609329224, 0.8791322112083435, 0.8956611752510071, 0.8987603187561035, 0.8791322112083435, 0.8915289044380188, 0.8688016533851624, 0.8966942429542542, 0.8822314143180847, 0.8801652789115906, 0.8832644820213318, 0.89462810754776, 0.8791322112083435, 0.8873966932296753, 0.8904958963394165, 0.8842975497245789, 0.8935950398445129, 0.8853305578231812, 0.8873966932296753, 0.8925619721412659, 0.8935950398445129, 0.8842975497245789, 0.8832644820213318, 0.8915289044380188, 0.8832644820213318, 0.8863636255264282, 0.8904958963394165, 0.8925619721412659, 0.8863636255264282, 0.8822314143180847, 0.8801652789115906, 0.8863636255264282, 0.8863636255264282, 0.8925619721412659, 0.8894628286361694, 0.8853305578231812, 0.8853305578231812, 0.8811983466148376, 0.8842975497245789, 0.8873966932296753, 0.8791322112083435, 0.8853305578231812, 0.8873966932296753, 0.8863636255264282, 0.8842975497245789, 0.8832644820213318, 0.8811983466148376, 0.8884297609329224, 0.8853305578231812, 0.8884297609329224, 0.8832644820213318, 0.8842975497245789, 0.8822314143180847, 0.8780992031097412, 0.8832644820213318, 0.8822314143180847, 0.8853305578231812, 0.8832644820213318, 0.8832644820213318, 0.8811983466148376, 0.8801652789115906, 0.8347107172012329, 0.8533057570457458, 0.8832644820213318, 0.8801652789115906, 0.8760330677032471, 0.8853305578231812, 0.8760330677032471, 0.8801652789115906, 0.8791322112083435, 0.8791322112083435, 0.8822314143180847, 0.8791322112083435, 0.8822314143180847, 0.8791322112083435]}\n","32/32 [==============================] - 0s 4ms/step\n"]}],"source":["global_model_CNN, metrics_df_CNN = federated_learning(Theta_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1717402936580,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"},"user_tz":-360},"id":"y3RXIk-qZ7ts","outputId":"2db3c766-6134-481c-8699-e3180616a6db"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.758      0.751   0.772  0.761        0.772        0.744   \n","1        1     0.785      0.810   0.743  0.775        0.743        0.826   \n","2        2     0.722      0.693   0.797  0.741        0.797        0.647   \n","3        0     0.771      0.780   0.755  0.768        0.755        0.787   \n","4        1     0.828      0.837   0.814  0.825        0.814        0.842   \n","5        2     0.754      0.724   0.821  0.770        0.821        0.687   \n","6        0     0.816      0.828   0.797  0.812        0.797        0.834   \n","7        1     0.845      0.842   0.850  0.846        0.850        0.840   \n","8        2     0.801      0.778   0.843  0.809        0.843        0.759   \n","9        0     0.842      0.851   0.829  0.840        0.829        0.854   \n","10       1     0.860      0.856   0.866  0.861        0.866        0.855   \n","11       2     0.853      0.833   0.884  0.858        0.884        0.823   \n","12       0     0.863      0.857   0.871  0.864        0.871        0.854   \n","13       1     0.886      0.870   0.908  0.889        0.908        0.864   \n","14       2     0.881      0.858   0.912  0.884        0.912        0.849   \n","\n","    Kappa  \n","0   0.516  \n","1   0.569  \n","2   0.444  \n","3   0.543  \n","4   0.655  \n","5   0.508  \n","6   0.631  \n","7   0.691  \n","8   0.602  \n","9   0.683  \n","10  0.720  \n","11  0.707  \n","12  0.725  \n","13  0.773  \n","14  0.761  "],"text/html":["\n","  <div id=\"df-5de25ca4-3611-4370-9434-155a9e2a3ba6\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.758</td>\n","      <td>0.751</td>\n","      <td>0.772</td>\n","      <td>0.761</td>\n","      <td>0.772</td>\n","      <td>0.744</td>\n","      <td>0.516</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.785</td>\n","      <td>0.810</td>\n","      <td>0.743</td>\n","      <td>0.775</td>\n","      <td>0.743</td>\n","      <td>0.826</td>\n","      <td>0.569</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.722</td>\n","      <td>0.693</td>\n","      <td>0.797</td>\n","      <td>0.741</td>\n","      <td>0.797</td>\n","      <td>0.647</td>\n","      <td>0.444</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.771</td>\n","      <td>0.780</td>\n","      <td>0.755</td>\n","      <td>0.768</td>\n","      <td>0.755</td>\n","      <td>0.787</td>\n","      <td>0.543</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.828</td>\n","      <td>0.837</td>\n","      <td>0.814</td>\n","      <td>0.825</td>\n","      <td>0.814</td>\n","      <td>0.842</td>\n","      <td>0.655</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.754</td>\n","      <td>0.724</td>\n","      <td>0.821</td>\n","      <td>0.770</td>\n","      <td>0.821</td>\n","      <td>0.687</td>\n","      <td>0.508</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.816</td>\n","      <td>0.828</td>\n","      <td>0.797</td>\n","      <td>0.812</td>\n","      <td>0.797</td>\n","      <td>0.834</td>\n","      <td>0.631</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.845</td>\n","      <td>0.842</td>\n","      <td>0.850</td>\n","      <td>0.846</td>\n","      <td>0.850</td>\n","      <td>0.840</td>\n","      <td>0.691</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.801</td>\n","      <td>0.778</td>\n","      <td>0.843</td>\n","      <td>0.809</td>\n","      <td>0.843</td>\n","      <td>0.759</td>\n","      <td>0.602</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.842</td>\n","      <td>0.851</td>\n","      <td>0.829</td>\n","      <td>0.840</td>\n","      <td>0.829</td>\n","      <td>0.854</td>\n","      <td>0.683</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.860</td>\n","      <td>0.856</td>\n","      <td>0.866</td>\n","      <td>0.861</td>\n","      <td>0.866</td>\n","      <td>0.855</td>\n","      <td>0.720</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.853</td>\n","      <td>0.833</td>\n","      <td>0.884</td>\n","      <td>0.858</td>\n","      <td>0.884</td>\n","      <td>0.823</td>\n","      <td>0.707</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.863</td>\n","      <td>0.857</td>\n","      <td>0.871</td>\n","      <td>0.864</td>\n","      <td>0.871</td>\n","      <td>0.854</td>\n","      <td>0.725</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.886</td>\n","      <td>0.870</td>\n","      <td>0.908</td>\n","      <td>0.889</td>\n","      <td>0.908</td>\n","      <td>0.864</td>\n","      <td>0.773</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.881</td>\n","      <td>0.858</td>\n","      <td>0.912</td>\n","      <td>0.884</td>\n","      <td>0.912</td>\n","      <td>0.849</td>\n","      <td>0.761</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5de25ca4-3611-4370-9434-155a9e2a3ba6')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5de25ca4-3611-4370-9434-155a9e2a3ba6 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5de25ca4-3611-4370-9434-155a9e2a3ba6');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-1e6ae898-f1e9-4dfb-8dcb-e6713b05ee15\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e6ae898-f1e9-4dfb-8dcb-e6713b05ee15')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-1e6ae898-f1e9-4dfb-8dcb-e6713b05ee15 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df_CNN\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.050365331992022706,\n        \"min\": 0.722,\n        \"max\": 0.886,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.842,\n          0.853,\n          0.758\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05410598065701372,\n        \"min\": 0.693,\n        \"max\": 0.87,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.851,\n          0.833,\n          0.751\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05232753986737222,\n        \"min\": 0.743,\n        \"max\": 0.912,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.866,\n          0.871,\n          0.772\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04792434514046965,\n        \"min\": 0.741,\n        \"max\": 0.889,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.84,\n          0.858,\n          0.761\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05232753986737222,\n        \"min\": 0.743,\n        \"max\": 0.912,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.866,\n          0.871,\n          0.772\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06652675795354468,\n        \"min\": 0.647,\n        \"max\": 0.864,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.854,\n          0.823,\n          0.744\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10069912753204112,\n        \"min\": 0.444,\n        \"max\": 0.773,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.683,\n          0.707,\n          0.516\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}],"source":["metrics_df_CNN.round(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_iOLsKpkfzdG"},"outputs":[],"source":["metrics_df_CNN.round(4).to_csv('//content/drive/MyDrive/EEG Signal /results/FLresults/DWT/CNN/DWT_CNN.csv', index = False)"]},{"cell_type":"markdown","source":["# GRU"],"metadata":{"id":"oUlc3oD2H_fZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ieXSN-9PI4Dx"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model_gru(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(GRU(256, return_sequences=True))\n","    model.add(GRU(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning_gru(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model_gru(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model_gru(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Total/CNN_GRU/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Total/CNN_GRU/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"]},{"cell_type":"code","source":["global_model_gru, metrics_df_gru = federated_learning_gru(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tt5TmdeDJPiq","executionInfo":{"status":"ok","timestamp":1717404232027,"user_tz":-360,"elapsed":1266396,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"outputId":"6dab01fd-2a1d-4a22-dae8-17f197056315"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 1.8132 - accuracy: 0.5898"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 53ms/step - loss: 1.8128 - accuracy: 0.5929 - val_loss: 1.8115 - val_accuracy: 0.7101\n","Epoch 2/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.7871 - accuracy: 0.7029 - val_loss: 1.7997 - val_accuracy: 0.7575\n","Epoch 3/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.7473 - accuracy: 0.7322 - val_loss: 1.7862 - val_accuracy: 0.7640\n","Epoch 4/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.6995 - accuracy: 0.7478 - val_loss: 1.7702 - val_accuracy: 0.7489\n","Epoch 5/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.6510 - accuracy: 0.7476 - val_loss: 1.7516 - val_accuracy: 0.7425\n","Epoch 6/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.6099 - accuracy: 0.7592 - val_loss: 1.7297 - val_accuracy: 0.7511\n","Epoch 7/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.5805 - accuracy: 0.7597 - val_loss: 1.7073 - val_accuracy: 0.7619\n","Epoch 8/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.5576 - accuracy: 0.7637 - val_loss: 1.6858 - val_accuracy: 0.7565\n","Epoch 9/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.5461 - accuracy: 0.7664 - val_loss: 1.6635 - val_accuracy: 0.7629\n","Epoch 10/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.5298 - accuracy: 0.7726 - val_loss: 1.6429 - val_accuracy: 0.7705\n","Epoch 11/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.5178 - accuracy: 0.7804 - val_loss: 1.6212 - val_accuracy: 0.7597\n","Epoch 12/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.5067 - accuracy: 0.7810 - val_loss: 1.5990 - val_accuracy: 0.7748\n","Epoch 13/100\n","29/29 [==============================] - 1s 31ms/step - loss: 1.4942 - accuracy: 0.7872 - val_loss: 1.5761 - val_accuracy: 0.7769\n","Epoch 14/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.4837 - accuracy: 0.7893 - val_loss: 1.5551 - val_accuracy: 0.7834\n","Epoch 15/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4720 - accuracy: 0.7888 - val_loss: 1.5323 - val_accuracy: 0.7759\n","Epoch 16/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.4685 - accuracy: 0.7899 - val_loss: 1.5169 - val_accuracy: 0.7856\n","Epoch 17/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4573 - accuracy: 0.7923 - val_loss: 1.4926 - val_accuracy: 0.7812\n","Epoch 18/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4474 - accuracy: 0.8009 - val_loss: 1.4757 - val_accuracy: 0.7845\n","Epoch 19/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.4388 - accuracy: 0.7945 - val_loss: 1.4606 - val_accuracy: 0.7920\n","Epoch 20/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4282 - accuracy: 0.7958 - val_loss: 1.4459 - val_accuracy: 0.7899\n","Epoch 21/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.4230 - accuracy: 0.7996 - val_loss: 1.4345 - val_accuracy: 0.7909\n","Epoch 22/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.4151 - accuracy: 0.7971 - val_loss: 1.4308 - val_accuracy: 0.7856\n","Epoch 23/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4046 - accuracy: 0.8025 - val_loss: 1.4216 - val_accuracy: 0.7845\n","Epoch 24/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.3968 - accuracy: 0.8017 - val_loss: 1.4070 - val_accuracy: 0.7953\n","Epoch 25/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3888 - accuracy: 0.8012 - val_loss: 1.4023 - val_accuracy: 0.7920\n","Epoch 26/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.3831 - accuracy: 0.8033 - val_loss: 1.3943 - val_accuracy: 0.7963\n","Epoch 27/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3746 - accuracy: 0.7971 - val_loss: 1.4006 - val_accuracy: 0.7748\n","Epoch 28/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3756 - accuracy: 0.7966 - val_loss: 1.3844 - val_accuracy: 0.7942\n","Epoch 29/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3595 - accuracy: 0.8071 - val_loss: 1.3852 - val_accuracy: 0.7759\n","Epoch 30/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.3536 - accuracy: 0.8025 - val_loss: 1.3686 - val_accuracy: 0.7985\n","Epoch 31/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3439 - accuracy: 0.8093 - val_loss: 1.3618 - val_accuracy: 0.7985\n","Epoch 32/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3382 - accuracy: 0.8052 - val_loss: 1.3551 - val_accuracy: 0.7985\n","Epoch 33/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3277 - accuracy: 0.8149 - val_loss: 1.3523 - val_accuracy: 0.7953\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3258 - accuracy: 0.8068 - val_loss: 1.3584 - val_accuracy: 0.7780\n","Epoch 35/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.3167 - accuracy: 0.8079 - val_loss: 1.3384 - val_accuracy: 0.7985\n","Epoch 36/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3089 - accuracy: 0.8044 - val_loss: 1.3328 - val_accuracy: 0.7963\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3028 - accuracy: 0.8109 - val_loss: 1.3286 - val_accuracy: 0.7963\n","Epoch 38/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.2941 - accuracy: 0.8138 - val_loss: 1.3197 - val_accuracy: 0.7985\n","Epoch 39/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.2902 - accuracy: 0.8077 - val_loss: 1.3131 - val_accuracy: 0.7963\n","Epoch 40/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.2773 - accuracy: 0.8171 - val_loss: 1.3086 - val_accuracy: 0.7953\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2727 - accuracy: 0.8179 - val_loss: 1.3012 - val_accuracy: 0.7985\n","Epoch 42/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.2688 - accuracy: 0.8136 - val_loss: 1.3011 - val_accuracy: 0.7931\n","Epoch 43/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.2552 - accuracy: 0.8203 - val_loss: 1.2944 - val_accuracy: 0.7963\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2542 - accuracy: 0.8184 - val_loss: 1.2843 - val_accuracy: 0.7942\n","Epoch 45/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2446 - accuracy: 0.8219 - val_loss: 1.2770 - val_accuracy: 0.7942\n","Epoch 46/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.2325 - accuracy: 0.8246 - val_loss: 1.2718 - val_accuracy: 0.7953\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2269 - accuracy: 0.8260 - val_loss: 1.2671 - val_accuracy: 0.7985\n","Epoch 48/100\n","29/29 [==============================] - 2s 72ms/step - loss: 1.2214 - accuracy: 0.8222 - val_loss: 1.2586 - val_accuracy: 0.8006\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2169 - accuracy: 0.8227 - val_loss: 1.2539 - val_accuracy: 0.7953\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2126 - accuracy: 0.8217 - val_loss: 1.2527 - val_accuracy: 0.8006\n","Epoch 51/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2015 - accuracy: 0.8219 - val_loss: 1.2416 - val_accuracy: 0.8006\n","Epoch 52/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1911 - accuracy: 0.8311 - val_loss: 1.2352 - val_accuracy: 0.8006\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1861 - accuracy: 0.8273 - val_loss: 1.2339 - val_accuracy: 0.7974\n","Epoch 54/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1795 - accuracy: 0.8305 - val_loss: 1.2277 - val_accuracy: 0.7963\n","Epoch 55/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1739 - accuracy: 0.8289 - val_loss: 1.2213 - val_accuracy: 0.7974\n","Epoch 56/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.1632 - accuracy: 0.8341 - val_loss: 1.2123 - val_accuracy: 0.8017\n","Epoch 57/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1565 - accuracy: 0.8338 - val_loss: 1.2173 - val_accuracy: 0.7942\n","Epoch 58/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1560 - accuracy: 0.8270 - val_loss: 1.2053 - val_accuracy: 0.7942\n","Epoch 59/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.1453 - accuracy: 0.8405 - val_loss: 1.1957 - val_accuracy: 0.8028\n","Epoch 60/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1427 - accuracy: 0.8330 - val_loss: 1.1966 - val_accuracy: 0.8006\n","Epoch 61/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1352 - accuracy: 0.8349 - val_loss: 1.1881 - val_accuracy: 0.7974\n","Epoch 62/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.1223 - accuracy: 0.8378 - val_loss: 1.1794 - val_accuracy: 0.8039\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1114 - accuracy: 0.8508 - val_loss: 1.1756 - val_accuracy: 0.8006\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1057 - accuracy: 0.8459 - val_loss: 1.1719 - val_accuracy: 0.8039\n","Epoch 65/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.1003 - accuracy: 0.8432 - val_loss: 1.1639 - val_accuracy: 0.8082\n","Epoch 66/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.0929 - accuracy: 0.8502 - val_loss: 1.1611 - val_accuracy: 0.8050\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0845 - accuracy: 0.8508 - val_loss: 1.1563 - val_accuracy: 0.8017\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0911 - accuracy: 0.8416 - val_loss: 1.1766 - val_accuracy: 0.7791\n","Epoch 69/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0792 - accuracy: 0.8446 - val_loss: 1.1527 - val_accuracy: 0.7931\n","Epoch 70/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.0739 - accuracy: 0.8448 - val_loss: 1.1372 - val_accuracy: 0.8125\n","Epoch 71/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.0636 - accuracy: 0.8478 - val_loss: 1.1317 - val_accuracy: 0.8168\n","Epoch 72/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0549 - accuracy: 0.8556 - val_loss: 1.1297 - val_accuracy: 0.8157\n","Epoch 73/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.0477 - accuracy: 0.8570 - val_loss: 1.1222 - val_accuracy: 0.8190\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0443 - accuracy: 0.8540 - val_loss: 1.1193 - val_accuracy: 0.8114\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0376 - accuracy: 0.8572 - val_loss: 1.1122 - val_accuracy: 0.8190\n","Epoch 76/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.0316 - accuracy: 0.8615 - val_loss: 1.1064 - val_accuracy: 0.8244\n","Epoch 77/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0228 - accuracy: 0.8580 - val_loss: 1.1042 - val_accuracy: 0.8179\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0191 - accuracy: 0.8599 - val_loss: 1.1015 - val_accuracy: 0.8147\n","Epoch 79/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0149 - accuracy: 0.8599 - val_loss: 1.0954 - val_accuracy: 0.8222\n","Epoch 80/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0082 - accuracy: 0.8605 - val_loss: 1.0947 - val_accuracy: 0.8147\n","Epoch 81/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9952 - accuracy: 0.8683 - val_loss: 1.0877 - val_accuracy: 0.8168\n","Epoch 82/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9927 - accuracy: 0.8653 - val_loss: 1.0830 - val_accuracy: 0.8200\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9828 - accuracy: 0.8677 - val_loss: 1.0800 - val_accuracy: 0.8222\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9809 - accuracy: 0.8685 - val_loss: 1.0791 - val_accuracy: 0.8168\n","Epoch 85/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9754 - accuracy: 0.8693 - val_loss: 1.0746 - val_accuracy: 0.8136\n","Epoch 86/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9667 - accuracy: 0.8766 - val_loss: 1.0661 - val_accuracy: 0.8168\n","Epoch 87/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9650 - accuracy: 0.8710 - val_loss: 1.0649 - val_accuracy: 0.8157\n","Epoch 88/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9609 - accuracy: 0.8704 - val_loss: 1.0579 - val_accuracy: 0.8211\n","Epoch 89/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9526 - accuracy: 0.8720 - val_loss: 1.0572 - val_accuracy: 0.8179\n","Epoch 90/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9462 - accuracy: 0.8715 - val_loss: 1.0605 - val_accuracy: 0.8125\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9469 - accuracy: 0.8726 - val_loss: 1.0781 - val_accuracy: 0.7985\n","Epoch 92/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9385 - accuracy: 0.8766 - val_loss: 1.0460 - val_accuracy: 0.8190\n","Epoch 93/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9285 - accuracy: 0.8766 - val_loss: 1.0390 - val_accuracy: 0.8190\n","Epoch 94/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9257 - accuracy: 0.8793 - val_loss: 1.0420 - val_accuracy: 0.8157\n","Epoch 95/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9216 - accuracy: 0.8823 - val_loss: 1.0360 - val_accuracy: 0.8190\n","Epoch 96/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9163 - accuracy: 0.8812 - val_loss: 1.0361 - val_accuracy: 0.8179\n","Epoch 97/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9081 - accuracy: 0.8817 - val_loss: 1.0335 - val_accuracy: 0.8168\n","Epoch 98/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9019 - accuracy: 0.8863 - val_loss: 1.0281 - val_accuracy: 0.8200\n","Epoch 99/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9009 - accuracy: 0.8836 - val_loss: 1.0286 - val_accuracy: 0.8168\n","Epoch 100/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8908 - accuracy: 0.8866 - val_loss: 1.0212 - val_accuracy: 0.8168\n","{'loss': [1.8128458261489868, 1.7871004343032837, 1.7473223209381104, 1.6994785070419312, 1.6510436534881592, 1.6099036931991577, 1.5805118083953857, 1.5576136112213135, 1.5460536479949951, 1.5297878980636597, 1.5178487300872803, 1.5067263841629028, 1.494200587272644, 1.4837403297424316, 1.4719712734222412, 1.4685475826263428, 1.4572869539260864, 1.4474127292633057, 1.4388155937194824, 1.4281500577926636, 1.4230496883392334, 1.4150639772415161, 1.4046125411987305, 1.3968291282653809, 1.3887583017349243, 1.3831413984298706, 1.3746025562286377, 1.3756103515625, 1.3595128059387207, 1.3536418676376343, 1.343949794769287, 1.33815336227417, 1.327699065208435, 1.3257596492767334, 1.316664695739746, 1.3088641166687012, 1.302826166152954, 1.2940661907196045, 1.2901742458343506, 1.277342438697815, 1.2727211713790894, 1.2687654495239258, 1.255150318145752, 1.254244089126587, 1.2445780038833618, 1.2325222492218018, 1.2268942594528198, 1.221359372138977, 1.2168850898742676, 1.2126219272613525, 1.20148503780365, 1.191135048866272, 1.1860682964324951, 1.1795250177383423, 1.1738502979278564, 1.1632286310195923, 1.1565017700195312, 1.155994176864624, 1.1453397274017334, 1.1427408456802368, 1.1352486610412598, 1.1222747564315796, 1.1113728284835815, 1.1057119369506836, 1.100289225578308, 1.0929038524627686, 1.0845277309417725, 1.0911188125610352, 1.0791794061660767, 1.0738675594329834, 1.0636322498321533, 1.0548948049545288, 1.047725796699524, 1.044349193572998, 1.037582516670227, 1.031640648841858, 1.022768497467041, 1.0190746784210205, 1.014915108680725, 1.0081526041030884, 0.9952402710914612, 0.9927408695220947, 0.9827543497085571, 0.9809278845787048, 0.9754287600517273, 0.9666904211044312, 0.9649916291236877, 0.9608759880065918, 0.9526073932647705, 0.9462290406227112, 0.9469463229179382, 0.9385369420051575, 0.9285286664962769, 0.9256796836853027, 0.92160964012146, 0.9162529706954956, 0.9080893397331238, 0.9019326567649841, 0.9008609056472778, 0.8908374905586243], 'accuracy': [0.5929418206214905, 0.7028555870056152, 0.7322198152542114, 0.7478448152542114, 0.7475754022598267, 0.759159505367279, 0.7596982717514038, 0.7637392282485962, 0.7664331793785095, 0.7726293206214905, 0.7804418206214905, 0.7809805870056152, 0.7871767282485962, 0.7893319129943848, 0.7887930870056152, 0.7898706793785095, 0.7922952771186829, 0.8009159564971924, 0.7944504022598267, 0.7957974076271057, 0.7995689511299133, 0.7971444129943848, 0.8025323152542114, 0.8017241358757019, 0.8011853694915771, 0.803340494632721, 0.7971444129943848, 0.7966055870056152, 0.8071120977401733, 0.8025323152542114, 0.8092672228813171, 0.8052262663841248, 0.8149245977401733, 0.8068426847457886, 0.8079202771186829, 0.8044180870056152, 0.810883641242981, 0.813847005367279, 0.8076508641242981, 0.8170797228813171, 0.8178879022598267, 0.8135775923728943, 0.8203125, 0.8184267282485962, 0.821928858757019, 0.8246228694915771, 0.8259698152542114, 0.8221982717514038, 0.8227370977401733, 0.821659505367279, 0.821928858757019, 0.8310883641242981, 0.8273168206214905, 0.8305495977401733, 0.8289331793785095, 0.8340517282485962, 0.8337823152542114, 0.8270474076271057, 0.8405172228813171, 0.8329741358757019, 0.8348599076271057, 0.8378232717514038, 0.8507543206214905, 0.8459051847457886, 0.8432112336158752, 0.850215494632721, 0.8507543206214905, 0.8415948152542114, 0.8445581793785095, 0.8448275923728943, 0.8477909564971924, 0.8556034564971924, 0.8569504022598267, 0.8539870977401733, 0.8572198152542114, 0.8615301847457886, 0.858027994632721, 0.8599137663841248, 0.8599137663841248, 0.8604525923728943, 0.8682650923728943, 0.8653017282485962, 0.8677262663841248, 0.868534505367279, 0.8693426847457886, 0.876616358757019, 0.8709590435028076, 0.8704202771186829, 0.8720366358757019, 0.8714978694915771, 0.8725754022598267, 0.876616358757019, 0.876616358757019, 0.8793103694915771, 0.8822737336158752, 0.881196141242981, 0.8817349076271057, 0.8863146305084229, 0.8836206793785095, 0.8865840435028076], 'val_loss': [1.8114686012268066, 1.799696922302246, 1.7861933708190918, 1.7701961994171143, 1.7515650987625122, 1.7296661138534546, 1.7072871923446655, 1.6858118772506714, 1.663544774055481, 1.642939567565918, 1.6211965084075928, 1.598995327949524, 1.5760802030563354, 1.5550506114959717, 1.5323216915130615, 1.5169299840927124, 1.4926365613937378, 1.4757447242736816, 1.4606250524520874, 1.4459363222122192, 1.434520959854126, 1.4308254718780518, 1.4216474294662476, 1.4069797992706299, 1.4023343324661255, 1.3943061828613281, 1.40058434009552, 1.3843584060668945, 1.3852089643478394, 1.3686308860778809, 1.3617568016052246, 1.3550779819488525, 1.352306842803955, 1.3584315776824951, 1.3383628129959106, 1.3327934741973877, 1.328576683998108, 1.3196905851364136, 1.3131442070007324, 1.3086425065994263, 1.3011574745178223, 1.301081895828247, 1.2943756580352783, 1.284274935722351, 1.2769575119018555, 1.271773338317871, 1.2671033143997192, 1.2585526704788208, 1.2538663148880005, 1.252655267715454, 1.241552472114563, 1.235177755355835, 1.2339494228363037, 1.2277371883392334, 1.221315622329712, 1.2123042345046997, 1.217255711555481, 1.2052888870239258, 1.1957319974899292, 1.1965827941894531, 1.188111662864685, 1.1794323921203613, 1.175595760345459, 1.1719202995300293, 1.1638693809509277, 1.161116361618042, 1.156326174736023, 1.1765999794006348, 1.152689814567566, 1.1372014284133911, 1.131662130355835, 1.1296578645706177, 1.1221959590911865, 1.1193312406539917, 1.1121774911880493, 1.1064338684082031, 1.1042354106903076, 1.1015018224716187, 1.0953952074050903, 1.0946654081344604, 1.0877423286437988, 1.0829885005950928, 1.0800361633300781, 1.0790984630584717, 1.0745576620101929, 1.0660732984542847, 1.0648999214172363, 1.0578656196594238, 1.0572118759155273, 1.0604732036590576, 1.0780786275863647, 1.046020269393921, 1.0390106439590454, 1.0419623851776123, 1.0359820127487183, 1.036129355430603, 1.033539056777954, 1.0280855894088745, 1.0285799503326416, 1.021224856376648], 'val_accuracy': [0.7101293206214905, 0.7575430870056152, 0.764008641242981, 0.7489224076271057, 0.7424569129943848, 0.7510775923728943, 0.7618534564971924, 0.756465494632721, 0.7629310488700867, 0.7704741358757019, 0.7596982717514038, 0.774784505367279, 0.7769396305084229, 0.7834051847457886, 0.7758620977401733, 0.7855603694915771, 0.78125, 0.7844827771186829, 0.7920258641242981, 0.7898706793785095, 0.7909482717514038, 0.7855603694915771, 0.7844827771186829, 0.795258641242981, 0.7920258641242981, 0.7963362336158752, 0.774784505367279, 0.7941810488700867, 0.7758620977401733, 0.798491358757019, 0.798491358757019, 0.798491358757019, 0.795258641242981, 0.7780172228813171, 0.798491358757019, 0.7963362336158752, 0.7963362336158752, 0.798491358757019, 0.7963362336158752, 0.795258641242981, 0.798491358757019, 0.7931034564971924, 0.7963362336158752, 0.7941810488700867, 0.7941810488700867, 0.795258641242981, 0.798491358757019, 0.8006465435028076, 0.795258641242981, 0.8006465435028076, 0.8006465435028076, 0.8006465435028076, 0.7974137663841248, 0.7963362336158752, 0.7974137663841248, 0.8017241358757019, 0.7941810488700867, 0.7941810488700867, 0.8028017282485962, 0.8006465435028076, 0.7974137663841248, 0.8038793206214905, 0.8006465435028076, 0.8038793206214905, 0.8081896305084229, 0.8049569129943848, 0.8017241358757019, 0.7790948152542114, 0.7931034564971924, 0.8125, 0.8168103694915771, 0.8157327771186829, 0.818965494632721, 0.8114224076271057, 0.818965494632721, 0.8243534564971924, 0.8178879022598267, 0.8146551847457886, 0.8221982717514038, 0.8146551847457886, 0.8168103694915771, 0.8200430870056152, 0.8221982717514038, 0.8168103694915771, 0.8135775923728943, 0.8168103694915771, 0.8157327771186829, 0.8211206793785095, 0.8178879022598267, 0.8125, 0.798491358757019, 0.818965494632721, 0.818965494632721, 0.8157327771186829, 0.818965494632721, 0.8178879022598267, 0.8168103694915771, 0.8200430870056152, 0.8168103694915771, 0.8168103694915771]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 1.8156 - accuracy: 0.5689"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 9s 59ms/step - loss: 1.8154 - accuracy: 0.5724 - val_loss: 1.8121 - val_accuracy: 0.6889\n","Epoch 2/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.7941 - accuracy: 0.6800 - val_loss: 1.8012 - val_accuracy: 0.7319\n","Epoch 3/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.7642 - accuracy: 0.7105 - val_loss: 1.7894 - val_accuracy: 0.7217\n","Epoch 4/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.7262 - accuracy: 0.7292 - val_loss: 1.7759 - val_accuracy: 0.7229\n","Epoch 5/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.6830 - accuracy: 0.7388 - val_loss: 1.7603 - val_accuracy: 0.7104\n","Epoch 6/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.6461 - accuracy: 0.7402 - val_loss: 1.7418 - val_accuracy: 0.7330\n","Epoch 7/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.6155 - accuracy: 0.7428 - val_loss: 1.7223 - val_accuracy: 0.7410\n","Epoch 8/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5892 - accuracy: 0.7513 - val_loss: 1.7032 - val_accuracy: 0.7217\n","Epoch 9/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5747 - accuracy: 0.7535 - val_loss: 1.6845 - val_accuracy: 0.7274\n","Epoch 10/100\n","28/28 [==============================] - 1s 33ms/step - loss: 1.5603 - accuracy: 0.7583 - val_loss: 1.6653 - val_accuracy: 0.7421\n","Epoch 11/100\n","28/28 [==============================] - 1s 34ms/step - loss: 1.5497 - accuracy: 0.7586 - val_loss: 1.6471 - val_accuracy: 0.7489\n","Epoch 12/100\n","28/28 [==============================] - 1s 37ms/step - loss: 1.5365 - accuracy: 0.7634 - val_loss: 1.6307 - val_accuracy: 0.7545\n","Epoch 13/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.5264 - accuracy: 0.7649 - val_loss: 1.6081 - val_accuracy: 0.7500\n","Epoch 14/100\n","28/28 [==============================] - 1s 32ms/step - loss: 1.5177 - accuracy: 0.7736 - val_loss: 1.5909 - val_accuracy: 0.7557\n","Epoch 15/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.5059 - accuracy: 0.7708 - val_loss: 1.5729 - val_accuracy: 0.7545\n","Epoch 16/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.4951 - accuracy: 0.7742 - val_loss: 1.5545 - val_accuracy: 0.7590\n","Epoch 17/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.4864 - accuracy: 0.7784 - val_loss: 1.5355 - val_accuracy: 0.7636\n","Epoch 18/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4778 - accuracy: 0.7748 - val_loss: 1.5184 - val_accuracy: 0.7613\n","Epoch 19/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.4692 - accuracy: 0.7759 - val_loss: 1.5109 - val_accuracy: 0.7568\n","Epoch 20/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.4636 - accuracy: 0.7782 - val_loss: 1.4899 - val_accuracy: 0.7647\n","Epoch 21/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4526 - accuracy: 0.7804 - val_loss: 1.4765 - val_accuracy: 0.7602\n","Epoch 22/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4453 - accuracy: 0.7804 - val_loss: 1.4652 - val_accuracy: 0.7602\n","Epoch 23/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4396 - accuracy: 0.7804 - val_loss: 1.4638 - val_accuracy: 0.7647\n","Epoch 24/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.4297 - accuracy: 0.7821 - val_loss: 1.4469 - val_accuracy: 0.7681\n","Epoch 25/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.4253 - accuracy: 0.7745 - val_loss: 1.4422 - val_accuracy: 0.7726\n","Epoch 26/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4131 - accuracy: 0.7849 - val_loss: 1.4370 - val_accuracy: 0.7704\n","Epoch 27/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4086 - accuracy: 0.7810 - val_loss: 1.4344 - val_accuracy: 0.7647\n","Epoch 28/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4000 - accuracy: 0.7816 - val_loss: 1.4183 - val_accuracy: 0.7704\n","Epoch 29/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.3931 - accuracy: 0.7878 - val_loss: 1.4113 - val_accuracy: 0.7704\n","Epoch 30/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3865 - accuracy: 0.7827 - val_loss: 1.4025 - val_accuracy: 0.7692\n","Epoch 31/100\n","28/28 [==============================] - 1s 30ms/step - loss: 1.3784 - accuracy: 0.7858 - val_loss: 1.3987 - val_accuracy: 0.7783\n","Epoch 32/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.3712 - accuracy: 0.7830 - val_loss: 1.3898 - val_accuracy: 0.7760\n","Epoch 33/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.3628 - accuracy: 0.7864 - val_loss: 1.3986 - val_accuracy: 0.7602\n","Epoch 34/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.3540 - accuracy: 0.7898 - val_loss: 1.3748 - val_accuracy: 0.7760\n","Epoch 35/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.3505 - accuracy: 0.7886 - val_loss: 1.3765 - val_accuracy: 0.7760\n","Epoch 36/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.3432 - accuracy: 0.7889 - val_loss: 1.3627 - val_accuracy: 0.7783\n","Epoch 37/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.3340 - accuracy: 0.7915 - val_loss: 1.3645 - val_accuracy: 0.7760\n","Epoch 38/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.3267 - accuracy: 0.7898 - val_loss: 1.3513 - val_accuracy: 0.7805\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3224 - accuracy: 0.7864 - val_loss: 1.3409 - val_accuracy: 0.7805\n","Epoch 40/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.3113 - accuracy: 0.7909 - val_loss: 1.3344 - val_accuracy: 0.7873\n","Epoch 41/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.3033 - accuracy: 0.7946 - val_loss: 1.3375 - val_accuracy: 0.7805\n","Epoch 42/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2980 - accuracy: 0.7937 - val_loss: 1.3213 - val_accuracy: 0.7851\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2884 - accuracy: 0.7957 - val_loss: 1.3166 - val_accuracy: 0.7828\n","Epoch 44/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.2840 - accuracy: 0.7971 - val_loss: 1.3083 - val_accuracy: 0.7896\n","Epoch 45/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2717 - accuracy: 0.8019 - val_loss: 1.3032 - val_accuracy: 0.7896\n","Epoch 46/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.2660 - accuracy: 0.7988 - val_loss: 1.3007 - val_accuracy: 0.7907\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2612 - accuracy: 0.8039 - val_loss: 1.2904 - val_accuracy: 0.7907\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2565 - accuracy: 0.8036 - val_loss: 1.2849 - val_accuracy: 0.7896\n","Epoch 49/100\n","28/28 [==============================] - 1s 33ms/step - loss: 1.2451 - accuracy: 0.8039 - val_loss: 1.2799 - val_accuracy: 0.7930\n","Epoch 50/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2374 - accuracy: 0.8118 - val_loss: 1.2758 - val_accuracy: 0.7885\n","Epoch 51/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2332 - accuracy: 0.8090 - val_loss: 1.2763 - val_accuracy: 0.7885\n","Epoch 52/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.2218 - accuracy: 0.8101 - val_loss: 1.2640 - val_accuracy: 0.7941\n","Epoch 53/100\n","28/28 [==============================] - 1s 32ms/step - loss: 1.2180 - accuracy: 0.8138 - val_loss: 1.2593 - val_accuracy: 0.7964\n","Epoch 54/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.2122 - accuracy: 0.8113 - val_loss: 1.2602 - val_accuracy: 0.7839\n","Epoch 55/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.2022 - accuracy: 0.8195 - val_loss: 1.2656 - val_accuracy: 0.7794\n","Epoch 56/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.2026 - accuracy: 0.8141 - val_loss: 1.2433 - val_accuracy: 0.7941\n","Epoch 57/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.1936 - accuracy: 0.8183 - val_loss: 1.2415 - val_accuracy: 0.7907\n","Epoch 58/100\n","28/28 [==============================] - 1s 34ms/step - loss: 1.1867 - accuracy: 0.8195 - val_loss: 1.2328 - val_accuracy: 0.8020\n","Epoch 59/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1824 - accuracy: 0.8186 - val_loss: 1.2293 - val_accuracy: 0.7919\n","Epoch 60/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.1725 - accuracy: 0.8237 - val_loss: 1.2220 - val_accuracy: 0.8043\n","Epoch 61/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1694 - accuracy: 0.8223 - val_loss: 1.2165 - val_accuracy: 0.7986\n","Epoch 62/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.1596 - accuracy: 0.8226 - val_loss: 1.2103 - val_accuracy: 0.8077\n","Epoch 63/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1505 - accuracy: 0.8260 - val_loss: 1.2094 - val_accuracy: 0.8032\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1507 - accuracy: 0.8234 - val_loss: 1.2009 - val_accuracy: 0.8054\n","Epoch 65/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1431 - accuracy: 0.8305 - val_loss: 1.2014 - val_accuracy: 0.7907\n","Epoch 66/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1356 - accuracy: 0.8282 - val_loss: 1.1933 - val_accuracy: 0.8032\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1280 - accuracy: 0.8336 - val_loss: 1.1880 - val_accuracy: 0.8020\n","Epoch 68/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1267 - accuracy: 0.8280 - val_loss: 1.1845 - val_accuracy: 0.8032\n","Epoch 69/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1156 - accuracy: 0.8305 - val_loss: 1.1941 - val_accuracy: 0.7817\n","Epoch 70/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1138 - accuracy: 0.8271 - val_loss: 1.1806 - val_accuracy: 0.7941\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1074 - accuracy: 0.8342 - val_loss: 1.1699 - val_accuracy: 0.8054\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0987 - accuracy: 0.8314 - val_loss: 1.1649 - val_accuracy: 0.8032\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0919 - accuracy: 0.8302 - val_loss: 1.1661 - val_accuracy: 0.8020\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0941 - accuracy: 0.8345 - val_loss: 1.1554 - val_accuracy: 0.8077\n","Epoch 75/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0817 - accuracy: 0.8356 - val_loss: 1.1623 - val_accuracy: 0.7941\n","Epoch 76/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.0821 - accuracy: 0.8308 - val_loss: 1.1671 - val_accuracy: 0.7873\n","Epoch 77/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.0683 - accuracy: 0.8427 - val_loss: 1.1411 - val_accuracy: 0.8032\n","Epoch 78/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.0651 - accuracy: 0.8350 - val_loss: 1.1369 - val_accuracy: 0.8054\n","Epoch 79/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.0616 - accuracy: 0.8424 - val_loss: 1.1329 - val_accuracy: 0.8043\n","Epoch 80/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.0604 - accuracy: 0.8333 - val_loss: 1.1414 - val_accuracy: 0.7964\n","Epoch 81/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.0479 - accuracy: 0.8438 - val_loss: 1.1422 - val_accuracy: 0.7930\n","Epoch 82/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.0447 - accuracy: 0.8418 - val_loss: 1.1306 - val_accuracy: 0.7964\n","Epoch 83/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0347 - accuracy: 0.8441 - val_loss: 1.1373 - val_accuracy: 0.7919\n","Epoch 84/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0380 - accuracy: 0.8398 - val_loss: 1.1179 - val_accuracy: 0.7998\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0288 - accuracy: 0.8432 - val_loss: 1.1224 - val_accuracy: 0.7930\n","Epoch 86/100\n","28/28 [==============================] - 2s 56ms/step - loss: 1.0274 - accuracy: 0.8413 - val_loss: 1.1083 - val_accuracy: 0.8088\n","Epoch 87/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0199 - accuracy: 0.8418 - val_loss: 1.1128 - val_accuracy: 0.8020\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0203 - accuracy: 0.8427 - val_loss: 1.0993 - val_accuracy: 0.8020\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0066 - accuracy: 0.8469 - val_loss: 1.0998 - val_accuracy: 0.8054\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9985 - accuracy: 0.8463 - val_loss: 1.0915 - val_accuracy: 0.7998\n","Epoch 91/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9929 - accuracy: 0.8548 - val_loss: 1.0878 - val_accuracy: 0.8020\n","Epoch 92/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.9877 - accuracy: 0.8568 - val_loss: 1.0847 - val_accuracy: 0.8020\n","Epoch 93/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.9840 - accuracy: 0.8495 - val_loss: 1.0825 - val_accuracy: 0.8009\n","Epoch 94/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9757 - accuracy: 0.8580 - val_loss: 1.0877 - val_accuracy: 0.7986\n","Epoch 95/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9733 - accuracy: 0.8531 - val_loss: 1.0753 - val_accuracy: 0.7998\n","Epoch 96/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9633 - accuracy: 0.8625 - val_loss: 1.0736 - val_accuracy: 0.8066\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9605 - accuracy: 0.8605 - val_loss: 1.0706 - val_accuracy: 0.8054\n","Epoch 98/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9554 - accuracy: 0.8599 - val_loss: 1.0693 - val_accuracy: 0.8020\n","Epoch 99/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9486 - accuracy: 0.8608 - val_loss: 1.0707 - val_accuracy: 0.8009\n","Epoch 100/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9382 - accuracy: 0.8659 - val_loss: 1.0606 - val_accuracy: 0.8032\n","{'loss': [1.815442681312561, 1.7940845489501953, 1.764180302619934, 1.726227879524231, 1.683048963546753, 1.6461015939712524, 1.6155413389205933, 1.5891892910003662, 1.5746957063674927, 1.5603302717208862, 1.5497483015060425, 1.536515712738037, 1.5264456272125244, 1.5177147388458252, 1.5059348344802856, 1.4951139688491821, 1.4863691329956055, 1.4778087139129639, 1.4692342281341553, 1.4635546207427979, 1.452629804611206, 1.445336937904358, 1.4396286010742188, 1.4297449588775635, 1.4252727031707764, 1.4130756855010986, 1.408621907234192, 1.3999615907669067, 1.3930726051330566, 1.3865416049957275, 1.3783739805221558, 1.371160626411438, 1.3627817630767822, 1.3539987802505493, 1.350501537322998, 1.3431594371795654, 1.3339900970458984, 1.3267498016357422, 1.3223588466644287, 1.3113305568695068, 1.3033370971679688, 1.2979800701141357, 1.2883856296539307, 1.2840344905853271, 1.2717212438583374, 1.2660256624221802, 1.2611579895019531, 1.2564605474472046, 1.2450816631317139, 1.2373689413070679, 1.2332388162612915, 1.2217822074890137, 1.2179756164550781, 1.2122400999069214, 1.2021502256393433, 1.2026106119155884, 1.1935710906982422, 1.18672776222229, 1.1823673248291016, 1.1725318431854248, 1.16938316822052, 1.1595635414123535, 1.1505190134048462, 1.1506991386413574, 1.1431461572647095, 1.135552167892456, 1.1279523372650146, 1.126715898513794, 1.1155608892440796, 1.1137531995773315, 1.107381820678711, 1.0986841917037964, 1.0918668508529663, 1.0940725803375244, 1.0817147493362427, 1.0821316242218018, 1.068320393562317, 1.0651301145553589, 1.0615990161895752, 1.0603693723678589, 1.0478836297988892, 1.0446864366531372, 1.0347381830215454, 1.0380488634109497, 1.028781533241272, 1.027388572692871, 1.0198794603347778, 1.020309567451477, 1.0065866708755493, 0.9984790086746216, 0.9929206967353821, 0.9877303242683411, 0.9839567542076111, 0.9757158160209656, 0.9733383655548096, 0.9633360505104065, 0.9605126976966858, 0.955414891242981, 0.9486450552940369, 0.9382416009902954], 'accuracy': [0.5724391341209412, 0.6799660325050354, 0.7105262875556946, 0.7292020320892334, 0.738822877407074, 0.7402377128601074, 0.7427843809127808, 0.7512733340263367, 0.7535370588302612, 0.7583475112915039, 0.7586304545402527, 0.7634408473968506, 0.764855682849884, 0.7736276388168335, 0.7707979679107666, 0.774193525314331, 0.7784380316734314, 0.7747594714164734, 0.7758913636207581, 0.7781550884246826, 0.7804188132286072, 0.7804188132286072, 0.7804188132286072, 0.7821165919303894, 0.7744765281677246, 0.7849462628364563, 0.7809846997261047, 0.7815506458282471, 0.7877758741378784, 0.7826825380325317, 0.7857951521873474, 0.7829654812812805, 0.786361038684845, 0.7897566556930542, 0.7886247634887695, 0.7889077663421631, 0.7914544343948364, 0.7897566556930542, 0.786361038684845, 0.7908884882926941, 0.7945670485496521, 0.793718159198761, 0.7956989407539368, 0.7971137762069702, 0.8019241690635681, 0.7988115549087524, 0.8039049506187439, 0.8036219477653503, 0.8039049506187439, 0.8118279576301575, 0.8089982867240906, 0.8101301789283752, 0.8138087391853333, 0.8112620115280151, 0.8194680213928223, 0.814091682434082, 0.8183361887931824, 0.8194680213928223, 0.8186191320419312, 0.8237125277519226, 0.8222976922988892, 0.8225806355476379, 0.8259762525558472, 0.823429524898529, 0.8305037021636963, 0.8282399773597717, 0.833616316318512, 0.8279569745063782, 0.8305037021636963, 0.8271080851554871, 0.8341822028160095, 0.8313525915145874, 0.8302206993103027, 0.8344652056694031, 0.835597038269043, 0.8307866454124451, 0.8426712155342102, 0.8350311517715454, 0.8423882126808167, 0.8333333134651184, 0.8438030481338501, 0.8418223261833191, 0.8440860509872437, 0.8398415446281433, 0.8432371020317078, 0.8412563800811768, 0.8418223261833191, 0.8426712155342102, 0.8469156622886658, 0.8463497161865234, 0.8548387289047241, 0.8568194508552551, 0.8494623899459839, 0.8579513430595398, 0.8531408905982971, 0.8624787926673889, 0.8604980111122131, 0.8599320650100708, 0.8607810139656067, 0.8658743500709534], 'val_loss': [1.8120782375335693, 1.801194429397583, 1.7893731594085693, 1.7759038209915161, 1.7603340148925781, 1.7418315410614014, 1.7223460674285889, 1.7031581401824951, 1.6844502687454224, 1.6653428077697754, 1.647080898284912, 1.6307399272918701, 1.6081353425979614, 1.590932846069336, 1.5728522539138794, 1.5544723272323608, 1.5354799032211304, 1.5184271335601807, 1.5109249353408813, 1.4899468421936035, 1.4765373468399048, 1.4651916027069092, 1.4637631177902222, 1.4469177722930908, 1.442182183265686, 1.4369810819625854, 1.4343514442443848, 1.418310284614563, 1.4113349914550781, 1.4025262594223022, 1.3987032175064087, 1.3897756338119507, 1.3986469507217407, 1.3747540712356567, 1.3764963150024414, 1.3626638650894165, 1.3644680976867676, 1.3513137102127075, 1.3409208059310913, 1.3343610763549805, 1.3375314474105835, 1.321295142173767, 1.3165676593780518, 1.3083354234695435, 1.3031704425811768, 1.3006863594055176, 1.2903953790664673, 1.2849103212356567, 1.2798751592636108, 1.2757742404937744, 1.2763340473175049, 1.2639683485031128, 1.259344458580017, 1.2602227926254272, 1.26558256149292, 1.243335485458374, 1.2414911985397339, 1.2328095436096191, 1.2293294668197632, 1.221974492073059, 1.216462254524231, 1.2103160619735718, 1.2093535661697388, 1.2008925676345825, 1.2013564109802246, 1.1932858228683472, 1.188048243522644, 1.1845122575759888, 1.1940938234329224, 1.1806230545043945, 1.1698864698410034, 1.1649154424667358, 1.1660585403442383, 1.155354380607605, 1.1623409986495972, 1.1671119928359985, 1.1411150693893433, 1.1369056701660156, 1.1328649520874023, 1.1413850784301758, 1.1421781778335571, 1.1306250095367432, 1.1372888088226318, 1.1179064512252808, 1.12239670753479, 1.108263373374939, 1.1127904653549194, 1.0993305444717407, 1.0997577905654907, 1.0915247201919556, 1.0878342390060425, 1.0847309827804565, 1.0825294256210327, 1.0876554250717163, 1.0752567052841187, 1.073622703552246, 1.0706299543380737, 1.069332242012024, 1.0706592798233032, 1.0606207847595215], 'val_accuracy': [0.6889140009880066, 0.7319004535675049, 0.7217194437980652, 0.7228506803512573, 0.7104072570800781, 0.733031690120697, 0.7409502267837524, 0.7217194437980652, 0.7273755669593811, 0.7420814633369446, 0.7488687634468079, 0.7545248866081238, 0.75, 0.7556561231613159, 0.7545248866081238, 0.7590497732162476, 0.7635746598243713, 0.7613122463226318, 0.7567873597145081, 0.7647058963775635, 0.7601810097694397, 0.7601810097694397, 0.7647058963775635, 0.7680995464324951, 0.7726244330406189, 0.7703620195388794, 0.7647058963775635, 0.7703620195388794, 0.7703620195388794, 0.7692307829856873, 0.7782805562019348, 0.7760180830955505, 0.7601810097694397, 0.7760180830955505, 0.7760180830955505, 0.7782805562019348, 0.7760180830955505, 0.7805429697036743, 0.7805429697036743, 0.7873303294181824, 0.7805429697036743, 0.7850678563117981, 0.7828054428100586, 0.7895927429199219, 0.7895927429199219, 0.790723979473114, 0.790723979473114, 0.7895927429199219, 0.7929864525794983, 0.7884615659713745, 0.7884615659713745, 0.7941176295280457, 0.7963801026344299, 0.7839366793632507, 0.779411792755127, 0.7941176295280457, 0.790723979473114, 0.8020362257957458, 0.7918552160263062, 0.8042986392974854, 0.7986425161361694, 0.807692289352417, 0.8031674027442932, 0.8054298758506775, 0.790723979473114, 0.8031674027442932, 0.8020362257957458, 0.8031674027442932, 0.7816742062568665, 0.7941176295280457, 0.8054298758506775, 0.8031674027442932, 0.8020362257957458, 0.807692289352417, 0.7941176295280457, 0.7873303294181824, 0.8031674027442932, 0.8054298758506775, 0.8042986392974854, 0.7963801026344299, 0.7929864525794983, 0.7963801026344299, 0.7918552160263062, 0.7997737526893616, 0.7929864525794983, 0.8088235259056091, 0.8020362257957458, 0.8020362257957458, 0.8054298758506775, 0.7997737526893616, 0.8020362257957458, 0.8020362257957458, 0.8009049892425537, 0.7986425161361694, 0.7997737526893616, 0.8065611124038696, 0.8054298758506775, 0.8020362257957458, 0.8009049892425537, 0.8031674027442932]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 1.8137 - accuracy: 0.5984"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 9s 56ms/step - loss: 1.8136 - accuracy: 0.5990 - val_loss: 1.8108 - val_accuracy: 0.7355\n","Epoch 2/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.7883 - accuracy: 0.7067 - val_loss: 1.7988 - val_accuracy: 0.7324\n","Epoch 3/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.7533 - accuracy: 0.7253 - val_loss: 1.7856 - val_accuracy: 0.7490\n","Epoch 4/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.7098 - accuracy: 0.7416 - val_loss: 1.7705 - val_accuracy: 0.6983\n","Epoch 5/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.6610 - accuracy: 0.7395 - val_loss: 1.7509 - val_accuracy: 0.7541\n","Epoch 6/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.6186 - accuracy: 0.7527 - val_loss: 1.7286 - val_accuracy: 0.7417\n","Epoch 7/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5803 - accuracy: 0.7649 - val_loss: 1.7056 - val_accuracy: 0.7417\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.5614 - accuracy: 0.7669 - val_loss: 1.6852 - val_accuracy: 0.7397\n","Epoch 9/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.5358 - accuracy: 0.7755 - val_loss: 1.6606 - val_accuracy: 0.7758\n","Epoch 10/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5169 - accuracy: 0.7858 - val_loss: 1.6376 - val_accuracy: 0.7645\n","Epoch 11/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.5067 - accuracy: 0.7850 - val_loss: 1.6138 - val_accuracy: 0.7686\n","Epoch 12/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4902 - accuracy: 0.7894 - val_loss: 1.5898 - val_accuracy: 0.7645\n","Epoch 13/100\n","31/31 [==============================] - 1s 31ms/step - loss: 1.4823 - accuracy: 0.7930 - val_loss: 1.5660 - val_accuracy: 0.7800\n","Epoch 14/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.4687 - accuracy: 0.7984 - val_loss: 1.5419 - val_accuracy: 0.7800\n","Epoch 15/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.4584 - accuracy: 0.7987 - val_loss: 1.5191 - val_accuracy: 0.7769\n","Epoch 16/100\n","31/31 [==============================] - 1s 32ms/step - loss: 1.4493 - accuracy: 0.7997 - val_loss: 1.5000 - val_accuracy: 0.7810\n","Epoch 17/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.4377 - accuracy: 0.8041 - val_loss: 1.4809 - val_accuracy: 0.7810\n","Epoch 18/100\n","31/31 [==============================] - 1s 30ms/step - loss: 1.4290 - accuracy: 0.8028 - val_loss: 1.4711 - val_accuracy: 0.7862\n","Epoch 19/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.4195 - accuracy: 0.8088 - val_loss: 1.4540 - val_accuracy: 0.7893\n","Epoch 20/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4084 - accuracy: 0.8047 - val_loss: 1.4374 - val_accuracy: 0.7820\n","Epoch 21/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4029 - accuracy: 0.8021 - val_loss: 1.4270 - val_accuracy: 0.7841\n","Epoch 22/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3931 - accuracy: 0.8083 - val_loss: 1.4334 - val_accuracy: 0.7748\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3855 - accuracy: 0.8065 - val_loss: 1.4097 - val_accuracy: 0.7841\n","Epoch 24/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.3768 - accuracy: 0.8080 - val_loss: 1.4035 - val_accuracy: 0.7975\n","Epoch 25/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3693 - accuracy: 0.8096 - val_loss: 1.4033 - val_accuracy: 0.7851\n","Epoch 26/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.3591 - accuracy: 0.8111 - val_loss: 1.3894 - val_accuracy: 0.7986\n","Epoch 27/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3502 - accuracy: 0.8147 - val_loss: 1.3803 - val_accuracy: 0.7944\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3410 - accuracy: 0.8147 - val_loss: 1.3753 - val_accuracy: 0.7872\n","Epoch 29/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3412 - accuracy: 0.8072 - val_loss: 1.3673 - val_accuracy: 0.7934\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3289 - accuracy: 0.8165 - val_loss: 1.3644 - val_accuracy: 0.7975\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3199 - accuracy: 0.8140 - val_loss: 1.3522 - val_accuracy: 0.7975\n","Epoch 32/100\n","31/31 [==============================] - 1s 30ms/step - loss: 1.3133 - accuracy: 0.8178 - val_loss: 1.3451 - val_accuracy: 0.7996\n","Epoch 33/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3033 - accuracy: 0.8163 - val_loss: 1.3390 - val_accuracy: 0.7965\n","Epoch 34/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.2945 - accuracy: 0.8207 - val_loss: 1.3322 - val_accuracy: 0.7965\n","Epoch 35/100\n","31/31 [==============================] - 1s 30ms/step - loss: 1.2856 - accuracy: 0.8230 - val_loss: 1.3248 - val_accuracy: 0.8017\n","Epoch 36/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2781 - accuracy: 0.8220 - val_loss: 1.3186 - val_accuracy: 0.7996\n","Epoch 37/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.2760 - accuracy: 0.8220 - val_loss: 1.3159 - val_accuracy: 0.7965\n","Epoch 38/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.2633 - accuracy: 0.8196 - val_loss: 1.3027 - val_accuracy: 0.8017\n","Epoch 39/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2547 - accuracy: 0.8225 - val_loss: 1.2981 - val_accuracy: 0.7955\n","Epoch 40/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2492 - accuracy: 0.8196 - val_loss: 1.2898 - val_accuracy: 0.7986\n","Epoch 41/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.2475 - accuracy: 0.8194 - val_loss: 1.2847 - val_accuracy: 0.8027\n","Epoch 42/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.2360 - accuracy: 0.8202 - val_loss: 1.2763 - val_accuracy: 0.8058\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2251 - accuracy: 0.8279 - val_loss: 1.2714 - val_accuracy: 0.7996\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2158 - accuracy: 0.8282 - val_loss: 1.2649 - val_accuracy: 0.8017\n","Epoch 45/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2103 - accuracy: 0.8326 - val_loss: 1.2596 - val_accuracy: 0.7934\n","Epoch 46/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2025 - accuracy: 0.8300 - val_loss: 1.2545 - val_accuracy: 0.7955\n","Epoch 47/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.1971 - accuracy: 0.8346 - val_loss: 1.2441 - val_accuracy: 0.8068\n","Epoch 48/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.1849 - accuracy: 0.8380 - val_loss: 1.2401 - val_accuracy: 0.8120\n","Epoch 49/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1828 - accuracy: 0.8364 - val_loss: 1.2307 - val_accuracy: 0.8017\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1722 - accuracy: 0.8364 - val_loss: 1.2238 - val_accuracy: 0.8079\n","Epoch 51/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1723 - accuracy: 0.8328 - val_loss: 1.2187 - val_accuracy: 0.8048\n","Epoch 52/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1652 - accuracy: 0.8370 - val_loss: 1.2144 - val_accuracy: 0.8130\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1514 - accuracy: 0.8429 - val_loss: 1.2068 - val_accuracy: 0.8027\n","Epoch 54/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.1445 - accuracy: 0.8429 - val_loss: 1.2019 - val_accuracy: 0.8079\n","Epoch 55/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.1384 - accuracy: 0.8421 - val_loss: 1.1944 - val_accuracy: 0.8037\n","Epoch 56/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.1353 - accuracy: 0.8375 - val_loss: 1.2025 - val_accuracy: 0.8099\n","Epoch 57/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.1295 - accuracy: 0.8395 - val_loss: 1.2107 - val_accuracy: 0.8037\n","Epoch 58/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1268 - accuracy: 0.8393 - val_loss: 1.1783 - val_accuracy: 0.8130\n","Epoch 59/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.1094 - accuracy: 0.8455 - val_loss: 1.1769 - val_accuracy: 0.8130\n","Epoch 60/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.1053 - accuracy: 0.8465 - val_loss: 1.1685 - val_accuracy: 0.7996\n","Epoch 61/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1025 - accuracy: 0.8465 - val_loss: 1.1649 - val_accuracy: 0.7986\n","Epoch 62/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.0961 - accuracy: 0.8478 - val_loss: 1.1609 - val_accuracy: 0.8140\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0912 - accuracy: 0.8494 - val_loss: 1.1556 - val_accuracy: 0.8140\n","Epoch 64/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0907 - accuracy: 0.8447 - val_loss: 1.1473 - val_accuracy: 0.7975\n","Epoch 65/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0776 - accuracy: 0.8509 - val_loss: 1.1427 - val_accuracy: 0.8089\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0700 - accuracy: 0.8465 - val_loss: 1.1461 - val_accuracy: 0.8140\n","Epoch 67/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0662 - accuracy: 0.8558 - val_loss: 1.1331 - val_accuracy: 0.8130\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0565 - accuracy: 0.8514 - val_loss: 1.1274 - val_accuracy: 0.8099\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0486 - accuracy: 0.8548 - val_loss: 1.1219 - val_accuracy: 0.8099\n","Epoch 70/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0474 - accuracy: 0.8527 - val_loss: 1.1464 - val_accuracy: 0.8027\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0434 - accuracy: 0.8576 - val_loss: 1.1115 - val_accuracy: 0.8079\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0319 - accuracy: 0.8545 - val_loss: 1.1044 - val_accuracy: 0.8110\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0298 - accuracy: 0.8568 - val_loss: 1.0993 - val_accuracy: 0.8140\n","Epoch 74/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.0202 - accuracy: 0.8618 - val_loss: 1.1000 - val_accuracy: 0.8151\n","Epoch 75/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0156 - accuracy: 0.8630 - val_loss: 1.0922 - val_accuracy: 0.8110\n","Epoch 76/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0116 - accuracy: 0.8587 - val_loss: 1.0924 - val_accuracy: 0.8079\n","Epoch 77/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0040 - accuracy: 0.8612 - val_loss: 1.0835 - val_accuracy: 0.8120\n","Epoch 78/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9992 - accuracy: 0.8584 - val_loss: 1.0785 - val_accuracy: 0.8110\n","Epoch 79/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9873 - accuracy: 0.8659 - val_loss: 1.0763 - val_accuracy: 0.8120\n","Epoch 80/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9836 - accuracy: 0.8628 - val_loss: 1.0734 - val_accuracy: 0.8099\n","Epoch 81/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9800 - accuracy: 0.8633 - val_loss: 1.0657 - val_accuracy: 0.8130\n","Epoch 82/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9746 - accuracy: 0.8633 - val_loss: 1.0596 - val_accuracy: 0.8110\n","Epoch 83/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9687 - accuracy: 0.8667 - val_loss: 1.0577 - val_accuracy: 0.8130\n","Epoch 84/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.9632 - accuracy: 0.8698 - val_loss: 1.0659 - val_accuracy: 0.8192\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9568 - accuracy: 0.8721 - val_loss: 1.0500 - val_accuracy: 0.8089\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9550 - accuracy: 0.8703 - val_loss: 1.0460 - val_accuracy: 0.8140\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9447 - accuracy: 0.8705 - val_loss: 1.0445 - val_accuracy: 0.8140\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9484 - accuracy: 0.8643 - val_loss: 1.0641 - val_accuracy: 0.7965\n","Epoch 89/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.9471 - accuracy: 0.8630 - val_loss: 1.0383 - val_accuracy: 0.8202\n","Epoch 90/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9327 - accuracy: 0.8716 - val_loss: 1.0413 - val_accuracy: 0.8192\n","Epoch 91/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9211 - accuracy: 0.8749 - val_loss: 1.0311 - val_accuracy: 0.8161\n","Epoch 92/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9163 - accuracy: 0.8765 - val_loss: 1.0309 - val_accuracy: 0.8213\n","Epoch 93/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9113 - accuracy: 0.8742 - val_loss: 1.0201 - val_accuracy: 0.8151\n","Epoch 94/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9058 - accuracy: 0.8783 - val_loss: 1.0267 - val_accuracy: 0.8202\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9081 - accuracy: 0.8734 - val_loss: 1.0137 - val_accuracy: 0.8130\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8954 - accuracy: 0.8793 - val_loss: 1.0102 - val_accuracy: 0.8130\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8947 - accuracy: 0.8780 - val_loss: 1.0175 - val_accuracy: 0.8202\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9026 - accuracy: 0.8705 - val_loss: 1.0088 - val_accuracy: 0.8089\n","Epoch 99/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.8868 - accuracy: 0.8780 - val_loss: 1.0115 - val_accuracy: 0.8233\n","Epoch 100/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.8832 - accuracy: 0.8755 - val_loss: 1.0211 - val_accuracy: 0.8171\n","{'loss': [1.813582181930542, 1.788323163986206, 1.7532538175582886, 1.7098355293273926, 1.6610182523727417, 1.6185519695281982, 1.5803298950195312, 1.561352252960205, 1.5358458757400513, 1.516856074333191, 1.5067296028137207, 1.4902424812316895, 1.4822992086410522, 1.468671441078186, 1.4583901166915894, 1.4492690563201904, 1.4377272129058838, 1.4289835691452026, 1.4194787740707397, 1.4083598852157593, 1.4029247760772705, 1.3930604457855225, 1.3854652643203735, 1.3767812252044678, 1.3692545890808105, 1.3591221570968628, 1.350231409072876, 1.3410230875015259, 1.3412078619003296, 1.3288692235946655, 1.319877028465271, 1.3133256435394287, 1.3033467531204224, 1.2945142984390259, 1.2856348752975464, 1.2781121730804443, 1.2760286331176758, 1.2633388042449951, 1.254690408706665, 1.2491635084152222, 1.2475343942642212, 1.235976219177246, 1.2250701189041138, 1.2158160209655762, 1.210324764251709, 1.20249605178833, 1.197080373764038, 1.1848790645599365, 1.1828277111053467, 1.1722177267074585, 1.172345519065857, 1.1651557683944702, 1.1514108180999756, 1.1445159912109375, 1.1383733749389648, 1.1353400945663452, 1.1295472383499146, 1.1267520189285278, 1.1093932390213013, 1.1052724123001099, 1.1024659872055054, 1.0960949659347534, 1.0911622047424316, 1.0907162427902222, 1.0775614976882935, 1.0700161457061768, 1.0661860704421997, 1.056532382965088, 1.0485960245132446, 1.0473591089248657, 1.043355107307434, 1.031863808631897, 1.0298103094100952, 1.02020263671875, 1.0156176090240479, 1.0115818977355957, 1.0040205717086792, 0.9992062449455261, 0.9872539639472961, 0.983616828918457, 0.9799973964691162, 0.9746251702308655, 0.9686556458473206, 0.963175356388092, 0.9568447470664978, 0.9549909830093384, 0.9446525573730469, 0.9483878016471863, 0.9471345543861389, 0.9327325820922852, 0.9210947155952454, 0.9162563681602478, 0.9113105535507202, 0.9057870507240295, 0.9080908298492432, 0.8953741788864136, 0.8946606516838074, 0.9026210308074951, 0.8868235349655151, 0.8831703662872314], 'accuracy': [0.5989664196968079, 0.7067183256149292, 0.7253230214118958, 0.7416020631790161, 0.739534854888916, 0.7527132034301758, 0.7648578882217407, 0.766925036907196, 0.775452196598053, 0.7857881188392639, 0.7850129008293152, 0.7894057035446167, 0.7930232286453247, 0.7984496355056763, 0.7987080216407776, 0.7997416257858276, 0.8041343688964844, 0.802842378616333, 0.8087855577468872, 0.804651141166687, 0.8020671606063843, 0.8082687258720398, 0.8064599633216858, 0.8080103397369385, 0.8095607161521912, 0.8111110925674438, 0.8147286772727966, 0.8147286772727966, 0.8072351217269897, 0.8165374398231506, 0.8139534592628479, 0.817829430103302, 0.8162790536880493, 0.8206718564033508, 0.8229973912239075, 0.8219638466835022, 0.8219638466835022, 0.8196382522583008, 0.8224806189537048, 0.8196382522583008, 0.8193798661231995, 0.8201550245285034, 0.8279069662094116, 0.8281653523445129, 0.8325581550598145, 0.8299741744995117, 0.8346253037452698, 0.8379845023155212, 0.8364341259002686, 0.8364341259002686, 0.8328165411949158, 0.8369508981704712, 0.8428940773010254, 0.8428940773010254, 0.8421188592910767, 0.8374677300453186, 0.8395348787307739, 0.8392764925956726, 0.8454780578613281, 0.8465116024017334, 0.8465116024017334, 0.8478035926818848, 0.8493540287017822, 0.8447028398513794, 0.8509044051170349, 0.8465116024017334, 0.8558139801025391, 0.8514211773872375, 0.854780375957489, 0.8527131676673889, 0.8576227426528931, 0.8545219898223877, 0.8568475246429443, 0.8617570996284485, 0.8630490899085999, 0.8586563467979431, 0.8612403273582458, 0.8583979606628418, 0.8658914566040039, 0.8627907037734985, 0.8633074760437012, 0.8633074760437012, 0.8666666746139526, 0.869767427444458, 0.8720930218696594, 0.8702842593193054, 0.8705426454544067, 0.8643410801887512, 0.8630490899085999, 0.8715762495994568, 0.8749353885650635, 0.8764857649803162, 0.8741602301597595, 0.8782945871353149, 0.8733850121498108, 0.879328191280365, 0.8780362010002136, 0.8705426454544067, 0.8780362010002136, 0.8754522204399109], 'val_loss': [1.8108339309692383, 1.7988264560699463, 1.7855969667434692, 1.770494818687439, 1.750887393951416, 1.7286070585250854, 1.7056035995483398, 1.6852365732192993, 1.6605615615844727, 1.6376031637191772, 1.6137564182281494, 1.5897940397262573, 1.5660151243209839, 1.5419244766235352, 1.5190699100494385, 1.5000170469284058, 1.4808874130249023, 1.4710941314697266, 1.454033374786377, 1.437375783920288, 1.427001714706421, 1.4334452152252197, 1.4096769094467163, 1.4034847021102905, 1.403255820274353, 1.389446496963501, 1.3802542686462402, 1.3752694129943848, 1.3672593832015991, 1.364424705505371, 1.352150321006775, 1.3450804948806763, 1.3389625549316406, 1.3321502208709717, 1.3247897624969482, 1.318638563156128, 1.315906047821045, 1.302741289138794, 1.2980968952178955, 1.289844036102295, 1.2846848964691162, 1.2763354778289795, 1.2714474201202393, 1.2649245262145996, 1.2595925331115723, 1.254457712173462, 1.2441000938415527, 1.2401310205459595, 1.2306591272354126, 1.22377347946167, 1.2187321186065674, 1.2143524885177612, 1.2067605257034302, 1.2018709182739258, 1.1943727731704712, 1.2024842500686646, 1.210669755935669, 1.1782530546188354, 1.1768549680709839, 1.168458342552185, 1.1649448871612549, 1.1608848571777344, 1.1556199789047241, 1.1472896337509155, 1.1427282094955444, 1.1460870504379272, 1.1330682039260864, 1.1274017095565796, 1.1219123601913452, 1.1463980674743652, 1.1114535331726074, 1.1043667793273926, 1.099321722984314, 1.099965214729309, 1.0921684503555298, 1.092445731163025, 1.0835402011871338, 1.0785081386566162, 1.0763423442840576, 1.0734429359436035, 1.065730333328247, 1.0596439838409424, 1.0577023029327393, 1.0659208297729492, 1.0499696731567383, 1.0460199117660522, 1.0445045232772827, 1.0640716552734375, 1.0383144617080688, 1.04132878780365, 1.031104564666748, 1.0308692455291748, 1.0201220512390137, 1.0266551971435547, 1.0137337446212769, 1.0101779699325562, 1.0175400972366333, 1.0087794065475464, 1.011498212814331, 1.0211492776870728], 'val_accuracy': [0.7355371713638306, 0.7324380278587341, 0.7489669322967529, 0.6983470916748047, 0.7541322112083435, 0.7417355179786682, 0.7417355179786682, 0.7396694421768188, 0.7758264541625977, 0.7644628286361694, 0.7685950398445129, 0.7644628286361694, 0.7799586653709412, 0.7799586653709412, 0.7768595218658447, 0.7809917330741882, 0.7809917330741882, 0.7861570119857788, 0.78925621509552, 0.7820248007774353, 0.7840909361839294, 0.7747933864593506, 0.7840909361839294, 0.797520637512207, 0.7851239442825317, 0.7985537052154541, 0.7944214940071106, 0.7871900796890259, 0.7933884263038635, 0.797520637512207, 0.797520637512207, 0.7995867729187012, 0.7964876294136047, 0.7964876294136047, 0.8016529083251953, 0.7995867729187012, 0.7964876294136047, 0.8016529083251953, 0.7954545617103577, 0.7985537052154541, 0.8026859760284424, 0.8057851195335388, 0.7995867729187012, 0.8016529083251953, 0.7933884263038635, 0.7954545617103577, 0.8068181872367859, 0.8119834661483765, 0.8016529083251953, 0.807851254940033, 0.8047520518302917, 0.8130165338516235, 0.8026859760284424, 0.807851254940033, 0.8037189841270447, 0.8099173307418823, 0.8037189841270447, 0.8130165338516235, 0.8130165338516235, 0.7995867729187012, 0.7985537052154541, 0.8140496015548706, 0.8140496015548706, 0.797520637512207, 0.80888432264328, 0.8140496015548706, 0.8130165338516235, 0.8099173307418823, 0.8099173307418823, 0.8026859760284424, 0.807851254940033, 0.8109503984451294, 0.8140496015548706, 0.8150826692581177, 0.8109503984451294, 0.807851254940033, 0.8119834661483765, 0.8109503984451294, 0.8119834661483765, 0.8099173307418823, 0.8130165338516235, 0.8109503984451294, 0.8130165338516235, 0.8192148804664612, 0.80888432264328, 0.8140496015548706, 0.8140496015548706, 0.7964876294136047, 0.8202479481697083, 0.8192148804664612, 0.81611567735672, 0.8212810158729553, 0.8150826692581177, 0.8202479481697083, 0.8130165338516235, 0.8130165338516235, 0.8202479481697083, 0.80888432264328, 0.8233470916748047, 0.817148745059967]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.9691 - accuracy: 0.8336"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 58ms/step - loss: 0.9667 - accuracy: 0.8354 - val_loss: 1.2555 - val_accuracy: 0.7705\n","Epoch 2/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9520 - accuracy: 0.8505 - val_loss: 1.2484 - val_accuracy: 0.7058\n","Epoch 3/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9396 - accuracy: 0.8513 - val_loss: 1.2361 - val_accuracy: 0.7597\n","Epoch 4/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.9301 - accuracy: 0.8591 - val_loss: 1.2276 - val_accuracy: 0.7080\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9263 - accuracy: 0.8570 - val_loss: 1.2164 - val_accuracy: 0.7349\n","Epoch 6/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9160 - accuracy: 0.8642 - val_loss: 1.2012 - val_accuracy: 0.7705\n","Epoch 7/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.9140 - accuracy: 0.8626 - val_loss: 1.1896 - val_accuracy: 0.7489\n","Epoch 8/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9057 - accuracy: 0.8610 - val_loss: 1.1755 - val_accuracy: 0.7705\n","Epoch 9/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8989 - accuracy: 0.8640 - val_loss: 1.1709 - val_accuracy: 0.6562\n","Epoch 10/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9065 - accuracy: 0.8586 - val_loss: 1.1453 - val_accuracy: 0.7543\n","Epoch 11/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.8870 - accuracy: 0.8669 - val_loss: 1.1223 - val_accuracy: 0.7748\n","Epoch 12/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.8824 - accuracy: 0.8666 - val_loss: 1.0993 - val_accuracy: 0.7845\n","Epoch 13/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8766 - accuracy: 0.8664 - val_loss: 1.0928 - val_accuracy: 0.7543\n","Epoch 14/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8681 - accuracy: 0.8677 - val_loss: 1.0697 - val_accuracy: 0.7705\n","Epoch 15/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8667 - accuracy: 0.8699 - val_loss: 1.0564 - val_accuracy: 0.7662\n","Epoch 16/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.8625 - accuracy: 0.8669 - val_loss: 1.0267 - val_accuracy: 0.7856\n","Epoch 17/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8654 - accuracy: 0.8645 - val_loss: 1.0540 - val_accuracy: 0.7252\n","Epoch 18/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8546 - accuracy: 0.8696 - val_loss: 0.9979 - val_accuracy: 0.7856\n","Epoch 19/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8517 - accuracy: 0.8788 - val_loss: 1.0168 - val_accuracy: 0.7651\n","Epoch 20/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.8400 - accuracy: 0.8804 - val_loss: 0.9333 - val_accuracy: 0.8222\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8377 - accuracy: 0.8758 - val_loss: 0.9330 - val_accuracy: 0.8147\n","Epoch 22/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8372 - accuracy: 0.8742 - val_loss: 0.9228 - val_accuracy: 0.8168\n","Epoch 23/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8246 - accuracy: 0.8796 - val_loss: 0.9056 - val_accuracy: 0.8211\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8157 - accuracy: 0.8817 - val_loss: 0.9159 - val_accuracy: 0.8082\n","Epoch 25/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.8223 - accuracy: 0.8804 - val_loss: 0.8950 - val_accuracy: 0.8276\n","Epoch 26/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.8200 - accuracy: 0.8750 - val_loss: 0.8902 - val_accuracy: 0.8308\n","Epoch 27/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8070 - accuracy: 0.8809 - val_loss: 0.8903 - val_accuracy: 0.8265\n","Epoch 28/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.7983 - accuracy: 0.8871 - val_loss: 0.8856 - val_accuracy: 0.8297\n","Epoch 29/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.7955 - accuracy: 0.8834 - val_loss: 0.8847 - val_accuracy: 0.8287\n","Epoch 30/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.7872 - accuracy: 0.8877 - val_loss: 0.8947 - val_accuracy: 0.8254\n","Epoch 31/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.7879 - accuracy: 0.8893 - val_loss: 0.8813 - val_accuracy: 0.8244\n","Epoch 32/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.7817 - accuracy: 0.8901 - val_loss: 0.8820 - val_accuracy: 0.8297\n","Epoch 33/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7857 - accuracy: 0.8874 - val_loss: 0.8883 - val_accuracy: 0.8265\n","Epoch 34/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.7749 - accuracy: 0.8882 - val_loss: 0.8777 - val_accuracy: 0.8319\n","Epoch 35/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.7833 - accuracy: 0.8831 - val_loss: 0.8754 - val_accuracy: 0.8362\n","Epoch 36/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7679 - accuracy: 0.8898 - val_loss: 0.8701 - val_accuracy: 0.8265\n","Epoch 37/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.7580 - accuracy: 0.8930 - val_loss: 0.8696 - val_accuracy: 0.8351\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7582 - accuracy: 0.8960 - val_loss: 0.8701 - val_accuracy: 0.8265\n","Epoch 39/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7520 - accuracy: 0.8982 - val_loss: 0.8710 - val_accuracy: 0.8308\n","Epoch 40/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7462 - accuracy: 0.8930 - val_loss: 0.8633 - val_accuracy: 0.8308\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7445 - accuracy: 0.8968 - val_loss: 0.8741 - val_accuracy: 0.8276\n","Epoch 42/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7407 - accuracy: 0.8976 - val_loss: 0.8739 - val_accuracy: 0.8254\n","Epoch 43/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.7342 - accuracy: 0.8955 - val_loss: 0.8560 - val_accuracy: 0.8384\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7289 - accuracy: 0.8987 - val_loss: 0.8642 - val_accuracy: 0.8341\n","Epoch 45/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.7273 - accuracy: 0.9033 - val_loss: 0.8522 - val_accuracy: 0.8405\n","Epoch 46/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7202 - accuracy: 0.9052 - val_loss: 0.8587 - val_accuracy: 0.8341\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7184 - accuracy: 0.9041 - val_loss: 0.8550 - val_accuracy: 0.8308\n","Epoch 48/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7177 - accuracy: 0.9033 - val_loss: 0.8520 - val_accuracy: 0.8373\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7092 - accuracy: 0.9049 - val_loss: 0.8499 - val_accuracy: 0.8362\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7091 - accuracy: 0.9044 - val_loss: 0.8704 - val_accuracy: 0.8222\n","Epoch 51/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6981 - accuracy: 0.9087 - val_loss: 0.8513 - val_accuracy: 0.8319\n","Epoch 52/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6928 - accuracy: 0.9138 - val_loss: 0.8540 - val_accuracy: 0.8319\n","Epoch 53/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6885 - accuracy: 0.9122 - val_loss: 0.8453 - val_accuracy: 0.8405\n","Epoch 54/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.6864 - accuracy: 0.9138 - val_loss: 0.8502 - val_accuracy: 0.8319\n","Epoch 55/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6857 - accuracy: 0.9119 - val_loss: 0.8510 - val_accuracy: 0.8341\n","Epoch 56/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6893 - accuracy: 0.9106 - val_loss: 0.8396 - val_accuracy: 0.8405\n","Epoch 57/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6768 - accuracy: 0.9133 - val_loss: 0.8436 - val_accuracy: 0.8330\n","Epoch 58/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.6841 - accuracy: 0.9103 - val_loss: 0.8390 - val_accuracy: 0.8405\n","Epoch 59/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6758 - accuracy: 0.9127 - val_loss: 0.8458 - val_accuracy: 0.8384\n","Epoch 60/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6660 - accuracy: 0.9130 - val_loss: 0.8497 - val_accuracy: 0.8341\n","Epoch 61/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6653 - accuracy: 0.9184 - val_loss: 0.8611 - val_accuracy: 0.8222\n","Epoch 62/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6549 - accuracy: 0.9205 - val_loss: 0.8376 - val_accuracy: 0.8405\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6505 - accuracy: 0.9243 - val_loss: 0.8369 - val_accuracy: 0.8351\n","Epoch 64/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6558 - accuracy: 0.9143 - val_loss: 0.8412 - val_accuracy: 0.8384\n","Epoch 65/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6475 - accuracy: 0.9224 - val_loss: 0.8524 - val_accuracy: 0.8287\n","Epoch 66/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6407 - accuracy: 0.9256 - val_loss: 0.8415 - val_accuracy: 0.8351\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6422 - accuracy: 0.9259 - val_loss: 0.8554 - val_accuracy: 0.8319\n","Epoch 68/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6395 - accuracy: 0.9262 - val_loss: 0.8371 - val_accuracy: 0.8351\n","Epoch 69/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6286 - accuracy: 0.9265 - val_loss: 0.8412 - val_accuracy: 0.8330\n","Epoch 70/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6345 - accuracy: 0.9224 - val_loss: 0.8611 - val_accuracy: 0.8287\n","Epoch 71/100\n","29/29 [==============================] - 1s 51ms/step - loss: 0.6416 - accuracy: 0.9221 - val_loss: 0.8355 - val_accuracy: 0.8438\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6287 - accuracy: 0.9232 - val_loss: 0.8326 - val_accuracy: 0.8384\n","Epoch 73/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6216 - accuracy: 0.9294 - val_loss: 0.9976 - val_accuracy: 0.7802\n","Epoch 74/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6326 - accuracy: 0.9216 - val_loss: 0.8324 - val_accuracy: 0.8448\n","Epoch 75/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6186 - accuracy: 0.9294 - val_loss: 0.8499 - val_accuracy: 0.8276\n","Epoch 76/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6267 - accuracy: 0.9259 - val_loss: 0.8708 - val_accuracy: 0.8211\n","Epoch 77/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6047 - accuracy: 0.9370 - val_loss: 0.8247 - val_accuracy: 0.8438\n","Epoch 78/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6097 - accuracy: 0.9286 - val_loss: 0.8280 - val_accuracy: 0.8341\n","Epoch 79/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5944 - accuracy: 0.9348 - val_loss: 0.8342 - val_accuracy: 0.8351\n","Epoch 80/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5945 - accuracy: 0.9340 - val_loss: 0.8284 - val_accuracy: 0.8384\n","Epoch 81/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5897 - accuracy: 0.9375 - val_loss: 0.8482 - val_accuracy: 0.8330\n","Epoch 82/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5891 - accuracy: 0.9364 - val_loss: 0.8650 - val_accuracy: 0.8254\n","Epoch 83/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5817 - accuracy: 0.9405 - val_loss: 0.8636 - val_accuracy: 0.8254\n","Epoch 84/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5887 - accuracy: 0.9327 - val_loss: 0.8514 - val_accuracy: 0.8297\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5762 - accuracy: 0.9423 - val_loss: 0.8479 - val_accuracy: 0.8341\n","Epoch 86/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5702 - accuracy: 0.9453 - val_loss: 0.8474 - val_accuracy: 0.8373\n","Epoch 87/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5744 - accuracy: 0.9397 - val_loss: 0.8523 - val_accuracy: 0.8330\n","Epoch 88/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5710 - accuracy: 0.9407 - val_loss: 0.8451 - val_accuracy: 0.8341\n","Epoch 89/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.5742 - accuracy: 0.9410 - val_loss: 0.8310 - val_accuracy: 0.8470\n","Epoch 90/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5732 - accuracy: 0.9362 - val_loss: 0.8377 - val_accuracy: 0.8308\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5720 - accuracy: 0.9383 - val_loss: 0.8287 - val_accuracy: 0.8394\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5632 - accuracy: 0.9434 - val_loss: 0.8468 - val_accuracy: 0.8319\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5661 - accuracy: 0.9383 - val_loss: 0.8484 - val_accuracy: 0.8265\n","Epoch 94/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5596 - accuracy: 0.9413 - val_loss: 0.8326 - val_accuracy: 0.8319\n","Epoch 95/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5556 - accuracy: 0.9423 - val_loss: 0.8394 - val_accuracy: 0.8308\n","Epoch 96/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5552 - accuracy: 0.9445 - val_loss: 0.8344 - val_accuracy: 0.8362\n","Epoch 97/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5379 - accuracy: 0.9523 - val_loss: 0.8533 - val_accuracy: 0.8384\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5432 - accuracy: 0.9467 - val_loss: 0.8333 - val_accuracy: 0.8384\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5497 - accuracy: 0.9461 - val_loss: 0.8406 - val_accuracy: 0.8341\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5333 - accuracy: 0.9529 - val_loss: 0.8409 - val_accuracy: 0.8384\n","{'loss': [0.9667035341262817, 0.9519820809364319, 0.9396186470985413, 0.9301325082778931, 0.9263345003128052, 0.9160023927688599, 0.9140458703041077, 0.9056785702705383, 0.8989195823669434, 0.9064648747444153, 0.8869702816009521, 0.882444441318512, 0.8765681982040405, 0.8681461215019226, 0.8667078614234924, 0.8625016212463379, 0.8654303550720215, 0.8545750975608826, 0.8517441749572754, 0.8399885892868042, 0.8376529216766357, 0.8372286558151245, 0.8245883584022522, 0.8157309293746948, 0.8223203420639038, 0.8199929594993591, 0.8069921731948853, 0.7982794046401978, 0.7954722046852112, 0.7872239351272583, 0.787865936756134, 0.7817091941833496, 0.7856861352920532, 0.7749378681182861, 0.7832530736923218, 0.7679352760314941, 0.7580440640449524, 0.7582328915596008, 0.7520390152931213, 0.7462387681007385, 0.7444825172424316, 0.7406678795814514, 0.7342299818992615, 0.7288939952850342, 0.7273107171058655, 0.7201931476593018, 0.7184264063835144, 0.7177061438560486, 0.7091779112815857, 0.709096372127533, 0.6980682611465454, 0.6927704811096191, 0.6884846687316895, 0.6864312291145325, 0.6857200264930725, 0.6893025636672974, 0.676771879196167, 0.6841066479682922, 0.6757522225379944, 0.6660383343696594, 0.6652855277061462, 0.6548610925674438, 0.6504611968994141, 0.6558126211166382, 0.6475104689598083, 0.6406620144844055, 0.6422479748725891, 0.639542818069458, 0.6285513043403625, 0.6344892978668213, 0.6416043043136597, 0.6286741495132446, 0.6216373443603516, 0.632563054561615, 0.6186492443084717, 0.6266815662384033, 0.6047340035438538, 0.609664797782898, 0.594427227973938, 0.5944871306419373, 0.5896543264389038, 0.5890653133392334, 0.5816820859909058, 0.5887172222137451, 0.5762497186660767, 0.5701735019683838, 0.5744118094444275, 0.5709807872772217, 0.5742008686065674, 0.5732449889183044, 0.5719777345657349, 0.5631775259971619, 0.5661097764968872, 0.5596439242362976, 0.5555935502052307, 0.5551710724830627, 0.5379493832588196, 0.543204665184021, 0.5496760010719299, 0.5333464741706848], 'accuracy': [0.8353987336158752, 0.8504849076271057, 0.8512930870056152, 0.8591055870056152, 0.8569504022598267, 0.8642241358757019, 0.8626077771186829, 0.860991358757019, 0.8639547228813171, 0.8585668206214905, 0.8669180870056152, 0.8666487336158752, 0.8663793206214905, 0.8677262663841248, 0.8698814511299133, 0.8669180870056152, 0.8644935488700867, 0.8696120977401733, 0.8787715435028076, 0.8803879022598267, 0.8758081793785095, 0.8741918206214905, 0.8795797228813171, 0.8817349076271057, 0.8803879022598267, 0.875, 0.8809267282485962, 0.8871228694915771, 0.8833512663841248, 0.8876616358757019, 0.889277994632721, 0.8900862336158752, 0.8873922228813171, 0.8882004022598267, 0.8830819129943848, 0.8898168206214905, 0.8930495977401733, 0.8960129022598267, 0.8981680870056152, 0.8930495977401733, 0.896821141242981, 0.8976293206214905, 0.8954741358757019, 0.8987069129943848, 0.9032866358757019, 0.9051724076271057, 0.9040948152542114, 0.9032866358757019, 0.904902994632721, 0.9043642282485962, 0.9086745977401733, 0.9137930870056152, 0.9121767282485962, 0.9137930870056152, 0.9119073152542114, 0.9105603694915771, 0.9132543206214905, 0.9102909564971924, 0.912715494632721, 0.9129849076271057, 0.9183728694915771, 0.920527994632721, 0.9242995977401733, 0.9143319129943848, 0.9224137663841248, 0.9256465435028076, 0.9259159564971924, 0.9261853694915771, 0.9264547228813171, 0.9224137663841248, 0.9221444129943848, 0.923222005367279, 0.9294180870056152, 0.9216055870056152, 0.9294180870056152, 0.9259159564971924, 0.9369612336158752, 0.9286099076271057, 0.9348060488700867, 0.9339978694915771, 0.9375, 0.9364224076271057, 0.9404633641242981, 0.9326508641242981, 0.9423491358757019, 0.9453125, 0.9396551847457886, 0.9407327771186829, 0.9410021305084229, 0.936152994632721, 0.9383081793785095, 0.9434267282485962, 0.9383081793785095, 0.9412715435028076, 0.9423491358757019, 0.9445043206214905, 0.9523168206214905, 0.946659505367279, 0.9461206793785095, 0.9528555870056152], 'val_loss': [1.2555320262908936, 1.2483956813812256, 1.2361067533493042, 1.227573037147522, 1.2163949012756348, 1.2012419700622559, 1.189647912979126, 1.1754639148712158, 1.1708866357803345, 1.1452993154525757, 1.12226140499115, 1.0992987155914307, 1.0928411483764648, 1.069669485092163, 1.0564329624176025, 1.0266594886779785, 1.054016351699829, 0.9979046583175659, 1.016785740852356, 0.9333240985870361, 0.933040976524353, 0.9227646589279175, 0.9055829644203186, 0.9158969521522522, 0.895017147064209, 0.8901601433753967, 0.8903423547744751, 0.8855856657028198, 0.8846736550331116, 0.8947317600250244, 0.8813071846961975, 0.8820412755012512, 0.8883373737335205, 0.8777279853820801, 0.8753753900527954, 0.8700624704360962, 0.8695541620254517, 0.8700549006462097, 0.8710010647773743, 0.8633339405059814, 0.8740726709365845, 0.8739081621170044, 0.8559660911560059, 0.864163339138031, 0.8521662950515747, 0.8586989641189575, 0.8549731969833374, 0.8520069122314453, 0.8498998284339905, 0.870361328125, 0.8513343334197998, 0.8540483117103577, 0.8453019261360168, 0.8501986861228943, 0.8509565591812134, 0.8396245837211609, 0.8435890078544617, 0.8390002250671387, 0.8458376526832581, 0.849653959274292, 0.8610939383506775, 0.8376126885414124, 0.8369070291519165, 0.84124356508255, 0.8524330258369446, 0.841515302658081, 0.8553619980812073, 0.8370556831359863, 0.8412202000617981, 0.8611347079277039, 0.8355206251144409, 0.8325902819633484, 0.9975636005401611, 0.8323739767074585, 0.8498997092247009, 0.8707880973815918, 0.8246673941612244, 0.828031063079834, 0.8342099785804749, 0.8284092545509338, 0.848220944404602, 0.864977240562439, 0.8635990619659424, 0.8514029383659363, 0.847948431968689, 0.8473517298698425, 0.8523420691490173, 0.845090389251709, 0.8309917449951172, 0.8377410173416138, 0.8287211656570435, 0.8467534184455872, 0.8484408259391785, 0.8326032161712646, 0.8393967747688293, 0.8344281911849976, 0.8532857298851013, 0.8333090543746948, 0.8406237959861755, 0.8409255743026733], 'val_accuracy': [0.7704741358757019, 0.7058189511299133, 0.7596982717514038, 0.7079741358757019, 0.7349137663841248, 0.7704741358757019, 0.7489224076271057, 0.7704741358757019, 0.65625, 0.7543103694915771, 0.774784505367279, 0.7844827771186829, 0.7543103694915771, 0.7704741358757019, 0.7661637663841248, 0.7855603694915771, 0.725215494632721, 0.7855603694915771, 0.7650862336158752, 0.8221982717514038, 0.8146551847457886, 0.8168103694915771, 0.8211206793785095, 0.8081896305084229, 0.8275862336158752, 0.8308189511299133, 0.826508641242981, 0.829741358757019, 0.8286637663841248, 0.8254310488700867, 0.8243534564971924, 0.829741358757019, 0.826508641242981, 0.8318965435028076, 0.8362069129943848, 0.826508641242981, 0.8351293206214905, 0.826508641242981, 0.8308189511299133, 0.8308189511299133, 0.8275862336158752, 0.8254310488700867, 0.8383620977401733, 0.8340517282485962, 0.8405172228813171, 0.8340517282485962, 0.8308189511299133, 0.837284505367279, 0.8362069129943848, 0.8221982717514038, 0.8318965435028076, 0.8318965435028076, 0.8405172228813171, 0.8318965435028076, 0.8340517282485962, 0.8405172228813171, 0.8329741358757019, 0.8405172228813171, 0.8383620977401733, 0.8340517282485962, 0.8221982717514038, 0.8405172228813171, 0.8351293206214905, 0.8383620977401733, 0.8286637663841248, 0.8351293206214905, 0.8318965435028076, 0.8351293206214905, 0.8329741358757019, 0.8286637663841248, 0.84375, 0.8383620977401733, 0.7801724076271057, 0.8448275923728943, 0.8275862336158752, 0.8211206793785095, 0.84375, 0.8340517282485962, 0.8351293206214905, 0.8383620977401733, 0.8329741358757019, 0.8254310488700867, 0.8254310488700867, 0.829741358757019, 0.8340517282485962, 0.837284505367279, 0.8329741358757019, 0.8340517282485962, 0.8469827771186829, 0.8308189511299133, 0.8394396305084229, 0.8318965435028076, 0.826508641242981, 0.8318965435028076, 0.8308189511299133, 0.8362069129943848, 0.8383620977401733, 0.8383620977401733, 0.8340517282485962, 0.8383620977401733]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.9813 - accuracy: 0.8328"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 60ms/step - loss: 0.9804 - accuracy: 0.8336 - val_loss: 1.2586 - val_accuracy: 0.7919\n","Epoch 2/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.9730 - accuracy: 0.8393 - val_loss: 1.2490 - val_accuracy: 0.7930\n","Epoch 3/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9665 - accuracy: 0.8390 - val_loss: 1.2408 - val_accuracy: 0.7907\n","Epoch 4/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9494 - accuracy: 0.8480 - val_loss: 1.2316 - val_accuracy: 0.7466\n","Epoch 5/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.9479 - accuracy: 0.8503 - val_loss: 1.2192 - val_accuracy: 0.8088\n","Epoch 6/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9375 - accuracy: 0.8506 - val_loss: 1.2124 - val_accuracy: 0.7274\n","Epoch 7/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9311 - accuracy: 0.8475 - val_loss: 1.2020 - val_accuracy: 0.7138\n","Epoch 8/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9292 - accuracy: 0.8495 - val_loss: 1.1883 - val_accuracy: 0.7217\n","Epoch 9/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9263 - accuracy: 0.8475 - val_loss: 1.1732 - val_accuracy: 0.7511\n","Epoch 10/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.9172 - accuracy: 0.8534 - val_loss: 1.1518 - val_accuracy: 0.8133\n","Epoch 11/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9136 - accuracy: 0.8458 - val_loss: 1.1438 - val_accuracy: 0.7624\n","Epoch 12/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9085 - accuracy: 0.8526 - val_loss: 1.1253 - val_accuracy: 0.7658\n","Epoch 13/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8993 - accuracy: 0.8543 - val_loss: 1.1108 - val_accuracy: 0.7602\n","Epoch 14/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8930 - accuracy: 0.8540 - val_loss: 1.0868 - val_accuracy: 0.7873\n","Epoch 15/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8836 - accuracy: 0.8534 - val_loss: 1.0721 - val_accuracy: 0.7839\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8869 - accuracy: 0.8557 - val_loss: 1.0617 - val_accuracy: 0.7670\n","Epoch 17/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8714 - accuracy: 0.8588 - val_loss: 1.0325 - val_accuracy: 0.7851\n","Epoch 18/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8742 - accuracy: 0.8599 - val_loss: 0.9962 - val_accuracy: 0.8111\n","Epoch 19/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8676 - accuracy: 0.8628 - val_loss: 1.0123 - val_accuracy: 0.7738\n","Epoch 20/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.8604 - accuracy: 0.8616 - val_loss: 0.9630 - val_accuracy: 0.8179\n","Epoch 21/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8602 - accuracy: 0.8622 - val_loss: 0.9719 - val_accuracy: 0.8043\n","Epoch 22/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.8638 - accuracy: 0.8557 - val_loss: 0.9379 - val_accuracy: 0.8269\n","Epoch 23/100\n","28/28 [==============================] - 1s 45ms/step - loss: 0.8558 - accuracy: 0.8611 - val_loss: 0.9261 - val_accuracy: 0.8360\n","Epoch 24/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8419 - accuracy: 0.8639 - val_loss: 0.9258 - val_accuracy: 0.8179\n","Epoch 25/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8344 - accuracy: 0.8662 - val_loss: 0.9181 - val_accuracy: 0.8326\n","Epoch 26/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8423 - accuracy: 0.8628 - val_loss: 0.9146 - val_accuracy: 0.8281\n","Epoch 27/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8357 - accuracy: 0.8684 - val_loss: 0.9100 - val_accuracy: 0.8326\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8283 - accuracy: 0.8656 - val_loss: 0.9104 - val_accuracy: 0.8337\n","Epoch 29/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8167 - accuracy: 0.8735 - val_loss: 0.9157 - val_accuracy: 0.8167\n","Epoch 30/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8119 - accuracy: 0.8792 - val_loss: 0.9091 - val_accuracy: 0.8269\n","Epoch 31/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8109 - accuracy: 0.8735 - val_loss: 0.9091 - val_accuracy: 0.8292\n","Epoch 32/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8166 - accuracy: 0.8681 - val_loss: 0.9150 - val_accuracy: 0.8224\n","Epoch 33/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8017 - accuracy: 0.8778 - val_loss: 0.9110 - val_accuracy: 0.8190\n","Epoch 34/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.7951 - accuracy: 0.8797 - val_loss: 0.9081 - val_accuracy: 0.8258\n","Epoch 35/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7885 - accuracy: 0.8857 - val_loss: 0.9076 - val_accuracy: 0.8224\n","Epoch 36/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7926 - accuracy: 0.8744 - val_loss: 0.9103 - val_accuracy: 0.8258\n","Epoch 37/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7774 - accuracy: 0.8851 - val_loss: 0.9055 - val_accuracy: 0.8190\n","Epoch 38/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7739 - accuracy: 0.8846 - val_loss: 0.9048 - val_accuracy: 0.8201\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7754 - accuracy: 0.8831 - val_loss: 0.9037 - val_accuracy: 0.8213\n","Epoch 40/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7704 - accuracy: 0.8874 - val_loss: 0.9012 - val_accuracy: 0.8303\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7791 - accuracy: 0.8772 - val_loss: 0.9014 - val_accuracy: 0.8213\n","Epoch 42/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7666 - accuracy: 0.8868 - val_loss: 0.8972 - val_accuracy: 0.8213\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7585 - accuracy: 0.8888 - val_loss: 0.9476 - val_accuracy: 0.8066\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7584 - accuracy: 0.8862 - val_loss: 0.8931 - val_accuracy: 0.8258\n","Epoch 45/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7552 - accuracy: 0.8896 - val_loss: 0.8901 - val_accuracy: 0.8269\n","Epoch 46/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7482 - accuracy: 0.8896 - val_loss: 0.8910 - val_accuracy: 0.8213\n","Epoch 47/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7388 - accuracy: 0.8899 - val_loss: 0.8892 - val_accuracy: 0.8269\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7352 - accuracy: 0.8945 - val_loss: 0.8876 - val_accuracy: 0.8281\n","Epoch 49/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7340 - accuracy: 0.8933 - val_loss: 0.8901 - val_accuracy: 0.8269\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7312 - accuracy: 0.8939 - val_loss: 0.9036 - val_accuracy: 0.8133\n","Epoch 51/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7293 - accuracy: 0.8902 - val_loss: 0.8878 - val_accuracy: 0.8224\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7190 - accuracy: 0.8978 - val_loss: 0.8859 - val_accuracy: 0.8292\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7176 - accuracy: 0.9029 - val_loss: 0.8813 - val_accuracy: 0.8269\n","Epoch 54/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7145 - accuracy: 0.9001 - val_loss: 0.8888 - val_accuracy: 0.8213\n","Epoch 55/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7256 - accuracy: 0.8916 - val_loss: 0.9505 - val_accuracy: 0.7828\n","Epoch 56/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7433 - accuracy: 0.8797 - val_loss: 0.9251 - val_accuracy: 0.8122\n","Epoch 57/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7112 - accuracy: 0.9004 - val_loss: 0.8757 - val_accuracy: 0.8258\n","Epoch 58/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6996 - accuracy: 0.9046 - val_loss: 0.8765 - val_accuracy: 0.8235\n","Epoch 59/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6937 - accuracy: 0.9041 - val_loss: 0.8772 - val_accuracy: 0.8281\n","Epoch 60/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6922 - accuracy: 0.9049 - val_loss: 0.8791 - val_accuracy: 0.8281\n","Epoch 61/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6796 - accuracy: 0.9106 - val_loss: 0.8792 - val_accuracy: 0.8258\n","Epoch 62/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6865 - accuracy: 0.9061 - val_loss: 0.8767 - val_accuracy: 0.8292\n","Epoch 63/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6851 - accuracy: 0.9055 - val_loss: 0.8852 - val_accuracy: 0.8179\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6750 - accuracy: 0.9114 - val_loss: 0.8784 - val_accuracy: 0.8247\n","Epoch 65/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6726 - accuracy: 0.9097 - val_loss: 0.9033 - val_accuracy: 0.8100\n","Epoch 66/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6734 - accuracy: 0.9061 - val_loss: 0.8838 - val_accuracy: 0.8213\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6634 - accuracy: 0.9103 - val_loss: 0.8813 - val_accuracy: 0.8303\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6641 - accuracy: 0.9117 - val_loss: 0.8744 - val_accuracy: 0.8235\n","Epoch 69/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6644 - accuracy: 0.9106 - val_loss: 0.8715 - val_accuracy: 0.8303\n","Epoch 70/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6464 - accuracy: 0.9270 - val_loss: 0.8761 - val_accuracy: 0.8235\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6547 - accuracy: 0.9128 - val_loss: 0.8761 - val_accuracy: 0.8224\n","Epoch 72/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6443 - accuracy: 0.9177 - val_loss: 0.8776 - val_accuracy: 0.8201\n","Epoch 73/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6456 - accuracy: 0.9179 - val_loss: 0.8802 - val_accuracy: 0.8281\n","Epoch 74/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6472 - accuracy: 0.9160 - val_loss: 0.8764 - val_accuracy: 0.8235\n","Epoch 75/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6345 - accuracy: 0.9196 - val_loss: 0.8882 - val_accuracy: 0.8111\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6367 - accuracy: 0.9202 - val_loss: 0.8719 - val_accuracy: 0.8235\n","Epoch 77/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6342 - accuracy: 0.9208 - val_loss: 0.8755 - val_accuracy: 0.8247\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6273 - accuracy: 0.9199 - val_loss: 0.8777 - val_accuracy: 0.8258\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6260 - accuracy: 0.9219 - val_loss: 0.8733 - val_accuracy: 0.8167\n","Epoch 80/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6166 - accuracy: 0.9259 - val_loss: 0.8742 - val_accuracy: 0.8235\n","Epoch 81/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6155 - accuracy: 0.9261 - val_loss: 0.8805 - val_accuracy: 0.8190\n","Epoch 82/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6217 - accuracy: 0.9211 - val_loss: 0.8810 - val_accuracy: 0.8235\n","Epoch 83/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6127 - accuracy: 0.9253 - val_loss: 0.8770 - val_accuracy: 0.8235\n","Epoch 84/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6009 - accuracy: 0.9312 - val_loss: 0.8814 - val_accuracy: 0.8235\n","Epoch 85/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6066 - accuracy: 0.9239 - val_loss: 0.8846 - val_accuracy: 0.8190\n","Epoch 86/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6095 - accuracy: 0.9225 - val_loss: 0.8786 - val_accuracy: 0.8156\n","Epoch 87/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5976 - accuracy: 0.9329 - val_loss: 0.8739 - val_accuracy: 0.8213\n","Epoch 88/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5976 - accuracy: 0.9335 - val_loss: 0.8889 - val_accuracy: 0.8224\n","Epoch 89/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5939 - accuracy: 0.9329 - val_loss: 0.8749 - val_accuracy: 0.8201\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5922 - accuracy: 0.9304 - val_loss: 0.8807 - val_accuracy: 0.8213\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5837 - accuracy: 0.9380 - val_loss: 0.8924 - val_accuracy: 0.8179\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5874 - accuracy: 0.9386 - val_loss: 0.8828 - val_accuracy: 0.8167\n","Epoch 93/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5822 - accuracy: 0.9363 - val_loss: 0.8779 - val_accuracy: 0.8213\n","Epoch 94/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5704 - accuracy: 0.9375 - val_loss: 0.9091 - val_accuracy: 0.8179\n","Epoch 95/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5810 - accuracy: 0.9310 - val_loss: 0.9089 - val_accuracy: 0.8167\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5726 - accuracy: 0.9344 - val_loss: 0.8850 - val_accuracy: 0.8201\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5857 - accuracy: 0.9278 - val_loss: 0.8826 - val_accuracy: 0.8201\n","Epoch 98/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5787 - accuracy: 0.9341 - val_loss: 0.8989 - val_accuracy: 0.8156\n","Epoch 99/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5715 - accuracy: 0.9341 - val_loss: 0.8808 - val_accuracy: 0.8145\n","Epoch 100/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5626 - accuracy: 0.9383 - val_loss: 0.9196 - val_accuracy: 0.8077\n","{'loss': [0.9804297089576721, 0.9729901552200317, 0.9664777517318726, 0.9494402408599854, 0.9478520154953003, 0.9374691247940063, 0.9310738444328308, 0.9292423725128174, 0.9262548685073853, 0.9172406792640686, 0.9135516285896301, 0.9084843397140503, 0.8992862105369568, 0.8929972648620605, 0.8836321830749512, 0.8868669867515564, 0.8714460730552673, 0.874204695224762, 0.867555558681488, 0.8604415655136108, 0.8602489233016968, 0.8638128638267517, 0.8557637929916382, 0.8418540954589844, 0.8344095349311829, 0.8422930836677551, 0.8357329368591309, 0.8282554149627686, 0.8166648745536804, 0.8119152784347534, 0.8109077215194702, 0.8166124224662781, 0.8016995787620544, 0.7950764894485474, 0.7884728312492371, 0.7926369905471802, 0.7773919105529785, 0.7738723158836365, 0.7753667235374451, 0.7703601717948914, 0.7790980339050293, 0.7666231393814087, 0.7585431337356567, 0.7583984136581421, 0.7552090883255005, 0.7481765151023865, 0.738823652267456, 0.7351630926132202, 0.7339780926704407, 0.7311525344848633, 0.7292991876602173, 0.7189878821372986, 0.7176289558410645, 0.714480996131897, 0.725641667842865, 0.7433121204376221, 0.7112203240394592, 0.699609100818634, 0.6937450766563416, 0.692162275314331, 0.6796298623085022, 0.686526894569397, 0.685107409954071, 0.674988865852356, 0.6725706458091736, 0.6734237670898438, 0.663396954536438, 0.6640797257423401, 0.6643671989440918, 0.6464429497718811, 0.6547309756278992, 0.6443130970001221, 0.6455943584442139, 0.6471810340881348, 0.6345052719116211, 0.636676013469696, 0.6342201828956604, 0.62732994556427, 0.6259726285934448, 0.6165613532066345, 0.6155348420143127, 0.6217285990715027, 0.612688422203064, 0.6009196043014526, 0.606611967086792, 0.6094830632209778, 0.5976365208625793, 0.5976083278656006, 0.5938710570335388, 0.5921851396560669, 0.5836954116821289, 0.5874404311180115, 0.5822471380233765, 0.5704177021980286, 0.5809738039970398, 0.5725533366203308, 0.5856627821922302, 0.578669011592865, 0.5715186595916748, 0.562643826007843], 'accuracy': [0.833616316318512, 0.839275598526001, 0.8389926552772522, 0.8480475544929504, 0.850311279296875, 0.8505942225456238, 0.8474816083908081, 0.8494623899459839, 0.8474816083908081, 0.8534238934516907, 0.8457838296890259, 0.8525750041007996, 0.8542727828025818, 0.853989839553833, 0.8534238934516907, 0.8556876182556152, 0.8588002324104309, 0.8599320650100708, 0.8627617359161377, 0.8616299033164978, 0.8621957898139954, 0.8556876182556152, 0.8610639572143555, 0.8638936281204224, 0.8661573529243469, 0.8627617359161377, 0.8684210777282715, 0.8655914068222046, 0.8735144138336182, 0.879173755645752, 0.8735144138336182, 0.8681380748748779, 0.8777589201927185, 0.8797396421432495, 0.8856819272041321, 0.8743633031845093, 0.8851160407066345, 0.8845500946044922, 0.8831352591514587, 0.8873797655105591, 0.8771929740905762, 0.8868138194084167, 0.8887945413589478, 0.8862478733062744, 0.8896434903144836, 0.8896434903144836, 0.8899264335632324, 0.8944538831710815, 0.8933219909667969, 0.8938879370689392, 0.8902093768119812, 0.897849440574646, 0.9029428362846375, 0.9001131653785706, 0.8916242122650146, 0.8797396421432495, 0.9003961682319641, 0.9046406149864197, 0.9040747284889221, 0.9049236178398132, 0.9105829000473022, 0.9060554504394531, 0.9054895043373108, 0.9114317893981934, 0.9097340106964111, 0.9060554504394531, 0.9102999567985535, 0.9117147922515869, 0.9105829000473022, 0.9269949197769165, 0.9128466248512268, 0.9176570177078247, 0.9179400205612183, 0.9159592390060425, 0.9196377992630005, 0.9202037453651428, 0.9207696914672852, 0.9199207425117493, 0.921901524066925, 0.9258630275726318, 0.9261460304260254, 0.9210526347160339, 0.9252971410751343, 0.9312393665313721, 0.9238823056221008, 0.9224674701690674, 0.9329372048377991, 0.9335030913352966, 0.9329372048377991, 0.930390477180481, 0.9380305409431458, 0.9385964870452881, 0.9363327622413635, 0.9374646544456482, 0.9309564232826233, 0.9343519806861877, 0.9278438091278076, 0.934069037437439, 0.934069037437439, 0.9383135437965393], 'val_loss': [1.2586208581924438, 1.249004602432251, 1.2408004999160767, 1.2316440343856812, 1.2191529273986816, 1.2124079465866089, 1.2019962072372437, 1.1883169412612915, 1.173150897026062, 1.1518373489379883, 1.1438230276107788, 1.1252517700195312, 1.1108273267745972, 1.086830496788025, 1.0721240043640137, 1.0616562366485596, 1.0325407981872559, 0.9962084889411926, 1.0123093128204346, 0.9629563093185425, 0.9718747138977051, 0.9378793239593506, 0.9260566234588623, 0.9257516860961914, 0.9181374311447144, 0.9146268963813782, 0.9100276827812195, 0.910351574420929, 0.9156899452209473, 0.9090536236763, 0.9090781211853027, 0.9150025844573975, 0.9110234379768372, 0.9081351161003113, 0.9076253771781921, 0.9103466868400574, 0.9054562449455261, 0.904766857624054, 0.9036879539489746, 0.9011567831039429, 0.9013680815696716, 0.8971957564353943, 0.9476062059402466, 0.8931065201759338, 0.8900734782218933, 0.8909562230110168, 0.8891916275024414, 0.8876469731330872, 0.8901033997535706, 0.9035760760307312, 0.8877813816070557, 0.8858864903450012, 0.8813127875328064, 0.8888100981712341, 0.9505372643470764, 0.9250802397727966, 0.8756985664367676, 0.8765149712562561, 0.8771685361862183, 0.8791102170944214, 0.8792423605918884, 0.8767181038856506, 0.8851979970932007, 0.8783913254737854, 0.9032555222511292, 0.8837800025939941, 0.8812611699104309, 0.8744048476219177, 0.8714685440063477, 0.8760839104652405, 0.8761422634124756, 0.8776460289955139, 0.8801817297935486, 0.8763671517372131, 0.888229250907898, 0.8719111084938049, 0.8754631280899048, 0.8776698112487793, 0.8733320236206055, 0.8742334246635437, 0.880514919757843, 0.8810391426086426, 0.877007782459259, 0.8814290165901184, 0.8846003413200378, 0.878578245639801, 0.8739199638366699, 0.8888841271400452, 0.8748942017555237, 0.8807044625282288, 0.8924394249916077, 0.8827850818634033, 0.8779357671737671, 0.9091207385063171, 0.9089316725730896, 0.8849791288375854, 0.8825799822807312, 0.8988964557647705, 0.8808419108390808, 0.9196393489837646], 'val_accuracy': [0.7918552160263062, 0.7929864525794983, 0.790723979473114, 0.7466063499450684, 0.8088235259056091, 0.7273755669593811, 0.7138009071350098, 0.7217194437980652, 0.7511312365531921, 0.8133484125137329, 0.7624434232711792, 0.7658371329307556, 0.7601810097694397, 0.7873303294181824, 0.7839366793632507, 0.766968309879303, 0.7850678563117981, 0.8110859990119934, 0.773755669593811, 0.8178732991218567, 0.8042986392974854, 0.8269230723381042, 0.8359728455543518, 0.8178732991218567, 0.8325791954994202, 0.8280543088912964, 0.8325791954994202, 0.8337104320526123, 0.8167420625686646, 0.8269230723381042, 0.8291855454444885, 0.8223981857299805, 0.8190045356750488, 0.8257918357849121, 0.8223981857299805, 0.8257918357849121, 0.8190045356750488, 0.820135772228241, 0.8212669491767883, 0.8303167223930359, 0.8212669491767883, 0.8212669491767883, 0.8065611124038696, 0.8257918357849121, 0.8269230723381042, 0.8212669491767883, 0.8269230723381042, 0.8280543088912964, 0.8269230723381042, 0.8133484125137329, 0.8223981857299805, 0.8291855454444885, 0.8269230723381042, 0.8212669491767883, 0.7828054428100586, 0.8122171759605408, 0.8257918357849121, 0.8235294222831726, 0.8280543088912964, 0.8280543088912964, 0.8257918357849121, 0.8291855454444885, 0.8178732991218567, 0.8246606588363647, 0.8099547624588013, 0.8212669491767883, 0.8303167223930359, 0.8235294222831726, 0.8303167223930359, 0.8235294222831726, 0.8223981857299805, 0.820135772228241, 0.8280543088912964, 0.8235294222831726, 0.8110859990119934, 0.8235294222831726, 0.8246606588363647, 0.8257918357849121, 0.8167420625686646, 0.8235294222831726, 0.8190045356750488, 0.8235294222831726, 0.8235294222831726, 0.8235294222831726, 0.8190045356750488, 0.8156108856201172, 0.8212669491767883, 0.8223981857299805, 0.820135772228241, 0.8212669491767883, 0.8178732991218567, 0.8167420625686646, 0.8212669491767883, 0.8178732991218567, 0.8167420625686646, 0.820135772228241, 0.820135772228241, 0.8156108856201172, 0.814479649066925, 0.807692289352417]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.9502 - accuracy: 0.8548"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 53ms/step - loss: 0.9511 - accuracy: 0.8543 - val_loss: 1.2547 - val_accuracy: 0.7810\n","Epoch 2/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9424 - accuracy: 0.8576 - val_loss: 1.2435 - val_accuracy: 0.7614\n","Epoch 3/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9323 - accuracy: 0.8587 - val_loss: 1.2342 - val_accuracy: 0.7469\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9222 - accuracy: 0.8602 - val_loss: 1.2209 - val_accuracy: 0.7758\n","Epoch 5/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.9169 - accuracy: 0.8589 - val_loss: 1.2093 - val_accuracy: 0.7831\n","Epoch 6/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9049 - accuracy: 0.8646 - val_loss: 1.1983 - val_accuracy: 0.7190\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9064 - accuracy: 0.8602 - val_loss: 1.1876 - val_accuracy: 0.6901\n","Epoch 8/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8971 - accuracy: 0.8633 - val_loss: 1.1662 - val_accuracy: 0.7634\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8873 - accuracy: 0.8636 - val_loss: 1.1457 - val_accuracy: 0.7655\n","Epoch 10/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8827 - accuracy: 0.8726 - val_loss: 1.1361 - val_accuracy: 0.7221\n","Epoch 11/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8836 - accuracy: 0.8667 - val_loss: 1.1095 - val_accuracy: 0.7634\n","Epoch 12/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.8757 - accuracy: 0.8661 - val_loss: 1.0773 - val_accuracy: 0.8027\n","Epoch 13/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8725 - accuracy: 0.8664 - val_loss: 1.0747 - val_accuracy: 0.7572\n","Epoch 14/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8625 - accuracy: 0.8713 - val_loss: 1.0508 - val_accuracy: 0.7748\n","Epoch 15/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8527 - accuracy: 0.8749 - val_loss: 1.0171 - val_accuracy: 0.7975\n","Epoch 16/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8486 - accuracy: 0.8739 - val_loss: 1.0025 - val_accuracy: 0.7924\n","Epoch 17/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.8531 - accuracy: 0.8726 - val_loss: 0.9625 - val_accuracy: 0.8275\n","Epoch 18/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8415 - accuracy: 0.8752 - val_loss: 0.9495 - val_accuracy: 0.8192\n","Epoch 19/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.8322 - accuracy: 0.8819 - val_loss: 0.9261 - val_accuracy: 0.8337\n","Epoch 20/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8298 - accuracy: 0.8804 - val_loss: 0.9380 - val_accuracy: 0.8130\n","Epoch 21/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8180 - accuracy: 0.8876 - val_loss: 0.8986 - val_accuracy: 0.8326\n","Epoch 22/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8212 - accuracy: 0.8817 - val_loss: 0.9016 - val_accuracy: 0.8347\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8141 - accuracy: 0.8811 - val_loss: 0.8886 - val_accuracy: 0.8347\n","Epoch 24/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8121 - accuracy: 0.8801 - val_loss: 0.8864 - val_accuracy: 0.8295\n","Epoch 25/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8081 - accuracy: 0.8858 - val_loss: 0.8882 - val_accuracy: 0.8316\n","Epoch 26/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7991 - accuracy: 0.8871 - val_loss: 0.8829 - val_accuracy: 0.8306\n","Epoch 27/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7988 - accuracy: 0.8853 - val_loss: 0.8808 - val_accuracy: 0.8316\n","Epoch 28/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7836 - accuracy: 0.8879 - val_loss: 0.8831 - val_accuracy: 0.8223\n","Epoch 29/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.7953 - accuracy: 0.8822 - val_loss: 0.8878 - val_accuracy: 0.8419\n","Epoch 30/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7756 - accuracy: 0.8925 - val_loss: 0.8842 - val_accuracy: 0.8213\n","Epoch 31/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.7710 - accuracy: 0.8961 - val_loss: 0.8743 - val_accuracy: 0.8357\n","Epoch 32/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.7755 - accuracy: 0.8876 - val_loss: 0.8926 - val_accuracy: 0.8378\n","Epoch 33/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7778 - accuracy: 0.8881 - val_loss: 0.8700 - val_accuracy: 0.8357\n","Epoch 34/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7656 - accuracy: 0.8915 - val_loss: 0.8752 - val_accuracy: 0.8357\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7641 - accuracy: 0.8884 - val_loss: 0.8743 - val_accuracy: 0.8378\n","Epoch 36/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7588 - accuracy: 0.8935 - val_loss: 0.8643 - val_accuracy: 0.8357\n","Epoch 37/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7571 - accuracy: 0.8897 - val_loss: 0.8672 - val_accuracy: 0.8368\n","Epoch 38/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7479 - accuracy: 0.8979 - val_loss: 0.8636 - val_accuracy: 0.8337\n","Epoch 39/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7447 - accuracy: 0.8979 - val_loss: 0.8615 - val_accuracy: 0.8326\n","Epoch 40/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7395 - accuracy: 0.8982 - val_loss: 0.8715 - val_accuracy: 0.8326\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7366 - accuracy: 0.8974 - val_loss: 0.8620 - val_accuracy: 0.8223\n","Epoch 42/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7309 - accuracy: 0.8990 - val_loss: 0.8597 - val_accuracy: 0.8306\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7295 - accuracy: 0.8943 - val_loss: 0.8526 - val_accuracy: 0.8347\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7274 - accuracy: 0.8961 - val_loss: 0.8748 - val_accuracy: 0.8357\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7300 - accuracy: 0.8930 - val_loss: 0.8493 - val_accuracy: 0.8316\n","Epoch 46/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7183 - accuracy: 0.9000 - val_loss: 0.8469 - val_accuracy: 0.8316\n","Epoch 47/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7153 - accuracy: 0.9039 - val_loss: 0.8449 - val_accuracy: 0.8378\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7066 - accuracy: 0.9065 - val_loss: 0.8516 - val_accuracy: 0.8264\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7029 - accuracy: 0.9083 - val_loss: 0.8446 - val_accuracy: 0.8337\n","Epoch 50/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7094 - accuracy: 0.9010 - val_loss: 0.8431 - val_accuracy: 0.8316\n","Epoch 51/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6979 - accuracy: 0.9085 - val_loss: 0.8451 - val_accuracy: 0.8368\n","Epoch 52/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6933 - accuracy: 0.9059 - val_loss: 0.8373 - val_accuracy: 0.8357\n","Epoch 53/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6946 - accuracy: 0.9059 - val_loss: 0.8423 - val_accuracy: 0.8326\n","Epoch 54/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6924 - accuracy: 0.9049 - val_loss: 0.8453 - val_accuracy: 0.8233\n","Epoch 55/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6877 - accuracy: 0.9057 - val_loss: 0.8341 - val_accuracy: 0.8378\n","Epoch 56/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6783 - accuracy: 0.9109 - val_loss: 0.8320 - val_accuracy: 0.8409\n","Epoch 57/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6737 - accuracy: 0.9134 - val_loss: 0.8572 - val_accuracy: 0.8233\n","Epoch 58/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6771 - accuracy: 0.9070 - val_loss: 0.8313 - val_accuracy: 0.8388\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6713 - accuracy: 0.9111 - val_loss: 0.8487 - val_accuracy: 0.8409\n","Epoch 60/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6692 - accuracy: 0.9039 - val_loss: 0.8437 - val_accuracy: 0.8378\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6631 - accuracy: 0.9111 - val_loss: 0.8491 - val_accuracy: 0.8182\n","Epoch 62/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6541 - accuracy: 0.9163 - val_loss: 0.8286 - val_accuracy: 0.8399\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6461 - accuracy: 0.9235 - val_loss: 0.8283 - val_accuracy: 0.8347\n","Epoch 64/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6481 - accuracy: 0.9137 - val_loss: 0.8319 - val_accuracy: 0.8409\n","Epoch 65/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6474 - accuracy: 0.9173 - val_loss: 0.8415 - val_accuracy: 0.8316\n","Epoch 66/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6420 - accuracy: 0.9163 - val_loss: 0.8298 - val_accuracy: 0.8275\n","Epoch 67/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6397 - accuracy: 0.9173 - val_loss: 0.8337 - val_accuracy: 0.8285\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6384 - accuracy: 0.9233 - val_loss: 0.8693 - val_accuracy: 0.8192\n","Epoch 69/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6422 - accuracy: 0.9155 - val_loss: 0.8274 - val_accuracy: 0.8368\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6316 - accuracy: 0.9207 - val_loss: 0.8234 - val_accuracy: 0.8306\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6332 - accuracy: 0.9196 - val_loss: 0.8456 - val_accuracy: 0.8295\n","Epoch 72/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6215 - accuracy: 0.9196 - val_loss: 0.8212 - val_accuracy: 0.8316\n","Epoch 73/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6137 - accuracy: 0.9310 - val_loss: 0.8392 - val_accuracy: 0.8223\n","Epoch 74/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6226 - accuracy: 0.9217 - val_loss: 0.8318 - val_accuracy: 0.8275\n","Epoch 75/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6127 - accuracy: 0.9209 - val_loss: 0.8227 - val_accuracy: 0.8378\n","Epoch 76/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6261 - accuracy: 0.9132 - val_loss: 0.8349 - val_accuracy: 0.8326\n","Epoch 77/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6338 - accuracy: 0.9129 - val_loss: 0.8277 - val_accuracy: 0.8326\n","Epoch 78/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6085 - accuracy: 0.9253 - val_loss: 0.8179 - val_accuracy: 0.8275\n","Epoch 79/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6026 - accuracy: 0.9258 - val_loss: 0.8300 - val_accuracy: 0.8306\n","Epoch 80/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6013 - accuracy: 0.9282 - val_loss: 0.8222 - val_accuracy: 0.8357\n","Epoch 81/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5924 - accuracy: 0.9287 - val_loss: 0.8233 - val_accuracy: 0.8275\n","Epoch 82/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5898 - accuracy: 0.9287 - val_loss: 0.8243 - val_accuracy: 0.8326\n","Epoch 83/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5958 - accuracy: 0.9261 - val_loss: 0.8229 - val_accuracy: 0.8347\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5803 - accuracy: 0.9349 - val_loss: 0.8224 - val_accuracy: 0.8275\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5817 - accuracy: 0.9359 - val_loss: 0.8236 - val_accuracy: 0.8275\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5849 - accuracy: 0.9297 - val_loss: 0.8267 - val_accuracy: 0.8306\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5774 - accuracy: 0.9346 - val_loss: 0.8263 - val_accuracy: 0.8264\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5741 - accuracy: 0.9313 - val_loss: 0.8285 - val_accuracy: 0.8357\n","Epoch 89/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5704 - accuracy: 0.9385 - val_loss: 0.8391 - val_accuracy: 0.8223\n","Epoch 90/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5784 - accuracy: 0.9279 - val_loss: 0.8289 - val_accuracy: 0.8337\n","Epoch 91/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5586 - accuracy: 0.9411 - val_loss: 0.8247 - val_accuracy: 0.8337\n","Epoch 92/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5652 - accuracy: 0.9328 - val_loss: 0.8286 - val_accuracy: 0.8254\n","Epoch 93/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5623 - accuracy: 0.9339 - val_loss: 0.8299 - val_accuracy: 0.8275\n","Epoch 94/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5598 - accuracy: 0.9370 - val_loss: 0.8505 - val_accuracy: 0.8244\n","Epoch 95/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5680 - accuracy: 0.9333 - val_loss: 0.8261 - val_accuracy: 0.8295\n","Epoch 96/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5528 - accuracy: 0.9370 - val_loss: 0.8257 - val_accuracy: 0.8306\n","Epoch 97/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5447 - accuracy: 0.9403 - val_loss: 0.8393 - val_accuracy: 0.8285\n","Epoch 98/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5465 - accuracy: 0.9382 - val_loss: 0.8415 - val_accuracy: 0.8233\n","Epoch 99/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5438 - accuracy: 0.9424 - val_loss: 0.8282 - val_accuracy: 0.8326\n","Epoch 100/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5411 - accuracy: 0.9377 - val_loss: 0.8330 - val_accuracy: 0.8275\n","{'loss': [0.9510941505432129, 0.9423789978027344, 0.9323309659957886, 0.9222477674484253, 0.9168762564659119, 0.9049319624900818, 0.9063717126846313, 0.8971210718154907, 0.8872550129890442, 0.8827096819877625, 0.8835582137107849, 0.8756853938102722, 0.872487485408783, 0.8625411987304688, 0.8526939153671265, 0.8486040830612183, 0.8530909419059753, 0.841478168964386, 0.8322392702102661, 0.8298143148422241, 0.8180388808250427, 0.8212320804595947, 0.8141145706176758, 0.8120986223220825, 0.808110773563385, 0.7991439700126648, 0.7987633943557739, 0.7836098074913025, 0.7953088879585266, 0.7755826115608215, 0.7710102796554565, 0.7754606604576111, 0.7777707576751709, 0.7655591368675232, 0.7641023993492126, 0.7588120698928833, 0.7571035623550415, 0.7478506565093994, 0.744745671749115, 0.7395432591438293, 0.7365952730178833, 0.7308573126792908, 0.7295435667037964, 0.7273964881896973, 0.730044960975647, 0.718325674533844, 0.715320348739624, 0.7066117525100708, 0.702886164188385, 0.7093505263328552, 0.6979066729545593, 0.6933100819587708, 0.6945896744728088, 0.6924217343330383, 0.6876862049102783, 0.6783347129821777, 0.6737103462219238, 0.6771243214607239, 0.6712672710418701, 0.6692074537277222, 0.6631250977516174, 0.6540921330451965, 0.6461479067802429, 0.6481141448020935, 0.6474035382270813, 0.6420444846153259, 0.6396929025650024, 0.6383746266365051, 0.6422380805015564, 0.6316015124320984, 0.6332387328147888, 0.6215314269065857, 0.6136758923530579, 0.6225885152816772, 0.6127346158027649, 0.626108705997467, 0.6337586641311646, 0.608549952507019, 0.6025609970092773, 0.6013178825378418, 0.5923842191696167, 0.5898350477218628, 0.5958446860313416, 0.5803282856941223, 0.5816760659217834, 0.5848706960678101, 0.5774292945861816, 0.5740960836410522, 0.5704029202461243, 0.5783759355545044, 0.5585814118385315, 0.5651618242263794, 0.562308669090271, 0.5597811937332153, 0.567996621131897, 0.5527886748313904, 0.5446702837944031, 0.546463131904602, 0.5437682867050171, 0.5411480665206909], 'accuracy': [0.8542635440826416, 0.8576227426528931, 0.8586563467979431, 0.8602067232131958, 0.8589147329330444, 0.8645994663238525, 0.8602067232131958, 0.8633074760437012, 0.8635658621788025, 0.8726097941398621, 0.8666666746139526, 0.8661498427391052, 0.8664082884788513, 0.8713178038597107, 0.8749353885650635, 0.8739017844200134, 0.8726097941398621, 0.8751937747001648, 0.8819121718406677, 0.8803617358207703, 0.8875969052314758, 0.8816537261009216, 0.881136953830719, 0.880103349685669, 0.8857881426811218, 0.8870801329612732, 0.8852713108062744, 0.8878552913665771, 0.882170557975769, 0.89250648021698, 0.896124005317688, 0.8875969052314758, 0.8881136775016785, 0.8914728760719299, 0.8883720636367798, 0.8935400247573853, 0.8896640539169312, 0.8979328274726868, 0.8979328274726868, 0.8981912136077881, 0.8974159955978394, 0.8989664316177368, 0.894315242767334, 0.896124005317688, 0.8930232524871826, 0.8999999761581421, 0.9038759469985962, 0.9064599275588989, 0.9082687497138977, 0.9010335803031921, 0.908527135848999, 0.9059431552886963, 0.9059431552886963, 0.9049095511436462, 0.905684769153595, 0.9108527302742004, 0.9134367108345032, 0.9069767594337463, 0.9111111164093018, 0.9038759469985962, 0.9111111164093018, 0.9162790775299072, 0.923514187335968, 0.9136950969696045, 0.9173126816749573, 0.9162790775299072, 0.9173126816749573, 0.9232558012008667, 0.9155038595199585, 0.920671820640564, 0.9196382164955139, 0.9196382164955139, 0.9310077428817749, 0.921705424785614, 0.9209302067756653, 0.9131782650947571, 0.9129198789596558, 0.9253230094909668, 0.9258397817611694, 0.9281653761863708, 0.9286821484565735, 0.9286821484565735, 0.9260981678962708, 0.934883713722229, 0.935917317867279, 0.9297157526016235, 0.9346253275871277, 0.9312661290168762, 0.9385012984275818, 0.9279069900512695, 0.9410852789878845, 0.9328165650367737, 0.933850109577179, 0.9369509220123291, 0.9333333373069763, 0.9369509220123291, 0.9403100609779358, 0.9382429122924805, 0.9423772692680359, 0.9377260804176331], 'val_loss': [1.2547346353530884, 1.2435377836227417, 1.234228253364563, 1.2209044694900513, 1.2093095779418945, 1.1982828378677368, 1.1875865459442139, 1.166157603263855, 1.1457103490829468, 1.1360859870910645, 1.10953688621521, 1.077258586883545, 1.0746662616729736, 1.0508488416671753, 1.0170767307281494, 1.0025185346603394, 0.9624730348587036, 0.9495353102684021, 0.9261366724967957, 0.9379727244377136, 0.8985657095909119, 0.9015784859657288, 0.8885519504547119, 0.8863519430160522, 0.8881828188896179, 0.8829036355018616, 0.8807854652404785, 0.8830590844154358, 0.8878472447395325, 0.8841704726219177, 0.8743010759353638, 0.8925963044166565, 0.8700259923934937, 0.8752472996711731, 0.8743444681167603, 0.8642563223838806, 0.8672115206718445, 0.86360764503479, 0.8615215420722961, 0.8715187311172485, 0.8619681000709534, 0.8596723675727844, 0.8525525331497192, 0.8747789263725281, 0.8493163585662842, 0.8469179272651672, 0.8448836803436279, 0.851590096950531, 0.8445503115653992, 0.8431277871131897, 0.8450843691825867, 0.8373180031776428, 0.8423144817352295, 0.8452693223953247, 0.8341498970985413, 0.8320295810699463, 0.8571552038192749, 0.8313191533088684, 0.848702609539032, 0.8436964154243469, 0.8490523099899292, 0.828593909740448, 0.8283335566520691, 0.8319013714790344, 0.8415451645851135, 0.8298137784004211, 0.8337377905845642, 0.869335949420929, 0.8273564577102661, 0.8233520984649658, 0.8455982804298401, 0.821155309677124, 0.8392357230186462, 0.8317744135856628, 0.8227379322052002, 0.8348981738090515, 0.8276905417442322, 0.8179411888122559, 0.8300461769104004, 0.8221555352210999, 0.8232680559158325, 0.8243319988250732, 0.822947084903717, 0.8224087953567505, 0.8236243724822998, 0.826654851436615, 0.8263070583343506, 0.8284619450569153, 0.8391289114952087, 0.828930675983429, 0.8246549367904663, 0.8285508155822754, 0.8298875689506531, 0.8505377173423767, 0.826097846031189, 0.8256929516792297, 0.8392754793167114, 0.8415470719337463, 0.8281710147857666, 0.8329513669013977], 'val_accuracy': [0.7809917330741882, 0.7613636255264282, 0.7469007968902588, 0.7758264541625977, 0.7830578684806824, 0.7190082669258118, 0.6900826692581177, 0.7634297609329224, 0.7654958963394165, 0.7221074104309082, 0.7634297609329224, 0.8026859760284424, 0.7572314143180847, 0.7747933864593506, 0.797520637512207, 0.7923553586006165, 0.827479362487793, 0.8192148804664612, 0.8336777091026306, 0.8130165338516235, 0.8326446413993835, 0.8347107172012329, 0.8347107172012329, 0.8295454382896423, 0.8316115736961365, 0.8305785059928894, 0.8316115736961365, 0.8223140239715576, 0.8419421315193176, 0.8212810158729553, 0.83574378490448, 0.8378099203109741, 0.83574378490448, 0.83574378490448, 0.8378099203109741, 0.83574378490448, 0.836776852607727, 0.8336777091026306, 0.8326446413993835, 0.8326446413993835, 0.8223140239715576, 0.8305785059928894, 0.8347107172012329, 0.83574378490448, 0.8316115736961365, 0.8316115736961365, 0.8378099203109741, 0.8264462947845459, 0.8336777091026306, 0.8316115736961365, 0.836776852607727, 0.83574378490448, 0.8326446413993835, 0.8233470916748047, 0.8378099203109741, 0.8409090638160706, 0.8233470916748047, 0.8388429880142212, 0.8409090638160706, 0.8378099203109741, 0.8181818127632141, 0.8398760557174683, 0.8347107172012329, 0.8409090638160706, 0.8316115736961365, 0.827479362487793, 0.8285123705863953, 0.8192148804664612, 0.836776852607727, 0.8305785059928894, 0.8295454382896423, 0.8316115736961365, 0.8223140239715576, 0.827479362487793, 0.8378099203109741, 0.8326446413993835, 0.8326446413993835, 0.827479362487793, 0.8305785059928894, 0.83574378490448, 0.827479362487793, 0.8326446413993835, 0.8347107172012329, 0.827479362487793, 0.827479362487793, 0.8305785059928894, 0.8264462947845459, 0.83574378490448, 0.8223140239715576, 0.8336777091026306, 0.8336777091026306, 0.8254132270812988, 0.827479362487793, 0.8243801593780518, 0.8295454382896423, 0.8305785059928894, 0.8285123705863953, 0.8233470916748047, 0.8326446413993835, 0.827479362487793]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.6173 - accuracy: 0.9102"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 6s 56ms/step - loss: 0.6175 - accuracy: 0.9098 - val_loss: 1.0515 - val_accuracy: 0.5668\n","Epoch 2/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6035 - accuracy: 0.9157 - val_loss: 1.0439 - val_accuracy: 0.5819\n","Epoch 3/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5918 - accuracy: 0.9213 - val_loss: 1.0412 - val_accuracy: 0.5463\n","Epoch 4/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5909 - accuracy: 0.9189 - val_loss: 1.0334 - val_accuracy: 0.5474\n","Epoch 5/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5942 - accuracy: 0.9176 - val_loss: 1.0409 - val_accuracy: 0.5140\n","Epoch 6/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6008 - accuracy: 0.9176 - val_loss: 1.0120 - val_accuracy: 0.5776\n","Epoch 7/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5847 - accuracy: 0.9232 - val_loss: 1.0229 - val_accuracy: 0.5323\n","Epoch 8/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5754 - accuracy: 0.9230 - val_loss: 1.0236 - val_accuracy: 0.5259\n","Epoch 9/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5656 - accuracy: 0.9275 - val_loss: 1.0203 - val_accuracy: 0.5323\n","Epoch 10/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5695 - accuracy: 0.9267 - val_loss: 1.0119 - val_accuracy: 0.5528\n","Epoch 11/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5664 - accuracy: 0.9283 - val_loss: 1.0591 - val_accuracy: 0.5237\n","Epoch 12/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5619 - accuracy: 0.9291 - val_loss: 1.0252 - val_accuracy: 0.5571\n","Epoch 13/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.5521 - accuracy: 0.9305 - val_loss: 0.9578 - val_accuracy: 0.6099\n","Epoch 14/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5570 - accuracy: 0.9340 - val_loss: 1.0033 - val_accuracy: 0.5884\n","Epoch 15/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5479 - accuracy: 0.9378 - val_loss: 1.0608 - val_accuracy: 0.5765\n","Epoch 16/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5386 - accuracy: 0.9394 - val_loss: 0.9506 - val_accuracy: 0.6519\n","Epoch 17/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5411 - accuracy: 0.9362 - val_loss: 0.8864 - val_accuracy: 0.7112\n","Epoch 18/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5410 - accuracy: 0.9386 - val_loss: 0.9041 - val_accuracy: 0.7026\n","Epoch 19/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5339 - accuracy: 0.9388 - val_loss: 1.0283 - val_accuracy: 0.6595\n","Epoch 20/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5351 - accuracy: 0.9359 - val_loss: 0.8334 - val_accuracy: 0.7672\n","Epoch 21/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5229 - accuracy: 0.9437 - val_loss: 0.7629 - val_accuracy: 0.8147\n","Epoch 22/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5431 - accuracy: 0.9367 - val_loss: 0.7883 - val_accuracy: 0.8082\n","Epoch 23/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5458 - accuracy: 0.9313 - val_loss: 0.8996 - val_accuracy: 0.7532\n","Epoch 24/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5197 - accuracy: 0.9453 - val_loss: 0.7445 - val_accuracy: 0.8244\n","Epoch 25/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.5158 - accuracy: 0.9469 - val_loss: 0.7201 - val_accuracy: 0.8448\n","Epoch 26/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5154 - accuracy: 0.9405 - val_loss: 0.7449 - val_accuracy: 0.8341\n","Epoch 27/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5190 - accuracy: 0.9426 - val_loss: 0.7255 - val_accuracy: 0.8438\n","Epoch 28/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5088 - accuracy: 0.9475 - val_loss: 0.7005 - val_accuracy: 0.8578\n","Epoch 29/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5039 - accuracy: 0.9475 - val_loss: 0.6888 - val_accuracy: 0.8599\n","Epoch 30/100\n","29/29 [==============================] - 1s 39ms/step - loss: 0.4986 - accuracy: 0.9515 - val_loss: 0.6919 - val_accuracy: 0.8621\n","Epoch 31/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5013 - accuracy: 0.9469 - val_loss: 0.6935 - val_accuracy: 0.8610\n","Epoch 32/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4984 - accuracy: 0.9526 - val_loss: 0.7014 - val_accuracy: 0.8621\n","Epoch 33/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.5079 - accuracy: 0.9429 - val_loss: 0.6936 - val_accuracy: 0.8664\n","Epoch 34/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4954 - accuracy: 0.9483 - val_loss: 0.7140 - val_accuracy: 0.8599\n","Epoch 35/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.4876 - accuracy: 0.9537 - val_loss: 0.6882 - val_accuracy: 0.8718\n","Epoch 36/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4903 - accuracy: 0.9537 - val_loss: 0.7040 - val_accuracy: 0.8653\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4902 - accuracy: 0.9518 - val_loss: 0.6973 - val_accuracy: 0.8707\n","Epoch 38/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4816 - accuracy: 0.9539 - val_loss: 0.7013 - val_accuracy: 0.8707\n","Epoch 39/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4775 - accuracy: 0.9558 - val_loss: 0.7018 - val_accuracy: 0.8631\n","Epoch 40/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4802 - accuracy: 0.9550 - val_loss: 0.7022 - val_accuracy: 0.8642\n","Epoch 41/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4808 - accuracy: 0.9510 - val_loss: 0.7000 - val_accuracy: 0.8685\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4818 - accuracy: 0.9526 - val_loss: 0.6943 - val_accuracy: 0.8718\n","Epoch 43/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4667 - accuracy: 0.9617 - val_loss: 0.7017 - val_accuracy: 0.8621\n","Epoch 44/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4915 - accuracy: 0.9456 - val_loss: 0.7224 - val_accuracy: 0.8534\n","Epoch 45/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4983 - accuracy: 0.9405 - val_loss: 0.7116 - val_accuracy: 0.8578\n","Epoch 46/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4677 - accuracy: 0.9585 - val_loss: 0.6986 - val_accuracy: 0.8728\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4757 - accuracy: 0.9507 - val_loss: 0.6952 - val_accuracy: 0.8675\n","Epoch 48/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4571 - accuracy: 0.9617 - val_loss: 0.6930 - val_accuracy: 0.8664\n","Epoch 49/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4612 - accuracy: 0.9623 - val_loss: 0.7109 - val_accuracy: 0.8707\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4527 - accuracy: 0.9626 - val_loss: 0.7066 - val_accuracy: 0.8675\n","Epoch 51/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4489 - accuracy: 0.9639 - val_loss: 0.7191 - val_accuracy: 0.8588\n","Epoch 52/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4489 - accuracy: 0.9647 - val_loss: 0.7332 - val_accuracy: 0.8556\n","Epoch 53/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4565 - accuracy: 0.9596 - val_loss: 0.7179 - val_accuracy: 0.8728\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4579 - accuracy: 0.9588 - val_loss: 0.7085 - val_accuracy: 0.8664\n","Epoch 55/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4606 - accuracy: 0.9574 - val_loss: 0.8203 - val_accuracy: 0.8373\n","Epoch 56/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4488 - accuracy: 0.9628 - val_loss: 0.7110 - val_accuracy: 0.8621\n","Epoch 57/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4401 - accuracy: 0.9663 - val_loss: 0.7250 - val_accuracy: 0.8621\n","Epoch 58/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4416 - accuracy: 0.9666 - val_loss: 0.7072 - val_accuracy: 0.8675\n","Epoch 59/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4364 - accuracy: 0.9639 - val_loss: 0.7151 - val_accuracy: 0.8599\n","Epoch 60/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4352 - accuracy: 0.9693 - val_loss: 0.7086 - val_accuracy: 0.8621\n","Epoch 61/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4295 - accuracy: 0.9693 - val_loss: 0.7815 - val_accuracy: 0.8513\n","Epoch 62/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4263 - accuracy: 0.9682 - val_loss: 0.7315 - val_accuracy: 0.8578\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4248 - accuracy: 0.9706 - val_loss: 0.7383 - val_accuracy: 0.8621\n","Epoch 64/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4311 - accuracy: 0.9655 - val_loss: 0.7598 - val_accuracy: 0.8545\n","Epoch 65/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4342 - accuracy: 0.9642 - val_loss: 0.7290 - val_accuracy: 0.8599\n","Epoch 66/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4295 - accuracy: 0.9650 - val_loss: 0.7563 - val_accuracy: 0.8588\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4164 - accuracy: 0.9723 - val_loss: 0.7301 - val_accuracy: 0.8642\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4192 - accuracy: 0.9717 - val_loss: 0.7266 - val_accuracy: 0.8653\n","Epoch 69/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4122 - accuracy: 0.9725 - val_loss: 0.7480 - val_accuracy: 0.8588\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4183 - accuracy: 0.9688 - val_loss: 0.7286 - val_accuracy: 0.8588\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4167 - accuracy: 0.9698 - val_loss: 0.7326 - val_accuracy: 0.8567\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4195 - accuracy: 0.9677 - val_loss: 0.7847 - val_accuracy: 0.8556\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4148 - accuracy: 0.9736 - val_loss: 0.7427 - val_accuracy: 0.8578\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4061 - accuracy: 0.9779 - val_loss: 0.7365 - val_accuracy: 0.8642\n","Epoch 75/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4098 - accuracy: 0.9712 - val_loss: 0.7325 - val_accuracy: 0.8599\n","Epoch 76/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4034 - accuracy: 0.9763 - val_loss: 0.7313 - val_accuracy: 0.8675\n","Epoch 77/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4192 - accuracy: 0.9674 - val_loss: 0.8515 - val_accuracy: 0.8427\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4075 - accuracy: 0.9739 - val_loss: 0.7562 - val_accuracy: 0.8567\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4047 - accuracy: 0.9766 - val_loss: 0.7255 - val_accuracy: 0.8675\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3976 - accuracy: 0.9779 - val_loss: 0.7434 - val_accuracy: 0.8578\n","Epoch 81/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3933 - accuracy: 0.9774 - val_loss: 0.7266 - val_accuracy: 0.8696\n","Epoch 82/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3967 - accuracy: 0.9763 - val_loss: 0.7319 - val_accuracy: 0.8642\n","Epoch 83/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3928 - accuracy: 0.9771 - val_loss: 0.7299 - val_accuracy: 0.8664\n","Epoch 84/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4002 - accuracy: 0.9731 - val_loss: 0.8248 - val_accuracy: 0.8438\n","Epoch 85/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3967 - accuracy: 0.9733 - val_loss: 0.8392 - val_accuracy: 0.8459\n","Epoch 86/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3969 - accuracy: 0.9758 - val_loss: 0.7772 - val_accuracy: 0.8610\n","Epoch 87/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3988 - accuracy: 0.9706 - val_loss: 0.7453 - val_accuracy: 0.8642\n","Epoch 88/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3918 - accuracy: 0.9771 - val_loss: 0.7559 - val_accuracy: 0.8610\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3818 - accuracy: 0.9784 - val_loss: 0.7507 - val_accuracy: 0.8675\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3783 - accuracy: 0.9814 - val_loss: 0.7491 - val_accuracy: 0.8621\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3788 - accuracy: 0.9820 - val_loss: 0.7391 - val_accuracy: 0.8642\n","Epoch 92/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3871 - accuracy: 0.9779 - val_loss: 0.7822 - val_accuracy: 0.8534\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3915 - accuracy: 0.9774 - val_loss: 0.7693 - val_accuracy: 0.8621\n","Epoch 94/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3855 - accuracy: 0.9768 - val_loss: 0.7693 - val_accuracy: 0.8610\n","Epoch 95/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3832 - accuracy: 0.9766 - val_loss: 0.7950 - val_accuracy: 0.8534\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3832 - accuracy: 0.9760 - val_loss: 0.7570 - val_accuracy: 0.8621\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3804 - accuracy: 0.9779 - val_loss: 0.7511 - val_accuracy: 0.8621\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3740 - accuracy: 0.9803 - val_loss: 0.7805 - val_accuracy: 0.8578\n","Epoch 99/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3754 - accuracy: 0.9784 - val_loss: 0.7622 - val_accuracy: 0.8642\n","Epoch 100/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3699 - accuracy: 0.9828 - val_loss: 0.7592 - val_accuracy: 0.8653\n","{'loss': [0.6175161004066467, 0.603487491607666, 0.5917906165122986, 0.590915322303772, 0.5942171216011047, 0.6008325219154358, 0.5847172141075134, 0.57539302110672, 0.5656195282936096, 0.5695310235023499, 0.5663548111915588, 0.5618889927864075, 0.5520602464675903, 0.5569968819618225, 0.547948956489563, 0.5386175513267517, 0.5411277413368225, 0.5409877896308899, 0.5339108109474182, 0.535072922706604, 0.52294921875, 0.5430732369422913, 0.5458412766456604, 0.5197012424468994, 0.5158456563949585, 0.5153884291648865, 0.5189757347106934, 0.5087724328041077, 0.5038719773292542, 0.4985657036304474, 0.5012567639350891, 0.4983654022216797, 0.5078717470169067, 0.495383083820343, 0.4875791370868683, 0.49032461643218994, 0.49019455909729004, 0.48157989978790283, 0.47752130031585693, 0.48021256923675537, 0.48076575994491577, 0.48180529475212097, 0.4667329490184784, 0.4914955198764801, 0.4983457028865814, 0.4677470624446869, 0.4756714999675751, 0.457081139087677, 0.46117961406707764, 0.4527256190776825, 0.44885438680648804, 0.4489050805568695, 0.4565039575099945, 0.4579411745071411, 0.4606081247329712, 0.4488474428653717, 0.44014155864715576, 0.44159945845603943, 0.43642765283584595, 0.4352213144302368, 0.42952805757522583, 0.42629802227020264, 0.4248466193675995, 0.43111738562583923, 0.4341754615306854, 0.4294784665107727, 0.41643384099006653, 0.4192450940608978, 0.4121761918067932, 0.4182591140270233, 0.41672369837760925, 0.4194848835468292, 0.4147941768169403, 0.40614986419677734, 0.4097508192062378, 0.40338173508644104, 0.4191596508026123, 0.40754759311676025, 0.4046809673309326, 0.39755958318710327, 0.3933127820491791, 0.39667364954948425, 0.3928222060203552, 0.4001953899860382, 0.3967439830303192, 0.39689263701438904, 0.3988172709941864, 0.39175862073898315, 0.3818404972553253, 0.3782913386821747, 0.378843754529953, 0.38714128732681274, 0.39150261878967285, 0.3854904770851135, 0.3831833600997925, 0.3832169771194458, 0.3803660273551941, 0.37395861744880676, 0.37535637617111206, 0.3699284493923187], 'accuracy': [0.9097521305084229, 0.915678858757019, 0.9213362336158752, 0.9189116358757019, 0.9175646305084229, 0.9175646305084229, 0.923222005367279, 0.9229525923728943, 0.9275323152542114, 0.9267241358757019, 0.928340494632721, 0.9291487336158752, 0.9304956793785095, 0.9339978694915771, 0.9377694129943848, 0.9393857717514038, 0.936152994632721, 0.9385775923728943, 0.938847005367279, 0.935883641242981, 0.943696141242981, 0.9366918206214905, 0.931303858757019, 0.9453125, 0.946928858757019, 0.9404633641242981, 0.9426185488700867, 0.9474676847457886, 0.9474676847457886, 0.951508641242981, 0.946928858757019, 0.9525862336158752, 0.9428879022598267, 0.9482758641242981, 0.9536637663841248, 0.9536637663841248, 0.951777994632721, 0.9539331793785095, 0.9558189511299133, 0.9550107717514038, 0.9509698152542114, 0.9525862336158752, 0.9617456793785095, 0.9455819129943848, 0.9404633641242981, 0.9585129022598267, 0.9507004022598267, 0.9617456793785095, 0.962284505367279, 0.962553858757019, 0.9639008641242981, 0.9647090435028076, 0.959590494632721, 0.9587823152542114, 0.9574353694915771, 0.9628232717514038, 0.9663254022598267, 0.9665948152542114, 0.9639008641242981, 0.9692887663841248, 0.9692887663841248, 0.9682112336158752, 0.9706357717514038, 0.9655172228813171, 0.9641702771186829, 0.9649784564971924, 0.9722521305084229, 0.9717133641242981, 0.9725215435028076, 0.96875, 0.9698275923728943, 0.9676724076271057, 0.9735991358757019, 0.977909505367279, 0.9711745977401733, 0.9762930870056152, 0.967402994632721, 0.9738685488700867, 0.9765625, 0.977909505367279, 0.9773706793785095, 0.9762930870056152, 0.9771012663841248, 0.9730603694915771, 0.9733297228813171, 0.9757543206214905, 0.9706357717514038, 0.9771012663841248, 0.9784482717514038, 0.9814116358757019, 0.9819504022598267, 0.977909505367279, 0.9773706793785095, 0.9768319129943848, 0.9765625, 0.9760237336158752, 0.977909505367279, 0.9803340435028076, 0.9784482717514038, 0.982758641242981], 'val_loss': [1.051485538482666, 1.043903112411499, 1.0411946773529053, 1.033389687538147, 1.0408923625946045, 1.011966347694397, 1.0228722095489502, 1.0235720872879028, 1.0203148126602173, 1.0119494199752808, 1.059129238128662, 1.0252068042755127, 0.9578143358230591, 1.0032765865325928, 1.060761570930481, 0.9505898952484131, 0.8864067196846008, 0.9041470289230347, 1.0283429622650146, 0.8334343433380127, 0.7628521919250488, 0.7883318066596985, 0.8996365070343018, 0.7445388436317444, 0.720130980014801, 0.7448509931564331, 0.7254551649093628, 0.7005323767662048, 0.688785970211029, 0.6919283866882324, 0.6935402154922485, 0.701363205909729, 0.6935855746269226, 0.7139695882797241, 0.6882175207138062, 0.7039597630500793, 0.6972606182098389, 0.7012823224067688, 0.7018392086029053, 0.702207624912262, 0.6999983191490173, 0.6943469047546387, 0.7017489075660706, 0.7223707437515259, 0.7115670442581177, 0.6985568404197693, 0.6951643824577332, 0.692992627620697, 0.710858941078186, 0.7065728306770325, 0.7190660834312439, 0.7331749200820923, 0.7178863883018494, 0.7084878087043762, 0.8203316330909729, 0.7110317945480347, 0.7249544858932495, 0.7071584463119507, 0.7150656580924988, 0.7086463570594788, 0.7815400958061218, 0.7314927577972412, 0.7383241057395935, 0.7597810626029968, 0.7289551496505737, 0.756323516368866, 0.7300770282745361, 0.7266266942024231, 0.7479503750801086, 0.7285986542701721, 0.7326471209526062, 0.7847416996955872, 0.742680013179779, 0.7365061640739441, 0.73247230052948, 0.7312583923339844, 0.8514514565467834, 0.7562099695205688, 0.7254981398582458, 0.7434396147727966, 0.7265961766242981, 0.7319023609161377, 0.7298826575279236, 0.8248006105422974, 0.8391565680503845, 0.7772202491760254, 0.7453038692474365, 0.7558795213699341, 0.7506799101829529, 0.7491306662559509, 0.7390594482421875, 0.7822144627571106, 0.7692981362342834, 0.7692992091178894, 0.795045793056488, 0.757030725479126, 0.7510662078857422, 0.7804798483848572, 0.7621932625770569, 0.7591610550880432], 'val_accuracy': [0.5668103694915771, 0.5818965435028076, 0.5463362336158752, 0.5474137663841248, 0.514008641242981, 0.5775862336158752, 0.5323275923728943, 0.5258620977401733, 0.5323275923728943, 0.5528017282485962, 0.5237069129943848, 0.5571120977401733, 0.6099137663841248, 0.5883620977401733, 0.576508641242981, 0.6519396305084229, 0.7112069129943848, 0.7025862336158752, 0.6594827771186829, 0.767241358757019, 0.8146551847457886, 0.8081896305084229, 0.7532327771186829, 0.8243534564971924, 0.8448275923728943, 0.8340517282485962, 0.84375, 0.857758641242981, 0.8599137663841248, 0.8620689511299133, 0.860991358757019, 0.8620689511299133, 0.8663793206214905, 0.8599137663841248, 0.8717672228813171, 0.8653017282485962, 0.8706896305084229, 0.8706896305084229, 0.8631465435028076, 0.8642241358757019, 0.868534505367279, 0.8717672228813171, 0.8620689511299133, 0.8534482717514038, 0.857758641242981, 0.8728448152542114, 0.8674569129943848, 0.8663793206214905, 0.8706896305084229, 0.8674569129943848, 0.8588362336158752, 0.8556034564971924, 0.8728448152542114, 0.8663793206214905, 0.837284505367279, 0.8620689511299133, 0.8620689511299133, 0.8674569129943848, 0.8599137663841248, 0.8620689511299133, 0.8512930870056152, 0.857758641242981, 0.8620689511299133, 0.8545258641242981, 0.8599137663841248, 0.8588362336158752, 0.8642241358757019, 0.8653017282485962, 0.8588362336158752, 0.8588362336158752, 0.8566810488700867, 0.8556034564971924, 0.857758641242981, 0.8642241358757019, 0.8599137663841248, 0.8674569129943848, 0.8426724076271057, 0.8566810488700867, 0.8674569129943848, 0.857758641242981, 0.8696120977401733, 0.8642241358757019, 0.8663793206214905, 0.84375, 0.8459051847457886, 0.860991358757019, 0.8642241358757019, 0.860991358757019, 0.8674569129943848, 0.8620689511299133, 0.8642241358757019, 0.8534482717514038, 0.8620689511299133, 0.860991358757019, 0.8534482717514038, 0.8620689511299133, 0.8620689511299133, 0.857758641242981, 0.8642241358757019, 0.8653017282485962]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.6320 - accuracy: 0.9038"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 58ms/step - loss: 0.6328 - accuracy: 0.9035 - val_loss: 1.0486 - val_accuracy: 0.6674\n","Epoch 2/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6113 - accuracy: 0.9128 - val_loss: 1.0424 - val_accuracy: 0.6143\n","Epoch 3/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6225 - accuracy: 0.9061 - val_loss: 1.0371 - val_accuracy: 0.6143\n","Epoch 4/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6009 - accuracy: 0.9205 - val_loss: 1.0386 - val_accuracy: 0.5317\n","Epoch 5/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6034 - accuracy: 0.9179 - val_loss: 1.0269 - val_accuracy: 0.5566\n","Epoch 6/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5899 - accuracy: 0.9222 - val_loss: 1.0303 - val_accuracy: 0.5271\n","Epoch 7/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5914 - accuracy: 0.9236 - val_loss: 1.0294 - val_accuracy: 0.5170\n","Epoch 8/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5839 - accuracy: 0.9191 - val_loss: 1.0207 - val_accuracy: 0.5328\n","Epoch 9/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5832 - accuracy: 0.9236 - val_loss: 1.0238 - val_accuracy: 0.5260\n","Epoch 10/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5830 - accuracy: 0.9157 - val_loss: 0.9792 - val_accuracy: 0.6120\n","Epoch 11/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5913 - accuracy: 0.9182 - val_loss: 1.0242 - val_accuracy: 0.5373\n","Epoch 12/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5767 - accuracy: 0.9211 - val_loss: 1.0017 - val_accuracy: 0.5701\n","Epoch 13/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5779 - accuracy: 0.9213 - val_loss: 1.0798 - val_accuracy: 0.5204\n","Epoch 14/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5813 - accuracy: 0.9168 - val_loss: 0.9632 - val_accuracy: 0.6301\n","Epoch 15/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5688 - accuracy: 0.9276 - val_loss: 0.9881 - val_accuracy: 0.6176\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5654 - accuracy: 0.9264 - val_loss: 0.9947 - val_accuracy: 0.6256\n","Epoch 17/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5642 - accuracy: 0.9276 - val_loss: 1.0064 - val_accuracy: 0.6301\n","Epoch 18/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5489 - accuracy: 0.9355 - val_loss: 0.9274 - val_accuracy: 0.6912\n","Epoch 19/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5519 - accuracy: 0.9315 - val_loss: 0.9893 - val_accuracy: 0.6719\n","Epoch 20/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5574 - accuracy: 0.9261 - val_loss: 0.8837 - val_accuracy: 0.7398\n","Epoch 21/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5510 - accuracy: 0.9324 - val_loss: 0.9024 - val_accuracy: 0.7364\n","Epoch 22/100\n","28/28 [==============================] - 1s 39ms/step - loss: 0.5523 - accuracy: 0.9298 - val_loss: 0.8281 - val_accuracy: 0.7783\n","Epoch 23/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5440 - accuracy: 0.9298 - val_loss: 0.8843 - val_accuracy: 0.7636\n","Epoch 24/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5443 - accuracy: 0.9338 - val_loss: 0.7297 - val_accuracy: 0.8348\n","Epoch 25/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5363 - accuracy: 0.9383 - val_loss: 0.7320 - val_accuracy: 0.8416\n","Epoch 26/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5545 - accuracy: 0.9278 - val_loss: 0.7638 - val_accuracy: 0.8224\n","Epoch 27/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.5273 - accuracy: 0.9380 - val_loss: 0.7213 - val_accuracy: 0.8484\n","Epoch 28/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.5297 - accuracy: 0.9358 - val_loss: 0.7390 - val_accuracy: 0.8518\n","Epoch 29/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5354 - accuracy: 0.9332 - val_loss: 0.7552 - val_accuracy: 0.8337\n","Epoch 30/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5307 - accuracy: 0.9346 - val_loss: 0.7250 - val_accuracy: 0.8507\n","Epoch 31/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5273 - accuracy: 0.9346 - val_loss: 0.7520 - val_accuracy: 0.8394\n","Epoch 32/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5208 - accuracy: 0.9423 - val_loss: 0.7475 - val_accuracy: 0.8484\n","Epoch 33/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5162 - accuracy: 0.9443 - val_loss: 0.7293 - val_accuracy: 0.8462\n","Epoch 34/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5220 - accuracy: 0.9400 - val_loss: 0.7316 - val_accuracy: 0.8541\n","Epoch 35/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5095 - accuracy: 0.9513 - val_loss: 0.7263 - val_accuracy: 0.8473\n","Epoch 36/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5033 - accuracy: 0.9488 - val_loss: 0.7315 - val_accuracy: 0.8484\n","Epoch 37/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5068 - accuracy: 0.9440 - val_loss: 0.7351 - val_accuracy: 0.8518\n","Epoch 38/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5137 - accuracy: 0.9394 - val_loss: 0.7397 - val_accuracy: 0.8428\n","Epoch 39/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4981 - accuracy: 0.9530 - val_loss: 0.7413 - val_accuracy: 0.8450\n","Epoch 40/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4993 - accuracy: 0.9443 - val_loss: 0.7664 - val_accuracy: 0.8394\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5001 - accuracy: 0.9474 - val_loss: 0.7354 - val_accuracy: 0.8450\n","Epoch 42/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4967 - accuracy: 0.9440 - val_loss: 0.7393 - val_accuracy: 0.8518\n","Epoch 43/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4912 - accuracy: 0.9491 - val_loss: 0.7424 - val_accuracy: 0.8439\n","Epoch 44/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4867 - accuracy: 0.9493 - val_loss: 0.7451 - val_accuracy: 0.8507\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4880 - accuracy: 0.9448 - val_loss: 0.7512 - val_accuracy: 0.8428\n","Epoch 46/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4893 - accuracy: 0.9493 - val_loss: 0.7411 - val_accuracy: 0.8439\n","Epoch 47/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4896 - accuracy: 0.9477 - val_loss: 0.7449 - val_accuracy: 0.8473\n","Epoch 48/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4786 - accuracy: 0.9522 - val_loss: 0.7521 - val_accuracy: 0.8450\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4698 - accuracy: 0.9587 - val_loss: 0.7517 - val_accuracy: 0.8428\n","Epoch 50/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4704 - accuracy: 0.9542 - val_loss: 0.7507 - val_accuracy: 0.8439\n","Epoch 51/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4749 - accuracy: 0.9519 - val_loss: 0.7479 - val_accuracy: 0.8428\n","Epoch 52/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4630 - accuracy: 0.9584 - val_loss: 0.7541 - val_accuracy: 0.8450\n","Epoch 53/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4657 - accuracy: 0.9533 - val_loss: 0.7549 - val_accuracy: 0.8541\n","Epoch 54/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4582 - accuracy: 0.9584 - val_loss: 0.7642 - val_accuracy: 0.8507\n","Epoch 55/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4813 - accuracy: 0.9462 - val_loss: 0.7711 - val_accuracy: 0.8507\n","Epoch 56/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4579 - accuracy: 0.9567 - val_loss: 0.7759 - val_accuracy: 0.8507\n","Epoch 57/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4570 - accuracy: 0.9573 - val_loss: 0.7547 - val_accuracy: 0.8541\n","Epoch 58/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4469 - accuracy: 0.9646 - val_loss: 0.8112 - val_accuracy: 0.8450\n","Epoch 59/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4627 - accuracy: 0.9519 - val_loss: 0.7683 - val_accuracy: 0.8518\n","Epoch 60/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4501 - accuracy: 0.9629 - val_loss: 0.7674 - val_accuracy: 0.8529\n","Epoch 61/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4575 - accuracy: 0.9581 - val_loss: 0.7637 - val_accuracy: 0.8507\n","Epoch 62/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4456 - accuracy: 0.9638 - val_loss: 0.7707 - val_accuracy: 0.8529\n","Epoch 63/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4500 - accuracy: 0.9618 - val_loss: 0.7793 - val_accuracy: 0.8439\n","Epoch 64/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4557 - accuracy: 0.9561 - val_loss: 0.7707 - val_accuracy: 0.8405\n","Epoch 65/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4453 - accuracy: 0.9624 - val_loss: 0.7672 - val_accuracy: 0.8394\n","Epoch 66/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4402 - accuracy: 0.9652 - val_loss: 0.7630 - val_accuracy: 0.8473\n","Epoch 67/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4379 - accuracy: 0.9632 - val_loss: 0.7697 - val_accuracy: 0.8473\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4339 - accuracy: 0.9683 - val_loss: 0.7755 - val_accuracy: 0.8473\n","Epoch 69/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4317 - accuracy: 0.9660 - val_loss: 0.7789 - val_accuracy: 0.8484\n","Epoch 70/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4324 - accuracy: 0.9643 - val_loss: 0.7744 - val_accuracy: 0.8473\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4352 - accuracy: 0.9669 - val_loss: 0.7744 - val_accuracy: 0.8450\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4248 - accuracy: 0.9723 - val_loss: 0.7781 - val_accuracy: 0.8507\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4265 - accuracy: 0.9675 - val_loss: 0.7855 - val_accuracy: 0.8450\n","Epoch 74/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4294 - accuracy: 0.9675 - val_loss: 0.7790 - val_accuracy: 0.8382\n","Epoch 75/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4184 - accuracy: 0.9714 - val_loss: 0.7772 - val_accuracy: 0.8439\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4157 - accuracy: 0.9714 - val_loss: 0.7846 - val_accuracy: 0.8439\n","Epoch 77/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4173 - accuracy: 0.9697 - val_loss: 0.7880 - val_accuracy: 0.8450\n","Epoch 78/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4220 - accuracy: 0.9680 - val_loss: 0.7958 - val_accuracy: 0.8484\n","Epoch 79/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4252 - accuracy: 0.9675 - val_loss: 0.7942 - val_accuracy: 0.8462\n","Epoch 80/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4129 - accuracy: 0.9700 - val_loss: 0.7933 - val_accuracy: 0.8462\n","Epoch 81/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4022 - accuracy: 0.9796 - val_loss: 0.7983 - val_accuracy: 0.8462\n","Epoch 82/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4078 - accuracy: 0.9717 - val_loss: 0.7865 - val_accuracy: 0.8439\n","Epoch 83/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4017 - accuracy: 0.9751 - val_loss: 0.7975 - val_accuracy: 0.8428\n","Epoch 84/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4066 - accuracy: 0.9740 - val_loss: 0.7922 - val_accuracy: 0.8450\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4090 - accuracy: 0.9734 - val_loss: 0.7903 - val_accuracy: 0.8439\n","Epoch 86/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3983 - accuracy: 0.9762 - val_loss: 0.8050 - val_accuracy: 0.8450\n","Epoch 87/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3980 - accuracy: 0.9745 - val_loss: 0.8018 - val_accuracy: 0.8462\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3996 - accuracy: 0.9748 - val_loss: 0.8044 - val_accuracy: 0.8416\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3939 - accuracy: 0.9743 - val_loss: 0.7893 - val_accuracy: 0.8428\n","Epoch 90/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3975 - accuracy: 0.9757 - val_loss: 0.8053 - val_accuracy: 0.8428\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4094 - accuracy: 0.9672 - val_loss: 0.8733 - val_accuracy: 0.8337\n","Epoch 92/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3977 - accuracy: 0.9731 - val_loss: 0.8226 - val_accuracy: 0.8416\n","Epoch 93/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3922 - accuracy: 0.9748 - val_loss: 0.8206 - val_accuracy: 0.8450\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3838 - accuracy: 0.9808 - val_loss: 0.8186 - val_accuracy: 0.8416\n","Epoch 95/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3866 - accuracy: 0.9808 - val_loss: 0.8168 - val_accuracy: 0.8450\n","Epoch 96/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3831 - accuracy: 0.9799 - val_loss: 0.8172 - val_accuracy: 0.8428\n","Epoch 97/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3841 - accuracy: 0.9788 - val_loss: 0.8092 - val_accuracy: 0.8405\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3840 - accuracy: 0.9791 - val_loss: 0.8140 - val_accuracy: 0.8473\n","Epoch 99/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3915 - accuracy: 0.9762 - val_loss: 0.8339 - val_accuracy: 0.8382\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3807 - accuracy: 0.9796 - val_loss: 0.8308 - val_accuracy: 0.8462\n","{'loss': [0.6328137516975403, 0.6112626194953918, 0.6224544644355774, 0.600883424282074, 0.6034322381019592, 0.5898506045341492, 0.5914362072944641, 0.583920419216156, 0.5832181572914124, 0.5829669237136841, 0.5912503004074097, 0.5766859650611877, 0.5779131054878235, 0.5813063383102417, 0.5688142776489258, 0.5654200911521912, 0.564198911190033, 0.5489278435707092, 0.5518980026245117, 0.5573994517326355, 0.5510292649269104, 0.552288293838501, 0.5439940690994263, 0.5443247556686401, 0.5363113880157471, 0.5545082092285156, 0.5272703766822815, 0.5297437906265259, 0.5353956818580627, 0.5307372808456421, 0.5273004770278931, 0.5207743644714355, 0.5162003040313721, 0.5219911932945251, 0.5094999670982361, 0.5033299326896667, 0.5067950487136841, 0.5137082934379578, 0.498050332069397, 0.49933844804763794, 0.5001460313796997, 0.49667343497276306, 0.49115613102912903, 0.4867215156555176, 0.4880351722240448, 0.4892842471599579, 0.4896223247051239, 0.47862425446510315, 0.46981081366539, 0.4704298675060272, 0.4748528301715851, 0.4629867672920227, 0.46572345495224, 0.45818856358528137, 0.48133385181427, 0.45788195729255676, 0.4570014476776123, 0.4469432830810547, 0.46265047788619995, 0.45007115602493286, 0.45745640993118286, 0.44560569524765015, 0.45004183053970337, 0.45570021867752075, 0.44529101252555847, 0.4402189552783966, 0.4378966987133026, 0.43385639786720276, 0.43174850940704346, 0.43238991498947144, 0.4352065622806549, 0.4248027801513672, 0.426515132188797, 0.4293513000011444, 0.41844695806503296, 0.41574931144714355, 0.41731199622154236, 0.4220156967639923, 0.42523589730262756, 0.41288524866104126, 0.40216386318206787, 0.40778225660324097, 0.4016807973384857, 0.40661731362342834, 0.4090336561203003, 0.39832615852355957, 0.39800870418548584, 0.3996186852455139, 0.39394089579582214, 0.3974805474281311, 0.40938445925712585, 0.3976563513278961, 0.3921813368797302, 0.38378793001174927, 0.38661056756973267, 0.383125901222229, 0.38405168056488037, 0.38399237394332886, 0.39145714044570923, 0.38074105978012085], 'accuracy': [0.9035087823867798, 0.9128466248512268, 0.9060554504394531, 0.9204866886138916, 0.9179400205612183, 0.9221844673156738, 0.9235993027687073, 0.9190718531608582, 0.9235993027687073, 0.9156762957572937, 0.918222963809967, 0.9210526347160339, 0.9213355779647827, 0.9168081283569336, 0.9275608658790588, 0.9264289736747742, 0.9275608658790588, 0.9354838728904724, 0.9315223693847656, 0.9261460304260254, 0.9323712587356567, 0.9298245906829834, 0.9298245906829834, 0.9337860941886902, 0.9383135437965393, 0.9278438091278076, 0.9380305409431458, 0.9357668161392212, 0.9332201480865479, 0.9346349835395813, 0.9346349835395813, 0.9422750473022461, 0.9442558288574219, 0.9400113224983215, 0.9513299465179443, 0.9487832188606262, 0.9439728260040283, 0.9394453763961792, 0.9530277252197266, 0.9442558288574219, 0.9473684430122375, 0.9439728260040283, 0.9490662217140198, 0.9493491649627686, 0.9448217153549194, 0.9493491649627686, 0.9476513862609863, 0.9521788358688354, 0.9586870670318604, 0.9541596174240112, 0.9518958926200867, 0.9584040641784668, 0.9533106684684753, 0.9584040641784668, 0.9462365508079529, 0.9567062854766846, 0.9572722315788269, 0.9646292924880981, 0.9518958926200867, 0.9629315137863159, 0.958121120929718, 0.963780403137207, 0.961799681186676, 0.9561403393745422, 0.9623655676841736, 0.9651952385902405, 0.9632145166397095, 0.9683078527450562, 0.9660441279411316, 0.9643463492393494, 0.9668930172920227, 0.9722693562507629, 0.967458963394165, 0.967458963394165, 0.9714204668998718, 0.9714204668998718, 0.9697226881980896, 0.9680249094963074, 0.967458963394165, 0.9700056314468384, 0.979626476764679, 0.9717034697532654, 0.9750990271568298, 0.9739671945571899, 0.9734012484550476, 0.9762309193611145, 0.9745330810546875, 0.974816083908081, 0.9742501378059387, 0.9756649732589722, 0.9671760201454163, 0.9731183052062988, 0.974816083908081, 0.9807583689689636, 0.9807583689689636, 0.9799094796180725, 0.9787775874137878, 0.9790605306625366, 0.9762309193611145, 0.979626476764679], 'val_loss': [1.0485873222351074, 1.042440414428711, 1.037145733833313, 1.0386264324188232, 1.0268560647964478, 1.030321478843689, 1.0293937921524048, 1.0206502676010132, 1.0238012075424194, 0.9792176485061646, 1.0242059230804443, 1.0017467737197876, 1.079843282699585, 0.9632296562194824, 0.988115668296814, 0.9946641325950623, 1.0064239501953125, 0.9273663759231567, 0.9893471002578735, 0.8836882710456848, 0.9023661017417908, 0.8280566334724426, 0.884323000907898, 0.7297124266624451, 0.7320312857627869, 0.7638047337532043, 0.7213261127471924, 0.7389740943908691, 0.7552059292793274, 0.7249947786331177, 0.7519646286964417, 0.7474895715713501, 0.7292877435684204, 0.7315811514854431, 0.7262834310531616, 0.7314502596855164, 0.735131025314331, 0.7397468090057373, 0.7412802577018738, 0.7663941979408264, 0.7353525161743164, 0.7393362522125244, 0.7424281239509583, 0.7450894713401794, 0.7512041330337524, 0.7410515546798706, 0.7449097037315369, 0.7521336078643799, 0.751700758934021, 0.7507379651069641, 0.7479302883148193, 0.7540987730026245, 0.7548671960830688, 0.764181911945343, 0.7710871696472168, 0.7759391069412231, 0.7547487020492554, 0.8112253546714783, 0.7682535648345947, 0.7673978209495544, 0.763653576374054, 0.77069491147995, 0.7792512774467468, 0.7707291841506958, 0.7671700119972229, 0.7630437016487122, 0.769727885723114, 0.775455117225647, 0.7789047956466675, 0.7744202613830566, 0.7744205594062805, 0.7781392335891724, 0.7854745984077454, 0.7790008187294006, 0.7771565914154053, 0.7845566868782043, 0.7880169153213501, 0.7958126664161682, 0.7941501140594482, 0.7933133244514465, 0.7983180284500122, 0.786517322063446, 0.7974892258644104, 0.7922309637069702, 0.7902513146400452, 0.8049976229667664, 0.8017780184745789, 0.8044393062591553, 0.7893471121788025, 0.805267333984375, 0.8732830882072449, 0.8226096034049988, 0.8205640316009521, 0.818625271320343, 0.8167925477027893, 0.817223846912384, 0.8092476725578308, 0.8140062093734741, 0.833916962146759, 0.8308241963386536], 'val_accuracy': [0.6674208045005798, 0.6142534017562866, 0.6142534017562866, 0.5316742062568665, 0.5565611124038696, 0.5271493196487427, 0.516968309879303, 0.5328054428100586, 0.5260180830955505, 0.6119909286499023, 0.5373303294181824, 0.570135772228241, 0.5203620195388794, 0.6300904750823975, 0.6176470518112183, 0.6255655884742737, 0.6300904750823975, 0.6911764740943909, 0.6719456911087036, 0.7398189902305603, 0.7364253401756287, 0.7782805562019348, 0.7635746598243713, 0.8348416090011597, 0.8416289687156677, 0.8223981857299805, 0.848416268825531, 0.8518099784851074, 0.8337104320526123, 0.8506787419319153, 0.8393664956092834, 0.848416268825531, 0.8461538553237915, 0.8540723919868469, 0.8472850918769836, 0.848416268825531, 0.8518099784851074, 0.8427602052688599, 0.8450226187705994, 0.8393664956092834, 0.8450226187705994, 0.8518099784851074, 0.8438913822174072, 0.8506787419319153, 0.8427602052688599, 0.8438913822174072, 0.8472850918769836, 0.8450226187705994, 0.8427602052688599, 0.8438913822174072, 0.8427602052688599, 0.8450226187705994, 0.8540723919868469, 0.8506787419319153, 0.8506787419319153, 0.8506787419319153, 0.8540723919868469, 0.8450226187705994, 0.8518099784851074, 0.8529411554336548, 0.8506787419319153, 0.8529411554336548, 0.8438913822174072, 0.8404977321624756, 0.8393664956092834, 0.8472850918769836, 0.8472850918769836, 0.8472850918769836, 0.848416268825531, 0.8472850918769836, 0.8450226187705994, 0.8506787419319153, 0.8450226187705994, 0.8382353186607361, 0.8438913822174072, 0.8438913822174072, 0.8450226187705994, 0.848416268825531, 0.8461538553237915, 0.8461538553237915, 0.8461538553237915, 0.8438913822174072, 0.8427602052688599, 0.8450226187705994, 0.8438913822174072, 0.8450226187705994, 0.8461538553237915, 0.8416289687156677, 0.8427602052688599, 0.8427602052688599, 0.8337104320526123, 0.8416289687156677, 0.8450226187705994, 0.8416289687156677, 0.8450226187705994, 0.8427602052688599, 0.8404977321624756, 0.8472850918769836, 0.8382353186607361, 0.8461538553237915]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.6427 - accuracy: 0.9025"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 64ms/step - loss: 0.6405 - accuracy: 0.9031 - val_loss: 1.0473 - val_accuracy: 0.5961\n","Epoch 2/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6034 - accuracy: 0.9183 - val_loss: 1.0467 - val_accuracy: 0.5382\n","Epoch 3/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5961 - accuracy: 0.9181 - val_loss: 1.0389 - val_accuracy: 0.5372\n","Epoch 4/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5993 - accuracy: 0.9202 - val_loss: 1.0300 - val_accuracy: 0.5465\n","Epoch 5/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5923 - accuracy: 0.9235 - val_loss: 1.0365 - val_accuracy: 0.5124\n","Epoch 6/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5914 - accuracy: 0.9202 - val_loss: 1.0196 - val_accuracy: 0.5341\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5836 - accuracy: 0.9230 - val_loss: 1.0280 - val_accuracy: 0.5207\n","Epoch 8/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5779 - accuracy: 0.9233 - val_loss: 0.9884 - val_accuracy: 0.5930\n","Epoch 9/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5843 - accuracy: 0.9222 - val_loss: 1.0511 - val_accuracy: 0.5093\n","Epoch 10/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5768 - accuracy: 0.9251 - val_loss: 1.0048 - val_accuracy: 0.5434\n","Epoch 11/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5701 - accuracy: 0.9266 - val_loss: 1.0169 - val_accuracy: 0.5382\n","Epoch 12/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5631 - accuracy: 0.9302 - val_loss: 1.0177 - val_accuracy: 0.5486\n","Epoch 13/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5590 - accuracy: 0.9305 - val_loss: 0.9705 - val_accuracy: 0.6033\n","Epoch 14/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5609 - accuracy: 0.9307 - val_loss: 1.0237 - val_accuracy: 0.5744\n","Epoch 15/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.5588 - accuracy: 0.9318 - val_loss: 0.9537 - val_accuracy: 0.6508\n","Epoch 16/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5525 - accuracy: 0.9289 - val_loss: 0.9852 - val_accuracy: 0.6457\n","Epoch 17/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5513 - accuracy: 0.9336 - val_loss: 0.8923 - val_accuracy: 0.7200\n","Epoch 18/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5507 - accuracy: 0.9292 - val_loss: 0.8884 - val_accuracy: 0.7242\n","Epoch 19/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5378 - accuracy: 0.9380 - val_loss: 0.8810 - val_accuracy: 0.7459\n","Epoch 20/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5506 - accuracy: 0.9297 - val_loss: 0.8318 - val_accuracy: 0.7831\n","Epoch 21/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5427 - accuracy: 0.9320 - val_loss: 0.8969 - val_accuracy: 0.7572\n","Epoch 22/100\n","31/31 [==============================] - 1s 35ms/step - loss: 0.5537 - accuracy: 0.9264 - val_loss: 0.7372 - val_accuracy: 0.8378\n","Epoch 23/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.5326 - accuracy: 0.9377 - val_loss: 0.6919 - val_accuracy: 0.8605\n","Epoch 24/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5303 - accuracy: 0.9382 - val_loss: 0.6938 - val_accuracy: 0.8595\n","Epoch 25/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5380 - accuracy: 0.9357 - val_loss: 0.7361 - val_accuracy: 0.8419\n","Epoch 26/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5282 - accuracy: 0.9370 - val_loss: 0.7199 - val_accuracy: 0.8523\n","Epoch 27/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5219 - accuracy: 0.9408 - val_loss: 0.7349 - val_accuracy: 0.8492\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5267 - accuracy: 0.9393 - val_loss: 0.7034 - val_accuracy: 0.8543\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5113 - accuracy: 0.9465 - val_loss: 0.7093 - val_accuracy: 0.8585\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5167 - accuracy: 0.9406 - val_loss: 0.7119 - val_accuracy: 0.8595\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5135 - accuracy: 0.9406 - val_loss: 0.7226 - val_accuracy: 0.8543\n","Epoch 32/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5079 - accuracy: 0.9478 - val_loss: 0.7154 - val_accuracy: 0.8533\n","Epoch 33/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5013 - accuracy: 0.9470 - val_loss: 0.7195 - val_accuracy: 0.8533\n","Epoch 34/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5036 - accuracy: 0.9421 - val_loss: 0.7248 - val_accuracy: 0.8523\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5039 - accuracy: 0.9434 - val_loss: 0.7551 - val_accuracy: 0.8461\n","Epoch 36/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5060 - accuracy: 0.9408 - val_loss: 0.7232 - val_accuracy: 0.8574\n","Epoch 37/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.5032 - accuracy: 0.9439 - val_loss: 0.7183 - val_accuracy: 0.8636\n","Epoch 38/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4994 - accuracy: 0.9481 - val_loss: 0.7201 - val_accuracy: 0.8543\n","Epoch 39/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4924 - accuracy: 0.9473 - val_loss: 0.7189 - val_accuracy: 0.8533\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4883 - accuracy: 0.9494 - val_loss: 0.7525 - val_accuracy: 0.8502\n","Epoch 41/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4912 - accuracy: 0.9478 - val_loss: 0.7324 - val_accuracy: 0.8554\n","Epoch 42/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4833 - accuracy: 0.9517 - val_loss: 0.7207 - val_accuracy: 0.8512\n","Epoch 43/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4776 - accuracy: 0.9545 - val_loss: 0.7236 - val_accuracy: 0.8574\n","Epoch 44/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4919 - accuracy: 0.9419 - val_loss: 0.7315 - val_accuracy: 0.8564\n","Epoch 45/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4989 - accuracy: 0.9377 - val_loss: 0.7366 - val_accuracy: 0.8543\n","Epoch 46/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4699 - accuracy: 0.9563 - val_loss: 0.7258 - val_accuracy: 0.8564\n","Epoch 47/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4693 - accuracy: 0.9540 - val_loss: 0.7256 - val_accuracy: 0.8554\n","Epoch 48/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4665 - accuracy: 0.9607 - val_loss: 0.7277 - val_accuracy: 0.8533\n","Epoch 49/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4799 - accuracy: 0.9463 - val_loss: 0.7403 - val_accuracy: 0.8574\n","Epoch 50/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4676 - accuracy: 0.9561 - val_loss: 0.7257 - val_accuracy: 0.8523\n","Epoch 51/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4613 - accuracy: 0.9581 - val_loss: 0.7458 - val_accuracy: 0.8481\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4609 - accuracy: 0.9563 - val_loss: 0.7454 - val_accuracy: 0.8564\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4631 - accuracy: 0.9530 - val_loss: 0.7318 - val_accuracy: 0.8564\n","Epoch 54/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4649 - accuracy: 0.9522 - val_loss: 0.8001 - val_accuracy: 0.8533\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4608 - accuracy: 0.9519 - val_loss: 0.7630 - val_accuracy: 0.8533\n","Epoch 56/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4609 - accuracy: 0.9566 - val_loss: 0.7469 - val_accuracy: 0.8502\n","Epoch 57/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4465 - accuracy: 0.9597 - val_loss: 0.7326 - val_accuracy: 0.8564\n","Epoch 58/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4448 - accuracy: 0.9646 - val_loss: 0.7438 - val_accuracy: 0.8554\n","Epoch 59/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4515 - accuracy: 0.9566 - val_loss: 0.7927 - val_accuracy: 0.8523\n","Epoch 60/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4504 - accuracy: 0.9563 - val_loss: 0.7517 - val_accuracy: 0.8512\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4538 - accuracy: 0.9537 - val_loss: 0.7428 - val_accuracy: 0.8564\n","Epoch 62/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4396 - accuracy: 0.9636 - val_loss: 0.7435 - val_accuracy: 0.8595\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4433 - accuracy: 0.9581 - val_loss: 0.7514 - val_accuracy: 0.8502\n","Epoch 64/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4370 - accuracy: 0.9641 - val_loss: 0.7445 - val_accuracy: 0.8564\n","Epoch 65/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4433 - accuracy: 0.9602 - val_loss: 0.7467 - val_accuracy: 0.8574\n","Epoch 66/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4330 - accuracy: 0.9630 - val_loss: 0.7547 - val_accuracy: 0.8512\n","Epoch 67/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4394 - accuracy: 0.9607 - val_loss: 0.7442 - val_accuracy: 0.8492\n","Epoch 68/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4314 - accuracy: 0.9680 - val_loss: 0.7563 - val_accuracy: 0.8409\n","Epoch 69/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4293 - accuracy: 0.9646 - val_loss: 0.7558 - val_accuracy: 0.8523\n","Epoch 70/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4317 - accuracy: 0.9638 - val_loss: 0.7555 - val_accuracy: 0.8471\n","Epoch 71/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4259 - accuracy: 0.9649 - val_loss: 0.7601 - val_accuracy: 0.8523\n","Epoch 72/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4257 - accuracy: 0.9651 - val_loss: 0.7681 - val_accuracy: 0.8564\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4243 - accuracy: 0.9672 - val_loss: 0.7625 - val_accuracy: 0.8523\n","Epoch 74/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4241 - accuracy: 0.9677 - val_loss: 0.7627 - val_accuracy: 0.8450\n","Epoch 75/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4423 - accuracy: 0.9574 - val_loss: 0.7681 - val_accuracy: 0.8481\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4207 - accuracy: 0.9649 - val_loss: 0.7766 - val_accuracy: 0.8585\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4185 - accuracy: 0.9680 - val_loss: 0.7569 - val_accuracy: 0.8440\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4154 - accuracy: 0.9667 - val_loss: 0.7604 - val_accuracy: 0.8481\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4117 - accuracy: 0.9690 - val_loss: 0.7707 - val_accuracy: 0.8461\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4162 - accuracy: 0.9677 - val_loss: 0.7842 - val_accuracy: 0.8471\n","Epoch 81/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4123 - accuracy: 0.9677 - val_loss: 0.7683 - val_accuracy: 0.8502\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4074 - accuracy: 0.9716 - val_loss: 0.8605 - val_accuracy: 0.8295\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4288 - accuracy: 0.9550 - val_loss: 0.7684 - val_accuracy: 0.8502\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3970 - accuracy: 0.9742 - val_loss: 0.8181 - val_accuracy: 0.8378\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4071 - accuracy: 0.9713 - val_loss: 0.7841 - val_accuracy: 0.8461\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3973 - accuracy: 0.9752 - val_loss: 0.7935 - val_accuracy: 0.8419\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4023 - accuracy: 0.9698 - val_loss: 0.8058 - val_accuracy: 0.8378\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3959 - accuracy: 0.9726 - val_loss: 0.8004 - val_accuracy: 0.8357\n","Epoch 89/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4006 - accuracy: 0.9721 - val_loss: 0.7936 - val_accuracy: 0.8430\n","Epoch 90/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3912 - accuracy: 0.9752 - val_loss: 0.7900 - val_accuracy: 0.8440\n","Epoch 91/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4031 - accuracy: 0.9716 - val_loss: 0.7984 - val_accuracy: 0.8419\n","Epoch 92/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3863 - accuracy: 0.9749 - val_loss: 0.8186 - val_accuracy: 0.8399\n","Epoch 93/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3919 - accuracy: 0.9752 - val_loss: 0.7925 - val_accuracy: 0.8512\n","Epoch 94/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3815 - accuracy: 0.9811 - val_loss: 0.8045 - val_accuracy: 0.8450\n","Epoch 95/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3902 - accuracy: 0.9739 - val_loss: 0.8011 - val_accuracy: 0.8502\n","Epoch 96/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3981 - accuracy: 0.9682 - val_loss: 0.7958 - val_accuracy: 0.8461\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3850 - accuracy: 0.9755 - val_loss: 0.8381 - val_accuracy: 0.8419\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3859 - accuracy: 0.9778 - val_loss: 0.8310 - val_accuracy: 0.8409\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3814 - accuracy: 0.9744 - val_loss: 0.8146 - val_accuracy: 0.8409\n","Epoch 100/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3813 - accuracy: 0.9765 - val_loss: 0.8280 - val_accuracy: 0.8419\n","{'loss': [0.6405401229858398, 0.6034120917320251, 0.596092164516449, 0.5992880463600159, 0.5923391580581665, 0.5914042592048645, 0.5836436748504639, 0.5779012441635132, 0.5842841863632202, 0.5767905712127686, 0.5700767040252686, 0.5631307363510132, 0.5589884519577026, 0.5608981847763062, 0.5588114857673645, 0.5525140166282654, 0.5512831807136536, 0.5506829619407654, 0.5378386974334717, 0.5506338477134705, 0.5427259206771851, 0.5537076592445374, 0.5326001644134521, 0.5303122997283936, 0.5379733443260193, 0.5282027125358582, 0.5218711495399475, 0.5266743898391724, 0.5112826824188232, 0.5166590213775635, 0.5134667754173279, 0.5078915357589722, 0.5012751817703247, 0.5035825967788696, 0.503853976726532, 0.5060420632362366, 0.5032272934913635, 0.4993837773799896, 0.4923727214336395, 0.488305002450943, 0.4912172257900238, 0.4832771420478821, 0.4775983691215515, 0.4918859899044037, 0.4989378750324249, 0.469912052154541, 0.469308078289032, 0.46648362278938293, 0.47987601161003113, 0.4675995707511902, 0.4613283574581146, 0.4608689546585083, 0.4631040692329407, 0.46487680077552795, 0.46081602573394775, 0.4609314799308777, 0.4464799165725708, 0.4448018968105316, 0.45151203870773315, 0.4503738582134247, 0.4537990391254425, 0.43959325551986694, 0.4433397948741913, 0.4369913637638092, 0.4433198571205139, 0.43297043442726135, 0.4393845498561859, 0.4314321279525757, 0.4293089509010315, 0.4317193329334259, 0.42594847083091736, 0.4257030785083771, 0.42430007457733154, 0.4240826964378357, 0.44233474135398865, 0.4206501841545105, 0.41853874921798706, 0.41536691784858704, 0.4116603136062622, 0.41615915298461914, 0.41230979561805725, 0.4074384570121765, 0.42878457903862, 0.3969881236553192, 0.40708863735198975, 0.3973362147808075, 0.4022822380065918, 0.395911306142807, 0.40057072043418884, 0.39124977588653564, 0.4030798375606537, 0.3862878382205963, 0.39186298847198486, 0.38152775168418884, 0.39018571376800537, 0.3980664908885956, 0.3850031793117523, 0.38591670989990234, 0.3813546895980835, 0.38125234842300415], 'accuracy': [0.9031007885932922, 0.9183462262153625, 0.9180878400802612, 0.9201550483703613, 0.923514187335968, 0.9201550483703613, 0.9229974150657654, 0.9232558012008667, 0.9222221970558167, 0.9250646233558655, 0.9266149997711182, 0.930232584476471, 0.9304909706115723, 0.9307493567466736, 0.9317829608917236, 0.9289405941963196, 0.9335917234420776, 0.9291989803314209, 0.9379844665527344, 0.9297157526016235, 0.932041347026825, 0.9263566136360168, 0.9377260804176331, 0.9382429122924805, 0.9356589317321777, 0.9369509220123291, 0.9408268928527832, 0.9392764568328857, 0.9465116262435913, 0.9405684471130371, 0.9405684471130371, 0.9478036165237427, 0.947028398513794, 0.9421188831329346, 0.9434108734130859, 0.9408268928527832, 0.9439276456832886, 0.948062002658844, 0.94728684425354, 0.9493539929389954, 0.9478036165237427, 0.9516795873641968, 0.9545219540596008, 0.9418604373931885, 0.9377260804176331, 0.9563307762145996, 0.9540051817893982, 0.9607235193252563, 0.94625324010849, 0.9560723304748535, 0.9581395387649536, 0.9563307762145996, 0.9529715776443481, 0.9521963596343994, 0.9519379734992981, 0.9565891623497009, 0.9596899151802063, 0.9645994901657104, 0.9565891623497009, 0.9563307762145996, 0.9537467956542969, 0.9635658860206604, 0.9581395387649536, 0.964082658290863, 0.9602067470550537, 0.9630491137504578, 0.9607235193252563, 0.9679586291313171, 0.9645994901657104, 0.9638242721557617, 0.9648578763008118, 0.9651162624359131, 0.9671834707260132, 0.9677002429962158, 0.9573643207550049, 0.9648578763008118, 0.9679586291313171, 0.9666666388511658, 0.9689922332763672, 0.9677002429962158, 0.9677002429962158, 0.9715762138366699, 0.9550387859344482, 0.9741601943969727, 0.9713178277015686, 0.9751937985420227, 0.9697674512863159, 0.97260981798172, 0.9720930457115173, 0.9751937985420227, 0.9715762138366699, 0.9749354124069214, 0.9751937985420227, 0.9811369776725769, 0.9739018082618713, 0.9682170748710632, 0.975452184677124, 0.9777777791023254, 0.974418580532074, 0.9764857888221741], 'val_loss': [1.0473002195358276, 1.0466639995574951, 1.038896918296814, 1.0300028324127197, 1.0365314483642578, 1.0196070671081543, 1.027982473373413, 0.9883697032928467, 1.0510936975479126, 1.004758358001709, 1.0168695449829102, 1.017707109451294, 0.9704796075820923, 1.0237294435501099, 0.9537050127983093, 0.985161304473877, 0.892293393611908, 0.8884339928627014, 0.8809757828712463, 0.8317674398422241, 0.8968592286109924, 0.7372229099273682, 0.6918987035751343, 0.693837583065033, 0.7361478805541992, 0.7199481725692749, 0.7348794341087341, 0.7034430503845215, 0.7093130946159363, 0.7119448184967041, 0.7225805521011353, 0.7153670191764832, 0.7195115685462952, 0.7247722744941711, 0.7550846338272095, 0.723186194896698, 0.7182916402816772, 0.7200870513916016, 0.7189237475395203, 0.7525081634521484, 0.7324445247650146, 0.7206993699073792, 0.7236053943634033, 0.7314974665641785, 0.7365832924842834, 0.7257840633392334, 0.7256247401237488, 0.727733314037323, 0.7403126955032349, 0.7256925106048584, 0.74577397108078, 0.7453723549842834, 0.7318320870399475, 0.8001434206962585, 0.7629721760749817, 0.7468956112861633, 0.7326058149337769, 0.7437968850135803, 0.7926976680755615, 0.7516736388206482, 0.7427973747253418, 0.7435137629508972, 0.7514066100120544, 0.7445283532142639, 0.7466895580291748, 0.7547466158866882, 0.7442092299461365, 0.7563357353210449, 0.7557774782180786, 0.7555415630340576, 0.760117769241333, 0.768101155757904, 0.7624521255493164, 0.7627116441726685, 0.7680714130401611, 0.7765713930130005, 0.756895124912262, 0.7603920698165894, 0.7706605195999146, 0.7842282652854919, 0.7683354020118713, 0.8604575991630554, 0.7683738470077515, 0.8181461095809937, 0.7840823531150818, 0.7935212850570679, 0.8058046698570251, 0.8003671169281006, 0.7936232089996338, 0.7899983525276184, 0.7983584403991699, 0.8186354041099548, 0.7924835085868835, 0.8045149445533752, 0.8010925650596619, 0.7957901358604431, 0.8381237387657166, 0.8309651613235474, 0.814644992351532, 0.827951967716217], 'val_accuracy': [0.5960744023323059, 0.538223147392273, 0.5371900796890259, 0.5464876294136047, 0.5123966932296753, 0.5340909361839294, 0.5206611752510071, 0.5929751992225647, 0.5092975497245789, 0.5433884263038635, 0.538223147392273, 0.5485537052154541, 0.6033057570457458, 0.5743801593780518, 0.6508264541625977, 0.6456611752510071, 0.7200413346290588, 0.7241735458374023, 0.7458677887916565, 0.7830578684806824, 0.7572314143180847, 0.8378099203109741, 0.8605371713638306, 0.8595041036605835, 0.8419421315193176, 0.8522727489471436, 0.8491735458374023, 0.8543388247489929, 0.8584710955619812, 0.8595041036605835, 0.8543388247489929, 0.8533057570457458, 0.8533057570457458, 0.8522727489471436, 0.8460744023323059, 0.8574380278587341, 0.8636363744735718, 0.8543388247489929, 0.8533057570457458, 0.8502066135406494, 0.85537189245224, 0.8512396812438965, 0.8574380278587341, 0.8564049601554871, 0.8543388247489929, 0.8564049601554871, 0.85537189245224, 0.8533057570457458, 0.8574380278587341, 0.8522727489471436, 0.8481404781341553, 0.8564049601554871, 0.8564049601554871, 0.8533057570457458, 0.8533057570457458, 0.8502066135406494, 0.8564049601554871, 0.85537189245224, 0.8522727489471436, 0.8512396812438965, 0.8564049601554871, 0.8595041036605835, 0.8502066135406494, 0.8564049601554871, 0.8574380278587341, 0.8512396812438965, 0.8491735458374023, 0.8409090638160706, 0.8522727489471436, 0.8471074104309082, 0.8522727489471436, 0.8564049601554871, 0.8522727489471436, 0.8450413346290588, 0.8481404781341553, 0.8584710955619812, 0.8440082669258118, 0.8481404781341553, 0.8460744023323059, 0.8471074104309082, 0.8502066135406494, 0.8295454382896423, 0.8502066135406494, 0.8378099203109741, 0.8460744023323059, 0.8419421315193176, 0.8378099203109741, 0.83574378490448, 0.8429751992225647, 0.8440082669258118, 0.8419421315193176, 0.8398760557174683, 0.8512396812438965, 0.8450413346290588, 0.8502066135406494, 0.8460744023323059, 0.8419421315193176, 0.8409090638160706, 0.8409090638160706, 0.8419421315193176]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.4530 - accuracy: 0.9475"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 55ms/step - loss: 0.4526 - accuracy: 0.9475 - val_loss: 0.9760 - val_accuracy: 0.5216\n","Epoch 2/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4359 - accuracy: 0.9542 - val_loss: 0.9668 - val_accuracy: 0.5377\n","Epoch 3/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4327 - accuracy: 0.9553 - val_loss: 0.9824 - val_accuracy: 0.4957\n","Epoch 4/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4247 - accuracy: 0.9566 - val_loss: 1.0001 - val_accuracy: 0.4881\n","Epoch 5/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4205 - accuracy: 0.9599 - val_loss: 0.9996 - val_accuracy: 0.4892\n","Epoch 6/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4129 - accuracy: 0.9626 - val_loss: 0.9813 - val_accuracy: 0.5032\n","Epoch 7/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4206 - accuracy: 0.9577 - val_loss: 1.0190 - val_accuracy: 0.4935\n","Epoch 8/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4065 - accuracy: 0.9658 - val_loss: 1.0206 - val_accuracy: 0.4978\n","Epoch 9/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4009 - accuracy: 0.9666 - val_loss: 1.0901 - val_accuracy: 0.4914\n","Epoch 10/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4077 - accuracy: 0.9626 - val_loss: 1.1434 - val_accuracy: 0.4903\n","Epoch 11/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4009 - accuracy: 0.9671 - val_loss: 1.1635 - val_accuracy: 0.4957\n","Epoch 12/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4089 - accuracy: 0.9615 - val_loss: 1.2555 - val_accuracy: 0.4946\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4092 - accuracy: 0.9628 - val_loss: 1.2097 - val_accuracy: 0.5194\n","Epoch 14/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3949 - accuracy: 0.9688 - val_loss: 1.4473 - val_accuracy: 0.5000\n","Epoch 15/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.3956 - accuracy: 0.9698 - val_loss: 1.2608 - val_accuracy: 0.5453\n","Epoch 16/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3903 - accuracy: 0.9693 - val_loss: 1.4772 - val_accuracy: 0.5366\n","Epoch 17/100\n","29/29 [==============================] - 1s 35ms/step - loss: 0.3889 - accuracy: 0.9723 - val_loss: 1.3740 - val_accuracy: 0.5636\n","Epoch 18/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.4053 - accuracy: 0.9631 - val_loss: 1.1500 - val_accuracy: 0.6239\n","Epoch 19/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3745 - accuracy: 0.9782 - val_loss: 1.0440 - val_accuracy: 0.6810\n","Epoch 20/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3847 - accuracy: 0.9728 - val_loss: 0.8464 - val_accuracy: 0.7651\n","Epoch 21/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3805 - accuracy: 0.9736 - val_loss: 0.8491 - val_accuracy: 0.7759\n","Epoch 22/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3765 - accuracy: 0.9752 - val_loss: 0.8488 - val_accuracy: 0.7823\n","Epoch 23/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3719 - accuracy: 0.9784 - val_loss: 0.6412 - val_accuracy: 0.8578\n","Epoch 24/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3896 - accuracy: 0.9679 - val_loss: 0.6102 - val_accuracy: 0.8718\n","Epoch 25/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3795 - accuracy: 0.9706 - val_loss: 0.6489 - val_accuracy: 0.8631\n","Epoch 26/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3732 - accuracy: 0.9766 - val_loss: 0.6355 - val_accuracy: 0.8675\n","Epoch 27/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3736 - accuracy: 0.9776 - val_loss: 0.6711 - val_accuracy: 0.8578\n","Epoch 28/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3668 - accuracy: 0.9774 - val_loss: 0.6286 - val_accuracy: 0.8772\n","Epoch 29/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3676 - accuracy: 0.9779 - val_loss: 0.6178 - val_accuracy: 0.8825\n","Epoch 30/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3643 - accuracy: 0.9790 - val_loss: 0.6526 - val_accuracy: 0.8718\n","Epoch 31/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3793 - accuracy: 0.9712 - val_loss: 0.6133 - val_accuracy: 0.8836\n","Epoch 32/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3650 - accuracy: 0.9774 - val_loss: 0.6343 - val_accuracy: 0.8836\n","Epoch 33/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3589 - accuracy: 0.9814 - val_loss: 0.6160 - val_accuracy: 0.8879\n","Epoch 34/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3591 - accuracy: 0.9809 - val_loss: 0.6464 - val_accuracy: 0.8815\n","Epoch 35/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.3698 - accuracy: 0.9774 - val_loss: 0.6140 - val_accuracy: 0.8976\n","Epoch 36/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3583 - accuracy: 0.9798 - val_loss: 0.6676 - val_accuracy: 0.8761\n","Epoch 37/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3543 - accuracy: 0.9833 - val_loss: 0.6226 - val_accuracy: 0.8879\n","Epoch 38/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3509 - accuracy: 0.9838 - val_loss: 0.6410 - val_accuracy: 0.8804\n","Epoch 39/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3457 - accuracy: 0.9879 - val_loss: 0.6381 - val_accuracy: 0.8858\n","Epoch 40/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3568 - accuracy: 0.9806 - val_loss: 0.6397 - val_accuracy: 0.9009\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3547 - accuracy: 0.9809 - val_loss: 0.6162 - val_accuracy: 0.8987\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3513 - accuracy: 0.9811 - val_loss: 0.6457 - val_accuracy: 0.8987\n","Epoch 43/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3577 - accuracy: 0.9782 - val_loss: 0.6378 - val_accuracy: 0.8836\n","Epoch 44/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3426 - accuracy: 0.9836 - val_loss: 0.6367 - val_accuracy: 0.8847\n","Epoch 45/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3509 - accuracy: 0.9798 - val_loss: 0.6517 - val_accuracy: 0.8858\n","Epoch 46/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3544 - accuracy: 0.9790 - val_loss: 0.6577 - val_accuracy: 0.8944\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3698 - accuracy: 0.9688 - val_loss: 0.6443 - val_accuracy: 0.8998\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3450 - accuracy: 0.9828 - val_loss: 0.6353 - val_accuracy: 0.8966\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3420 - accuracy: 0.9849 - val_loss: 0.6645 - val_accuracy: 0.8804\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3377 - accuracy: 0.9857 - val_loss: 0.6434 - val_accuracy: 0.8793\n","Epoch 51/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3499 - accuracy: 0.9801 - val_loss: 0.6873 - val_accuracy: 0.8750\n","Epoch 52/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3548 - accuracy: 0.9768 - val_loss: 0.6404 - val_accuracy: 0.8836\n","Epoch 53/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3505 - accuracy: 0.9787 - val_loss: 0.6898 - val_accuracy: 0.8772\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3461 - accuracy: 0.9817 - val_loss: 0.6406 - val_accuracy: 0.8901\n","Epoch 55/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3363 - accuracy: 0.9865 - val_loss: 0.6389 - val_accuracy: 0.8922\n","Epoch 56/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3382 - accuracy: 0.9857 - val_loss: 0.6766 - val_accuracy: 0.8793\n","Epoch 57/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3310 - accuracy: 0.9879 - val_loss: 0.6425 - val_accuracy: 0.8966\n","Epoch 58/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3322 - accuracy: 0.9855 - val_loss: 0.6503 - val_accuracy: 0.8976\n","Epoch 59/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3359 - accuracy: 0.9860 - val_loss: 0.6416 - val_accuracy: 0.8944\n","Epoch 60/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3342 - accuracy: 0.9844 - val_loss: 0.6510 - val_accuracy: 0.8879\n","Epoch 61/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.3353 - accuracy: 0.9865 - val_loss: 0.6435 - val_accuracy: 0.9019\n","Epoch 62/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3297 - accuracy: 0.9873 - val_loss: 0.6517 - val_accuracy: 0.8869\n","Epoch 63/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3247 - accuracy: 0.9906 - val_loss: 0.6572 - val_accuracy: 0.8858\n","Epoch 64/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3424 - accuracy: 0.9790 - val_loss: 0.6487 - val_accuracy: 0.8998\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3379 - accuracy: 0.9825 - val_loss: 0.6467 - val_accuracy: 0.8944\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3215 - accuracy: 0.9916 - val_loss: 0.6873 - val_accuracy: 0.8761\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3285 - accuracy: 0.9855 - val_loss: 0.6733 - val_accuracy: 0.8761\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3253 - accuracy: 0.9884 - val_loss: 0.6908 - val_accuracy: 0.8761\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3202 - accuracy: 0.9911 - val_loss: 0.6661 - val_accuracy: 0.8825\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3211 - accuracy: 0.9890 - val_loss: 0.6880 - val_accuracy: 0.8815\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3323 - accuracy: 0.9830 - val_loss: 0.6630 - val_accuracy: 0.8825\n","Epoch 72/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3389 - accuracy: 0.9798 - val_loss: 0.6523 - val_accuracy: 0.8933\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3201 - accuracy: 0.9892 - val_loss: 0.6667 - val_accuracy: 0.8869\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3151 - accuracy: 0.9914 - val_loss: 0.6617 - val_accuracy: 0.8944\n","Epoch 75/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3214 - accuracy: 0.9876 - val_loss: 0.6554 - val_accuracy: 0.8966\n","Epoch 76/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3183 - accuracy: 0.9906 - val_loss: 0.6612 - val_accuracy: 0.8901\n","Epoch 77/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3131 - accuracy: 0.9914 - val_loss: 0.6577 - val_accuracy: 0.8933\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3114 - accuracy: 0.9906 - val_loss: 0.6775 - val_accuracy: 0.8858\n","Epoch 79/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3104 - accuracy: 0.9916 - val_loss: 0.6543 - val_accuracy: 0.8944\n","Epoch 80/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3143 - accuracy: 0.9908 - val_loss: 0.6770 - val_accuracy: 0.8944\n","Epoch 81/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3172 - accuracy: 0.9890 - val_loss: 0.7055 - val_accuracy: 0.8750\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3181 - accuracy: 0.9868 - val_loss: 0.6677 - val_accuracy: 0.8869\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3140 - accuracy: 0.9879 - val_loss: 0.6774 - val_accuracy: 0.8890\n","Epoch 84/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3106 - accuracy: 0.9922 - val_loss: 0.6698 - val_accuracy: 0.8933\n","Epoch 85/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3041 - accuracy: 0.9930 - val_loss: 0.6727 - val_accuracy: 0.8847\n","Epoch 86/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3027 - accuracy: 0.9949 - val_loss: 0.6820 - val_accuracy: 0.8879\n","Epoch 87/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3013 - accuracy: 0.9930 - val_loss: 0.6856 - val_accuracy: 0.8955\n","Epoch 88/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3063 - accuracy: 0.9925 - val_loss: 0.6818 - val_accuracy: 0.8879\n","Epoch 89/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3049 - accuracy: 0.9925 - val_loss: 0.6843 - val_accuracy: 0.8879\n","Epoch 90/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2984 - accuracy: 0.9960 - val_loss: 0.7053 - val_accuracy: 0.8825\n","Epoch 91/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2986 - accuracy: 0.9938 - val_loss: 0.7135 - val_accuracy: 0.8825\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3037 - accuracy: 0.9916 - val_loss: 0.6835 - val_accuracy: 0.8847\n","Epoch 93/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3071 - accuracy: 0.9900 - val_loss: 0.6920 - val_accuracy: 0.8879\n","Epoch 94/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2983 - accuracy: 0.9930 - val_loss: 0.6897 - val_accuracy: 0.8879\n","Epoch 95/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2988 - accuracy: 0.9930 - val_loss: 0.6959 - val_accuracy: 0.8793\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3038 - accuracy: 0.9916 - val_loss: 0.6735 - val_accuracy: 0.8922\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2976 - accuracy: 0.9935 - val_loss: 0.7123 - val_accuracy: 0.8825\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2946 - accuracy: 0.9952 - val_loss: 0.6901 - val_accuracy: 0.8901\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2955 - accuracy: 0.9938 - val_loss: 0.7137 - val_accuracy: 0.8804\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3237 - accuracy: 0.9817 - val_loss: 0.6935 - val_accuracy: 0.8912\n","{'loss': [0.452572226524353, 0.4358901083469391, 0.432734876871109, 0.42467811703681946, 0.42047202587127686, 0.41286781430244446, 0.4206203818321228, 0.40650075674057007, 0.40093162655830383, 0.40769094228744507, 0.40094029903411865, 0.408918559551239, 0.4091585874557495, 0.3948529362678528, 0.39556795358657837, 0.3902691602706909, 0.3888999819755554, 0.4052753746509552, 0.37446829676628113, 0.38468483090400696, 0.38050881028175354, 0.3765166699886322, 0.3719412088394165, 0.3896354138851166, 0.3795185685157776, 0.373213529586792, 0.3736216723918915, 0.36683446168899536, 0.36762264370918274, 0.3643346428871155, 0.3793031871318817, 0.3650343120098114, 0.35893723368644714, 0.35905230045318604, 0.3697800040245056, 0.35832393169403076, 0.35434818267822266, 0.35088980197906494, 0.3456903100013733, 0.35679712891578674, 0.3546616733074188, 0.3512897193431854, 0.357720285654068, 0.34259986877441406, 0.3508504033088684, 0.35437214374542236, 0.36975550651550293, 0.34499165415763855, 0.34195318818092346, 0.337680846452713, 0.3498910367488861, 0.35478663444519043, 0.35054194927215576, 0.3460976183414459, 0.336264044046402, 0.3381767272949219, 0.3310096859931946, 0.33217141032218933, 0.33589500188827515, 0.33418676257133484, 0.335320383310318, 0.3297247290611267, 0.32467886805534363, 0.342436283826828, 0.337894469499588, 0.32148969173431396, 0.3285498321056366, 0.3252680003643036, 0.3201500475406647, 0.32113638520240784, 0.3323215842247009, 0.3388547897338867, 0.3200606405735016, 0.3150860667228699, 0.3213753402233124, 0.31832534074783325, 0.3131463825702667, 0.3114290237426758, 0.3104046881198883, 0.3143163323402405, 0.3171606957912445, 0.31811392307281494, 0.3139880895614624, 0.31061843037605286, 0.304083913564682, 0.30266863107681274, 0.3013031482696533, 0.3063467741012573, 0.30488958954811096, 0.29836368560791016, 0.29858627915382385, 0.30372199416160583, 0.3071229159832001, 0.29830336570739746, 0.29880398511886597, 0.3037561774253845, 0.2975643277168274, 0.2946440279483795, 0.2955402135848999, 0.32371845841407776], 'accuracy': [0.9474676847457886, 0.9542025923728943, 0.9552801847457886, 0.9566271305084229, 0.9598599076271057, 0.962553858757019, 0.9577047228813171, 0.9657866358757019, 0.9665948152542114, 0.962553858757019, 0.967133641242981, 0.9614762663841248, 0.9628232717514038, 0.96875, 0.9698275923728943, 0.9692887663841248, 0.9722521305084229, 0.9630926847457886, 0.978178858757019, 0.9727909564971924, 0.9735991358757019, 0.975215494632721, 0.9784482717514038, 0.9679418206214905, 0.9706357717514038, 0.9765625, 0.9776400923728943, 0.9773706793785095, 0.977909505367279, 0.9789870977401733, 0.9711745977401733, 0.9773706793785095, 0.9814116358757019, 0.9808728694915771, 0.9773706793785095, 0.9797952771186829, 0.9832974076271057, 0.9838362336158752, 0.9878771305084229, 0.9806034564971924, 0.9808728694915771, 0.9811422228813171, 0.978178858757019, 0.9835668206214905, 0.9797952771186829, 0.9789870977401733, 0.96875, 0.982758641242981, 0.9849137663841248, 0.985722005367279, 0.9800646305084229, 0.9768319129943848, 0.9787176847457886, 0.9816810488700867, 0.9865301847457886, 0.985722005367279, 0.9878771305084229, 0.9854525923728943, 0.985991358757019, 0.984375, 0.9865301847457886, 0.9873383641242981, 0.990571141242981, 0.9789870977401733, 0.9824892282485962, 0.9916487336158752, 0.9854525923728943, 0.9884159564971924, 0.9911099076271057, 0.9889547228813171, 0.983027994632721, 0.9797952771186829, 0.9892241358757019, 0.9913793206214905, 0.9876077771186829, 0.990571141242981, 0.9913793206214905, 0.990571141242981, 0.9916487336158752, 0.990840494632721, 0.9889547228813171, 0.9867995977401733, 0.9878771305084229, 0.9921875, 0.9929956793785095, 0.9948814511299133, 0.9929956793785095, 0.9924569129943848, 0.9924569129943848, 0.9959590435028076, 0.993803858757019, 0.9916487336158752, 0.9900323152542114, 0.9929956793785095, 0.9929956793785095, 0.9916487336158752, 0.993534505367279, 0.9951508641242981, 0.993803858757019, 0.9816810488700867], 'val_loss': [0.9759806990623474, 0.9667651057243347, 0.9823507070541382, 1.0000534057617188, 0.9995700120925903, 0.9812708497047424, 1.0189521312713623, 1.0206001996994019, 1.0901179313659668, 1.1433653831481934, 1.1635432243347168, 1.255474328994751, 1.209716558456421, 1.447250485420227, 1.260779857635498, 1.4772038459777832, 1.3739691972732544, 1.150028109550476, 1.0440213680267334, 0.846390426158905, 0.849148154258728, 0.8487746119499207, 0.641169011592865, 0.6102163791656494, 0.6489276885986328, 0.6355133652687073, 0.6711093783378601, 0.6285501718521118, 0.6178144216537476, 0.6525884866714478, 0.6132833957672119, 0.6342830061912537, 0.6160486340522766, 0.6464072465896606, 0.6139514446258545, 0.6675592660903931, 0.6226421594619751, 0.6410132646560669, 0.638108491897583, 0.6397249698638916, 0.6161697506904602, 0.645721435546875, 0.6377546787261963, 0.6367276906967163, 0.6516910791397095, 0.6577401757240295, 0.6443121433258057, 0.6353332996368408, 0.6645367741584778, 0.6434264779090881, 0.687293529510498, 0.6404035091400146, 0.689802885055542, 0.6406275033950806, 0.6389096975326538, 0.6765578985214233, 0.6425092816352844, 0.6502866148948669, 0.6416199207305908, 0.6509557366371155, 0.6434716582298279, 0.651662290096283, 0.6571933627128601, 0.6486983895301819, 0.6466788649559021, 0.6872732043266296, 0.6732572317123413, 0.6907560229301453, 0.6660856604576111, 0.6880190372467041, 0.6630354523658752, 0.6523143649101257, 0.666713297367096, 0.6616959571838379, 0.6553851366043091, 0.6612168550491333, 0.6577076315879822, 0.6774570345878601, 0.6543090343475342, 0.6770402193069458, 0.7055356502532959, 0.6676858067512512, 0.6773682236671448, 0.6697587370872498, 0.6726924180984497, 0.682025134563446, 0.685629665851593, 0.6817831993103027, 0.6843025088310242, 0.7053229808807373, 0.7135334014892578, 0.6834826469421387, 0.6920081973075867, 0.68965083360672, 0.6959272623062134, 0.6734904050827026, 0.712334394454956, 0.6901415586471558, 0.7136715054512024, 0.6934987902641296], 'val_accuracy': [0.5215517282485962, 0.537715494632721, 0.49568966031074524, 0.4881465435028076, 0.4892241358757019, 0.5032327771186829, 0.49353447556495667, 0.4978448152542114, 0.4913793206214905, 0.4903017282485962, 0.49568966031074524, 0.49461206793785095, 0.5193965435028076, 0.5, 0.545258641242981, 0.5366379022598267, 0.5635775923728943, 0.6239224076271057, 0.681034505367279, 0.7650862336158752, 0.7758620977401733, 0.7823275923728943, 0.857758641242981, 0.8717672228813171, 0.8631465435028076, 0.8674569129943848, 0.857758641242981, 0.8771551847457886, 0.8825430870056152, 0.8717672228813171, 0.8836206793785095, 0.8836206793785095, 0.8879310488700867, 0.881465494632721, 0.8976293206214905, 0.8760775923728943, 0.8879310488700867, 0.8803879022598267, 0.8857758641242981, 0.9008620977401733, 0.8987069129943848, 0.8987069129943848, 0.8836206793785095, 0.8846982717514038, 0.8857758641242981, 0.8943965435028076, 0.899784505367279, 0.8965517282485962, 0.8803879022598267, 0.8793103694915771, 0.875, 0.8836206793785095, 0.8771551847457886, 0.8900862336158752, 0.892241358757019, 0.8793103694915771, 0.8965517282485962, 0.8976293206214905, 0.8943965435028076, 0.8879310488700867, 0.9019396305084229, 0.8868534564971924, 0.8857758641242981, 0.899784505367279, 0.8943965435028076, 0.8760775923728943, 0.8760775923728943, 0.8760775923728943, 0.8825430870056152, 0.881465494632721, 0.8825430870056152, 0.8933189511299133, 0.8868534564971924, 0.8943965435028076, 0.8965517282485962, 0.8900862336158752, 0.8933189511299133, 0.8857758641242981, 0.8943965435028076, 0.8943965435028076, 0.875, 0.8868534564971924, 0.889008641242981, 0.8933189511299133, 0.8846982717514038, 0.8879310488700867, 0.8954741358757019, 0.8879310488700867, 0.8879310488700867, 0.8825430870056152, 0.8825430870056152, 0.8846982717514038, 0.8879310488700867, 0.8879310488700867, 0.8793103694915771, 0.892241358757019, 0.8825430870056152, 0.8900862336158752, 0.8803879022598267, 0.8911637663841248]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.4699 - accuracy: 0.9363"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 9s 61ms/step - loss: 0.4701 - accuracy: 0.9363 - val_loss: 0.9603 - val_accuracy: 0.6380\n","Epoch 2/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4414 - accuracy: 0.9553 - val_loss: 0.9729 - val_accuracy: 0.5215\n","Epoch 3/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4424 - accuracy: 0.9488 - val_loss: 0.9790 - val_accuracy: 0.5090\n","Epoch 4/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4274 - accuracy: 0.9547 - val_loss: 0.9713 - val_accuracy: 0.5170\n","Epoch 5/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4283 - accuracy: 0.9556 - val_loss: 0.9635 - val_accuracy: 0.5283\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4273 - accuracy: 0.9556 - val_loss: 0.9962 - val_accuracy: 0.5034\n","Epoch 7/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4281 - accuracy: 0.9584 - val_loss: 1.0220 - val_accuracy: 0.5034\n","Epoch 8/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4171 - accuracy: 0.9587 - val_loss: 1.0137 - val_accuracy: 0.5068\n","Epoch 9/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4108 - accuracy: 0.9615 - val_loss: 1.0891 - val_accuracy: 0.5023\n","Epoch 10/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4114 - accuracy: 0.9615 - val_loss: 1.0747 - val_accuracy: 0.5079\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4079 - accuracy: 0.9641 - val_loss: 1.1048 - val_accuracy: 0.5124\n","Epoch 12/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4025 - accuracy: 0.9666 - val_loss: 1.1822 - val_accuracy: 0.5124\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4251 - accuracy: 0.9533 - val_loss: 1.1517 - val_accuracy: 0.5294\n","Epoch 14/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4067 - accuracy: 0.9649 - val_loss: 1.0983 - val_accuracy: 0.5588\n","Epoch 15/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3988 - accuracy: 0.9669 - val_loss: 1.2018 - val_accuracy: 0.5532\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3984 - accuracy: 0.9689 - val_loss: 1.3057 - val_accuracy: 0.5554\n","Epoch 17/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3972 - accuracy: 0.9672 - val_loss: 1.2090 - val_accuracy: 0.5984\n","Epoch 18/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3866 - accuracy: 0.9728 - val_loss: 1.0538 - val_accuracy: 0.6516\n","Epoch 19/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.3876 - accuracy: 0.9731 - val_loss: 0.9827 - val_accuracy: 0.6968\n","Epoch 20/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.4020 - accuracy: 0.9635 - val_loss: 0.9009 - val_accuracy: 0.7387\n","Epoch 21/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.4045 - accuracy: 0.9615 - val_loss: 0.8253 - val_accuracy: 0.7760\n","Epoch 22/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.3868 - accuracy: 0.9714 - val_loss: 0.8063 - val_accuracy: 0.7885\n","Epoch 23/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.3804 - accuracy: 0.9745 - val_loss: 0.6956 - val_accuracy: 0.8416\n","Epoch 24/100\n","28/28 [==============================] - 1s 43ms/step - loss: 0.3812 - accuracy: 0.9740 - val_loss: 0.6662 - val_accuracy: 0.8529\n","Epoch 25/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4059 - accuracy: 0.9615 - val_loss: 0.6138 - val_accuracy: 0.8790\n","Epoch 26/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.4022 - accuracy: 0.9641 - val_loss: 0.6088 - val_accuracy: 0.8824\n","Epoch 27/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3876 - accuracy: 0.9677 - val_loss: 0.6658 - val_accuracy: 0.8586\n","Epoch 28/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3796 - accuracy: 0.9726 - val_loss: 0.6166 - val_accuracy: 0.8812\n","Epoch 29/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3727 - accuracy: 0.9774 - val_loss: 0.6082 - val_accuracy: 0.8790\n","Epoch 30/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3687 - accuracy: 0.9782 - val_loss: 0.6329 - val_accuracy: 0.8790\n","Epoch 31/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3763 - accuracy: 0.9759 - val_loss: 0.6225 - val_accuracy: 0.8812\n","Epoch 32/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3670 - accuracy: 0.9796 - val_loss: 0.6303 - val_accuracy: 0.8801\n","Epoch 33/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3770 - accuracy: 0.9711 - val_loss: 0.6608 - val_accuracy: 0.8710\n","Epoch 34/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3658 - accuracy: 0.9782 - val_loss: 0.6501 - val_accuracy: 0.8824\n","Epoch 35/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3738 - accuracy: 0.9726 - val_loss: 0.6716 - val_accuracy: 0.8722\n","Epoch 36/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3686 - accuracy: 0.9768 - val_loss: 0.6455 - val_accuracy: 0.8699\n","Epoch 37/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3579 - accuracy: 0.9827 - val_loss: 0.6577 - val_accuracy: 0.8733\n","Epoch 38/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3650 - accuracy: 0.9791 - val_loss: 0.6409 - val_accuracy: 0.8824\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3525 - accuracy: 0.9853 - val_loss: 0.6541 - val_accuracy: 0.8767\n","Epoch 40/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3579 - accuracy: 0.9819 - val_loss: 0.6545 - val_accuracy: 0.8778\n","Epoch 41/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3663 - accuracy: 0.9734 - val_loss: 0.6571 - val_accuracy: 0.8801\n","Epoch 42/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3667 - accuracy: 0.9737 - val_loss: 0.6498 - val_accuracy: 0.8801\n","Epoch 43/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3636 - accuracy: 0.9745 - val_loss: 0.6578 - val_accuracy: 0.8801\n","Epoch 44/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3578 - accuracy: 0.9768 - val_loss: 0.6438 - val_accuracy: 0.8790\n","Epoch 45/100\n","28/28 [==============================] - 2s 74ms/step - loss: 0.3516 - accuracy: 0.9827 - val_loss: 0.6543 - val_accuracy: 0.8846\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3472 - accuracy: 0.9844 - val_loss: 0.6679 - val_accuracy: 0.8767\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3521 - accuracy: 0.9799 - val_loss: 0.6736 - val_accuracy: 0.8824\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3505 - accuracy: 0.9822 - val_loss: 0.6665 - val_accuracy: 0.8824\n","Epoch 49/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3456 - accuracy: 0.9830 - val_loss: 0.6742 - val_accuracy: 0.8756\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3510 - accuracy: 0.9830 - val_loss: 0.6654 - val_accuracy: 0.8744\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3407 - accuracy: 0.9861 - val_loss: 0.6601 - val_accuracy: 0.8812\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3455 - accuracy: 0.9816 - val_loss: 0.6905 - val_accuracy: 0.8643\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3480 - accuracy: 0.9802 - val_loss: 0.7044 - val_accuracy: 0.8722\n","Epoch 54/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3469 - accuracy: 0.9802 - val_loss: 0.6841 - val_accuracy: 0.8722\n","Epoch 55/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3404 - accuracy: 0.9859 - val_loss: 0.6635 - val_accuracy: 0.8756\n","Epoch 56/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3397 - accuracy: 0.9878 - val_loss: 0.6849 - val_accuracy: 0.8744\n","Epoch 57/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3358 - accuracy: 0.9856 - val_loss: 0.6836 - val_accuracy: 0.8756\n","Epoch 58/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3387 - accuracy: 0.9847 - val_loss: 0.6797 - val_accuracy: 0.8733\n","Epoch 59/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3389 - accuracy: 0.9836 - val_loss: 0.6932 - val_accuracy: 0.8710\n","Epoch 60/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3332 - accuracy: 0.9873 - val_loss: 0.6936 - val_accuracy: 0.8688\n","Epoch 61/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3388 - accuracy: 0.9842 - val_loss: 0.6843 - val_accuracy: 0.8790\n","Epoch 62/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3317 - accuracy: 0.9873 - val_loss: 0.6848 - val_accuracy: 0.8790\n","Epoch 63/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3334 - accuracy: 0.9861 - val_loss: 0.6968 - val_accuracy: 0.8710\n","Epoch 64/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.3312 - accuracy: 0.9867 - val_loss: 0.6992 - val_accuracy: 0.8699\n","Epoch 65/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3380 - accuracy: 0.9808 - val_loss: 0.6817 - val_accuracy: 0.8812\n","Epoch 66/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3351 - accuracy: 0.9861 - val_loss: 0.7193 - val_accuracy: 0.8643\n","Epoch 67/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3335 - accuracy: 0.9844 - val_loss: 0.6970 - val_accuracy: 0.8744\n","Epoch 68/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3476 - accuracy: 0.9779 - val_loss: 0.7291 - val_accuracy: 0.8665\n","Epoch 69/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3316 - accuracy: 0.9864 - val_loss: 0.6976 - val_accuracy: 0.8654\n","Epoch 70/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3219 - accuracy: 0.9915 - val_loss: 0.7006 - val_accuracy: 0.8733\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3204 - accuracy: 0.9912 - val_loss: 0.6883 - val_accuracy: 0.8801\n","Epoch 72/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3259 - accuracy: 0.9864 - val_loss: 0.7131 - val_accuracy: 0.8744\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3298 - accuracy: 0.9861 - val_loss: 0.7631 - val_accuracy: 0.8699\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3308 - accuracy: 0.9856 - val_loss: 0.7386 - val_accuracy: 0.8665\n","Epoch 75/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3281 - accuracy: 0.9847 - val_loss: 0.7151 - val_accuracy: 0.8733\n","Epoch 76/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3272 - accuracy: 0.9847 - val_loss: 0.7064 - val_accuracy: 0.8699\n","Epoch 77/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3178 - accuracy: 0.9904 - val_loss: 0.7129 - val_accuracy: 0.8722\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3196 - accuracy: 0.9892 - val_loss: 0.7029 - val_accuracy: 0.8710\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3194 - accuracy: 0.9870 - val_loss: 0.7107 - val_accuracy: 0.8733\n","Epoch 80/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3149 - accuracy: 0.9915 - val_loss: 0.7217 - val_accuracy: 0.8756\n","Epoch 81/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3141 - accuracy: 0.9921 - val_loss: 0.7216 - val_accuracy: 0.8722\n","Epoch 82/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3172 - accuracy: 0.9912 - val_loss: 0.7292 - val_accuracy: 0.8654\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3119 - accuracy: 0.9932 - val_loss: 0.7201 - val_accuracy: 0.8733\n","Epoch 84/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3130 - accuracy: 0.9915 - val_loss: 0.7309 - val_accuracy: 0.8722\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3151 - accuracy: 0.9895 - val_loss: 0.7781 - val_accuracy: 0.8665\n","Epoch 86/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3183 - accuracy: 0.9867 - val_loss: 0.7229 - val_accuracy: 0.8643\n","Epoch 87/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3087 - accuracy: 0.9924 - val_loss: 0.7257 - val_accuracy: 0.8722\n","Epoch 88/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3132 - accuracy: 0.9875 - val_loss: 0.7397 - val_accuracy: 0.8688\n","Epoch 89/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3092 - accuracy: 0.9921 - val_loss: 0.7494 - val_accuracy: 0.8756\n","Epoch 90/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3149 - accuracy: 0.9878 - val_loss: 0.7462 - val_accuracy: 0.8676\n","Epoch 91/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3091 - accuracy: 0.9895 - val_loss: 0.7350 - val_accuracy: 0.8699\n","Epoch 92/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3153 - accuracy: 0.9907 - val_loss: 0.7516 - val_accuracy: 0.8654\n","Epoch 93/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3233 - accuracy: 0.9844 - val_loss: 0.7463 - val_accuracy: 0.8710\n","Epoch 94/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3086 - accuracy: 0.9898 - val_loss: 0.7170 - val_accuracy: 0.8665\n","Epoch 95/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3034 - accuracy: 0.9924 - val_loss: 0.7383 - val_accuracy: 0.8654\n","Epoch 96/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3207 - accuracy: 0.9839 - val_loss: 0.7597 - val_accuracy: 0.8756\n","Epoch 97/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3246 - accuracy: 0.9802 - val_loss: 0.8023 - val_accuracy: 0.8597\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3100 - accuracy: 0.9915 - val_loss: 0.7438 - val_accuracy: 0.8643\n","Epoch 99/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3072 - accuracy: 0.9909 - val_loss: 0.7718 - val_accuracy: 0.8699\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3020 - accuracy: 0.9924 - val_loss: 0.7579 - val_accuracy: 0.8620\n","{'loss': [0.47008058428764343, 0.44143831729888916, 0.44235190749168396, 0.42740756273269653, 0.42831841111183167, 0.427275687456131, 0.42812833189964294, 0.4170584976673126, 0.41081443428993225, 0.4114139676094055, 0.4079326391220093, 0.40253788232803345, 0.425067275762558, 0.4066835343837738, 0.39880308508872986, 0.39839601516723633, 0.3971835672855377, 0.38655412197113037, 0.38759705424308777, 0.40195727348327637, 0.40447762608528137, 0.3868423104286194, 0.3803580403327942, 0.38124608993530273, 0.40594592690467834, 0.4022187292575836, 0.3875633180141449, 0.37957897782325745, 0.3727169334888458, 0.3687122166156769, 0.3762986958026886, 0.3669970631599426, 0.37703177332878113, 0.3657768666744232, 0.3738074004650116, 0.3686293661594391, 0.35792648792266846, 0.3650059998035431, 0.35245248675346375, 0.3578607141971588, 0.3662596344947815, 0.3667455017566681, 0.363604873418808, 0.35784807801246643, 0.35164541006088257, 0.34716957807540894, 0.35207876563072205, 0.35051730275154114, 0.3455987870693207, 0.35103344917297363, 0.3407299220561981, 0.34545913338661194, 0.34795376658439636, 0.3468502461910248, 0.34038451313972473, 0.3396839499473572, 0.33578988909721375, 0.33866697549819946, 0.3389239013195038, 0.33318814635276794, 0.3387725055217743, 0.3317103087902069, 0.3334192633628845, 0.3311712443828583, 0.33802810311317444, 0.33506426215171814, 0.33352720737457275, 0.34756389260292053, 0.331598699092865, 0.3218574523925781, 0.32037174701690674, 0.32585692405700684, 0.32982146739959717, 0.33083099126815796, 0.3280622959136963, 0.3272430896759033, 0.3177680969238281, 0.3196236789226532, 0.31939125061035156, 0.31491076946258545, 0.314055472612381, 0.31722292304039, 0.3119193911552429, 0.3129592537879944, 0.31510722637176514, 0.31834787130355835, 0.3087187111377716, 0.3132460415363312, 0.3091687858104706, 0.3148667514324188, 0.30910736322402954, 0.31525543332099915, 0.32330837845802307, 0.308569997549057, 0.30336683988571167, 0.32067081332206726, 0.3246191442012787, 0.30996236205101013, 0.3071768879890442, 0.30197393894195557], 'accuracy': [0.9363327622413635, 0.9552914500236511, 0.9487832188606262, 0.9547255039215088, 0.9555743932723999, 0.9555743932723999, 0.9584040641784668, 0.9586870670318604, 0.9615166783332825, 0.9615166783332825, 0.9640634059906006, 0.9666100740432739, 0.9533106684684753, 0.9649122953414917, 0.9668930172920227, 0.9688737988471985, 0.9671760201454163, 0.9728353023529053, 0.9731183052062988, 0.9634974598884583, 0.9615166783332825, 0.9714204668998718, 0.9745330810546875, 0.9739671945571899, 0.9615166783332825, 0.9640634059906006, 0.9677419066429138, 0.9725523591041565, 0.9773627519607544, 0.9782116413116455, 0.975947916507721, 0.979626476764679, 0.971137523651123, 0.9782116413116455, 0.9725523591041565, 0.9767968058586121, 0.9827390909194946, 0.9790605306625366, 0.9852858185768127, 0.9818902015686035, 0.9734012484550476, 0.9736841917037964, 0.9745330810546875, 0.9767968058586121, 0.9827390909194946, 0.9844368696212769, 0.9799094796180725, 0.9821732044219971, 0.9830220937728882, 0.9830220937728882, 0.9861347079277039, 0.9816072583198547, 0.9801924228668213, 0.9801924228668213, 0.9858517050743103, 0.9878324866294861, 0.9855687618255615, 0.9847198724746704, 0.9835879802703857, 0.9872665405273438, 0.9841539263725281, 0.9872665405273438, 0.9861347079277039, 0.9867005944252014, 0.9807583689689636, 0.9861347079277039, 0.9844368696212769, 0.9779286980628967, 0.9864176511764526, 0.9915110468864441, 0.9912280440330505, 0.9864176511764526, 0.9861347079277039, 0.9855687618255615, 0.9847198724746704, 0.9847198724746704, 0.9903791546821594, 0.9892473220825195, 0.986983597278595, 0.9915110468864441, 0.9920769929885864, 0.9912280440330505, 0.9932088255882263, 0.9915110468864441, 0.9895302653312683, 0.9867005944252014, 0.9923599362373352, 0.9875495433807373, 0.9920769929885864, 0.9878324866294861, 0.9895302653312683, 0.990662157535553, 0.9844368696212769, 0.9898132681846619, 0.9923599362373352, 0.9838709831237793, 0.9801924228668213, 0.9915110468864441, 0.9909451007843018, 0.9923599362373352], 'val_loss': [0.9603040814399719, 0.9728934168815613, 0.9789873361587524, 0.9713015556335449, 0.963547945022583, 0.9961599707603455, 1.0219602584838867, 1.0137255191802979, 1.0890674591064453, 1.0747451782226562, 1.104831576347351, 1.1822054386138916, 1.1517157554626465, 1.0983184576034546, 1.2017744779586792, 1.3057231903076172, 1.2089558839797974, 1.0538418292999268, 0.9827103614807129, 0.9009296298027039, 0.8253264427185059, 0.8063280582427979, 0.6956040263175964, 0.6662441492080688, 0.6138243079185486, 0.6088008880615234, 0.6657776236534119, 0.6165853142738342, 0.6081936359405518, 0.6328586339950562, 0.6225172877311707, 0.6302837133407593, 0.6607900857925415, 0.650114119052887, 0.6715664863586426, 0.6455290913581848, 0.6577289700508118, 0.6409478783607483, 0.6540811061859131, 0.6545000076293945, 0.6570613980293274, 0.6498072147369385, 0.6578212976455688, 0.6438283920288086, 0.6542945504188538, 0.6678882241249084, 0.6736164093017578, 0.6664857268333435, 0.674156904220581, 0.665356457233429, 0.6600747108459473, 0.6905239820480347, 0.7044438123703003, 0.6841387748718262, 0.6635344624519348, 0.6848698258399963, 0.6836238503456116, 0.6797271966934204, 0.6932403445243835, 0.6935984492301941, 0.6843094229698181, 0.6847546696662903, 0.6967535018920898, 0.6991539597511292, 0.681734025478363, 0.7192642688751221, 0.6969568729400635, 0.7290825247764587, 0.697644829750061, 0.7005924582481384, 0.6882887482643127, 0.7131146192550659, 0.7630963325500488, 0.738612711429596, 0.7151294350624084, 0.7063924670219421, 0.7129092216491699, 0.7029327750205994, 0.7106980085372925, 0.7217193245887756, 0.7215811014175415, 0.7291880249977112, 0.7200931310653687, 0.7309222221374512, 0.7780861854553223, 0.722925066947937, 0.7257423400878906, 0.7397022247314453, 0.7494080066680908, 0.7461780309677124, 0.7349836230278015, 0.751620888710022, 0.7463338375091553, 0.7170025706291199, 0.7382543683052063, 0.7597437500953674, 0.8023331165313721, 0.7438271641731262, 0.7718059420585632, 0.7578991651535034], 'val_accuracy': [0.6380090713500977, 0.5214931964874268, 0.5090497732162476, 0.516968309879303, 0.5282805562019348, 0.5033936500549316, 0.5033936500549316, 0.5067873597145081, 0.5022624731063843, 0.5079185366630554, 0.5124434232711792, 0.5124434232711792, 0.529411792755127, 0.5588235259056091, 0.5531674027442932, 0.5554298758506775, 0.598416268825531, 0.651583731174469, 0.6968325972557068, 0.7386877536773682, 0.7760180830955505, 0.7884615659713745, 0.8416289687156677, 0.8529411554336548, 0.8789592981338501, 0.8823529481887817, 0.8585972785949707, 0.8812217116355896, 0.8789592981338501, 0.8789592981338501, 0.8812217116355896, 0.8800904750823975, 0.8710407018661499, 0.8823529481887817, 0.872171938419342, 0.8699095249176025, 0.8733031749725342, 0.8823529481887817, 0.8766968250274658, 0.877828061580658, 0.8800904750823975, 0.8800904750823975, 0.8800904750823975, 0.8789592981338501, 0.8846153616905212, 0.8766968250274658, 0.8823529481887817, 0.8823529481887817, 0.8755655884742737, 0.8744344115257263, 0.8812217116355896, 0.8642534017562866, 0.872171938419342, 0.872171938419342, 0.8755655884742737, 0.8744344115257263, 0.8755655884742737, 0.8733031749725342, 0.8710407018661499, 0.8687782883644104, 0.8789592981338501, 0.8789592981338501, 0.8710407018661499, 0.8699095249176025, 0.8812217116355896, 0.8642534017562866, 0.8744344115257263, 0.8665158152580261, 0.8653846383094788, 0.8733031749725342, 0.8800904750823975, 0.8744344115257263, 0.8699095249176025, 0.8665158152580261, 0.8733031749725342, 0.8699095249176025, 0.872171938419342, 0.8710407018661499, 0.8733031749725342, 0.8755655884742737, 0.872171938419342, 0.8653846383094788, 0.8733031749725342, 0.872171938419342, 0.8665158152580261, 0.8642534017562866, 0.872171938419342, 0.8687782883644104, 0.8755655884742737, 0.8676470518112183, 0.8699095249176025, 0.8653846383094788, 0.8710407018661499, 0.8665158152580261, 0.8653846383094788, 0.8755655884742737, 0.8597285151481628, 0.8642534017562866, 0.8699095249176025, 0.8619909286499023]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.4666 - accuracy: 0.9423"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 53ms/step - loss: 0.4661 - accuracy: 0.9426 - val_loss: 0.9745 - val_accuracy: 0.5248\n","Epoch 2/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4516 - accuracy: 0.9514 - val_loss: 0.9652 - val_accuracy: 0.5382\n","Epoch 3/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4300 - accuracy: 0.9561 - val_loss: 0.9737 - val_accuracy: 0.5031\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4402 - accuracy: 0.9527 - val_loss: 0.9830 - val_accuracy: 0.5010\n","Epoch 5/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4264 - accuracy: 0.9556 - val_loss: 1.0044 - val_accuracy: 0.4959\n","Epoch 6/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4224 - accuracy: 0.9610 - val_loss: 1.0024 - val_accuracy: 0.4990\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4186 - accuracy: 0.9602 - val_loss: 1.0012 - val_accuracy: 0.5031\n","Epoch 8/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4367 - accuracy: 0.9494 - val_loss: 0.9760 - val_accuracy: 0.5248\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4604 - accuracy: 0.9395 - val_loss: 1.0286 - val_accuracy: 0.5114\n","Epoch 10/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4203 - accuracy: 0.9628 - val_loss: 1.1039 - val_accuracy: 0.5031\n","Epoch 11/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4116 - accuracy: 0.9615 - val_loss: 1.2076 - val_accuracy: 0.5000\n","Epoch 12/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4068 - accuracy: 0.9659 - val_loss: 1.1882 - val_accuracy: 0.5165\n","Epoch 13/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4047 - accuracy: 0.9656 - val_loss: 1.2238 - val_accuracy: 0.5227\n","Epoch 14/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4048 - accuracy: 0.9664 - val_loss: 1.2391 - val_accuracy: 0.5382\n","Epoch 15/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3961 - accuracy: 0.9674 - val_loss: 1.2728 - val_accuracy: 0.5527\n","Epoch 16/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3966 - accuracy: 0.9667 - val_loss: 1.2403 - val_accuracy: 0.5857\n","Epoch 17/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3994 - accuracy: 0.9693 - val_loss: 1.2854 - val_accuracy: 0.5981\n","Epoch 18/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4008 - accuracy: 0.9638 - val_loss: 1.2896 - val_accuracy: 0.6219\n","Epoch 19/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4107 - accuracy: 0.9587 - val_loss: 1.0712 - val_accuracy: 0.6870\n","Epoch 20/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3917 - accuracy: 0.9687 - val_loss: 0.7919 - val_accuracy: 0.7934\n","Epoch 21/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3885 - accuracy: 0.9716 - val_loss: 0.7326 - val_accuracy: 0.8182\n","Epoch 22/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3876 - accuracy: 0.9687 - val_loss: 0.7406 - val_accuracy: 0.8254\n","Epoch 23/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3844 - accuracy: 0.9705 - val_loss: 0.7119 - val_accuracy: 0.8409\n","Epoch 24/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3824 - accuracy: 0.9726 - val_loss: 0.6215 - val_accuracy: 0.8812\n","Epoch 25/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4100 - accuracy: 0.9597 - val_loss: 0.6293 - val_accuracy: 0.8771\n","Epoch 26/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3855 - accuracy: 0.9672 - val_loss: 0.6335 - val_accuracy: 0.8791\n","Epoch 27/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3937 - accuracy: 0.9656 - val_loss: 0.6520 - val_accuracy: 0.8750\n","Epoch 28/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3820 - accuracy: 0.9703 - val_loss: 0.6391 - val_accuracy: 0.8791\n","Epoch 29/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3757 - accuracy: 0.9731 - val_loss: 0.7092 - val_accuracy: 0.8554\n","Epoch 30/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3821 - accuracy: 0.9674 - val_loss: 0.7059 - val_accuracy: 0.8554\n","Epoch 31/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3750 - accuracy: 0.9734 - val_loss: 0.6641 - val_accuracy: 0.8812\n","Epoch 32/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3778 - accuracy: 0.9700 - val_loss: 0.6541 - val_accuracy: 0.8895\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3851 - accuracy: 0.9674 - val_loss: 0.6611 - val_accuracy: 0.8771\n","Epoch 34/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3756 - accuracy: 0.9718 - val_loss: 0.6547 - val_accuracy: 0.8812\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3736 - accuracy: 0.9742 - val_loss: 0.6777 - val_accuracy: 0.8719\n","Epoch 36/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3710 - accuracy: 0.9736 - val_loss: 0.6708 - val_accuracy: 0.8760\n","Epoch 37/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3742 - accuracy: 0.9711 - val_loss: 0.6990 - val_accuracy: 0.8657\n","Epoch 38/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4000 - accuracy: 0.9605 - val_loss: 0.6670 - val_accuracy: 0.8771\n","Epoch 39/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3702 - accuracy: 0.9770 - val_loss: 0.6644 - val_accuracy: 0.8864\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3619 - accuracy: 0.9798 - val_loss: 0.6655 - val_accuracy: 0.8802\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3600 - accuracy: 0.9806 - val_loss: 0.6877 - val_accuracy: 0.8853\n","Epoch 42/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3787 - accuracy: 0.9698 - val_loss: 0.6902 - val_accuracy: 0.8843\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3646 - accuracy: 0.9775 - val_loss: 0.6741 - val_accuracy: 0.8781\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3568 - accuracy: 0.9804 - val_loss: 0.6759 - val_accuracy: 0.8698\n","Epoch 45/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3600 - accuracy: 0.9760 - val_loss: 0.6784 - val_accuracy: 0.8853\n","Epoch 46/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3560 - accuracy: 0.9801 - val_loss: 0.6859 - val_accuracy: 0.8843\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3559 - accuracy: 0.9767 - val_loss: 0.6795 - val_accuracy: 0.8729\n","Epoch 48/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3609 - accuracy: 0.9770 - val_loss: 0.7212 - val_accuracy: 0.8657\n","Epoch 49/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3625 - accuracy: 0.9747 - val_loss: 0.6827 - val_accuracy: 0.8740\n","Epoch 50/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3522 - accuracy: 0.9783 - val_loss: 0.7491 - val_accuracy: 0.8533\n","Epoch 51/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3712 - accuracy: 0.9687 - val_loss: 0.7137 - val_accuracy: 0.8667\n","Epoch 52/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3561 - accuracy: 0.9752 - val_loss: 0.6861 - val_accuracy: 0.8833\n","Epoch 53/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3533 - accuracy: 0.9786 - val_loss: 0.6882 - val_accuracy: 0.8791\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3584 - accuracy: 0.9775 - val_loss: 0.7411 - val_accuracy: 0.8729\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3552 - accuracy: 0.9778 - val_loss: 0.7101 - val_accuracy: 0.8781\n","Epoch 56/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3518 - accuracy: 0.9770 - val_loss: 0.6816 - val_accuracy: 0.8802\n","Epoch 57/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3424 - accuracy: 0.9829 - val_loss: 0.6877 - val_accuracy: 0.8833\n","Epoch 58/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3457 - accuracy: 0.9806 - val_loss: 0.6970 - val_accuracy: 0.8657\n","Epoch 59/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3441 - accuracy: 0.9801 - val_loss: 0.7759 - val_accuracy: 0.8523\n","Epoch 60/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3491 - accuracy: 0.9801 - val_loss: 0.6964 - val_accuracy: 0.8843\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3473 - accuracy: 0.9798 - val_loss: 0.7042 - val_accuracy: 0.8812\n","Epoch 62/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3397 - accuracy: 0.9853 - val_loss: 0.6907 - val_accuracy: 0.8853\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3298 - accuracy: 0.9894 - val_loss: 0.7505 - val_accuracy: 0.8605\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3437 - accuracy: 0.9804 - val_loss: 0.6981 - val_accuracy: 0.8802\n","Epoch 65/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3384 - accuracy: 0.9835 - val_loss: 0.7033 - val_accuracy: 0.8802\n","Epoch 66/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3372 - accuracy: 0.9835 - val_loss: 0.7062 - val_accuracy: 0.8781\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3317 - accuracy: 0.9860 - val_loss: 0.7026 - val_accuracy: 0.8802\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3251 - accuracy: 0.9881 - val_loss: 0.7245 - val_accuracy: 0.8802\n","Epoch 69/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3348 - accuracy: 0.9827 - val_loss: 0.7463 - val_accuracy: 0.8585\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3280 - accuracy: 0.9876 - val_loss: 0.7268 - val_accuracy: 0.8698\n","Epoch 71/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3313 - accuracy: 0.9837 - val_loss: 0.7404 - val_accuracy: 0.8605\n","Epoch 72/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3296 - accuracy: 0.9860 - val_loss: 0.7633 - val_accuracy: 0.8595\n","Epoch 73/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3306 - accuracy: 0.9850 - val_loss: 0.7235 - val_accuracy: 0.8740\n","Epoch 74/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3345 - accuracy: 0.9850 - val_loss: 0.7228 - val_accuracy: 0.8812\n","Epoch 75/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3316 - accuracy: 0.9853 - val_loss: 0.7563 - val_accuracy: 0.8771\n","Epoch 76/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3297 - accuracy: 0.9840 - val_loss: 0.7254 - val_accuracy: 0.8812\n","Epoch 77/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3253 - accuracy: 0.9855 - val_loss: 0.7499 - val_accuracy: 0.8802\n","Epoch 78/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3222 - accuracy: 0.9881 - val_loss: 0.7260 - val_accuracy: 0.8771\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3250 - accuracy: 0.9853 - val_loss: 0.7309 - val_accuracy: 0.8771\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3226 - accuracy: 0.9873 - val_loss: 0.7403 - val_accuracy: 0.8822\n","Epoch 81/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3242 - accuracy: 0.9858 - val_loss: 0.7334 - val_accuracy: 0.8812\n","Epoch 82/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3240 - accuracy: 0.9860 - val_loss: 0.7631 - val_accuracy: 0.8626\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3359 - accuracy: 0.9780 - val_loss: 0.7291 - val_accuracy: 0.8760\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3260 - accuracy: 0.9832 - val_loss: 0.7296 - val_accuracy: 0.8781\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3136 - accuracy: 0.9907 - val_loss: 0.7743 - val_accuracy: 0.8750\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3617 - accuracy: 0.9667 - val_loss: 0.7472 - val_accuracy: 0.8760\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3213 - accuracy: 0.9863 - val_loss: 0.7435 - val_accuracy: 0.8698\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3199 - accuracy: 0.9866 - val_loss: 0.8010 - val_accuracy: 0.8574\n","Epoch 89/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3203 - accuracy: 0.9866 - val_loss: 0.7610 - val_accuracy: 0.8657\n","Epoch 90/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3138 - accuracy: 0.9899 - val_loss: 0.7469 - val_accuracy: 0.8678\n","Epoch 91/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3085 - accuracy: 0.9915 - val_loss: 0.7240 - val_accuracy: 0.8729\n","Epoch 92/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3073 - accuracy: 0.9920 - val_loss: 0.7381 - val_accuracy: 0.8791\n","Epoch 93/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3143 - accuracy: 0.9868 - val_loss: 0.7594 - val_accuracy: 0.8636\n","Epoch 94/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3093 - accuracy: 0.9899 - val_loss: 0.7602 - val_accuracy: 0.8781\n","Epoch 95/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3111 - accuracy: 0.9881 - val_loss: 0.7574 - val_accuracy: 0.8636\n","Epoch 96/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3127 - accuracy: 0.9891 - val_loss: 0.9026 - val_accuracy: 0.8409\n","Epoch 97/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3319 - accuracy: 0.9788 - val_loss: 0.7629 - val_accuracy: 0.8647\n","Epoch 98/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3042 - accuracy: 0.9910 - val_loss: 0.8190 - val_accuracy: 0.8636\n","Epoch 99/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3069 - accuracy: 0.9897 - val_loss: 0.8276 - val_accuracy: 0.8698\n","Epoch 100/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3305 - accuracy: 0.9796 - val_loss: 0.7496 - val_accuracy: 0.8740\n","{'loss': [0.46610695123672485, 0.4515850245952606, 0.4300418496131897, 0.44016996026039124, 0.42640450596809387, 0.42241474986076355, 0.4186346232891083, 0.4367467164993286, 0.46036258339881897, 0.42028263211250305, 0.41158005595207214, 0.40679025650024414, 0.40474754571914673, 0.40475237369537354, 0.3960858881473541, 0.39660412073135376, 0.39944151043891907, 0.40078333020210266, 0.4106994867324829, 0.39170846343040466, 0.3884516656398773, 0.38764438033103943, 0.38441208004951477, 0.3823501169681549, 0.4099571108818054, 0.3854563534259796, 0.39373713731765747, 0.38197511434555054, 0.3756953775882721, 0.38214418292045593, 0.37501949071884155, 0.3777850270271301, 0.38511693477630615, 0.3755859136581421, 0.3735847473144531, 0.37100353837013245, 0.3742101788520813, 0.40001702308654785, 0.37019070982933044, 0.3619084060192108, 0.35998326539993286, 0.37873250246047974, 0.3646082580089569, 0.35677406191825867, 0.35999444127082825, 0.3560132682323456, 0.35589107871055603, 0.3608984649181366, 0.3624967932701111, 0.3521919548511505, 0.37115243077278137, 0.3561135232448578, 0.353312611579895, 0.35843154788017273, 0.35520297288894653, 0.3517875671386719, 0.34242498874664307, 0.34574416279792786, 0.3441199064254761, 0.3491423428058624, 0.34725049138069153, 0.3397192656993866, 0.3297516703605652, 0.34372711181640625, 0.33840999007225037, 0.33723393082618713, 0.3317483067512512, 0.32508203387260437, 0.3348093032836914, 0.32800641655921936, 0.33134180307388306, 0.3296384811401367, 0.33055415749549866, 0.33451059460639954, 0.3316449224948883, 0.3297075629234314, 0.3252697288990021, 0.3222050964832306, 0.32496508955955505, 0.32258450984954834, 0.3241797089576721, 0.3240177631378174, 0.33589085936546326, 0.32599911093711853, 0.313551127910614, 0.3616980314254761, 0.3213439881801605, 0.3199382424354553, 0.32030826807022095, 0.31383123993873596, 0.3084641098976135, 0.3072500228881836, 0.3143136203289032, 0.3093178868293762, 0.3111322820186615, 0.31269899010658264, 0.33186301589012146, 0.30419719219207764, 0.3069244921207428, 0.33051106333732605], 'accuracy': [0.9426356554031372, 0.9514212012290955, 0.9560723304748535, 0.9527131915092468, 0.9555555582046509, 0.9609819054603577, 0.9602067470550537, 0.9493539929389954, 0.9395349025726318, 0.9627906680107117, 0.9614987373352051, 0.9658914804458618, 0.9656330943107605, 0.9664082527160645, 0.9674418568611145, 0.9666666388511658, 0.9692506194114685, 0.9638242721557617, 0.9586563110351562, 0.9687338471412659, 0.9715762138366699, 0.9687338471412659, 0.9705426096916199, 0.97260981798172, 0.9596899151802063, 0.9671834707260132, 0.9656330943107605, 0.9702842235565186, 0.9731265902519226, 0.9674418568611145, 0.9733850359916687, 0.9700258374214172, 0.9674418568611145, 0.9718345999717712, 0.9741601943969727, 0.97364342212677, 0.9710594415664673, 0.960465133190155, 0.9770025610923767, 0.9798449873924255, 0.9806201457977295, 0.9697674512863159, 0.9775193929672241, 0.9803617596626282, 0.9759690165519714, 0.9801033735275269, 0.9767441749572754, 0.9770025610923767, 0.9746770262718201, 0.9782945513725281, 0.9687338471412659, 0.9751937985420227, 0.9785529971122742, 0.9775193929672241, 0.9777777791023254, 0.9770025610923767, 0.9829457402229309, 0.9806201457977295, 0.9801033735275269, 0.9801033735275269, 0.9798449873924255, 0.9852713346481323, 0.9894056916236877, 0.9803617596626282, 0.9834625124931335, 0.9834625124931335, 0.9860464930534363, 0.9881137013435364, 0.9826873540878296, 0.987596869468689, 0.9837209582328796, 0.9860464930534363, 0.985012948513031, 0.985012948513031, 0.9852713346481323, 0.983979344367981, 0.9855297207832336, 0.9881137013435364, 0.9852713346481323, 0.9873384833335876, 0.985788106918335, 0.9860464930534363, 0.9780361652374268, 0.9832041263580322, 0.9906976819038391, 0.9666666388511658, 0.9863049387931824, 0.9865633249282837, 0.9865633249282837, 0.9899224638938904, 0.9914728403091431, 0.9919896721839905, 0.986821711063385, 0.9899224638938904, 0.9881137013435364, 0.9891473054885864, 0.9788113832473755, 0.9909560680389404, 0.9896640777587891, 0.9795865416526794], 'val_loss': [0.9744788408279419, 0.9651892781257629, 0.9736559987068176, 0.9830494523048401, 1.0043584108352661, 1.0023807287216187, 1.0012115240097046, 0.9760144948959351, 1.0285941362380981, 1.1039257049560547, 1.2075691223144531, 1.188222885131836, 1.223763108253479, 1.2391338348388672, 1.2728188037872314, 1.2403266429901123, 1.2853972911834717, 1.2896288633346558, 1.0712316036224365, 0.7918578386306763, 0.732599139213562, 0.7405844330787659, 0.7118589878082275, 0.6215014457702637, 0.629326581954956, 0.6334737539291382, 0.6520469784736633, 0.6390636563301086, 0.7091888785362244, 0.7058668732643127, 0.6640531420707703, 0.6541460752487183, 0.6610929369926453, 0.6547492742538452, 0.6777273416519165, 0.6707558631896973, 0.6990435123443604, 0.6670095324516296, 0.6644356846809387, 0.6655200123786926, 0.6876974105834961, 0.6901884078979492, 0.6740692257881165, 0.675909698009491, 0.6783546805381775, 0.6858661770820618, 0.6795095801353455, 0.7211533784866333, 0.6826768517494202, 0.7490757703781128, 0.713749349117279, 0.6860929727554321, 0.6881892681121826, 0.7410919666290283, 0.7101367115974426, 0.6816230416297913, 0.6877317428588867, 0.6969594955444336, 0.7759107947349548, 0.6964495182037354, 0.7041837573051453, 0.6906869411468506, 0.7505431175231934, 0.6980526447296143, 0.7033471465110779, 0.7062345147132874, 0.7026323676109314, 0.7245278358459473, 0.7463183403015137, 0.7268257737159729, 0.7404379844665527, 0.763340950012207, 0.7234855890274048, 0.7227795720100403, 0.7563342452049255, 0.72541344165802, 0.7498889565467834, 0.726043701171875, 0.7308977842330933, 0.7402560114860535, 0.7333523631095886, 0.7630531787872314, 0.7290505766868591, 0.7295696139335632, 0.7742913961410522, 0.7471648454666138, 0.7435413599014282, 0.8010320067405701, 0.7609830498695374, 0.7468867301940918, 0.7240404486656189, 0.7381033897399902, 0.7594432234764099, 0.7602009177207947, 0.7574343085289001, 0.9026162624359131, 0.7629427909851074, 0.818988025188446, 0.8275718092918396, 0.7496288418769836], 'val_accuracy': [0.5247933864593506, 0.538223147392273, 0.5030992031097412, 0.5010330677032471, 0.4958677589893341, 0.49896693229675293, 0.5030992031097412, 0.5247933864593506, 0.5113636255264282, 0.5030992031097412, 0.5, 0.5165289044380188, 0.5227272510528564, 0.538223147392273, 0.5526859760284424, 0.58574378490448, 0.5981404781341553, 0.6219007968902588, 0.6869834661483765, 0.7933884263038635, 0.8181818127632141, 0.8254132270812988, 0.8409090638160706, 0.8811983466148376, 0.8770661354064941, 0.8791322112083435, 0.875, 0.8791322112083435, 0.85537189245224, 0.85537189245224, 0.8811983466148376, 0.8894628286361694, 0.8770661354064941, 0.8811983466148376, 0.8719007968902588, 0.8760330677032471, 0.8657024502754211, 0.8770661354064941, 0.8863636255264282, 0.8801652789115906, 0.8853305578231812, 0.8842975497245789, 0.8780992031097412, 0.8698347210884094, 0.8853305578231812, 0.8842975497245789, 0.8729338645935059, 0.8657024502754211, 0.8739669322967529, 0.8533057570457458, 0.8667355179786682, 0.8832644820213318, 0.8791322112083435, 0.8729338645935059, 0.8780992031097412, 0.8801652789115906, 0.8832644820213318, 0.8657024502754211, 0.8522727489471436, 0.8842975497245789, 0.8811983466148376, 0.8853305578231812, 0.8605371713638306, 0.8801652789115906, 0.8801652789115906, 0.8780992031097412, 0.8801652789115906, 0.8801652789115906, 0.8584710955619812, 0.8698347210884094, 0.8605371713638306, 0.8595041036605835, 0.8739669322967529, 0.8811983466148376, 0.8770661354064941, 0.8811983466148376, 0.8801652789115906, 0.8770661354064941, 0.8770661354064941, 0.8822314143180847, 0.8811983466148376, 0.8626033067703247, 0.8760330677032471, 0.8780992031097412, 0.875, 0.8760330677032471, 0.8698347210884094, 0.8574380278587341, 0.8657024502754211, 0.8677685856819153, 0.8729338645935059, 0.8791322112083435, 0.8636363744735718, 0.8780992031097412, 0.8636363744735718, 0.8409090638160706, 0.8646694421768188, 0.8636363744735718, 0.8698347210884094, 0.8739669322967529]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.3627 - accuracy: 0.9690"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 56ms/step - loss: 0.3631 - accuracy: 0.9682 - val_loss: 0.9341 - val_accuracy: 0.5151\n","Epoch 2/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3645 - accuracy: 0.9669 - val_loss: 0.9421 - val_accuracy: 0.5000\n","Epoch 3/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3493 - accuracy: 0.9733 - val_loss: 0.9522 - val_accuracy: 0.4957\n","Epoch 4/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3360 - accuracy: 0.9790 - val_loss: 0.9808 - val_accuracy: 0.4881\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3277 - accuracy: 0.9806 - val_loss: 1.0102 - val_accuracy: 0.4881\n","Epoch 6/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3174 - accuracy: 0.9852 - val_loss: 1.0250 - val_accuracy: 0.4881\n","Epoch 7/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3177 - accuracy: 0.9871 - val_loss: 1.0592 - val_accuracy: 0.4881\n","Epoch 8/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3211 - accuracy: 0.9836 - val_loss: 1.1116 - val_accuracy: 0.4881\n","Epoch 9/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3159 - accuracy: 0.9855 - val_loss: 1.1563 - val_accuracy: 0.4903\n","Epoch 10/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3194 - accuracy: 0.9822 - val_loss: 1.3104 - val_accuracy: 0.4881\n","Epoch 11/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3187 - accuracy: 0.9844 - val_loss: 1.4537 - val_accuracy: 0.4881\n","Epoch 12/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3195 - accuracy: 0.9841 - val_loss: 1.3919 - val_accuracy: 0.4946\n","Epoch 13/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3131 - accuracy: 0.9863 - val_loss: 1.4581 - val_accuracy: 0.5075\n","Epoch 14/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3136 - accuracy: 0.9855 - val_loss: 1.4972 - val_accuracy: 0.5259\n","Epoch 15/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3115 - accuracy: 0.9857 - val_loss: 1.5031 - val_accuracy: 0.5388\n","Epoch 16/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.3100 - accuracy: 0.9871 - val_loss: 1.6344 - val_accuracy: 0.5463\n","Epoch 17/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.3112 - accuracy: 0.9865 - val_loss: 1.4683 - val_accuracy: 0.5819\n","Epoch 18/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.3050 - accuracy: 0.9892 - val_loss: 1.5525 - val_accuracy: 0.5884\n","Epoch 19/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3104 - accuracy: 0.9846 - val_loss: 1.7149 - val_accuracy: 0.5862\n","Epoch 20/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.3061 - accuracy: 0.9868 - val_loss: 1.2295 - val_accuracy: 0.6983\n","Epoch 21/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3018 - accuracy: 0.9903 - val_loss: 0.9405 - val_accuracy: 0.7629\n","Epoch 22/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3031 - accuracy: 0.9887 - val_loss: 0.8918 - val_accuracy: 0.7823\n","Epoch 23/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.2986 - accuracy: 0.9900 - val_loss: 0.8059 - val_accuracy: 0.8233\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3040 - accuracy: 0.9860 - val_loss: 0.9301 - val_accuracy: 0.7942\n","Epoch 25/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3043 - accuracy: 0.9884 - val_loss: 0.5330 - val_accuracy: 0.9052\n","Epoch 26/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2988 - accuracy: 0.9881 - val_loss: 0.6295 - val_accuracy: 0.8728\n","Epoch 27/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3020 - accuracy: 0.9865 - val_loss: 0.6074 - val_accuracy: 0.8836\n","Epoch 28/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2960 - accuracy: 0.9919 - val_loss: 0.5478 - val_accuracy: 0.9041\n","Epoch 29/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3153 - accuracy: 0.9814 - val_loss: 0.5383 - val_accuracy: 0.9192\n","Epoch 30/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3026 - accuracy: 0.9884 - val_loss: 0.5352 - val_accuracy: 0.9256\n","Epoch 31/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2935 - accuracy: 0.9911 - val_loss: 0.5346 - val_accuracy: 0.9256\n","Epoch 32/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2929 - accuracy: 0.9911 - val_loss: 0.5497 - val_accuracy: 0.9095\n","Epoch 33/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2929 - accuracy: 0.9911 - val_loss: 0.5470 - val_accuracy: 0.9246\n","Epoch 34/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2919 - accuracy: 0.9914 - val_loss: 0.5507 - val_accuracy: 0.9127\n","Epoch 35/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2906 - accuracy: 0.9903 - val_loss: 0.5654 - val_accuracy: 0.9138\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2969 - accuracy: 0.9876 - val_loss: 0.5737 - val_accuracy: 0.9127\n","Epoch 37/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3245 - accuracy: 0.9776 - val_loss: 0.5575 - val_accuracy: 0.9246\n","Epoch 38/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2907 - accuracy: 0.9914 - val_loss: 0.5529 - val_accuracy: 0.9256\n","Epoch 39/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2945 - accuracy: 0.9871 - val_loss: 0.5467 - val_accuracy: 0.9181\n","Epoch 40/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2918 - accuracy: 0.9887 - val_loss: 0.5507 - val_accuracy: 0.9159\n","Epoch 41/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2885 - accuracy: 0.9914 - val_loss: 0.5575 - val_accuracy: 0.9062\n","Epoch 42/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.2877 - accuracy: 0.9922 - val_loss: 0.5743 - val_accuracy: 0.9062\n","Epoch 43/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2819 - accuracy: 0.9935 - val_loss: 0.5514 - val_accuracy: 0.9116\n","Epoch 44/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2870 - accuracy: 0.9922 - val_loss: 0.5715 - val_accuracy: 0.9106\n","Epoch 45/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2931 - accuracy: 0.9881 - val_loss: 0.5715 - val_accuracy: 0.9192\n","Epoch 46/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2870 - accuracy: 0.9903 - val_loss: 0.5767 - val_accuracy: 0.9062\n","Epoch 47/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2854 - accuracy: 0.9911 - val_loss: 0.5486 - val_accuracy: 0.9170\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2813 - accuracy: 0.9938 - val_loss: 0.5620 - val_accuracy: 0.9106\n","Epoch 49/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2765 - accuracy: 0.9965 - val_loss: 0.5718 - val_accuracy: 0.9095\n","Epoch 50/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2826 - accuracy: 0.9927 - val_loss: 0.5651 - val_accuracy: 0.9127\n","Epoch 51/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2887 - accuracy: 0.9881 - val_loss: 0.5845 - val_accuracy: 0.9127\n","Epoch 52/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2820 - accuracy: 0.9919 - val_loss: 0.6398 - val_accuracy: 0.8976\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2836 - accuracy: 0.9903 - val_loss: 0.5574 - val_accuracy: 0.9192\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2798 - accuracy: 0.9935 - val_loss: 0.5574 - val_accuracy: 0.9138\n","Epoch 55/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2762 - accuracy: 0.9927 - val_loss: 0.5616 - val_accuracy: 0.9138\n","Epoch 56/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2757 - accuracy: 0.9949 - val_loss: 0.5710 - val_accuracy: 0.9106\n","Epoch 57/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2787 - accuracy: 0.9906 - val_loss: 0.6041 - val_accuracy: 0.9009\n","Epoch 58/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2812 - accuracy: 0.9914 - val_loss: 0.5780 - val_accuracy: 0.9095\n","Epoch 59/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2744 - accuracy: 0.9938 - val_loss: 0.5778 - val_accuracy: 0.9095\n","Epoch 60/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2737 - accuracy: 0.9935 - val_loss: 0.5684 - val_accuracy: 0.9073\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2748 - accuracy: 0.9938 - val_loss: 0.5926 - val_accuracy: 0.9106\n","Epoch 62/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2748 - accuracy: 0.9930 - val_loss: 0.5813 - val_accuracy: 0.9116\n","Epoch 63/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2760 - accuracy: 0.9927 - val_loss: 0.5705 - val_accuracy: 0.9138\n","Epoch 64/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2682 - accuracy: 0.9968 - val_loss: 0.5803 - val_accuracy: 0.9138\n","Epoch 65/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2684 - accuracy: 0.9960 - val_loss: 0.5767 - val_accuracy: 0.9170\n","Epoch 66/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2688 - accuracy: 0.9960 - val_loss: 0.6261 - val_accuracy: 0.8976\n","Epoch 67/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2723 - accuracy: 0.9938 - val_loss: 0.5538 - val_accuracy: 0.9224\n","Epoch 68/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2683 - accuracy: 0.9960 - val_loss: 0.5658 - val_accuracy: 0.9224\n","Epoch 69/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2731 - accuracy: 0.9930 - val_loss: 0.5857 - val_accuracy: 0.9041\n","Epoch 70/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2722 - accuracy: 0.9922 - val_loss: 0.5746 - val_accuracy: 0.9106\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2699 - accuracy: 0.9949 - val_loss: 0.6526 - val_accuracy: 0.8912\n","Epoch 72/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2838 - accuracy: 0.9863 - val_loss: 0.5831 - val_accuracy: 0.9041\n","Epoch 73/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2655 - accuracy: 0.9968 - val_loss: 0.6014 - val_accuracy: 0.9009\n","Epoch 74/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2676 - accuracy: 0.9949 - val_loss: 0.5625 - val_accuracy: 0.9246\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2673 - accuracy: 0.9943 - val_loss: 0.5822 - val_accuracy: 0.9170\n","Epoch 76/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2762 - accuracy: 0.9914 - val_loss: 0.5650 - val_accuracy: 0.9181\n","Epoch 77/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2983 - accuracy: 0.9801 - val_loss: 0.5986 - val_accuracy: 0.9116\n","Epoch 78/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2700 - accuracy: 0.9922 - val_loss: 0.5670 - val_accuracy: 0.9138\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2601 - accuracy: 0.9970 - val_loss: 0.6221 - val_accuracy: 0.8987\n","Epoch 80/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2615 - accuracy: 0.9952 - val_loss: 0.5835 - val_accuracy: 0.9138\n","Epoch 81/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2606 - accuracy: 0.9968 - val_loss: 0.5831 - val_accuracy: 0.9052\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2579 - accuracy: 0.9973 - val_loss: 0.5878 - val_accuracy: 0.9062\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2557 - accuracy: 0.9984 - val_loss: 0.6052 - val_accuracy: 0.9041\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2553 - accuracy: 0.9976 - val_loss: 0.6194 - val_accuracy: 0.9009\n","Epoch 85/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2571 - accuracy: 0.9973 - val_loss: 0.5890 - val_accuracy: 0.9084\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2608 - accuracy: 0.9949 - val_loss: 0.6203 - val_accuracy: 0.8998\n","Epoch 87/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2593 - accuracy: 0.9952 - val_loss: 0.6014 - val_accuracy: 0.9030\n","Epoch 88/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2562 - accuracy: 0.9973 - val_loss: 0.6007 - val_accuracy: 0.9084\n","Epoch 89/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2559 - accuracy: 0.9968 - val_loss: 0.6000 - val_accuracy: 0.9224\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2576 - accuracy: 0.9952 - val_loss: 0.6546 - val_accuracy: 0.8944\n","Epoch 91/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2535 - accuracy: 0.9976 - val_loss: 0.6346 - val_accuracy: 0.9009\n","Epoch 92/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2596 - accuracy: 0.9943 - val_loss: 0.7050 - val_accuracy: 0.8879\n","Epoch 93/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2705 - accuracy: 0.9908 - val_loss: 0.7425 - val_accuracy: 0.8782\n","Epoch 94/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2638 - accuracy: 0.9933 - val_loss: 0.6686 - val_accuracy: 0.8890\n","Epoch 95/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2566 - accuracy: 0.9946 - val_loss: 0.5837 - val_accuracy: 0.9127\n","Epoch 96/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2517 - accuracy: 0.9968 - val_loss: 0.6004 - val_accuracy: 0.9170\n","Epoch 97/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2523 - accuracy: 0.9965 - val_loss: 0.6495 - val_accuracy: 0.8944\n","Epoch 98/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2564 - accuracy: 0.9949 - val_loss: 0.5995 - val_accuracy: 0.9159\n","Epoch 99/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2531 - accuracy: 0.9960 - val_loss: 0.6083 - val_accuracy: 0.9041\n","Epoch 100/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2531 - accuracy: 0.9952 - val_loss: 0.6155 - val_accuracy: 0.9052\n","{'loss': [0.3631078600883484, 0.364459365606308, 0.349325954914093, 0.33599284291267395, 0.3277072012424469, 0.3174026310443878, 0.3177131116390228, 0.3210544288158417, 0.31588247418403625, 0.31939488649368286, 0.3187068998813629, 0.3194568157196045, 0.3131137192249298, 0.31359633803367615, 0.3114511966705322, 0.3100469708442688, 0.3111885190010071, 0.3050188422203064, 0.31044548749923706, 0.30606788396835327, 0.30178552865982056, 0.3031122386455536, 0.2986382246017456, 0.30401793122291565, 0.3043077290058136, 0.29877808690071106, 0.3020264506340027, 0.29599615931510925, 0.3153184652328491, 0.30258724093437195, 0.29354915022850037, 0.2929082214832306, 0.2929201126098633, 0.29190924763679504, 0.2906307876110077, 0.2969356179237366, 0.3244856595993042, 0.2907441258430481, 0.29449576139450073, 0.2917533814907074, 0.28846514225006104, 0.2876957654953003, 0.281857430934906, 0.28695011138916016, 0.29310932755470276, 0.28702595829963684, 0.2853706181049347, 0.28128084540367126, 0.2765105962753296, 0.2825637757778168, 0.28869637846946716, 0.2820257544517517, 0.28364601731300354, 0.2797926068305969, 0.2762259244918823, 0.27565884590148926, 0.2787032425403595, 0.2811563313007355, 0.2743525207042694, 0.2737249433994293, 0.2747722268104553, 0.27477186918258667, 0.27598920464515686, 0.2681654691696167, 0.26839885115623474, 0.26883476972579956, 0.27225252985954285, 0.26833420991897583, 0.27307844161987305, 0.27216970920562744, 0.2698718309402466, 0.28382712602615356, 0.2655141055583954, 0.2676171660423279, 0.2672792673110962, 0.27622538805007935, 0.2982594966888428, 0.2699688971042633, 0.26006728410720825, 0.2614908814430237, 0.26063594222068787, 0.2579316198825836, 0.2556723952293396, 0.2552590072154999, 0.25707873702049255, 0.26084667444229126, 0.25934043526649475, 0.25617465376853943, 0.2559121251106262, 0.2576446235179901, 0.2534686326980591, 0.2596096694469452, 0.2704651653766632, 0.26383277773857117, 0.2566290497779846, 0.25165966153144836, 0.25234314799308777, 0.2563791871070862, 0.25313252210617065, 0.25313064455986023], 'accuracy': [0.9682112336158752, 0.9668642282485962, 0.9733297228813171, 0.9789870977401733, 0.9806034564971924, 0.9851831793785095, 0.9870689511299133, 0.9835668206214905, 0.9854525923728943, 0.9822198152542114, 0.984375, 0.9841055870056152, 0.9862607717514038, 0.9854525923728943, 0.985722005367279, 0.9870689511299133, 0.9865301847457886, 0.9892241358757019, 0.9846444129943848, 0.9867995977401733, 0.9903017282485962, 0.9886853694915771, 0.9900323152542114, 0.985991358757019, 0.9884159564971924, 0.9881465435028076, 0.9865301847457886, 0.9919180870056152, 0.9814116358757019, 0.9884159564971924, 0.9911099076271057, 0.9911099076271057, 0.9911099076271057, 0.9913793206214905, 0.9903017282485962, 0.9876077771186829, 0.9776400923728943, 0.9913793206214905, 0.9870689511299133, 0.9886853694915771, 0.9913793206214905, 0.9921875, 0.993534505367279, 0.9921875, 0.9881465435028076, 0.9903017282485962, 0.9911099076271057, 0.993803858757019, 0.9964978694915771, 0.9927262663841248, 0.9881465435028076, 0.9919180870056152, 0.9903017282485962, 0.993534505367279, 0.9927262663841248, 0.9948814511299133, 0.990571141242981, 0.9913793206214905, 0.993803858757019, 0.993534505367279, 0.993803858757019, 0.9929956793785095, 0.9927262663841248, 0.9967672228813171, 0.9959590435028076, 0.9959590435028076, 0.993803858757019, 0.9959590435028076, 0.9929956793785095, 0.9921875, 0.9948814511299133, 0.9862607717514038, 0.9967672228813171, 0.9948814511299133, 0.9943426847457886, 0.9913793206214905, 0.9800646305084229, 0.9921875, 0.9970366358757019, 0.9951508641242981, 0.9967672228813171, 0.9973060488700867, 0.998383641242981, 0.9975754022598267, 0.9973060488700867, 0.9948814511299133, 0.9951508641242981, 0.9973060488700867, 0.9967672228813171, 0.9951508641242981, 0.9975754022598267, 0.9943426847457886, 0.990840494632721, 0.9932650923728943, 0.9946120977401733, 0.9967672228813171, 0.9964978694915771, 0.9948814511299133, 0.9959590435028076, 0.9951508641242981], 'val_loss': [0.9340537786483765, 0.942147970199585, 0.9522441625595093, 0.9807509779930115, 1.0102229118347168, 1.0249654054641724, 1.0591599941253662, 1.1116081476211548, 1.1562775373458862, 1.3104251623153687, 1.4536975622177124, 1.3918513059616089, 1.4580906629562378, 1.497154951095581, 1.5030889511108398, 1.634411334991455, 1.4683390855789185, 1.5524799823760986, 1.7149001359939575, 1.2294937372207642, 0.9404884576797485, 0.8917732834815979, 0.8059319853782654, 0.9301459789276123, 0.5330303311347961, 0.6295427083969116, 0.6073885560035706, 0.5478166341781616, 0.5383113622665405, 0.535213053226471, 0.534633994102478, 0.549727201461792, 0.5470370650291443, 0.5507429838180542, 0.5654195547103882, 0.5736998915672302, 0.5574867129325867, 0.5529053211212158, 0.5466907024383545, 0.5506992340087891, 0.557539701461792, 0.5742827653884888, 0.551360011100769, 0.5714849829673767, 0.5714918375015259, 0.5766952037811279, 0.5486086010932922, 0.5619613528251648, 0.5717825889587402, 0.5650563836097717, 0.5845075249671936, 0.6397635340690613, 0.5574207305908203, 0.5573957562446594, 0.5616487860679626, 0.5709831714630127, 0.6040553450584412, 0.5780011415481567, 0.5778152942657471, 0.568440854549408, 0.592568039894104, 0.5813305974006653, 0.5705093741416931, 0.5802951455116272, 0.5766857266426086, 0.6260653734207153, 0.5537959337234497, 0.5658183097839355, 0.5857358574867249, 0.5746298432350159, 0.6526264548301697, 0.5831029415130615, 0.6014176607131958, 0.5624682307243347, 0.582165539264679, 0.5649818181991577, 0.5986344814300537, 0.5670157074928284, 0.6220999360084534, 0.5834788084030151, 0.5830675363540649, 0.5877910256385803, 0.6051703095436096, 0.6194407343864441, 0.5889700055122375, 0.6203359365463257, 0.6014305353164673, 0.600738525390625, 0.6000071167945862, 0.6545695662498474, 0.6346306204795837, 0.7050288915634155, 0.7425311803817749, 0.6686485409736633, 0.5836594700813293, 0.6003791093826294, 0.6495497226715088, 0.5994530320167542, 0.6082659959793091, 0.6154605150222778], 'val_accuracy': [0.5150862336158752, 0.5, 0.49568966031074524, 0.4881465435028076, 0.4881465435028076, 0.4881465435028076, 0.4881465435028076, 0.4881465435028076, 0.4903017282485962, 0.4881465435028076, 0.4881465435028076, 0.49461206793785095, 0.5075430870056152, 0.5258620977401733, 0.5387930870056152, 0.5463362336158752, 0.5818965435028076, 0.5883620977401733, 0.5862069129943848, 0.6982758641242981, 0.7629310488700867, 0.7823275923728943, 0.8232758641242981, 0.7941810488700867, 0.9051724076271057, 0.8728448152542114, 0.8836206793785095, 0.9040948152542114, 0.9191810488700867, 0.9256465435028076, 0.9256465435028076, 0.9094827771186829, 0.9245689511299133, 0.912715494632721, 0.9137930870056152, 0.912715494632721, 0.9245689511299133, 0.9256465435028076, 0.9181034564971924, 0.9159482717514038, 0.90625, 0.90625, 0.9116379022598267, 0.9105603694915771, 0.9191810488700867, 0.90625, 0.9170258641242981, 0.9105603694915771, 0.9094827771186829, 0.912715494632721, 0.912715494632721, 0.8976293206214905, 0.9191810488700867, 0.9137930870056152, 0.9137930870056152, 0.9105603694915771, 0.9008620977401733, 0.9094827771186829, 0.9094827771186829, 0.9073275923728943, 0.9105603694915771, 0.9116379022598267, 0.9137930870056152, 0.9137930870056152, 0.9170258641242981, 0.8976293206214905, 0.9224137663841248, 0.9224137663841248, 0.9040948152542114, 0.9105603694915771, 0.8911637663841248, 0.9040948152542114, 0.9008620977401733, 0.9245689511299133, 0.9170258641242981, 0.9181034564971924, 0.9116379022598267, 0.9137930870056152, 0.8987069129943848, 0.9137930870056152, 0.9051724076271057, 0.90625, 0.9040948152542114, 0.9008620977401733, 0.9084051847457886, 0.899784505367279, 0.9030172228813171, 0.9084051847457886, 0.9224137663841248, 0.8943965435028076, 0.9008620977401733, 0.8879310488700867, 0.8782327771186829, 0.889008641242981, 0.912715494632721, 0.9170258641242981, 0.8943965435028076, 0.9159482717514038, 0.9040948152542114, 0.9051724076271057]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.3706 - accuracy: 0.9660"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 75ms/step - loss: 0.3711 - accuracy: 0.9655 - val_loss: 0.9224 - val_accuracy: 0.5633\n","Epoch 2/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3493 - accuracy: 0.9728 - val_loss: 0.9398 - val_accuracy: 0.5158\n","Epoch 3/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3528 - accuracy: 0.9734 - val_loss: 0.9412 - val_accuracy: 0.5102\n","Epoch 4/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3369 - accuracy: 0.9782 - val_loss: 0.9325 - val_accuracy: 0.5181\n","Epoch 5/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3299 - accuracy: 0.9819 - val_loss: 0.9838 - val_accuracy: 0.5045\n","Epoch 6/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3298 - accuracy: 0.9796 - val_loss: 1.0015 - val_accuracy: 0.5057\n","Epoch 7/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3258 - accuracy: 0.9839 - val_loss: 1.0128 - val_accuracy: 0.5068\n","Epoch 8/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3205 - accuracy: 0.9842 - val_loss: 1.0687 - val_accuracy: 0.5057\n","Epoch 9/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3180 - accuracy: 0.9867 - val_loss: 1.1779 - val_accuracy: 0.5000\n","Epoch 10/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3284 - accuracy: 0.9808 - val_loss: 1.1330 - val_accuracy: 0.5124\n","Epoch 11/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3200 - accuracy: 0.9825 - val_loss: 1.2234 - val_accuracy: 0.5113\n","Epoch 12/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3185 - accuracy: 0.9833 - val_loss: 1.3337 - val_accuracy: 0.5124\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3134 - accuracy: 0.9870 - val_loss: 1.3679 - val_accuracy: 0.5215\n","Epoch 14/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3132 - accuracy: 0.9875 - val_loss: 1.4127 - val_accuracy: 0.5339\n","Epoch 15/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3129 - accuracy: 0.9825 - val_loss: 1.6750 - val_accuracy: 0.5271\n","Epoch 16/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3138 - accuracy: 0.9842 - val_loss: 1.3579 - val_accuracy: 0.5837\n","Epoch 17/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3173 - accuracy: 0.9810 - val_loss: 1.3898 - val_accuracy: 0.5995\n","Epoch 18/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3152 - accuracy: 0.9827 - val_loss: 1.2402 - val_accuracy: 0.6437\n","Epoch 19/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3155 - accuracy: 0.9830 - val_loss: 1.1966 - val_accuracy: 0.6753\n","Epoch 20/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3076 - accuracy: 0.9887 - val_loss: 0.9916 - val_accuracy: 0.7274\n","Epoch 21/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.3011 - accuracy: 0.9912 - val_loss: 1.0179 - val_accuracy: 0.7364\n","Epoch 22/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.3188 - accuracy: 0.9808 - val_loss: 1.0130 - val_accuracy: 0.7489\n","Epoch 23/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.3074 - accuracy: 0.9861 - val_loss: 0.7477 - val_accuracy: 0.8201\n","Epoch 24/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.3090 - accuracy: 0.9842 - val_loss: 0.6890 - val_accuracy: 0.8609\n","Epoch 25/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3030 - accuracy: 0.9895 - val_loss: 0.7762 - val_accuracy: 0.8281\n","Epoch 26/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3138 - accuracy: 0.9830 - val_loss: 0.7315 - val_accuracy: 0.8495\n","Epoch 27/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3015 - accuracy: 0.9898 - val_loss: 0.5992 - val_accuracy: 0.8891\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3372 - accuracy: 0.9692 - val_loss: 0.7114 - val_accuracy: 0.8676\n","Epoch 29/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3031 - accuracy: 0.9892 - val_loss: 0.5749 - val_accuracy: 0.8993\n","Epoch 30/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.2974 - accuracy: 0.9904 - val_loss: 0.5451 - val_accuracy: 0.9129\n","Epoch 31/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3003 - accuracy: 0.9887 - val_loss: 0.5708 - val_accuracy: 0.8971\n","Epoch 32/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2983 - accuracy: 0.9878 - val_loss: 0.5486 - val_accuracy: 0.9027\n","Epoch 33/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2928 - accuracy: 0.9915 - val_loss: 0.6027 - val_accuracy: 0.8971\n","Epoch 34/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2999 - accuracy: 0.9875 - val_loss: 0.5504 - val_accuracy: 0.9129\n","Epoch 35/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2946 - accuracy: 0.9918 - val_loss: 0.5558 - val_accuracy: 0.9016\n","Epoch 36/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2917 - accuracy: 0.9921 - val_loss: 0.5726 - val_accuracy: 0.9027\n","Epoch 37/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2954 - accuracy: 0.9890 - val_loss: 0.6270 - val_accuracy: 0.8891\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2910 - accuracy: 0.9912 - val_loss: 0.6197 - val_accuracy: 0.8971\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2922 - accuracy: 0.9918 - val_loss: 0.5844 - val_accuracy: 0.8993\n","Epoch 40/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2832 - accuracy: 0.9958 - val_loss: 0.5755 - val_accuracy: 0.9038\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2860 - accuracy: 0.9926 - val_loss: 0.5988 - val_accuracy: 0.8982\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2912 - accuracy: 0.9901 - val_loss: 0.5959 - val_accuracy: 0.8993\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2867 - accuracy: 0.9932 - val_loss: 0.5839 - val_accuracy: 0.8993\n","Epoch 44/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2853 - accuracy: 0.9929 - val_loss: 0.5844 - val_accuracy: 0.9005\n","Epoch 45/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2903 - accuracy: 0.9918 - val_loss: 0.5691 - val_accuracy: 0.9027\n","Epoch 46/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2897 - accuracy: 0.9898 - val_loss: 0.5780 - val_accuracy: 0.9016\n","Epoch 47/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2949 - accuracy: 0.9887 - val_loss: 0.5996 - val_accuracy: 0.9027\n","Epoch 48/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2874 - accuracy: 0.9901 - val_loss: 0.6130 - val_accuracy: 0.8948\n","Epoch 49/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2848 - accuracy: 0.9912 - val_loss: 0.5833 - val_accuracy: 0.8971\n","Epoch 50/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2830 - accuracy: 0.9943 - val_loss: 0.5666 - val_accuracy: 0.9050\n","Epoch 51/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2815 - accuracy: 0.9926 - val_loss: 0.5910 - val_accuracy: 0.9027\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2830 - accuracy: 0.9918 - val_loss: 0.5955 - val_accuracy: 0.8971\n","Epoch 53/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2836 - accuracy: 0.9915 - val_loss: 0.6003 - val_accuracy: 0.9005\n","Epoch 54/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2802 - accuracy: 0.9941 - val_loss: 0.6005 - val_accuracy: 0.8948\n","Epoch 55/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2796 - accuracy: 0.9941 - val_loss: 0.6139 - val_accuracy: 0.8903\n","Epoch 56/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2793 - accuracy: 0.9949 - val_loss: 0.6234 - val_accuracy: 0.8914\n","Epoch 57/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2762 - accuracy: 0.9946 - val_loss: 0.6078 - val_accuracy: 0.8948\n","Epoch 58/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2752 - accuracy: 0.9963 - val_loss: 0.5979 - val_accuracy: 0.8937\n","Epoch 59/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2771 - accuracy: 0.9952 - val_loss: 0.6276 - val_accuracy: 0.8914\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2775 - accuracy: 0.9941 - val_loss: 0.6130 - val_accuracy: 0.8982\n","Epoch 61/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2881 - accuracy: 0.9892 - val_loss: 0.7253 - val_accuracy: 0.8767\n","Epoch 62/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2958 - accuracy: 0.9853 - val_loss: 0.8320 - val_accuracy: 0.8631\n","Epoch 63/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3015 - accuracy: 0.9842 - val_loss: 0.6450 - val_accuracy: 0.8959\n","Epoch 64/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2976 - accuracy: 0.9825 - val_loss: 0.6489 - val_accuracy: 0.8903\n","Epoch 65/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2799 - accuracy: 0.9926 - val_loss: 0.5968 - val_accuracy: 0.9061\n","Epoch 66/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2790 - accuracy: 0.9941 - val_loss: 0.6042 - val_accuracy: 0.9027\n","Epoch 67/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2746 - accuracy: 0.9938 - val_loss: 0.6152 - val_accuracy: 0.9016\n","Epoch 68/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2725 - accuracy: 0.9935 - val_loss: 0.6252 - val_accuracy: 0.8914\n","Epoch 69/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2713 - accuracy: 0.9958 - val_loss: 0.6097 - val_accuracy: 0.8948\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2754 - accuracy: 0.9918 - val_loss: 0.6046 - val_accuracy: 0.9016\n","Epoch 71/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2713 - accuracy: 0.9949 - val_loss: 0.6266 - val_accuracy: 0.8903\n","Epoch 72/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2709 - accuracy: 0.9941 - val_loss: 0.6076 - val_accuracy: 0.9027\n","Epoch 73/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2833 - accuracy: 0.9892 - val_loss: 0.6724 - val_accuracy: 0.8903\n","Epoch 74/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2840 - accuracy: 0.9875 - val_loss: 0.6149 - val_accuracy: 0.8959\n","Epoch 75/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2815 - accuracy: 0.9890 - val_loss: 0.6246 - val_accuracy: 0.8948\n","Epoch 76/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2670 - accuracy: 0.9958 - val_loss: 0.5923 - val_accuracy: 0.8982\n","Epoch 77/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2711 - accuracy: 0.9943 - val_loss: 0.6158 - val_accuracy: 0.9027\n","Epoch 78/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2677 - accuracy: 0.9952 - val_loss: 0.6234 - val_accuracy: 0.8948\n","Epoch 79/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2669 - accuracy: 0.9966 - val_loss: 0.6092 - val_accuracy: 0.8993\n","Epoch 80/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2743 - accuracy: 0.9921 - val_loss: 0.5993 - val_accuracy: 0.9005\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2726 - accuracy: 0.9921 - val_loss: 0.6110 - val_accuracy: 0.8925\n","Epoch 82/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2670 - accuracy: 0.9958 - val_loss: 0.5904 - val_accuracy: 0.9050\n","Epoch 83/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2665 - accuracy: 0.9949 - val_loss: 0.6039 - val_accuracy: 0.8982\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2680 - accuracy: 0.9941 - val_loss: 0.6102 - val_accuracy: 0.8959\n","Epoch 85/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2585 - accuracy: 0.9989 - val_loss: 0.6117 - val_accuracy: 0.8925\n","Epoch 86/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2585 - accuracy: 0.9975 - val_loss: 0.6260 - val_accuracy: 0.8948\n","Epoch 87/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2598 - accuracy: 0.9966 - val_loss: 0.6460 - val_accuracy: 0.8937\n","Epoch 88/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2944 - accuracy: 0.9802 - val_loss: 0.6162 - val_accuracy: 0.8880\n","Epoch 89/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2641 - accuracy: 0.9946 - val_loss: 0.6288 - val_accuracy: 0.8993\n","Epoch 90/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2618 - accuracy: 0.9966 - val_loss: 0.6569 - val_accuracy: 0.8835\n","Epoch 91/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2602 - accuracy: 0.9960 - val_loss: 0.6377 - val_accuracy: 0.8925\n","Epoch 92/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2575 - accuracy: 0.9972 - val_loss: 0.6052 - val_accuracy: 0.8982\n","Epoch 93/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2635 - accuracy: 0.9938 - val_loss: 0.6492 - val_accuracy: 0.8824\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2656 - accuracy: 0.9946 - val_loss: 0.6495 - val_accuracy: 0.8948\n","Epoch 95/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2607 - accuracy: 0.9952 - val_loss: 0.6300 - val_accuracy: 0.8903\n","Epoch 96/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2602 - accuracy: 0.9946 - val_loss: 0.6213 - val_accuracy: 0.8948\n","Epoch 97/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2591 - accuracy: 0.9952 - val_loss: 0.6490 - val_accuracy: 0.8880\n","Epoch 98/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2575 - accuracy: 0.9966 - val_loss: 0.6358 - val_accuracy: 0.8903\n","Epoch 99/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2541 - accuracy: 0.9972 - val_loss: 0.6334 - val_accuracy: 0.8948\n","Epoch 100/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2543 - accuracy: 0.9972 - val_loss: 0.6292 - val_accuracy: 0.8948\n","{'loss': [0.3711433410644531, 0.3493155241012573, 0.3527921736240387, 0.3369268476963043, 0.32985544204711914, 0.3297981917858124, 0.32581955194473267, 0.32047998905181885, 0.3180288076400757, 0.3283909261226654, 0.3199794292449951, 0.3184840977191925, 0.3134203553199768, 0.31323111057281494, 0.31294921040534973, 0.31376132369041443, 0.3173406422138214, 0.3151825964450836, 0.31550106406211853, 0.30761465430259705, 0.30111730098724365, 0.3187698721885681, 0.30739152431488037, 0.3090234100818634, 0.3030211329460144, 0.3138006031513214, 0.3014797270298004, 0.33724525570869446, 0.30312901735305786, 0.29737088084220886, 0.30031901597976685, 0.2983148694038391, 0.2928382158279419, 0.2998550534248352, 0.29457223415374756, 0.29169702529907227, 0.2954378128051758, 0.291020005941391, 0.29224535822868347, 0.2831500768661499, 0.2860407829284668, 0.29119765758514404, 0.28674402832984924, 0.2852807343006134, 0.29027339816093445, 0.2897386848926544, 0.2949061691761017, 0.28744131326675415, 0.2848402261734009, 0.2830445170402527, 0.28146329522132874, 0.28299516439437866, 0.283633828163147, 0.2801670730113983, 0.2796154320240021, 0.27932608127593994, 0.2761577367782593, 0.2752029001712799, 0.2771032452583313, 0.2774769067764282, 0.2880699932575226, 0.29577597975730896, 0.3015258312225342, 0.2975727319717407, 0.279902845621109, 0.2790411114692688, 0.2746228575706482, 0.27254223823547363, 0.2713431417942047, 0.2753722369670868, 0.2712741196155548, 0.27093127369880676, 0.2832883894443512, 0.28395333886146545, 0.2815273106098175, 0.2670116424560547, 0.2710842192173004, 0.26769283413887024, 0.26688873767852783, 0.2743102014064789, 0.2726270258426666, 0.26699942350387573, 0.26647108793258667, 0.2680034339427948, 0.2585352659225464, 0.25848618149757385, 0.2597878575325012, 0.29436933994293213, 0.264064222574234, 0.2618149220943451, 0.2602269649505615, 0.25750845670700073, 0.2634500563144684, 0.26563867926597595, 0.2607019245624542, 0.2601553797721863, 0.25910547375679016, 0.25745320320129395, 0.2540980875492096, 0.2542937695980072], 'accuracy': [0.965478241443634, 0.9728353023529053, 0.9734012484550476, 0.9782116413116455, 0.9818902015686035, 0.979626476764679, 0.9838709831237793, 0.9841539263725281, 0.9867005944252014, 0.9807583689689636, 0.9824561476707458, 0.983305037021637, 0.986983597278595, 0.9875495433807373, 0.9824561476707458, 0.9841539263725281, 0.9810413122177124, 0.9827390909194946, 0.9830220937728882, 0.9886813759803772, 0.9912280440330505, 0.9807583689689636, 0.9861347079277039, 0.9841539263725281, 0.9895302653312683, 0.9830220937728882, 0.9898132681846619, 0.9691567420959473, 0.9892473220825195, 0.9903791546821594, 0.9886813759803772, 0.9878324866294861, 0.9915110468864441, 0.9875495433807373, 0.9917939901351929, 0.9920769929885864, 0.988964319229126, 0.9912280440330505, 0.9917939901351929, 0.9957554936408997, 0.992642879486084, 0.9900962114334106, 0.9932088255882263, 0.9929258823394775, 0.9917939901351929, 0.9898132681846619, 0.9886813759803772, 0.9900962114334106, 0.9912280440330505, 0.994340717792511, 0.992642879486084, 0.9917939901351929, 0.9915110468864441, 0.9940577149391174, 0.9940577149391174, 0.9949066042900085, 0.9946236610412598, 0.996321439743042, 0.9951896071434021, 0.9940577149391174, 0.9892473220825195, 0.9852858185768127, 0.9841539263725281, 0.9824561476707458, 0.992642879486084, 0.9940577149391174, 0.9937747716903687, 0.9934917688369751, 0.9957554936408997, 0.9917939901351929, 0.9949066042900085, 0.9940577149391174, 0.9892473220825195, 0.9875495433807373, 0.988964319229126, 0.9957554936408997, 0.994340717792511, 0.9951896071434021, 0.9966044425964355, 0.9920769929885864, 0.9920769929885864, 0.9957554936408997, 0.9949066042900085, 0.9940577149391174, 0.9988681674003601, 0.9974533319473267, 0.9966044425964355, 0.9801924228668213, 0.9946236610412598, 0.9966044425964355, 0.9960384964942932, 0.9971703290939331, 0.9937747716903687, 0.9946236610412598, 0.9951896071434021, 0.9946236610412598, 0.9951896071434021, 0.9966044425964355, 0.9971703290939331, 0.9971703290939331], 'val_loss': [0.9224345088005066, 0.9397874474525452, 0.9411838054656982, 0.9325270652770996, 0.9838384389877319, 1.0015085935592651, 1.0127817392349243, 1.0687438249588013, 1.177869200706482, 1.1329766511917114, 1.2234095335006714, 1.3336542844772339, 1.3678698539733887, 1.4126996994018555, 1.6749584674835205, 1.357861042022705, 1.3897826671600342, 1.2402034997940063, 1.1966429948806763, 0.9916174411773682, 1.0178682804107666, 1.0130478143692017, 0.7476709485054016, 0.6889910101890564, 0.7762019634246826, 0.731479823589325, 0.5991735458374023, 0.7114036083221436, 0.5748924016952515, 0.5450829267501831, 0.5708467960357666, 0.5485579967498779, 0.6026840806007385, 0.5503531694412231, 0.5558180809020996, 0.5726460218429565, 0.6269915103912354, 0.6197320818901062, 0.5844212770462036, 0.5754801630973816, 0.5988413095474243, 0.5958713889122009, 0.5838683247566223, 0.5844027400016785, 0.5691181421279907, 0.5779829621315002, 0.5995967984199524, 0.6129623055458069, 0.583302915096283, 0.5666362643241882, 0.5909944176673889, 0.595488965511322, 0.6002602577209473, 0.6004859805107117, 0.613885223865509, 0.6233618259429932, 0.6077551245689392, 0.5978916883468628, 0.6276392340660095, 0.6130496859550476, 0.7252597808837891, 0.8319798111915588, 0.6450243592262268, 0.6488673090934753, 0.5967608094215393, 0.6042128801345825, 0.6152169108390808, 0.6251731514930725, 0.609716534614563, 0.6045814752578735, 0.6266409158706665, 0.607602059841156, 0.6724023818969727, 0.6149336695671082, 0.6246340870857239, 0.5923039317131042, 0.6158077716827393, 0.6233746409416199, 0.6092408895492554, 0.5992893576622009, 0.6110380291938782, 0.590428352355957, 0.603924036026001, 0.6102075576782227, 0.6117449998855591, 0.625961184501648, 0.6460114121437073, 0.6162213087081909, 0.6288068294525146, 0.656933069229126, 0.6377150416374207, 0.6052179932594299, 0.6491515636444092, 0.6494794487953186, 0.6299692392349243, 0.6213032007217407, 0.6490100026130676, 0.6357910633087158, 0.6333506107330322, 0.6292259097099304], 'val_accuracy': [0.5633484125137329, 0.5158371329307556, 0.5101810097694397, 0.5180995464324951, 0.5045248866081238, 0.5056561231613159, 0.5067873597145081, 0.5056561231613159, 0.5, 0.5124434232711792, 0.5113122463226318, 0.5124434232711792, 0.5214931964874268, 0.5339366793632507, 0.5271493196487427, 0.5837104320526123, 0.5995475053787231, 0.6436651349067688, 0.6753393411636353, 0.7273755669593811, 0.7364253401756287, 0.7488687634468079, 0.820135772228241, 0.860859751701355, 0.8280543088912964, 0.8495475053787231, 0.889140248298645, 0.8676470518112183, 0.8993212580680847, 0.912895917892456, 0.8970588445663452, 0.9027149081230164, 0.8970588445663452, 0.912895917892456, 0.901583731174469, 0.9027149081230164, 0.889140248298645, 0.8970588445663452, 0.8993212580680847, 0.9038461446762085, 0.8981900215148926, 0.8993212580680847, 0.8993212580680847, 0.9004524946212769, 0.9027149081230164, 0.901583731174469, 0.9027149081230164, 0.8947963714599609, 0.8970588445663452, 0.9049773812294006, 0.9027149081230164, 0.8970588445663452, 0.9004524946212769, 0.8947963714599609, 0.8902714848518372, 0.8914027214050293, 0.8947963714599609, 0.8936651349067688, 0.8914027214050293, 0.8981900215148926, 0.8766968250274658, 0.8631221652030945, 0.8959276080131531, 0.8902714848518372, 0.9061086177825928, 0.9027149081230164, 0.901583731174469, 0.8914027214050293, 0.8947963714599609, 0.901583731174469, 0.8902714848518372, 0.9027149081230164, 0.8902714848518372, 0.8959276080131531, 0.8947963714599609, 0.8981900215148926, 0.9027149081230164, 0.8947963714599609, 0.8993212580680847, 0.9004524946212769, 0.8925339579582214, 0.9049773812294006, 0.8981900215148926, 0.8959276080131531, 0.8925339579582214, 0.8947963714599609, 0.8936651349067688, 0.8880090713500977, 0.8993212580680847, 0.8834841847419739, 0.8925339579582214, 0.8981900215148926, 0.8823529481887817, 0.8947963714599609, 0.8902714848518372, 0.8947963714599609, 0.8880090713500977, 0.8902714848518372, 0.8947963714599609, 0.8947963714599609]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.9625"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 9s 53ms/step - loss: 0.3802 - accuracy: 0.9625 - val_loss: 0.9348 - val_accuracy: 0.5217\n","Epoch 2/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3443 - accuracy: 0.9749 - val_loss: 0.9318 - val_accuracy: 0.5165\n","Epoch 3/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3459 - accuracy: 0.9736 - val_loss: 0.9363 - val_accuracy: 0.5083\n","Epoch 4/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3445 - accuracy: 0.9749 - val_loss: 0.9668 - val_accuracy: 0.4979\n","Epoch 5/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3384 - accuracy: 0.9775 - val_loss: 0.9932 - val_accuracy: 0.4979\n","Epoch 6/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3378 - accuracy: 0.9786 - val_loss: 1.0492 - val_accuracy: 0.4959\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3284 - accuracy: 0.9809 - val_loss: 1.0960 - val_accuracy: 0.4969\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3374 - accuracy: 0.9780 - val_loss: 1.1734 - val_accuracy: 0.4959\n","Epoch 9/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3268 - accuracy: 0.9806 - val_loss: 1.1649 - val_accuracy: 0.5000\n","Epoch 10/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3359 - accuracy: 0.9780 - val_loss: 1.3359 - val_accuracy: 0.4979\n","Epoch 11/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3248 - accuracy: 0.9819 - val_loss: 1.3917 - val_accuracy: 0.5000\n","Epoch 12/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3284 - accuracy: 0.9765 - val_loss: 1.5714 - val_accuracy: 0.5000\n","Epoch 13/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3242 - accuracy: 0.9801 - val_loss: 1.4329 - val_accuracy: 0.5217\n","Epoch 14/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3202 - accuracy: 0.9827 - val_loss: 1.6804 - val_accuracy: 0.5176\n","Epoch 15/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3249 - accuracy: 0.9809 - val_loss: 1.3271 - val_accuracy: 0.5837\n","Epoch 16/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.3230 - accuracy: 0.9788 - val_loss: 1.3287 - val_accuracy: 0.5981\n","Epoch 17/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.3171 - accuracy: 0.9842 - val_loss: 1.0266 - val_accuracy: 0.6932\n","Epoch 18/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.3262 - accuracy: 0.9793 - val_loss: 0.7644 - val_accuracy: 0.7955\n","Epoch 19/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3289 - accuracy: 0.9778 - val_loss: 0.9388 - val_accuracy: 0.7572\n","Epoch 20/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3084 - accuracy: 0.9868 - val_loss: 0.8787 - val_accuracy: 0.7872\n","Epoch 21/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3092 - accuracy: 0.9871 - val_loss: 0.9350 - val_accuracy: 0.7831\n","Epoch 22/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3258 - accuracy: 0.9780 - val_loss: 0.8816 - val_accuracy: 0.8048\n","Epoch 23/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3222 - accuracy: 0.9783 - val_loss: 0.5893 - val_accuracy: 0.8802\n","Epoch 24/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3243 - accuracy: 0.9780 - val_loss: 0.6775 - val_accuracy: 0.8564\n","Epoch 25/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3136 - accuracy: 0.9817 - val_loss: 0.6483 - val_accuracy: 0.8698\n","Epoch 26/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3080 - accuracy: 0.9858 - val_loss: 0.5743 - val_accuracy: 0.9101\n","Epoch 27/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3060 - accuracy: 0.9873 - val_loss: 0.5763 - val_accuracy: 0.9060\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3094 - accuracy: 0.9863 - val_loss: 0.5850 - val_accuracy: 0.9029\n","Epoch 29/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3079 - accuracy: 0.9868 - val_loss: 0.6296 - val_accuracy: 0.8802\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3066 - accuracy: 0.9876 - val_loss: 0.6476 - val_accuracy: 0.8853\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3002 - accuracy: 0.9891 - val_loss: 0.5904 - val_accuracy: 0.9019\n","Epoch 32/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3007 - accuracy: 0.9884 - val_loss: 0.6261 - val_accuracy: 0.8915\n","Epoch 33/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3193 - accuracy: 0.9791 - val_loss: 0.6051 - val_accuracy: 0.8988\n","Epoch 34/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3010 - accuracy: 0.9881 - val_loss: 0.6037 - val_accuracy: 0.9050\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2962 - accuracy: 0.9904 - val_loss: 0.6190 - val_accuracy: 0.9081\n","Epoch 36/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3083 - accuracy: 0.9842 - val_loss: 0.6223 - val_accuracy: 0.8998\n","Epoch 37/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3012 - accuracy: 0.9868 - val_loss: 0.6085 - val_accuracy: 0.8946\n","Epoch 38/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2953 - accuracy: 0.9904 - val_loss: 0.6242 - val_accuracy: 0.9019\n","Epoch 39/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2948 - accuracy: 0.9891 - val_loss: 0.6203 - val_accuracy: 0.9039\n","Epoch 40/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2931 - accuracy: 0.9912 - val_loss: 0.6203 - val_accuracy: 0.8967\n","Epoch 41/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2889 - accuracy: 0.9925 - val_loss: 0.6141 - val_accuracy: 0.9019\n","Epoch 42/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2944 - accuracy: 0.9881 - val_loss: 0.6221 - val_accuracy: 0.8977\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2907 - accuracy: 0.9915 - val_loss: 0.6433 - val_accuracy: 0.8988\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2906 - accuracy: 0.9910 - val_loss: 0.6560 - val_accuracy: 0.8822\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2888 - accuracy: 0.9915 - val_loss: 0.6490 - val_accuracy: 0.8988\n","Epoch 46/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2889 - accuracy: 0.9928 - val_loss: 0.6519 - val_accuracy: 0.9029\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2985 - accuracy: 0.9855 - val_loss: 0.7077 - val_accuracy: 0.8802\n","Epoch 48/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2938 - accuracy: 0.9894 - val_loss: 0.7315 - val_accuracy: 0.8740\n","Epoch 49/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3107 - accuracy: 0.9817 - val_loss: 0.6667 - val_accuracy: 0.8998\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2935 - accuracy: 0.9879 - val_loss: 0.6578 - val_accuracy: 0.8967\n","Epoch 51/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3059 - accuracy: 0.9824 - val_loss: 0.6452 - val_accuracy: 0.8998\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2931 - accuracy: 0.9879 - val_loss: 0.6476 - val_accuracy: 0.8998\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2907 - accuracy: 0.9899 - val_loss: 0.6534 - val_accuracy: 0.8926\n","Epoch 54/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2848 - accuracy: 0.9920 - val_loss: 0.6356 - val_accuracy: 0.9008\n","Epoch 55/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2839 - accuracy: 0.9912 - val_loss: 0.6260 - val_accuracy: 0.9008\n","Epoch 56/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2940 - accuracy: 0.9853 - val_loss: 0.6451 - val_accuracy: 0.9039\n","Epoch 57/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2842 - accuracy: 0.9904 - val_loss: 0.6626 - val_accuracy: 0.8884\n","Epoch 58/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2848 - accuracy: 0.9902 - val_loss: 0.6348 - val_accuracy: 0.8967\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2890 - accuracy: 0.9899 - val_loss: 0.6951 - val_accuracy: 0.8915\n","Epoch 60/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2934 - accuracy: 0.9863 - val_loss: 0.6362 - val_accuracy: 0.8998\n","Epoch 61/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2827 - accuracy: 0.9912 - val_loss: 0.6427 - val_accuracy: 0.8946\n","Epoch 62/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2790 - accuracy: 0.9915 - val_loss: 0.6452 - val_accuracy: 0.8957\n","Epoch 63/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2868 - accuracy: 0.9891 - val_loss: 0.6581 - val_accuracy: 0.8957\n","Epoch 64/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2767 - accuracy: 0.9938 - val_loss: 0.6459 - val_accuracy: 0.9008\n","Epoch 65/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2781 - accuracy: 0.9943 - val_loss: 0.6432 - val_accuracy: 0.8998\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2780 - accuracy: 0.9922 - val_loss: 0.6576 - val_accuracy: 0.8884\n","Epoch 67/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2731 - accuracy: 0.9948 - val_loss: 0.6496 - val_accuracy: 0.8957\n","Epoch 68/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2731 - accuracy: 0.9946 - val_loss: 0.6542 - val_accuracy: 0.8905\n","Epoch 69/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2723 - accuracy: 0.9941 - val_loss: 0.6661 - val_accuracy: 0.8998\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2806 - accuracy: 0.9894 - val_loss: 0.6456 - val_accuracy: 0.8977\n","Epoch 71/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2715 - accuracy: 0.9956 - val_loss: 0.6677 - val_accuracy: 0.8853\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2747 - accuracy: 0.9933 - val_loss: 0.6572 - val_accuracy: 0.8967\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2758 - accuracy: 0.9920 - val_loss: 0.6984 - val_accuracy: 0.8946\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2805 - accuracy: 0.9899 - val_loss: 0.6681 - val_accuracy: 0.8988\n","Epoch 75/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2731 - accuracy: 0.9938 - val_loss: 0.6583 - val_accuracy: 0.8998\n","Epoch 76/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2721 - accuracy: 0.9933 - val_loss: 0.6932 - val_accuracy: 0.8988\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2719 - accuracy: 0.9928 - val_loss: 0.6626 - val_accuracy: 0.8977\n","Epoch 78/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2729 - accuracy: 0.9912 - val_loss: 0.6851 - val_accuracy: 0.8957\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2795 - accuracy: 0.9891 - val_loss: 0.7132 - val_accuracy: 0.8895\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2785 - accuracy: 0.9899 - val_loss: 0.6962 - val_accuracy: 0.8967\n","Epoch 81/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2699 - accuracy: 0.9925 - val_loss: 0.6734 - val_accuracy: 0.8957\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2679 - accuracy: 0.9951 - val_loss: 0.6789 - val_accuracy: 0.8915\n","Epoch 83/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2646 - accuracy: 0.9966 - val_loss: 0.6689 - val_accuracy: 0.8957\n","Epoch 84/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2660 - accuracy: 0.9941 - val_loss: 0.6751 - val_accuracy: 0.8895\n","Epoch 85/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2681 - accuracy: 0.9928 - val_loss: 0.7893 - val_accuracy: 0.8740\n","Epoch 86/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2726 - accuracy: 0.9907 - val_loss: 0.6986 - val_accuracy: 0.8843\n","Epoch 87/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2729 - accuracy: 0.9907 - val_loss: 0.7331 - val_accuracy: 0.8895\n","Epoch 88/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.2697 - accuracy: 0.9915 - val_loss: 0.6836 - val_accuracy: 0.8946\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2654 - accuracy: 0.9948 - val_loss: 0.6782 - val_accuracy: 0.8884\n","Epoch 90/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2586 - accuracy: 0.9966 - val_loss: 0.6873 - val_accuracy: 0.8864\n","Epoch 91/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2620 - accuracy: 0.9956 - val_loss: 0.7344 - val_accuracy: 0.8946\n","Epoch 92/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2817 - accuracy: 0.9871 - val_loss: 0.6781 - val_accuracy: 0.8884\n","Epoch 93/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2583 - accuracy: 0.9974 - val_loss: 0.6993 - val_accuracy: 0.8926\n","Epoch 94/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2660 - accuracy: 0.9938 - val_loss: 0.6988 - val_accuracy: 0.8905\n","Epoch 95/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2621 - accuracy: 0.9951 - val_loss: 0.6876 - val_accuracy: 0.8957\n","Epoch 96/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2574 - accuracy: 0.9959 - val_loss: 0.7165 - val_accuracy: 0.8812\n","Epoch 97/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2591 - accuracy: 0.9943 - val_loss: 0.6959 - val_accuracy: 0.8853\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2550 - accuracy: 0.9972 - val_loss: 0.6938 - val_accuracy: 0.8977\n","Epoch 99/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2594 - accuracy: 0.9943 - val_loss: 0.6886 - val_accuracy: 0.8884\n","Epoch 100/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2673 - accuracy: 0.9886 - val_loss: 0.6816 - val_accuracy: 0.8812\n","{'loss': [0.38020384311676025, 0.3443104922771454, 0.34592974185943604, 0.3445497155189514, 0.3384007513523102, 0.33777081966400146, 0.3283712863922119, 0.33739471435546875, 0.32677289843559265, 0.3359217643737793, 0.3247535228729248, 0.3283810615539551, 0.32418766617774963, 0.3201664984226227, 0.32490551471710205, 0.3230132460594177, 0.3170909881591797, 0.32618606090545654, 0.3288758397102356, 0.30844685435295105, 0.30924174189567566, 0.3258059024810791, 0.3222210109233856, 0.3243318200111389, 0.31362706422805786, 0.3080490529537201, 0.30597618222236633, 0.30935752391815186, 0.3078891634941101, 0.30657991766929626, 0.30022644996643066, 0.3006700873374939, 0.3192773759365082, 0.30097097158432007, 0.2962326407432556, 0.30826497077941895, 0.30119749903678894, 0.2952994406223297, 0.2948223948478699, 0.2930965721607208, 0.2889326810836792, 0.29441606998443604, 0.29066547751426697, 0.2905804216861725, 0.2888104319572449, 0.28893670439720154, 0.2984689474105835, 0.29380691051483154, 0.31066691875457764, 0.29347699880599976, 0.3059375286102295, 0.29313236474990845, 0.2907410264015198, 0.284836083650589, 0.28391996026039124, 0.2939770817756653, 0.2841733992099762, 0.28480803966522217, 0.2889830470085144, 0.2933914363384247, 0.28270506858825684, 0.27902424335479736, 0.28683605790138245, 0.2767135202884674, 0.27807074785232544, 0.2780427038669586, 0.2731167674064636, 0.2731410264968872, 0.27230504155158997, 0.280592143535614, 0.27147138118743896, 0.27468374371528625, 0.27584296464920044, 0.2804502546787262, 0.27305713295936584, 0.27210503816604614, 0.2718753516674042, 0.2728937566280365, 0.27946823835372925, 0.27850937843322754, 0.2699185311794281, 0.2678815722465515, 0.2645900547504425, 0.2660224735736847, 0.26810532808303833, 0.2726322114467621, 0.2729405462741852, 0.2697429656982422, 0.26536670327186584, 0.2586226463317871, 0.2620244324207306, 0.28170424699783325, 0.2583048641681671, 0.2659946382045746, 0.26208052039146423, 0.2573544979095459, 0.2591376006603241, 0.2550475001335144, 0.2594243288040161, 0.2673307955265045], 'accuracy': [0.9625322818756104, 0.9749354124069214, 0.97364342212677, 0.9749354124069214, 0.9775193929672241, 0.9785529971122742, 0.9808785319328308, 0.9780361652374268, 0.9806201457977295, 0.9780361652374268, 0.9819121360778809, 0.9764857888221741, 0.9801033735275269, 0.9826873540878296, 0.9808785319328308, 0.9788113832473755, 0.9842377305030823, 0.9793281555175781, 0.9777777791023254, 0.986821711063385, 0.9870800971984863, 0.9780361652374268, 0.9782945513725281, 0.9780361652374268, 0.9816537499427795, 0.985788106918335, 0.9873384833335876, 0.9863049387931824, 0.986821711063385, 0.987596869468689, 0.9891473054885864, 0.9883720874786377, 0.9790697693824768, 0.9881137013435364, 0.9904392957687378, 0.9842377305030823, 0.986821711063385, 0.9904392957687378, 0.9891473054885864, 0.9912144541740417, 0.9925064444541931, 0.9881137013435364, 0.9914728403091431, 0.9909560680389404, 0.9914728403091431, 0.9927648305892944, 0.9855297207832336, 0.9894056916236877, 0.9816537499427795, 0.9878553152084351, 0.9824289679527283, 0.9878553152084351, 0.9899224638938904, 0.9919896721839905, 0.9912144541740417, 0.9852713346481323, 0.9904392957687378, 0.9901808500289917, 0.9899224638938904, 0.9863049387931824, 0.9912144541740417, 0.9914728403091431, 0.9891473054885864, 0.9937984347343445, 0.9943152666091919, 0.9922480583190918, 0.9948320388793945, 0.9945736527442932, 0.9940568208694458, 0.9894056916236877, 0.9956072568893433, 0.9932816624641418, 0.9919896721839905, 0.9899224638938904, 0.9937984347343445, 0.9932816624641418, 0.9927648305892944, 0.9912144541740417, 0.9891473054885864, 0.9899224638938904, 0.9925064444541931, 0.9950904250144958, 0.9966408014297485, 0.9940568208694458, 0.9927648305892944, 0.9906976819038391, 0.9906976819038391, 0.9914728403091431, 0.9948320388793945, 0.9966408014297485, 0.9956072568893433, 0.9870800971984863, 0.9974160194396973, 0.9937984347343445, 0.9950904250144958, 0.9958656430244446, 0.9943152666091919, 0.997157633304596, 0.9943152666091919, 0.988630473613739], 'val_loss': [0.934836745262146, 0.9317724108695984, 0.9363465309143066, 0.9667717814445496, 0.9932069182395935, 1.0491888523101807, 1.0959845781326294, 1.1734341382980347, 1.1649419069290161, 1.3358675241470337, 1.3916839361190796, 1.5713845491409302, 1.4328559637069702, 1.6804431676864624, 1.3271024227142334, 1.3287471532821655, 1.0265953540802002, 0.7644186019897461, 0.9387624859809875, 0.8786891102790833, 0.9349716305732727, 0.8815528750419617, 0.5892500877380371, 0.6774612665176392, 0.648333728313446, 0.5742928981781006, 0.5763239860534668, 0.5849881768226624, 0.6295665502548218, 0.6476221084594727, 0.5904480218887329, 0.6260563731193542, 0.6050590872764587, 0.6036860346794128, 0.6190170049667358, 0.6222564578056335, 0.6085322499275208, 0.6241610050201416, 0.6202898025512695, 0.6202906966209412, 0.6141172647476196, 0.6220982074737549, 0.6432928442955017, 0.6559789180755615, 0.6489879488945007, 0.6518840789794922, 0.7077385187149048, 0.7315289378166199, 0.6667034029960632, 0.6577924489974976, 0.6451972723007202, 0.647567868232727, 0.6534273624420166, 0.6356440186500549, 0.6259983777999878, 0.6451376080513, 0.6625792384147644, 0.6348387598991394, 0.6950665712356567, 0.6361914873123169, 0.6426884531974792, 0.645151674747467, 0.6580623388290405, 0.6459166407585144, 0.6431761980056763, 0.6576360464096069, 0.649605393409729, 0.6542372703552246, 0.6661016345024109, 0.6455990672111511, 0.6676921844482422, 0.6571778059005737, 0.6984387040138245, 0.6680575013160706, 0.6582982540130615, 0.6931714415550232, 0.6625766158103943, 0.6850699782371521, 0.7131569981575012, 0.6961941123008728, 0.6733543872833252, 0.6788554787635803, 0.6688652634620667, 0.6750927567481995, 0.7892577648162842, 0.6986106634140015, 0.7331079244613647, 0.6836007833480835, 0.6781613230705261, 0.6872763633728027, 0.734432578086853, 0.678083062171936, 0.6993042230606079, 0.6988224387168884, 0.6875548958778381, 0.7164524793624878, 0.6959337592124939, 0.6938051581382751, 0.6885705590248108, 0.68157958984375], 'val_accuracy': [0.5216942429542542, 0.5165289044380188, 0.5082644820213318, 0.49793389439582825, 0.49793389439582825, 0.4958677589893341, 0.4969008266925812, 0.4958677589893341, 0.5, 0.49793389439582825, 0.5, 0.5, 0.5216942429542542, 0.5175619721412659, 0.5836777091026306, 0.5981404781341553, 0.6931818127632141, 0.7954545617103577, 0.7572314143180847, 0.7871900796890259, 0.7830578684806824, 0.8047520518302917, 0.8801652789115906, 0.8564049601554871, 0.8698347210884094, 0.9101239442825317, 0.9059917330741882, 0.9028925895690918, 0.8801652789115906, 0.8853305578231812, 0.9018595218658447, 0.8915289044380188, 0.8987603187561035, 0.9049586653709412, 0.9080578684806824, 0.8997933864593506, 0.89462810754776, 0.9018595218658447, 0.9039255976676941, 0.8966942429542542, 0.9018595218658447, 0.8977272510528564, 0.8987603187561035, 0.8822314143180847, 0.8987603187561035, 0.9028925895690918, 0.8801652789115906, 0.8739669322967529, 0.8997933864593506, 0.8966942429542542, 0.8997933864593506, 0.8997933864593506, 0.8925619721412659, 0.9008264541625977, 0.9008264541625977, 0.9039255976676941, 0.8884297609329224, 0.8966942429542542, 0.8915289044380188, 0.8997933864593506, 0.89462810754776, 0.8956611752510071, 0.8956611752510071, 0.9008264541625977, 0.8997933864593506, 0.8884297609329224, 0.8956611752510071, 0.8904958963394165, 0.8997933864593506, 0.8977272510528564, 0.8853305578231812, 0.8966942429542542, 0.89462810754776, 0.8987603187561035, 0.8997933864593506, 0.8987603187561035, 0.8977272510528564, 0.8956611752510071, 0.8894628286361694, 0.8966942429542542, 0.8956611752510071, 0.8915289044380188, 0.8956611752510071, 0.8894628286361694, 0.8739669322967529, 0.8842975497245789, 0.8894628286361694, 0.89462810754776, 0.8884297609329224, 0.8863636255264282, 0.89462810754776, 0.8884297609329224, 0.8925619721412659, 0.8904958963394165, 0.8956611752510071, 0.8811983466148376, 0.8853305578231812, 0.8977272510528564, 0.8884297609329224, 0.8811983466148376]}\n","32/32 [==============================] - 1s 4ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_gru"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"id":"sysMojBfIVXR","executionInfo":{"status":"ok","timestamp":1717404232029,"user_tz":-360,"elapsed":48,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"outputId":"81455956-28fc-47da-f332-dfa81557704f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision    Recall        F1  Sensitivity  Specificity  \\\n","0        0  0.768007   0.769360  0.765494  0.767422     0.765494     0.770519   \n","1        1  0.777542   0.759577  0.812147  0.784983     0.812147     0.742938   \n","2        2  0.712851   0.721757  0.692771  0.706967     0.692771     0.732932   \n","3        0  0.781407   0.796820  0.755444  0.775580     0.755444     0.807370   \n","4        1  0.814972   0.835843  0.783898  0.809038     0.783898     0.846045   \n","5        2  0.756024   0.744722  0.779116  0.761531     0.779116     0.732932   \n","6        0  0.812395   0.826620  0.790620  0.808219     0.790620     0.834171   \n","7        1  0.842514   0.862481  0.814972  0.838054     0.814972     0.870056   \n","8        2  0.796185   0.774674  0.835341  0.803865     0.835341     0.757028   \n","9        0  0.840871   0.849057  0.829146  0.838983     0.829146     0.852596   \n","10       1  0.859463   0.850069  0.872881  0.861324     0.872881     0.846045   \n","11       2  0.841365   0.830739  0.857430  0.843874     0.857430     0.825301   \n","12       0  0.860134   0.874564  0.840871  0.857387     0.840871     0.879397   \n","13       1  0.880650   0.870702  0.894068  0.882230     0.894068     0.867232   \n","14       2  0.864458   0.848369  0.887550  0.867517     0.887550     0.841365   \n","\n","       Kappa  \n","0   0.536013  \n","1   0.555085  \n","2   0.425703  \n","3   0.562814  \n","4   0.629944  \n","5   0.512048  \n","6   0.624791  \n","7   0.685028  \n","8   0.592369  \n","9   0.681742  \n","10  0.718927  \n","11  0.682731  \n","12  0.720268  \n","13  0.761299  \n","14  0.728916  "],"text/html":["\n","  <div id=\"df-d1b8a1ac-a10a-4ac8-bc08-353647f6e846\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.768007</td>\n","      <td>0.769360</td>\n","      <td>0.765494</td>\n","      <td>0.767422</td>\n","      <td>0.765494</td>\n","      <td>0.770519</td>\n","      <td>0.536013</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.777542</td>\n","      <td>0.759577</td>\n","      <td>0.812147</td>\n","      <td>0.784983</td>\n","      <td>0.812147</td>\n","      <td>0.742938</td>\n","      <td>0.555085</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.712851</td>\n","      <td>0.721757</td>\n","      <td>0.692771</td>\n","      <td>0.706967</td>\n","      <td>0.692771</td>\n","      <td>0.732932</td>\n","      <td>0.425703</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.781407</td>\n","      <td>0.796820</td>\n","      <td>0.755444</td>\n","      <td>0.775580</td>\n","      <td>0.755444</td>\n","      <td>0.807370</td>\n","      <td>0.562814</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.814972</td>\n","      <td>0.835843</td>\n","      <td>0.783898</td>\n","      <td>0.809038</td>\n","      <td>0.783898</td>\n","      <td>0.846045</td>\n","      <td>0.629944</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.756024</td>\n","      <td>0.744722</td>\n","      <td>0.779116</td>\n","      <td>0.761531</td>\n","      <td>0.779116</td>\n","      <td>0.732932</td>\n","      <td>0.512048</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.812395</td>\n","      <td>0.826620</td>\n","      <td>0.790620</td>\n","      <td>0.808219</td>\n","      <td>0.790620</td>\n","      <td>0.834171</td>\n","      <td>0.624791</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.842514</td>\n","      <td>0.862481</td>\n","      <td>0.814972</td>\n","      <td>0.838054</td>\n","      <td>0.814972</td>\n","      <td>0.870056</td>\n","      <td>0.685028</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.796185</td>\n","      <td>0.774674</td>\n","      <td>0.835341</td>\n","      <td>0.803865</td>\n","      <td>0.835341</td>\n","      <td>0.757028</td>\n","      <td>0.592369</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.840871</td>\n","      <td>0.849057</td>\n","      <td>0.829146</td>\n","      <td>0.838983</td>\n","      <td>0.829146</td>\n","      <td>0.852596</td>\n","      <td>0.681742</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.859463</td>\n","      <td>0.850069</td>\n","      <td>0.872881</td>\n","      <td>0.861324</td>\n","      <td>0.872881</td>\n","      <td>0.846045</td>\n","      <td>0.718927</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.841365</td>\n","      <td>0.830739</td>\n","      <td>0.857430</td>\n","      <td>0.843874</td>\n","      <td>0.857430</td>\n","      <td>0.825301</td>\n","      <td>0.682731</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.860134</td>\n","      <td>0.874564</td>\n","      <td>0.840871</td>\n","      <td>0.857387</td>\n","      <td>0.840871</td>\n","      <td>0.879397</td>\n","      <td>0.720268</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.880650</td>\n","      <td>0.870702</td>\n","      <td>0.894068</td>\n","      <td>0.882230</td>\n","      <td>0.894068</td>\n","      <td>0.867232</td>\n","      <td>0.761299</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.864458</td>\n","      <td>0.848369</td>\n","      <td>0.887550</td>\n","      <td>0.867517</td>\n","      <td>0.887550</td>\n","      <td>0.841365</td>\n","      <td>0.728916</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1b8a1ac-a10a-4ac8-bc08-353647f6e846')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d1b8a1ac-a10a-4ac8-bc08-353647f6e846 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d1b8a1ac-a10a-4ac8-bc08-353647f6e846');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0be71254-ef21-4ed3-adc9-91b48aeda99b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0be71254-ef21-4ed3-adc9-91b48aeda99b')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0be71254-ef21-4ed3-adc9-91b48aeda99b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"metrics_df_gru","summary":"{\n  \"name\": \"metrics_df_gru\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04772488798721974,\n        \"min\": 0.7128514056224899,\n        \"max\": 0.8806497175141242,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.8408710217755444,\n          0.8413654618473896,\n          0.7680067001675042\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04925428125195226,\n        \"min\": 0.7217573221757322,\n        \"max\": 0.8745644599303136,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.8490566037735849,\n          0.830739299610895,\n          0.7693602693602694\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05459749290157638,\n        \"min\": 0.6927710843373494,\n        \"max\": 0.8940677966101694,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.8291457286432161,\n          0.857429718875502,\n          0.7654941373534339\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04825029459311224,\n        \"min\": 0.706967213114754,\n        \"max\": 0.8822299651567944,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.8389830508474577,\n          0.8438735177865613,\n          0.7674223341729638\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05459749290157638,\n        \"min\": 0.6927710843373494,\n        \"max\": 0.8940677966101694,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.8291457286432161,\n          0.857429718875502,\n          0.7654941373534339\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0524082845196198,\n        \"min\": 0.7329317269076305,\n        \"max\": 0.8793969849246231,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.867231638418079,\n          0.8253012048192772,\n          0.7705192629815746\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09544977597443947,\n        \"min\": 0.4257028112449799,\n        \"max\": 0.7612994350282486,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6817420435510888,\n          0.6827309236947792,\n          0.5360134003350083\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["metrics_df_gru.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/DWT/CNN_GRU/DWT_GRU.csv', index = False)"],"metadata":{"id":"xlP6sFIgIYA4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HW1V-C1bJJQ6"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}