{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Mbfw8uvdftFM","executionInfo":{"status":"ok","timestamp":1717531567453,"user_tz":-360,"elapsed":3326,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sb"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"INiFJfLjgOkx","executionInfo":{"status":"ok","timestamp":1717531567465,"user_tz":-360,"elapsed":17,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"outputs":[],"source":["from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"lYo2Uq77gQSH","executionInfo":{"status":"ok","timestamp":1717531571754,"user_tz":-360,"elapsed":4304,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score, cross_val_predict"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"g66575_xgVzz","executionInfo":{"status":"ok","timestamp":1717531575519,"user_tz":-360,"elapsed":3786,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPool1D, Flatten, Dropout,LSTM"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3647,"status":"ok","timestamp":1717531579157,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"},"user_tz":-360},"id":"MOCNWlamfr3v","outputId":"b17812b1-42a9-4aa8-dbca-7b381220a183"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"iNy9eOGMf2qO","executionInfo":{"status":"ok","timestamp":1717531579158,"user_tz":-360,"elapsed":15,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"outputs":[],"source":["# Raw_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/only data/raw_data.npz'\n","\n","Theta_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/DWT/Raw/Delta_DWT.npz'\n","\n","\n","\n","# RAW = np.load(Raw_data, allow_pickle=True)  # Allow loading pickled object arrays\n","# X = RAW['X'].astype('float64')\n","# Y = RAW['Y'].astype('float64')\n","# group = RAW['Group'].astype('float64')"]},{"cell_type":"markdown","metadata":{"id":"PzeABzSyHgKg"},"source":["This is a good performing model"]},{"cell_type":"code","source":["# %%capture\n","# !pip install wandb"],"metadata":{"id":"PTmHq1-S6XWL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import wandb"],"metadata":{"id":"XX0yEFJG6QYM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !wandb login"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mmlbTHI36aVt","executionInfo":{"status":"ok","timestamp":1716626562113,"user_tz":-360,"elapsed":54787,"user":{"displayName":"FAZLA RABBY RAIHAN 241-44-013","userId":"09883248152183661883"}},"outputId":"fb67369e-14fa-465a-ad7b-08f498bf586f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}]},{"cell_type":"markdown","source":["# CNN-LSTM"],"metadata":{"id":"6DhAYwXUSE9z"}},{"cell_type":"code","source":["%%capture\n","!pip install tensorflow_addons"],"metadata":{"id":"fxwgRS-C1tES","executionInfo":{"status":"ok","timestamp":1717531585589,"user_tz":-360,"elapsed":6442,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Delta/CNN_LSTM/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Delta/CNN_LSTM/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"-kPJ3TCp9vdp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717528371866,"user_tz":-360,"elapsed":22,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"c276e32e-8908-4504-ed8f-0015f6407c90"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["global_model, metrics_df = federated_learning(Theta_data)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVURUnmYNNNg","outputId":"7f280d3a-d7cc-456d-b189-cb2f4f209c46","executionInfo":{"status":"ok","timestamp":1717529715812,"user_tz":-360,"elapsed":64398,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":9,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 1.7715 - accuracy: 0.5024"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 19s 64ms/step - loss: 1.7715 - accuracy: 0.5024 - val_loss: 1.7155 - val_accuracy: 0.5151\n","Epoch 2/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.6668 - accuracy: 0.4946 - val_loss: 1.6160 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.5714 - accuracy: 0.5019 - val_loss: 1.5248 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4837 - accuracy: 0.5038 - val_loss: 1.4408 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4032 - accuracy: 0.4914 - val_loss: 1.3641 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3299 - accuracy: 0.5038 - val_loss: 1.2944 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2633 - accuracy: 0.5046 - val_loss: 1.2312 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2031 - accuracy: 0.5057 - val_loss: 1.1743 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1488 - accuracy: 0.5054 - val_loss: 1.1231 - val_accuracy: 0.4849\n","Epoch 10/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0993 - accuracy: 0.5450 - val_loss: 1.0780 - val_accuracy: 0.4849\n","Epoch 11/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.0509 - accuracy: 0.5445 - val_loss: 1.0298 - val_accuracy: 0.5862\n","Epoch 12/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.9990 - accuracy: 0.5900 - val_loss: 0.9876 - val_accuracy: 0.6002\n","Epoch 13/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9551 - accuracy: 0.6059 - val_loss: 0.9546 - val_accuracy: 0.5765\n","Epoch 14/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9213 - accuracy: 0.6126 - val_loss: 0.9532 - val_accuracy: 0.4989\n","Epoch 15/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.8856 - accuracy: 0.6298 - val_loss: 0.9060 - val_accuracy: 0.5442\n","Epoch 16/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.8508 - accuracy: 0.6474 - val_loss: 0.9252 - val_accuracy: 0.5248\n","Epoch 17/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.8272 - accuracy: 0.6606 - val_loss: 0.8749 - val_accuracy: 0.5388\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8198 - accuracy: 0.6474 - val_loss: 0.8528 - val_accuracy: 0.5453\n","Epoch 19/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7832 - accuracy: 0.6724 - val_loss: 0.8672 - val_accuracy: 0.5528\n","Epoch 20/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7556 - accuracy: 0.6875 - val_loss: 0.8579 - val_accuracy: 0.5463\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7346 - accuracy: 0.6934 - val_loss: 0.8153 - val_accuracy: 0.5916\n","Epoch 22/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7199 - accuracy: 0.6969 - val_loss: 0.8065 - val_accuracy: 0.5873\n","Epoch 23/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6974 - accuracy: 0.7101 - val_loss: 0.7633 - val_accuracy: 0.6379\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6928 - accuracy: 0.7080 - val_loss: 0.7671 - val_accuracy: 0.6272\n","Epoch 25/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6662 - accuracy: 0.7249 - val_loss: 0.7685 - val_accuracy: 0.6056\n","Epoch 26/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6461 - accuracy: 0.7325 - val_loss: 0.7665 - val_accuracy: 0.6379\n","Epoch 27/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6069 - accuracy: 0.7624 - val_loss: 0.7779 - val_accuracy: 0.6218\n","Epoch 28/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5877 - accuracy: 0.7718 - val_loss: 0.8070 - val_accuracy: 0.6261\n","Epoch 29/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5953 - accuracy: 0.7670 - val_loss: 0.7980 - val_accuracy: 0.6207\n","Epoch 30/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5530 - accuracy: 0.7918 - val_loss: 0.7933 - val_accuracy: 0.6250\n","Epoch 31/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5221 - accuracy: 0.8079 - val_loss: 0.7942 - val_accuracy: 0.6304\n","Epoch 32/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4783 - accuracy: 0.8322 - val_loss: 0.8699 - val_accuracy: 0.6239\n","Epoch 33/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4663 - accuracy: 0.8359 - val_loss: 0.8664 - val_accuracy: 0.6121\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4303 - accuracy: 0.8578 - val_loss: 0.9626 - val_accuracy: 0.6369\n","Epoch 35/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4012 - accuracy: 0.8693 - val_loss: 1.0079 - val_accuracy: 0.6121\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3805 - accuracy: 0.8763 - val_loss: 0.9880 - val_accuracy: 0.6164\n","Epoch 37/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3395 - accuracy: 0.9001 - val_loss: 0.9987 - val_accuracy: 0.6272\n","Epoch 38/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3387 - accuracy: 0.8971 - val_loss: 1.0710 - val_accuracy: 0.6228\n","Epoch 39/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.3290 - accuracy: 0.9022 - val_loss: 0.9758 - val_accuracy: 0.6433\n","Epoch 40/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3130 - accuracy: 0.9068 - val_loss: 1.1310 - val_accuracy: 0.6369\n","Epoch 41/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.2545 - accuracy: 0.9302 - val_loss: 1.1597 - val_accuracy: 0.6175\n","Epoch 42/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2404 - accuracy: 0.9386 - val_loss: 1.1901 - val_accuracy: 0.6185\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2403 - accuracy: 0.9345 - val_loss: 1.2635 - val_accuracy: 0.6056\n","Epoch 44/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2520 - accuracy: 0.9302 - val_loss: 1.3100 - val_accuracy: 0.6121\n","Epoch 45/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2335 - accuracy: 0.9375 - val_loss: 1.2662 - val_accuracy: 0.6218\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1803 - accuracy: 0.9582 - val_loss: 1.4001 - val_accuracy: 0.5991\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1793 - accuracy: 0.9561 - val_loss: 1.3571 - val_accuracy: 0.6142\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1652 - accuracy: 0.9620 - val_loss: 1.4373 - val_accuracy: 0.6110\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1815 - accuracy: 0.9547 - val_loss: 1.3424 - val_accuracy: 0.6153\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1569 - accuracy: 0.9650 - val_loss: 1.4931 - val_accuracy: 0.6207\n","Epoch 51/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1551 - accuracy: 0.9642 - val_loss: 1.4068 - val_accuracy: 0.6142\n","Epoch 52/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.1232 - accuracy: 0.9760 - val_loss: 1.4679 - val_accuracy: 0.6293\n","Epoch 53/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.1055 - accuracy: 0.9836 - val_loss: 1.6739 - val_accuracy: 0.6196\n","Epoch 54/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.1273 - accuracy: 0.9744 - val_loss: 1.6011 - val_accuracy: 0.6002\n","Epoch 55/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.1393 - accuracy: 0.9690 - val_loss: 1.4787 - val_accuracy: 0.6099\n","Epoch 56/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.1086 - accuracy: 0.9811 - val_loss: 1.6771 - val_accuracy: 0.6045\n","Epoch 57/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.1144 - accuracy: 0.9803 - val_loss: 1.6546 - val_accuracy: 0.6088\n","Epoch 58/100\n","29/29 [==============================] - 1s 39ms/step - loss: 0.1380 - accuracy: 0.9696 - val_loss: 1.5813 - val_accuracy: 0.6272\n","Epoch 59/100\n","29/29 [==============================] - 1s 36ms/step - loss: 0.1093 - accuracy: 0.9798 - val_loss: 1.5800 - val_accuracy: 0.6175\n","Epoch 60/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1153 - accuracy: 0.9782 - val_loss: 1.6280 - val_accuracy: 0.6293\n","Epoch 61/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1299 - accuracy: 0.9720 - val_loss: 1.5544 - val_accuracy: 0.5981\n","Epoch 62/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.1078 - accuracy: 0.9841 - val_loss: 1.6348 - val_accuracy: 0.6131\n","Epoch 63/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.0969 - accuracy: 0.9857 - val_loss: 1.6614 - val_accuracy: 0.6056\n","Epoch 64/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0893 - accuracy: 0.9873 - val_loss: 1.6460 - val_accuracy: 0.6239\n","Epoch 65/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0797 - accuracy: 0.9914 - val_loss: 1.7256 - val_accuracy: 0.6358\n","Epoch 66/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0799 - accuracy: 0.9906 - val_loss: 1.7333 - val_accuracy: 0.6218\n","Epoch 67/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0985 - accuracy: 0.9828 - val_loss: 1.6988 - val_accuracy: 0.5830\n","Epoch 68/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0998 - accuracy: 0.9817 - val_loss: 1.6941 - val_accuracy: 0.6185\n","Epoch 69/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0875 - accuracy: 0.9841 - val_loss: 1.6792 - val_accuracy: 0.6228\n","Epoch 70/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0804 - accuracy: 0.9890 - val_loss: 1.8025 - val_accuracy: 0.6175\n","Epoch 71/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0747 - accuracy: 0.9900 - val_loss: 1.8112 - val_accuracy: 0.6272\n","Epoch 72/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0707 - accuracy: 0.9906 - val_loss: 1.9042 - val_accuracy: 0.6121\n","Epoch 73/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0736 - accuracy: 0.9906 - val_loss: 1.9631 - val_accuracy: 0.5873\n","Epoch 74/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.1036 - accuracy: 0.9795 - val_loss: 1.8220 - val_accuracy: 0.5884\n","Epoch 75/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.0704 - accuracy: 0.9908 - val_loss: 1.8431 - val_accuracy: 0.6218\n","Epoch 76/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0733 - accuracy: 0.9876 - val_loss: 1.8305 - val_accuracy: 0.6045\n","Epoch 77/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0674 - accuracy: 0.9906 - val_loss: 1.9847 - val_accuracy: 0.6228\n","Epoch 78/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0662 - accuracy: 0.9911 - val_loss: 1.9969 - val_accuracy: 0.6099\n","Epoch 79/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0737 - accuracy: 0.9873 - val_loss: 1.8886 - val_accuracy: 0.5948\n","Epoch 80/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0659 - accuracy: 0.9908 - val_loss: 1.8721 - val_accuracy: 0.6261\n","Epoch 81/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0645 - accuracy: 0.9900 - val_loss: 1.9128 - val_accuracy: 0.6088\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1707 - accuracy: 0.9539 - val_loss: 1.2724 - val_accuracy: 0.5970\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1145 - accuracy: 0.9741 - val_loss: 1.5877 - val_accuracy: 0.6218\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0626 - accuracy: 0.9914 - val_loss: 1.9316 - val_accuracy: 0.6207\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0542 - accuracy: 0.9946 - val_loss: 2.0290 - val_accuracy: 0.5970\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0544 - accuracy: 0.9938 - val_loss: 2.0324 - val_accuracy: 0.6131\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0590 - accuracy: 0.9906 - val_loss: 1.9958 - val_accuracy: 0.6250\n","Epoch 88/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1054 - accuracy: 0.9736 - val_loss: 1.7941 - val_accuracy: 0.5959\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0631 - accuracy: 0.9906 - val_loss: 1.9336 - val_accuracy: 0.6261\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0531 - accuracy: 0.9952 - val_loss: 1.9694 - val_accuracy: 0.6002\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0503 - accuracy: 0.9949 - val_loss: 2.0865 - val_accuracy: 0.6013\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0513 - accuracy: 0.9941 - val_loss: 2.1650 - val_accuracy: 0.6304\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0628 - accuracy: 0.9887 - val_loss: 2.0224 - val_accuracy: 0.6153\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0541 - accuracy: 0.9930 - val_loss: 2.1689 - val_accuracy: 0.6358\n","Epoch 95/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0605 - accuracy: 0.9908 - val_loss: 2.0478 - val_accuracy: 0.6185\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0530 - accuracy: 0.9941 - val_loss: 2.1134 - val_accuracy: 0.6013\n","Epoch 97/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0526 - accuracy: 0.9922 - val_loss: 2.1484 - val_accuracy: 0.6088\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0549 - accuracy: 0.9916 - val_loss: 2.0874 - val_accuracy: 0.6228\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0483 - accuracy: 0.9949 - val_loss: 2.2084 - val_accuracy: 0.6261\n","Epoch 100/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0471 - accuracy: 0.9941 - val_loss: 2.2474 - val_accuracy: 0.6272\n","{'loss': [1.7714524269104004, 1.6668457984924316, 1.5714271068572998, 1.4836626052856445, 1.4032124280929565, 1.3298591375350952, 1.2633109092712402, 1.2031352519989014, 1.1488206386566162, 1.099300503730774, 1.0508978366851807, 0.9990202784538269, 0.9551073908805847, 0.9213187098503113, 0.8856233954429626, 0.8507809042930603, 0.8272231817245483, 0.8197618126869202, 0.7831867337226868, 0.7556119561195374, 0.7345996499061584, 0.7198662161827087, 0.6973677277565002, 0.6928220987319946, 0.6661778688430786, 0.6461099982261658, 0.6068801283836365, 0.5877109169960022, 0.5952550768852234, 0.5529641509056091, 0.5221074223518372, 0.47830551862716675, 0.4662519693374634, 0.43031877279281616, 0.4012088477611542, 0.38046324253082275, 0.3395153284072876, 0.33873581886291504, 0.3290250897407532, 0.313017338514328, 0.2545030117034912, 0.24044692516326904, 0.24028915166854858, 0.252045214176178, 0.23346897959709167, 0.1803412139415741, 0.1793060451745987, 0.1652499884366989, 0.1815183311700821, 0.15691538155078888, 0.15506592392921448, 0.12324704974889755, 0.1055142879486084, 0.1273459494113922, 0.1392601877450943, 0.10856935381889343, 0.11439012736082077, 0.1380295604467392, 0.10927528887987137, 0.11529728770256042, 0.12994882464408875, 0.1078467145562172, 0.09686006605625153, 0.0893288254737854, 0.07966462522745132, 0.07986827194690704, 0.09850792586803436, 0.09982910752296448, 0.08747941255569458, 0.0803753063082695, 0.07474812865257263, 0.0706697329878807, 0.07364712655544281, 0.10361930727958679, 0.07039906084537506, 0.07330749928951263, 0.06740511208772659, 0.06624175608158112, 0.07370656728744507, 0.06591010838747025, 0.06454358249902725, 0.1707095056772232, 0.11447233706712723, 0.06259554624557495, 0.05417647957801819, 0.054439932107925415, 0.05902605503797531, 0.10537801682949066, 0.06310171633958817, 0.053051166236400604, 0.050255242735147476, 0.05127056688070297, 0.06275182217359543, 0.054143764078617096, 0.06045093759894371, 0.05301407724618912, 0.05259178951382637, 0.054861053824424744, 0.048259805887937546, 0.04714197665452957], 'accuracy': [0.5024245977401733, 0.49461206793785095, 0.5018857717514038, 0.5037715435028076, 0.4913793206214905, 0.5037715435028076, 0.5045797228813171, 0.5056573152542114, 0.5053879022598267, 0.5449892282485962, 0.5444504022598267, 0.5899784564971924, 0.6058728694915771, 0.6126077771186829, 0.6298491358757019, 0.6473599076271057, 0.6605603694915771, 0.6473599076271057, 0.6724137663841248, 0.6875, 0.6934267282485962, 0.696928858757019, 0.7101293206214905, 0.7079741358757019, 0.724946141242981, 0.7324892282485962, 0.7623922228813171, 0.771821141242981, 0.766972005367279, 0.7917564511299133, 0.8079202771186829, 0.8321659564971924, 0.8359375, 0.857758641242981, 0.8693426847457886, 0.876347005367279, 0.900053858757019, 0.897090494632721, 0.9022090435028076, 0.9067887663841248, 0.9302262663841248, 0.9385775923728943, 0.9345366358757019, 0.9302262663841248, 0.9375, 0.9582435488700867, 0.9560883641242981, 0.9620150923728943, 0.954741358757019, 0.9649784564971924, 0.9641702771186829, 0.9760237336158752, 0.9835668206214905, 0.9744073152542114, 0.9690194129943848, 0.9811422228813171, 0.9803340435028076, 0.9695581793785095, 0.9797952771186829, 0.978178858757019, 0.9719827771186829, 0.9841055870056152, 0.985722005367279, 0.9873383641242981, 0.9913793206214905, 0.990571141242981, 0.982758641242981, 0.9816810488700867, 0.9841055870056152, 0.9889547228813171, 0.9900323152542114, 0.990571141242981, 0.990571141242981, 0.9795258641242981, 0.990840494632721, 0.9876077771186829, 0.990571141242981, 0.9911099076271057, 0.9873383641242981, 0.990840494632721, 0.9900323152542114, 0.9539331793785095, 0.9741379022598267, 0.9913793206214905, 0.9946120977401733, 0.993803858757019, 0.990571141242981, 0.9735991358757019, 0.990571141242981, 0.9951508641242981, 0.9948814511299133, 0.9940732717514038, 0.9886853694915771, 0.9929956793785095, 0.990840494632721, 0.9940732717514038, 0.9921875, 0.9916487336158752, 0.9948814511299133, 0.9940732717514038], 'val_loss': [1.71554434299469, 1.616042137145996, 1.5248122215270996, 1.440821886062622, 1.3641151189804077, 1.2944129705429077, 1.2312326431274414, 1.1742982864379883, 1.1231297254562378, 1.0779879093170166, 1.029786467552185, 0.9876369833946228, 0.9546269774436951, 0.9531595706939697, 0.9059587717056274, 0.9252235293388367, 0.8749029636383057, 0.8527772426605225, 0.8672338724136353, 0.8579180240631104, 0.8153083920478821, 0.806492030620575, 0.7633150219917297, 0.7670941948890686, 0.7684598565101624, 0.766482412815094, 0.7778735160827637, 0.8069819211959839, 0.7980154156684875, 0.7933472394943237, 0.7941957116127014, 0.8699400424957275, 0.866375207901001, 0.9625570178031921, 1.0079171657562256, 0.9880182147026062, 0.9986997842788696, 1.0710070133209229, 0.9757512807846069, 1.1309657096862793, 1.1596852540969849, 1.190070390701294, 1.263548493385315, 1.309980869293213, 1.2661662101745605, 1.400146484375, 1.3571295738220215, 1.4373420476913452, 1.3424196243286133, 1.493132472038269, 1.406842589378357, 1.4679265022277832, 1.673864722251892, 1.6011340618133545, 1.478652834892273, 1.6770577430725098, 1.6545624732971191, 1.5812571048736572, 1.5800199508666992, 1.6279598474502563, 1.5544458627700806, 1.6348206996917725, 1.661436676979065, 1.6460305452346802, 1.7256276607513428, 1.73330819606781, 1.6988210678100586, 1.6941009759902954, 1.6792340278625488, 1.802521824836731, 1.8112033605575562, 1.9042448997497559, 1.9631057977676392, 1.8220288753509521, 1.843116044998169, 1.8304636478424072, 1.984707236289978, 1.9968552589416504, 1.888596534729004, 1.872074007987976, 1.9128479957580566, 1.272402048110962, 1.5877357721328735, 1.9316402673721313, 2.0290215015411377, 2.032414197921753, 1.995847225189209, 1.7940764427185059, 1.9335896968841553, 1.969376802444458, 2.086507558822632, 2.16501522064209, 2.0223684310913086, 2.1689441204071045, 2.0477895736694336, 2.113447904586792, 2.148374557495117, 2.0874295234680176, 2.208427906036377, 2.247357130050659], 'val_accuracy': [0.5150862336158752, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.5862069129943848, 0.600215494632721, 0.576508641242981, 0.4989224076271057, 0.5441810488700867, 0.524784505367279, 0.5387930870056152, 0.545258641242981, 0.5528017282485962, 0.5463362336158752, 0.5915948152542114, 0.587284505367279, 0.6379310488700867, 0.6271551847457886, 0.6056034564971924, 0.6379310488700867, 0.6217672228813171, 0.6260775923728943, 0.6206896305084229, 0.625, 0.6303879022598267, 0.6239224076271057, 0.6120689511299133, 0.6368534564971924, 0.6120689511299133, 0.6163793206214905, 0.6271551847457886, 0.6228448152542114, 0.6433189511299133, 0.6368534564971924, 0.6174569129943848, 0.618534505367279, 0.6056034564971924, 0.6120689511299133, 0.6217672228813171, 0.5991379022598267, 0.6142241358757019, 0.610991358757019, 0.6153017282485962, 0.6206896305084229, 0.6142241358757019, 0.6293103694915771, 0.6196120977401733, 0.600215494632721, 0.6099137663841248, 0.6045258641242981, 0.6088362336158752, 0.6271551847457886, 0.6174569129943848, 0.6293103694915771, 0.5980603694915771, 0.6131465435028076, 0.6056034564971924, 0.6239224076271057, 0.6357758641242981, 0.6217672228813171, 0.5829741358757019, 0.618534505367279, 0.6228448152542114, 0.6174569129943848, 0.6271551847457886, 0.6120689511299133, 0.587284505367279, 0.5883620977401733, 0.6217672228813171, 0.6045258641242981, 0.6228448152542114, 0.6099137663841248, 0.5948275923728943, 0.6260775923728943, 0.6088362336158752, 0.5969827771186829, 0.6217672228813171, 0.6206896305084229, 0.5969827771186829, 0.6131465435028076, 0.625, 0.5959051847457886, 0.6260775923728943, 0.600215494632721, 0.6012930870056152, 0.6303879022598267, 0.6153017282485962, 0.6357758641242981, 0.618534505367279, 0.6012930870056152, 0.6088362336158752, 0.6228448152542114, 0.6260775923728943, 0.6271551847457886]}\n","38/38 [==============================] - 1s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 1.7745 - accuracy: 0.5088"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 9s 117ms/step - loss: 1.7745 - accuracy: 0.5088 - val_loss: 1.7229 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.6796 - accuracy: 0.4918 - val_loss: 1.6310 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5898 - accuracy: 0.4884 - val_loss: 1.5452 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5072 - accuracy: 0.5014 - val_loss: 1.4660 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4311 - accuracy: 0.4912 - val_loss: 1.3931 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3610 - accuracy: 0.4989 - val_loss: 1.3263 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2967 - accuracy: 0.5153 - val_loss: 1.2651 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2380 - accuracy: 0.5218 - val_loss: 1.2093 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.1843 - accuracy: 0.5226 - val_loss: 1.1583 - val_accuracy: 0.5090\n","Epoch 10/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.1344 - accuracy: 0.5371 - val_loss: 1.1113 - val_accuracy: 0.5226\n","Epoch 11/100\n","28/28 [==============================] - 1s 31ms/step - loss: 1.0814 - accuracy: 0.5696 - val_loss: 1.0628 - val_accuracy: 0.5532\n","Epoch 12/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.0291 - accuracy: 0.5911 - val_loss: 1.0223 - val_accuracy: 0.5758\n","Epoch 13/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9903 - accuracy: 0.6041 - val_loss: 0.9912 - val_accuracy: 0.5656\n","Epoch 14/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.9579 - accuracy: 0.6033 - val_loss: 0.9570 - val_accuracy: 0.5882\n","Epoch 15/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.9289 - accuracy: 0.6013 - val_loss: 0.9270 - val_accuracy: 0.6120\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9029 - accuracy: 0.6149 - val_loss: 0.9106 - val_accuracy: 0.5781\n","Epoch 17/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8744 - accuracy: 0.6234 - val_loss: 0.9015 - val_accuracy: 0.5656\n","Epoch 18/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8541 - accuracy: 0.6251 - val_loss: 0.8682 - val_accuracy: 0.5916\n","Epoch 19/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.8280 - accuracy: 0.6336 - val_loss: 0.8453 - val_accuracy: 0.6143\n","Epoch 20/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.8178 - accuracy: 0.6330 - val_loss: 0.8288 - val_accuracy: 0.6256\n","Epoch 21/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7927 - accuracy: 0.6488 - val_loss: 0.8184 - val_accuracy: 0.6143\n","Epoch 22/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7907 - accuracy: 0.6319 - val_loss: 0.8027 - val_accuracy: 0.6075\n","Epoch 23/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7674 - accuracy: 0.6568 - val_loss: 0.8107 - val_accuracy: 0.6052\n","Epoch 24/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7377 - accuracy: 0.6817 - val_loss: 0.7832 - val_accuracy: 0.6109\n","Epoch 25/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7129 - accuracy: 0.7009 - val_loss: 0.7888 - val_accuracy: 0.6029\n","Epoch 26/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6999 - accuracy: 0.6972 - val_loss: 0.7738 - val_accuracy: 0.6154\n","Epoch 27/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6880 - accuracy: 0.7023 - val_loss: 0.7639 - val_accuracy: 0.6278\n","Epoch 28/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6526 - accuracy: 0.7366 - val_loss: 0.7796 - val_accuracy: 0.6109\n","Epoch 29/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6366 - accuracy: 0.7391 - val_loss: 0.7956 - val_accuracy: 0.6176\n","Epoch 30/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6173 - accuracy: 0.7470 - val_loss: 0.7704 - val_accuracy: 0.6199\n","Epoch 31/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5969 - accuracy: 0.7632 - val_loss: 0.7943 - val_accuracy: 0.6176\n","Epoch 32/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5606 - accuracy: 0.7912 - val_loss: 0.8342 - val_accuracy: 0.5950\n","Epoch 33/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5378 - accuracy: 0.7960 - val_loss: 0.8580 - val_accuracy: 0.6063\n","Epoch 34/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5503 - accuracy: 0.7759 - val_loss: 0.7987 - val_accuracy: 0.6120\n","Epoch 35/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4955 - accuracy: 0.8220 - val_loss: 0.9000 - val_accuracy: 0.5826\n","Epoch 36/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4560 - accuracy: 0.8362 - val_loss: 0.8785 - val_accuracy: 0.5939\n","Epoch 37/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4655 - accuracy: 0.8294 - val_loss: 0.9051 - val_accuracy: 0.5860\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4048 - accuracy: 0.8679 - val_loss: 0.9528 - val_accuracy: 0.5860\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3878 - accuracy: 0.8729 - val_loss: 1.0197 - val_accuracy: 0.5973\n","Epoch 40/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3626 - accuracy: 0.8902 - val_loss: 1.0236 - val_accuracy: 0.5882\n","Epoch 41/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3278 - accuracy: 0.9041 - val_loss: 1.1195 - val_accuracy: 0.5928\n","Epoch 42/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.3331 - accuracy: 0.8993 - val_loss: 1.0186 - val_accuracy: 0.5894\n","Epoch 43/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3486 - accuracy: 0.8826 - val_loss: 1.0616 - val_accuracy: 0.5814\n","Epoch 44/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2814 - accuracy: 0.9230 - val_loss: 1.2896 - val_accuracy: 0.5747\n","Epoch 45/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2484 - accuracy: 0.9338 - val_loss: 1.2830 - val_accuracy: 0.5690\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2346 - accuracy: 0.9363 - val_loss: 1.2780 - val_accuracy: 0.5781\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2147 - accuracy: 0.9496 - val_loss: 1.3913 - val_accuracy: 0.5950\n","Epoch 48/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1911 - accuracy: 0.9590 - val_loss: 1.4369 - val_accuracy: 0.5973\n","Epoch 49/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.1816 - accuracy: 0.9576 - val_loss: 1.4457 - val_accuracy: 0.5814\n","Epoch 50/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.1601 - accuracy: 0.9663 - val_loss: 1.5604 - val_accuracy: 0.5928\n","Epoch 51/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.1657 - accuracy: 0.9646 - val_loss: 1.4934 - val_accuracy: 0.5724\n","Epoch 52/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.2427 - accuracy: 0.9276 - val_loss: 1.4411 - val_accuracy: 0.5792\n","Epoch 53/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.1556 - accuracy: 0.9672 - val_loss: 1.5228 - val_accuracy: 0.5928\n","Epoch 54/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.1403 - accuracy: 0.9740 - val_loss: 1.5211 - val_accuracy: 0.5837\n","Epoch 55/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.1348 - accuracy: 0.9745 - val_loss: 1.5233 - val_accuracy: 0.6075\n","Epoch 56/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.1333 - accuracy: 0.9751 - val_loss: 1.5763 - val_accuracy: 0.5724\n","Epoch 57/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.1270 - accuracy: 0.9754 - val_loss: 1.5231 - val_accuracy: 0.5781\n","Epoch 58/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.1407 - accuracy: 0.9694 - val_loss: 1.4975 - val_accuracy: 0.5566\n","Epoch 59/100\n","28/28 [==============================] - 1s 37ms/step - loss: 0.1301 - accuracy: 0.9703 - val_loss: 1.8243 - val_accuracy: 0.5758\n","Epoch 60/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1144 - accuracy: 0.9759 - val_loss: 1.8383 - val_accuracy: 0.5758\n","Epoch 61/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1120 - accuracy: 0.9771 - val_loss: 1.8633 - val_accuracy: 0.5758\n","Epoch 62/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0847 - accuracy: 0.9909 - val_loss: 1.8322 - val_accuracy: 0.5894\n","Epoch 63/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0735 - accuracy: 0.9941 - val_loss: 1.9732 - val_accuracy: 0.5962\n","Epoch 64/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0950 - accuracy: 0.9819 - val_loss: 1.7715 - val_accuracy: 0.5950\n","Epoch 65/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0911 - accuracy: 0.9847 - val_loss: 1.8813 - val_accuracy: 0.5905\n","Epoch 66/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1029 - accuracy: 0.9793 - val_loss: 1.7794 - val_accuracy: 0.5882\n","Epoch 67/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0891 - accuracy: 0.9844 - val_loss: 1.9824 - val_accuracy: 0.5939\n","Epoch 68/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1267 - accuracy: 0.9666 - val_loss: 1.5971 - val_accuracy: 0.5735\n","Epoch 69/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1033 - accuracy: 0.9796 - val_loss: 2.0096 - val_accuracy: 0.5781\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0828 - accuracy: 0.9867 - val_loss: 1.9049 - val_accuracy: 0.5894\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0767 - accuracy: 0.9887 - val_loss: 1.9721 - val_accuracy: 0.5995\n","Epoch 72/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0715 - accuracy: 0.9901 - val_loss: 2.0490 - val_accuracy: 0.5826\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0946 - accuracy: 0.9808 - val_loss: 1.7918 - val_accuracy: 0.5803\n","Epoch 74/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0865 - accuracy: 0.9853 - val_loss: 1.9701 - val_accuracy: 0.5950\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0722 - accuracy: 0.9898 - val_loss: 1.9599 - val_accuracy: 0.5826\n","Epoch 76/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0765 - accuracy: 0.9870 - val_loss: 1.9337 - val_accuracy: 0.5860\n","Epoch 77/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0735 - accuracy: 0.9915 - val_loss: 2.0955 - val_accuracy: 0.5905\n","Epoch 78/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0640 - accuracy: 0.9935 - val_loss: 2.0468 - val_accuracy: 0.5769\n","Epoch 79/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0644 - accuracy: 0.9921 - val_loss: 2.0718 - val_accuracy: 0.5781\n","Epoch 80/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0566 - accuracy: 0.9960 - val_loss: 2.2823 - val_accuracy: 0.5848\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0574 - accuracy: 0.9946 - val_loss: 2.2130 - val_accuracy: 0.5781\n","Epoch 82/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0711 - accuracy: 0.9892 - val_loss: 1.8507 - val_accuracy: 0.6041\n","Epoch 83/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0863 - accuracy: 0.9805 - val_loss: 2.0945 - val_accuracy: 0.5758\n","Epoch 84/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1862 - accuracy: 0.9440 - val_loss: 1.7831 - val_accuracy: 0.5950\n","Epoch 85/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0768 - accuracy: 0.9878 - val_loss: 2.0089 - val_accuracy: 0.5973\n","Epoch 86/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0549 - accuracy: 0.9958 - val_loss: 2.2329 - val_accuracy: 0.5769\n","Epoch 87/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0541 - accuracy: 0.9943 - val_loss: 2.1382 - val_accuracy: 0.5962\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0487 - accuracy: 0.9969 - val_loss: 2.1316 - val_accuracy: 0.5769\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0465 - accuracy: 0.9972 - val_loss: 2.1843 - val_accuracy: 0.5962\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0443 - accuracy: 0.9977 - val_loss: 2.2495 - val_accuracy: 0.5984\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0446 - accuracy: 0.9966 - val_loss: 2.2315 - val_accuracy: 0.5973\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0445 - accuracy: 0.9969 - val_loss: 2.3594 - val_accuracy: 0.5860\n","Epoch 93/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0440 - accuracy: 0.9960 - val_loss: 2.3671 - val_accuracy: 0.5848\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0562 - accuracy: 0.9918 - val_loss: 2.4504 - val_accuracy: 0.5803\n","Epoch 95/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1238 - accuracy: 0.9692 - val_loss: 1.5217 - val_accuracy: 0.5758\n","Epoch 96/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0770 - accuracy: 0.9853 - val_loss: 2.3508 - val_accuracy: 0.5758\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0638 - accuracy: 0.9870 - val_loss: 2.1244 - val_accuracy: 0.5860\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0498 - accuracy: 0.9938 - val_loss: 2.3402 - val_accuracy: 0.5882\n","Epoch 99/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0426 - accuracy: 0.9969 - val_loss: 2.3943 - val_accuracy: 0.5826\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0429 - accuracy: 0.9966 - val_loss: 2.4464 - val_accuracy: 0.5962\n","{'loss': [1.7745294570922852, 1.6795790195465088, 1.5898462533950806, 1.5072234869003296, 1.431097388267517, 1.3609508275985718, 1.2966630458831787, 1.2380049228668213, 1.1842893362045288, 1.1343761682510376, 1.0813590288162231, 1.0291132926940918, 0.9903103113174438, 0.9579139947891235, 0.9289328455924988, 0.9028503894805908, 0.8743613362312317, 0.8541412353515625, 0.8280177116394043, 0.817847490310669, 0.7927073836326599, 0.7907235622406006, 0.7674022912979126, 0.7376636862754822, 0.7128689289093018, 0.6999216079711914, 0.6879555583000183, 0.6525953412055969, 0.6366024017333984, 0.6172852516174316, 0.5969304442405701, 0.5605953931808472, 0.5377546548843384, 0.5503304600715637, 0.4955023527145386, 0.45595431327819824, 0.46545708179473877, 0.4047572612762451, 0.3878480792045593, 0.3626457154750824, 0.3277962803840637, 0.33314645290374756, 0.34861651062965393, 0.2813737094402313, 0.24835728108882904, 0.23460280895233154, 0.21469637751579285, 0.19107264280319214, 0.18156588077545166, 0.16006970405578613, 0.16570450365543365, 0.24267999827861786, 0.1555846929550171, 0.14029015600681305, 0.1347801387310028, 0.13328257203102112, 0.12703101336956024, 0.14073015749454498, 0.13005217909812927, 0.11439108848571777, 0.11198443919420242, 0.08466875553131104, 0.07349706441164017, 0.09504545480012894, 0.09111377596855164, 0.10288462787866592, 0.08909402042627335, 0.12671315670013428, 0.10329295694828033, 0.08283477276563644, 0.07668150216341019, 0.07149511575698853, 0.0945921465754509, 0.08648805320262909, 0.07221722602844238, 0.0764688029885292, 0.07345345616340637, 0.06399808079004288, 0.06444547325372696, 0.05664746090769768, 0.05743599310517311, 0.07108408957719803, 0.08634547144174576, 0.18623116612434387, 0.07681833207607269, 0.05492846295237541, 0.05413317680358887, 0.04870511218905449, 0.04651331156492233, 0.04427647963166237, 0.044610556215047836, 0.04448884353041649, 0.043979253619909286, 0.05624949932098389, 0.12383577972650528, 0.07700423151254654, 0.06376920640468597, 0.049775321036577225, 0.04263551905751228, 0.042910970747470856], 'accuracy': [0.5087719559669495, 0.49179399013519287, 0.48839840292930603, 0.5014148354530334, 0.4912280738353729, 0.4988681375980377, 0.5152801275253296, 0.5217883586883545, 0.5226372480392456, 0.5370684862136841, 0.569609522819519, 0.59111487865448, 0.604131281375885, 0.6032823920249939, 0.6013016700744629, 0.6148839592933655, 0.6233729720115662, 0.6250707507133484, 0.6335597038269043, 0.632993757724762, 0.6488398313522339, 0.6318619251251221, 0.6567628979682922, 0.6816638112068176, 0.7009055018424988, 0.6972269415855408, 0.7023203372955322, 0.7365591526031494, 0.7391058206558228, 0.7470288872718811, 0.7631579041481018, 0.7911714911460876, 0.7959818840026855, 0.7758913636207581, 0.8220146894454956, 0.8361629843711853, 0.8293718099594116, 0.8678551316261292, 0.8729485273361206, 0.8902093768119812, 0.9040747284889221, 0.8992642760276794, 0.8825693130493164, 0.9230334162712097, 0.9337860941886902, 0.9363327622413635, 0.9496321678161621, 0.9589700102806091, 0.9575551748275757, 0.9663271307945251, 0.9646292924880981, 0.9275608658790588, 0.9671760201454163, 0.9739671945571899, 0.9745330810546875, 0.9750990271568298, 0.9753820300102234, 0.9694397449493408, 0.9702886343002319, 0.975947916507721, 0.9770798087120056, 0.9909451007843018, 0.9940577149391174, 0.9818902015686035, 0.9847198724746704, 0.9793435335159302, 0.9844368696212769, 0.9666100740432739, 0.979626476764679, 0.9867005944252014, 0.9886813759803772, 0.9900962114334106, 0.9807583689689636, 0.9852858185768127, 0.9898132681846619, 0.986983597278595, 0.9915110468864441, 0.9934917688369751, 0.9920769929885864, 0.9960384964942932, 0.9946236610412598, 0.9892473220825195, 0.9804753661155701, 0.9439728260040283, 0.9878324866294861, 0.9957554936408997, 0.994340717792511, 0.9968873858451843, 0.9971703290939331, 0.9977362751960754, 0.9966044425964355, 0.9968873858451843, 0.9960384964942932, 0.9917939901351929, 0.9691567420959473, 0.9852858185768127, 0.986983597278595, 0.9937747716903687, 0.9968873858451843, 0.9966044425964355], 'val_loss': [1.722914457321167, 1.6310491561889648, 1.5451710224151611, 1.4659874439239502, 1.3931241035461426, 1.3263049125671387, 1.2651335000991821, 1.2092736959457397, 1.1583362817764282, 1.111312747001648, 1.0628372430801392, 1.0223299264907837, 0.9911559820175171, 0.95701003074646, 0.9270331859588623, 0.9106223583221436, 0.9015071392059326, 0.868160605430603, 0.8453420996665955, 0.8287677764892578, 0.8183860182762146, 0.80269855260849, 0.8106986880302429, 0.7831720113754272, 0.7887977957725525, 0.7737863659858704, 0.7639137506484985, 0.779551088809967, 0.7956135869026184, 0.7703640460968018, 0.7942727208137512, 0.8341910243034363, 0.8579938411712646, 0.7986851334571838, 0.9000060558319092, 0.8784615397453308, 0.9051181077957153, 0.9527738690376282, 1.0196723937988281, 1.0236496925354004, 1.119486689567566, 1.018592357635498, 1.0615679025650024, 1.289628028869629, 1.2829722166061401, 1.2780171632766724, 1.391252040863037, 1.436928153038025, 1.4457112550735474, 1.5604289770126343, 1.4933909177780151, 1.4411382675170898, 1.522840142250061, 1.5210516452789307, 1.5233138799667358, 1.5763341188430786, 1.5230603218078613, 1.4975260496139526, 1.8242769241333008, 1.8382569551467896, 1.8633075952529907, 1.8321834802627563, 1.9732204675674438, 1.7715299129486084, 1.8813250064849854, 1.779350996017456, 1.982354998588562, 1.597143292427063, 2.009641647338867, 1.9049391746520996, 1.9720937013626099, 2.049032688140869, 1.791846513748169, 1.9700756072998047, 1.9598606824874878, 1.9336538314819336, 2.0955240726470947, 2.0468220710754395, 2.071833610534668, 2.2823128700256348, 2.213007926940918, 1.850692868232727, 2.0944602489471436, 1.7831202745437622, 2.0089149475097656, 2.232909917831421, 2.138241767883301, 2.1316299438476562, 2.1842615604400635, 2.24946665763855, 2.231494903564453, 2.359438419342041, 2.3670835494995117, 2.4504284858703613, 1.5216920375823975, 2.350802183151245, 2.1244335174560547, 2.340226650238037, 2.3942604064941406, 2.4463706016540527], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.5090497732162476, 0.5226244330406189, 0.5531674027442932, 0.5757918357849121, 0.5656108856201172, 0.5882353186607361, 0.6119909286499023, 0.5780543088912964, 0.5656108856201172, 0.5916289687156677, 0.6142534017562866, 0.6255655884742737, 0.6142534017562866, 0.6074660420417786, 0.6052036285400391, 0.610859751701355, 0.6029411554336548, 0.6153846383094788, 0.627828061580658, 0.610859751701355, 0.6176470518112183, 0.6199095249176025, 0.6176470518112183, 0.5950226187705994, 0.6063348650932312, 0.6119909286499023, 0.5825791954994202, 0.5938913822174072, 0.5859728455543518, 0.5859728455543518, 0.5972850918769836, 0.5882353186607361, 0.5927602052688599, 0.5893664956092834, 0.581447958946228, 0.5746606588363647, 0.5690045356750488, 0.5780543088912964, 0.5950226187705994, 0.5972850918769836, 0.581447958946228, 0.5927602052688599, 0.5723981857299805, 0.5791855454444885, 0.5927602052688599, 0.5837104320526123, 0.6074660420417786, 0.5723981857299805, 0.5780543088912964, 0.5565611124038696, 0.5757918357849121, 0.5757918357849121, 0.5757918357849121, 0.5893664956092834, 0.5961538553237915, 0.5950226187705994, 0.5904977321624756, 0.5882353186607361, 0.5938913822174072, 0.5735294222831726, 0.5780543088912964, 0.5893664956092834, 0.5995475053787231, 0.5825791954994202, 0.5803167223930359, 0.5950226187705994, 0.5825791954994202, 0.5859728455543518, 0.5904977321624756, 0.5769230723381042, 0.5780543088912964, 0.5848416090011597, 0.5780543088912964, 0.6040723919868469, 0.5757918357849121, 0.5950226187705994, 0.5972850918769836, 0.5769230723381042, 0.5961538553237915, 0.5769230723381042, 0.5961538553237915, 0.598416268825531, 0.5972850918769836, 0.5859728455543518, 0.5848416090011597, 0.5803167223930359, 0.5757918357849121, 0.5757918357849121, 0.5859728455543518, 0.5882353186607361, 0.5825791954994202, 0.5961538553237915]}\n","45/45 [==============================] - 1s 10ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 1.7666 - accuracy: 0.4938"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 8s 74ms/step - loss: 1.7666 - accuracy: 0.4938 - val_loss: 1.7039 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.6525 - accuracy: 0.5026 - val_loss: 1.5965 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5503 - accuracy: 0.5000 - val_loss: 1.4997 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.4575 - accuracy: 0.5036 - val_loss: 1.4118 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.3735 - accuracy: 0.5036 - val_loss: 1.3322 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.2977 - accuracy: 0.5036 - val_loss: 1.2606 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.2296 - accuracy: 0.5065 - val_loss: 1.1963 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.1686 - accuracy: 0.5036 - val_loss: 1.1389 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.1141 - accuracy: 0.5036 - val_loss: 1.0876 - val_accuracy: 0.4855\n","Epoch 10/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0654 - accuracy: 0.5036 - val_loss: 1.0418 - val_accuracy: 0.4855\n","Epoch 11/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0221 - accuracy: 0.5039 - val_loss: 1.0011 - val_accuracy: 0.4855\n","Epoch 12/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9837 - accuracy: 0.5036 - val_loss: 0.9651 - val_accuracy: 0.4855\n","Epoch 13/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9495 - accuracy: 0.5036 - val_loss: 0.9330 - val_accuracy: 0.4855\n","Epoch 14/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9193 - accuracy: 0.5039 - val_loss: 0.9047 - val_accuracy: 0.4855\n","Epoch 15/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8925 - accuracy: 0.5036 - val_loss: 0.8797 - val_accuracy: 0.4855\n","Epoch 16/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8690 - accuracy: 0.5096 - val_loss: 0.8578 - val_accuracy: 0.4855\n","Epoch 17/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8479 - accuracy: 0.5036 - val_loss: 0.8380 - val_accuracy: 0.4855\n","Epoch 18/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8291 - accuracy: 0.5393 - val_loss: 0.8214 - val_accuracy: 0.4855\n","Epoch 19/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8100 - accuracy: 0.5628 - val_loss: 0.8067 - val_accuracy: 0.5062\n","Epoch 20/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7820 - accuracy: 0.5850 - val_loss: 0.7726 - val_accuracy: 0.5713\n","Epoch 21/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7672 - accuracy: 0.5969 - val_loss: 0.7803 - val_accuracy: 0.5382\n","Epoch 22/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7447 - accuracy: 0.6147 - val_loss: 0.7755 - val_accuracy: 0.5331\n","Epoch 23/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7261 - accuracy: 0.6318 - val_loss: 0.7584 - val_accuracy: 0.5764\n","Epoch 24/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.7191 - accuracy: 0.6238 - val_loss: 0.7357 - val_accuracy: 0.5888\n","Epoch 25/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7025 - accuracy: 0.6488 - val_loss: 0.7317 - val_accuracy: 0.5868\n","Epoch 26/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.6842 - accuracy: 0.6605 - val_loss: 0.7083 - val_accuracy: 0.6260\n","Epoch 27/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.6749 - accuracy: 0.6682 - val_loss: 0.7018 - val_accuracy: 0.6384\n","Epoch 28/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6599 - accuracy: 0.6770 - val_loss: 0.7131 - val_accuracy: 0.6343\n","Epoch 29/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6461 - accuracy: 0.6889 - val_loss: 0.7037 - val_accuracy: 0.6209\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6428 - accuracy: 0.6974 - val_loss: 0.6931 - val_accuracy: 0.6343\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6338 - accuracy: 0.6891 - val_loss: 0.7242 - val_accuracy: 0.5971\n","Epoch 32/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6089 - accuracy: 0.7238 - val_loss: 0.7522 - val_accuracy: 0.6012\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5914 - accuracy: 0.7336 - val_loss: 0.7402 - val_accuracy: 0.6136\n","Epoch 34/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5763 - accuracy: 0.7473 - val_loss: 0.7599 - val_accuracy: 0.6012\n","Epoch 35/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5598 - accuracy: 0.7512 - val_loss: 0.7325 - val_accuracy: 0.6054\n","Epoch 36/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5583 - accuracy: 0.7475 - val_loss: 0.7374 - val_accuracy: 0.6012\n","Epoch 37/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5151 - accuracy: 0.7881 - val_loss: 0.7867 - val_accuracy: 0.6054\n","Epoch 38/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5007 - accuracy: 0.7943 - val_loss: 0.7772 - val_accuracy: 0.6167\n","Epoch 39/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4851 - accuracy: 0.8026 - val_loss: 0.9775 - val_accuracy: 0.5950\n","Epoch 40/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4887 - accuracy: 0.7948 - val_loss: 0.8470 - val_accuracy: 0.6136\n","Epoch 41/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4245 - accuracy: 0.8336 - val_loss: 0.8737 - val_accuracy: 0.6033\n","Epoch 42/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4568 - accuracy: 0.8101 - val_loss: 0.8145 - val_accuracy: 0.6147\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3891 - accuracy: 0.8563 - val_loss: 0.9585 - val_accuracy: 0.6002\n","Epoch 44/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3774 - accuracy: 0.8553 - val_loss: 0.9265 - val_accuracy: 0.5868\n","Epoch 45/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4143 - accuracy: 0.8292 - val_loss: 0.8540 - val_accuracy: 0.6126\n","Epoch 46/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3247 - accuracy: 0.8897 - val_loss: 1.1541 - val_accuracy: 0.5868\n","Epoch 47/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3204 - accuracy: 0.8814 - val_loss: 1.0369 - val_accuracy: 0.6033\n","Epoch 48/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3032 - accuracy: 0.8946 - val_loss: 1.1301 - val_accuracy: 0.5961\n","Epoch 49/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2784 - accuracy: 0.9041 - val_loss: 1.1635 - val_accuracy: 0.6043\n","Epoch 50/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3072 - accuracy: 0.8897 - val_loss: 1.0657 - val_accuracy: 0.5909\n","Epoch 51/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2635 - accuracy: 0.9096 - val_loss: 1.2147 - val_accuracy: 0.5868\n","Epoch 52/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2068 - accuracy: 0.9372 - val_loss: 1.2440 - val_accuracy: 0.5971\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2220 - accuracy: 0.9245 - val_loss: 1.2841 - val_accuracy: 0.6043\n","Epoch 54/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2165 - accuracy: 0.9271 - val_loss: 1.2241 - val_accuracy: 0.5806\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1743 - accuracy: 0.9488 - val_loss: 1.2920 - val_accuracy: 0.5992\n","Epoch 56/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1732 - accuracy: 0.9475 - val_loss: 1.4003 - val_accuracy: 0.5816\n","Epoch 57/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1928 - accuracy: 0.9395 - val_loss: 1.3147 - val_accuracy: 0.5806\n","Epoch 58/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1833 - accuracy: 0.9442 - val_loss: 1.2963 - val_accuracy: 0.5919\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1419 - accuracy: 0.9646 - val_loss: 1.5021 - val_accuracy: 0.5754\n","Epoch 60/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1448 - accuracy: 0.9602 - val_loss: 1.4543 - val_accuracy: 0.5940\n","Epoch 61/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1254 - accuracy: 0.9682 - val_loss: 1.4649 - val_accuracy: 0.5899\n","Epoch 62/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1354 - accuracy: 0.9641 - val_loss: 1.4285 - val_accuracy: 0.5847\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1329 - accuracy: 0.9646 - val_loss: 1.4981 - val_accuracy: 0.5826\n","Epoch 64/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1084 - accuracy: 0.9747 - val_loss: 1.5571 - val_accuracy: 0.5950\n","Epoch 65/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1065 - accuracy: 0.9747 - val_loss: 1.5235 - val_accuracy: 0.5661\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0898 - accuracy: 0.9824 - val_loss: 1.7094 - val_accuracy: 0.5754\n","Epoch 67/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1045 - accuracy: 0.9760 - val_loss: 1.6613 - val_accuracy: 0.5610\n","Epoch 68/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.1059 - accuracy: 0.9718 - val_loss: 1.5257 - val_accuracy: 0.5950\n","Epoch 69/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0879 - accuracy: 0.9804 - val_loss: 1.5864 - val_accuracy: 0.5961\n","Epoch 70/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0879 - accuracy: 0.9798 - val_loss: 1.7982 - val_accuracy: 0.5589\n","Epoch 71/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1374 - accuracy: 0.9558 - val_loss: 1.4582 - val_accuracy: 0.5713\n","Epoch 72/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.1131 - accuracy: 0.9693 - val_loss: 1.6779 - val_accuracy: 0.5764\n","Epoch 73/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1220 - accuracy: 0.9643 - val_loss: 1.5441 - val_accuracy: 0.5785\n","Epoch 74/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0924 - accuracy: 0.9757 - val_loss: 1.7060 - val_accuracy: 0.5971\n","Epoch 75/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0832 - accuracy: 0.9822 - val_loss: 1.6739 - val_accuracy: 0.5806\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0657 - accuracy: 0.9855 - val_loss: 1.8065 - val_accuracy: 0.5878\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0582 - accuracy: 0.9889 - val_loss: 1.8132 - val_accuracy: 0.5775\n","Epoch 78/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0686 - accuracy: 0.9845 - val_loss: 1.7909 - val_accuracy: 0.5702\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0859 - accuracy: 0.9778 - val_loss: 1.9211 - val_accuracy: 0.5785\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0862 - accuracy: 0.9791 - val_loss: 1.8822 - val_accuracy: 0.5733\n","Epoch 81/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0638 - accuracy: 0.9876 - val_loss: 1.8268 - val_accuracy: 0.5795\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0511 - accuracy: 0.9920 - val_loss: 1.9903 - val_accuracy: 0.5816\n","Epoch 83/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0449 - accuracy: 0.9925 - val_loss: 2.0301 - val_accuracy: 0.5837\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0422 - accuracy: 0.9938 - val_loss: 2.0805 - val_accuracy: 0.5754\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0492 - accuracy: 0.9889 - val_loss: 2.1373 - val_accuracy: 0.5857\n","Epoch 86/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0769 - accuracy: 0.9801 - val_loss: 1.8283 - val_accuracy: 0.5610\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1534 - accuracy: 0.9525 - val_loss: 1.7639 - val_accuracy: 0.5733\n","Epoch 88/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0666 - accuracy: 0.9814 - val_loss: 1.9383 - val_accuracy: 0.5496\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0502 - accuracy: 0.9907 - val_loss: 1.9628 - val_accuracy: 0.5775\n","Epoch 90/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0464 - accuracy: 0.9910 - val_loss: 2.1517 - val_accuracy: 0.5806\n","Epoch 91/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.0430 - accuracy: 0.9912 - val_loss: 2.1809 - val_accuracy: 0.5888\n","Epoch 92/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.0622 - accuracy: 0.9840 - val_loss: 2.2401 - val_accuracy: 0.5661\n","Epoch 93/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.1220 - accuracy: 0.9620 - val_loss: 1.9090 - val_accuracy: 0.5630\n","Epoch 94/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0492 - accuracy: 0.9889 - val_loss: 2.0933 - val_accuracy: 0.5733\n","Epoch 95/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0664 - accuracy: 0.9822 - val_loss: 1.9994 - val_accuracy: 0.5785\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0802 - accuracy: 0.9755 - val_loss: 2.0881 - val_accuracy: 0.5651\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1311 - accuracy: 0.9558 - val_loss: 1.8356 - val_accuracy: 0.5692\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0425 - accuracy: 0.9904 - val_loss: 2.0129 - val_accuracy: 0.5888\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0294 - accuracy: 0.9951 - val_loss: 2.1921 - val_accuracy: 0.5795\n","Epoch 100/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0289 - accuracy: 0.9948 - val_loss: 2.2554 - val_accuracy: 0.5940\n","{'loss': [1.7665921449661255, 1.6524856090545654, 1.5502525568008423, 1.4574735164642334, 1.373512864112854, 1.2977429628372192, 1.2296271324157715, 1.1685879230499268, 1.1140542030334473, 1.0654107332229614, 1.022121548652649, 0.9836974740028381, 0.9495149254798889, 0.9192931056022644, 0.8925414085388184, 0.8689767718315125, 0.8478940725326538, 0.8290655612945557, 0.8099933862686157, 0.7820279598236084, 0.767188549041748, 0.7447003722190857, 0.7260720133781433, 0.7191271781921387, 0.702463686466217, 0.6842390894889832, 0.6749269366264343, 0.6599433422088623, 0.6461041569709778, 0.6428297758102417, 0.6337745189666748, 0.6088999509811401, 0.5914469361305237, 0.576335072517395, 0.5598000288009644, 0.5582525134086609, 0.5150964856147766, 0.5006639361381531, 0.48508408665657043, 0.4886940121650696, 0.42447394132614136, 0.4567778706550598, 0.3890589475631714, 0.3774193823337555, 0.4142521321773529, 0.32472777366638184, 0.3203873634338379, 0.3031582832336426, 0.2784000635147095, 0.3071843385696411, 0.2635369300842285, 0.20675954222679138, 0.2220437377691269, 0.2164989709854126, 0.17431792616844177, 0.17323724925518036, 0.19282038509845734, 0.1832890659570694, 0.14191584289073944, 0.14482152462005615, 0.12542477250099182, 0.1353864073753357, 0.1328669637441635, 0.10836954414844513, 0.10649974644184113, 0.08982061594724655, 0.10450717061758041, 0.10594049841165543, 0.08787568658590317, 0.08789236843585968, 0.13741637766361237, 0.11310940235853195, 0.12195122241973877, 0.09241481125354767, 0.08320827782154083, 0.06568806618452072, 0.058152951300144196, 0.06861962378025055, 0.08594093471765518, 0.08618210256099701, 0.06381015479564667, 0.05106563866138458, 0.04489090293645859, 0.04221320152282715, 0.04915948957204819, 0.07692823559045792, 0.15340226888656616, 0.06660879403352737, 0.05022483691573143, 0.046392787247896194, 0.04299524426460266, 0.06217008829116821, 0.12195225059986115, 0.04923824220895767, 0.06641193479299545, 0.08018749207258224, 0.1311240941286087, 0.04245217517018318, 0.029416291043162346, 0.028870459645986557], 'accuracy': [0.4937984347343445, 0.5025839805603027, 0.5, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5064599514007568, 0.5036175847053528, 0.5036175847053528, 0.5036175847053528, 0.5038759708404541, 0.5036175847053528, 0.5036175847053528, 0.5038759708404541, 0.5036175847053528, 0.5095607042312622, 0.5036175847053528, 0.5392764806747437, 0.5627906918525696, 0.5850129127502441, 0.5968992114067078, 0.6147286891937256, 0.6317829489707947, 0.6237726211547852, 0.6488372087478638, 0.6604651212692261, 0.6682170629501343, 0.6770026087760925, 0.6888889074325562, 0.6974160075187683, 0.6891472935676575, 0.7237725853919983, 0.7335917353630066, 0.7472867965698242, 0.7511627674102783, 0.7475452423095703, 0.7881137132644653, 0.7943152189254761, 0.8025839924812317, 0.7948320508003235, 0.8335917592048645, 0.8100775480270386, 0.8563307523727417, 0.8552971482276917, 0.829198956489563, 0.8896640539169312, 0.8813953399658203, 0.8945736289024353, 0.9041343927383423, 0.8896640539169312, 0.9095607399940491, 0.9372093081474304, 0.9245477914810181, 0.9271317720413208, 0.9488372206687927, 0.9475452303886414, 0.9395349025726318, 0.9441860318183899, 0.9645994901657104, 0.9602067470550537, 0.9682170748710632, 0.964082658290863, 0.9645994901657104, 0.9746770262718201, 0.9746770262718201, 0.9824289679527283, 0.9759690165519714, 0.9718345999717712, 0.9803617596626282, 0.9798449873924255, 0.9558139443397522, 0.9692506194114685, 0.9643411040306091, 0.9757105708122253, 0.9821705222129822, 0.9855297207832336, 0.9888888597488403, 0.9844961166381836, 0.9777777791023254, 0.9790697693824768, 0.987596869468689, 0.9919896721839905, 0.9925064444541931, 0.9937984347343445, 0.9888888597488403, 0.9801033735275269, 0.9524548053741455, 0.9813953638076782, 0.9906976819038391, 0.9909560680389404, 0.9912144541740417, 0.983979344367981, 0.9620155096054077, 0.9888888597488403, 0.9821705222129822, 0.975452184677124, 0.9558139443397522, 0.9904392957687378, 0.9950904250144958, 0.9948320388793945], 'val_loss': [1.7039337158203125, 1.5965352058410645, 1.4996742010116577, 1.4117847681045532, 1.3322453498840332, 1.2606077194213867, 1.196347951889038, 1.1388568878173828, 1.0875635147094727, 1.0418365001678467, 1.0011197328567505, 0.9650692343711853, 0.9330453872680664, 0.9047166705131531, 0.8797202110290527, 0.8577594757080078, 0.8380201458930969, 0.8214176893234253, 0.8067285418510437, 0.7726202607154846, 0.7802976369857788, 0.7754588723182678, 0.7583563923835754, 0.7356827259063721, 0.7316727638244629, 0.7082594633102417, 0.7018137574195862, 0.7131252288818359, 0.703723132610321, 0.6930839419364929, 0.7242473363876343, 0.7522473931312561, 0.7402306199073792, 0.7599495649337769, 0.7324540615081787, 0.7374005317687988, 0.78673255443573, 0.7772489190101624, 0.977520227432251, 0.8469841480255127, 0.8736943006515503, 0.8144508004188538, 0.9584763050079346, 0.9265250563621521, 0.8540107607841492, 1.1540544033050537, 1.036932349205017, 1.1300911903381348, 1.1634714603424072, 1.0657074451446533, 1.2146575450897217, 1.2440499067306519, 1.284071683883667, 1.2240544557571411, 1.2919842004776, 1.4002509117126465, 1.314692497253418, 1.2962582111358643, 1.502114176750183, 1.4543192386627197, 1.4648566246032715, 1.4284937381744385, 1.4981064796447754, 1.5570510625839233, 1.5234858989715576, 1.7094076871871948, 1.6613093614578247, 1.5256965160369873, 1.5864020586013794, 1.7981932163238525, 1.4582288265228271, 1.6778889894485474, 1.5441231727600098, 1.7060022354125977, 1.6739153861999512, 1.8064936399459839, 1.813239574432373, 1.7908945083618164, 1.9210683107376099, 1.882168173789978, 1.8267852067947388, 1.9902523756027222, 2.030109405517578, 2.0804543495178223, 2.13734769821167, 1.8282828330993652, 1.763925313949585, 1.9382615089416504, 1.9628424644470215, 2.1516547203063965, 2.180859327316284, 2.2401041984558105, 1.9090125560760498, 2.0933165550231934, 1.9993889331817627, 2.0881214141845703, 1.8356215953826904, 2.0128729343414307, 2.1920602321624756, 2.2554197311401367], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.5061983466148376, 0.5712810158729553, 0.538223147392273, 0.5330578684806824, 0.5764462947845459, 0.5888429880142212, 0.586776852607727, 0.6260330677032471, 0.6384297609329224, 0.6342975497245789, 0.6208677887916565, 0.6342975497245789, 0.5971074104309082, 0.6012396812438965, 0.6136363744735718, 0.6012396812438965, 0.60537189245224, 0.6012396812438965, 0.60537189245224, 0.6167355179786682, 0.5950413346290588, 0.6136363744735718, 0.6033057570457458, 0.6146694421768188, 0.6002066135406494, 0.586776852607727, 0.6126033067703247, 0.586776852607727, 0.6033057570457458, 0.5960744023323059, 0.6043388247489929, 0.5909090638160706, 0.586776852607727, 0.5971074104309082, 0.6043388247489929, 0.5805785059928894, 0.5991735458374023, 0.5816115736961365, 0.5805785059928894, 0.5919421315193176, 0.5754132270812988, 0.5940082669258118, 0.5898760557174683, 0.5847107172012329, 0.5826446413993835, 0.5950413346290588, 0.56611567735672, 0.5754132270812988, 0.5609503984451294, 0.5950413346290588, 0.5960744023323059, 0.55888432264328, 0.5712810158729553, 0.5764462947845459, 0.5785123705863953, 0.5971074104309082, 0.5805785059928894, 0.5878099203109741, 0.577479362487793, 0.5702479481697083, 0.5785123705863953, 0.5733470916748047, 0.5795454382896423, 0.5816115736961365, 0.5836777091026306, 0.5754132270812988, 0.58574378490448, 0.5609503984451294, 0.5733470916748047, 0.5495867729187012, 0.577479362487793, 0.5805785059928894, 0.5888429880142212, 0.56611567735672, 0.5630165338516235, 0.5733470916748047, 0.5785123705863953, 0.5650826692581177, 0.5692148804664612, 0.5888429880142212, 0.5795454382896423, 0.5940082669258118]}\n","32/32 [==============================] - 1s 10ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.5869 - accuracy: 0.7109"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 7s 59ms/step - loss: 0.5869 - accuracy: 0.7109 - val_loss: 0.7040 - val_accuracy: 0.4978\n","Epoch 2/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4795 - accuracy: 0.7915 - val_loss: 0.7021 - val_accuracy: 0.5323\n","Epoch 3/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.4074 - accuracy: 0.8314 - val_loss: 0.6995 - val_accuracy: 0.6272\n","Epoch 4/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3309 - accuracy: 0.8691 - val_loss: 0.6958 - val_accuracy: 0.6228\n","Epoch 5/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3134 - accuracy: 0.8742 - val_loss: 0.6937 - val_accuracy: 0.6218\n","Epoch 6/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2559 - accuracy: 0.9079 - val_loss: 0.6884 - val_accuracy: 0.6067\n","Epoch 7/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2100 - accuracy: 0.9300 - val_loss: 0.6851 - val_accuracy: 0.6034\n","Epoch 8/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1621 - accuracy: 0.9496 - val_loss: 0.6856 - val_accuracy: 0.5614\n","Epoch 9/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2703 - accuracy: 0.8941 - val_loss: 0.6838 - val_accuracy: 0.5830\n","Epoch 10/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1395 - accuracy: 0.9615 - val_loss: 0.6761 - val_accuracy: 0.6013\n","Epoch 11/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1079 - accuracy: 0.9704 - val_loss: 0.7513 - val_accuracy: 0.5205\n","Epoch 12/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1030 - accuracy: 0.9714 - val_loss: 0.7170 - val_accuracy: 0.5657\n","Epoch 13/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0850 - accuracy: 0.9787 - val_loss: 0.7636 - val_accuracy: 0.5647\n","Epoch 14/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0740 - accuracy: 0.9841 - val_loss: 0.8869 - val_accuracy: 0.5485\n","Epoch 15/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0684 - accuracy: 0.9846 - val_loss: 0.8946 - val_accuracy: 0.5539\n","Epoch 16/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0735 - accuracy: 0.9820 - val_loss: 0.9005 - val_accuracy: 0.5959\n","Epoch 17/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0729 - accuracy: 0.9844 - val_loss: 1.2376 - val_accuracy: 0.5312\n","Epoch 18/100\n","29/29 [==============================] - 1s 35ms/step - loss: 0.1273 - accuracy: 0.9612 - val_loss: 1.0690 - val_accuracy: 0.5506\n","Epoch 19/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0947 - accuracy: 0.9731 - val_loss: 1.0786 - val_accuracy: 0.5851\n","Epoch 20/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0705 - accuracy: 0.9833 - val_loss: 1.1762 - val_accuracy: 0.6067\n","Epoch 21/100\n","29/29 [==============================] - 2s 67ms/step - loss: 0.0526 - accuracy: 0.9903 - val_loss: 1.2222 - val_accuracy: 0.6379\n","Epoch 22/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0490 - accuracy: 0.9914 - val_loss: 1.2731 - val_accuracy: 0.6487\n","Epoch 23/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0515 - accuracy: 0.9914 - val_loss: 1.2428 - val_accuracy: 0.6649\n","Epoch 24/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0456 - accuracy: 0.9935 - val_loss: 1.4542 - val_accuracy: 0.6476\n","Epoch 25/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0510 - accuracy: 0.9903 - val_loss: 1.3498 - val_accuracy: 0.6681\n","Epoch 26/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0599 - accuracy: 0.9841 - val_loss: 1.4389 - val_accuracy: 0.6692\n","Epoch 27/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0829 - accuracy: 0.9760 - val_loss: 1.3032 - val_accuracy: 0.6530\n","Epoch 28/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.0731 - accuracy: 0.9795 - val_loss: 1.3460 - val_accuracy: 0.6950\n","Epoch 29/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0983 - accuracy: 0.9696 - val_loss: 1.3330 - val_accuracy: 0.6616\n","Epoch 30/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0566 - accuracy: 0.9868 - val_loss: 1.4123 - val_accuracy: 0.6756\n","Epoch 31/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0441 - accuracy: 0.9914 - val_loss: 1.5888 - val_accuracy: 0.6347\n","Epoch 32/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0419 - accuracy: 0.9930 - val_loss: 1.5238 - val_accuracy: 0.6692\n","Epoch 33/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0346 - accuracy: 0.9952 - val_loss: 1.5662 - val_accuracy: 0.6692\n","Epoch 34/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0461 - accuracy: 0.9914 - val_loss: 1.5379 - val_accuracy: 0.6681\n","Epoch 35/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0341 - accuracy: 0.9960 - val_loss: 1.7335 - val_accuracy: 0.6853\n","Epoch 36/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0328 - accuracy: 0.9965 - val_loss: 1.8196 - val_accuracy: 0.6778\n","Epoch 37/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0467 - accuracy: 0.9900 - val_loss: 1.6000 - val_accuracy: 0.6509\n","Epoch 38/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0482 - accuracy: 0.9898 - val_loss: 1.5739 - val_accuracy: 0.6789\n","Epoch 39/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0314 - accuracy: 0.9970 - val_loss: 1.6366 - val_accuracy: 0.6789\n","Epoch 40/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0324 - accuracy: 0.9954 - val_loss: 1.7940 - val_accuracy: 0.6573\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0346 - accuracy: 0.9946 - val_loss: 1.6022 - val_accuracy: 0.6735\n","Epoch 42/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0325 - accuracy: 0.9965 - val_loss: 1.5996 - val_accuracy: 0.6853\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0350 - accuracy: 0.9941 - val_loss: 1.6640 - val_accuracy: 0.6681\n","Epoch 44/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0452 - accuracy: 0.9898 - val_loss: 1.6920 - val_accuracy: 0.6606\n","Epoch 45/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0595 - accuracy: 0.9849 - val_loss: 1.7135 - val_accuracy: 0.6724\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0662 - accuracy: 0.9806 - val_loss: 1.4735 - val_accuracy: 0.6756\n","Epoch 47/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0816 - accuracy: 0.9731 - val_loss: 1.4129 - val_accuracy: 0.6659\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1007 - accuracy: 0.9712 - val_loss: 1.2417 - val_accuracy: 0.6810\n","Epoch 49/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0351 - accuracy: 0.9946 - val_loss: 1.5653 - val_accuracy: 0.6843\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0305 - accuracy: 0.9957 - val_loss: 1.5800 - val_accuracy: 0.6875\n","Epoch 51/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0260 - accuracy: 0.9978 - val_loss: 1.6292 - val_accuracy: 0.6810\n","Epoch 52/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0275 - accuracy: 0.9978 - val_loss: 1.6767 - val_accuracy: 0.6940\n","Epoch 53/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0235 - accuracy: 0.9984 - val_loss: 1.6222 - val_accuracy: 0.6864\n","Epoch 54/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0229 - accuracy: 0.9981 - val_loss: 1.6132 - val_accuracy: 0.6929\n","Epoch 55/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0233 - accuracy: 0.9976 - val_loss: 1.6636 - val_accuracy: 0.6864\n","Epoch 56/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0269 - accuracy: 0.9965 - val_loss: 1.6380 - val_accuracy: 0.6778\n","Epoch 57/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0229 - accuracy: 0.9976 - val_loss: 1.6543 - val_accuracy: 0.6918\n","Epoch 58/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0219 - accuracy: 0.9973 - val_loss: 1.6504 - val_accuracy: 0.6832\n","Epoch 59/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0215 - accuracy: 0.9984 - val_loss: 1.6504 - val_accuracy: 0.6864\n","Epoch 60/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0218 - accuracy: 0.9981 - val_loss: 1.8391 - val_accuracy: 0.6821\n","Epoch 61/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0215 - accuracy: 0.9978 - val_loss: 1.7228 - val_accuracy: 0.6864\n","Epoch 62/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0202 - accuracy: 0.9981 - val_loss: 1.6752 - val_accuracy: 0.6832\n","Epoch 63/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0212 - accuracy: 0.9981 - val_loss: 1.6854 - val_accuracy: 0.6746\n","Epoch 64/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0230 - accuracy: 0.9973 - val_loss: 1.6597 - val_accuracy: 0.6843\n","Epoch 65/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0201 - accuracy: 0.9981 - val_loss: 1.8505 - val_accuracy: 0.6638\n","Epoch 66/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0207 - accuracy: 0.9984 - val_loss: 1.7030 - val_accuracy: 0.6832\n","Epoch 67/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0196 - accuracy: 0.9984 - val_loss: 1.7815 - val_accuracy: 0.6767\n","Epoch 68/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0245 - accuracy: 0.9960 - val_loss: 1.6873 - val_accuracy: 0.6789\n","Epoch 69/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0318 - accuracy: 0.9927 - val_loss: 1.6515 - val_accuracy: 0.6843\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0582 - accuracy: 0.9844 - val_loss: 1.5065 - val_accuracy: 0.6703\n","Epoch 71/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1827 - accuracy: 0.9324 - val_loss: 1.1589 - val_accuracy: 0.6390\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0829 - accuracy: 0.9763 - val_loss: 1.4573 - val_accuracy: 0.6724\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0339 - accuracy: 0.9930 - val_loss: 1.6747 - val_accuracy: 0.6552\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0411 - accuracy: 0.9906 - val_loss: 1.7457 - val_accuracy: 0.6433\n","Epoch 75/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0639 - accuracy: 0.9798 - val_loss: 1.3434 - val_accuracy: 0.6703\n","Epoch 76/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0492 - accuracy: 0.9887 - val_loss: 1.5540 - val_accuracy: 0.6703\n","Epoch 77/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0244 - accuracy: 0.9960 - val_loss: 1.7301 - val_accuracy: 0.6789\n","Epoch 78/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0271 - accuracy: 0.9954 - val_loss: 1.6577 - val_accuracy: 0.6789\n","Epoch 79/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0325 - accuracy: 0.9943 - val_loss: 1.6778 - val_accuracy: 0.6810\n","Epoch 80/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0324 - accuracy: 0.9935 - val_loss: 1.6627 - val_accuracy: 0.6810\n","Epoch 81/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0326 - accuracy: 0.9927 - val_loss: 1.6728 - val_accuracy: 0.6756\n","Epoch 82/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0325 - accuracy: 0.9930 - val_loss: 1.7545 - val_accuracy: 0.6530\n","Epoch 83/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0237 - accuracy: 0.9954 - val_loss: 1.7865 - val_accuracy: 0.6649\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0200 - accuracy: 0.9976 - val_loss: 1.9467 - val_accuracy: 0.6541\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0245 - accuracy: 0.9960 - val_loss: 1.7591 - val_accuracy: 0.6767\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0218 - accuracy: 0.9968 - val_loss: 1.7776 - val_accuracy: 0.6875\n","Epoch 87/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0222 - accuracy: 0.9962 - val_loss: 1.9082 - val_accuracy: 0.6466\n","Epoch 88/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0221 - accuracy: 0.9968 - val_loss: 1.9668 - val_accuracy: 0.6530\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0265 - accuracy: 0.9957 - val_loss: 1.7514 - val_accuracy: 0.6832\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0550 - accuracy: 0.9868 - val_loss: 1.5379 - val_accuracy: 0.6541\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1078 - accuracy: 0.9661 - val_loss: 1.1672 - val_accuracy: 0.6606\n","Epoch 92/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0376 - accuracy: 0.9914 - val_loss: 1.7130 - val_accuracy: 0.6616\n","Epoch 93/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0226 - accuracy: 0.9970 - val_loss: 1.6674 - val_accuracy: 0.6810\n","Epoch 94/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0214 - accuracy: 0.9970 - val_loss: 1.7107 - val_accuracy: 0.6735\n","Epoch 95/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0193 - accuracy: 0.9976 - val_loss: 1.8352 - val_accuracy: 0.6670\n","Epoch 96/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0183 - accuracy: 0.9981 - val_loss: 1.9301 - val_accuracy: 0.6821\n","Epoch 97/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0194 - accuracy: 0.9976 - val_loss: 1.7401 - val_accuracy: 0.6735\n","Epoch 98/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0176 - accuracy: 0.9989 - val_loss: 1.7935 - val_accuracy: 0.6659\n","Epoch 99/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0174 - accuracy: 0.9981 - val_loss: 1.8891 - val_accuracy: 0.6681\n","Epoch 100/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0192 - accuracy: 0.9965 - val_loss: 1.9459 - val_accuracy: 0.6606\n","{'loss': [0.5868586897850037, 0.47948867082595825, 0.40737155079841614, 0.33092957735061646, 0.3134044110774994, 0.25594857335090637, 0.20995567739009857, 0.16208983957767487, 0.2702532112598419, 0.13952377438545227, 0.10790851712226868, 0.10301009565591812, 0.0849713459610939, 0.07400918006896973, 0.06842674314975739, 0.07345949858427048, 0.07291951030492783, 0.12725546956062317, 0.09471453726291656, 0.07047142833471298, 0.05261388048529625, 0.0490463562309742, 0.05149741843342781, 0.045590709894895554, 0.05104804411530495, 0.05994151905179024, 0.08286571502685547, 0.07310840487480164, 0.098297618329525, 0.056612130254507065, 0.044094931334257126, 0.04187731444835663, 0.034562308341264725, 0.04614703357219696, 0.03414761275053024, 0.03281276300549507, 0.04665401205420494, 0.048154234886169434, 0.03143095225095749, 0.03239813819527626, 0.03457428514957428, 0.03253550827503204, 0.03500722721219063, 0.04519077390432358, 0.059476546943187714, 0.06624311208724976, 0.08156275004148483, 0.1006983295083046, 0.035139307379722595, 0.03049572929739952, 0.025991367176175117, 0.027544979006052017, 0.023527396842837334, 0.022915171459317207, 0.02325352095067501, 0.026912031695246696, 0.022917652502655983, 0.021917179226875305, 0.021549636498093605, 0.021841013804078102, 0.021547017619013786, 0.020154841244220734, 0.021249955520033836, 0.022964296862483025, 0.020064501091837883, 0.020738942548632622, 0.019616330042481422, 0.024494243785738945, 0.03179473429918289, 0.0582459531724453, 0.1826784759759903, 0.08287915587425232, 0.03390255197882652, 0.041080862283706665, 0.06394609808921814, 0.04922004044055939, 0.02440161257982254, 0.02705138362944126, 0.032524581998586655, 0.03238864988088608, 0.032589782029390335, 0.03246702253818512, 0.023742761462926865, 0.019991343840956688, 0.024519599974155426, 0.021766528487205505, 0.022199926897883415, 0.02209191769361496, 0.02647027187049389, 0.055026207119226456, 0.10779941827058792, 0.03758034482598305, 0.022575343027710915, 0.021397992968559265, 0.019279107451438904, 0.01826641894876957, 0.019360041245818138, 0.017561590299010277, 0.017363861203193665, 0.019236618652939796], 'accuracy': [0.7109375, 0.7914870977401733, 0.8313577771186829, 0.8690732717514038, 0.8741918206214905, 0.907866358757019, 0.9299569129943848, 0.9496228694915771, 0.8941271305084229, 0.9614762663841248, 0.970366358757019, 0.9714439511299133, 0.9787176847457886, 0.9841055870056152, 0.9846444129943848, 0.9819504022598267, 0.984375, 0.9612069129943848, 0.9730603694915771, 0.9832974076271057, 0.9903017282485962, 0.9913793206214905, 0.9913793206214905, 0.993534505367279, 0.9903017282485962, 0.9841055870056152, 0.9760237336158752, 0.9795258641242981, 0.9695581793785095, 0.9867995977401733, 0.9913793206214905, 0.9929956793785095, 0.9951508641242981, 0.9913793206214905, 0.9959590435028076, 0.9964978694915771, 0.9900323152542114, 0.9897629022598267, 0.9970366358757019, 0.9954202771186829, 0.9946120977401733, 0.9964978694915771, 0.9940732717514038, 0.9897629022598267, 0.9849137663841248, 0.9806034564971924, 0.9730603694915771, 0.9711745977401733, 0.9946120977401733, 0.9956896305084229, 0.9978448152542114, 0.9978448152542114, 0.998383641242981, 0.9981142282485962, 0.9975754022598267, 0.9964978694915771, 0.9975754022598267, 0.9973060488700867, 0.998383641242981, 0.9981142282485962, 0.9978448152542114, 0.9981142282485962, 0.9981142282485962, 0.9973060488700867, 0.9981142282485962, 0.998383641242981, 0.998383641242981, 0.9959590435028076, 0.9927262663841248, 0.984375, 0.9323814511299133, 0.9762930870056152, 0.9929956793785095, 0.990571141242981, 0.9797952771186829, 0.9886853694915771, 0.9959590435028076, 0.9954202771186829, 0.9943426847457886, 0.993534505367279, 0.9927262663841248, 0.9929956793785095, 0.9954202771186829, 0.9975754022598267, 0.9959590435028076, 0.9967672228813171, 0.9962284564971924, 0.9967672228813171, 0.9956896305084229, 0.9867995977401733, 0.9660560488700867, 0.9913793206214905, 0.9970366358757019, 0.9970366358757019, 0.9975754022598267, 0.9981142282485962, 0.9975754022598267, 0.9989224076271057, 0.9981142282485962, 0.9964978694915771], 'val_loss': [0.7040345668792725, 0.7020859122276306, 0.6995353698730469, 0.6957665681838989, 0.6936681866645813, 0.688352644443512, 0.6851258873939514, 0.6855528354644775, 0.68379807472229, 0.6761153936386108, 0.7513449192047119, 0.7169566750526428, 0.763562798500061, 0.8869121074676514, 0.8945943713188171, 0.9005321264266968, 1.2376493215560913, 1.0689949989318848, 1.0786020755767822, 1.1762261390686035, 1.222152590751648, 1.2730844020843506, 1.2427914142608643, 1.4542080163955688, 1.349755048751831, 1.4388941526412964, 1.3031642436981201, 1.3459588289260864, 1.3329887390136719, 1.4123003482818604, 1.5887678861618042, 1.5237897634506226, 1.5662249326705933, 1.5378568172454834, 1.7335423231124878, 1.8196394443511963, 1.5999643802642822, 1.5738626718521118, 1.6365721225738525, 1.7940078973770142, 1.6022202968597412, 1.5995733737945557, 1.6639775037765503, 1.691973090171814, 1.7134641408920288, 1.4734858274459839, 1.412886619567871, 1.2417206764221191, 1.5653265714645386, 1.5799890756607056, 1.629237174987793, 1.6767340898513794, 1.6222312450408936, 1.6131917238235474, 1.6635549068450928, 1.638043761253357, 1.6542601585388184, 1.6504441499710083, 1.6504453420639038, 1.8390902280807495, 1.7227810621261597, 1.6751827001571655, 1.6854259967803955, 1.6596605777740479, 1.8505425453186035, 1.7030221223831177, 1.7814542055130005, 1.6872578859329224, 1.6514654159545898, 1.5064579248428345, 1.1588771343231201, 1.4572525024414062, 1.6747252941131592, 1.7457183599472046, 1.343448519706726, 1.5540375709533691, 1.7300920486450195, 1.6576802730560303, 1.6778331995010376, 1.662675142288208, 1.6727527379989624, 1.7544629573822021, 1.786525845527649, 1.9467097520828247, 1.7590996026992798, 1.7775988578796387, 1.9082165956497192, 1.9667731523513794, 1.7513747215270996, 1.5378601551055908, 1.1672215461730957, 1.7129911184310913, 1.6673682928085327, 1.7107272148132324, 1.8351948261260986, 1.930059790611267, 1.7400628328323364, 1.79347825050354, 1.8890800476074219, 1.9459316730499268], 'val_accuracy': [0.4978448152542114, 0.5323275923728943, 0.6271551847457886, 0.6228448152542114, 0.6217672228813171, 0.6066810488700867, 0.6034482717514038, 0.5614224076271057, 0.5829741358757019, 0.6012930870056152, 0.5204741358757019, 0.5657327771186829, 0.5646551847457886, 0.548491358757019, 0.5538793206214905, 0.5959051847457886, 0.53125, 0.5506465435028076, 0.5851293206214905, 0.6066810488700867, 0.6379310488700867, 0.6487069129943848, 0.6648706793785095, 0.6476293206214905, 0.6681034564971924, 0.6691810488700867, 0.6530172228813171, 0.6950430870056152, 0.6616379022598267, 0.6756465435028076, 0.6346982717514038, 0.6691810488700867, 0.6691810488700867, 0.6681034564971924, 0.6853448152542114, 0.6778017282485962, 0.6508620977401733, 0.6788793206214905, 0.6788793206214905, 0.6573275923728943, 0.673491358757019, 0.6853448152542114, 0.6681034564971924, 0.6605603694915771, 0.6724137663841248, 0.6756465435028076, 0.6659482717514038, 0.681034505367279, 0.6842672228813171, 0.6875, 0.681034505367279, 0.693965494632721, 0.6864224076271057, 0.6928879022598267, 0.6864224076271057, 0.6778017282485962, 0.6918103694915771, 0.6831896305084229, 0.6864224076271057, 0.6821120977401733, 0.6864224076271057, 0.6831896305084229, 0.6745689511299133, 0.6842672228813171, 0.6637930870056152, 0.6831896305084229, 0.6767241358757019, 0.6788793206214905, 0.6842672228813171, 0.670258641242981, 0.639008641242981, 0.6724137663841248, 0.6551724076271057, 0.6433189511299133, 0.670258641242981, 0.670258641242981, 0.6788793206214905, 0.6788793206214905, 0.681034505367279, 0.681034505367279, 0.6756465435028076, 0.6530172228813171, 0.6648706793785095, 0.6540948152542114, 0.6767241358757019, 0.6875, 0.6465517282485962, 0.6530172228813171, 0.6831896305084229, 0.6540948152542114, 0.6605603694915771, 0.6616379022598267, 0.681034505367279, 0.673491358757019, 0.6670258641242981, 0.6821120977401733, 0.673491358757019, 0.6659482717514038, 0.6681034564971924, 0.6605603694915771]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.5991 - accuracy: 0.7031"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 83ms/step - loss: 0.5993 - accuracy: 0.7035 - val_loss: 0.7036 - val_accuracy: 0.5045\n","Epoch 2/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.5027 - accuracy: 0.7697 - val_loss: 0.7024 - val_accuracy: 0.5215\n","Epoch 3/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.4433 - accuracy: 0.8200 - val_loss: 0.6994 - val_accuracy: 0.6109\n","Epoch 4/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4050 - accuracy: 0.8333 - val_loss: 0.6980 - val_accuracy: 0.5973\n","Epoch 5/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3305 - accuracy: 0.8797 - val_loss: 0.6936 - val_accuracy: 0.6176\n","Epoch 6/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.2994 - accuracy: 0.8896 - val_loss: 0.6893 - val_accuracy: 0.6256\n","Epoch 7/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2324 - accuracy: 0.9259 - val_loss: 0.6866 - val_accuracy: 0.5928\n","Epoch 8/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2224 - accuracy: 0.9244 - val_loss: 0.6802 - val_accuracy: 0.6041\n","Epoch 9/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2029 - accuracy: 0.9346 - val_loss: 0.6725 - val_accuracy: 0.6210\n","Epoch 10/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1368 - accuracy: 0.9612 - val_loss: 0.6689 - val_accuracy: 0.6097\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1229 - accuracy: 0.9646 - val_loss: 0.6744 - val_accuracy: 0.6188\n","Epoch 12/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0975 - accuracy: 0.9791 - val_loss: 0.7229 - val_accuracy: 0.6176\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1182 - accuracy: 0.9669 - val_loss: 0.6833 - val_accuracy: 0.6041\n","Epoch 14/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.1367 - accuracy: 0.9612 - val_loss: 0.7026 - val_accuracy: 0.6290\n","Epoch 15/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0936 - accuracy: 0.9751 - val_loss: 0.7813 - val_accuracy: 0.6097\n","Epoch 16/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1035 - accuracy: 0.9683 - val_loss: 0.7444 - val_accuracy: 0.6290\n","Epoch 17/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0784 - accuracy: 0.9813 - val_loss: 0.8528 - val_accuracy: 0.6120\n","Epoch 18/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0679 - accuracy: 0.9833 - val_loss: 0.9446 - val_accuracy: 0.6109\n","Epoch 19/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0701 - accuracy: 0.9830 - val_loss: 1.0733 - val_accuracy: 0.6052\n","Epoch 20/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.0997 - accuracy: 0.9689 - val_loss: 0.9203 - val_accuracy: 0.6346\n","Epoch 21/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.0577 - accuracy: 0.9890 - val_loss: 1.0711 - val_accuracy: 0.6369\n","Epoch 22/100\n","28/28 [==============================] - 1s 37ms/step - loss: 0.0442 - accuracy: 0.9921 - val_loss: 1.1778 - val_accuracy: 0.6516\n","Epoch 23/100\n","28/28 [==============================] - 1s 37ms/step - loss: 0.0512 - accuracy: 0.9884 - val_loss: 1.2829 - val_accuracy: 0.6527\n","Epoch 24/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0529 - accuracy: 0.9907 - val_loss: 1.2751 - val_accuracy: 0.6606\n","Epoch 25/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0564 - accuracy: 0.9861 - val_loss: 1.3074 - val_accuracy: 0.6550\n","Epoch 26/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0584 - accuracy: 0.9867 - val_loss: 1.5307 - val_accuracy: 0.6471\n","Epoch 27/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0781 - accuracy: 0.9771 - val_loss: 1.4309 - val_accuracy: 0.6459\n","Epoch 28/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0775 - accuracy: 0.9793 - val_loss: 1.2727 - val_accuracy: 0.6697\n","Epoch 29/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0482 - accuracy: 0.9904 - val_loss: 1.3338 - val_accuracy: 0.6765\n","Epoch 30/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0351 - accuracy: 0.9946 - val_loss: 1.4049 - val_accuracy: 0.6810\n","Epoch 31/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0359 - accuracy: 0.9946 - val_loss: 1.5835 - val_accuracy: 0.6652\n","Epoch 32/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0329 - accuracy: 0.9946 - val_loss: 1.5636 - val_accuracy: 0.6765\n","Epoch 33/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0319 - accuracy: 0.9949 - val_loss: 1.5940 - val_accuracy: 0.6799\n","Epoch 34/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0310 - accuracy: 0.9972 - val_loss: 1.6412 - val_accuracy: 0.6618\n","Epoch 35/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0604 - accuracy: 0.9856 - val_loss: 1.4732 - val_accuracy: 0.6595\n","Epoch 36/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0465 - accuracy: 0.9901 - val_loss: 1.6529 - val_accuracy: 0.6550\n","Epoch 37/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0394 - accuracy: 0.9946 - val_loss: 1.6287 - val_accuracy: 0.6719\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0307 - accuracy: 0.9952 - val_loss: 1.6796 - val_accuracy: 0.6742\n","Epoch 39/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0310 - accuracy: 0.9952 - val_loss: 1.7552 - val_accuracy: 0.6742\n","Epoch 40/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0349 - accuracy: 0.9952 - val_loss: 1.7924 - val_accuracy: 0.6482\n","Epoch 41/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0413 - accuracy: 0.9918 - val_loss: 1.5729 - val_accuracy: 0.6674\n","Epoch 42/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0368 - accuracy: 0.9935 - val_loss: 1.6028 - val_accuracy: 0.6663\n","Epoch 43/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0357 - accuracy: 0.9938 - val_loss: 1.7285 - val_accuracy: 0.6697\n","Epoch 44/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0378 - accuracy: 0.9926 - val_loss: 1.7092 - val_accuracy: 0.6765\n","Epoch 45/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0352 - accuracy: 0.9935 - val_loss: 1.7102 - val_accuracy: 0.6765\n","Epoch 46/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0445 - accuracy: 0.9904 - val_loss: 1.6632 - val_accuracy: 0.6595\n","Epoch 47/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0300 - accuracy: 0.9969 - val_loss: 1.7147 - val_accuracy: 0.6493\n","Epoch 48/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0304 - accuracy: 0.9946 - val_loss: 1.8214 - val_accuracy: 0.6629\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0722 - accuracy: 0.9788 - val_loss: 1.7508 - val_accuracy: 0.6357\n","Epoch 50/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0780 - accuracy: 0.9751 - val_loss: 1.4353 - val_accuracy: 0.6708\n","Epoch 51/100\n","28/28 [==============================] - 2s 79ms/step - loss: 0.0742 - accuracy: 0.9785 - val_loss: 1.4102 - val_accuracy: 0.6833\n","Epoch 52/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0434 - accuracy: 0.9890 - val_loss: 1.5355 - val_accuracy: 0.6719\n","Epoch 53/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0282 - accuracy: 0.9955 - val_loss: 1.6896 - val_accuracy: 0.6595\n","Epoch 54/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0253 - accuracy: 0.9969 - val_loss: 1.8211 - val_accuracy: 0.6527\n","Epoch 55/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0240 - accuracy: 0.9966 - val_loss: 1.7754 - val_accuracy: 0.6538\n","Epoch 56/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0370 - accuracy: 0.9909 - val_loss: 1.6451 - val_accuracy: 0.6833\n","Epoch 57/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0399 - accuracy: 0.9895 - val_loss: 1.6471 - val_accuracy: 0.6652\n","Epoch 58/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0298 - accuracy: 0.9952 - val_loss: 1.6357 - val_accuracy: 0.6742\n","Epoch 59/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0261 - accuracy: 0.9958 - val_loss: 1.7549 - val_accuracy: 0.6697\n","Epoch 60/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0297 - accuracy: 0.9952 - val_loss: 1.6736 - val_accuracy: 0.6663\n","Epoch 61/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0221 - accuracy: 0.9977 - val_loss: 1.7385 - val_accuracy: 0.6753\n","Epoch 62/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0176 - accuracy: 0.9992 - val_loss: 1.7872 - val_accuracy: 0.6776\n","Epoch 63/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0176 - accuracy: 0.9986 - val_loss: 1.7881 - val_accuracy: 0.6697\n","Epoch 64/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0184 - accuracy: 0.9986 - val_loss: 1.7755 - val_accuracy: 0.6686\n","Epoch 65/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0186 - accuracy: 0.9986 - val_loss: 1.7269 - val_accuracy: 0.6742\n","Epoch 66/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0171 - accuracy: 0.9992 - val_loss: 1.7209 - val_accuracy: 0.6765\n","Epoch 67/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0166 - accuracy: 0.9989 - val_loss: 1.7581 - val_accuracy: 0.6697\n","Epoch 68/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0186 - accuracy: 0.9986 - val_loss: 1.8555 - val_accuracy: 0.6629\n","Epoch 69/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0168 - accuracy: 0.9986 - val_loss: 1.7596 - val_accuracy: 0.6753\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0161 - accuracy: 0.9992 - val_loss: 1.8470 - val_accuracy: 0.6742\n","Epoch 71/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0170 - accuracy: 0.9992 - val_loss: 1.9244 - val_accuracy: 0.6663\n","Epoch 72/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0156 - accuracy: 0.9994 - val_loss: 1.7715 - val_accuracy: 0.6833\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0163 - accuracy: 0.9992 - val_loss: 1.7439 - val_accuracy: 0.6753\n","Epoch 74/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0166 - accuracy: 0.9992 - val_loss: 1.7210 - val_accuracy: 0.6652\n","Epoch 75/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0151 - accuracy: 0.9994 - val_loss: 1.7459 - val_accuracy: 0.6697\n","Epoch 76/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0165 - accuracy: 0.9986 - val_loss: 1.6834 - val_accuracy: 0.6719\n","Epoch 77/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0153 - accuracy: 0.9989 - val_loss: 1.6817 - val_accuracy: 0.6719\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0141 - accuracy: 0.9994 - val_loss: 1.7036 - val_accuracy: 0.6697\n","Epoch 79/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0138 - accuracy: 0.9994 - val_loss: 1.7960 - val_accuracy: 0.6799\n","Epoch 80/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0150 - accuracy: 0.9986 - val_loss: 1.8412 - val_accuracy: 0.6640\n","Epoch 81/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0204 - accuracy: 0.9969 - val_loss: 1.7934 - val_accuracy: 0.6787\n","Epoch 82/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0267 - accuracy: 0.9949 - val_loss: 1.8018 - val_accuracy: 0.6538\n","Epoch 83/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0903 - accuracy: 0.9709 - val_loss: 1.2408 - val_accuracy: 0.6550\n","Epoch 84/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0787 - accuracy: 0.9771 - val_loss: 1.4025 - val_accuracy: 0.6584\n","Epoch 85/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0479 - accuracy: 0.9875 - val_loss: 1.5342 - val_accuracy: 0.6572\n","Epoch 86/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0341 - accuracy: 0.9924 - val_loss: 1.6340 - val_accuracy: 0.6776\n","Epoch 87/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0620 - accuracy: 0.9810 - val_loss: 1.4967 - val_accuracy: 0.6618\n","Epoch 88/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0505 - accuracy: 0.9864 - val_loss: 1.5484 - val_accuracy: 0.6776\n","Epoch 89/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0268 - accuracy: 0.9946 - val_loss: 1.8302 - val_accuracy: 0.6708\n","Epoch 90/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0263 - accuracy: 0.9946 - val_loss: 1.7620 - val_accuracy: 0.6606\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0222 - accuracy: 0.9975 - val_loss: 1.7899 - val_accuracy: 0.6652\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0278 - accuracy: 0.9946 - val_loss: 1.7180 - val_accuracy: 0.6753\n","Epoch 93/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0433 - accuracy: 0.9887 - val_loss: 1.5782 - val_accuracy: 0.6572\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0266 - accuracy: 0.9946 - val_loss: 1.6012 - val_accuracy: 0.6810\n","Epoch 95/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0211 - accuracy: 0.9980 - val_loss: 1.8110 - val_accuracy: 0.6787\n","Epoch 96/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0303 - accuracy: 0.9926 - val_loss: 1.9223 - val_accuracy: 0.6663\n","Epoch 97/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0560 - accuracy: 0.9847 - val_loss: 1.5364 - val_accuracy: 0.6686\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0654 - accuracy: 0.9822 - val_loss: 1.5291 - val_accuracy: 0.6335\n","Epoch 99/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0467 - accuracy: 0.9859 - val_loss: 1.5386 - val_accuracy: 0.6719\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0263 - accuracy: 0.9943 - val_loss: 1.7319 - val_accuracy: 0.6482\n","{'loss': [0.5992926359176636, 0.5026872158050537, 0.44332456588745117, 0.4049646258354187, 0.3305068016052246, 0.2993859052658081, 0.23242492973804474, 0.22241243720054626, 0.20285259187221527, 0.13677987456321716, 0.12290546298027039, 0.09753550589084625, 0.11824191361665726, 0.13669435679912567, 0.09360605478286743, 0.10346024483442307, 0.07840291410684586, 0.0678989589214325, 0.07006790488958359, 0.09969477355480194, 0.05771399661898613, 0.04422627389431, 0.051152680069208145, 0.05294283106923103, 0.0563771054148674, 0.0584012046456337, 0.07814241200685501, 0.07748568803071976, 0.04818817228078842, 0.03513723611831665, 0.03588606044650078, 0.03289300203323364, 0.031918298453092575, 0.03102658875286579, 0.06042914092540741, 0.04649366810917854, 0.03938885033130646, 0.03067588061094284, 0.030979732051491737, 0.03494836017489433, 0.041291747242212296, 0.03683379665017128, 0.03570101410150528, 0.0377824492752552, 0.03524642810225487, 0.044527068734169006, 0.03000631369650364, 0.030394142493605614, 0.07221025228500366, 0.07802709937095642, 0.07420733571052551, 0.04344336315989494, 0.028186500072479248, 0.025317780673503876, 0.023975644260644913, 0.03700345382094383, 0.039937373250722885, 0.02981683984398842, 0.026125937700271606, 0.029688868671655655, 0.022126752883195877, 0.017612792551517487, 0.017560414969921112, 0.018367381766438484, 0.018561894074082375, 0.01708310842514038, 0.016609791666269302, 0.01856963522732258, 0.016761111095547676, 0.01609497144818306, 0.01697150617837906, 0.015560765750706196, 0.016286233440041542, 0.016645556315779686, 0.015130176208913326, 0.016500722616910934, 0.015338471159338951, 0.014056098647415638, 0.01379304938018322, 0.015036478638648987, 0.02043708972632885, 0.026732327416539192, 0.0902845561504364, 0.07871529459953308, 0.047931112349033356, 0.0341477170586586, 0.06199784576892853, 0.0504847951233387, 0.026794062927365303, 0.02627505175769329, 0.022196397185325623, 0.02783343382179737, 0.04333566501736641, 0.026576917618513107, 0.02105742320418358, 0.03025502897799015, 0.05602715164422989, 0.06539816409349442, 0.046679697930812836, 0.026255246251821518], 'accuracy': [0.7034521698951721, 0.7696660757064819, 0.8200339674949646, 0.8333333134651184, 0.8797396421432495, 0.8896434903144836, 0.9258630275726318, 0.9244481921195984, 0.9346349835395813, 0.9612337350845337, 0.9646292924880981, 0.9790605306625366, 0.9668930172920227, 0.9612337350845337, 0.9750990271568298, 0.9683078527450562, 0.9813242554664612, 0.983305037021637, 0.9830220937728882, 0.9688737988471985, 0.988964319229126, 0.9920769929885864, 0.9883984327316284, 0.990662157535553, 0.9861347079277039, 0.9867005944252014, 0.9770798087120056, 0.9793435335159302, 0.9903791546821594, 0.9946236610412598, 0.9946236610412598, 0.9946236610412598, 0.9949066042900085, 0.9971703290939331, 0.9855687618255615, 0.9900962114334106, 0.9946236610412598, 0.9951896071434021, 0.9951896071434021, 0.9951896071434021, 0.9917939901351929, 0.9934917688369751, 0.9937747716903687, 0.992642879486084, 0.9934917688369751, 0.9903791546821594, 0.9968873858451843, 0.9946236610412598, 0.9787775874137878, 0.9750990271568298, 0.9784946441650391, 0.988964319229126, 0.9954725503921509, 0.9968873858451843, 0.9966044425964355, 0.9909451007843018, 0.9895302653312683, 0.9951896071434021, 0.9957554936408997, 0.9951896071434021, 0.9977362751960754, 0.9991511106491089, 0.9985851645469666, 0.9985851645469666, 0.9985851645469666, 0.9991511106491089, 0.9988681674003601, 0.9985851645469666, 0.9985851645469666, 0.9991511106491089, 0.9991511106491089, 0.9994340538978577, 0.9991511106491089, 0.9991511106491089, 0.9994340538978577, 0.9985851645469666, 0.9988681674003601, 0.9994340538978577, 0.9994340538978577, 0.9985851645469666, 0.9968873858451843, 0.9949066042900085, 0.9708545804023743, 0.9770798087120056, 0.9875495433807373, 0.9923599362373352, 0.9810413122177124, 0.9864176511764526, 0.9946236610412598, 0.9946236610412598, 0.9974533319473267, 0.9946236610412598, 0.9886813759803772, 0.9946236610412598, 0.9980192184448242, 0.992642879486084, 0.9847198724746704, 0.9821732044219971, 0.9858517050743103, 0.994340717792511], 'val_loss': [0.703647792339325, 0.702399492263794, 0.6994171142578125, 0.6980043053627014, 0.6935528516769409, 0.6893184185028076, 0.6866046190261841, 0.6802375316619873, 0.6724573969841003, 0.6689398288726807, 0.6743887662887573, 0.7229298949241638, 0.6832678318023682, 0.7025887966156006, 0.7812803387641907, 0.7444395422935486, 0.8528277277946472, 0.9445647597312927, 1.0733225345611572, 0.9203391075134277, 1.071129322052002, 1.1777595281600952, 1.282859444618225, 1.2750663757324219, 1.3074332475662231, 1.530667781829834, 1.4309052228927612, 1.2726980447769165, 1.3338048458099365, 1.4048694372177124, 1.5835071802139282, 1.5635918378829956, 1.5939630270004272, 1.6412290334701538, 1.4731940031051636, 1.652924656867981, 1.6287370920181274, 1.6795846223831177, 1.7552480697631836, 1.792397379875183, 1.5729236602783203, 1.6027778387069702, 1.728475570678711, 1.7092441320419312, 1.7101857662200928, 1.6632274389266968, 1.714717984199524, 1.821399450302124, 1.7508176565170288, 1.435283899307251, 1.4102416038513184, 1.5355408191680908, 1.6895784139633179, 1.8211243152618408, 1.775407314300537, 1.6450690031051636, 1.6470972299575806, 1.6356689929962158, 1.7549058198928833, 1.6735541820526123, 1.7384908199310303, 1.7872134447097778, 1.7881499528884888, 1.7754802703857422, 1.7269225120544434, 1.720865249633789, 1.7580986022949219, 1.8555247783660889, 1.7595535516738892, 1.8469680547714233, 1.924424171447754, 1.7714636325836182, 1.7439299821853638, 1.7210332155227661, 1.7459492683410645, 1.683386206626892, 1.6817327737808228, 1.7036389112472534, 1.7959918975830078, 1.841190218925476, 1.7934006452560425, 1.8018237352371216, 1.2407609224319458, 1.4025102853775024, 1.5342082977294922, 1.6340302228927612, 1.496681571006775, 1.548351526260376, 1.8302103281021118, 1.7619673013687134, 1.7898788452148438, 1.7179852724075317, 1.5782461166381836, 1.6011866331100464, 1.8110076189041138, 1.9222609996795654, 1.5363547801971436, 1.529072642326355, 1.5386203527450562, 1.731887698173523], 'val_accuracy': [0.5045248866081238, 0.5214931964874268, 0.610859751701355, 0.5972850918769836, 0.6176470518112183, 0.6255655884742737, 0.5927602052688599, 0.6040723919868469, 0.6210407018661499, 0.6097285151481628, 0.6187782883644104, 0.6176470518112183, 0.6040723919868469, 0.6289592981338501, 0.6097285151481628, 0.6289592981338501, 0.6119909286499023, 0.610859751701355, 0.6052036285400391, 0.6346153616905212, 0.6368778347969055, 0.651583731174469, 0.6527149081230164, 0.6606335043907166, 0.6549773812294006, 0.6470588445663452, 0.6459276080131531, 0.6696832776069641, 0.6764705777168274, 0.6809954643249512, 0.6651583909988403, 0.6764705777168274, 0.679864227771759, 0.6617646813392639, 0.6595022678375244, 0.6549773812294006, 0.6719456911087036, 0.6742081642150879, 0.6742081642150879, 0.6481900215148926, 0.6674208045005798, 0.6662895679473877, 0.6696832776069641, 0.6764705777168274, 0.6764705777168274, 0.6595022678375244, 0.6493212580680847, 0.662895917892456, 0.6357465982437134, 0.6708144545555115, 0.6832579374313354, 0.6719456911087036, 0.6595022678375244, 0.6527149081230164, 0.6538461446762085, 0.6832579374313354, 0.6651583909988403, 0.6742081642150879, 0.6696832776069641, 0.6662895679473877, 0.6753393411636353, 0.6776018142700195, 0.6696832776069641, 0.668552041053772, 0.6742081642150879, 0.6764705777168274, 0.6696832776069641, 0.662895917892456, 0.6753393411636353, 0.6742081642150879, 0.6662895679473877, 0.6832579374313354, 0.6753393411636353, 0.6651583909988403, 0.6696832776069641, 0.6719456911087036, 0.6719456911087036, 0.6696832776069641, 0.679864227771759, 0.6640271544456482, 0.6787330508232117, 0.6538461446762085, 0.6549773812294006, 0.6583710312843323, 0.6572397947311401, 0.6776018142700195, 0.6617646813392639, 0.6776018142700195, 0.6708144545555115, 0.6606335043907166, 0.6651583909988403, 0.6753393411636353, 0.6572397947311401, 0.6809954643249512, 0.6787330508232117, 0.6662895679473877, 0.668552041053772, 0.6334841847419739, 0.6719456911087036, 0.6481900215148926]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.6058 - accuracy: 0.7081"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 7s 57ms/step - loss: 0.6058 - accuracy: 0.7085 - val_loss: 0.7037 - val_accuracy: 0.6219\n","Epoch 2/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5324 - accuracy: 0.7486 - val_loss: 0.7022 - val_accuracy: 0.6240\n","Epoch 3/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4618 - accuracy: 0.8026 - val_loss: 0.7011 - val_accuracy: 0.6023\n","Epoch 4/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4007 - accuracy: 0.8372 - val_loss: 0.6982 - val_accuracy: 0.5961\n","Epoch 5/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3711 - accuracy: 0.8473 - val_loss: 0.6965 - val_accuracy: 0.6023\n","Epoch 6/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3324 - accuracy: 0.8726 - val_loss: 0.6942 - val_accuracy: 0.6064\n","Epoch 7/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.2715 - accuracy: 0.8995 - val_loss: 0.6924 - val_accuracy: 0.5723\n","Epoch 8/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2605 - accuracy: 0.9026 - val_loss: 0.6882 - val_accuracy: 0.5764\n","Epoch 9/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2132 - accuracy: 0.9284 - val_loss: 0.6853 - val_accuracy: 0.5785\n","Epoch 10/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1641 - accuracy: 0.9442 - val_loss: 0.6795 - val_accuracy: 0.6012\n","Epoch 11/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1944 - accuracy: 0.9344 - val_loss: 0.6816 - val_accuracy: 0.6043\n","Epoch 12/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1608 - accuracy: 0.9475 - val_loss: 0.6842 - val_accuracy: 0.5950\n","Epoch 13/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1227 - accuracy: 0.9638 - val_loss: 0.7449 - val_accuracy: 0.5837\n","Epoch 14/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1239 - accuracy: 0.9618 - val_loss: 0.7252 - val_accuracy: 0.6219\n","Epoch 15/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1039 - accuracy: 0.9705 - val_loss: 0.9467 - val_accuracy: 0.5548\n","Epoch 16/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1539 - accuracy: 0.9491 - val_loss: 0.9559 - val_accuracy: 0.5455\n","Epoch 17/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1117 - accuracy: 0.9685 - val_loss: 0.8696 - val_accuracy: 0.6240\n","Epoch 18/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0643 - accuracy: 0.9873 - val_loss: 1.1281 - val_accuracy: 0.6033\n","Epoch 19/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0802 - accuracy: 0.9783 - val_loss: 1.0526 - val_accuracy: 0.6343\n","Epoch 20/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0936 - accuracy: 0.9724 - val_loss: 1.4035 - val_accuracy: 0.5754\n","Epoch 21/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1119 - accuracy: 0.9646 - val_loss: 1.1234 - val_accuracy: 0.6240\n","Epoch 22/100\n","31/31 [==============================] - 1s 41ms/step - loss: 0.0560 - accuracy: 0.9899 - val_loss: 1.3347 - val_accuracy: 0.6395\n","Epoch 23/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0560 - accuracy: 0.9871 - val_loss: 1.3584 - val_accuracy: 0.6488\n","Epoch 24/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.0487 - accuracy: 0.9904 - val_loss: 1.5500 - val_accuracy: 0.6591\n","Epoch 25/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0631 - accuracy: 0.9837 - val_loss: 1.5656 - val_accuracy: 0.6333\n","Epoch 26/100\n","31/31 [==============================] - 1s 35ms/step - loss: 0.0711 - accuracy: 0.9817 - val_loss: 1.4382 - val_accuracy: 0.6622\n","Epoch 27/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.1295 - accuracy: 0.9612 - val_loss: 1.2391 - val_accuracy: 0.6467\n","Epoch 28/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0606 - accuracy: 0.9876 - val_loss: 1.5109 - val_accuracy: 0.6519\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0564 - accuracy: 0.9891 - val_loss: 1.5616 - val_accuracy: 0.6488\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0399 - accuracy: 0.9935 - val_loss: 1.6052 - val_accuracy: 0.6477\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0371 - accuracy: 0.9935 - val_loss: 1.9701 - val_accuracy: 0.6219\n","Epoch 32/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0601 - accuracy: 0.9832 - val_loss: 1.6136 - val_accuracy: 0.6529\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0504 - accuracy: 0.9881 - val_loss: 1.6150 - val_accuracy: 0.6519\n","Epoch 34/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0470 - accuracy: 0.9915 - val_loss: 1.7474 - val_accuracy: 0.6581\n","Epoch 35/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0574 - accuracy: 0.9855 - val_loss: 1.6851 - val_accuracy: 0.6446\n","Epoch 36/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0625 - accuracy: 0.9822 - val_loss: 1.5811 - val_accuracy: 0.6570\n","Epoch 37/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0722 - accuracy: 0.9793 - val_loss: 1.7117 - val_accuracy: 0.6353\n","Epoch 38/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0619 - accuracy: 0.9811 - val_loss: 1.7131 - val_accuracy: 0.6405\n","Epoch 39/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0499 - accuracy: 0.9860 - val_loss: 1.8191 - val_accuracy: 0.6178\n","Epoch 40/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0357 - accuracy: 0.9941 - val_loss: 1.7582 - val_accuracy: 0.6415\n","Epoch 41/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0276 - accuracy: 0.9966 - val_loss: 1.7924 - val_accuracy: 0.6519\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0242 - accuracy: 0.9987 - val_loss: 1.9718 - val_accuracy: 0.6395\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0286 - accuracy: 0.9972 - val_loss: 1.9406 - val_accuracy: 0.6426\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0273 - accuracy: 0.9972 - val_loss: 1.9401 - val_accuracy: 0.6539\n","Epoch 45/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0277 - accuracy: 0.9969 - val_loss: 1.8324 - val_accuracy: 0.6529\n","Epoch 46/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0252 - accuracy: 0.9972 - val_loss: 1.8526 - val_accuracy: 0.6457\n","Epoch 47/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0339 - accuracy: 0.9943 - val_loss: 1.8125 - val_accuracy: 0.6467\n","Epoch 48/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0320 - accuracy: 0.9948 - val_loss: 2.0200 - val_accuracy: 0.6219\n","Epoch 49/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0642 - accuracy: 0.9855 - val_loss: 1.7745 - val_accuracy: 0.6488\n","Epoch 50/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0469 - accuracy: 0.9891 - val_loss: 1.7169 - val_accuracy: 0.6322\n","Epoch 51/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0429 - accuracy: 0.9915 - val_loss: 1.7872 - val_accuracy: 0.6488\n","Epoch 52/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0536 - accuracy: 0.9871 - val_loss: 1.8033 - val_accuracy: 0.6457\n","Epoch 53/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1129 - accuracy: 0.9630 - val_loss: 1.3571 - val_accuracy: 0.6591\n","Epoch 54/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0561 - accuracy: 0.9863 - val_loss: 1.6385 - val_accuracy: 0.6457\n","Epoch 55/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0355 - accuracy: 0.9943 - val_loss: 1.6988 - val_accuracy: 0.6508\n","Epoch 56/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0625 - accuracy: 0.9832 - val_loss: 1.6208 - val_accuracy: 0.6436\n","Epoch 57/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0391 - accuracy: 0.9922 - val_loss: 1.7925 - val_accuracy: 0.6250\n","Epoch 58/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0339 - accuracy: 0.9953 - val_loss: 1.7208 - val_accuracy: 0.6436\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0231 - accuracy: 0.9972 - val_loss: 1.8976 - val_accuracy: 0.6302\n","Epoch 60/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0272 - accuracy: 0.9961 - val_loss: 2.0237 - val_accuracy: 0.6405\n","Epoch 61/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0325 - accuracy: 0.9941 - val_loss: 1.8400 - val_accuracy: 0.6426\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0308 - accuracy: 0.9941 - val_loss: 1.9251 - val_accuracy: 0.6219\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0241 - accuracy: 0.9969 - val_loss: 2.0238 - val_accuracy: 0.6436\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0213 - accuracy: 0.9974 - val_loss: 2.0372 - val_accuracy: 0.6498\n","Epoch 65/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0211 - accuracy: 0.9977 - val_loss: 2.0915 - val_accuracy: 0.6395\n","Epoch 66/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0395 - accuracy: 0.9920 - val_loss: 1.8862 - val_accuracy: 0.6384\n","Epoch 67/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0291 - accuracy: 0.9964 - val_loss: 1.9402 - val_accuracy: 0.6405\n","Epoch 68/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0376 - accuracy: 0.9915 - val_loss: 1.7593 - val_accuracy: 0.6581\n","Epoch 69/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0346 - accuracy: 0.9930 - val_loss: 1.7817 - val_accuracy: 0.6467\n","Epoch 70/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0330 - accuracy: 0.9941 - val_loss: 1.9877 - val_accuracy: 0.6477\n","Epoch 71/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0743 - accuracy: 0.9796 - val_loss: 1.4577 - val_accuracy: 0.6529\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0461 - accuracy: 0.9891 - val_loss: 1.7276 - val_accuracy: 0.6467\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0291 - accuracy: 0.9946 - val_loss: 1.7603 - val_accuracy: 0.6508\n","Epoch 74/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0269 - accuracy: 0.9956 - val_loss: 1.9559 - val_accuracy: 0.6364\n","Epoch 75/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0214 - accuracy: 0.9979 - val_loss: 1.8820 - val_accuracy: 0.6519\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0174 - accuracy: 0.9992 - val_loss: 1.9120 - val_accuracy: 0.6591\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0252 - accuracy: 0.9956 - val_loss: 1.9926 - val_accuracy: 0.6353\n","Epoch 78/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0214 - accuracy: 0.9972 - val_loss: 2.0450 - val_accuracy: 0.6384\n","Epoch 79/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0211 - accuracy: 0.9974 - val_loss: 1.9636 - val_accuracy: 0.6519\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0166 - accuracy: 0.9992 - val_loss: 2.0240 - val_accuracy: 0.6519\n","Epoch 81/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0210 - accuracy: 0.9979 - val_loss: 1.9656 - val_accuracy: 0.6591\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0227 - accuracy: 0.9972 - val_loss: 1.9637 - val_accuracy: 0.6508\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0199 - accuracy: 0.9982 - val_loss: 1.8904 - val_accuracy: 0.6374\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0198 - accuracy: 0.9977 - val_loss: 2.0781 - val_accuracy: 0.6374\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0313 - accuracy: 0.9935 - val_loss: 2.0421 - val_accuracy: 0.6322\n","Epoch 86/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0744 - accuracy: 0.9783 - val_loss: 1.4074 - val_accuracy: 0.6612\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0673 - accuracy: 0.9780 - val_loss: 1.6177 - val_accuracy: 0.6477\n","Epoch 88/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0296 - accuracy: 0.9938 - val_loss: 1.9905 - val_accuracy: 0.6250\n","Epoch 89/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0267 - accuracy: 0.9953 - val_loss: 1.9406 - val_accuracy: 0.6302\n","Epoch 90/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0290 - accuracy: 0.9946 - val_loss: 2.0092 - val_accuracy: 0.6364\n","Epoch 91/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0268 - accuracy: 0.9959 - val_loss: 1.8854 - val_accuracy: 0.6405\n","Epoch 92/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0277 - accuracy: 0.9951 - val_loss: 2.0661 - val_accuracy: 0.6405\n","Epoch 93/100\n","31/31 [==============================] - 2s 57ms/step - loss: 0.0250 - accuracy: 0.9948 - val_loss: 1.8290 - val_accuracy: 0.6694\n","Epoch 94/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0309 - accuracy: 0.9941 - val_loss: 1.9270 - val_accuracy: 0.6291\n","Epoch 95/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0486 - accuracy: 0.9855 - val_loss: 1.6315 - val_accuracy: 0.6384\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0425 - accuracy: 0.9876 - val_loss: 1.8310 - val_accuracy: 0.6250\n","Epoch 97/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0370 - accuracy: 0.9910 - val_loss: 1.7516 - val_accuracy: 0.6591\n","Epoch 98/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1474 - accuracy: 0.9535 - val_loss: 1.2317 - val_accuracy: 0.6457\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0432 - accuracy: 0.9891 - val_loss: 1.8119 - val_accuracy: 0.6488\n","Epoch 100/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0291 - accuracy: 0.9946 - val_loss: 1.9210 - val_accuracy: 0.6384\n","{'loss': [0.6057843565940857, 0.5324257016181946, 0.46178168058395386, 0.40068474411964417, 0.37114813923835754, 0.3324472904205322, 0.2715478837490082, 0.2604900896549225, 0.2132379114627838, 0.16406671702861786, 0.19439801573753357, 0.16083648800849915, 0.1226503998041153, 0.12389303743839264, 0.10391691327095032, 0.15386871993541718, 0.1117405891418457, 0.06428754329681396, 0.08020852506160736, 0.0935763344168663, 0.11190981417894363, 0.05599088966846466, 0.05601055920124054, 0.04867365583777428, 0.06311707198619843, 0.07111106067895889, 0.1295020431280136, 0.060595933347940445, 0.05642395094037056, 0.03985576704144478, 0.03713574260473251, 0.0601496621966362, 0.05035007745027542, 0.04704399034380913, 0.05736326426267624, 0.062487151473760605, 0.07223578542470932, 0.0619482658803463, 0.049886662513017654, 0.03572002798318863, 0.027572397142648697, 0.024236608296632767, 0.028621800243854523, 0.027347251772880554, 0.027695249766111374, 0.025208352133631706, 0.03386847674846649, 0.03203235939145088, 0.06424469500780106, 0.04685244709253311, 0.042853545397520065, 0.05355817452073097, 0.11286704242229462, 0.05609601363539696, 0.03551128879189491, 0.06246774643659592, 0.03913576528429985, 0.03393353894352913, 0.023129941895604134, 0.027161376550793648, 0.03251495212316513, 0.030791178345680237, 0.024056613445281982, 0.021339507773518562, 0.021119849756360054, 0.03945104777812958, 0.029121756553649902, 0.037625838071107864, 0.03457006812095642, 0.0330125167965889, 0.0742933452129364, 0.04614486172795296, 0.02908359467983246, 0.026858946308493614, 0.021404825150966644, 0.017378518357872963, 0.025237472727894783, 0.02140815183520317, 0.02107890136539936, 0.01655014045536518, 0.02101941406726837, 0.022663500159978867, 0.01993749290704727, 0.019764157012104988, 0.031280308961868286, 0.07443419098854065, 0.06727071851491928, 0.029582176357507706, 0.026652848348021507, 0.029004108160734177, 0.02677052840590477, 0.027715709060430527, 0.025012444704771042, 0.03085608407855034, 0.048591408878564835, 0.04252312332391739, 0.037003424018621445, 0.14741909503936768, 0.04315771907567978, 0.0290741715580225], 'accuracy': [0.708527147769928, 0.7485787868499756, 0.8025839924812317, 0.8372092843055725, 0.8472868204116821, 0.8726097941398621, 0.8994832038879395, 0.9025839567184448, 0.9284237623214722, 0.9441860318183899, 0.9343669414520264, 0.9475452303886414, 0.9638242721557617, 0.9617571234703064, 0.9705426096916199, 0.949095606803894, 0.9684754610061646, 0.9873384833335876, 0.9782945513725281, 0.9723514318466187, 0.9645994901657104, 0.9899224638938904, 0.9870800971984863, 0.9904392957687378, 0.9837209582328796, 0.9816537499427795, 0.961240291595459, 0.987596869468689, 0.9891473054885864, 0.9935400485992432, 0.9935400485992432, 0.9832041263580322, 0.9881137013435364, 0.9914728403091431, 0.9855297207832336, 0.9821705222129822, 0.9793281555175781, 0.9811369776725769, 0.9860464930534363, 0.9940568208694458, 0.9966408014297485, 0.9987080097198486, 0.997157633304596, 0.997157633304596, 0.9968992471694946, 0.997157633304596, 0.9943152666091919, 0.9948320388793945, 0.9855297207832336, 0.9891473054885864, 0.9914728403091431, 0.9870800971984863, 0.9630491137504578, 0.9863049387931824, 0.9943152666091919, 0.9832041263580322, 0.9922480583190918, 0.9953488111495972, 0.997157633304596, 0.9961240291595459, 0.9940568208694458, 0.9940568208694458, 0.9968992471694946, 0.9974160194396973, 0.9976744055747986, 0.9919896721839905, 0.9963824152946472, 0.9914728403091431, 0.9930232763290405, 0.9940568208694458, 0.9795865416526794, 0.9891473054885864, 0.9945736527442932, 0.9956072568893433, 0.9979327917098999, 0.9992247819900513, 0.9956072568893433, 0.997157633304596, 0.9974160194396973, 0.9992247819900513, 0.9979327917098999, 0.997157633304596, 0.998191237449646, 0.9976744055747986, 0.9935400485992432, 0.9782945513725281, 0.9780361652374268, 0.9937984347343445, 0.9953488111495972, 0.9945736527442932, 0.9958656430244446, 0.9950904250144958, 0.9948320388793945, 0.9940568208694458, 0.9855297207832336, 0.987596869468689, 0.9909560680389404, 0.9534883499145508, 0.9891473054885864, 0.9945736527442932], 'val_loss': [0.703718364238739, 0.7021961808204651, 0.7011207342147827, 0.6981603503227234, 0.6965161561965942, 0.6941574215888977, 0.6924028396606445, 0.6882452964782715, 0.6852527260780334, 0.6794850826263428, 0.6815922856330872, 0.6842000484466553, 0.7448573708534241, 0.725153923034668, 0.946714460849762, 0.9558727145195007, 0.8696331977844238, 1.12812340259552, 1.0526272058486938, 1.4034898281097412, 1.123445987701416, 1.3346552848815918, 1.3583788871765137, 1.549981951713562, 1.5656394958496094, 1.4381632804870605, 1.2391287088394165, 1.5108907222747803, 1.5616497993469238, 1.605200171470642, 1.9701017141342163, 1.6135759353637695, 1.6149691343307495, 1.747380256652832, 1.685095191001892, 1.5811259746551514, 1.7117174863815308, 1.7130635976791382, 1.8190529346466064, 1.7582182884216309, 1.7924474477767944, 1.9718419313430786, 1.9405786991119385, 1.9401288032531738, 1.832407832145691, 1.8526238203048706, 1.812504768371582, 2.0199761390686035, 1.7744786739349365, 1.716909408569336, 1.7872200012207031, 1.8032550811767578, 1.357072353363037, 1.6385090351104736, 1.6987890005111694, 1.6208367347717285, 1.792543649673462, 1.720786690711975, 1.8976194858551025, 2.0236549377441406, 1.839962363243103, 1.9251375198364258, 2.0238049030303955, 2.0372326374053955, 2.0914766788482666, 1.8861660957336426, 1.9401521682739258, 1.7592644691467285, 1.7817169427871704, 1.9877077341079712, 1.457706093788147, 1.7276198863983154, 1.7603113651275635, 1.9558546543121338, 1.8820154666900635, 1.9120230674743652, 1.9925827980041504, 2.045032024383545, 1.963588833808899, 2.024012565612793, 1.9656001329421997, 1.9637006521224976, 1.890432357788086, 2.078054904937744, 2.0421483516693115, 1.4074156284332275, 1.6176670789718628, 1.9905099868774414, 1.9406237602233887, 2.00919771194458, 1.8853955268859863, 2.0660672187805176, 1.8289787769317627, 1.9270261526107788, 1.6315462589263916, 1.8309783935546875, 1.751569390296936, 1.2317365407943726, 1.8118643760681152, 1.9210114479064941], 'val_accuracy': [0.6219007968902588, 0.6239669322967529, 0.6022727489471436, 0.5960744023323059, 0.6022727489471436, 0.6064049601554871, 0.5723140239715576, 0.5764462947845459, 0.5785123705863953, 0.6012396812438965, 0.6043388247489929, 0.5950413346290588, 0.5836777091026306, 0.6219007968902588, 0.5547520518302917, 0.5454545617103577, 0.6239669322967529, 0.6033057570457458, 0.6342975497245789, 0.5754132270812988, 0.6239669322967529, 0.6394628286361694, 0.6487603187561035, 0.6590909361839294, 0.6332644820213318, 0.6621900796890259, 0.6466942429542542, 0.6518595218658447, 0.6487603187561035, 0.6477272510528564, 0.6219007968902588, 0.6528925895690918, 0.6518595218658447, 0.6580578684806824, 0.64462810754776, 0.6570248007774353, 0.6353305578231812, 0.6404958963394165, 0.6177685856819153, 0.6415289044380188, 0.6518595218658447, 0.6394628286361694, 0.6425619721412659, 0.6539255976676941, 0.6528925895690918, 0.6456611752510071, 0.6466942429542542, 0.6219007968902588, 0.6487603187561035, 0.6322314143180847, 0.6487603187561035, 0.6456611752510071, 0.6590909361839294, 0.6456611752510071, 0.6508264541625977, 0.6435950398445129, 0.625, 0.6435950398445129, 0.6301652789115906, 0.6404958963394165, 0.6425619721412659, 0.6219007968902588, 0.6435950398445129, 0.6497933864593506, 0.6394628286361694, 0.6384297609329224, 0.6404958963394165, 0.6580578684806824, 0.6466942429542542, 0.6477272510528564, 0.6528925895690918, 0.6466942429542542, 0.6508264541625977, 0.6363636255264282, 0.6518595218658447, 0.6590909361839294, 0.6353305578231812, 0.6384297609329224, 0.6518595218658447, 0.6518595218658447, 0.6590909361839294, 0.6508264541625977, 0.6373966932296753, 0.6373966932296753, 0.6322314143180847, 0.6611570119857788, 0.6477272510528564, 0.625, 0.6301652789115906, 0.6363636255264282, 0.6404958963394165, 0.6404958963394165, 0.6694214940071106, 0.6291322112083435, 0.6384297609329224, 0.625, 0.6590909361839294, 0.6456611752510071, 0.6487603187561035, 0.6384297609329224]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.1586 - accuracy: 0.9506"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 8s 59ms/step - loss: 0.1579 - accuracy: 0.9510 - val_loss: 0.6880 - val_accuracy: 0.6024\n","Epoch 2/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0717 - accuracy: 0.9803 - val_loss: 0.6802 - val_accuracy: 0.6390\n","Epoch 3/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0515 - accuracy: 0.9871 - val_loss: 0.6723 - val_accuracy: 0.6185\n","Epoch 4/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0353 - accuracy: 0.9919 - val_loss: 0.6629 - val_accuracy: 0.6369\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0505 - accuracy: 0.9863 - val_loss: 0.6602 - val_accuracy: 0.6142\n","Epoch 6/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0714 - accuracy: 0.9766 - val_loss: 0.6532 - val_accuracy: 0.6487\n","Epoch 7/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0382 - accuracy: 0.9914 - val_loss: 0.6494 - val_accuracy: 0.6304\n","Epoch 8/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0378 - accuracy: 0.9908 - val_loss: 0.6424 - val_accuracy: 0.6358\n","Epoch 9/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0356 - accuracy: 0.9930 - val_loss: 0.6410 - val_accuracy: 0.6272\n","Epoch 10/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0291 - accuracy: 0.9935 - val_loss: 0.6537 - val_accuracy: 0.6347\n","Epoch 11/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0227 - accuracy: 0.9968 - val_loss: 0.6914 - val_accuracy: 0.6250\n","Epoch 12/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0296 - accuracy: 0.9943 - val_loss: 0.6587 - val_accuracy: 0.6606\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0232 - accuracy: 0.9960 - val_loss: 0.7525 - val_accuracy: 0.6412\n","Epoch 14/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0430 - accuracy: 0.9900 - val_loss: 0.7894 - val_accuracy: 0.6379\n","Epoch 15/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0469 - accuracy: 0.9881 - val_loss: 1.0056 - val_accuracy: 0.5905\n","Epoch 16/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0445 - accuracy: 0.9868 - val_loss: 1.1035 - val_accuracy: 0.5905\n","Epoch 17/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0393 - accuracy: 0.9898 - val_loss: 1.1128 - val_accuracy: 0.6131\n","Epoch 18/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.0543 - accuracy: 0.9828 - val_loss: 0.8669 - val_accuracy: 0.6649\n","Epoch 19/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0285 - accuracy: 0.9935 - val_loss: 0.9648 - val_accuracy: 0.6897\n","Epoch 20/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0219 - accuracy: 0.9962 - val_loss: 1.0334 - val_accuracy: 0.7037\n","Epoch 21/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0232 - accuracy: 0.9957 - val_loss: 1.0015 - val_accuracy: 0.7263\n","Epoch 22/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0341 - accuracy: 0.9900 - val_loss: 1.0966 - val_accuracy: 0.7015\n","Epoch 23/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0622 - accuracy: 0.9817 - val_loss: 0.7985 - val_accuracy: 0.7575\n","Epoch 24/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0770 - accuracy: 0.9723 - val_loss: 0.6233 - val_accuracy: 0.7759\n","Epoch 25/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0269 - accuracy: 0.9943 - val_loss: 0.9871 - val_accuracy: 0.7629\n","Epoch 26/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0192 - accuracy: 0.9970 - val_loss: 0.9047 - val_accuracy: 0.7802\n","Epoch 27/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0188 - accuracy: 0.9976 - val_loss: 0.9493 - val_accuracy: 0.7683\n","Epoch 28/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0179 - accuracy: 0.9970 - val_loss: 1.0323 - val_accuracy: 0.7726\n","Epoch 29/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0350 - accuracy: 0.9914 - val_loss: 0.9868 - val_accuracy: 0.7769\n","Epoch 30/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0241 - accuracy: 0.9952 - val_loss: 1.0204 - val_accuracy: 0.7802\n","Epoch 31/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0210 - accuracy: 0.9965 - val_loss: 1.1419 - val_accuracy: 0.7791\n","Epoch 32/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0166 - accuracy: 0.9981 - val_loss: 1.1485 - val_accuracy: 0.7748\n","Epoch 33/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0161 - accuracy: 0.9978 - val_loss: 1.1923 - val_accuracy: 0.7694\n","Epoch 34/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0196 - accuracy: 0.9960 - val_loss: 1.1466 - val_accuracy: 0.7672\n","Epoch 35/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0250 - accuracy: 0.9949 - val_loss: 1.4316 - val_accuracy: 0.7392\n","Epoch 36/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0615 - accuracy: 0.9828 - val_loss: 1.1188 - val_accuracy: 0.7188\n","Epoch 37/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0500 - accuracy: 0.9833 - val_loss: 1.0162 - val_accuracy: 0.7716\n","Epoch 38/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0316 - accuracy: 0.9933 - val_loss: 1.0055 - val_accuracy: 0.7683\n","Epoch 39/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.0275 - accuracy: 0.9935 - val_loss: 0.9847 - val_accuracy: 0.7834\n","Epoch 40/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0233 - accuracy: 0.9957 - val_loss: 1.1713 - val_accuracy: 0.7629\n","Epoch 41/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0318 - accuracy: 0.9911 - val_loss: 1.2132 - val_accuracy: 0.7619\n","Epoch 42/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0462 - accuracy: 0.9865 - val_loss: 0.9350 - val_accuracy: 0.7888\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0540 - accuracy: 0.9822 - val_loss: 0.8630 - val_accuracy: 0.7651\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0196 - accuracy: 0.9981 - val_loss: 1.0351 - val_accuracy: 0.7769\n","Epoch 45/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0176 - accuracy: 0.9976 - val_loss: 1.1198 - val_accuracy: 0.7780\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0180 - accuracy: 0.9965 - val_loss: 1.0453 - val_accuracy: 0.7802\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0166 - accuracy: 0.9981 - val_loss: 1.1784 - val_accuracy: 0.7748\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0223 - accuracy: 0.9954 - val_loss: 1.1667 - val_accuracy: 0.7489\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0241 - accuracy: 0.9949 - val_loss: 1.1416 - val_accuracy: 0.7672\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0267 - accuracy: 0.9925 - val_loss: 1.1262 - val_accuracy: 0.7597\n","Epoch 51/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0257 - accuracy: 0.9935 - val_loss: 1.0876 - val_accuracy: 0.7812\n","Epoch 52/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0305 - accuracy: 0.9916 - val_loss: 1.0160 - val_accuracy: 0.7694\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0216 - accuracy: 0.9962 - val_loss: 1.1249 - val_accuracy: 0.7683\n","Epoch 54/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0140 - accuracy: 0.9989 - val_loss: 1.2320 - val_accuracy: 0.7575\n","Epoch 55/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0129 - accuracy: 0.9992 - val_loss: 1.3335 - val_accuracy: 0.7586\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0147 - accuracy: 0.9973 - val_loss: 1.2519 - val_accuracy: 0.7737\n","Epoch 57/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0138 - accuracy: 0.9989 - val_loss: 1.2279 - val_accuracy: 0.7748\n","Epoch 58/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0131 - accuracy: 0.9992 - val_loss: 1.2448 - val_accuracy: 0.7812\n","Epoch 59/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0172 - accuracy: 0.9976 - val_loss: 1.3072 - val_accuracy: 0.7597\n","Epoch 60/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0222 - accuracy: 0.9952 - val_loss: 1.2070 - val_accuracy: 0.7769\n","Epoch 61/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0538 - accuracy: 0.9844 - val_loss: 1.1180 - val_accuracy: 0.7144\n","Epoch 62/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0305 - accuracy: 0.9927 - val_loss: 1.2139 - val_accuracy: 0.7575\n","Epoch 63/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0257 - accuracy: 0.9943 - val_loss: 1.2973 - val_accuracy: 0.7522\n","Epoch 64/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0328 - accuracy: 0.9903 - val_loss: 0.9932 - val_accuracy: 0.7737\n","Epoch 65/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0321 - accuracy: 0.9914 - val_loss: 1.1889 - val_accuracy: 0.7586\n","Epoch 66/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0356 - accuracy: 0.9898 - val_loss: 1.1982 - val_accuracy: 0.7392\n","Epoch 67/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0308 - accuracy: 0.9906 - val_loss: 1.1296 - val_accuracy: 0.7522\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0218 - accuracy: 0.9954 - val_loss: 1.4263 - val_accuracy: 0.7220\n","Epoch 69/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0309 - accuracy: 0.9930 - val_loss: 1.1734 - val_accuracy: 0.7468\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0179 - accuracy: 0.9960 - val_loss: 1.1951 - val_accuracy: 0.7511\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0165 - accuracy: 0.9981 - val_loss: 1.2354 - val_accuracy: 0.7575\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0252 - accuracy: 0.9935 - val_loss: 1.2607 - val_accuracy: 0.7575\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0396 - accuracy: 0.9884 - val_loss: 1.0289 - val_accuracy: 0.7662\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0507 - accuracy: 0.9836 - val_loss: 0.9910 - val_accuracy: 0.7468\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0455 - accuracy: 0.9855 - val_loss: 1.1272 - val_accuracy: 0.7403\n","Epoch 76/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0247 - accuracy: 0.9949 - val_loss: 1.2726 - val_accuracy: 0.7403\n","Epoch 77/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0230 - accuracy: 0.9954 - val_loss: 1.2032 - val_accuracy: 0.7554\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0188 - accuracy: 0.9962 - val_loss: 1.2215 - val_accuracy: 0.7435\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0158 - accuracy: 0.9978 - val_loss: 1.4603 - val_accuracy: 0.7101\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0347 - accuracy: 0.9916 - val_loss: 1.2061 - val_accuracy: 0.7511\n","Epoch 81/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0287 - accuracy: 0.9925 - val_loss: 1.2474 - val_accuracy: 0.7392\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0178 - accuracy: 0.9957 - val_loss: 1.3819 - val_accuracy: 0.7231\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0198 - accuracy: 0.9960 - val_loss: 1.2488 - val_accuracy: 0.7381\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0184 - accuracy: 0.9965 - val_loss: 1.2231 - val_accuracy: 0.7317\n","Epoch 85/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0167 - accuracy: 0.9970 - val_loss: 1.2759 - val_accuracy: 0.7349\n","Epoch 86/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0149 - accuracy: 0.9987 - val_loss: 1.2131 - val_accuracy: 0.7532\n","Epoch 87/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0119 - accuracy: 0.9989 - val_loss: 1.2989 - val_accuracy: 0.7435\n","Epoch 88/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0101 - accuracy: 0.9995 - val_loss: 1.2702 - val_accuracy: 0.7500\n","Epoch 89/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0106 - accuracy: 0.9992 - val_loss: 1.4050 - val_accuracy: 0.7381\n","Epoch 90/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0096 - accuracy: 0.9997 - val_loss: 1.2839 - val_accuracy: 0.7543\n","Epoch 91/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0103 - accuracy: 0.9995 - val_loss: 1.2770 - val_accuracy: 0.7554\n","Epoch 92/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0106 - accuracy: 0.9989 - val_loss: 1.2714 - val_accuracy: 0.7511\n","Epoch 93/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0101 - accuracy: 0.9995 - val_loss: 1.2380 - val_accuracy: 0.7565\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0095 - accuracy: 0.9995 - val_loss: 1.3040 - val_accuracy: 0.7425\n","Epoch 95/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0100 - accuracy: 0.9995 - val_loss: 1.2761 - val_accuracy: 0.7511\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0095 - accuracy: 0.9995 - val_loss: 1.2551 - val_accuracy: 0.7586\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0095 - accuracy: 0.9992 - val_loss: 1.2278 - val_accuracy: 0.7565\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0095 - accuracy: 0.9995 - val_loss: 1.2613 - val_accuracy: 0.7478\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0103 - accuracy: 0.9992 - val_loss: 1.2135 - val_accuracy: 0.7575\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0095 - accuracy: 0.9995 - val_loss: 1.2150 - val_accuracy: 0.7575\n","{'loss': [0.15790526568889618, 0.0716591328382492, 0.05153471976518631, 0.03530793637037277, 0.05054169148206711, 0.0714157298207283, 0.03816180303692818, 0.03781858831644058, 0.035609230399131775, 0.029078958556056023, 0.022746726870536804, 0.029559293761849403, 0.023228855803608894, 0.043027907609939575, 0.04690880700945854, 0.04445376619696617, 0.039262425154447556, 0.05427611619234085, 0.02847607247531414, 0.02192365750670433, 0.02323685772716999, 0.0340711809694767, 0.062216076999902725, 0.07700730115175247, 0.026875006034970284, 0.019214602187275887, 0.01883874647319317, 0.017885928973555565, 0.03503195196390152, 0.02411196008324623, 0.02103322744369507, 0.01657230779528618, 0.01605082117021084, 0.01962575875222683, 0.024964867159724236, 0.06148969382047653, 0.049955595284700394, 0.031569257378578186, 0.02750549092888832, 0.0232543982565403, 0.03177296742796898, 0.04619934782385826, 0.054045047610998154, 0.01955626718699932, 0.017627403140068054, 0.018038198351860046, 0.016567600890994072, 0.022289013490080833, 0.024055181071162224, 0.026732271537184715, 0.02567567676305771, 0.030528051778674126, 0.02155647799372673, 0.013996856287121773, 0.012906924821436405, 0.014682026579976082, 0.013786314986646175, 0.01313030906021595, 0.017173580825328827, 0.02215939201414585, 0.05376904457807541, 0.0304950550198555, 0.025723770260810852, 0.032831307500600815, 0.03210435062646866, 0.03561942279338837, 0.030834879726171494, 0.0217625442892313, 0.03085986152291298, 0.01789649948477745, 0.016455166041851044, 0.025220012292265892, 0.039613496512174606, 0.05065879970788956, 0.04554472118616104, 0.02469785325229168, 0.023028966039419174, 0.01882687583565712, 0.01582939736545086, 0.03467132896184921, 0.028737615793943405, 0.017803624272346497, 0.019787359982728958, 0.018433479592204094, 0.016666065901517868, 0.014890912920236588, 0.011859876103699207, 0.010136984288692474, 0.01055213063955307, 0.009569856338202953, 0.010308059863746166, 0.010587882250547409, 0.010141690261662006, 0.00949262548238039, 0.010028598830103874, 0.009536881931126118, 0.009549061767756939, 0.00954383797943592, 0.01031207013875246, 0.009514079429209232], 'accuracy': [0.9509698152542114, 0.9803340435028076, 0.9870689511299133, 0.9919180870056152, 0.9862607717514038, 0.9765625, 0.9913793206214905, 0.990840494632721, 0.9929956793785095, 0.993534505367279, 0.9967672228813171, 0.9943426847457886, 0.9959590435028076, 0.9900323152542114, 0.9881465435028076, 0.9867995977401733, 0.9897629022598267, 0.982758641242981, 0.993534505367279, 0.9962284564971924, 0.9956896305084229, 0.9900323152542114, 0.9816810488700867, 0.9722521305084229, 0.9943426847457886, 0.9970366358757019, 0.9975754022598267, 0.9970366358757019, 0.9913793206214905, 0.9951508641242981, 0.9964978694915771, 0.9981142282485962, 0.9978448152542114, 0.9959590435028076, 0.9948814511299133, 0.982758641242981, 0.9832974076271057, 0.9932650923728943, 0.993534505367279, 0.9956896305084229, 0.9911099076271057, 0.9865301847457886, 0.9822198152542114, 0.9981142282485962, 0.9975754022598267, 0.9964978694915771, 0.9981142282485962, 0.9954202771186829, 0.9948814511299133, 0.9924569129943848, 0.993534505367279, 0.9916487336158752, 0.9962284564971924, 0.9989224076271057, 0.9991918206214905, 0.9973060488700867, 0.9989224076271057, 0.9991918206214905, 0.9975754022598267, 0.9951508641242981, 0.984375, 0.9927262663841248, 0.9943426847457886, 0.9903017282485962, 0.9913793206214905, 0.9897629022598267, 0.990571141242981, 0.9954202771186829, 0.9929956793785095, 0.9959590435028076, 0.9981142282485962, 0.993534505367279, 0.9884159564971924, 0.9835668206214905, 0.9854525923728943, 0.9948814511299133, 0.9954202771186829, 0.9962284564971924, 0.9978448152542114, 0.9916487336158752, 0.9924569129943848, 0.9956896305084229, 0.9959590435028076, 0.9964978694915771, 0.9970366358757019, 0.998652994632721, 0.9989224076271057, 0.9994612336158752, 0.9991918206214905, 0.9997305870056152, 0.9994612336158752, 0.9989224076271057, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9991918206214905, 0.9994612336158752, 0.9991918206214905, 0.9994612336158752], 'val_loss': [0.6879743337631226, 0.6801961660385132, 0.6723213195800781, 0.6629005670547485, 0.6602020263671875, 0.6531520485877991, 0.6494274735450745, 0.6424399614334106, 0.6410340070724487, 0.6536669135093689, 0.691412091255188, 0.6587442755699158, 0.7524500489234924, 0.7894320487976074, 1.0055971145629883, 1.1034815311431885, 1.11275053024292, 0.8668814897537231, 0.9647942781448364, 1.0333975553512573, 1.0014897584915161, 1.0965919494628906, 0.7985000014305115, 0.6233103275299072, 0.9871281385421753, 0.9046523571014404, 0.9492796659469604, 1.0323363542556763, 0.9868276715278625, 1.0204261541366577, 1.1419161558151245, 1.1485068798065186, 1.1923353672027588, 1.146581768989563, 1.4316363334655762, 1.1187925338745117, 1.0162057876586914, 1.0055265426635742, 0.9846755862236023, 1.1712511777877808, 1.213181972503662, 0.9350293874740601, 0.8629809617996216, 1.0351024866104126, 1.1198421716690063, 1.0453335046768188, 1.1784040927886963, 1.1667430400848389, 1.14164137840271, 1.1262112855911255, 1.087607502937317, 1.0159698724746704, 1.124874472618103, 1.2319843769073486, 1.333469271659851, 1.2518819570541382, 1.2279385328292847, 1.2448071241378784, 1.3071730136871338, 1.207007884979248, 1.1179708242416382, 1.213851809501648, 1.297254204750061, 0.9932249188423157, 1.1889283657073975, 1.1981613636016846, 1.1296433210372925, 1.4262629747390747, 1.1733746528625488, 1.1951264142990112, 1.2353966236114502, 1.2606732845306396, 1.0289310216903687, 0.9909700751304626, 1.1271629333496094, 1.272645115852356, 1.203168272972107, 1.2215254306793213, 1.4603149890899658, 1.2060720920562744, 1.247357964515686, 1.3819234371185303, 1.2487983703613281, 1.2230806350708008, 1.2758723497390747, 1.213072657585144, 1.298852562904358, 1.2702491283416748, 1.4050010442733765, 1.2838938236236572, 1.2769877910614014, 1.2714287042617798, 1.238043189048767, 1.303981065750122, 1.276123285293579, 1.255113124847412, 1.2278162240982056, 1.2613197565078735, 1.2134523391723633, 1.2150434255599976], 'val_accuracy': [0.6023706793785095, 0.639008641242981, 0.618534505367279, 0.6368534564971924, 0.6142241358757019, 0.6487069129943848, 0.6303879022598267, 0.6357758641242981, 0.6271551847457886, 0.6346982717514038, 0.625, 0.6605603694915771, 0.6411637663841248, 0.6379310488700867, 0.5905172228813171, 0.5905172228813171, 0.6131465435028076, 0.6648706793785095, 0.6896551847457886, 0.7036637663841248, 0.7262930870056152, 0.701508641242981, 0.7575430870056152, 0.7758620977401733, 0.7629310488700867, 0.7801724076271057, 0.7683189511299133, 0.7726293206214905, 0.7769396305084229, 0.7801724076271057, 0.7790948152542114, 0.774784505367279, 0.7693965435028076, 0.767241358757019, 0.7392241358757019, 0.71875, 0.7715517282485962, 0.7683189511299133, 0.7834051847457886, 0.7629310488700867, 0.7618534564971924, 0.7887930870056152, 0.7650862336158752, 0.7769396305084229, 0.7780172228813171, 0.7801724076271057, 0.774784505367279, 0.7489224076271057, 0.767241358757019, 0.7596982717514038, 0.78125, 0.7693965435028076, 0.7683189511299133, 0.7575430870056152, 0.7586206793785095, 0.7737069129943848, 0.774784505367279, 0.78125, 0.7596982717514038, 0.7769396305084229, 0.7144396305084229, 0.7575430870056152, 0.7521551847457886, 0.7737069129943848, 0.7586206793785095, 0.7392241358757019, 0.7521551847457886, 0.7219827771186829, 0.7467672228813171, 0.7510775923728943, 0.7575430870056152, 0.7575430870056152, 0.7661637663841248, 0.7467672228813171, 0.7403017282485962, 0.7403017282485962, 0.7553879022598267, 0.743534505367279, 0.7101293206214905, 0.7510775923728943, 0.7392241358757019, 0.7230603694915771, 0.7381465435028076, 0.7316810488700867, 0.7349137663841248, 0.7532327771186829, 0.743534505367279, 0.75, 0.7381465435028076, 0.7543103694915771, 0.7553879022598267, 0.7510775923728943, 0.756465494632721, 0.7424569129943848, 0.7510775923728943, 0.7586206793785095, 0.756465494632721, 0.7478448152542114, 0.7575430870056152, 0.7575430870056152]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.1447 - accuracy: 0.9543"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 67ms/step - loss: 0.1453 - accuracy: 0.9542 - val_loss: 0.6914 - val_accuracy: 0.5600\n","Epoch 2/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0676 - accuracy: 0.9830 - val_loss: 0.6888 - val_accuracy: 0.5520\n","Epoch 3/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0466 - accuracy: 0.9878 - val_loss: 0.6964 - val_accuracy: 0.5373\n","Epoch 4/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0403 - accuracy: 0.9892 - val_loss: 0.6718 - val_accuracy: 0.5894\n","Epoch 5/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0532 - accuracy: 0.9853 - val_loss: 0.6508 - val_accuracy: 0.6516\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0848 - accuracy: 0.9737 - val_loss: 0.6613 - val_accuracy: 0.6244\n","Epoch 7/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0433 - accuracy: 0.9887 - val_loss: 0.6579 - val_accuracy: 0.6199\n","Epoch 8/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0302 - accuracy: 0.9935 - val_loss: 0.6471 - val_accuracy: 0.6346\n","Epoch 9/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0295 - accuracy: 0.9938 - val_loss: 0.6566 - val_accuracy: 0.6414\n","Epoch 10/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0494 - accuracy: 0.9870 - val_loss: 0.6411 - val_accuracy: 0.6550\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0375 - accuracy: 0.9892 - val_loss: 0.7856 - val_accuracy: 0.6222\n","Epoch 12/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0456 - accuracy: 0.9853 - val_loss: 0.6806 - val_accuracy: 0.6516\n","Epoch 13/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0544 - accuracy: 0.9850 - val_loss: 0.6409 - val_accuracy: 0.6606\n","Epoch 14/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0383 - accuracy: 0.9907 - val_loss: 0.7690 - val_accuracy: 0.6301\n","Epoch 15/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0468 - accuracy: 0.9864 - val_loss: 0.6836 - val_accuracy: 0.6731\n","Epoch 16/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.0301 - accuracy: 0.9926 - val_loss: 0.7208 - val_accuracy: 0.6957\n","Epoch 17/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.0276 - accuracy: 0.9946 - val_loss: 0.7573 - val_accuracy: 0.7025\n","Epoch 18/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0297 - accuracy: 0.9921 - val_loss: 0.8646 - val_accuracy: 0.6968\n","Epoch 19/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.0190 - accuracy: 0.9975 - val_loss: 0.9488 - val_accuracy: 0.7081\n","Epoch 20/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0233 - accuracy: 0.9955 - val_loss: 0.8832 - val_accuracy: 0.7421\n","Epoch 21/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0508 - accuracy: 0.9867 - val_loss: 0.7687 - val_accuracy: 0.7421\n","Epoch 22/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0352 - accuracy: 0.9918 - val_loss: 0.8311 - val_accuracy: 0.7511\n","Epoch 23/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0192 - accuracy: 0.9966 - val_loss: 0.9546 - val_accuracy: 0.7579\n","Epoch 24/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0469 - accuracy: 0.9873 - val_loss: 1.0494 - val_accuracy: 0.7398\n","Epoch 25/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0398 - accuracy: 0.9898 - val_loss: 0.8032 - val_accuracy: 0.7726\n","Epoch 26/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0267 - accuracy: 0.9946 - val_loss: 0.8594 - val_accuracy: 0.7873\n","Epoch 27/100\n","28/28 [==============================] - 1s 45ms/step - loss: 0.0188 - accuracy: 0.9966 - val_loss: 0.9312 - val_accuracy: 0.7919\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0213 - accuracy: 0.9963 - val_loss: 1.0700 - val_accuracy: 0.7624\n","Epoch 29/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0197 - accuracy: 0.9966 - val_loss: 0.9779 - val_accuracy: 0.7794\n","Epoch 30/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0203 - accuracy: 0.9969 - val_loss: 0.9965 - val_accuracy: 0.7919\n","Epoch 31/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0170 - accuracy: 0.9977 - val_loss: 0.9616 - val_accuracy: 0.7998\n","Epoch 32/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0138 - accuracy: 0.9992 - val_loss: 0.9717 - val_accuracy: 0.8032\n","Epoch 33/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0139 - accuracy: 0.9986 - val_loss: 0.9845 - val_accuracy: 0.7952\n","Epoch 34/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0142 - accuracy: 0.9989 - val_loss: 1.0194 - val_accuracy: 0.7952\n","Epoch 35/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0175 - accuracy: 0.9975 - val_loss: 1.0515 - val_accuracy: 0.7885\n","Epoch 36/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0317 - accuracy: 0.9921 - val_loss: 1.1412 - val_accuracy: 0.7771\n","Epoch 37/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0866 - accuracy: 0.9720 - val_loss: 1.1783 - val_accuracy: 0.7104\n","Epoch 38/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0665 - accuracy: 0.9779 - val_loss: 0.8692 - val_accuracy: 0.7828\n","Epoch 39/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0360 - accuracy: 0.9898 - val_loss: 0.9045 - val_accuracy: 0.7952\n","Epoch 40/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0222 - accuracy: 0.9946 - val_loss: 1.1043 - val_accuracy: 0.7783\n","Epoch 41/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0237 - accuracy: 0.9963 - val_loss: 1.3921 - val_accuracy: 0.7398\n","Epoch 42/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0327 - accuracy: 0.9912 - val_loss: 0.9316 - val_accuracy: 0.7749\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0253 - accuracy: 0.9943 - val_loss: 1.0372 - val_accuracy: 0.7771\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0207 - accuracy: 0.9963 - val_loss: 1.0372 - val_accuracy: 0.7873\n","Epoch 45/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0176 - accuracy: 0.9975 - val_loss: 1.0869 - val_accuracy: 0.7670\n","Epoch 46/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0172 - accuracy: 0.9977 - val_loss: 1.0215 - val_accuracy: 0.7885\n","Epoch 47/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0159 - accuracy: 0.9983 - val_loss: 1.0221 - val_accuracy: 0.7907\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0136 - accuracy: 0.9992 - val_loss: 0.9918 - val_accuracy: 0.7986\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0117 - accuracy: 0.9994 - val_loss: 1.0469 - val_accuracy: 0.7952\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0145 - accuracy: 0.9986 - val_loss: 1.0848 - val_accuracy: 0.7783\n","Epoch 51/100\n","28/28 [==============================] - 2s 58ms/step - loss: 0.0169 - accuracy: 0.9977 - val_loss: 0.9838 - val_accuracy: 0.8133\n","Epoch 52/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0119 - accuracy: 0.9992 - val_loss: 1.0082 - val_accuracy: 0.7975\n","Epoch 53/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0133 - accuracy: 0.9986 - val_loss: 1.0625 - val_accuracy: 0.7919\n","Epoch 54/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0117 - accuracy: 0.9992 - val_loss: 1.0061 - val_accuracy: 0.8020\n","Epoch 55/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0130 - accuracy: 0.9983 - val_loss: 1.0525 - val_accuracy: 0.7998\n","Epoch 56/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0128 - accuracy: 0.9989 - val_loss: 1.2223 - val_accuracy: 0.7624\n","Epoch 57/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0128 - accuracy: 0.9992 - val_loss: 1.0260 - val_accuracy: 0.8009\n","Epoch 58/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0129 - accuracy: 0.9989 - val_loss: 1.0027 - val_accuracy: 0.8020\n","Epoch 59/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0126 - accuracy: 0.9986 - val_loss: 0.9508 - val_accuracy: 0.8077\n","Epoch 60/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0117 - accuracy: 0.9989 - val_loss: 0.9522 - val_accuracy: 0.8077\n","Epoch 61/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0120 - accuracy: 0.9989 - val_loss: 0.9815 - val_accuracy: 0.7964\n","Epoch 62/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0106 - accuracy: 0.9994 - val_loss: 0.9399 - val_accuracy: 0.8054\n","Epoch 63/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0101 - accuracy: 0.9994 - val_loss: 0.9755 - val_accuracy: 0.8054\n","Epoch 64/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0104 - accuracy: 0.9994 - val_loss: 0.9699 - val_accuracy: 0.8066\n","Epoch 65/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0112 - accuracy: 0.9989 - val_loss: 0.9481 - val_accuracy: 0.8043\n","Epoch 66/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0101 - accuracy: 0.9994 - val_loss: 0.9840 - val_accuracy: 0.8032\n","Epoch 67/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0102 - accuracy: 0.9994 - val_loss: 1.0104 - val_accuracy: 0.7986\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0111 - accuracy: 0.9989 - val_loss: 0.9437 - val_accuracy: 0.8054\n","Epoch 69/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0108 - accuracy: 0.9986 - val_loss: 0.9927 - val_accuracy: 0.7986\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0121 - accuracy: 0.9986 - val_loss: 1.2170 - val_accuracy: 0.7500\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0105 - accuracy: 0.9994 - val_loss: 0.9894 - val_accuracy: 0.8054\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0108 - accuracy: 0.9992 - val_loss: 1.0233 - val_accuracy: 0.7964\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0098 - accuracy: 0.9994 - val_loss: 0.9749 - val_accuracy: 0.8054\n","Epoch 74/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0103 - accuracy: 0.9992 - val_loss: 0.9512 - val_accuracy: 0.8088\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0095 - accuracy: 0.9992 - val_loss: 0.9575 - val_accuracy: 0.8100\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0097 - accuracy: 0.9992 - val_loss: 0.9674 - val_accuracy: 0.8054\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0100 - accuracy: 0.9994 - val_loss: 0.9814 - val_accuracy: 0.8032\n","Epoch 78/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0112 - accuracy: 0.9983 - val_loss: 1.0468 - val_accuracy: 0.7885\n","Epoch 79/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0116 - accuracy: 0.9992 - val_loss: 1.0042 - val_accuracy: 0.7986\n","Epoch 80/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0109 - accuracy: 0.9992 - val_loss: 1.0625 - val_accuracy: 0.7839\n","Epoch 81/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0098 - accuracy: 0.9994 - val_loss: 0.9958 - val_accuracy: 0.8088\n","Epoch 82/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0095 - accuracy: 0.9989 - val_loss: 1.0021 - val_accuracy: 0.7975\n","Epoch 83/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0104 - accuracy: 0.9986 - val_loss: 0.9763 - val_accuracy: 0.8009\n","Epoch 84/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0129 - accuracy: 0.9986 - val_loss: 1.0142 - val_accuracy: 0.7862\n","Epoch 85/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0100 - accuracy: 0.9994 - val_loss: 1.1044 - val_accuracy: 0.7749\n","Epoch 86/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0106 - accuracy: 0.9992 - val_loss: 1.0857 - val_accuracy: 0.7851\n","Epoch 87/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0110 - accuracy: 0.9986 - val_loss: 1.0187 - val_accuracy: 0.7907\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0103 - accuracy: 0.9992 - val_loss: 0.9806 - val_accuracy: 0.7975\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0101 - accuracy: 0.9992 - val_loss: 1.0199 - val_accuracy: 0.7975\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0105 - accuracy: 0.9992 - val_loss: 1.1137 - val_accuracy: 0.7783\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0105 - accuracy: 0.9989 - val_loss: 1.1675 - val_accuracy: 0.7862\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0096 - accuracy: 0.9994 - val_loss: 1.0306 - val_accuracy: 0.8066\n","Epoch 93/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0091 - accuracy: 0.9992 - val_loss: 1.1400 - val_accuracy: 0.7873\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0117 - accuracy: 0.9989 - val_loss: 1.0359 - val_accuracy: 0.7794\n","Epoch 95/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0096 - accuracy: 0.9992 - val_loss: 1.0926 - val_accuracy: 0.8009\n","Epoch 96/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0111 - accuracy: 0.9983 - val_loss: 1.0692 - val_accuracy: 0.7964\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3074 - accuracy: 0.8758 - val_loss: 0.6601 - val_accuracy: 0.6980\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2255 - accuracy: 0.9145 - val_loss: 0.7619 - val_accuracy: 0.7590\n","Epoch 99/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0757 - accuracy: 0.9765 - val_loss: 1.0543 - val_accuracy: 0.7443\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0570 - accuracy: 0.9836 - val_loss: 1.1904 - val_accuracy: 0.7115\n","{'loss': [0.1453453153371811, 0.0675891637802124, 0.04657815024256706, 0.04034122824668884, 0.05321731045842171, 0.08475341647863388, 0.04327602684497833, 0.03016068786382675, 0.02951861172914505, 0.049355849623680115, 0.03751204535365105, 0.04560175910592079, 0.05440173298120499, 0.038338009268045425, 0.04684894531965256, 0.030143368989229202, 0.027618663385510445, 0.02973865531384945, 0.019033413380384445, 0.023262007161974907, 0.05081402137875557, 0.035241540521383286, 0.019231194630265236, 0.046860937029123306, 0.039793774485588074, 0.026728682219982147, 0.018752114847302437, 0.021289821714162827, 0.01968086138367653, 0.020252741873264313, 0.01703396625816822, 0.013845509849488735, 0.013856313191354275, 0.014243748970329762, 0.017535792663693428, 0.03173670172691345, 0.08660928905010223, 0.06646440178155899, 0.036031316965818405, 0.022205350920557976, 0.02372373454272747, 0.03274274617433548, 0.025341102853417397, 0.020729949697852135, 0.017644736915826797, 0.017174143344163895, 0.015899240970611572, 0.013614719733595848, 0.011687472462654114, 0.014507211744785309, 0.016852425411343575, 0.01190701313316822, 0.013343112543225288, 0.011667774058878422, 0.013015530072152615, 0.01281849853694439, 0.012755801901221275, 0.012905745767056942, 0.01260447222739458, 0.011729001067578793, 0.011952830478549004, 0.010585770010948181, 0.010053540579974651, 0.010416724719107151, 0.011222471483051777, 0.010075898841023445, 0.010170089080929756, 0.011050736531615257, 0.01076335646212101, 0.012088123708963394, 0.01045391894876957, 0.010811827145516872, 0.00979552697390318, 0.01033384446054697, 0.009510554373264313, 0.009717331267893314, 0.009964464232325554, 0.011151295155286789, 0.011569013819098473, 0.010907155461609364, 0.00984962098300457, 0.009451434947550297, 0.010423699393868446, 0.012917840853333473, 0.009961980395019054, 0.010568711906671524, 0.011039101518690586, 0.01029833871871233, 0.010091227479279041, 0.010457457043230534, 0.01052271481603384, 0.009601287543773651, 0.009148012846708298, 0.01172380056232214, 0.009553415700793266, 0.01114734634757042, 0.30743303894996643, 0.22546450793743134, 0.07568993419408798, 0.05698395520448685], 'accuracy': [0.9541596174240112, 0.9830220937728882, 0.9878324866294861, 0.9892473220825195, 0.9852858185768127, 0.9736841917037964, 0.9886813759803772, 0.9934917688369751, 0.9937747716903687, 0.986983597278595, 0.9892473220825195, 0.9852858185768127, 0.9850028157234192, 0.990662157535553, 0.9864176511764526, 0.992642879486084, 0.9946236610412598, 0.9920769929885864, 0.9974533319473267, 0.9954725503921509, 0.9867005944252014, 0.9917939901351929, 0.9966044425964355, 0.9872665405273438, 0.9898132681846619, 0.9946236610412598, 0.9966044425964355, 0.996321439743042, 0.9966044425964355, 0.9968873858451843, 0.9977362751960754, 0.9991511106491089, 0.9985851645469666, 0.9988681674003601, 0.9974533319473267, 0.9920769929885864, 0.9719864130020142, 0.9779286980628967, 0.9898132681846619, 0.9946236610412598, 0.996321439743042, 0.9912280440330505, 0.994340717792511, 0.996321439743042, 0.9974533319473267, 0.9977362751960754, 0.9983022212982178, 0.9991511106491089, 0.9994340538978577, 0.9985851645469666, 0.9977362751960754, 0.9991511106491089, 0.9985851645469666, 0.9991511106491089, 0.9983022212982178, 0.9988681674003601, 0.9991511106491089, 0.9988681674003601, 0.9985851645469666, 0.9988681674003601, 0.9988681674003601, 0.9994340538978577, 0.9994340538978577, 0.9994340538978577, 0.9988681674003601, 0.9994340538978577, 0.9994340538978577, 0.9988681674003601, 0.9985851645469666, 0.9985851645469666, 0.9994340538978577, 0.9991511106491089, 0.9994340538978577, 0.9991511106491089, 0.9991511106491089, 0.9991511106491089, 0.9994340538978577, 0.9983022212982178, 0.9991511106491089, 0.9991511106491089, 0.9994340538978577, 0.9988681674003601, 0.9985851645469666, 0.9985851645469666, 0.9994340538978577, 0.9991511106491089, 0.9985851645469666, 0.9991511106491089, 0.9991511106491089, 0.9991511106491089, 0.9988681674003601, 0.9994340538978577, 0.9991511106491089, 0.9988681674003601, 0.9991511106491089, 0.9983022212982178, 0.8757781386375427, 0.914544403553009, 0.9765138626098633, 0.9835879802703857], 'val_loss': [0.691362738609314, 0.688774585723877, 0.6963580846786499, 0.6717531085014343, 0.6508393883705139, 0.6612761616706848, 0.6578702330589294, 0.6470900774002075, 0.6566289067268372, 0.6411392688751221, 0.7855812311172485, 0.6805693507194519, 0.6409100294113159, 0.7689948678016663, 0.6836427450180054, 0.7208121418952942, 0.7572892308235168, 0.8646232485771179, 0.9487698674201965, 0.8831820487976074, 0.7687289714813232, 0.8310661315917969, 0.9545698165893555, 1.0493699312210083, 0.8032431602478027, 0.8593587875366211, 0.9311566352844238, 1.0700336694717407, 0.9779320359230042, 0.9965440034866333, 0.9616199731826782, 0.9716793894767761, 0.984512448310852, 1.0193977355957031, 1.0514905452728271, 1.1412347555160522, 1.1782872676849365, 0.8692152500152588, 0.9044970870018005, 1.1042969226837158, 1.3921232223510742, 0.9315512180328369, 1.0372108221054077, 1.0371965169906616, 1.0868788957595825, 1.0214979648590088, 1.0220884084701538, 0.9917678236961365, 1.0468835830688477, 1.0847842693328857, 0.9837717413902283, 1.0082299709320068, 1.0625028610229492, 1.0061380863189697, 1.0525269508361816, 1.2222704887390137, 1.0260392427444458, 1.0027154684066772, 0.9508497714996338, 0.9522185921669006, 0.9815418124198914, 0.9398652911186218, 0.9754505157470703, 0.9699206948280334, 0.948082685470581, 0.9839524030685425, 1.010427713394165, 0.9436628818511963, 0.9926750659942627, 1.2169932126998901, 0.9893881678581238, 1.0232549905776978, 0.974911093711853, 0.9511858224868774, 0.9575418829917908, 0.9673924446105957, 0.9813790917396545, 1.0467678308486938, 1.004225730895996, 1.0625146627426147, 0.995812177658081, 1.002084493637085, 0.9762853980064392, 1.0142028331756592, 1.1044094562530518, 1.0857332944869995, 1.0187386274337769, 0.9806042313575745, 1.0199172496795654, 1.1136504411697388, 1.167492389678955, 1.0305529832839966, 1.1399677991867065, 1.035908579826355, 1.0926039218902588, 1.0691659450531006, 0.6600615978240967, 0.7618758082389832, 1.0543428659439087, 1.1904226541519165], 'val_accuracy': [0.5599547624588013, 0.5520362257957458, 0.5373303294181824, 0.5893664956092834, 0.651583731174469, 0.6244344115257263, 0.6199095249176025, 0.6346153616905212, 0.6414027214050293, 0.6549773812294006, 0.622171938419342, 0.651583731174469, 0.6606335043907166, 0.6300904750823975, 0.6730769276618958, 0.6957013607025146, 0.7024886608123779, 0.6968325972557068, 0.7081447839736938, 0.7420814633369446, 0.7420814633369446, 0.7511312365531921, 0.7579185366630554, 0.7398189902305603, 0.7726244330406189, 0.7873303294181824, 0.7918552160263062, 0.7624434232711792, 0.779411792755127, 0.7918552160263062, 0.7997737526893616, 0.8031674027442932, 0.7952488660812378, 0.7952488660812378, 0.7884615659713745, 0.7771493196487427, 0.7104072570800781, 0.7828054428100586, 0.7952488660812378, 0.7782805562019348, 0.7398189902305603, 0.7748869061470032, 0.7771493196487427, 0.7873303294181824, 0.766968309879303, 0.7884615659713745, 0.790723979473114, 0.7986425161361694, 0.7952488660812378, 0.7782805562019348, 0.8133484125137329, 0.7975113391876221, 0.7918552160263062, 0.8020362257957458, 0.7997737526893616, 0.7624434232711792, 0.8009049892425537, 0.8020362257957458, 0.807692289352417, 0.807692289352417, 0.7963801026344299, 0.8054298758506775, 0.8054298758506775, 0.8065611124038696, 0.8042986392974854, 0.8031674027442932, 0.7986425161361694, 0.8054298758506775, 0.7986425161361694, 0.75, 0.8054298758506775, 0.7963801026344299, 0.8054298758506775, 0.8088235259056091, 0.8099547624588013, 0.8054298758506775, 0.8031674027442932, 0.7884615659713745, 0.7986425161361694, 0.7839366793632507, 0.8088235259056091, 0.7975113391876221, 0.8009049892425537, 0.7861990928649902, 0.7748869061470032, 0.7850678563117981, 0.790723979473114, 0.7975113391876221, 0.7975113391876221, 0.7782805562019348, 0.7861990928649902, 0.8065611124038696, 0.7873303294181824, 0.779411792755127, 0.8009049892425537, 0.7963801026344299, 0.6979637742042542, 0.7590497732162476, 0.7443438768386841, 0.7115384340286255]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.1660 - accuracy: 0.9450"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 7s 66ms/step - loss: 0.1660 - accuracy: 0.9450 - val_loss: 0.6915 - val_accuracy: 0.5857\n","Epoch 2/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0894 - accuracy: 0.9747 - val_loss: 0.6854 - val_accuracy: 0.5754\n","Epoch 3/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.1416 - accuracy: 0.9532 - val_loss: 0.6846 - val_accuracy: 0.5940\n","Epoch 4/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.0611 - accuracy: 0.9842 - val_loss: 0.6756 - val_accuracy: 0.6095\n","Epoch 5/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0417 - accuracy: 0.9928 - val_loss: 0.6681 - val_accuracy: 0.6012\n","Epoch 6/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0328 - accuracy: 0.9928 - val_loss: 0.6686 - val_accuracy: 0.5992\n","Epoch 7/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0289 - accuracy: 0.9948 - val_loss: 0.6519 - val_accuracy: 0.6209\n","Epoch 8/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0404 - accuracy: 0.9886 - val_loss: 0.6530 - val_accuracy: 0.6240\n","Epoch 9/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0354 - accuracy: 0.9912 - val_loss: 0.6758 - val_accuracy: 0.6043\n","Epoch 10/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0374 - accuracy: 0.9904 - val_loss: 0.6831 - val_accuracy: 0.6260\n","Epoch 11/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0351 - accuracy: 0.9902 - val_loss: 0.6829 - val_accuracy: 0.6322\n","Epoch 12/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0499 - accuracy: 0.9871 - val_loss: 0.8098 - val_accuracy: 0.5909\n","Epoch 13/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0399 - accuracy: 0.9917 - val_loss: 0.7512 - val_accuracy: 0.6436\n","Epoch 14/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0348 - accuracy: 0.9922 - val_loss: 0.8550 - val_accuracy: 0.6498\n","Epoch 15/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0405 - accuracy: 0.9897 - val_loss: 0.9623 - val_accuracy: 0.6488\n","Epoch 16/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0668 - accuracy: 0.9791 - val_loss: 0.9489 - val_accuracy: 0.6157\n","Epoch 17/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0475 - accuracy: 0.9858 - val_loss: 0.9645 - val_accuracy: 0.6488\n","Epoch 18/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0274 - accuracy: 0.9941 - val_loss: 1.0553 - val_accuracy: 0.6756\n","Epoch 19/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.0357 - accuracy: 0.9917 - val_loss: 0.9204 - val_accuracy: 0.7221\n","Epoch 20/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.0443 - accuracy: 0.9879 - val_loss: 0.8923 - val_accuracy: 0.7376\n","Epoch 21/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0419 - accuracy: 0.9871 - val_loss: 1.1047 - val_accuracy: 0.7242\n","Epoch 22/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.0232 - accuracy: 0.9964 - val_loss: 1.0421 - val_accuracy: 0.7572\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0211 - accuracy: 0.9974 - val_loss: 1.1563 - val_accuracy: 0.7572\n","Epoch 24/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0430 - accuracy: 0.9891 - val_loss: 1.2127 - val_accuracy: 0.7252\n","Epoch 25/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0588 - accuracy: 0.9835 - val_loss: 1.0949 - val_accuracy: 0.7314\n","Epoch 26/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0317 - accuracy: 0.9922 - val_loss: 0.9453 - val_accuracy: 0.7986\n","Epoch 27/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0352 - accuracy: 0.9902 - val_loss: 1.1521 - val_accuracy: 0.7479\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1411 - accuracy: 0.9556 - val_loss: 0.7360 - val_accuracy: 0.7603\n","Epoch 29/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0439 - accuracy: 0.9873 - val_loss: 0.9183 - val_accuracy: 0.7676\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0209 - accuracy: 0.9979 - val_loss: 1.0360 - val_accuracy: 0.7727\n","Epoch 31/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0177 - accuracy: 0.9987 - val_loss: 1.1142 - val_accuracy: 0.7624\n","Epoch 32/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0162 - accuracy: 0.9984 - val_loss: 1.1214 - val_accuracy: 0.7758\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0145 - accuracy: 0.9979 - val_loss: 1.1331 - val_accuracy: 0.7758\n","Epoch 34/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0147 - accuracy: 0.9990 - val_loss: 1.1249 - val_accuracy: 0.7810\n","Epoch 35/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0132 - accuracy: 0.9990 - val_loss: 1.0991 - val_accuracy: 0.7851\n","Epoch 36/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0129 - accuracy: 0.9995 - val_loss: 1.1459 - val_accuracy: 0.7748\n","Epoch 37/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0161 - accuracy: 0.9979 - val_loss: 1.1791 - val_accuracy: 0.7727\n","Epoch 38/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0141 - accuracy: 0.9987 - val_loss: 1.1532 - val_accuracy: 0.7676\n","Epoch 39/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0156 - accuracy: 0.9984 - val_loss: 1.1527 - val_accuracy: 0.7696\n","Epoch 40/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0249 - accuracy: 0.9951 - val_loss: 1.0343 - val_accuracy: 0.7738\n","Epoch 41/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0203 - accuracy: 0.9969 - val_loss: 1.1418 - val_accuracy: 0.7686\n","Epoch 42/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0139 - accuracy: 0.9984 - val_loss: 1.1681 - val_accuracy: 0.7779\n","Epoch 43/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0152 - accuracy: 0.9987 - val_loss: 1.1553 - val_accuracy: 0.7727\n","Epoch 44/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0185 - accuracy: 0.9977 - val_loss: 1.1760 - val_accuracy: 0.7707\n","Epoch 45/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0187 - accuracy: 0.9974 - val_loss: 1.1209 - val_accuracy: 0.7831\n","Epoch 46/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0404 - accuracy: 0.9879 - val_loss: 1.1156 - val_accuracy: 0.7469\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1180 - accuracy: 0.9584 - val_loss: 0.7993 - val_accuracy: 0.7541\n","Epoch 48/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0317 - accuracy: 0.9928 - val_loss: 1.1254 - val_accuracy: 0.7645\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0217 - accuracy: 0.9956 - val_loss: 1.1572 - val_accuracy: 0.7655\n","Epoch 50/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0165 - accuracy: 0.9977 - val_loss: 1.2432 - val_accuracy: 0.7603\n","Epoch 51/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0256 - accuracy: 0.9933 - val_loss: 1.2678 - val_accuracy: 0.7562\n","Epoch 52/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0495 - accuracy: 0.9853 - val_loss: 1.0001 - val_accuracy: 0.7593\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0304 - accuracy: 0.9935 - val_loss: 1.2300 - val_accuracy: 0.7283\n","Epoch 54/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0215 - accuracy: 0.9959 - val_loss: 1.1644 - val_accuracy: 0.7614\n","Epoch 55/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0256 - accuracy: 0.9951 - val_loss: 1.3130 - val_accuracy: 0.7293\n","Epoch 56/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0351 - accuracy: 0.9897 - val_loss: 1.5592 - val_accuracy: 0.7118\n","Epoch 57/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0479 - accuracy: 0.9876 - val_loss: 1.1755 - val_accuracy: 0.7200\n","Epoch 58/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0392 - accuracy: 0.9889 - val_loss: 1.2589 - val_accuracy: 0.7283\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0292 - accuracy: 0.9925 - val_loss: 1.1700 - val_accuracy: 0.7583\n","Epoch 60/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0797 - accuracy: 0.9767 - val_loss: 1.0265 - val_accuracy: 0.7366\n","Epoch 61/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0417 - accuracy: 0.9889 - val_loss: 1.2346 - val_accuracy: 0.7190\n","Epoch 62/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0352 - accuracy: 0.9910 - val_loss: 1.3891 - val_accuracy: 0.7066\n","Epoch 63/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0371 - accuracy: 0.9904 - val_loss: 1.2217 - val_accuracy: 0.7252\n","Epoch 64/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0247 - accuracy: 0.9941 - val_loss: 1.1932 - val_accuracy: 0.7521\n","Epoch 65/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0170 - accuracy: 0.9977 - val_loss: 1.2718 - val_accuracy: 0.7428\n","Epoch 66/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0134 - accuracy: 0.9982 - val_loss: 1.2613 - val_accuracy: 0.7397\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0126 - accuracy: 0.9990 - val_loss: 1.2723 - val_accuracy: 0.7510\n","Epoch 68/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0119 - accuracy: 0.9995 - val_loss: 1.2882 - val_accuracy: 0.7500\n","Epoch 69/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0129 - accuracy: 0.9992 - val_loss: 1.3642 - val_accuracy: 0.7304\n","Epoch 70/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0114 - accuracy: 0.9992 - val_loss: 1.2958 - val_accuracy: 0.7428\n","Epoch 71/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0110 - accuracy: 0.9995 - val_loss: 1.3132 - val_accuracy: 0.7428\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0110 - accuracy: 0.9992 - val_loss: 1.3118 - val_accuracy: 0.7552\n","Epoch 73/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0114 - accuracy: 0.9995 - val_loss: 1.2608 - val_accuracy: 0.7500\n","Epoch 74/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0103 - accuracy: 0.9995 - val_loss: 1.2587 - val_accuracy: 0.7521\n","Epoch 75/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0117 - accuracy: 0.9990 - val_loss: 1.2198 - val_accuracy: 0.7552\n","Epoch 76/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0114 - accuracy: 0.9992 - val_loss: 1.1898 - val_accuracy: 0.7531\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0104 - accuracy: 0.9995 - val_loss: 1.1918 - val_accuracy: 0.7510\n","Epoch 78/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0112 - accuracy: 0.9990 - val_loss: 1.1857 - val_accuracy: 0.7593\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0102 - accuracy: 0.9992 - val_loss: 1.2641 - val_accuracy: 0.7521\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0104 - accuracy: 0.9995 - val_loss: 1.2158 - val_accuracy: 0.7541\n","Epoch 81/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0103 - accuracy: 0.9992 - val_loss: 1.2910 - val_accuracy: 0.7490\n","Epoch 82/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0102 - accuracy: 0.9992 - val_loss: 1.2439 - val_accuracy: 0.7552\n","Epoch 83/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0104 - accuracy: 0.9995 - val_loss: 1.1909 - val_accuracy: 0.7500\n","Epoch 84/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0099 - accuracy: 0.9995 - val_loss: 1.2385 - val_accuracy: 0.7593\n","Epoch 85/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0096 - accuracy: 0.9992 - val_loss: 1.2613 - val_accuracy: 0.7562\n","Epoch 86/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0095 - accuracy: 0.9992 - val_loss: 1.2292 - val_accuracy: 0.7603\n","Epoch 87/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0105 - accuracy: 0.9990 - val_loss: 1.2099 - val_accuracy: 0.7583\n","Epoch 88/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0101 - accuracy: 0.9990 - val_loss: 1.2006 - val_accuracy: 0.7624\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0101 - accuracy: 0.9995 - val_loss: 1.2210 - val_accuracy: 0.7583\n","Epoch 90/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0105 - accuracy: 0.9992 - val_loss: 1.2147 - val_accuracy: 0.7603\n","Epoch 91/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0096 - accuracy: 0.9995 - val_loss: 1.2365 - val_accuracy: 0.7552\n","Epoch 92/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0096 - accuracy: 0.9995 - val_loss: 1.2598 - val_accuracy: 0.7417\n","Epoch 93/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0101 - accuracy: 0.9992 - val_loss: 1.2380 - val_accuracy: 0.7603\n","Epoch 94/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0095 - accuracy: 0.9995 - val_loss: 1.2388 - val_accuracy: 0.7510\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0114 - accuracy: 0.9987 - val_loss: 1.3795 - val_accuracy: 0.7293\n","Epoch 96/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0105 - accuracy: 0.9992 - val_loss: 1.3087 - val_accuracy: 0.7593\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0098 - accuracy: 0.9995 - val_loss: 1.2507 - val_accuracy: 0.7676\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0097 - accuracy: 0.9995 - val_loss: 1.2382 - val_accuracy: 0.7655\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0097 - accuracy: 0.9990 - val_loss: 1.2321 - val_accuracy: 0.7707\n","Epoch 100/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0092 - accuracy: 0.9995 - val_loss: 1.2499 - val_accuracy: 0.7624\n","{'loss': [0.16602353751659393, 0.08937309682369232, 0.1415947526693344, 0.06107770651578903, 0.041740842163562775, 0.032842349261045456, 0.028879601508378983, 0.040419384837150574, 0.03537873178720474, 0.0373665951192379, 0.03513041138648987, 0.0499289333820343, 0.03992479294538498, 0.034820299595594406, 0.04051246866583824, 0.0668187290430069, 0.04751776531338692, 0.027428822591900826, 0.035692017525434494, 0.04431760683655739, 0.04191870242357254, 0.023245446383953094, 0.02105853334069252, 0.04301755875349045, 0.058792732656002045, 0.031695567071437836, 0.03516530990600586, 0.14105482399463654, 0.043920114636421204, 0.02086535654962063, 0.01770758628845215, 0.016153963282704353, 0.014472966082394123, 0.014653511345386505, 0.013227144256234169, 0.012854966334998608, 0.01609329879283905, 0.01410828996449709, 0.015601101331412792, 0.02488238736987114, 0.020269565284252167, 0.013873445801436901, 0.015175392851233482, 0.01852354407310486, 0.018741831183433533, 0.04039148986339569, 0.1180482804775238, 0.03172310069203377, 0.02165401540696621, 0.016468141227960587, 0.025593601167201996, 0.049473632127046585, 0.030404580757021904, 0.021472249180078506, 0.025602351874113083, 0.035055965185165405, 0.047887999564409256, 0.03920085355639458, 0.029225433245301247, 0.07965346425771713, 0.041745882481336594, 0.035223644226789474, 0.03714151307940483, 0.02469547651708126, 0.01702750101685524, 0.013431789353489876, 0.012637101113796234, 0.011850936338305473, 0.012861840426921844, 0.0113785769790411, 0.011013876646757126, 0.010991301387548447, 0.01135967392474413, 0.010263861157000065, 0.01171313039958477, 0.011396682821214199, 0.010371127165853977, 0.011156001128256321, 0.010178115218877792, 0.010384798049926758, 0.0102942930534482, 0.010242204181849957, 0.010386050678789616, 0.009948221035301685, 0.00959221925586462, 0.00951750110834837, 0.01053309254348278, 0.01008527260273695, 0.010147097520530224, 0.01053609885275364, 0.009558948688209057, 0.009610888548195362, 0.01005101203918457, 0.009455685503780842, 0.011435186490416527, 0.010479489341378212, 0.009760948829352856, 0.009661324322223663, 0.009677071124315262, 0.009150311350822449], 'accuracy': [0.9449612498283386, 0.9746770262718201, 0.9532299637794495, 0.9842377305030823, 0.9927648305892944, 0.9927648305892944, 0.9948320388793945, 0.988630473613739, 0.9912144541740417, 0.9904392957687378, 0.9901808500289917, 0.9870800971984863, 0.9917312860488892, 0.9922480583190918, 0.9896640777587891, 0.9790697693824768, 0.985788106918335, 0.9940568208694458, 0.9917312860488892, 0.9878553152084351, 0.9870800971984863, 0.9963824152946472, 0.9974160194396973, 0.9891473054885864, 0.9834625124931335, 0.9922480583190918, 0.9901808500289917, 0.9555555582046509, 0.9873384833335876, 0.9979327917098999, 0.9987080097198486, 0.9984496235847473, 0.9979327917098999, 0.99896639585495, 0.99896639585495, 0.9994832277297974, 0.9979327917098999, 0.9987080097198486, 0.9984496235847473, 0.9950904250144958, 0.9968992471694946, 0.9984496235847473, 0.9987080097198486, 0.9976744055747986, 0.9974160194396973, 0.9878553152084351, 0.9583979249000549, 0.9927648305892944, 0.9956072568893433, 0.9976744055747986, 0.9932816624641418, 0.9852713346481323, 0.9935400485992432, 0.9958656430244446, 0.9950904250144958, 0.9896640777587891, 0.987596869468689, 0.9888888597488403, 0.9925064444541931, 0.9767441749572754, 0.9888888597488403, 0.9909560680389404, 0.9904392957687378, 0.9940568208694458, 0.9976744055747986, 0.998191237449646, 0.99896639585495, 0.9994832277297974, 0.9992247819900513, 0.9992247819900513, 0.9994832277297974, 0.9992247819900513, 0.9994832277297974, 0.9994832277297974, 0.99896639585495, 0.9992247819900513, 0.9994832277297974, 0.99896639585495, 0.9992247819900513, 0.9994832277297974, 0.9992247819900513, 0.9992247819900513, 0.9994832277297974, 0.9994832277297974, 0.9992247819900513, 0.9992247819900513, 0.99896639585495, 0.99896639585495, 0.9994832277297974, 0.9992247819900513, 0.9994832277297974, 0.9994832277297974, 0.9992247819900513, 0.9994832277297974, 0.9987080097198486, 0.9992247819900513, 0.9994832277297974, 0.9994832277297974, 0.99896639585495, 0.9994832277297974], 'val_loss': [0.6914505958557129, 0.6854439377784729, 0.6846430897712708, 0.6755549311637878, 0.6680690050125122, 0.6686276793479919, 0.6518616080284119, 0.6530444622039795, 0.6758190989494324, 0.6830959916114807, 0.6829031705856323, 0.8097898960113525, 0.7512263655662537, 0.854982852935791, 0.962263822555542, 0.9488657116889954, 0.9645466208457947, 1.0553463697433472, 0.9203959703445435, 0.8923133015632629, 1.1046780347824097, 1.0420671701431274, 1.1563349962234497, 1.212747573852539, 1.094889760017395, 0.9452680349349976, 1.152134895324707, 0.7359703779220581, 0.9182594418525696, 1.0359936952590942, 1.1142282485961914, 1.121354341506958, 1.1330546140670776, 1.1249339580535889, 1.0990649461746216, 1.145909309387207, 1.179092288017273, 1.1531851291656494, 1.1526724100112915, 1.0343096256256104, 1.1418383121490479, 1.168075680732727, 1.1553080081939697, 1.1759910583496094, 1.120866298675537, 1.1155650615692139, 0.7992656826972961, 1.125411033630371, 1.1571705341339111, 1.243177890777588, 1.2677931785583496, 1.0000923871994019, 1.230007290840149, 1.1644096374511719, 1.3130080699920654, 1.559219241142273, 1.1755262613296509, 1.2589048147201538, 1.1699767112731934, 1.026452660560608, 1.2345967292785645, 1.3890982866287231, 1.2217049598693848, 1.1932367086410522, 1.2718069553375244, 1.2612736225128174, 1.2722622156143188, 1.2881853580474854, 1.3641941547393799, 1.2958054542541504, 1.3132212162017822, 1.311767339706421, 1.2607777118682861, 1.2586663961410522, 1.219835638999939, 1.1898083686828613, 1.1918264627456665, 1.1857432126998901, 1.264080286026001, 1.215757966041565, 1.2910120487213135, 1.2438511848449707, 1.1909228563308716, 1.2384963035583496, 1.2612624168395996, 1.229242205619812, 1.2098774909973145, 1.2006335258483887, 1.2210451364517212, 1.2146520614624023, 1.236536979675293, 1.2597756385803223, 1.2379827499389648, 1.2388379573822021, 1.3794646263122559, 1.3087352514266968, 1.2506608963012695, 1.2382439374923706, 1.2321491241455078, 1.2498780488967896], 'val_accuracy': [0.58574378490448, 0.5754132270812988, 0.5940082669258118, 0.6095041036605835, 0.6012396812438965, 0.5991735458374023, 0.6208677887916565, 0.6239669322967529, 0.6043388247489929, 0.6260330677032471, 0.6322314143180847, 0.5909090638160706, 0.6435950398445129, 0.6497933864593506, 0.6487603187561035, 0.6157024502754211, 0.6487603187561035, 0.6756198406219482, 0.7221074104309082, 0.7376033067703247, 0.7241735458374023, 0.7572314143180847, 0.7572314143180847, 0.7252066135406494, 0.7314049601554871, 0.7985537052154541, 0.7479338645935059, 0.7603305578231812, 0.7675619721412659, 0.7727272510528564, 0.7623966932296753, 0.7758264541625977, 0.7758264541625977, 0.7809917330741882, 0.7851239442825317, 0.7747933864593506, 0.7727272510528564, 0.7675619721412659, 0.76962810754776, 0.7737603187561035, 0.7685950398445129, 0.7778925895690918, 0.7727272510528564, 0.7706611752510071, 0.7830578684806824, 0.7469007968902588, 0.7541322112083435, 0.7644628286361694, 0.7654958963394165, 0.7603305578231812, 0.7561983466148376, 0.7592975497245789, 0.7283057570457458, 0.7613636255264282, 0.7293388247489929, 0.711776852607727, 0.7200413346290588, 0.7283057570457458, 0.7582644820213318, 0.7365702390670776, 0.7190082669258118, 0.7066115736961365, 0.7252066135406494, 0.7520661354064941, 0.7427685856819153, 0.7396694421768188, 0.7510330677032471, 0.75, 0.73037189245224, 0.7427685856819153, 0.7427685856819153, 0.7551652789115906, 0.75, 0.7520661354064941, 0.7551652789115906, 0.7530992031097412, 0.7510330677032471, 0.7592975497245789, 0.7520661354064941, 0.7541322112083435, 0.7489669322967529, 0.7551652789115906, 0.75, 0.7592975497245789, 0.7561983466148376, 0.7603305578231812, 0.7582644820213318, 0.7623966932296753, 0.7582644820213318, 0.7603305578231812, 0.7551652789115906, 0.7417355179786682, 0.7603305578231812, 0.7510330677032471, 0.7293388247489929, 0.7592975497245789, 0.7675619721412659, 0.7654958963394165, 0.7706611752510071, 0.7623966932296753]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.0643 - accuracy: 0.9816"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 7s 82ms/step - loss: 0.0644 - accuracy: 0.9817 - val_loss: 0.6807 - val_accuracy: 0.5700\n","Epoch 2/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0307 - accuracy: 0.9925 - val_loss: 0.6862 - val_accuracy: 0.5463\n","Epoch 3/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0243 - accuracy: 0.9941 - val_loss: 0.6791 - val_accuracy: 0.5636\n","Epoch 4/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0157 - accuracy: 0.9981 - val_loss: 0.6747 - val_accuracy: 0.5851\n","Epoch 5/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0115 - accuracy: 0.9987 - val_loss: 0.6880 - val_accuracy: 0.5841\n","Epoch 6/100\n","29/29 [==============================] - 1s 37ms/step - loss: 0.0122 - accuracy: 0.9987 - val_loss: 0.6425 - val_accuracy: 0.6336\n","Epoch 7/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0143 - accuracy: 0.9976 - val_loss: 0.6519 - val_accuracy: 0.6304\n","Epoch 8/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0147 - accuracy: 0.9981 - val_loss: 0.6091 - val_accuracy: 0.6606\n","Epoch 9/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0430 - accuracy: 0.9884 - val_loss: 0.6054 - val_accuracy: 0.6692\n","Epoch 10/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0685 - accuracy: 0.9798 - val_loss: 0.6278 - val_accuracy: 0.6562\n","Epoch 11/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0443 - accuracy: 0.9855 - val_loss: 0.6012 - val_accuracy: 0.6864\n","Epoch 12/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0391 - accuracy: 0.9898 - val_loss: 0.6976 - val_accuracy: 0.6444\n","Epoch 13/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0252 - accuracy: 0.9943 - val_loss: 0.7630 - val_accuracy: 0.6616\n","Epoch 14/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0243 - accuracy: 0.9941 - val_loss: 0.6608 - val_accuracy: 0.7069\n","Epoch 15/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0353 - accuracy: 0.9916 - val_loss: 0.6676 - val_accuracy: 0.7209\n","Epoch 16/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0481 - accuracy: 0.9881 - val_loss: 0.8588 - val_accuracy: 0.6595\n","Epoch 17/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0196 - accuracy: 0.9957 - val_loss: 1.1297 - val_accuracy: 0.6627\n","Epoch 18/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0146 - accuracy: 0.9978 - val_loss: 1.2635 - val_accuracy: 0.6756\n","Epoch 19/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0157 - accuracy: 0.9976 - val_loss: 1.2610 - val_accuracy: 0.6886\n","Epoch 20/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.0172 - accuracy: 0.9965 - val_loss: 0.8502 - val_accuracy: 0.7425\n","Epoch 21/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.0243 - accuracy: 0.9952 - val_loss: 0.8401 - val_accuracy: 0.7791\n","Epoch 22/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0182 - accuracy: 0.9960 - val_loss: 1.0404 - val_accuracy: 0.7554\n","Epoch 23/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.0156 - accuracy: 0.9976 - val_loss: 0.7305 - val_accuracy: 0.8265\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0397 - accuracy: 0.9871 - val_loss: 0.9228 - val_accuracy: 0.7575\n","Epoch 25/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0343 - accuracy: 0.9900 - val_loss: 0.9774 - val_accuracy: 0.7532\n","Epoch 26/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0411 - accuracy: 0.9884 - val_loss: 0.6507 - val_accuracy: 0.8190\n","Epoch 27/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0341 - accuracy: 0.9919 - val_loss: 0.8917 - val_accuracy: 0.7769\n","Epoch 28/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 0.7231 - val_accuracy: 0.8330\n","Epoch 29/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0246 - accuracy: 0.9927 - val_loss: 0.8088 - val_accuracy: 0.8168\n","Epoch 30/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0241 - accuracy: 0.9941 - val_loss: 0.8568 - val_accuracy: 0.8136\n","Epoch 31/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0270 - accuracy: 0.9941 - val_loss: 0.8755 - val_accuracy: 0.8125\n","Epoch 32/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0342 - accuracy: 0.9916 - val_loss: 0.6926 - val_accuracy: 0.8287\n","Epoch 33/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0167 - accuracy: 0.9973 - val_loss: 0.8175 - val_accuracy: 0.8244\n","Epoch 34/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0175 - accuracy: 0.9957 - val_loss: 0.8445 - val_accuracy: 0.8319\n","Epoch 35/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0307 - accuracy: 0.9916 - val_loss: 0.9346 - val_accuracy: 0.7823\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0269 - accuracy: 0.9930 - val_loss: 0.7067 - val_accuracy: 0.8297\n","Epoch 37/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0223 - accuracy: 0.9941 - val_loss: 0.7649 - val_accuracy: 0.8222\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0244 - accuracy: 0.9925 - val_loss: 0.7510 - val_accuracy: 0.8244\n","Epoch 39/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0144 - accuracy: 0.9970 - val_loss: 0.9241 - val_accuracy: 0.8103\n","Epoch 40/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.0141 - accuracy: 0.9981 - val_loss: 0.8650 - val_accuracy: 0.8341\n","Epoch 41/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0215 - accuracy: 0.9943 - val_loss: 0.9305 - val_accuracy: 0.8028\n","Epoch 42/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0312 - accuracy: 0.9919 - val_loss: 0.7860 - val_accuracy: 0.8136\n","Epoch 43/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0183 - accuracy: 0.9957 - val_loss: 0.8803 - val_accuracy: 0.8319\n","Epoch 44/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0273 - accuracy: 0.9938 - val_loss: 0.8179 - val_accuracy: 0.8039\n","Epoch 45/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0157 - accuracy: 0.9976 - val_loss: 0.8806 - val_accuracy: 0.8060\n","Epoch 46/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0176 - accuracy: 0.9968 - val_loss: 0.8763 - val_accuracy: 0.8168\n","Epoch 47/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0135 - accuracy: 0.9981 - val_loss: 0.9579 - val_accuracy: 0.8093\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0153 - accuracy: 0.9973 - val_loss: 1.0177 - val_accuracy: 0.7996\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0205 - accuracy: 0.9957 - val_loss: 1.0218 - val_accuracy: 0.7931\n","Epoch 50/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 1.2215 - val_accuracy: 0.7694\n","Epoch 51/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0353 - accuracy: 0.9906 - val_loss: 0.8615 - val_accuracy: 0.8071\n","Epoch 52/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0447 - accuracy: 0.9855 - val_loss: 0.8328 - val_accuracy: 0.7931\n","Epoch 53/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0150 - accuracy: 0.9970 - val_loss: 0.9090 - val_accuracy: 0.7899\n","Epoch 54/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0105 - accuracy: 0.9984 - val_loss: 1.0354 - val_accuracy: 0.8028\n","Epoch 55/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0116 - accuracy: 0.9989 - val_loss: 0.9027 - val_accuracy: 0.8233\n","Epoch 56/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0111 - accuracy: 0.9987 - val_loss: 0.9046 - val_accuracy: 0.8050\n","Epoch 57/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0094 - accuracy: 0.9989 - val_loss: 0.9637 - val_accuracy: 0.8060\n","Epoch 58/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0093 - accuracy: 0.9992 - val_loss: 0.9196 - val_accuracy: 0.8168\n","Epoch 59/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0118 - accuracy: 0.9978 - val_loss: 0.8489 - val_accuracy: 0.8254\n","Epoch 60/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0100 - accuracy: 0.9989 - val_loss: 0.9546 - val_accuracy: 0.8050\n","Epoch 61/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0100 - accuracy: 0.9989 - val_loss: 0.8979 - val_accuracy: 0.8168\n","Epoch 62/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0096 - accuracy: 0.9992 - val_loss: 0.9615 - val_accuracy: 0.8114\n","Epoch 63/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0085 - accuracy: 0.9995 - val_loss: 0.9073 - val_accuracy: 0.8168\n","Epoch 64/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0090 - accuracy: 0.9992 - val_loss: 0.8968 - val_accuracy: 0.8147\n","Epoch 65/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0089 - accuracy: 0.9987 - val_loss: 0.8996 - val_accuracy: 0.8157\n","Epoch 66/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0081 - accuracy: 0.9995 - val_loss: 0.9023 - val_accuracy: 0.8125\n","Epoch 67/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0083 - accuracy: 0.9995 - val_loss: 0.9025 - val_accuracy: 0.8168\n","Epoch 68/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0082 - accuracy: 0.9995 - val_loss: 0.8974 - val_accuracy: 0.8179\n","Epoch 69/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0085 - accuracy: 0.9989 - val_loss: 0.9205 - val_accuracy: 0.8157\n","Epoch 70/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0082 - accuracy: 0.9995 - val_loss: 0.9259 - val_accuracy: 0.8114\n","Epoch 71/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0091 - accuracy: 0.9984 - val_loss: 0.8748 - val_accuracy: 0.8211\n","Epoch 72/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0086 - accuracy: 0.9995 - val_loss: 0.9324 - val_accuracy: 0.8179\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0082 - accuracy: 0.9995 - val_loss: 0.9084 - val_accuracy: 0.8157\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0089 - accuracy: 0.9992 - val_loss: 0.8962 - val_accuracy: 0.8114\n","Epoch 75/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0079 - accuracy: 0.9995 - val_loss: 0.8844 - val_accuracy: 0.8190\n","Epoch 76/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0080 - accuracy: 0.9995 - val_loss: 0.8997 - val_accuracy: 0.8157\n","Epoch 77/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0079 - accuracy: 0.9995 - val_loss: 0.8979 - val_accuracy: 0.8200\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0077 - accuracy: 0.9995 - val_loss: 0.9127 - val_accuracy: 0.8136\n","Epoch 79/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.8952 - val_accuracy: 0.8157\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0078 - accuracy: 0.9995 - val_loss: 0.9103 - val_accuracy: 0.8125\n","Epoch 81/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0077 - accuracy: 0.9995 - val_loss: 0.9145 - val_accuracy: 0.8157\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.8945 - val_accuracy: 0.8136\n","Epoch 83/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.9070 - val_accuracy: 0.8157\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0079 - accuracy: 0.9995 - val_loss: 0.9515 - val_accuracy: 0.8114\n","Epoch 85/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0085 - accuracy: 0.9992 - val_loss: 0.8847 - val_accuracy: 0.8168\n","Epoch 86/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0077 - accuracy: 0.9995 - val_loss: 0.9263 - val_accuracy: 0.8157\n","Epoch 87/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0075 - accuracy: 0.9995 - val_loss: 0.9184 - val_accuracy: 0.8147\n","Epoch 88/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0076 - accuracy: 0.9995 - val_loss: 0.9220 - val_accuracy: 0.8136\n","Epoch 89/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0077 - accuracy: 0.9995 - val_loss: 0.9272 - val_accuracy: 0.8200\n","Epoch 90/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0078 - accuracy: 0.9992 - val_loss: 0.9141 - val_accuracy: 0.8114\n","Epoch 91/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0077 - accuracy: 0.9995 - val_loss: 0.9875 - val_accuracy: 0.8157\n","Epoch 92/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0077 - accuracy: 0.9995 - val_loss: 0.9414 - val_accuracy: 0.8147\n","Epoch 93/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0078 - accuracy: 0.9995 - val_loss: 0.9460 - val_accuracy: 0.8190\n","Epoch 94/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0075 - accuracy: 0.9995 - val_loss: 0.9696 - val_accuracy: 0.8168\n","Epoch 95/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0083 - accuracy: 0.9992 - val_loss: 1.0249 - val_accuracy: 0.8071\n","Epoch 96/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0091 - accuracy: 0.9987 - val_loss: 1.0369 - val_accuracy: 0.8050\n","Epoch 97/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0538 - accuracy: 0.9860 - val_loss: 0.8066 - val_accuracy: 0.7468\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1179 - accuracy: 0.9542 - val_loss: 0.7759 - val_accuracy: 0.7522\n","Epoch 99/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0809 - accuracy: 0.9733 - val_loss: 0.7599 - val_accuracy: 0.7672\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0530 - accuracy: 0.9820 - val_loss: 0.8387 - val_accuracy: 0.7953\n","{'loss': [0.06437136232852936, 0.030663754791021347, 0.024323446676135063, 0.015734074637293816, 0.011459100991487503, 0.01224972028285265, 0.014349212870001793, 0.01466136984527111, 0.042973827570676804, 0.06854352355003357, 0.04433002695441246, 0.039098236709833145, 0.025181155651807785, 0.024264659732580185, 0.03530409559607506, 0.04808255285024643, 0.019633769989013672, 0.014594177715480328, 0.01573794335126877, 0.01723361201584339, 0.02429920621216297, 0.01815163530409336, 0.015595703385770321, 0.03967435657978058, 0.034306176006793976, 0.04113071411848068, 0.03409412130713463, 0.023587556555867195, 0.024624710902571678, 0.02410249412059784, 0.02700459398329258, 0.034207072108983994, 0.016689348965883255, 0.017514986917376518, 0.030652480199933052, 0.026927661150693893, 0.022303801029920578, 0.024350766092538834, 0.014365273527801037, 0.014137549325823784, 0.021530091762542725, 0.031163493171334267, 0.01834585890173912, 0.02732454240322113, 0.015650058165192604, 0.01758699305355549, 0.013503465801477432, 0.015292773954570293, 0.02054390124976635, 0.02064673975110054, 0.035321686416864395, 0.04470491409301758, 0.015023164451122284, 0.010496947914361954, 0.011551025323569775, 0.011069225147366524, 0.009394586086273193, 0.009317231364548206, 0.011823932640254498, 0.010045540519058704, 0.010038835927844048, 0.00959684606641531, 0.008481412194669247, 0.009032678790390491, 0.008901135064661503, 0.008142906241118908, 0.008279459550976753, 0.008223656564950943, 0.008541525341570377, 0.008229153230786324, 0.009124784730374813, 0.008634189143776894, 0.008188432082533836, 0.008936501108109951, 0.007904202677309513, 0.008015146479010582, 0.007948757149279118, 0.007654016371816397, 0.008104566484689713, 0.007779412902891636, 0.007677353452891111, 0.008219188079237938, 0.008180172182619572, 0.007913080975413322, 0.008469650521874428, 0.007655429653823376, 0.0075455293990671635, 0.007601854391396046, 0.007672085426747799, 0.00775834871456027, 0.007730598095804453, 0.007679300382733345, 0.007757301442325115, 0.007532042451202869, 0.008315778337419033, 0.00914644543081522, 0.05381806194782257, 0.11789888143539429, 0.08089031279087067, 0.05299072340130806], 'accuracy': [0.9816810488700867, 0.9924569129943848, 0.9940732717514038, 0.9981142282485962, 0.998652994632721, 0.998652994632721, 0.9975754022598267, 0.9981142282485962, 0.9884159564971924, 0.9797952771186829, 0.9854525923728943, 0.9897629022598267, 0.9943426847457886, 0.9940732717514038, 0.9916487336158752, 0.9881465435028076, 0.9956896305084229, 0.9978448152542114, 0.9975754022598267, 0.9964978694915771, 0.9951508641242981, 0.9959590435028076, 0.9975754022598267, 0.9870689511299133, 0.9900323152542114, 0.9884159564971924, 0.9919180870056152, 0.9932650923728943, 0.9927262663841248, 0.9940732717514038, 0.9940732717514038, 0.9916487336158752, 0.9973060488700867, 0.9956896305084229, 0.9916487336158752, 0.9929956793785095, 0.9940732717514038, 0.9924569129943848, 0.9970366358757019, 0.9981142282485962, 0.9943426847457886, 0.9919180870056152, 0.9956896305084229, 0.993803858757019, 0.9975754022598267, 0.9967672228813171, 0.9981142282485962, 0.9973060488700867, 0.9956896305084229, 0.9940732717514038, 0.990571141242981, 0.9854525923728943, 0.9970366358757019, 0.998383641242981, 0.9989224076271057, 0.998652994632721, 0.9989224076271057, 0.9991918206214905, 0.9978448152542114, 0.9989224076271057, 0.9989224076271057, 0.9991918206214905, 0.9994612336158752, 0.9991918206214905, 0.998652994632721, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9989224076271057, 0.9994612336158752, 0.998383641242981, 0.9994612336158752, 0.9994612336158752, 0.9991918206214905, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9991918206214905, 0.9994612336158752, 0.9994612336158752, 0.9991918206214905, 0.9991918206214905, 0.9994612336158752, 0.9991918206214905, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9991918206214905, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9991918206214905, 0.998652994632721, 0.985991358757019, 0.9542025923728943, 0.9733297228813171, 0.9819504022598267], 'val_loss': [0.6806831955909729, 0.6862248778343201, 0.679117739200592, 0.6747434735298157, 0.6879820823669434, 0.642509937286377, 0.6518848538398743, 0.6090809106826782, 0.6054089069366455, 0.627760112285614, 0.6011543273925781, 0.6975745558738708, 0.7629911303520203, 0.660792887210846, 0.6675784587860107, 0.8587636351585388, 1.1297481060028076, 1.2635210752487183, 1.2610498666763306, 0.850151538848877, 0.8400781750679016, 1.040377140045166, 0.7304840683937073, 0.9228397607803345, 0.9773943424224854, 0.6506608128547668, 0.8916767835617065, 0.7231279015541077, 0.8088191747665405, 0.8568496108055115, 0.8754741549491882, 0.6925837397575378, 0.8175240159034729, 0.8444682955741882, 0.9346030950546265, 0.7066856622695923, 0.7649037837982178, 0.7510477304458618, 0.924053430557251, 0.8649834990501404, 0.9304568767547607, 0.786038875579834, 0.8802797794342041, 0.8179051876068115, 0.8805518746376038, 0.8763266801834106, 0.9579078555107117, 1.0177074670791626, 1.0218112468719482, 1.221512794494629, 0.8614551424980164, 0.8328022956848145, 0.9089556932449341, 1.0354288816452026, 0.9027143120765686, 0.90455162525177, 0.9637113809585571, 0.919569194316864, 0.8488955497741699, 0.9545589089393616, 0.8978810906410217, 0.9614571928977966, 0.9072907567024231, 0.8967713117599487, 0.89960116147995, 0.90229332447052, 0.9024798274040222, 0.8974043130874634, 0.9204604625701904, 0.925898015499115, 0.874836802482605, 0.9324125647544861, 0.908417284488678, 0.896175742149353, 0.8843656182289124, 0.8997441530227661, 0.8978772163391113, 0.9127487540245056, 0.8951517939567566, 0.9102646112442017, 0.9145492911338806, 0.8944682478904724, 0.9070265293121338, 0.9515202045440674, 0.8847075700759888, 0.9263301491737366, 0.918424129486084, 0.9219735264778137, 0.9272492527961731, 0.9141069054603577, 0.9875494837760925, 0.9413749575614929, 0.9459871053695679, 0.9696380496025085, 1.0249439477920532, 1.0369195938110352, 0.8065997362136841, 0.7759437561035156, 0.7599443793296814, 0.8386524319648743], 'val_accuracy': [0.5700430870056152, 0.5463362336158752, 0.5635775923728943, 0.5851293206214905, 0.5840517282485962, 0.6336206793785095, 0.6303879022598267, 0.6605603694915771, 0.6691810488700867, 0.65625, 0.6864224076271057, 0.6443965435028076, 0.6616379022598267, 0.7068965435028076, 0.7209051847457886, 0.6594827771186829, 0.662715494632721, 0.6756465435028076, 0.6885775923728943, 0.7424569129943848, 0.7790948152542114, 0.7553879022598267, 0.826508641242981, 0.7575430870056152, 0.7532327771186829, 0.818965494632721, 0.7769396305084229, 0.8329741358757019, 0.8168103694915771, 0.8135775923728943, 0.8125, 0.8286637663841248, 0.8243534564971924, 0.8318965435028076, 0.7823275923728943, 0.829741358757019, 0.8221982717514038, 0.8243534564971924, 0.8103448152542114, 0.8340517282485962, 0.8028017282485962, 0.8135775923728943, 0.8318965435028076, 0.8038793206214905, 0.806034505367279, 0.8168103694915771, 0.8092672228813171, 0.7995689511299133, 0.7931034564971924, 0.7693965435028076, 0.8071120977401733, 0.7931034564971924, 0.7898706793785095, 0.8028017282485962, 0.8232758641242981, 0.8049569129943848, 0.806034505367279, 0.8168103694915771, 0.8254310488700867, 0.8049569129943848, 0.8168103694915771, 0.8114224076271057, 0.8168103694915771, 0.8146551847457886, 0.8157327771186829, 0.8125, 0.8168103694915771, 0.8178879022598267, 0.8157327771186829, 0.8114224076271057, 0.8211206793785095, 0.8178879022598267, 0.8157327771186829, 0.8114224076271057, 0.818965494632721, 0.8157327771186829, 0.8200430870056152, 0.8135775923728943, 0.8157327771186829, 0.8125, 0.8157327771186829, 0.8135775923728943, 0.8157327771186829, 0.8114224076271057, 0.8168103694915771, 0.8157327771186829, 0.8146551847457886, 0.8135775923728943, 0.8200430870056152, 0.8114224076271057, 0.8157327771186829, 0.8146551847457886, 0.818965494632721, 0.8168103694915771, 0.8071120977401733, 0.8049569129943848, 0.7467672228813171, 0.7521551847457886, 0.767241358757019, 0.795258641242981]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.0663 - accuracy: 0.9793"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 92ms/step - loss: 0.0660 - accuracy: 0.9796 - val_loss: 0.6944 - val_accuracy: 0.5102\n","Epoch 2/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.0346 - accuracy: 0.9892 - val_loss: 0.6763 - val_accuracy: 0.5701\n","Epoch 3/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0287 - accuracy: 0.9918 - val_loss: 0.7032 - val_accuracy: 0.5283\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0278 - accuracy: 0.9929 - val_loss: 0.7028 - val_accuracy: 0.5419\n","Epoch 5/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.0292 - accuracy: 0.9926 - val_loss: 0.6452 - val_accuracy: 0.6346\n","Epoch 6/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0299 - accuracy: 0.9921 - val_loss: 0.6490 - val_accuracy: 0.6097\n","Epoch 7/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0252 - accuracy: 0.9938 - val_loss: 0.6874 - val_accuracy: 0.6063\n","Epoch 8/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0145 - accuracy: 0.9983 - val_loss: 0.8178 - val_accuracy: 0.5882\n","Epoch 9/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0231 - accuracy: 0.9941 - val_loss: 0.8180 - val_accuracy: 0.5973\n","Epoch 10/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0326 - accuracy: 0.9918 - val_loss: 0.6911 - val_accuracy: 0.6459\n","Epoch 11/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0306 - accuracy: 0.9924 - val_loss: 0.6356 - val_accuracy: 0.6652\n","Epoch 12/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0203 - accuracy: 0.9958 - val_loss: 0.6748 - val_accuracy: 0.6776\n","Epoch 13/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0159 - accuracy: 0.9977 - val_loss: 0.6803 - val_accuracy: 0.6889\n","Epoch 14/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0349 - accuracy: 0.9909 - val_loss: 0.6785 - val_accuracy: 0.6923\n","Epoch 15/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0972 - accuracy: 0.9669 - val_loss: 0.5844 - val_accuracy: 0.7025\n","Epoch 16/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0332 - accuracy: 0.9915 - val_loss: 0.6180 - val_accuracy: 0.7398\n","Epoch 17/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0166 - accuracy: 0.9972 - val_loss: 0.6615 - val_accuracy: 0.7398\n","Epoch 18/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0237 - accuracy: 0.9943 - val_loss: 0.7317 - val_accuracy: 0.7364\n","Epoch 19/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0330 - accuracy: 0.9901 - val_loss: 0.6144 - val_accuracy: 0.7794\n","Epoch 20/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0268 - accuracy: 0.9926 - val_loss: 0.8689 - val_accuracy: 0.7149\n","Epoch 21/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0273 - accuracy: 0.9926 - val_loss: 0.8354 - val_accuracy: 0.7455\n","Epoch 22/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0143 - accuracy: 0.9975 - val_loss: 0.7303 - val_accuracy: 0.8020\n","Epoch 23/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0119 - accuracy: 0.9989 - val_loss: 0.8101 - val_accuracy: 0.7873\n","Epoch 24/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.0121 - accuracy: 0.9980 - val_loss: 0.6992 - val_accuracy: 0.8462\n","Epoch 25/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0116 - accuracy: 0.9992 - val_loss: 0.6741 - val_accuracy: 0.8439\n","Epoch 26/100\n","28/28 [==============================] - 1s 38ms/step - loss: 0.0115 - accuracy: 0.9986 - val_loss: 0.6315 - val_accuracy: 0.8552\n","Epoch 27/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0096 - accuracy: 0.9997 - val_loss: 0.6132 - val_accuracy: 0.8541\n","Epoch 28/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0110 - accuracy: 0.9989 - val_loss: 0.6006 - val_accuracy: 0.8654\n","Epoch 29/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0111 - accuracy: 0.9980 - val_loss: 0.6349 - val_accuracy: 0.8552\n","Epoch 30/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0104 - accuracy: 0.9992 - val_loss: 0.6401 - val_accuracy: 0.8676\n","Epoch 31/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0125 - accuracy: 0.9980 - val_loss: 0.6633 - val_accuracy: 0.8541\n","Epoch 32/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0510 - accuracy: 0.9859 - val_loss: 0.6664 - val_accuracy: 0.8088\n","Epoch 33/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0346 - accuracy: 0.9912 - val_loss: 0.7617 - val_accuracy: 0.8145\n","Epoch 34/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0256 - accuracy: 0.9924 - val_loss: 0.7177 - val_accuracy: 0.8235\n","Epoch 35/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0260 - accuracy: 0.9929 - val_loss: 0.8478 - val_accuracy: 0.8122\n","Epoch 36/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0351 - accuracy: 0.9909 - val_loss: 0.6911 - val_accuracy: 0.8247\n","Epoch 37/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0301 - accuracy: 0.9929 - val_loss: 0.7479 - val_accuracy: 0.8088\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0443 - accuracy: 0.9878 - val_loss: 0.6439 - val_accuracy: 0.8314\n","Epoch 39/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0343 - accuracy: 0.9912 - val_loss: 0.7825 - val_accuracy: 0.8077\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0258 - accuracy: 0.9932 - val_loss: 0.6887 - val_accuracy: 0.8405\n","Epoch 41/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0645 - accuracy: 0.9762 - val_loss: 0.6517 - val_accuracy: 0.8179\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0289 - accuracy: 0.9924 - val_loss: 0.7214 - val_accuracy: 0.8303\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0155 - accuracy: 0.9975 - val_loss: 0.7662 - val_accuracy: 0.8269\n","Epoch 44/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0142 - accuracy: 0.9975 - val_loss: 0.9022 - val_accuracy: 0.8269\n","Epoch 45/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0214 - accuracy: 0.9960 - val_loss: 0.9447 - val_accuracy: 0.8009\n","Epoch 46/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0313 - accuracy: 0.9915 - val_loss: 0.6904 - val_accuracy: 0.8382\n","Epoch 47/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0149 - accuracy: 0.9972 - val_loss: 0.8112 - val_accuracy: 0.8314\n","Epoch 48/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0165 - accuracy: 0.9977 - val_loss: 0.8282 - val_accuracy: 0.8382\n","Epoch 49/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0224 - accuracy: 0.9969 - val_loss: 0.7634 - val_accuracy: 0.8281\n","Epoch 50/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0203 - accuracy: 0.9958 - val_loss: 0.6777 - val_accuracy: 0.8314\n","Epoch 51/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0167 - accuracy: 0.9960 - val_loss: 0.8047 - val_accuracy: 0.8258\n","Epoch 52/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0261 - accuracy: 0.9929 - val_loss: 0.8822 - val_accuracy: 0.8167\n","Epoch 53/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0319 - accuracy: 0.9918 - val_loss: 0.7110 - val_accuracy: 0.8269\n","Epoch 54/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0194 - accuracy: 0.9955 - val_loss: 0.8351 - val_accuracy: 0.8213\n","Epoch 55/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0143 - accuracy: 0.9983 - val_loss: 0.8559 - val_accuracy: 0.8213\n","Epoch 56/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0150 - accuracy: 0.9975 - val_loss: 0.9247 - val_accuracy: 0.8337\n","Epoch 57/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.9892 - val_accuracy: 0.8054\n","Epoch 58/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0395 - accuracy: 0.9873 - val_loss: 0.7945 - val_accuracy: 0.7941\n","Epoch 59/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0271 - accuracy: 0.9924 - val_loss: 0.7769 - val_accuracy: 0.8224\n","Epoch 60/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0184 - accuracy: 0.9960 - val_loss: 0.9314 - val_accuracy: 0.7964\n","Epoch 61/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0140 - accuracy: 0.9983 - val_loss: 0.8703 - val_accuracy: 0.8247\n","Epoch 62/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0191 - accuracy: 0.9966 - val_loss: 0.9478 - val_accuracy: 0.7998\n","Epoch 63/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0131 - accuracy: 0.9986 - val_loss: 0.8620 - val_accuracy: 0.8269\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.8509 - val_accuracy: 0.8235\n","Epoch 65/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0320 - accuracy: 0.9909 - val_loss: 0.9612 - val_accuracy: 0.7998\n","Epoch 66/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0265 - accuracy: 0.9924 - val_loss: 0.7582 - val_accuracy: 0.8167\n","Epoch 67/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0204 - accuracy: 0.9946 - val_loss: 0.8641 - val_accuracy: 0.8122\n","Epoch 68/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.9020 - val_accuracy: 0.8111\n","Epoch 69/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0162 - accuracy: 0.9960 - val_loss: 1.1065 - val_accuracy: 0.7805\n","Epoch 70/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0195 - accuracy: 0.9949 - val_loss: 1.0102 - val_accuracy: 0.7907\n","Epoch 71/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0154 - accuracy: 0.9963 - val_loss: 0.9247 - val_accuracy: 0.7952\n","Epoch 72/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 1.0995 - val_accuracy: 0.7805\n","Epoch 73/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0152 - accuracy: 0.9966 - val_loss: 0.9345 - val_accuracy: 0.8201\n","Epoch 74/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0117 - accuracy: 0.9980 - val_loss: 0.9497 - val_accuracy: 0.8167\n","Epoch 75/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0098 - accuracy: 0.9989 - val_loss: 0.8695 - val_accuracy: 0.8371\n","Epoch 76/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0089 - accuracy: 0.9992 - val_loss: 0.9021 - val_accuracy: 0.8179\n","Epoch 77/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0088 - accuracy: 0.9994 - val_loss: 0.8753 - val_accuracy: 0.8337\n","Epoch 78/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0110 - accuracy: 0.9989 - val_loss: 0.8545 - val_accuracy: 0.8314\n","Epoch 79/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 1.0197 - val_accuracy: 0.7998\n","Epoch 80/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0135 - accuracy: 0.9977 - val_loss: 0.8396 - val_accuracy: 0.8269\n","Epoch 81/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0097 - accuracy: 0.9992 - val_loss: 0.8873 - val_accuracy: 0.8167\n","Epoch 82/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0100 - accuracy: 0.9986 - val_loss: 0.8581 - val_accuracy: 0.8258\n","Epoch 83/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0085 - accuracy: 0.9992 - val_loss: 0.8343 - val_accuracy: 0.8281\n","Epoch 84/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0084 - accuracy: 0.9994 - val_loss: 0.8672 - val_accuracy: 0.8292\n","Epoch 85/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0087 - accuracy: 0.9989 - val_loss: 0.7927 - val_accuracy: 0.8348\n","Epoch 86/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0079 - accuracy: 0.9992 - val_loss: 0.7897 - val_accuracy: 0.8326\n","Epoch 87/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0078 - accuracy: 0.9992 - val_loss: 0.7927 - val_accuracy: 0.8326\n","Epoch 88/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0080 - accuracy: 0.9992 - val_loss: 0.7905 - val_accuracy: 0.8314\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0079 - accuracy: 0.9994 - val_loss: 0.8606 - val_accuracy: 0.8303\n","Epoch 90/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0079 - accuracy: 0.9992 - val_loss: 0.7866 - val_accuracy: 0.8326\n","Epoch 91/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0076 - accuracy: 0.9994 - val_loss: 0.8088 - val_accuracy: 0.8292\n","Epoch 92/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0077 - accuracy: 0.9997 - val_loss: 0.7810 - val_accuracy: 0.8382\n","Epoch 93/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0077 - accuracy: 0.9994 - val_loss: 0.8932 - val_accuracy: 0.8235\n","Epoch 94/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0081 - accuracy: 0.9994 - val_loss: 0.7951 - val_accuracy: 0.8394\n","Epoch 95/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0075 - accuracy: 0.9994 - val_loss: 0.7991 - val_accuracy: 0.8337\n","Epoch 96/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0079 - accuracy: 0.9989 - val_loss: 0.7920 - val_accuracy: 0.8394\n","Epoch 97/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0082 - accuracy: 0.9986 - val_loss: 0.7860 - val_accuracy: 0.8258\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0080 - accuracy: 0.9992 - val_loss: 0.7818 - val_accuracy: 0.8326\n","Epoch 99/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0077 - accuracy: 0.9992 - val_loss: 0.7900 - val_accuracy: 0.8405\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0084 - accuracy: 0.9994 - val_loss: 0.9778 - val_accuracy: 0.8077\n","{'loss': [0.06596953421831131, 0.03460439667105675, 0.028679611161351204, 0.02780245617032051, 0.02924896962940693, 0.029911478981375694, 0.025247035548090935, 0.014542097225785255, 0.023075245320796967, 0.032555125653743744, 0.030596192926168442, 0.02034863829612732, 0.015851004049181938, 0.034861259162425995, 0.09716616570949554, 0.03321335092186928, 0.01655861735343933, 0.023682063445448875, 0.033010635524988174, 0.026825709268450737, 0.0273125097155571, 0.014280950650572777, 0.011854330077767372, 0.012054184451699257, 0.011603659018874168, 0.011548515409231186, 0.009608492255210876, 0.011048275046050549, 0.011076414957642555, 0.010380913503468037, 0.012516217306256294, 0.051032595336437225, 0.0346127524971962, 0.025593824684619904, 0.026049833744764328, 0.035139452666044235, 0.030135683715343475, 0.044275086373090744, 0.03433714807033539, 0.02580569125711918, 0.06447169184684753, 0.028936099261045456, 0.015456488355994225, 0.014193926937878132, 0.021350516006350517, 0.031285740435123444, 0.014916755259037018, 0.01653551682829857, 0.02242218889296055, 0.020311977714300156, 0.01669551245868206, 0.026084942743182182, 0.03193681314587593, 0.019406739622354507, 0.014305425807833672, 0.014991157688200474, 0.01825706474483013, 0.039512749761343, 0.027088705450296402, 0.01843300275504589, 0.01403833832591772, 0.019114922732114792, 0.013087507337331772, 0.014980083331465721, 0.031957317143678665, 0.026490360498428345, 0.020375946536660194, 0.015110150910913944, 0.016193613409996033, 0.019490743055939674, 0.015443320386111736, 0.014045448042452335, 0.01515053678303957, 0.01170422974973917, 0.009824013337492943, 0.008949855342507362, 0.00878816656768322, 0.01095166988670826, 0.015091569162905216, 0.013472413644194603, 0.009707956574857235, 0.010035272687673569, 0.008497976697981358, 0.008385274559259415, 0.008657376281917095, 0.00786819402128458, 0.007780082523822784, 0.00801095925271511, 0.007866841740906239, 0.00792261864989996, 0.007634538225829601, 0.007692533079534769, 0.007717919070273638, 0.008115596137940884, 0.007501846179366112, 0.007883143611252308, 0.008195767179131508, 0.007960218004882336, 0.007728936150670052, 0.008390063419938087], 'accuracy': [0.979626476764679, 0.9892473220825195, 0.9917939901351929, 0.9929258823394775, 0.992642879486084, 0.9920769929885864, 0.9937747716903687, 0.9983022212982178, 0.9940577149391174, 0.9917939901351929, 0.9923599362373352, 0.9957554936408997, 0.9977362751960754, 0.9909451007843018, 0.9668930172920227, 0.9915110468864441, 0.9971703290939331, 0.994340717792511, 0.9900962114334106, 0.992642879486084, 0.992642879486084, 0.9974533319473267, 0.9988681674003601, 0.9980192184448242, 0.9991511106491089, 0.9985851645469666, 0.9997170567512512, 0.9988681674003601, 0.9980192184448242, 0.9991511106491089, 0.9980192184448242, 0.9858517050743103, 0.9912280440330505, 0.9923599362373352, 0.9929258823394775, 0.9909451007843018, 0.9929258823394775, 0.9878324866294861, 0.9912280440330505, 0.9932088255882263, 0.9762309193611145, 0.9923599362373352, 0.9974533319473267, 0.9974533319473267, 0.9960384964942932, 0.9915110468864441, 0.9971703290939331, 0.9977362751960754, 0.9968873858451843, 0.9957554936408997, 0.9960384964942932, 0.9929258823394775, 0.9917939901351929, 0.9954725503921509, 0.9983022212982178, 0.9974533319473267, 0.9946236610412598, 0.9872665405273438, 0.9923599362373352, 0.9960384964942932, 0.9983022212982178, 0.9966044425964355, 0.9985851645469666, 0.9966044425964355, 0.9909451007843018, 0.9923599362373352, 0.9946236610412598, 0.9968873858451843, 0.9960384964942932, 0.9949066042900085, 0.996321439743042, 0.9966044425964355, 0.9966044425964355, 0.9980192184448242, 0.9988681674003601, 0.9991511106491089, 0.9994340538978577, 0.9988681674003601, 0.9968873858451843, 0.9977362751960754, 0.9991511106491089, 0.9985851645469666, 0.9991511106491089, 0.9994340538978577, 0.9988681674003601, 0.9991511106491089, 0.9991511106491089, 0.9991511106491089, 0.9994340538978577, 0.9991511106491089, 0.9994340538978577, 0.9997170567512512, 0.9994340538978577, 0.9994340538978577, 0.9994340538978577, 0.9988681674003601, 0.9985851645469666, 0.9991511106491089, 0.9991511106491089, 0.9994340538978577], 'val_loss': [0.6943734884262085, 0.6762932538986206, 0.7031728625297546, 0.7027930617332458, 0.6451665163040161, 0.6489895582199097, 0.6873917579650879, 0.8177821040153503, 0.8179877996444702, 0.6911095380783081, 0.6355952024459839, 0.6748462319374084, 0.6803391575813293, 0.6784632802009583, 0.584419846534729, 0.6180005073547363, 0.6614971160888672, 0.7317203283309937, 0.6143667101860046, 0.8689061403274536, 0.8354322910308838, 0.7302924394607544, 0.8101287484169006, 0.6991584300994873, 0.6740634441375732, 0.6315412521362305, 0.6132373213768005, 0.600604772567749, 0.634880542755127, 0.6401253938674927, 0.6632725596427917, 0.6664209365844727, 0.7616685628890991, 0.7177075147628784, 0.8477635979652405, 0.6911171078681946, 0.7478806972503662, 0.6439084410667419, 0.7824889421463013, 0.6887445449829102, 0.6517398953437805, 0.7213868498802185, 0.7661618590354919, 0.9022052884101868, 0.9447463154792786, 0.6903557181358337, 0.8112117648124695, 0.8281925320625305, 0.7633610963821411, 0.6776903867721558, 0.8046988248825073, 0.8822475671768188, 0.7110022902488708, 0.8350656032562256, 0.8558869957923889, 0.924652099609375, 0.9892107248306274, 0.7944543957710266, 0.7768710255622864, 0.9314358830451965, 0.8703175783157349, 0.9478165507316589, 0.8620449900627136, 0.8509307503700256, 0.9611717462539673, 0.7582274675369263, 0.8641369342803955, 0.9019958972930908, 1.1065478324890137, 1.010240077972412, 0.9246954321861267, 1.0994906425476074, 0.9344538450241089, 0.9496719837188721, 0.8695210814476013, 0.9020920991897583, 0.8752658367156982, 0.8545321226119995, 1.019695520401001, 0.8396074175834656, 0.8873174786567688, 0.8581006526947021, 0.8342839479446411, 0.8672496676445007, 0.7926693558692932, 0.7896912097930908, 0.792712926864624, 0.7904637455940247, 0.8606221675872803, 0.786629855632782, 0.8087747693061829, 0.7810243368148804, 0.8932458758354187, 0.7951149344444275, 0.7990947961807251, 0.7920374274253845, 0.785968005657196, 0.7818219661712646, 0.790009081363678, 0.9777873754501343], 'val_accuracy': [0.5101810097694397, 0.570135772228241, 0.5282805562019348, 0.5418552160263062, 0.6346153616905212, 0.6097285151481628, 0.6063348650932312, 0.5882353186607361, 0.5972850918769836, 0.6459276080131531, 0.6651583909988403, 0.6776018142700195, 0.6889140009880066, 0.692307710647583, 0.7024886608123779, 0.7398189902305603, 0.7398189902305603, 0.7364253401756287, 0.779411792755127, 0.7149321436882019, 0.7454751133918762, 0.8020362257957458, 0.7873303294181824, 0.8461538553237915, 0.8438913822174072, 0.8552036285400391, 0.8540723919868469, 0.8653846383094788, 0.8552036285400391, 0.8676470518112183, 0.8540723919868469, 0.8088235259056091, 0.814479649066925, 0.8235294222831726, 0.8122171759605408, 0.8246606588363647, 0.8088235259056091, 0.831447958946228, 0.807692289352417, 0.8404977321624756, 0.8178732991218567, 0.8303167223930359, 0.8269230723381042, 0.8269230723381042, 0.8009049892425537, 0.8382353186607361, 0.831447958946228, 0.8382353186607361, 0.8280543088912964, 0.831447958946228, 0.8257918357849121, 0.8167420625686646, 0.8269230723381042, 0.8212669491767883, 0.8212669491767883, 0.8337104320526123, 0.8054298758506775, 0.7941176295280457, 0.8223981857299805, 0.7963801026344299, 0.8246606588363647, 0.7997737526893616, 0.8269230723381042, 0.8235294222831726, 0.7997737526893616, 0.8167420625686646, 0.8122171759605408, 0.8110859990119934, 0.7805429697036743, 0.790723979473114, 0.7952488660812378, 0.7805429697036743, 0.820135772228241, 0.8167420625686646, 0.837104082107544, 0.8178732991218567, 0.8337104320526123, 0.831447958946228, 0.7997737526893616, 0.8269230723381042, 0.8167420625686646, 0.8257918357849121, 0.8280543088912964, 0.8291855454444885, 0.8348416090011597, 0.8325791954994202, 0.8325791954994202, 0.831447958946228, 0.8303167223930359, 0.8325791954994202, 0.8291855454444885, 0.8382353186607361, 0.8235294222831726, 0.8393664956092834, 0.8337104320526123, 0.8393664956092834, 0.8257918357849121, 0.8325791954994202, 0.8404977321624756, 0.807692289352417]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.0892 - accuracy: 0.9721"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 8s 59ms/step - loss: 0.0871 - accuracy: 0.9731 - val_loss: 0.6892 - val_accuracy: 0.5300\n","Epoch 2/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0696 - accuracy: 0.9773 - val_loss: 0.6836 - val_accuracy: 0.5393\n","Epoch 3/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0445 - accuracy: 0.9891 - val_loss: 0.6917 - val_accuracy: 0.5362\n","Epoch 4/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0229 - accuracy: 0.9956 - val_loss: 0.6728 - val_accuracy: 0.5785\n","Epoch 5/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0216 - accuracy: 0.9956 - val_loss: 0.6763 - val_accuracy: 0.5857\n","Epoch 6/100\n","31/31 [==============================] - 1s 37ms/step - loss: 0.0435 - accuracy: 0.9860 - val_loss: 0.6415 - val_accuracy: 0.6426\n","Epoch 7/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0405 - accuracy: 0.9886 - val_loss: 0.6399 - val_accuracy: 0.6291\n","Epoch 8/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0202 - accuracy: 0.9959 - val_loss: 0.6438 - val_accuracy: 0.6333\n","Epoch 9/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.0224 - accuracy: 0.9964 - val_loss: 0.6323 - val_accuracy: 0.6550\n","Epoch 10/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.0255 - accuracy: 0.9938 - val_loss: 0.6294 - val_accuracy: 0.6839\n","Epoch 11/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0272 - accuracy: 0.9928 - val_loss: 0.6805 - val_accuracy: 0.6622\n","Epoch 12/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0520 - accuracy: 0.9819 - val_loss: 0.6083 - val_accuracy: 0.6942\n","Epoch 13/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0432 - accuracy: 0.9868 - val_loss: 0.7039 - val_accuracy: 0.6612\n","Epoch 14/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0196 - accuracy: 0.9961 - val_loss: 0.7263 - val_accuracy: 0.6901\n","Epoch 15/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0248 - accuracy: 0.9941 - val_loss: 0.7925 - val_accuracy: 0.7118\n","Epoch 16/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0287 - accuracy: 0.9933 - val_loss: 0.9764 - val_accuracy: 0.6829\n","Epoch 17/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 0.7265 - val_accuracy: 0.7531\n","Epoch 18/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0195 - accuracy: 0.9961 - val_loss: 0.8315 - val_accuracy: 0.7448\n","Epoch 19/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0156 - accuracy: 0.9979 - val_loss: 0.9195 - val_accuracy: 0.7521\n","Epoch 20/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0153 - accuracy: 0.9974 - val_loss: 0.9600 - val_accuracy: 0.7696\n","Epoch 21/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0164 - accuracy: 0.9972 - val_loss: 0.9780 - val_accuracy: 0.7779\n","Epoch 22/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0396 - accuracy: 0.9879 - val_loss: 0.8398 - val_accuracy: 0.7614\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0389 - accuracy: 0.9891 - val_loss: 1.0550 - val_accuracy: 0.7500\n","Epoch 24/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0606 - accuracy: 0.9817 - val_loss: 0.9732 - val_accuracy: 0.7252\n","Epoch 25/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0407 - accuracy: 0.9884 - val_loss: 0.7281 - val_accuracy: 0.8130\n","Epoch 26/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.0230 - accuracy: 0.9930 - val_loss: 0.6833 - val_accuracy: 0.8316\n","Epoch 27/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.8033 - val_accuracy: 0.8202\n","Epoch 28/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9987 - val_loss: 0.7179 - val_accuracy: 0.8409\n","Epoch 29/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.0124 - accuracy: 0.9984 - val_loss: 0.7887 - val_accuracy: 0.8419\n","Epoch 30/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0097 - accuracy: 0.9995 - val_loss: 0.8099 - val_accuracy: 0.8337\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0150 - accuracy: 0.9974 - val_loss: 0.7940 - val_accuracy: 0.8368\n","Epoch 32/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0119 - accuracy: 0.9982 - val_loss: 0.8453 - val_accuracy: 0.8378\n","Epoch 33/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0122 - accuracy: 0.9984 - val_loss: 1.0052 - val_accuracy: 0.8120\n","Epoch 34/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0133 - accuracy: 0.9984 - val_loss: 0.9291 - val_accuracy: 0.8192\n","Epoch 35/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0451 - accuracy: 0.9871 - val_loss: 0.7733 - val_accuracy: 0.8017\n","Epoch 36/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0381 - accuracy: 0.9873 - val_loss: 0.7207 - val_accuracy: 0.8244\n","Epoch 37/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0276 - accuracy: 0.9930 - val_loss: 0.7988 - val_accuracy: 0.8151\n","Epoch 38/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0379 - accuracy: 0.9868 - val_loss: 0.6919 - val_accuracy: 0.8285\n","Epoch 39/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0404 - accuracy: 0.9889 - val_loss: 0.8084 - val_accuracy: 0.8006\n","Epoch 40/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0418 - accuracy: 0.9884 - val_loss: 0.7416 - val_accuracy: 0.7996\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0397 - accuracy: 0.9884 - val_loss: 0.8317 - val_accuracy: 0.7841\n","Epoch 42/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0200 - accuracy: 0.9948 - val_loss: 0.9324 - val_accuracy: 0.7934\n","Epoch 43/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0207 - accuracy: 0.9961 - val_loss: 0.8715 - val_accuracy: 0.8058\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0377 - accuracy: 0.9904 - val_loss: 0.7992 - val_accuracy: 0.7831\n","Epoch 45/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0256 - accuracy: 0.9930 - val_loss: 0.7888 - val_accuracy: 0.8161\n","Epoch 46/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0176 - accuracy: 0.9974 - val_loss: 0.8768 - val_accuracy: 0.7944\n","Epoch 47/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0111 - accuracy: 0.9992 - val_loss: 0.8451 - val_accuracy: 0.8130\n","Epoch 48/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0097 - accuracy: 0.9990 - val_loss: 0.8241 - val_accuracy: 0.8110\n","Epoch 49/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0094 - accuracy: 0.9992 - val_loss: 0.8154 - val_accuracy: 0.8171\n","Epoch 50/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0089 - accuracy: 0.9995 - val_loss: 0.8164 - val_accuracy: 0.8171\n","Epoch 51/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0095 - accuracy: 0.9987 - val_loss: 0.7933 - val_accuracy: 0.8264\n","Epoch 52/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0091 - accuracy: 0.9995 - val_loss: 0.8007 - val_accuracy: 0.8202\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0089 - accuracy: 0.9995 - val_loss: 0.7936 - val_accuracy: 0.8213\n","Epoch 54/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0091 - accuracy: 0.9995 - val_loss: 0.8384 - val_accuracy: 0.8110\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0095 - accuracy: 0.9987 - val_loss: 0.8331 - val_accuracy: 0.8244\n","Epoch 56/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0100 - accuracy: 0.9990 - val_loss: 0.8209 - val_accuracy: 0.8182\n","Epoch 57/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0089 - accuracy: 0.9990 - val_loss: 0.7840 - val_accuracy: 0.8285\n","Epoch 58/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0085 - accuracy: 0.9995 - val_loss: 0.8085 - val_accuracy: 0.8244\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0085 - accuracy: 0.9995 - val_loss: 0.7994 - val_accuracy: 0.8254\n","Epoch 60/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0084 - accuracy: 0.9992 - val_loss: 0.7857 - val_accuracy: 0.8275\n","Epoch 61/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0083 - accuracy: 0.9992 - val_loss: 0.7973 - val_accuracy: 0.8337\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0084 - accuracy: 0.9992 - val_loss: 0.7888 - val_accuracy: 0.8347\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0091 - accuracy: 0.9992 - val_loss: 0.7773 - val_accuracy: 0.8316\n","Epoch 64/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0089 - accuracy: 0.9992 - val_loss: 0.7851 - val_accuracy: 0.8285\n","Epoch 65/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0081 - accuracy: 0.9995 - val_loss: 0.7908 - val_accuracy: 0.8316\n","Epoch 66/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0088 - accuracy: 0.9987 - val_loss: 0.7842 - val_accuracy: 0.8337\n","Epoch 67/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0085 - accuracy: 0.9995 - val_loss: 0.8043 - val_accuracy: 0.8264\n","Epoch 68/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0082 - accuracy: 0.9995 - val_loss: 0.7769 - val_accuracy: 0.8244\n","Epoch 69/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0087 - accuracy: 0.9992 - val_loss: 0.7861 - val_accuracy: 0.8285\n","Epoch 70/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0081 - accuracy: 0.9995 - val_loss: 0.7980 - val_accuracy: 0.8316\n","Epoch 71/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0082 - accuracy: 0.9995 - val_loss: 0.7785 - val_accuracy: 0.8264\n","Epoch 72/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.7830 - val_accuracy: 0.8316\n","Epoch 73/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.7902 - val_accuracy: 0.8244\n","Epoch 74/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0086 - accuracy: 0.9990 - val_loss: 0.7841 - val_accuracy: 0.8275\n","Epoch 75/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.8474 - val_accuracy: 0.8233\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0082 - accuracy: 0.9995 - val_loss: 0.8105 - val_accuracy: 0.8316\n","Epoch 77/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0080 - accuracy: 0.9995 - val_loss: 0.7997 - val_accuracy: 0.8264\n","Epoch 78/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0078 - accuracy: 0.9995 - val_loss: 0.7982 - val_accuracy: 0.8275\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0079 - accuracy: 0.9995 - val_loss: 0.7970 - val_accuracy: 0.8295\n","Epoch 80/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0076 - accuracy: 0.9995 - val_loss: 0.7947 - val_accuracy: 0.8275\n","Epoch 81/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.7968 - val_accuracy: 0.8316\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0082 - accuracy: 0.9995 - val_loss: 0.8775 - val_accuracy: 0.8233\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0082 - accuracy: 0.9987 - val_loss: 0.8970 - val_accuracy: 0.8110\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0085 - accuracy: 0.9995 - val_loss: 0.8201 - val_accuracy: 0.8409\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0080 - accuracy: 0.9995 - val_loss: 0.7922 - val_accuracy: 0.8295\n","Epoch 86/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0076 - accuracy: 0.9995 - val_loss: 0.7895 - val_accuracy: 0.8254\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0077 - accuracy: 0.9995 - val_loss: 0.7818 - val_accuracy: 0.8264\n","Epoch 88/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0078 - accuracy: 0.9995 - val_loss: 0.8243 - val_accuracy: 0.8326\n","Epoch 89/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0076 - accuracy: 0.9990 - val_loss: 0.8520 - val_accuracy: 0.8295\n","Epoch 90/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0111 - accuracy: 0.9984 - val_loss: 0.9280 - val_accuracy: 0.8079\n","Epoch 91/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0767 - accuracy: 0.9767 - val_loss: 0.9070 - val_accuracy: 0.6921\n","Epoch 92/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1648 - accuracy: 0.9398 - val_loss: 0.7584 - val_accuracy: 0.7500\n","Epoch 93/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0879 - accuracy: 0.9677 - val_loss: 0.7780 - val_accuracy: 0.8006\n","Epoch 94/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0371 - accuracy: 0.9889 - val_loss: 1.6011 - val_accuracy: 0.6787\n","Epoch 95/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0625 - accuracy: 0.9793 - val_loss: 0.7811 - val_accuracy: 0.7924\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0258 - accuracy: 0.9941 - val_loss: 0.9601 - val_accuracy: 0.7820\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0531 - accuracy: 0.9848 - val_loss: 0.8463 - val_accuracy: 0.7789\n","Epoch 98/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0741 - accuracy: 0.9747 - val_loss: 0.7127 - val_accuracy: 0.7758\n","Epoch 99/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0272 - accuracy: 0.9938 - val_loss: 1.0466 - val_accuracy: 0.7707\n","Epoch 100/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0201 - accuracy: 0.9953 - val_loss: 1.1393 - val_accuracy: 0.7645\n","{'loss': [0.08705678582191467, 0.06956370174884796, 0.044465433806180954, 0.02294098399579525, 0.02164556458592415, 0.04349492862820625, 0.040470708161592484, 0.02021009474992752, 0.022431157529354095, 0.02549959532916546, 0.027213703840970993, 0.05201757326722145, 0.04322395846247673, 0.01957201212644577, 0.02484968863427639, 0.0287236999720335, 0.02371499128639698, 0.019501036033034325, 0.015580960549414158, 0.015332008711993694, 0.016368389129638672, 0.03962458297610283, 0.038894884288311005, 0.06063087657094002, 0.040697131305933, 0.023048503324389458, 0.014575659297406673, 0.01268460787832737, 0.012358302250504494, 0.00970615353435278, 0.015020881779491901, 0.011864488944411278, 0.012201016768813133, 0.013312557712197304, 0.04514661058783531, 0.038070499897003174, 0.027576349675655365, 0.03789994865655899, 0.04040394723415375, 0.04183802381157875, 0.0397045724093914, 0.020006245002150536, 0.020663011819124222, 0.03766724094748497, 0.025604236871004105, 0.017574945464730263, 0.01105747651308775, 0.009668134152889252, 0.009423822164535522, 0.008896272629499435, 0.009529768489301205, 0.00908550526946783, 0.008867464028298855, 0.009116370230913162, 0.009458137676119804, 0.010036374442279339, 0.008922538720071316, 0.008453791961073875, 0.008511311374604702, 0.008418414741754532, 0.008331294171512127, 0.008415226824581623, 0.00910869613289833, 0.008879564702510834, 0.008117140270769596, 0.008788296952843666, 0.008504500612616539, 0.008203374221920967, 0.008730532601475716, 0.008096599020063877, 0.008202072232961655, 0.008139429613947868, 0.008187111467123032, 0.008552520535886288, 0.008142315782606602, 0.008155111223459244, 0.007959509268403053, 0.007801815401762724, 0.007887263782322407, 0.0076201846823096275, 0.008186526596546173, 0.00815171655267477, 0.008216322399675846, 0.008495614863932133, 0.008041382767260075, 0.007627119775861502, 0.0077051823027431965, 0.007845723070204258, 0.007619168609380722, 0.01108731422573328, 0.07674536108970642, 0.16476339101791382, 0.08793281763792038, 0.03709085285663605, 0.06253840774297714, 0.02577543631196022, 0.05305939540266991, 0.07406946271657944, 0.02717992104589939, 0.020130304619669914], 'accuracy': [0.9731265902519226, 0.9772610068321228, 0.9891473054885864, 0.9956072568893433, 0.9956072568893433, 0.9860464930534363, 0.988630473613739, 0.9958656430244446, 0.9963824152946472, 0.9937984347343445, 0.9927648305892944, 0.9819121360778809, 0.986821711063385, 0.9961240291595459, 0.9940568208694458, 0.9932816624641418, 0.9932816624641418, 0.9961240291595459, 0.9979327917098999, 0.9974160194396973, 0.997157633304596, 0.9878553152084351, 0.9891473054885864, 0.9816537499427795, 0.9883720874786377, 0.9930232763290405, 0.9968992471694946, 0.9987080097198486, 0.9984496235847473, 0.9994832277297974, 0.9974160194396973, 0.998191237449646, 0.9984496235847473, 0.9984496235847473, 0.9870800971984863, 0.9873384833335876, 0.9930232763290405, 0.986821711063385, 0.9888888597488403, 0.9883720874786377, 0.9883720874786377, 0.9948320388793945, 0.9961240291595459, 0.9904392957687378, 0.9930232763290405, 0.9974160194396973, 0.9992247819900513, 0.99896639585495, 0.9992247819900513, 0.9994832277297974, 0.9987080097198486, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.9987080097198486, 0.99896639585495, 0.99896639585495, 0.9994832277297974, 0.9994832277297974, 0.9992247819900513, 0.9992247819900513, 0.9992247819900513, 0.9992247819900513, 0.9992247819900513, 0.9994832277297974, 0.9987080097198486, 0.9994832277297974, 0.9994832277297974, 0.9992247819900513, 0.9994832277297974, 0.9994832277297974, 0.9992247819900513, 0.9992247819900513, 0.99896639585495, 0.9992247819900513, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.9992247819900513, 0.9994832277297974, 0.9987080097198486, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.99896639585495, 0.9984496235847473, 0.9767441749572754, 0.9397932887077332, 0.9677002429962158, 0.9888888597488403, 0.9793281555175781, 0.9940568208694458, 0.9847545027732849, 0.9746770262718201, 0.9937984347343445, 0.9953488111495972], 'val_loss': [0.6892186999320984, 0.6835976839065552, 0.6916704177856445, 0.6728146076202393, 0.6763443350791931, 0.6414880156517029, 0.6399495601654053, 0.6438068747520447, 0.632294774055481, 0.6293706893920898, 0.6804553866386414, 0.6083062291145325, 0.703864574432373, 0.7263048887252808, 0.7925492525100708, 0.9764032959938049, 0.7265437245368958, 0.8315155506134033, 0.9194589257240295, 0.9600268006324768, 0.9779980778694153, 0.8398021459579468, 1.0549825429916382, 0.9731511473655701, 0.7281275987625122, 0.6832849383354187, 0.8032917380332947, 0.7178514003753662, 0.7886901497840881, 0.8099009394645691, 0.7939857840538025, 0.8453084230422974, 1.0051621198654175, 0.9290730953216553, 0.7732849717140198, 0.7206888794898987, 0.7988298535346985, 0.691864013671875, 0.8083738088607788, 0.7416256070137024, 0.8316619992256165, 0.9323664903640747, 0.8715403079986572, 0.7991701364517212, 0.7887903451919556, 0.8767526149749756, 0.8451277017593384, 0.8241323828697205, 0.8154354095458984, 0.8164240717887878, 0.7933295369148254, 0.8006940484046936, 0.7935819029808044, 0.8383705615997314, 0.8330828547477722, 0.820878803730011, 0.784008264541626, 0.808455765247345, 0.7994372844696045, 0.785651683807373, 0.7973153591156006, 0.7888336181640625, 0.7772522568702698, 0.7850993275642395, 0.7908115983009338, 0.7841667532920837, 0.804293692111969, 0.7768644690513611, 0.7860853672027588, 0.7979808449745178, 0.7785411477088928, 0.7829571962356567, 0.7901917099952698, 0.7840646505355835, 0.8473533391952515, 0.8104817867279053, 0.7997197508811951, 0.7981740832328796, 0.7969768643379211, 0.794680655002594, 0.7967998385429382, 0.8775477409362793, 0.8969956040382385, 0.8200995922088623, 0.7921636700630188, 0.7894733548164368, 0.7818202376365662, 0.824258029460907, 0.85200434923172, 0.92796391248703, 0.9070148468017578, 0.7583729028701782, 0.7780345678329468, 1.6010594367980957, 0.7811453342437744, 0.9600832462310791, 0.846327006816864, 0.7127271890640259, 1.0466424226760864, 1.1392624378204346], 'val_accuracy': [0.5299586653709412, 0.53925621509552, 0.5361570119857788, 0.5785123705863953, 0.58574378490448, 0.6425619721412659, 0.6291322112083435, 0.6332644820213318, 0.6549586653709412, 0.68388432264328, 0.6621900796890259, 0.6942148804664612, 0.6611570119857788, 0.6900826692581177, 0.711776852607727, 0.682851254940033, 0.7530992031097412, 0.7448347210884094, 0.7520661354064941, 0.76962810754776, 0.7778925895690918, 0.7613636255264282, 0.75, 0.7252066135406494, 0.8130165338516235, 0.8316115736961365, 0.8202479481697083, 0.8409090638160706, 0.8419421315193176, 0.8336777091026306, 0.836776852607727, 0.8378099203109741, 0.8119834661483765, 0.8192148804664612, 0.8016529083251953, 0.8243801593780518, 0.8150826692581177, 0.8285123705863953, 0.8006198406219482, 0.7995867729187012, 0.7840909361839294, 0.7933884263038635, 0.8057851195335388, 0.7830578684806824, 0.81611567735672, 0.7944214940071106, 0.8130165338516235, 0.8109503984451294, 0.817148745059967, 0.817148745059967, 0.8264462947845459, 0.8202479481697083, 0.8212810158729553, 0.8109503984451294, 0.8243801593780518, 0.8181818127632141, 0.8285123705863953, 0.8243801593780518, 0.8254132270812988, 0.827479362487793, 0.8336777091026306, 0.8347107172012329, 0.8316115736961365, 0.8285123705863953, 0.8316115736961365, 0.8336777091026306, 0.8264462947845459, 0.8243801593780518, 0.8285123705863953, 0.8316115736961365, 0.8264462947845459, 0.8316115736961365, 0.8243801593780518, 0.827479362487793, 0.8233470916748047, 0.8316115736961365, 0.8264462947845459, 0.827479362487793, 0.8295454382896423, 0.827479362487793, 0.8316115736961365, 0.8233470916748047, 0.8109503984451294, 0.8409090638160706, 0.8295454382896423, 0.8254132270812988, 0.8264462947845459, 0.8326446413993835, 0.8295454382896423, 0.807851254940033, 0.692148745059967, 0.75, 0.8006198406219482, 0.6787189841270447, 0.7923553586006165, 0.7820248007774353, 0.7789255976676941, 0.7758264541625977, 0.7706611752510071, 0.7644628286361694]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9873"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 8s 59ms/step - loss: 0.0417 - accuracy: 0.9873 - val_loss: 0.6749 - val_accuracy: 0.5690\n","Epoch 2/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0199 - accuracy: 0.9952 - val_loss: 0.7185 - val_accuracy: 0.5291\n","Epoch 3/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0144 - accuracy: 0.9976 - val_loss: 0.6782 - val_accuracy: 0.5711\n","Epoch 4/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0247 - accuracy: 0.9925 - val_loss: 0.6636 - val_accuracy: 0.5873\n","Epoch 5/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0246 - accuracy: 0.9927 - val_loss: 0.6251 - val_accuracy: 0.6498\n","Epoch 6/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0441 - accuracy: 0.9860 - val_loss: 0.7302 - val_accuracy: 0.5582\n","Epoch 7/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0355 - accuracy: 0.9892 - val_loss: 0.6051 - val_accuracy: 0.6821\n","Epoch 8/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0200 - accuracy: 0.9960 - val_loss: 0.6221 - val_accuracy: 0.6659\n","Epoch 9/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0126 - accuracy: 0.9976 - val_loss: 0.6124 - val_accuracy: 0.6810\n","Epoch 10/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0132 - accuracy: 0.9978 - val_loss: 0.5734 - val_accuracy: 0.7188\n","Epoch 11/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0153 - accuracy: 0.9970 - val_loss: 0.6167 - val_accuracy: 0.6994\n","Epoch 12/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0188 - accuracy: 0.9957 - val_loss: 0.5855 - val_accuracy: 0.7166\n","Epoch 13/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.0196 - accuracy: 0.9960 - val_loss: 0.5797 - val_accuracy: 0.7500\n","Epoch 14/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.0128 - accuracy: 0.9981 - val_loss: 0.6334 - val_accuracy: 0.7532\n","Epoch 15/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0164 - accuracy: 0.9962 - val_loss: 0.6545 - val_accuracy: 0.7522\n","Epoch 16/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0172 - accuracy: 0.9957 - val_loss: 1.3196 - val_accuracy: 0.6476\n","Epoch 17/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0329 - accuracy: 0.9892 - val_loss: 0.6692 - val_accuracy: 0.7500\n","Epoch 18/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0303 - accuracy: 0.9919 - val_loss: 0.6510 - val_accuracy: 0.7802\n","Epoch 19/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0185 - accuracy: 0.9952 - val_loss: 1.0102 - val_accuracy: 0.7155\n","Epoch 20/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0242 - accuracy: 0.9935 - val_loss: 0.5989 - val_accuracy: 0.8168\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0166 - accuracy: 0.9960 - val_loss: 0.8029 - val_accuracy: 0.7866\n","Epoch 22/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0159 - accuracy: 0.9962 - val_loss: 0.7243 - val_accuracy: 0.8211\n","Epoch 23/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0167 - accuracy: 0.9968 - val_loss: 0.6814 - val_accuracy: 0.8200\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0179 - accuracy: 0.9968 - val_loss: 0.8078 - val_accuracy: 0.8179\n","Epoch 25/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0146 - accuracy: 0.9976 - val_loss: 0.7010 - val_accuracy: 0.8459\n","Epoch 26/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0204 - accuracy: 0.9957 - val_loss: 0.5430 - val_accuracy: 0.8739\n","Epoch 27/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0209 - accuracy: 0.9938 - val_loss: 0.4964 - val_accuracy: 0.8664\n","Epoch 28/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0340 - accuracy: 0.9892 - val_loss: 0.7293 - val_accuracy: 0.8222\n","Epoch 29/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0331 - accuracy: 0.9903 - val_loss: 0.5756 - val_accuracy: 0.8599\n","Epoch 30/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0178 - accuracy: 0.9965 - val_loss: 0.5665 - val_accuracy: 0.8728\n","Epoch 31/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0182 - accuracy: 0.9949 - val_loss: 0.7461 - val_accuracy: 0.8308\n","Epoch 32/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0249 - accuracy: 0.9938 - val_loss: 0.6367 - val_accuracy: 0.8524\n","Epoch 33/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0321 - accuracy: 0.9908 - val_loss: 0.5825 - val_accuracy: 0.8416\n","Epoch 34/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0205 - accuracy: 0.9957 - val_loss: 0.5885 - val_accuracy: 0.8578\n","Epoch 35/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0207 - accuracy: 0.9943 - val_loss: 0.6051 - val_accuracy: 0.8416\n","Epoch 36/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0179 - accuracy: 0.9952 - val_loss: 0.5759 - val_accuracy: 0.8696\n","Epoch 37/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0158 - accuracy: 0.9965 - val_loss: 0.7975 - val_accuracy: 0.8276\n","Epoch 38/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0158 - accuracy: 0.9965 - val_loss: 0.6204 - val_accuracy: 0.8675\n","Epoch 39/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0143 - accuracy: 0.9968 - val_loss: 0.8492 - val_accuracy: 0.8319\n","Epoch 40/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0395 - accuracy: 0.9887 - val_loss: 0.5706 - val_accuracy: 0.8394\n","Epoch 41/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 0.6784 - val_accuracy: 0.8545\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0149 - accuracy: 0.9960 - val_loss: 0.6754 - val_accuracy: 0.8599\n","Epoch 43/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0153 - accuracy: 0.9968 - val_loss: 0.6531 - val_accuracy: 0.8567\n","Epoch 44/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0284 - accuracy: 0.9916 - val_loss: 0.8935 - val_accuracy: 0.7985\n","Epoch 45/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0279 - accuracy: 0.9919 - val_loss: 0.5785 - val_accuracy: 0.8416\n","Epoch 46/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.6299 - val_accuracy: 0.8578\n","Epoch 47/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0133 - accuracy: 0.9976 - val_loss: 0.8701 - val_accuracy: 0.8254\n","Epoch 48/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0131 - accuracy: 0.9976 - val_loss: 0.6479 - val_accuracy: 0.8599\n","Epoch 49/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0124 - accuracy: 0.9976 - val_loss: 0.8771 - val_accuracy: 0.8405\n","Epoch 50/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0140 - accuracy: 0.9976 - val_loss: 0.8396 - val_accuracy: 0.8265\n","Epoch 51/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.6170 - val_accuracy: 0.8502\n","Epoch 52/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0219 - accuracy: 0.9935 - val_loss: 0.6861 - val_accuracy: 0.8244\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0151 - accuracy: 0.9965 - val_loss: 0.7025 - val_accuracy: 0.8416\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0127 - accuracy: 0.9973 - val_loss: 0.7015 - val_accuracy: 0.8405\n","Epoch 55/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0128 - accuracy: 0.9973 - val_loss: 0.7092 - val_accuracy: 0.8459\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0094 - accuracy: 0.9987 - val_loss: 0.6406 - val_accuracy: 0.8653\n","Epoch 57/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0082 - accuracy: 0.9995 - val_loss: 0.6618 - val_accuracy: 0.8621\n","Epoch 58/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0077 - accuracy: 0.9995 - val_loss: 0.6537 - val_accuracy: 0.8621\n","Epoch 59/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0080 - accuracy: 0.9989 - val_loss: 0.6446 - val_accuracy: 0.8578\n","Epoch 60/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0075 - accuracy: 0.9995 - val_loss: 0.6370 - val_accuracy: 0.8631\n","Epoch 61/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.6770 - val_accuracy: 0.8599\n","Epoch 62/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0079 - accuracy: 0.9995 - val_loss: 0.6253 - val_accuracy: 0.8664\n","Epoch 63/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0088 - accuracy: 0.9987 - val_loss: 0.6244 - val_accuracy: 0.8696\n","Epoch 64/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 0.6610 - val_accuracy: 0.8653\n","Epoch 65/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0075 - accuracy: 0.9989 - val_loss: 0.8133 - val_accuracy: 0.8384\n","Epoch 66/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0083 - accuracy: 0.9989 - val_loss: 0.6687 - val_accuracy: 0.8696\n","Epoch 67/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 0.6607 - val_accuracy: 0.8653\n","Epoch 68/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0085 - accuracy: 0.9978 - val_loss: 0.6400 - val_accuracy: 0.8707\n","Epoch 69/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0077 - accuracy: 0.9995 - val_loss: 0.6719 - val_accuracy: 0.8642\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 0.6475 - val_accuracy: 0.8653\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 0.6554 - val_accuracy: 0.8631\n","Epoch 72/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 0.6564 - val_accuracy: 0.8610\n","Epoch 73/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 0.6840 - val_accuracy: 0.8631\n","Epoch 74/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.6675 - val_accuracy: 0.8642\n","Epoch 75/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 0.6641 - val_accuracy: 0.8631\n","Epoch 76/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 0.6610 - val_accuracy: 0.8621\n","Epoch 77/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 0.6523 - val_accuracy: 0.8653\n","Epoch 78/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 0.6536 - val_accuracy: 0.8642\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 0.6616 - val_accuracy: 0.8631\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 0.6607 - val_accuracy: 0.8631\n","Epoch 81/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 0.6707 - val_accuracy: 0.8653\n","Epoch 82/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 0.6656 - val_accuracy: 0.8631\n","Epoch 83/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 0.6699 - val_accuracy: 0.8664\n","Epoch 84/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 0.6658 - val_accuracy: 0.8631\n","Epoch 85/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 0.6631 - val_accuracy: 0.8631\n","Epoch 86/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 0.6655 - val_accuracy: 0.8685\n","Epoch 87/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.6671 - val_accuracy: 0.8631\n","Epoch 88/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0068 - accuracy: 0.9995 - val_loss: 0.6882 - val_accuracy: 0.8675\n","Epoch 89/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 0.6610 - val_accuracy: 0.8653\n","Epoch 90/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 0.6693 - val_accuracy: 0.8621\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.6859 - val_accuracy: 0.8631\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 0.6904 - val_accuracy: 0.8685\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 0.6958 - val_accuracy: 0.8675\n","Epoch 94/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0072 - accuracy: 0.9992 - val_loss: 0.6889 - val_accuracy: 0.8675\n","Epoch 95/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 0.6800 - val_accuracy: 0.8653\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 0.6970 - val_accuracy: 0.8621\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 0.6782 - val_accuracy: 0.8664\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 0.6763 - val_accuracy: 0.8621\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 0.6848 - val_accuracy: 0.8718\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0067 - accuracy: 0.9995 - val_loss: 0.6902 - val_accuracy: 0.8685\n","{'loss': [0.041698720306158066, 0.019919833168387413, 0.014401733875274658, 0.024688901379704475, 0.024614669382572174, 0.044078752398490906, 0.03551054000854492, 0.020016781985759735, 0.012648265808820724, 0.013217469677329063, 0.01529864501208067, 0.018763937056064606, 0.019647564738988876, 0.012777221389114857, 0.016371596604585648, 0.017214948311448097, 0.03285310044884682, 0.03034648485481739, 0.018482230603694916, 0.02421882562339306, 0.016639212146401405, 0.0158665981143713, 0.01665002852678299, 0.017934484407305717, 0.014563522301614285, 0.020421523600816727, 0.02092624455690384, 0.03402351960539818, 0.03307921439409256, 0.01781659945845604, 0.01816544681787491, 0.024882791563868523, 0.03210565820336342, 0.020504435524344444, 0.020705776289105415, 0.017904939129948616, 0.015772705897688866, 0.01584591157734394, 0.014313465915620327, 0.03952617198228836, 0.013062526471912861, 0.014916590414941311, 0.015339760109782219, 0.02839587815105915, 0.027929725125432014, 0.0132056949660182, 0.013268792070448399, 0.013119008392095566, 0.012399359606206417, 0.013964307494461536, 0.024144388735294342, 0.021941201761364937, 0.015137388370931149, 0.012708375230431557, 0.012789137661457062, 0.009442402049899101, 0.008176391944289207, 0.007710629142820835, 0.007999629713594913, 0.007520551327615976, 0.007519497070461512, 0.007856733165681362, 0.008848857134580612, 0.009207385592162609, 0.007534346543252468, 0.008307070471346378, 0.008161930367350578, 0.008484574034810066, 0.0077413348481059074, 0.0071147652342915535, 0.007358394097536802, 0.007152909878641367, 0.0071462723426520824, 0.007309400476515293, 0.007413945626467466, 0.007368647027760744, 0.007597734685987234, 0.007129323668777943, 0.007049740757793188, 0.007184079848229885, 0.006971592549234629, 0.007041389588266611, 0.007011123467236757, 0.0070198518224060535, 0.007056946400552988, 0.007169303018599749, 0.006917029153555632, 0.006805097684264183, 0.007375967688858509, 0.006996238604187965, 0.006915852427482605, 0.007398573681712151, 0.006892441771924496, 0.007200648542493582, 0.007006943225860596, 0.007049938198179007, 0.007082722615450621, 0.007025470957159996, 0.007042578887194395, 0.006715694908052683], 'accuracy': [0.9873383641242981, 0.9951508641242981, 0.9975754022598267, 0.9924569129943848, 0.9927262663841248, 0.985991358757019, 0.9892241358757019, 0.9959590435028076, 0.9975754022598267, 0.9978448152542114, 0.9970366358757019, 0.9956896305084229, 0.9959590435028076, 0.9981142282485962, 0.9962284564971924, 0.9956896305084229, 0.9892241358757019, 0.9919180870056152, 0.9951508641242981, 0.993534505367279, 0.9959590435028076, 0.9962284564971924, 0.9967672228813171, 0.9967672228813171, 0.9975754022598267, 0.9956896305084229, 0.993803858757019, 0.9892241358757019, 0.9903017282485962, 0.9964978694915771, 0.9948814511299133, 0.993803858757019, 0.990840494632721, 0.9956896305084229, 0.9943426847457886, 0.9951508641242981, 0.9964978694915771, 0.9964978694915771, 0.9967672228813171, 0.9886853694915771, 0.9973060488700867, 0.9959590435028076, 0.9967672228813171, 0.9916487336158752, 0.9919180870056152, 0.9975754022598267, 0.9975754022598267, 0.9975754022598267, 0.9975754022598267, 0.9975754022598267, 0.9927262663841248, 0.993534505367279, 0.9964978694915771, 0.9973060488700867, 0.9973060488700867, 0.998652994632721, 0.9994612336158752, 0.9994612336158752, 0.9989224076271057, 0.9994612336158752, 0.9991918206214905, 0.9994612336158752, 0.998652994632721, 0.998383641242981, 0.9989224076271057, 0.9989224076271057, 0.998383641242981, 0.9978448152542114, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9991918206214905, 0.9994612336158752, 0.9994612336158752, 0.9991918206214905, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9991918206214905, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9991918206214905, 0.9991918206214905, 0.9994612336158752, 0.9991918206214905, 0.9994612336158752, 0.9994612336158752, 0.9994612336158752, 0.9989224076271057, 0.9994612336158752, 0.9994612336158752], 'val_loss': [0.6749293208122253, 0.7185138463973999, 0.6782031059265137, 0.6635749936103821, 0.6251150965690613, 0.7301564812660217, 0.605065643787384, 0.6220716834068298, 0.6123937368392944, 0.5734187364578247, 0.6166780591011047, 0.5855244398117065, 0.579719603061676, 0.6333919167518616, 0.6545366048812866, 1.3195786476135254, 0.6691845655441284, 0.6510147452354431, 1.010168433189392, 0.5989214777946472, 0.8028517365455627, 0.7243250012397766, 0.6814195513725281, 0.8078449368476868, 0.7009679675102234, 0.5429708957672119, 0.49635475873947144, 0.7292914390563965, 0.5755957961082458, 0.5664831399917603, 0.7460911870002747, 0.6366787552833557, 0.5824769735336304, 0.5885070562362671, 0.6050905585289001, 0.575901448726654, 0.7974522113800049, 0.6203891634941101, 0.8492144346237183, 0.5705854892730713, 0.6783995628356934, 0.6754133701324463, 0.6531043648719788, 0.8934667706489563, 0.57845538854599, 0.6299456357955933, 0.8701131939888, 0.6479359269142151, 0.877146303653717, 0.8396052122116089, 0.6170237064361572, 0.6860947608947754, 0.702523410320282, 0.7015058994293213, 0.7092117071151733, 0.6406238079071045, 0.6617612242698669, 0.6536927223205566, 0.6446272134780884, 0.6369850039482117, 0.6770312190055847, 0.6253282427787781, 0.6244279146194458, 0.6609715819358826, 0.813286542892456, 0.6687082648277283, 0.660677433013916, 0.6399538516998291, 0.6718791723251343, 0.6475310921669006, 0.6553744673728943, 0.6564021110534668, 0.6839662194252014, 0.6675438284873962, 0.6641421318054199, 0.6609827280044556, 0.6523184180259705, 0.6536146998405457, 0.6615736484527588, 0.6607156991958618, 0.670730471611023, 0.6656146049499512, 0.6698641777038574, 0.6658072471618652, 0.6631361842155457, 0.6655207276344299, 0.6671480536460876, 0.6881979703903198, 0.6610397696495056, 0.6693130731582642, 0.6859480738639832, 0.6904429197311401, 0.6957534551620483, 0.6888922452926636, 0.6800051331520081, 0.6969667673110962, 0.678228497505188, 0.676330029964447, 0.6848341822624207, 0.6902444362640381], 'val_accuracy': [0.568965494632721, 0.5290948152542114, 0.5711206793785095, 0.587284505367279, 0.649784505367279, 0.5581896305084229, 0.6821120977401733, 0.6659482717514038, 0.681034505367279, 0.71875, 0.6993534564971924, 0.7165948152542114, 0.75, 0.7532327771186829, 0.7521551847457886, 0.6476293206214905, 0.75, 0.7801724076271057, 0.7155172228813171, 0.8168103694915771, 0.7866379022598267, 0.8211206793785095, 0.8200430870056152, 0.8178879022598267, 0.8459051847457886, 0.8739224076271057, 0.8663793206214905, 0.8221982717514038, 0.8599137663841248, 0.8728448152542114, 0.8308189511299133, 0.8523706793785095, 0.8415948152542114, 0.857758641242981, 0.8415948152542114, 0.8696120977401733, 0.8275862336158752, 0.8674569129943848, 0.8318965435028076, 0.8394396305084229, 0.8545258641242981, 0.8599137663841248, 0.8566810488700867, 0.798491358757019, 0.8415948152542114, 0.857758641242981, 0.8254310488700867, 0.8599137663841248, 0.8405172228813171, 0.826508641242981, 0.850215494632721, 0.8243534564971924, 0.8415948152542114, 0.8405172228813171, 0.8459051847457886, 0.8653017282485962, 0.8620689511299133, 0.8620689511299133, 0.857758641242981, 0.8631465435028076, 0.8599137663841248, 0.8663793206214905, 0.8696120977401733, 0.8653017282485962, 0.8383620977401733, 0.8696120977401733, 0.8653017282485962, 0.8706896305084229, 0.8642241358757019, 0.8653017282485962, 0.8631465435028076, 0.860991358757019, 0.8631465435028076, 0.8642241358757019, 0.8631465435028076, 0.8620689511299133, 0.8653017282485962, 0.8642241358757019, 0.8631465435028076, 0.8631465435028076, 0.8653017282485962, 0.8631465435028076, 0.8663793206214905, 0.8631465435028076, 0.8631465435028076, 0.868534505367279, 0.8631465435028076, 0.8674569129943848, 0.8653017282485962, 0.8620689511299133, 0.8631465435028076, 0.868534505367279, 0.8674569129943848, 0.8674569129943848, 0.8653017282485962, 0.8620689511299133, 0.8663793206214905, 0.8620689511299133, 0.8717672228813171, 0.868534505367279]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.0445 - accuracy: 0.9861"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 65ms/step - loss: 0.0438 - accuracy: 0.9864 - val_loss: 0.6781 - val_accuracy: 0.5452\n","Epoch 2/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0162 - accuracy: 0.9966 - val_loss: 0.7256 - val_accuracy: 0.5204\n","Epoch 3/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0224 - accuracy: 0.9949 - val_loss: 0.7212 - val_accuracy: 0.5339\n","Epoch 4/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0190 - accuracy: 0.9949 - val_loss: 0.6773 - val_accuracy: 0.5803\n","Epoch 5/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0134 - accuracy: 0.9972 - val_loss: 0.6987 - val_accuracy: 0.5826\n","Epoch 6/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0113 - accuracy: 0.9986 - val_loss: 0.6441 - val_accuracy: 0.6335\n","Epoch 7/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0143 - accuracy: 0.9980 - val_loss: 0.6653 - val_accuracy: 0.6357\n","Epoch 8/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0203 - accuracy: 0.9952 - val_loss: 0.5811 - val_accuracy: 0.6900\n","Epoch 9/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0450 - accuracy: 0.9864 - val_loss: 0.5938 - val_accuracy: 0.6878\n","Epoch 10/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0469 - accuracy: 0.9847 - val_loss: 0.5803 - val_accuracy: 0.7036\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0340 - accuracy: 0.9901 - val_loss: 0.5900 - val_accuracy: 0.6957\n","Epoch 12/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0176 - accuracy: 0.9958 - val_loss: 0.6162 - val_accuracy: 0.6968\n","Epoch 13/100\n","28/28 [==============================] - 1s 48ms/step - loss: 0.0197 - accuracy: 0.9952 - val_loss: 0.6216 - val_accuracy: 0.7251\n","Epoch 14/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0170 - accuracy: 0.9960 - val_loss: 0.7048 - val_accuracy: 0.7195\n","Epoch 15/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.0140 - accuracy: 0.9977 - val_loss: 0.6401 - val_accuracy: 0.7579\n","Epoch 16/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 0.6524 - val_accuracy: 0.7704\n","Epoch 17/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0125 - accuracy: 0.9972 - val_loss: 0.7105 - val_accuracy: 0.7557\n","Epoch 18/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0118 - accuracy: 0.9983 - val_loss: 0.7125 - val_accuracy: 0.7839\n","Epoch 19/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0098 - accuracy: 0.9989 - val_loss: 0.7291 - val_accuracy: 0.7930\n","Epoch 20/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0083 - accuracy: 0.9992 - val_loss: 0.7500 - val_accuracy: 0.8066\n","Epoch 21/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0083 - accuracy: 0.9992 - val_loss: 0.7420 - val_accuracy: 0.8190\n","Epoch 22/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0078 - accuracy: 0.9997 - val_loss: 0.5182 - val_accuracy: 0.8665\n","Epoch 23/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0085 - accuracy: 0.9989 - val_loss: 0.6825 - val_accuracy: 0.8394\n","Epoch 24/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.0083 - accuracy: 0.9986 - val_loss: 0.5175 - val_accuracy: 0.8756\n","Epoch 25/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0085 - accuracy: 0.9992 - val_loss: 0.4258 - val_accuracy: 0.8937\n","Epoch 26/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0082 - accuracy: 0.9989 - val_loss: 0.4652 - val_accuracy: 0.8891\n","Epoch 27/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0076 - accuracy: 0.9994 - val_loss: 0.5195 - val_accuracy: 0.8869\n","Epoch 28/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.4630 - val_accuracy: 0.8914\n","Epoch 29/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0078 - accuracy: 0.9992 - val_loss: 0.5686 - val_accuracy: 0.8812\n","Epoch 30/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.4267 - val_accuracy: 0.9072\n","Epoch 31/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 0.5434 - val_accuracy: 0.8880\n","Epoch 32/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0091 - accuracy: 0.9989 - val_loss: 0.4404 - val_accuracy: 0.9005\n","Epoch 33/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.0078 - accuracy: 0.9992 - val_loss: 0.4392 - val_accuracy: 0.9084\n","Epoch 34/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.4450 - val_accuracy: 0.9050\n","Epoch 35/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.0075 - accuracy: 0.9989 - val_loss: 0.4421 - val_accuracy: 0.9163\n","Epoch 36/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0082 - accuracy: 0.9986 - val_loss: 0.4439 - val_accuracy: 0.9072\n","Epoch 37/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0094 - accuracy: 0.9989 - val_loss: 0.4897 - val_accuracy: 0.8880\n","Epoch 38/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0140 - accuracy: 0.9972 - val_loss: 0.8932 - val_accuracy: 0.8292\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0955 - accuracy: 0.9677 - val_loss: 0.4822 - val_accuracy: 0.8450\n","Epoch 40/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0494 - accuracy: 0.9856 - val_loss: 0.5694 - val_accuracy: 0.8518\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0492 - accuracy: 0.9844 - val_loss: 0.5036 - val_accuracy: 0.8484\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0366 - accuracy: 0.9887 - val_loss: 0.5513 - val_accuracy: 0.8563\n","Epoch 43/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0316 - accuracy: 0.9909 - val_loss: 0.6218 - val_accuracy: 0.8597\n","Epoch 44/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0422 - accuracy: 0.9847 - val_loss: 0.6158 - val_accuracy: 0.8450\n","Epoch 45/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0297 - accuracy: 0.9915 - val_loss: 0.5804 - val_accuracy: 0.8631\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0167 - accuracy: 0.9960 - val_loss: 0.5651 - val_accuracy: 0.8744\n","Epoch 47/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0123 - accuracy: 0.9980 - val_loss: 0.6550 - val_accuracy: 0.8812\n","Epoch 48/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0154 - accuracy: 0.9966 - val_loss: 0.5969 - val_accuracy: 0.8790\n","Epoch 49/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0192 - accuracy: 0.9949 - val_loss: 0.6614 - val_accuracy: 0.8620\n","Epoch 50/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 0.6240 - val_accuracy: 0.8688\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.6439 - val_accuracy: 0.8609\n","Epoch 52/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0240 - accuracy: 0.9929 - val_loss: 0.6378 - val_accuracy: 0.8609\n","Epoch 53/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0159 - accuracy: 0.9958 - val_loss: 0.6351 - val_accuracy: 0.8688\n","Epoch 54/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0337 - accuracy: 0.9904 - val_loss: 0.7198 - val_accuracy: 0.8258\n","Epoch 55/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0416 - accuracy: 0.9856 - val_loss: 0.6075 - val_accuracy: 0.8394\n","Epoch 56/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0194 - accuracy: 0.9960 - val_loss: 0.5297 - val_accuracy: 0.8846\n","Epoch 57/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0116 - accuracy: 0.9977 - val_loss: 0.5228 - val_accuracy: 0.8846\n","Epoch 58/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0081 - accuracy: 0.9994 - val_loss: 0.5427 - val_accuracy: 0.8903\n","Epoch 59/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0087 - accuracy: 0.9986 - val_loss: 0.5230 - val_accuracy: 0.8880\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0080 - accuracy: 0.9994 - val_loss: 0.6128 - val_accuracy: 0.8812\n","Epoch 61/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0087 - accuracy: 0.9989 - val_loss: 0.5287 - val_accuracy: 0.8959\n","Epoch 62/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.5322 - val_accuracy: 0.8948\n","Epoch 63/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.5356 - val_accuracy: 0.8835\n","Epoch 64/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.5273 - val_accuracy: 0.8925\n","Epoch 65/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 0.5281 - val_accuracy: 0.8982\n","Epoch 66/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0073 - accuracy: 0.9994 - val_loss: 0.5387 - val_accuracy: 0.8891\n","Epoch 67/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.5327 - val_accuracy: 0.8948\n","Epoch 68/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.5312 - val_accuracy: 0.8903\n","Epoch 69/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.5303 - val_accuracy: 0.8971\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0071 - accuracy: 0.9989 - val_loss: 0.5313 - val_accuracy: 0.8959\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0071 - accuracy: 0.9994 - val_loss: 0.5325 - val_accuracy: 0.8937\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0070 - accuracy: 0.9992 - val_loss: 0.5438 - val_accuracy: 0.8891\n","Epoch 73/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.5408 - val_accuracy: 0.8891\n","Epoch 74/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0069 - accuracy: 0.9994 - val_loss: 0.5466 - val_accuracy: 0.8925\n","Epoch 75/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.5442 - val_accuracy: 0.8925\n","Epoch 76/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.5442 - val_accuracy: 0.8925\n","Epoch 77/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.5462 - val_accuracy: 0.8925\n","Epoch 78/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.5614 - val_accuracy: 0.8857\n","Epoch 79/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.5414 - val_accuracy: 0.8925\n","Epoch 80/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 0.5459 - val_accuracy: 0.8937\n","Epoch 81/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0069 - accuracy: 0.9994 - val_loss: 0.5489 - val_accuracy: 0.8948\n","Epoch 82/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0067 - accuracy: 0.9992 - val_loss: 0.5533 - val_accuracy: 0.8914\n","Epoch 83/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.5517 - val_accuracy: 0.8925\n","Epoch 84/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.5529 - val_accuracy: 0.8925\n","Epoch 85/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 0.5570 - val_accuracy: 0.8914\n","Epoch 86/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0068 - accuracy: 0.9992 - val_loss: 0.5567 - val_accuracy: 0.8914\n","Epoch 87/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.5621 - val_accuracy: 0.8903\n","Epoch 88/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0075 - accuracy: 0.9989 - val_loss: 0.5508 - val_accuracy: 0.8925\n","Epoch 89/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0067 - accuracy: 0.9992 - val_loss: 0.5854 - val_accuracy: 0.8891\n","Epoch 90/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0066 - accuracy: 0.9992 - val_loss: 0.5577 - val_accuracy: 0.8925\n","Epoch 91/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0070 - accuracy: 0.9992 - val_loss: 0.5700 - val_accuracy: 0.8903\n","Epoch 92/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0071 - accuracy: 0.9994 - val_loss: 0.5734 - val_accuracy: 0.8869\n","Epoch 93/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.5576 - val_accuracy: 0.8914\n","Epoch 94/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0067 - accuracy: 0.9992 - val_loss: 0.5541 - val_accuracy: 0.8971\n","Epoch 95/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 0.5773 - val_accuracy: 0.8880\n","Epoch 96/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.5608 - val_accuracy: 0.8925\n","Epoch 97/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0066 - accuracy: 0.9994 - val_loss: 0.5570 - val_accuracy: 0.8948\n","Epoch 98/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.6696 - val_accuracy: 0.8767\n","Epoch 99/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0071 - accuracy: 0.9989 - val_loss: 0.5885 - val_accuracy: 0.8903\n","Epoch 100/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 0.5748 - val_accuracy: 0.8925\n","{'loss': [0.04378165304660797, 0.016247481107711792, 0.022369753569364548, 0.018972603604197502, 0.0133895892649889, 0.011346825398504734, 0.014257881790399551, 0.020291117951273918, 0.04501934349536896, 0.046882059425115585, 0.033965934067964554, 0.017617659643292427, 0.019652269780635834, 0.017048105597496033, 0.01402246206998825, 0.01353116799145937, 0.012492820620536804, 0.011806602589786053, 0.009794886223971844, 0.008339525200426579, 0.008347142487764359, 0.007815840654075146, 0.008481679484248161, 0.008347957395017147, 0.008512213826179504, 0.008218498900532722, 0.007628018036484718, 0.007571021560579538, 0.007845926098525524, 0.007506758905947208, 0.007611838169395924, 0.009059537202119827, 0.007777511607855558, 0.007468730676919222, 0.007536625489592552, 0.008158753626048565, 0.009390950202941895, 0.014045003801584244, 0.09552865475416183, 0.04936856031417847, 0.049173615872859955, 0.03658035025000572, 0.03158731013536453, 0.042220328003168106, 0.029662886634469032, 0.016703655943274498, 0.012348548509180546, 0.0153511269018054, 0.01916399784386158, 0.0155539121478796, 0.01524705346673727, 0.023973511531949043, 0.015935353934764862, 0.03372516855597496, 0.04157988354563713, 0.01941145956516266, 0.011585230007767677, 0.008147257380187511, 0.008722667582333088, 0.007951587438583374, 0.008652754127979279, 0.00751050841063261, 0.0080640884116292, 0.007472263183444738, 0.007223125547170639, 0.007291468326002359, 0.007170684635639191, 0.007328107487410307, 0.007004296872764826, 0.007109182421118021, 0.0070585706271231174, 0.007044643629342318, 0.007402827963232994, 0.006928202696144581, 0.006888208910822868, 0.006945344153791666, 0.007037336006760597, 0.006955624092370272, 0.00707557238638401, 0.0071912710554897785, 0.006929227150976658, 0.00670189643278718, 0.006809451151639223, 0.006757115479558706, 0.006744383834302425, 0.0068291909992694855, 0.006772181484848261, 0.0075071994215250015, 0.006749615538865328, 0.006636140868067741, 0.007032135967165232, 0.007075662724673748, 0.00686529790982604, 0.00673317164182663, 0.006747005041688681, 0.006827173288911581, 0.006639642175287008, 0.006980553735047579, 0.007093904074281454, 0.006719687487930059], 'accuracy': [0.9864176511764526, 0.9966044425964355, 0.9949066042900085, 0.9949066042900085, 0.9971703290939331, 0.9985851645469666, 0.9980192184448242, 0.9951896071434021, 0.9864176511764526, 0.9847198724746704, 0.9900962114334106, 0.9957554936408997, 0.9951896071434021, 0.9960384964942932, 0.9977362751960754, 0.9968873858451843, 0.9971703290939331, 0.9983022212982178, 0.9988681674003601, 0.9991511106491089, 0.9991511106491089, 0.9997170567512512, 0.9988681674003601, 0.9985851645469666, 0.9991511106491089, 0.9988681674003601, 0.9994340538978577, 0.9988681674003601, 0.9991511106491089, 0.9991511106491089, 0.9991511106491089, 0.9988681674003601, 0.9991511106491089, 0.9991511106491089, 0.9988681674003601, 0.9985851645469666, 0.9988681674003601, 0.9971703290939331, 0.9677419066429138, 0.9855687618255615, 0.9844368696212769, 0.9886813759803772, 0.9909451007843018, 0.9847198724746704, 0.9915110468864441, 0.9960384964942932, 0.9980192184448242, 0.9966044425964355, 0.9949066042900085, 0.996321439743042, 0.9968873858451843, 0.9929258823394775, 0.9957554936408997, 0.9903791546821594, 0.9855687618255615, 0.9960384964942932, 0.9977362751960754, 0.9994340538978577, 0.9985851645469666, 0.9994340538978577, 0.9988681674003601, 0.9991511106491089, 0.9991511106491089, 0.9991511106491089, 0.9988681674003601, 0.9994340538978577, 0.9994340538978577, 0.9991511106491089, 0.9994340538978577, 0.9988681674003601, 0.9994340538978577, 0.9991511106491089, 0.9988681674003601, 0.9994340538978577, 0.9991511106491089, 0.9988681674003601, 0.9994340538978577, 0.9994340538978577, 0.9991511106491089, 0.9988681674003601, 0.9994340538978577, 0.9991511106491089, 0.9994340538978577, 0.9994340538978577, 0.9994340538978577, 0.9991511106491089, 0.9994340538978577, 0.9988681674003601, 0.9991511106491089, 0.9991511106491089, 0.9991511106491089, 0.9994340538978577, 0.9988681674003601, 0.9991511106491089, 0.9994340538978577, 0.9988681674003601, 0.9994340538978577, 0.9994340538978577, 0.9988681674003601, 0.9994340538978577], 'val_loss': [0.6780685782432556, 0.7256152033805847, 0.7212330102920532, 0.6773310899734497, 0.6986675262451172, 0.6440575122833252, 0.665288507938385, 0.581078052520752, 0.593804121017456, 0.5802582502365112, 0.5899596214294434, 0.6161677241325378, 0.6215668320655823, 0.7048380374908447, 0.6400718092918396, 0.6524428725242615, 0.710547685623169, 0.7125130295753479, 0.7291481494903564, 0.7499604225158691, 0.7419988512992859, 0.5181583762168884, 0.6824877858161926, 0.5174849629402161, 0.4258236289024353, 0.4652208983898163, 0.5194900631904602, 0.4630143940448761, 0.5686401724815369, 0.42665135860443115, 0.5434460043907166, 0.44042354822158813, 0.4391758441925049, 0.44499897956848145, 0.4420752227306366, 0.4439051151275635, 0.489662766456604, 0.8932016491889954, 0.4822111427783966, 0.569389820098877, 0.5035547018051147, 0.5512628555297852, 0.6218087673187256, 0.6157671213150024, 0.5804302096366882, 0.5650532841682434, 0.6549539566040039, 0.5969098806381226, 0.6614218354225159, 0.6240013241767883, 0.643880307674408, 0.6378211975097656, 0.6351206302642822, 0.7198072075843811, 0.6075388193130493, 0.5296743512153625, 0.5227888822555542, 0.5426778197288513, 0.5229998230934143, 0.6127638220787048, 0.5286786556243896, 0.5322427153587341, 0.535624086856842, 0.5273453593254089, 0.528106153011322, 0.5386704206466675, 0.5327174663543701, 0.5311909914016724, 0.5303017497062683, 0.5312892198562622, 0.5324671864509583, 0.5438474416732788, 0.540767252445221, 0.5466325879096985, 0.5442119240760803, 0.5442015528678894, 0.5461685061454773, 0.5613711476325989, 0.5413718223571777, 0.5458987355232239, 0.5488733053207397, 0.5533300042152405, 0.5517459511756897, 0.5528683662414551, 0.5570021867752075, 0.5566726326942444, 0.5621378421783447, 0.550753653049469, 0.5854008793830872, 0.5577012300491333, 0.5699656009674072, 0.5734319090843201, 0.55760258436203, 0.5540865659713745, 0.577278196811676, 0.5608393549919128, 0.5570456981658936, 0.6695696711540222, 0.5884867310523987, 0.5747963786125183], 'val_accuracy': [0.5452488660812378, 0.5203620195388794, 0.5339366793632507, 0.5803167223930359, 0.5825791954994202, 0.6334841847419739, 0.6357465982437134, 0.6900452375411987, 0.6877828240394592, 0.7036198973655701, 0.6957013607025146, 0.6968325972557068, 0.7251130938529968, 0.7194570302963257, 0.7579185366630554, 0.7703620195388794, 0.7556561231613159, 0.7839366793632507, 0.7929864525794983, 0.8065611124038696, 0.8190045356750488, 0.8665158152580261, 0.8393664956092834, 0.8755655884742737, 0.8936651349067688, 0.889140248298645, 0.8868778347969055, 0.8914027214050293, 0.8812217116355896, 0.9072397947311401, 0.8880090713500977, 0.9004524946212769, 0.9083710312843323, 0.9049773812294006, 0.9162895679473877, 0.9072397947311401, 0.8880090713500977, 0.8291855454444885, 0.8450226187705994, 0.8518099784851074, 0.848416268825531, 0.8563348650932312, 0.8597285151481628, 0.8450226187705994, 0.8631221652030945, 0.8744344115257263, 0.8812217116355896, 0.8789592981338501, 0.8619909286499023, 0.8687782883644104, 0.860859751701355, 0.860859751701355, 0.8687782883644104, 0.8257918357849121, 0.8393664956092834, 0.8846153616905212, 0.8846153616905212, 0.8902714848518372, 0.8880090713500977, 0.8812217116355896, 0.8959276080131531, 0.8947963714599609, 0.8834841847419739, 0.8925339579582214, 0.8981900215148926, 0.889140248298645, 0.8947963714599609, 0.8902714848518372, 0.8970588445663452, 0.8959276080131531, 0.8936651349067688, 0.889140248298645, 0.889140248298645, 0.8925339579582214, 0.8925339579582214, 0.8925339579582214, 0.8925339579582214, 0.8857465982437134, 0.8925339579582214, 0.8936651349067688, 0.8947963714599609, 0.8914027214050293, 0.8925339579582214, 0.8925339579582214, 0.8914027214050293, 0.8914027214050293, 0.8902714848518372, 0.8925339579582214, 0.889140248298645, 0.8925339579582214, 0.8902714848518372, 0.8868778347969055, 0.8914027214050293, 0.8970588445663452, 0.8880090713500977, 0.8925339579582214, 0.8947963714599609, 0.8766968250274658, 0.8902714848518372, 0.8925339579582214]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 5, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4820545 (18.39 MB)\n","Trainable params: 4820033 (18.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.0610 - accuracy: 0.9833"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 8s 65ms/step - loss: 0.0619 - accuracy: 0.9824 - val_loss: 0.7032 - val_accuracy: 0.5176\n","Epoch 2/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0287 - accuracy: 0.9922 - val_loss: 0.6841 - val_accuracy: 0.5496\n","Epoch 3/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0293 - accuracy: 0.9910 - val_loss: 0.6845 - val_accuracy: 0.5475\n","Epoch 4/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0288 - accuracy: 0.9928 - val_loss: 0.6873 - val_accuracy: 0.5640\n","Epoch 5/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0137 - accuracy: 0.9966 - val_loss: 0.8132 - val_accuracy: 0.5444\n","Epoch 6/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 0.7488 - val_accuracy: 0.5671\n","Epoch 7/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0124 - accuracy: 0.9966 - val_loss: 0.7954 - val_accuracy: 0.5847\n","Epoch 8/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0174 - accuracy: 0.9956 - val_loss: 0.7471 - val_accuracy: 0.6178\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0248 - accuracy: 0.9946 - val_loss: 0.7629 - val_accuracy: 0.6136\n","Epoch 10/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0419 - accuracy: 0.9879 - val_loss: 0.6116 - val_accuracy: 0.6973\n","Epoch 11/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0345 - accuracy: 0.9912 - val_loss: 0.6604 - val_accuracy: 0.6818\n","Epoch 12/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0356 - accuracy: 0.9904 - val_loss: 0.6125 - val_accuracy: 0.7076\n","Epoch 13/100\n","31/31 [==============================] - 1s 44ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.6579 - val_accuracy: 0.7097\n","Epoch 14/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.0168 - accuracy: 0.9972 - val_loss: 0.6522 - val_accuracy: 0.7262\n","Epoch 15/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 0.8363 - val_accuracy: 0.7066\n","Epoch 16/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.0128 - accuracy: 0.9982 - val_loss: 0.7754 - val_accuracy: 0.7562\n","Epoch 17/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0124 - accuracy: 0.9982 - val_loss: 0.7775 - val_accuracy: 0.7676\n","Epoch 18/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0236 - accuracy: 0.9935 - val_loss: 0.7019 - val_accuracy: 0.8037\n","Epoch 19/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1299 - accuracy: 0.9607 - val_loss: 0.6160 - val_accuracy: 0.7593\n","Epoch 20/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0242 - accuracy: 0.9951 - val_loss: 0.7630 - val_accuracy: 0.7862\n","Epoch 21/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0146 - accuracy: 0.9966 - val_loss: 0.6585 - val_accuracy: 0.8275\n","Epoch 22/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0099 - accuracy: 0.9984 - val_loss: 0.6454 - val_accuracy: 0.8306\n","Epoch 23/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0089 - accuracy: 0.9995 - val_loss: 0.6463 - val_accuracy: 0.8512\n","Epoch 24/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0095 - accuracy: 0.9990 - val_loss: 0.6138 - val_accuracy: 0.8667\n","Epoch 25/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0083 - accuracy: 0.9995 - val_loss: 0.6094 - val_accuracy: 0.8740\n","Epoch 26/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0084 - accuracy: 0.9995 - val_loss: 0.6106 - val_accuracy: 0.8698\n","Epoch 27/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0080 - accuracy: 0.9995 - val_loss: 0.6068 - val_accuracy: 0.8771\n","Epoch 28/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0078 - accuracy: 0.9995 - val_loss: 0.6128 - val_accuracy: 0.8750\n","Epoch 29/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.0078 - accuracy: 0.9990 - val_loss: 0.6047 - val_accuracy: 0.8781\n","Epoch 30/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.0086 - accuracy: 0.9990 - val_loss: 0.5916 - val_accuracy: 0.8822\n","Epoch 31/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0097 - accuracy: 0.9987 - val_loss: 0.7501 - val_accuracy: 0.8502\n","Epoch 32/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0083 - accuracy: 0.9992 - val_loss: 0.6175 - val_accuracy: 0.8709\n","Epoch 33/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0078 - accuracy: 0.9990 - val_loss: 0.6431 - val_accuracy: 0.8781\n","Epoch 34/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0077 - accuracy: 0.9995 - val_loss: 0.6399 - val_accuracy: 0.8667\n","Epoch 35/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0086 - accuracy: 0.9992 - val_loss: 0.6126 - val_accuracy: 0.8833\n","Epoch 36/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0077 - accuracy: 0.9992 - val_loss: 0.6325 - val_accuracy: 0.8812\n","Epoch 37/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0075 - accuracy: 0.9995 - val_loss: 0.6086 - val_accuracy: 0.8843\n","Epoch 38/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0092 - accuracy: 0.9990 - val_loss: 0.5799 - val_accuracy: 0.8822\n","Epoch 39/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0078 - accuracy: 0.9995 - val_loss: 0.5766 - val_accuracy: 0.8853\n","Epoch 40/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 0.5796 - val_accuracy: 0.8874\n","Epoch 41/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0075 - accuracy: 0.9995 - val_loss: 0.5809 - val_accuracy: 0.8843\n","Epoch 42/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0076 - accuracy: 0.9990 - val_loss: 0.6076 - val_accuracy: 0.8864\n","Epoch 43/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0076 - accuracy: 0.9995 - val_loss: 0.5955 - val_accuracy: 0.8874\n","Epoch 44/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0073 - accuracy: 0.9995 - val_loss: 0.5906 - val_accuracy: 0.8864\n","Epoch 45/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 0.5917 - val_accuracy: 0.8853\n","Epoch 46/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 0.6046 - val_accuracy: 0.8864\n","Epoch 47/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 0.5971 - val_accuracy: 0.8843\n","Epoch 48/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0076 - accuracy: 0.9995 - val_loss: 0.6203 - val_accuracy: 0.8740\n","Epoch 49/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 0.6547 - val_accuracy: 0.8843\n","Epoch 50/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 0.6184 - val_accuracy: 0.8802\n","Epoch 51/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0080 - accuracy: 0.9995 - val_loss: 0.5981 - val_accuracy: 0.8843\n","Epoch 52/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.6346 - val_accuracy: 0.8853\n","Epoch 53/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 0.6073 - val_accuracy: 0.8843\n","Epoch 54/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 0.6206 - val_accuracy: 0.8833\n","Epoch 55/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.6013 - val_accuracy: 0.8864\n","Epoch 56/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 0.6062 - val_accuracy: 0.8843\n","Epoch 57/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 0.6132 - val_accuracy: 0.8853\n","Epoch 58/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0073 - accuracy: 0.9995 - val_loss: 0.6350 - val_accuracy: 0.8750\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0077 - accuracy: 0.9990 - val_loss: 0.6175 - val_accuracy: 0.8833\n","Epoch 60/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0073 - accuracy: 0.9995 - val_loss: 0.6113 - val_accuracy: 0.8802\n","Epoch 61/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 0.6378 - val_accuracy: 0.8833\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0073 - accuracy: 0.9995 - val_loss: 0.6471 - val_accuracy: 0.8760\n","Epoch 63/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 0.6669 - val_accuracy: 0.8812\n","Epoch 64/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 0.6327 - val_accuracy: 0.8781\n","Epoch 65/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.6249 - val_accuracy: 0.8791\n","Epoch 66/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 0.6244 - val_accuracy: 0.8822\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.6643 - val_accuracy: 0.8833\n","Epoch 68/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0075 - accuracy: 0.9995 - val_loss: 0.9801 - val_accuracy: 0.8192\n","Epoch 69/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0772 - accuracy: 0.9731 - val_loss: 0.6245 - val_accuracy: 0.7758\n","Epoch 70/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1015 - accuracy: 0.9661 - val_loss: 0.6629 - val_accuracy: 0.8223\n","Epoch 71/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0716 - accuracy: 0.9767 - val_loss: 0.7327 - val_accuracy: 0.8079\n","Epoch 72/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0584 - accuracy: 0.9824 - val_loss: 0.5701 - val_accuracy: 0.8264\n","Epoch 73/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0847 - accuracy: 0.9708 - val_loss: 0.7445 - val_accuracy: 0.7696\n","Epoch 74/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0317 - accuracy: 0.9920 - val_loss: 0.7477 - val_accuracy: 0.8285\n","Epoch 75/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0287 - accuracy: 0.9920 - val_loss: 0.7677 - val_accuracy: 0.8275\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0343 - accuracy: 0.9917 - val_loss: 0.6675 - val_accuracy: 0.8337\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0569 - accuracy: 0.9824 - val_loss: 0.6618 - val_accuracy: 0.8099\n","Epoch 78/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0346 - accuracy: 0.9904 - val_loss: 0.8426 - val_accuracy: 0.7975\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0287 - accuracy: 0.9915 - val_loss: 0.7503 - val_accuracy: 0.8161\n","Epoch 80/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0162 - accuracy: 0.9966 - val_loss: 0.8040 - val_accuracy: 0.8213\n","Epoch 81/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0125 - accuracy: 0.9987 - val_loss: 0.8966 - val_accuracy: 0.8182\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0203 - accuracy: 0.9953 - val_loss: 0.8191 - val_accuracy: 0.8244\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 0.8047 - val_accuracy: 0.8058\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0146 - accuracy: 0.9979 - val_loss: 0.8043 - val_accuracy: 0.8306\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0221 - accuracy: 0.9951 - val_loss: 0.9344 - val_accuracy: 0.8037\n","Epoch 86/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0261 - accuracy: 0.9928 - val_loss: 0.7884 - val_accuracy: 0.8182\n","Epoch 87/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0179 - accuracy: 0.9959 - val_loss: 0.8326 - val_accuracy: 0.8254\n","Epoch 88/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0135 - accuracy: 0.9974 - val_loss: 0.7887 - val_accuracy: 0.8430\n","Epoch 89/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0209 - accuracy: 0.9956 - val_loss: 0.9513 - val_accuracy: 0.7944\n","Epoch 90/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0251 - accuracy: 0.9922 - val_loss: 0.7550 - val_accuracy: 0.8295\n","Epoch 91/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0160 - accuracy: 0.9977 - val_loss: 0.8726 - val_accuracy: 0.8285\n","Epoch 92/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0231 - accuracy: 0.9938 - val_loss: 1.0218 - val_accuracy: 0.7851\n","Epoch 93/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0293 - accuracy: 0.9922 - val_loss: 0.7879 - val_accuracy: 0.8120\n","Epoch 94/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 0.7694 - val_accuracy: 0.8326\n","Epoch 95/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0123 - accuracy: 0.9979 - val_loss: 0.7731 - val_accuracy: 0.8326\n","Epoch 96/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0090 - accuracy: 0.9990 - val_loss: 0.8127 - val_accuracy: 0.8275\n","Epoch 97/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0077 - accuracy: 0.9995 - val_loss: 0.8041 - val_accuracy: 0.8481\n","Epoch 98/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 0.8638 - val_accuracy: 0.8326\n","Epoch 99/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0113 - accuracy: 0.9979 - val_loss: 0.9818 - val_accuracy: 0.8027\n","Epoch 100/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0129 - accuracy: 0.9979 - val_loss: 0.9011 - val_accuracy: 0.8079\n","{'loss': [0.06186465919017792, 0.0286855548620224, 0.029280878603458405, 0.02878032624721527, 0.013708440586924553, 0.014040244743227959, 0.01244205143302679, 0.017352638766169548, 0.024774964898824692, 0.041867926716804504, 0.03451906889677048, 0.03561408072710037, 0.022327350452542305, 0.016822444275021553, 0.015031171031296253, 0.012832301668822765, 0.012430881150066853, 0.023573899641633034, 0.12991245090961456, 0.024212900549173355, 0.01458833273500204, 0.009919260628521442, 0.00886415597051382, 0.009451345540583134, 0.008263839408755302, 0.008369263261556625, 0.007997342385351658, 0.007754736579954624, 0.007803850341588259, 0.008594481274485588, 0.009709185920655727, 0.008346302434802055, 0.007848170585930347, 0.007721749134361744, 0.008601359091699123, 0.007658191490918398, 0.007474873214960098, 0.009221509099006653, 0.007803307380527258, 0.007371736690402031, 0.007475745398551226, 0.007643610239028931, 0.0076093426905572414, 0.007339545991271734, 0.007372003979980946, 0.007051796652376652, 0.007175755687057972, 0.007642103359103203, 0.007372220978140831, 0.007371838670223951, 0.007971339859068394, 0.007115970831364393, 0.007211234886199236, 0.007052858825773001, 0.0074936808086931705, 0.007144964765757322, 0.007091411389410496, 0.00731896236538887, 0.0076753548346459866, 0.007300276774913073, 0.00698323268443346, 0.007270733825862408, 0.007146262563765049, 0.006976647302508354, 0.007147707510739565, 0.006867538206279278, 0.00690454663708806, 0.007534560281783342, 0.07719289511442184, 0.10146744549274445, 0.07156796753406525, 0.05836190655827522, 0.08474725484848022, 0.03170264512300491, 0.02866373211145401, 0.03427785634994507, 0.056863944977521896, 0.034626320004463196, 0.02872936800122261, 0.01617232896387577, 0.012469915673136711, 0.020286940038204193, 0.025190120562911034, 0.014571183361113071, 0.022084755823016167, 0.026105528697371483, 0.017940113320946693, 0.013460641726851463, 0.020911959931254387, 0.025077102705836296, 0.016001904383301735, 0.02310309372842312, 0.02929370105266571, 0.018264783546328545, 0.012337709777057171, 0.008952314034104347, 0.007710872683674097, 0.007422301918268204, 0.011302267201244831, 0.012945672497153282], 'accuracy': [0.9824289679527283, 0.9922480583190918, 0.9909560680389404, 0.9927648305892944, 0.9966408014297485, 0.9963824152946472, 0.9966408014297485, 0.9956072568893433, 0.9945736527442932, 0.9878553152084351, 0.9912144541740417, 0.9904392957687378, 0.9932816624641418, 0.997157633304596, 0.9968992471694946, 0.998191237449646, 0.998191237449646, 0.9935400485992432, 0.9607235193252563, 0.9950904250144958, 0.9966408014297485, 0.9984496235847473, 0.9994832277297974, 0.99896639585495, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.99896639585495, 0.99896639585495, 0.9987080097198486, 0.9992247819900513, 0.99896639585495, 0.9994832277297974, 0.9992247819900513, 0.9992247819900513, 0.9994832277297974, 0.99896639585495, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.99896639585495, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.9992247819900513, 0.9994832277297974, 0.9994832277297974, 0.9992247819900513, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.99896639585495, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 0.9992247819900513, 0.9994832277297974, 0.9992247819900513, 0.9994832277297974, 0.9731265902519226, 0.9661498665809631, 0.9767441749572754, 0.9824289679527283, 0.970801055431366, 0.9919896721839905, 0.9919896721839905, 0.9917312860488892, 0.9824289679527283, 0.9904392957687378, 0.9914728403091431, 0.9966408014297485, 0.9987080097198486, 0.9953488111495972, 0.9932816624641418, 0.9979327917098999, 0.9950904250144958, 0.9927648305892944, 0.9958656430244446, 0.9974160194396973, 0.9956072568893433, 0.9922480583190918, 0.9976744055747986, 0.9937984347343445, 0.9922480583190918, 0.9950904250144958, 0.9979327917098999, 0.99896639585495, 0.9994832277297974, 0.9994832277297974, 0.9979327917098999, 0.9979327917098999], 'val_loss': [0.7031692266464233, 0.6840925812721252, 0.6844834089279175, 0.6872974038124084, 0.8131991028785706, 0.7487701773643494, 0.7954083681106567, 0.7470998167991638, 0.7628763914108276, 0.6116167306900024, 0.6604211330413818, 0.6124909520149231, 0.6578775644302368, 0.6521683931350708, 0.836287260055542, 0.7753961086273193, 0.7774759531021118, 0.7019069790840149, 0.6160390377044678, 0.7629917860031128, 0.6585333347320557, 0.6453733444213867, 0.6463066935539246, 0.6137805581092834, 0.6094232201576233, 0.6105934977531433, 0.6068298816680908, 0.6128352284431458, 0.6046969890594482, 0.5915766358375549, 0.7500647902488708, 0.6174675226211548, 0.6430535912513733, 0.6399252414703369, 0.6126028895378113, 0.6325140595436096, 0.6086224913597107, 0.5799127817153931, 0.576582670211792, 0.5796387195587158, 0.580937385559082, 0.6075772643089294, 0.5954869985580444, 0.5905978679656982, 0.5916703939437866, 0.604624330997467, 0.5970643162727356, 0.6203016042709351, 0.6547484993934631, 0.6184380650520325, 0.5980991721153259, 0.6345913410186768, 0.6072679162025452, 0.6205587387084961, 0.6012845635414124, 0.6062284111976624, 0.6131853461265564, 0.6350246667861938, 0.61753249168396, 0.6113377809524536, 0.6377911567687988, 0.6471223831176758, 0.6668703556060791, 0.6326544880867004, 0.6248877644538879, 0.6243776679039001, 0.664349377155304, 0.9800500273704529, 0.6244547367095947, 0.6629133224487305, 0.73273104429245, 0.570134699344635, 0.7445247173309326, 0.7476946711540222, 0.7676799893379211, 0.6674767732620239, 0.6618435978889465, 0.8425562381744385, 0.750342845916748, 0.8040488362312317, 0.8965927362442017, 0.8191332817077637, 0.8047086000442505, 0.8043309450149536, 0.934408962726593, 0.7884227633476257, 0.8326427340507507, 0.7887386679649353, 0.9513141512870789, 0.7550190091133118, 0.872585117816925, 1.02182936668396, 0.7878825068473816, 0.7693564891815186, 0.7731022238731384, 0.8126915693283081, 0.8040758967399597, 0.8637893795967102, 0.9817688465118408, 0.9011157155036926], 'val_accuracy': [0.5175619721412659, 0.5495867729187012, 0.547520637512207, 0.5640496015548706, 0.5444214940071106, 0.567148745059967, 0.5847107172012329, 0.6177685856819153, 0.6136363744735718, 0.6973140239715576, 0.6818181872367859, 0.7076446413993835, 0.7097107172012329, 0.7262396812438965, 0.7066115736961365, 0.7561983466148376, 0.7675619721412659, 0.8037189841270447, 0.7592975497245789, 0.7861570119857788, 0.827479362487793, 0.8305785059928894, 0.8512396812438965, 0.8667355179786682, 0.8739669322967529, 0.8698347210884094, 0.8770661354064941, 0.875, 0.8780992031097412, 0.8822314143180847, 0.8502066135406494, 0.8708677887916565, 0.8780992031097412, 0.8667355179786682, 0.8832644820213318, 0.8811983466148376, 0.8842975497245789, 0.8822314143180847, 0.8853305578231812, 0.8873966932296753, 0.8842975497245789, 0.8863636255264282, 0.8873966932296753, 0.8863636255264282, 0.8853305578231812, 0.8863636255264282, 0.8842975497245789, 0.8739669322967529, 0.8842975497245789, 0.8801652789115906, 0.8842975497245789, 0.8853305578231812, 0.8842975497245789, 0.8832644820213318, 0.8863636255264282, 0.8842975497245789, 0.8853305578231812, 0.875, 0.8832644820213318, 0.8801652789115906, 0.8832644820213318, 0.8760330677032471, 0.8811983466148376, 0.8780992031097412, 0.8791322112083435, 0.8822314143180847, 0.8832644820213318, 0.8192148804664612, 0.7758264541625977, 0.8223140239715576, 0.807851254940033, 0.8264462947845459, 0.76962810754776, 0.8285123705863953, 0.827479362487793, 0.8336777091026306, 0.8099173307418823, 0.797520637512207, 0.81611567735672, 0.8212810158729553, 0.8181818127632141, 0.8243801593780518, 0.8057851195335388, 0.8305785059928894, 0.8037189841270447, 0.8181818127632141, 0.8254132270812988, 0.8429751992225647, 0.7944214940071106, 0.8295454382896423, 0.8285123705863953, 0.7851239442825317, 0.8119834661483765, 0.8326446413993835, 0.8326446413993835, 0.827479362487793, 0.8481404781341553, 0.8326446413993835, 0.8026859760284424, 0.807851254940033]}\n","32/32 [==============================] - 1s 5ms/step\n"]}]},{"cell_type":"code","source":["\n","metrics_df.round(3)"],"metadata":{"id":"Ik5JoVP2NPvY","colab":{"base_uri":"https://localhost:8080/","height":519},"executionInfo":{"status":"ok","timestamp":1717529715827,"user_tz":-360,"elapsed":10,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"53b263c5-f7c9-454e-a2c7-45d43b932cc9"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.582      0.604   0.477  0.533        0.477        0.687   \n","1        1     0.614      0.623   0.579  0.600        0.579        0.650   \n","2        2     0.646      0.664   0.588  0.624        0.588        0.703   \n","3        0     0.647      0.634   0.693  0.662        0.693        0.600   \n","4        1     0.668      0.737   0.523  0.612        0.523        0.814   \n","5        2     0.654      0.685   0.568  0.621        0.568        0.739   \n","6        0     0.726      0.704   0.781  0.740        0.781        0.672   \n","7        1     0.782      0.787   0.775  0.781        0.775        0.790   \n","8        2     0.804      0.798   0.815  0.806        0.815        0.793   \n","9        0     0.786      0.784   0.789  0.786        0.789        0.782   \n","10       1     0.851      0.848   0.856  0.852        0.856        0.846   \n","11       2     0.834      0.854   0.807  0.830        0.807        0.861   \n","12       0     0.861      0.865   0.856  0.860        0.856        0.866   \n","13       1     0.873      0.899   0.840  0.869        0.840        0.905   \n","14       2     0.882      0.878   0.886  0.882        0.886        0.878   \n","\n","    Kappa  \n","0   0.164  \n","1   0.229  \n","2   0.291  \n","3   0.293  \n","4   0.336  \n","5   0.307  \n","6   0.452  \n","7   0.565  \n","8   0.608  \n","9   0.571  \n","10  0.702  \n","11  0.669  \n","12  0.722  \n","13  0.746  \n","14  0.763  "],"text/html":["\n","  <div id=\"df-d88bcd1b-273c-4b9f-8a94-5f7c51663444\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.582</td>\n","      <td>0.604</td>\n","      <td>0.477</td>\n","      <td>0.533</td>\n","      <td>0.477</td>\n","      <td>0.687</td>\n","      <td>0.164</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.614</td>\n","      <td>0.623</td>\n","      <td>0.579</td>\n","      <td>0.600</td>\n","      <td>0.579</td>\n","      <td>0.650</td>\n","      <td>0.229</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.646</td>\n","      <td>0.664</td>\n","      <td>0.588</td>\n","      <td>0.624</td>\n","      <td>0.588</td>\n","      <td>0.703</td>\n","      <td>0.291</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.647</td>\n","      <td>0.634</td>\n","      <td>0.693</td>\n","      <td>0.662</td>\n","      <td>0.693</td>\n","      <td>0.600</td>\n","      <td>0.293</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.668</td>\n","      <td>0.737</td>\n","      <td>0.523</td>\n","      <td>0.612</td>\n","      <td>0.523</td>\n","      <td>0.814</td>\n","      <td>0.336</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.654</td>\n","      <td>0.685</td>\n","      <td>0.568</td>\n","      <td>0.621</td>\n","      <td>0.568</td>\n","      <td>0.739</td>\n","      <td>0.307</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.726</td>\n","      <td>0.704</td>\n","      <td>0.781</td>\n","      <td>0.740</td>\n","      <td>0.781</td>\n","      <td>0.672</td>\n","      <td>0.452</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.782</td>\n","      <td>0.787</td>\n","      <td>0.775</td>\n","      <td>0.781</td>\n","      <td>0.775</td>\n","      <td>0.790</td>\n","      <td>0.565</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.804</td>\n","      <td>0.798</td>\n","      <td>0.815</td>\n","      <td>0.806</td>\n","      <td>0.815</td>\n","      <td>0.793</td>\n","      <td>0.608</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.786</td>\n","      <td>0.784</td>\n","      <td>0.789</td>\n","      <td>0.786</td>\n","      <td>0.789</td>\n","      <td>0.782</td>\n","      <td>0.571</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.851</td>\n","      <td>0.848</td>\n","      <td>0.856</td>\n","      <td>0.852</td>\n","      <td>0.856</td>\n","      <td>0.846</td>\n","      <td>0.702</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.834</td>\n","      <td>0.854</td>\n","      <td>0.807</td>\n","      <td>0.830</td>\n","      <td>0.807</td>\n","      <td>0.861</td>\n","      <td>0.669</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.861</td>\n","      <td>0.865</td>\n","      <td>0.856</td>\n","      <td>0.860</td>\n","      <td>0.856</td>\n","      <td>0.866</td>\n","      <td>0.722</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.873</td>\n","      <td>0.899</td>\n","      <td>0.840</td>\n","      <td>0.869</td>\n","      <td>0.840</td>\n","      <td>0.905</td>\n","      <td>0.746</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.882</td>\n","      <td>0.878</td>\n","      <td>0.886</td>\n","      <td>0.882</td>\n","      <td>0.886</td>\n","      <td>0.878</td>\n","      <td>0.763</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d88bcd1b-273c-4b9f-8a94-5f7c51663444')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d88bcd1b-273c-4b9f-8a94-5f7c51663444 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d88bcd1b-273c-4b9f-8a94-5f7c51663444');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b79a2b6f-3782-4174-8c49-d4c90b4e3e96\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b79a2b6f-3782-4174-8c49-d4c90b4e3e96')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b79a2b6f-3782-4174-8c49-d4c90b4e3e96 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10417064754298022,\n        \"min\": 0.582,\n        \"max\": 0.882,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.786,\n          0.834,\n          0.582\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10035636501986309,\n        \"min\": 0.604,\n        \"max\": 0.899,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.784,\n          0.854,\n          0.604\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13783333621235674,\n        \"min\": 0.477,\n        \"max\": 0.886,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.789,\n          0.807,\n          0.477\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11723553824916501,\n        \"min\": 0.533,\n        \"max\": 0.882,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.786,\n          0.83,\n          0.533\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13783333621235674,\n        \"min\": 0.477,\n        \"max\": 0.886,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.789,\n          0.807,\n          0.477\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09309273410345806,\n        \"min\": 0.6,\n        \"max\": 0.905,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.782,\n          0.861,\n          0.687\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2084178038277463,\n        \"min\": 0.164,\n        \"max\": 0.763,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.571,\n          0.669,\n          0.164\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["metrics_df.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/DWT/CNN_LSTM/Delta_DWT_CNN_LSTM.csv', index = False)"],"metadata":{"id":"Ncf_cMAQF6g4","executionInfo":{"status":"ok","timestamp":1717529717776,"user_tz":-360,"elapsed":1956,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# CNN-LSTM Graph"],"metadata":{"id":"ZUR_QwblhNjJ"}},{"cell_type":"code","source":["import wandb\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import re\n","import seaborn as sns\n","\n","# Initialize the API\n","api = wandb.Api()\n","\n","# Specify the entity and project\n","entity = \"raihanrabby\"\n","project = \"Beta_time_domain_CNN_Lstm\"\n","\n","# Fetch all runs from the project\n","runs = api.runs(f\"{entity}/{project}\")\n","\n","# List to store the dataframes\n","dataframes = []\n","\n","# Iterate over each run and fetch the history\n","for run in runs:\n","    # Fetch the history for each run\n","    history = run.history()\n","\n","    # Add columns to identify the run, model name, epoch, and client\n","    history['run_id'] = run.id\n","    history['model_name'] = run.name\n","\n","    # Extract epoch and client from model name\n","    match = re.match(r'epoch_(\\d+)_client_(\\d+)', run.name)\n","    if match:\n","        history['epoch_number'] = int(match.group(1))\n","        history['client_number'] = int(match.group(2))\n","    else:\n","        history['epoch_number'] = None\n","        history['client_number'] = None\n","\n","    # Append to the list of dataframes\n","    dataframes.append(history)\n","\n","# Concatenate all dataframes into a single dataframe\n","all_metrics_df = pd.concat(dataframes)\n","\n","# Filter out rows with None epoch_number\n","all_metrics_df = all_metrics_df.dropna(subset=['epoch_number'])\n","\n","# Get the unique epochs\n","unique_epochs = sorted(all_metrics_df['epoch_number'].unique())\n","\n","# Set the Seaborn style\n","sns.set(style=\"whitegrid\")\n","\n","# Create subplots for each epoch\n","fig, axes = plt.subplots(2, len(unique_epochs), figsize=(len(unique_epochs) * 3, 4.5), sharex=True)\n","\n","# Set the color palette\n","palette = sns.color_palette(\"Set1\", n_colors=all_metrics_df['client_number'].nunique())\n","\n","# Store the lines and labels for the legend\n","lines = []\n","labels = []\n","\n","# Iterate through each epoch and plot the training and validation accuracy\n","for i, epoch in enumerate(unique_epochs):\n","    epoch_df = all_metrics_df[all_metrics_df['epoch_number'] == epoch]\n","    for j, client in enumerate(epoch_df['client_number'].unique()):\n","        client_df = epoch_df[epoch_df['client_number'] == client]\n","        line, = axes[0, i].plot(client_df['accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","        axes[1, i].plot(client_df['val_accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","\n","        if i == 0:\n","            lines.append(line)\n","            labels.append(f'Client {client}')\n","\n","    axes[0, i].set_title(f'Epoch {epoch}', fontsize=12, fontweight='bold')\n","    axes[0, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","    axes[1, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","    # axes[0, i].set_ylim(0.5)  # Ensure y-axis covers full range of accuracy\n","    axes[1, i].set_ylim(0.5, 1.0)  # Ensure y-axis covers full range of accuracy\n","    axes[1, i].set_xlabel('Steps', fontsize=10, fontweight='bold')\n","    axes[0, i].grid(True)\n","    axes[1, i].grid(True)\n","    axes[0, i].tick_params(axis='both', which='major', labelsize=10)\n","    axes[1, i].tick_params(axis='both', which='major', labelsize=10)\n","\n","# Add a single legend for the entire figure\n","fig.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 1.0), ncol=len(labels), fontsize=10, frameon=True)\n","\n","# Add row labels\n","fig.text(0.04, 0.75, 'Training Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","fig.text(0.04, 0.25, 'Validation Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","\n","plt.tight_layout(rect=[0.05, 0, 1, 0.95])\n","plt.subplots_adjust(hspace=0.2, top=0.88)  # Add some space between the rows and reduce space between the legend and plot\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":462},"id":"zdihdEQAk8x9","executionInfo":{"status":"ok","timestamp":1716740043376,"user_tz":-360,"elapsed":15427,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"6f210444-99b7-4a2d-e54d-c63ffe64373a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x450 with 10 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"F0IzJ6S5k8vk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_metrics_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"dF-KSdKdhsqv","executionInfo":{"status":"ok","timestamp":1716636800286,"user_tz":-360,"elapsed":373,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"468ed3c0-e85c-4f92-da49-0afecd4c142c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      _runtime  accuracy  val_loss    _timestamp  val_accuracy      loss  \\\n","0    13.310213  0.894723  0.860759  1.716588e+09      0.504283  0.247455   \n","1    22.364346  0.917493  0.848398  1.716588e+09      0.504283  0.195490   \n","2    33.860330  0.914814  0.825522  1.716588e+09      0.504283  0.204736   \n","3    43.363837  0.909992  0.825889  1.716588e+09      0.504283  0.208303   \n","4    44.307076  0.922047  0.801610  1.716588e+09      0.504283  0.188477   \n","..         ...       ...       ...           ...           ...       ...   \n","95  416.614793  0.788910  0.553507  1.716585e+09      0.730193  0.455315   \n","96  417.041695  0.782213  0.548009  1.716585e+09      0.732334  0.458011   \n","97  417.444440  0.778998  0.550679  1.716585e+09      0.729122  0.459626   \n","98  417.884801  0.792660  0.559028  1.716585e+09      0.722698  0.451855   \n","99  418.304440  0.782748  0.551085  1.716585e+09      0.729122  0.454946   \n","\n","    _step  epoch    run_id  \n","0       0      0  2nsbmzjb  \n","1       1      1  2nsbmzjb  \n","2       2      2  2nsbmzjb  \n","3       3      3  2nsbmzjb  \n","4       4      4  2nsbmzjb  \n","..    ...    ...       ...  \n","95     95     95  u6ki5wej  \n","96     96     96  u6ki5wej  \n","97     97     97  u6ki5wej  \n","98     98     98  u6ki5wej  \n","99     99     99  u6ki5wej  \n","\n","[1500 rows x 9 columns]"],"text/html":["\n","  <div id=\"df-c54c6cd2-19dd-4a84-90fb-57f868070b89\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>_runtime</th>\n","      <th>accuracy</th>\n","      <th>val_loss</th>\n","      <th>_timestamp</th>\n","      <th>val_accuracy</th>\n","      <th>loss</th>\n","      <th>_step</th>\n","      <th>epoch</th>\n","      <th>run_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>13.310213</td>\n","      <td>0.894723</td>\n","      <td>0.860759</td>\n","      <td>1.716588e+09</td>\n","      <td>0.504283</td>\n","      <td>0.247455</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2nsbmzjb</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>22.364346</td>\n","      <td>0.917493</td>\n","      <td>0.848398</td>\n","      <td>1.716588e+09</td>\n","      <td>0.504283</td>\n","      <td>0.195490</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2nsbmzjb</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>33.860330</td>\n","      <td>0.914814</td>\n","      <td>0.825522</td>\n","      <td>1.716588e+09</td>\n","      <td>0.504283</td>\n","      <td>0.204736</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2nsbmzjb</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>43.363837</td>\n","      <td>0.909992</td>\n","      <td>0.825889</td>\n","      <td>1.716588e+09</td>\n","      <td>0.504283</td>\n","      <td>0.208303</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2nsbmzjb</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>44.307076</td>\n","      <td>0.922047</td>\n","      <td>0.801610</td>\n","      <td>1.716588e+09</td>\n","      <td>0.504283</td>\n","      <td>0.188477</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>2nsbmzjb</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>416.614793</td>\n","      <td>0.788910</td>\n","      <td>0.553507</td>\n","      <td>1.716585e+09</td>\n","      <td>0.730193</td>\n","      <td>0.455315</td>\n","      <td>95</td>\n","      <td>95</td>\n","      <td>u6ki5wej</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>417.041695</td>\n","      <td>0.782213</td>\n","      <td>0.548009</td>\n","      <td>1.716585e+09</td>\n","      <td>0.732334</td>\n","      <td>0.458011</td>\n","      <td>96</td>\n","      <td>96</td>\n","      <td>u6ki5wej</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>417.444440</td>\n","      <td>0.778998</td>\n","      <td>0.550679</td>\n","      <td>1.716585e+09</td>\n","      <td>0.729122</td>\n","      <td>0.459626</td>\n","      <td>97</td>\n","      <td>97</td>\n","      <td>u6ki5wej</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>417.884801</td>\n","      <td>0.792660</td>\n","      <td>0.559028</td>\n","      <td>1.716585e+09</td>\n","      <td>0.722698</td>\n","      <td>0.451855</td>\n","      <td>98</td>\n","      <td>98</td>\n","      <td>u6ki5wej</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>418.304440</td>\n","      <td>0.782748</td>\n","      <td>0.551085</td>\n","      <td>1.716585e+09</td>\n","      <td>0.729122</td>\n","      <td>0.454946</td>\n","      <td>99</td>\n","      <td>99</td>\n","      <td>u6ki5wej</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1500 rows × 9 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c54c6cd2-19dd-4a84-90fb-57f868070b89')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c54c6cd2-19dd-4a84-90fb-57f868070b89 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c54c6cd2-19dd-4a84-90fb-57f868070b89');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d2db8c50-ed3f-4d64-8b19-fc6d9c84f4c6\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2db8c50-ed3f-4d64-8b19-fc6d9c84f4c6')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d2db8c50-ed3f-4d64-8b19-fc6d9c84f4c6 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_af67ca15-c1be-45e1-84f8-5c85a974368d\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('all_metrics_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_af67ca15-c1be-45e1-84f8-5c85a974368d button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('all_metrics_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"all_metrics_df","summary":"{\n  \"name\": \"all_metrics_df\",\n  \"rows\": 1500,\n  \"fields\": [\n    {\n      \"column\": \"_runtime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 88.45497529136644,\n        \"min\": 10.388507843017578,\n        \"max\": 525.9502971172333,\n        \"num_unique_values\": 1499,\n        \"samples\": [\n          171.23451471328735,\n          514.5650720596313,\n          154.19228529930115\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08458249714165784,\n        \"min\": 0.5001339316368103,\n        \"max\": 0.9694615602493286,\n        \"num_unique_values\": 773,\n        \"samples\": [\n          0.8494508266448975,\n          0.7013126015663147,\n          0.7811411619186401\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07423729060194581,\n        \"min\": 0.42367106676101685,\n        \"max\": 0.898168683052063,\n        \"num_unique_values\": 1498,\n        \"samples\": [\n          0.49998635053634644,\n          0.6923187971115112,\n          0.5667726397514343\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_timestamp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1152.2215388098273,\n        \"min\": 1716584329.3731794,\n        \"max\": 1716588576.7424233,\n        \"num_unique_values\": 1500,\n        \"samples\": [\n          1716585811.4945405,\n          1716585200.7616174,\n          1716587598.5155294\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08631999854487923,\n        \"min\": 0.4860813617706299,\n        \"max\": 0.835117757320404,\n        \"num_unique_values\": 240,\n        \"samples\": [\n          0.7644539475440979,\n          0.5920770764350891,\n          0.5224839448928833\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1503027321511436,\n        \"min\": 0.08336261659860611,\n        \"max\": 0.6930587291717529,\n        \"num_unique_values\": 1500,\n        \"samples\": [\n          0.46639472246170044,\n          0.4926566481590271,\n          0.23360194265842438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_step\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          83,\n          53,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          83,\n          53,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"run_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"0ebggn8j\",\n          \"tsl17cy8\",\n          \"2nsbmzjb\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["# CNN"],"metadata":{"id":"QUuWzfMHSNmi"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    # model.add(Dropout(0.5))\n","    # model.add(LSTM(256, return_sequences=True))\n","    # model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Delta/CNN/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Delta/CNN/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"8xrx_fxBSWGd","executionInfo":{"status":"ok","timestamp":1717529717791,"user_tz":-360,"elapsed":12,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["global_model_CNN, metrics_df_CNN = federated_learning(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1TaNdIbSfkq","outputId":"7337cf53-5e4a-4ba3-ea9c-da365c59e783","executionInfo":{"status":"ok","timestamp":1717530847356,"user_tz":-360,"elapsed":1129577,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"collapsed":true},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 2.0188 - accuracy: 0.5106"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 56ms/step - loss: 2.0183 - accuracy: 0.5116 - val_loss: 2.0050 - val_accuracy: 0.4860\n","Epoch 2/100\n","29/29 [==============================] - 1s 47ms/step - loss: 1.9927 - accuracy: 0.5323 - val_loss: 1.9864 - val_accuracy: 0.5873\n","Epoch 3/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.9716 - accuracy: 0.5450 - val_loss: 1.9685 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.9493 - accuracy: 0.5706 - val_loss: 1.9503 - val_accuracy: 0.4957\n","Epoch 5/100\n","29/29 [==============================] - 1s 38ms/step - loss: 1.9288 - accuracy: 0.5706 - val_loss: 1.9327 - val_accuracy: 0.4763\n","Epoch 6/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.9079 - accuracy: 0.5698 - val_loss: 1.9144 - val_accuracy: 0.5841\n","Epoch 7/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.8900 - accuracy: 0.5733 - val_loss: 1.8970 - val_accuracy: 0.5205\n","Epoch 8/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.8696 - accuracy: 0.5781 - val_loss: 1.8804 - val_accuracy: 0.4860\n","Epoch 9/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.8529 - accuracy: 0.5733 - val_loss: 1.8636 - val_accuracy: 0.4849\n","Epoch 10/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.8317 - accuracy: 0.5849 - val_loss: 1.8445 - val_accuracy: 0.5668\n","Epoch 11/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.8122 - accuracy: 0.5991 - val_loss: 1.8281 - val_accuracy: 0.5603\n","Epoch 12/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.7937 - accuracy: 0.5938 - val_loss: 1.8134 - val_accuracy: 0.5011\n","Epoch 13/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.7811 - accuracy: 0.5927 - val_loss: 1.7994 - val_accuracy: 0.4978\n","Epoch 14/100\n","29/29 [==============================] - 1s 40ms/step - loss: 1.7629 - accuracy: 0.5905 - val_loss: 1.7760 - val_accuracy: 0.5894\n","Epoch 15/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.7436 - accuracy: 0.6067 - val_loss: 1.7632 - val_accuracy: 0.5366\n","Epoch 16/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.7249 - accuracy: 0.6199 - val_loss: 1.7436 - val_accuracy: 0.5754\n","Epoch 17/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.7079 - accuracy: 0.6202 - val_loss: 1.7285 - val_accuracy: 0.5690\n","Epoch 18/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.6942 - accuracy: 0.6255 - val_loss: 1.7118 - val_accuracy: 0.5862\n","Epoch 19/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.6769 - accuracy: 0.6263 - val_loss: 1.6974 - val_accuracy: 0.5765\n","Epoch 20/100\n","29/29 [==============================] - 1s 35ms/step - loss: 1.6638 - accuracy: 0.6177 - val_loss: 1.6803 - val_accuracy: 0.6024\n","Epoch 21/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.6473 - accuracy: 0.6312 - val_loss: 1.6719 - val_accuracy: 0.5700\n","Epoch 22/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.6318 - accuracy: 0.6360 - val_loss: 1.6534 - val_accuracy: 0.5991\n","Epoch 23/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.6194 - accuracy: 0.6387 - val_loss: 1.6511 - val_accuracy: 0.5679\n","Epoch 24/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.6089 - accuracy: 0.6460 - val_loss: 1.6376 - val_accuracy: 0.5733\n","Epoch 25/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.5903 - accuracy: 0.6487 - val_loss: 1.6301 - val_accuracy: 0.5711\n","Epoch 26/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.5848 - accuracy: 0.6404 - val_loss: 1.6159 - val_accuracy: 0.5797\n","Epoch 27/100\n","29/29 [==============================] - 1s 35ms/step - loss: 1.5643 - accuracy: 0.6546 - val_loss: 1.5989 - val_accuracy: 0.5851\n","Epoch 28/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.5517 - accuracy: 0.6546 - val_loss: 1.5876 - val_accuracy: 0.5808\n","Epoch 29/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.5373 - accuracy: 0.6643 - val_loss: 1.5786 - val_accuracy: 0.5884\n","Epoch 30/100\n","29/29 [==============================] - 2s 75ms/step - loss: 1.5280 - accuracy: 0.6557 - val_loss: 1.5590 - val_accuracy: 0.6185\n","Epoch 31/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5153 - accuracy: 0.6606 - val_loss: 1.5484 - val_accuracy: 0.6185\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5018 - accuracy: 0.6695 - val_loss: 1.5375 - val_accuracy: 0.6110\n","Epoch 33/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.4884 - accuracy: 0.6719 - val_loss: 1.5270 - val_accuracy: 0.6272\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4792 - accuracy: 0.6711 - val_loss: 1.5197 - val_accuracy: 0.6078\n","Epoch 35/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4715 - accuracy: 0.6730 - val_loss: 1.5086 - val_accuracy: 0.6207\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4594 - accuracy: 0.6692 - val_loss: 1.4989 - val_accuracy: 0.6175\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4430 - accuracy: 0.6727 - val_loss: 1.4954 - val_accuracy: 0.5981\n","Epoch 38/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.4325 - accuracy: 0.6800 - val_loss: 1.4880 - val_accuracy: 0.6121\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4262 - accuracy: 0.6756 - val_loss: 1.4736 - val_accuracy: 0.6142\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4118 - accuracy: 0.6862 - val_loss: 1.4632 - val_accuracy: 0.6207\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4032 - accuracy: 0.6808 - val_loss: 1.4555 - val_accuracy: 0.6175\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3913 - accuracy: 0.6899 - val_loss: 1.4505 - val_accuracy: 0.6078\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3798 - accuracy: 0.6921 - val_loss: 1.4456 - val_accuracy: 0.6024\n","Epoch 44/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.3692 - accuracy: 0.6961 - val_loss: 1.4299 - val_accuracy: 0.6196\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3620 - accuracy: 0.6845 - val_loss: 1.4311 - val_accuracy: 0.6013\n","Epoch 46/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.3520 - accuracy: 0.6983 - val_loss: 1.4148 - val_accuracy: 0.6207\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3412 - accuracy: 0.6969 - val_loss: 1.4068 - val_accuracy: 0.6185\n","Epoch 48/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3314 - accuracy: 0.7042 - val_loss: 1.4036 - val_accuracy: 0.6218\n","Epoch 49/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3298 - accuracy: 0.6899 - val_loss: 1.3990 - val_accuracy: 0.6034\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3138 - accuracy: 0.7034 - val_loss: 1.3920 - val_accuracy: 0.6250\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3059 - accuracy: 0.7004 - val_loss: 1.3802 - val_accuracy: 0.6218\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2974 - accuracy: 0.7053 - val_loss: 1.3753 - val_accuracy: 0.6261\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2876 - accuracy: 0.7058 - val_loss: 1.3727 - val_accuracy: 0.6088\n","Epoch 54/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.2838 - accuracy: 0.7069 - val_loss: 1.3782 - val_accuracy: 0.6013\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2739 - accuracy: 0.7018 - val_loss: 1.3549 - val_accuracy: 0.6078\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2609 - accuracy: 0.7150 - val_loss: 1.3513 - val_accuracy: 0.6013\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2636 - accuracy: 0.6950 - val_loss: 1.3381 - val_accuracy: 0.6034\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2475 - accuracy: 0.7117 - val_loss: 1.3342 - val_accuracy: 0.6078\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2419 - accuracy: 0.7163 - val_loss: 1.3264 - val_accuracy: 0.6078\n","Epoch 60/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2290 - accuracy: 0.7223 - val_loss: 1.3222 - val_accuracy: 0.6024\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2250 - accuracy: 0.7112 - val_loss: 1.3191 - val_accuracy: 0.6261\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2167 - accuracy: 0.7109 - val_loss: 1.3118 - val_accuracy: 0.6131\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2061 - accuracy: 0.7247 - val_loss: 1.3132 - val_accuracy: 0.6121\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2049 - accuracy: 0.7169 - val_loss: 1.3095 - val_accuracy: 0.6067\n","Epoch 65/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1920 - accuracy: 0.7276 - val_loss: 1.2987 - val_accuracy: 0.6207\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1866 - accuracy: 0.7260 - val_loss: 1.2900 - val_accuracy: 0.6207\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1737 - accuracy: 0.7360 - val_loss: 1.2895 - val_accuracy: 0.6175\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1715 - accuracy: 0.7301 - val_loss: 1.2798 - val_accuracy: 0.6196\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1596 - accuracy: 0.7376 - val_loss: 1.2931 - val_accuracy: 0.6034\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1553 - accuracy: 0.7328 - val_loss: 1.2755 - val_accuracy: 0.6239\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1440 - accuracy: 0.7462 - val_loss: 1.2797 - val_accuracy: 0.6088\n","Epoch 72/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1403 - accuracy: 0.7438 - val_loss: 1.2718 - val_accuracy: 0.6175\n","Epoch 73/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1315 - accuracy: 0.7468 - val_loss: 1.2664 - val_accuracy: 0.6207\n","Epoch 74/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1332 - accuracy: 0.7322 - val_loss: 1.2532 - val_accuracy: 0.6239\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1248 - accuracy: 0.7371 - val_loss: 1.2525 - val_accuracy: 0.6164\n","Epoch 76/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1105 - accuracy: 0.7481 - val_loss: 1.2496 - val_accuracy: 0.6272\n","Epoch 77/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1041 - accuracy: 0.7567 - val_loss: 1.2539 - val_accuracy: 0.6153\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0970 - accuracy: 0.7562 - val_loss: 1.2385 - val_accuracy: 0.6228\n","Epoch 79/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.0892 - accuracy: 0.7548 - val_loss: 1.2472 - val_accuracy: 0.6185\n","Epoch 80/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0924 - accuracy: 0.7495 - val_loss: 1.2915 - val_accuracy: 0.5722\n","Epoch 81/100\n","29/29 [==============================] - 2s 58ms/step - loss: 1.0781 - accuracy: 0.7573 - val_loss: 1.2322 - val_accuracy: 0.6282\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0722 - accuracy: 0.7581 - val_loss: 1.2323 - val_accuracy: 0.6175\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0614 - accuracy: 0.7691 - val_loss: 1.2324 - val_accuracy: 0.6185\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0676 - accuracy: 0.7522 - val_loss: 1.2535 - val_accuracy: 0.5884\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0667 - accuracy: 0.7427 - val_loss: 1.2486 - val_accuracy: 0.5959\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0458 - accuracy: 0.7670 - val_loss: 1.2145 - val_accuracy: 0.6207\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0366 - accuracy: 0.7683 - val_loss: 1.2207 - val_accuracy: 0.6164\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0358 - accuracy: 0.7619 - val_loss: 1.2520 - val_accuracy: 0.5862\n","Epoch 89/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0331 - accuracy: 0.7645 - val_loss: 1.2050 - val_accuracy: 0.6261\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0156 - accuracy: 0.7786 - val_loss: 1.2062 - val_accuracy: 0.6218\n","Epoch 91/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.0117 - accuracy: 0.7810 - val_loss: 1.2035 - val_accuracy: 0.6304\n","Epoch 92/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0111 - accuracy: 0.7718 - val_loss: 1.1995 - val_accuracy: 0.6293\n","Epoch 93/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0097 - accuracy: 0.7629 - val_loss: 1.2296 - val_accuracy: 0.5948\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0055 - accuracy: 0.7718 - val_loss: 1.1983 - val_accuracy: 0.6218\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9950 - accuracy: 0.7745 - val_loss: 1.1937 - val_accuracy: 0.6293\n","Epoch 96/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9834 - accuracy: 0.7899 - val_loss: 1.1953 - val_accuracy: 0.6239\n","Epoch 97/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9837 - accuracy: 0.7767 - val_loss: 1.2365 - val_accuracy: 0.5905\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9715 - accuracy: 0.7982 - val_loss: 1.2084 - val_accuracy: 0.6056\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9621 - accuracy: 0.7988 - val_loss: 1.1956 - val_accuracy: 0.6164\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9603 - accuracy: 0.7907 - val_loss: 1.2304 - val_accuracy: 0.5938\n","{'loss': [2.0183165073394775, 1.9926533699035645, 1.9715855121612549, 1.9492647647857666, 1.9287887811660767, 1.9078716039657593, 1.8899502754211426, 1.8695975542068481, 1.852935552597046, 1.8316930532455444, 1.8122262954711914, 1.7937290668487549, 1.7811028957366943, 1.7629063129425049, 1.743580937385559, 1.7248839139938354, 1.7079145908355713, 1.694206953048706, 1.6768951416015625, 1.663794755935669, 1.6472575664520264, 1.631796956062317, 1.6193872690200806, 1.6088838577270508, 1.5902934074401855, 1.5848113298416138, 1.5643407106399536, 1.5516784191131592, 1.537285327911377, 1.5280139446258545, 1.5152753591537476, 1.5018168687820435, 1.4884499311447144, 1.4791563749313354, 1.4715287685394287, 1.4593514204025269, 1.4429835081100464, 1.432466983795166, 1.4261643886566162, 1.411779522895813, 1.4032020568847656, 1.3912711143493652, 1.3798335790634155, 1.3692491054534912, 1.3619946241378784, 1.3519601821899414, 1.341185450553894, 1.3314297199249268, 1.3298135995864868, 1.3138214349746704, 1.3059040307998657, 1.2973682880401611, 1.287635087966919, 1.2837592363357544, 1.2738555669784546, 1.2608811855316162, 1.2635802030563354, 1.2475138902664185, 1.2418876886367798, 1.2290089130401611, 1.225040316581726, 1.2166533470153809, 1.206127405166626, 1.2048614025115967, 1.1920183897018433, 1.1866494417190552, 1.1737024784088135, 1.1714760065078735, 1.1595611572265625, 1.1553473472595215, 1.1439836025238037, 1.140284776687622, 1.1315232515335083, 1.133172869682312, 1.1247795820236206, 1.1105393171310425, 1.1041136980056763, 1.0970171689987183, 1.0892153978347778, 1.0923503637313843, 1.0780882835388184, 1.0721608400344849, 1.0614426136016846, 1.0675818920135498, 1.066676139831543, 1.0458248853683472, 1.0366331338882446, 1.0358009338378906, 1.0331062078475952, 1.0156176090240479, 1.0116925239562988, 1.0110539197921753, 1.0096760988235474, 1.0055054426193237, 0.9950351715087891, 0.9834191799163818, 0.9837363958358765, 0.9715092182159424, 0.9621223211288452, 0.9603213667869568], 'accuracy': [0.5115840435028076, 0.5323275923728943, 0.5449892282485962, 0.5705819129943848, 0.5705819129943848, 0.5697737336158752, 0.5732758641242981, 0.578125, 0.5732758641242981, 0.5848599076271057, 0.5991379022598267, 0.59375, 0.5926724076271057, 0.5905172228813171, 0.6066810488700867, 0.6198814511299133, 0.6201508641242981, 0.6255387663841248, 0.626347005367279, 0.6177262663841248, 0.631196141242981, 0.6360452771186829, 0.6387392282485962, 0.6460129022598267, 0.6487069129943848, 0.6403555870056152, 0.654633641242981, 0.654633641242981, 0.6643319129943848, 0.6557112336158752, 0.6605603694915771, 0.6694504022598267, 0.671875, 0.6710668206214905, 0.6729525923728943, 0.6691810488700867, 0.6726831793785095, 0.6799569129943848, 0.6756465435028076, 0.686152994632721, 0.6807650923728943, 0.6899245977401733, 0.6920797228813171, 0.6961206793785095, 0.6845366358757019, 0.6982758641242981, 0.696928858757019, 0.7042025923728943, 0.6899245977401733, 0.7033944129943848, 0.7004310488700867, 0.7052801847457886, 0.7058189511299133, 0.7068965435028076, 0.701777994632721, 0.7149784564971924, 0.6950430870056152, 0.7117456793785095, 0.7163254022598267, 0.7222521305084229, 0.7112069129943848, 0.7109375, 0.7246767282485962, 0.7168642282485962, 0.7276400923728943, 0.7260237336158752, 0.735991358757019, 0.7300646305084229, 0.7376077771186829, 0.732758641242981, 0.7462284564971924, 0.743803858757019, 0.7467672228813171, 0.7322198152542114, 0.7370689511299133, 0.7481142282485962, 0.7567349076271057, 0.756196141242981, 0.7548491358757019, 0.7494612336158752, 0.7572737336158752, 0.7580819129943848, 0.7691271305084229, 0.7521551847457886, 0.7427262663841248, 0.766972005367279, 0.7683189511299133, 0.7618534564971924, 0.7645474076271057, 0.7785560488700867, 0.7809805870056152, 0.771821141242981, 0.7629310488700867, 0.771821141242981, 0.7745150923728943, 0.7898706793785095, 0.7766702771186829, 0.798222005367279, 0.7987607717514038, 0.790678858757019], 'val_loss': [2.0050268173217773, 1.9864166975021362, 1.9684621095657349, 1.9503124952316284, 1.9326802492141724, 1.9143513441085815, 1.8970329761505127, 1.8804025650024414, 1.863600492477417, 1.8445475101470947, 1.828080177307129, 1.8134151697158813, 1.799434781074524, 1.7760173082351685, 1.7631632089614868, 1.743598222732544, 1.7284947633743286, 1.7118370532989502, 1.6974477767944336, 1.6802875995635986, 1.6719063520431519, 1.6534018516540527, 1.6511238813400269, 1.6375850439071655, 1.6300578117370605, 1.6159392595291138, 1.5988937616348267, 1.5876437425613403, 1.5786312818527222, 1.558973789215088, 1.548371434211731, 1.537453532218933, 1.527035117149353, 1.5196900367736816, 1.5085840225219727, 1.4988933801651, 1.4954429864883423, 1.4879798889160156, 1.4735852479934692, 1.4632296562194824, 1.455540418624878, 1.4504996538162231, 1.445582389831543, 1.4298958778381348, 1.4310802221298218, 1.4147839546203613, 1.4067738056182861, 1.4035637378692627, 1.3990353345870972, 1.39198899269104, 1.380215048789978, 1.3753231763839722, 1.372714638710022, 1.3782322406768799, 1.3548524379730225, 1.3512687683105469, 1.3381223678588867, 1.3341927528381348, 1.3263624906539917, 1.3222402334213257, 1.3190932273864746, 1.3118431568145752, 1.3131917715072632, 1.309494972229004, 1.2987115383148193, 1.289989709854126, 1.2895129919052124, 1.2798247337341309, 1.293055534362793, 1.2754507064819336, 1.2796883583068848, 1.2717705965042114, 1.2663755416870117, 1.2532213926315308, 1.252509593963623, 1.2496066093444824, 1.2539278268814087, 1.2385125160217285, 1.2471963167190552, 1.2914692163467407, 1.2322098016738892, 1.2322945594787598, 1.2324167490005493, 1.2534558773040771, 1.24858820438385, 1.2144672870635986, 1.2206916809082031, 1.252000093460083, 1.204968810081482, 1.206166386604309, 1.2034666538238525, 1.1995388269424438, 1.22963285446167, 1.1982818841934204, 1.19374418258667, 1.1952942609786987, 1.2364565134048462, 1.2084375619888306, 1.195562481880188, 1.2304340600967407], 'val_accuracy': [0.48599138855934143, 0.587284505367279, 0.48491379618644714, 0.49568966031074524, 0.4762931168079376, 0.5840517282485962, 0.5204741358757019, 0.48599138855934143, 0.48491379618644714, 0.5668103694915771, 0.5603448152542114, 0.5010775923728943, 0.4978448152542114, 0.5894396305084229, 0.5366379022598267, 0.5754310488700867, 0.568965494632721, 0.5862069129943848, 0.576508641242981, 0.6023706793785095, 0.5700430870056152, 0.5991379022598267, 0.5678879022598267, 0.5732758641242981, 0.5711206793785095, 0.579741358757019, 0.5851293206214905, 0.5808189511299133, 0.5883620977401733, 0.618534505367279, 0.618534505367279, 0.610991358757019, 0.6271551847457886, 0.607758641242981, 0.6206896305084229, 0.6174569129943848, 0.5980603694915771, 0.6120689511299133, 0.6142241358757019, 0.6206896305084229, 0.6174569129943848, 0.607758641242981, 0.6023706793785095, 0.6196120977401733, 0.6012930870056152, 0.6206896305084229, 0.618534505367279, 0.6217672228813171, 0.6034482717514038, 0.625, 0.6217672228813171, 0.6260775923728943, 0.6088362336158752, 0.6012930870056152, 0.607758641242981, 0.6012930870056152, 0.6034482717514038, 0.607758641242981, 0.607758641242981, 0.6023706793785095, 0.6260775923728943, 0.6131465435028076, 0.6120689511299133, 0.6066810488700867, 0.6206896305084229, 0.6206896305084229, 0.6174569129943848, 0.6196120977401733, 0.6034482717514038, 0.6239224076271057, 0.6088362336158752, 0.6174569129943848, 0.6206896305084229, 0.6239224076271057, 0.6163793206214905, 0.6271551847457886, 0.6153017282485962, 0.6228448152542114, 0.618534505367279, 0.5721982717514038, 0.6282327771186829, 0.6174569129943848, 0.618534505367279, 0.5883620977401733, 0.5959051847457886, 0.6206896305084229, 0.6163793206214905, 0.5862069129943848, 0.6260775923728943, 0.6217672228813171, 0.6303879022598267, 0.6293103694915771, 0.5948275923728943, 0.6217672228813171, 0.6293103694915771, 0.6239224076271057, 0.5905172228813171, 0.6056034564971924, 0.6163793206214905, 0.59375]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 2.0226 - accuracy: 0.5096"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 5s 36ms/step - loss: 2.0215 - accuracy: 0.5091 - val_loss: 2.0058 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.9931 - accuracy: 0.5340 - val_loss: 1.9882 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.9718 - accuracy: 0.5529 - val_loss: 1.9707 - val_accuracy: 0.4864\n","Epoch 4/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.9533 - accuracy: 0.5656 - val_loss: 1.9534 - val_accuracy: 0.5045\n","Epoch 5/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.9327 - accuracy: 0.5713 - val_loss: 1.9365 - val_accuracy: 0.4932\n","Epoch 6/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.9130 - accuracy: 0.5668 - val_loss: 1.9194 - val_accuracy: 0.4966\n","Epoch 7/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.8928 - accuracy: 0.5855 - val_loss: 1.9027 - val_accuracy: 0.4898\n","Epoch 8/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.8736 - accuracy: 0.5931 - val_loss: 1.8855 - val_accuracy: 0.5362\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.8558 - accuracy: 0.5937 - val_loss: 1.8690 - val_accuracy: 0.5226\n","Epoch 10/100\n","28/28 [==============================] - 1s 30ms/step - loss: 1.8372 - accuracy: 0.5931 - val_loss: 1.8521 - val_accuracy: 0.5532\n","Epoch 11/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.8191 - accuracy: 0.6010 - val_loss: 1.8364 - val_accuracy: 0.5215\n","Epoch 12/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.8021 - accuracy: 0.6019 - val_loss: 1.8180 - val_accuracy: 0.5950\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.7842 - accuracy: 0.6072 - val_loss: 1.8025 - val_accuracy: 0.5509\n","Epoch 14/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.7701 - accuracy: 0.6064 - val_loss: 1.7858 - val_accuracy: 0.5781\n","Epoch 15/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.7509 - accuracy: 0.6115 - val_loss: 1.7673 - val_accuracy: 0.6120\n","Epoch 16/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.7347 - accuracy: 0.6180 - val_loss: 1.7574 - val_accuracy: 0.5509\n","Epoch 17/100\n","28/28 [==============================] - 1s 44ms/step - loss: 1.7249 - accuracy: 0.6078 - val_loss: 1.7356 - val_accuracy: 0.6176\n","Epoch 18/100\n","28/28 [==============================] - 1s 32ms/step - loss: 1.7110 - accuracy: 0.6047 - val_loss: 1.7193 - val_accuracy: 0.6176\n","Epoch 19/100\n","28/28 [==============================] - 1s 45ms/step - loss: 1.6936 - accuracy: 0.6149 - val_loss: 1.7037 - val_accuracy: 0.6233\n","Epoch 20/100\n","28/28 [==============================] - 1s 31ms/step - loss: 1.6763 - accuracy: 0.6316 - val_loss: 1.6934 - val_accuracy: 0.6007\n","Epoch 21/100\n","28/28 [==============================] - 1s 31ms/step - loss: 1.6638 - accuracy: 0.6211 - val_loss: 1.6764 - val_accuracy: 0.6131\n","Epoch 22/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.6461 - accuracy: 0.6370 - val_loss: 1.6645 - val_accuracy: 0.6075\n","Epoch 23/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.6317 - accuracy: 0.6418 - val_loss: 1.6571 - val_accuracy: 0.6086\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.6215 - accuracy: 0.6364 - val_loss: 1.6373 - val_accuracy: 0.6165\n","Epoch 25/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.6132 - accuracy: 0.6245 - val_loss: 1.6272 - val_accuracy: 0.6007\n","Epoch 26/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.5984 - accuracy: 0.6449 - val_loss: 1.6115 - val_accuracy: 0.6267\n","Epoch 27/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5831 - accuracy: 0.6454 - val_loss: 1.6022 - val_accuracy: 0.6267\n","Epoch 28/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.5687 - accuracy: 0.6542 - val_loss: 1.5899 - val_accuracy: 0.6324\n","Epoch 29/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.5584 - accuracy: 0.6488 - val_loss: 1.5790 - val_accuracy: 0.6335\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5442 - accuracy: 0.6562 - val_loss: 1.5838 - val_accuracy: 0.6143\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.5358 - accuracy: 0.6545 - val_loss: 1.5658 - val_accuracy: 0.6244\n","Epoch 32/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5202 - accuracy: 0.6627 - val_loss: 1.5502 - val_accuracy: 0.6301\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5094 - accuracy: 0.6590 - val_loss: 1.5433 - val_accuracy: 0.6278\n","Epoch 34/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.5007 - accuracy: 0.6579 - val_loss: 1.5310 - val_accuracy: 0.6391\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4853 - accuracy: 0.6638 - val_loss: 1.5220 - val_accuracy: 0.6357\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4769 - accuracy: 0.6653 - val_loss: 1.5123 - val_accuracy: 0.6357\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4636 - accuracy: 0.6743 - val_loss: 1.5053 - val_accuracy: 0.6346\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4551 - accuracy: 0.6689 - val_loss: 1.4999 - val_accuracy: 0.6233\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4463 - accuracy: 0.6701 - val_loss: 1.4961 - val_accuracy: 0.6052\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4333 - accuracy: 0.6802 - val_loss: 1.4842 - val_accuracy: 0.6290\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4272 - accuracy: 0.6715 - val_loss: 1.4755 - val_accuracy: 0.6335\n","Epoch 42/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4201 - accuracy: 0.6698 - val_loss: 1.4662 - val_accuracy: 0.6256\n","Epoch 43/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.4097 - accuracy: 0.6774 - val_loss: 1.4719 - val_accuracy: 0.6165\n","Epoch 44/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4049 - accuracy: 0.6641 - val_loss: 1.4460 - val_accuracy: 0.6391\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3859 - accuracy: 0.6836 - val_loss: 1.4405 - val_accuracy: 0.6369\n","Epoch 46/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.3770 - accuracy: 0.6802 - val_loss: 1.4355 - val_accuracy: 0.6346\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3662 - accuracy: 0.6885 - val_loss: 1.4262 - val_accuracy: 0.6335\n","Epoch 48/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.3583 - accuracy: 0.6882 - val_loss: 1.4183 - val_accuracy: 0.6335\n","Epoch 49/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3500 - accuracy: 0.6856 - val_loss: 1.4113 - val_accuracy: 0.6357\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3391 - accuracy: 0.6919 - val_loss: 1.4046 - val_accuracy: 0.6312\n","Epoch 51/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3331 - accuracy: 0.6862 - val_loss: 1.3973 - val_accuracy: 0.6335\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3217 - accuracy: 0.7009 - val_loss: 1.3973 - val_accuracy: 0.6301\n","Epoch 53/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3110 - accuracy: 0.7018 - val_loss: 1.3860 - val_accuracy: 0.6301\n","Epoch 54/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3023 - accuracy: 0.7063 - val_loss: 1.3812 - val_accuracy: 0.6312\n","Epoch 55/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2960 - accuracy: 0.7074 - val_loss: 1.3733 - val_accuracy: 0.6290\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2862 - accuracy: 0.7077 - val_loss: 1.3669 - val_accuracy: 0.6346\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2779 - accuracy: 0.7080 - val_loss: 1.3637 - val_accuracy: 0.6357\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2717 - accuracy: 0.7049 - val_loss: 1.3652 - val_accuracy: 0.6278\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2650 - accuracy: 0.7063 - val_loss: 1.3738 - val_accuracy: 0.6041\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2589 - accuracy: 0.7074 - val_loss: 1.3531 - val_accuracy: 0.6290\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2479 - accuracy: 0.7108 - val_loss: 1.3389 - val_accuracy: 0.6346\n","Epoch 62/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2396 - accuracy: 0.7156 - val_loss: 1.3388 - val_accuracy: 0.6301\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2312 - accuracy: 0.7148 - val_loss: 1.3281 - val_accuracy: 0.6369\n","Epoch 64/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2260 - accuracy: 0.7111 - val_loss: 1.3256 - val_accuracy: 0.6357\n","Epoch 65/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2151 - accuracy: 0.7179 - val_loss: 1.3178 - val_accuracy: 0.6391\n","Epoch 66/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2071 - accuracy: 0.7292 - val_loss: 1.3184 - val_accuracy: 0.6278\n","Epoch 67/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2025 - accuracy: 0.7289 - val_loss: 1.3085 - val_accuracy: 0.6357\n","Epoch 68/100\n","28/28 [==============================] - 2s 59ms/step - loss: 1.1927 - accuracy: 0.7351 - val_loss: 1.3041 - val_accuracy: 0.6425\n","Epoch 69/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1855 - accuracy: 0.7312 - val_loss: 1.3004 - val_accuracy: 0.6369\n","Epoch 70/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1767 - accuracy: 0.7346 - val_loss: 1.3107 - val_accuracy: 0.6176\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1722 - accuracy: 0.7301 - val_loss: 1.2914 - val_accuracy: 0.6414\n","Epoch 72/100\n","28/28 [==============================] - 1s 30ms/step - loss: 1.1624 - accuracy: 0.7334 - val_loss: 1.2860 - val_accuracy: 0.6459\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1563 - accuracy: 0.7380 - val_loss: 1.2965 - val_accuracy: 0.6188\n","Epoch 74/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.1460 - accuracy: 0.7467 - val_loss: 1.2803 - val_accuracy: 0.6414\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1411 - accuracy: 0.7484 - val_loss: 1.2767 - val_accuracy: 0.6346\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1319 - accuracy: 0.7530 - val_loss: 1.2731 - val_accuracy: 0.6357\n","Epoch 77/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1242 - accuracy: 0.7541 - val_loss: 1.2692 - val_accuracy: 0.6357\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1183 - accuracy: 0.7572 - val_loss: 1.2665 - val_accuracy: 0.6335\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1129 - accuracy: 0.7598 - val_loss: 1.2661 - val_accuracy: 0.6324\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1043 - accuracy: 0.7572 - val_loss: 1.2916 - val_accuracy: 0.6063\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1102 - accuracy: 0.7521 - val_loss: 1.2597 - val_accuracy: 0.6233\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0928 - accuracy: 0.7583 - val_loss: 1.2538 - val_accuracy: 0.6380\n","Epoch 83/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0902 - accuracy: 0.7555 - val_loss: 1.2543 - val_accuracy: 0.6290\n","Epoch 84/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0888 - accuracy: 0.7507 - val_loss: 1.2515 - val_accuracy: 0.6256\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0689 - accuracy: 0.7728 - val_loss: 1.2472 - val_accuracy: 0.6312\n","Epoch 86/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0613 - accuracy: 0.7765 - val_loss: 1.2452 - val_accuracy: 0.6346\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0644 - accuracy: 0.7609 - val_loss: 1.2503 - val_accuracy: 0.6233\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0514 - accuracy: 0.7773 - val_loss: 1.2454 - val_accuracy: 0.6256\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0428 - accuracy: 0.7790 - val_loss: 1.2390 - val_accuracy: 0.6210\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0414 - accuracy: 0.7742 - val_loss: 1.2364 - val_accuracy: 0.6312\n","Epoch 91/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.0285 - accuracy: 0.7883 - val_loss: 1.2397 - val_accuracy: 0.6199\n","Epoch 92/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0236 - accuracy: 0.7844 - val_loss: 1.2375 - val_accuracy: 0.6176\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0188 - accuracy: 0.7915 - val_loss: 1.2423 - val_accuracy: 0.6097\n","Epoch 94/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0141 - accuracy: 0.7881 - val_loss: 1.2327 - val_accuracy: 0.6210\n","Epoch 95/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0074 - accuracy: 0.7900 - val_loss: 1.2350 - val_accuracy: 0.6154\n","Epoch 96/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9967 - accuracy: 0.7917 - val_loss: 1.2311 - val_accuracy: 0.6267\n","Epoch 97/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9941 - accuracy: 0.7915 - val_loss: 1.2666 - val_accuracy: 0.5950\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9870 - accuracy: 0.7943 - val_loss: 1.2354 - val_accuracy: 0.6120\n","Epoch 99/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9823 - accuracy: 0.7943 - val_loss: 1.2313 - val_accuracy: 0.6109\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9809 - accuracy: 0.7824 - val_loss: 1.2387 - val_accuracy: 0.6120\n","{'loss': [2.0215189456939697, 1.9930622577667236, 1.9717551469802856, 1.953331708908081, 1.932685136795044, 1.9130326509475708, 1.8928438425064087, 1.8735829591751099, 1.8557664155960083, 1.8372108936309814, 1.8190869092941284, 1.8021148443222046, 1.784218430519104, 1.7700608968734741, 1.7509397268295288, 1.7347469329833984, 1.7249447107315063, 1.71095871925354, 1.6936475038528442, 1.6763265132904053, 1.6638351678848267, 1.6461368799209595, 1.6316595077514648, 1.6215322017669678, 1.6132131814956665, 1.5983575582504272, 1.5831352472305298, 1.5686655044555664, 1.5584192276000977, 1.544154405593872, 1.5358068943023682, 1.5201729536056519, 1.5093839168548584, 1.5006601810455322, 1.4852707386016846, 1.4768871068954468, 1.463591456413269, 1.4551057815551758, 1.446294903755188, 1.4333305358886719, 1.4272105693817139, 1.420075535774231, 1.4096946716308594, 1.4049381017684937, 1.3859118223190308, 1.376992106437683, 1.3662301301956177, 1.3582509756088257, 1.3499846458435059, 1.3391449451446533, 1.3330696821212769, 1.3217405080795288, 1.3109569549560547, 1.3023419380187988, 1.2960214614868164, 1.2862015962600708, 1.2778810262680054, 1.271697998046875, 1.265041470527649, 1.2588818073272705, 1.2478747367858887, 1.239624261856079, 1.2311711311340332, 1.225980281829834, 1.215131163597107, 1.2070918083190918, 1.2024970054626465, 1.1927045583724976, 1.185540795326233, 1.1766581535339355, 1.1722060441970825, 1.1624470949172974, 1.156263828277588, 1.14596426486969, 1.141130805015564, 1.1318992376327515, 1.124159336090088, 1.1182688474655151, 1.112862229347229, 1.1043378114700317, 1.11020028591156, 1.092840313911438, 1.0902098417282104, 1.0888136625289917, 1.06894850730896, 1.0613137483596802, 1.0644128322601318, 1.0513792037963867, 1.0427932739257812, 1.0413731336593628, 1.028464913368225, 1.0235984325408936, 1.0187944173812866, 1.014105200767517, 1.0074288845062256, 0.9967483878135681, 0.9940546154975891, 0.9870117902755737, 0.9823209643363953, 0.9808970093727112], 'accuracy': [0.5090548992156982, 0.5339558720588684, 0.552914559841156, 0.5656480193138123, 0.5713073015213013, 0.5667798519134521, 0.585455596446991, 0.5930956602096558, 0.5936615467071533, 0.5930956602096558, 0.6010186672210693, 0.6018675565719604, 0.6072438955307007, 0.6063950061798096, 0.611488401889801, 0.6179966330528259, 0.607809841632843, 0.6046972274780273, 0.6148839592933655, 0.6315789222717285, 0.6211092472076416, 0.6369553208351135, 0.6417657136917114, 0.6363893747329712, 0.624504804611206, 0.6448783278465271, 0.6454442739486694, 0.6542161703109741, 0.6488398313522339, 0.6561969518661499, 0.6544991731643677, 0.66270512342453, 0.6590266227722168, 0.6578947305679321, 0.6638370156288147, 0.6652518510818481, 0.6743067502975464, 0.6689304113388062, 0.670062243938446, 0.680249035358429, 0.6714770793914795, 0.6697793006896973, 0.6774193644523621, 0.6641199588775635, 0.6836445927619934, 0.680249035358429, 0.6884549856185913, 0.6881720423698425, 0.6856253743171692, 0.6918506026268005, 0.6861912608146667, 0.7009055018424988, 0.7017543911933899, 0.706281840801239, 0.7074136734008789, 0.7076966762542725, 0.7079796195030212, 0.7048670053482056, 0.706281840801239, 0.7074136734008789, 0.7108092904090881, 0.715619683265686, 0.7147707939147949, 0.7110922336578369, 0.7178834080696106, 0.7292020320892334, 0.7289190888404846, 0.735144317150116, 0.7311828136444092, 0.7345783710479736, 0.7300509214401245, 0.7334465384483337, 0.7379739880561829, 0.7467458844184875, 0.7484436631202698, 0.7529711127281189, 0.7541030049324036, 0.7572156190872192, 0.7597622871398926, 0.7572156190872192, 0.7521222233772278, 0.7583475112915039, 0.755517840385437, 0.7507073879241943, 0.7727787494659424, 0.7764572501182556, 0.7608941793441772, 0.7773061394691467, 0.7790039777755737, 0.774193525314331, 0.7883418202400208, 0.784380316734314, 0.7914544343948364, 0.788058876991272, 0.790039598941803, 0.79173743724823, 0.7914544343948364, 0.7942841053009033, 0.7942841053009033, 0.7823995351791382], 'val_loss': [2.0058364868164062, 1.9881993532180786, 1.9706999063491821, 1.9534052610397339, 1.9364590644836426, 1.9193888902664185, 1.9026732444763184, 1.8855063915252686, 1.8689782619476318, 1.8520699739456177, 1.8364429473876953, 1.8179737329483032, 1.8025082349777222, 1.7857576608657837, 1.7673044204711914, 1.757436990737915, 1.7355867624282837, 1.71928071975708, 1.7037080526351929, 1.6934014558792114, 1.676361322402954, 1.6644737720489502, 1.6570515632629395, 1.6373488903045654, 1.6272411346435547, 1.6114739179611206, 1.6021665334701538, 1.5898938179016113, 1.5789875984191895, 1.5838202238082886, 1.5658175945281982, 1.5501567125320435, 1.543317437171936, 1.5309991836547852, 1.5219789743423462, 1.512325406074524, 1.5053274631500244, 1.4998735189437866, 1.4961446523666382, 1.4841594696044922, 1.475463628768921, 1.4662004709243774, 1.4718900918960571, 1.4459782838821411, 1.4404925107955933, 1.4355087280273438, 1.426169514656067, 1.4183088541030884, 1.4112935066223145, 1.404612421989441, 1.3973195552825928, 1.3972856998443604, 1.385962724685669, 1.3812354803085327, 1.3733477592468262, 1.3669012784957886, 1.363723635673523, 1.3652139902114868, 1.3737728595733643, 1.3531023263931274, 1.3388725519180298, 1.3387733697891235, 1.3281491994857788, 1.3255573511123657, 1.3177937269210815, 1.3184075355529785, 1.3084542751312256, 1.3041398525238037, 1.3003926277160645, 1.3107119798660278, 1.2913908958435059, 1.2860394716262817, 1.296453595161438, 1.2803021669387817, 1.2767218351364136, 1.2730575799942017, 1.2691891193389893, 1.2665350437164307, 1.2661460638046265, 1.2915538549423218, 1.2596977949142456, 1.2538379430770874, 1.2543137073516846, 1.2514584064483643, 1.247176170349121, 1.245235800743103, 1.250299334526062, 1.245428204536438, 1.2390272617340088, 1.2363919019699097, 1.239742398262024, 1.2375093698501587, 1.2422988414764404, 1.2327181100845337, 1.234988808631897, 1.231066346168518, 1.2665512561798096, 1.2353663444519043, 1.231323003768921, 1.238723635673523], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.48642534017562866, 0.5045248866081238, 0.49321267008781433, 0.49660632014274597, 0.4898189902305603, 0.5361990928649902, 0.5226244330406189, 0.5531674027442932, 0.5214931964874268, 0.5950226187705994, 0.5509049892425537, 0.5780543088912964, 0.6119909286499023, 0.5509049892425537, 0.6176470518112183, 0.6176470518112183, 0.6233031749725342, 0.6006787419319153, 0.6131221652030945, 0.6074660420417786, 0.6085972785949707, 0.6165158152580261, 0.6006787419319153, 0.6266968250274658, 0.6266968250274658, 0.6323529481887817, 0.6334841847419739, 0.6142534017562866, 0.6244344115257263, 0.6300904750823975, 0.627828061580658, 0.639140248298645, 0.6357465982437134, 0.6357465982437134, 0.6346153616905212, 0.6233031749725342, 0.6052036285400391, 0.6289592981338501, 0.6334841847419739, 0.6255655884742737, 0.6165158152580261, 0.639140248298645, 0.6368778347969055, 0.6346153616905212, 0.6334841847419739, 0.6334841847419739, 0.6357465982437134, 0.6312217116355896, 0.6334841847419739, 0.6300904750823975, 0.6300904750823975, 0.6312217116355896, 0.6289592981338501, 0.6346153616905212, 0.6357465982437134, 0.627828061580658, 0.6040723919868469, 0.6289592981338501, 0.6346153616905212, 0.6300904750823975, 0.6368778347969055, 0.6357465982437134, 0.639140248298645, 0.627828061580658, 0.6357465982437134, 0.6425339579582214, 0.6368778347969055, 0.6176470518112183, 0.6414027214050293, 0.6459276080131531, 0.6187782883644104, 0.6414027214050293, 0.6346153616905212, 0.6357465982437134, 0.6357465982437134, 0.6334841847419739, 0.6323529481887817, 0.6063348650932312, 0.6233031749725342, 0.6380090713500977, 0.6289592981338501, 0.6255655884742737, 0.6312217116355896, 0.6346153616905212, 0.6233031749725342, 0.6255655884742737, 0.6210407018661499, 0.6312217116355896, 0.6199095249176025, 0.6176470518112183, 0.6097285151481628, 0.6210407018661499, 0.6153846383094788, 0.6266968250274658, 0.5950226187705994, 0.6119909286499023, 0.610859751701355, 0.6119909286499023]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 2.0173 - accuracy: 0.5125"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 4s 35ms/step - loss: 2.0172 - accuracy: 0.5127 - val_loss: 2.0039 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.9919 - accuracy: 0.5233 - val_loss: 1.9844 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.9688 - accuracy: 0.5571 - val_loss: 1.9654 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.9491 - accuracy: 0.5408 - val_loss: 1.9459 - val_accuracy: 0.4824\n","Epoch 5/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.9272 - accuracy: 0.5540 - val_loss: 1.9272 - val_accuracy: 0.4783\n","Epoch 6/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.9059 - accuracy: 0.5711 - val_loss: 1.9096 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.8874 - accuracy: 0.5519 - val_loss: 1.8909 - val_accuracy: 0.4783\n","Epoch 8/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.8674 - accuracy: 0.5736 - val_loss: 1.8726 - val_accuracy: 0.4824\n","Epoch 9/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.8477 - accuracy: 0.5791 - val_loss: 1.8560 - val_accuracy: 0.4824\n","Epoch 10/100\n","31/31 [==============================] - 1s 29ms/step - loss: 1.8271 - accuracy: 0.5907 - val_loss: 1.8365 - val_accuracy: 0.5434\n","Epoch 11/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.8096 - accuracy: 0.5783 - val_loss: 1.8225 - val_accuracy: 0.4855\n","Epoch 12/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.7910 - accuracy: 0.5920 - val_loss: 1.8018 - val_accuracy: 0.5372\n","Epoch 13/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.7739 - accuracy: 0.5884 - val_loss: 1.7872 - val_accuracy: 0.5072\n","Epoch 14/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.7551 - accuracy: 0.6065 - val_loss: 1.7715 - val_accuracy: 0.5103\n","Epoch 15/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.7394 - accuracy: 0.5977 - val_loss: 1.7500 - val_accuracy: 0.5568\n","Epoch 16/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.7190 - accuracy: 0.6178 - val_loss: 1.7360 - val_accuracy: 0.5517\n","Epoch 17/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.7023 - accuracy: 0.6230 - val_loss: 1.7217 - val_accuracy: 0.5382\n","Epoch 18/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.6871 - accuracy: 0.6168 - val_loss: 1.6967 - val_accuracy: 0.5847\n","Epoch 19/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.6739 - accuracy: 0.6116 - val_loss: 1.6803 - val_accuracy: 0.5940\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.6543 - accuracy: 0.6323 - val_loss: 1.6718 - val_accuracy: 0.5785\n","Epoch 21/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.6385 - accuracy: 0.6364 - val_loss: 1.6514 - val_accuracy: 0.5961\n","Epoch 22/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.6223 - accuracy: 0.6367 - val_loss: 1.6539 - val_accuracy: 0.5548\n","Epoch 23/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.6082 - accuracy: 0.6406 - val_loss: 1.6324 - val_accuracy: 0.5764\n","Epoch 24/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.5956 - accuracy: 0.6403 - val_loss: 1.6067 - val_accuracy: 0.6188\n","Epoch 25/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.5794 - accuracy: 0.6439 - val_loss: 1.5935 - val_accuracy: 0.6095\n","Epoch 26/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.5674 - accuracy: 0.6413 - val_loss: 1.5850 - val_accuracy: 0.6002\n","Epoch 27/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.5533 - accuracy: 0.6491 - val_loss: 1.5691 - val_accuracy: 0.6219\n","Epoch 28/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.5390 - accuracy: 0.6527 - val_loss: 1.5578 - val_accuracy: 0.6240\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5267 - accuracy: 0.6522 - val_loss: 1.5473 - val_accuracy: 0.6136\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5201 - accuracy: 0.6426 - val_loss: 1.5893 - val_accuracy: 0.5413\n","Epoch 31/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.5326 - accuracy: 0.6129 - val_loss: 1.5242 - val_accuracy: 0.6260\n","Epoch 32/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.4934 - accuracy: 0.6514 - val_loss: 1.5183 - val_accuracy: 0.6002\n","Epoch 33/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.4795 - accuracy: 0.6615 - val_loss: 1.5035 - val_accuracy: 0.6240\n","Epoch 34/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.4714 - accuracy: 0.6535 - val_loss: 1.4941 - val_accuracy: 0.6281\n","Epoch 35/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.4614 - accuracy: 0.6550 - val_loss: 1.4830 - val_accuracy: 0.6291\n","Epoch 36/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4461 - accuracy: 0.6636 - val_loss: 1.4744 - val_accuracy: 0.6198\n","Epoch 37/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4338 - accuracy: 0.6693 - val_loss: 1.4656 - val_accuracy: 0.6074\n","Epoch 38/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.4224 - accuracy: 0.6690 - val_loss: 1.4563 - val_accuracy: 0.6312\n","Epoch 39/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4158 - accuracy: 0.6558 - val_loss: 1.4487 - val_accuracy: 0.6260\n","Epoch 40/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4026 - accuracy: 0.6693 - val_loss: 1.4418 - val_accuracy: 0.6105\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3910 - accuracy: 0.6744 - val_loss: 1.4290 - val_accuracy: 0.6250\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3843 - accuracy: 0.6700 - val_loss: 1.4250 - val_accuracy: 0.6260\n","Epoch 43/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3876 - accuracy: 0.6460 - val_loss: 1.4206 - val_accuracy: 0.6002\n","Epoch 44/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3675 - accuracy: 0.6731 - val_loss: 1.4084 - val_accuracy: 0.6219\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3563 - accuracy: 0.6775 - val_loss: 1.3955 - val_accuracy: 0.6178\n","Epoch 46/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3448 - accuracy: 0.6775 - val_loss: 1.3876 - val_accuracy: 0.6167\n","Epoch 47/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3363 - accuracy: 0.6721 - val_loss: 1.3825 - val_accuracy: 0.6136\n","Epoch 48/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.3291 - accuracy: 0.6770 - val_loss: 1.3814 - val_accuracy: 0.6002\n","Epoch 49/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3173 - accuracy: 0.6881 - val_loss: 1.3692 - val_accuracy: 0.6136\n","Epoch 50/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3085 - accuracy: 0.6835 - val_loss: 1.3578 - val_accuracy: 0.6178\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3000 - accuracy: 0.6811 - val_loss: 1.3518 - val_accuracy: 0.6126\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2963 - accuracy: 0.6726 - val_loss: 1.3565 - val_accuracy: 0.5950\n","Epoch 53/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.2828 - accuracy: 0.6855 - val_loss: 1.3412 - val_accuracy: 0.6105\n","Epoch 54/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2758 - accuracy: 0.6889 - val_loss: 1.3360 - val_accuracy: 0.6095\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2658 - accuracy: 0.6953 - val_loss: 1.3234 - val_accuracy: 0.6198\n","Epoch 56/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2572 - accuracy: 0.7010 - val_loss: 1.3188 - val_accuracy: 0.6136\n","Epoch 57/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.2483 - accuracy: 0.6935 - val_loss: 1.3290 - val_accuracy: 0.5961\n","Epoch 58/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2410 - accuracy: 0.7016 - val_loss: 1.3050 - val_accuracy: 0.6271\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2332 - accuracy: 0.6966 - val_loss: 1.3073 - val_accuracy: 0.6095\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2265 - accuracy: 0.6987 - val_loss: 1.2934 - val_accuracy: 0.6260\n","Epoch 61/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2169 - accuracy: 0.7044 - val_loss: 1.2877 - val_accuracy: 0.6240\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2089 - accuracy: 0.6948 - val_loss: 1.2826 - val_accuracy: 0.6147\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2030 - accuracy: 0.7003 - val_loss: 1.2782 - val_accuracy: 0.6281\n","Epoch 64/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1965 - accuracy: 0.7039 - val_loss: 1.2711 - val_accuracy: 0.6188\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1870 - accuracy: 0.7039 - val_loss: 1.2659 - val_accuracy: 0.6188\n","Epoch 66/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1799 - accuracy: 0.7049 - val_loss: 1.2713 - val_accuracy: 0.6002\n","Epoch 67/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1768 - accuracy: 0.6982 - val_loss: 1.2617 - val_accuracy: 0.6116\n","Epoch 68/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1705 - accuracy: 0.7049 - val_loss: 1.2549 - val_accuracy: 0.6105\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1573 - accuracy: 0.7158 - val_loss: 1.2465 - val_accuracy: 0.6188\n","Epoch 70/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1505 - accuracy: 0.7142 - val_loss: 1.2504 - val_accuracy: 0.5992\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1450 - accuracy: 0.7173 - val_loss: 1.2422 - val_accuracy: 0.6116\n","Epoch 72/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1405 - accuracy: 0.7109 - val_loss: 1.2392 - val_accuracy: 0.6240\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1300 - accuracy: 0.7220 - val_loss: 1.2307 - val_accuracy: 0.6105\n","Epoch 74/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1262 - accuracy: 0.7207 - val_loss: 1.2245 - val_accuracy: 0.6240\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1185 - accuracy: 0.7165 - val_loss: 1.2218 - val_accuracy: 0.6178\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1127 - accuracy: 0.7212 - val_loss: 1.2169 - val_accuracy: 0.6188\n","Epoch 77/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1048 - accuracy: 0.7204 - val_loss: 1.2130 - val_accuracy: 0.6281\n","Epoch 78/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0967 - accuracy: 0.7310 - val_loss: 1.2109 - val_accuracy: 0.6157\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0919 - accuracy: 0.7253 - val_loss: 1.2083 - val_accuracy: 0.6074\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0840 - accuracy: 0.7271 - val_loss: 1.2102 - val_accuracy: 0.6229\n","Epoch 81/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0796 - accuracy: 0.7271 - val_loss: 1.1983 - val_accuracy: 0.6198\n","Epoch 82/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0720 - accuracy: 0.7357 - val_loss: 1.1984 - val_accuracy: 0.6126\n","Epoch 83/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0667 - accuracy: 0.7336 - val_loss: 1.2255 - val_accuracy: 0.5816\n","Epoch 84/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0683 - accuracy: 0.7274 - val_loss: 1.1897 - val_accuracy: 0.6136\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0581 - accuracy: 0.7377 - val_loss: 1.1869 - val_accuracy: 0.6167\n","Epoch 86/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0465 - accuracy: 0.7388 - val_loss: 1.1845 - val_accuracy: 0.6167\n","Epoch 87/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0403 - accuracy: 0.7434 - val_loss: 1.1793 - val_accuracy: 0.6188\n","Epoch 88/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0344 - accuracy: 0.7486 - val_loss: 1.1896 - val_accuracy: 0.5971\n","Epoch 89/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0270 - accuracy: 0.7519 - val_loss: 1.1748 - val_accuracy: 0.6136\n","Epoch 90/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0211 - accuracy: 0.7494 - val_loss: 1.1719 - val_accuracy: 0.6198\n","Epoch 91/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0185 - accuracy: 0.7486 - val_loss: 1.1849 - val_accuracy: 0.5909\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0155 - accuracy: 0.7501 - val_loss: 1.2001 - val_accuracy: 0.5919\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0172 - accuracy: 0.7331 - val_loss: 1.1680 - val_accuracy: 0.6209\n","Epoch 94/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0049 - accuracy: 0.7463 - val_loss: 1.1825 - val_accuracy: 0.6116\n","Epoch 95/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9984 - accuracy: 0.7605 - val_loss: 1.1730 - val_accuracy: 0.6136\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9899 - accuracy: 0.7558 - val_loss: 1.1763 - val_accuracy: 0.5961\n","Epoch 97/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9834 - accuracy: 0.7630 - val_loss: 1.1611 - val_accuracy: 0.6095\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9746 - accuracy: 0.7581 - val_loss: 1.1571 - val_accuracy: 0.6178\n","Epoch 99/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9679 - accuracy: 0.7672 - val_loss: 1.1545 - val_accuracy: 0.6147\n","Epoch 100/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9623 - accuracy: 0.7731 - val_loss: 1.1578 - val_accuracy: 0.6105\n","{'loss': [2.017174243927002, 1.9918859004974365, 1.9688293933868408, 1.9491280317306519, 1.927163004875183, 1.9058626890182495, 1.887356162071228, 1.8674038648605347, 1.8477082252502441, 1.8271360397338867, 1.809627890586853, 1.7910096645355225, 1.7738661766052246, 1.7550914287567139, 1.7393958568572998, 1.7190285921096802, 1.7022814750671387, 1.6871320009231567, 1.6738871335983276, 1.6543437242507935, 1.6385319232940674, 1.6222779750823975, 1.6081750392913818, 1.5956339836120605, 1.5794044733047485, 1.5673797130584717, 1.553315281867981, 1.5390135049819946, 1.5266972780227661, 1.5200855731964111, 1.5326029062271118, 1.4933761358261108, 1.4795128107070923, 1.47138249874115, 1.461422085762024, 1.4460970163345337, 1.4337722063064575, 1.422371506690979, 1.4157865047454834, 1.4025744199752808, 1.3910014629364014, 1.384348750114441, 1.3875843286514282, 1.367506504058838, 1.356275200843811, 1.3447626829147339, 1.336324691772461, 1.3290653228759766, 1.3173202276229858, 1.308467984199524, 1.3000394105911255, 1.2962918281555176, 1.282846212387085, 1.2757899761199951, 1.2658374309539795, 1.257163643836975, 1.248281717300415, 1.2409679889678955, 1.233160138130188, 1.2265291213989258, 1.216944694519043, 1.208930253982544, 1.2029584646224976, 1.196523666381836, 1.1869986057281494, 1.1798574924468994, 1.1768057346343994, 1.1704732179641724, 1.15727698802948, 1.1504870653152466, 1.144999384880066, 1.1404756307601929, 1.1299593448638916, 1.1261804103851318, 1.1185137033462524, 1.1126713752746582, 1.1048028469085693, 1.0967451333999634, 1.0919394493103027, 1.0839899778366089, 1.079618215560913, 1.0720411539077759, 1.0666719675064087, 1.068327784538269, 1.0581282377243042, 1.0465408563613892, 1.0402629375457764, 1.0344189405441284, 1.0270203351974487, 1.0211032629013062, 1.018492579460144, 1.0155102014541626, 1.0171897411346436, 1.0049158334732056, 0.9983503222465515, 0.9898860454559326, 0.98343425989151, 0.9745712876319885, 0.9679161310195923, 0.9622632265090942], 'accuracy': [0.5126615166664124, 0.5232558250427246, 0.5571059584617615, 0.5408268570899963, 0.5540051460266113, 0.5710594058036804, 0.551937997341156, 0.5736433863639832, 0.5790697932243347, 0.5906976461410522, 0.578294575214386, 0.5919896364212036, 0.5883721113204956, 0.6064599752426147, 0.5976744294166565, 0.617829442024231, 0.6229974031448364, 0.6167958378791809, 0.6116279363632202, 0.6322997212409973, 0.6364341378211975, 0.6366925239562988, 0.6405684947967529, 0.6403100490570068, 0.6439276337623596, 0.6413436532020569, 0.6490955948829651, 0.6527131795883179, 0.6521964073181152, 0.6426356434822083, 0.6129198670387268, 0.6514211893081665, 0.6614987254142761, 0.6534883975982666, 0.6550387740135193, 0.6635658740997314, 0.6692506670951843, 0.6689922213554382, 0.6558139324188232, 0.6692506670951843, 0.6744186282157898, 0.6700258255004883, 0.6459948420524597, 0.6731266379356384, 0.6775193810462952, 0.6775193810462952, 0.6720930337905884, 0.6770026087760925, 0.6881136894226074, 0.6834625601768494, 0.681136965751648, 0.672609806060791, 0.6855297088623047, 0.6888889074325562, 0.695348858833313, 0.7010335922241211, 0.6935400366783142, 0.7015503644943237, 0.6966408491134644, 0.6987079977989197, 0.7043927907943726, 0.6948320269584656, 0.7002583742141724, 0.7038759589195251, 0.7038759589195251, 0.7049095630645752, 0.698191225528717, 0.7049095630645752, 0.7157622575759888, 0.7142118811607361, 0.7173126339912415, 0.7108527421951294, 0.7219638228416443, 0.7206718325614929, 0.7165374755859375, 0.7211886048316956, 0.7204134464263916, 0.7310077548027039, 0.7253230214118958, 0.7271317839622498, 0.7271317839622498, 0.7356589436531067, 0.7335917353630066, 0.7273901700973511, 0.737726092338562, 0.7387596964836121, 0.7434108257293701, 0.7485787868499756, 0.751937985420227, 0.7493540048599243, 0.7485787868499756, 0.750129222869873, 0.733074963092804, 0.746253252029419, 0.760465145111084, 0.7558139562606812, 0.7630490660667419, 0.7581395506858826, 0.7671834826469421, 0.7731266021728516], 'val_loss': [2.003910541534424, 1.9844156503677368, 1.9654299020767212, 1.9459182024002075, 1.9271639585494995, 1.9096041917800903, 1.8908747434616089, 1.8726433515548706, 1.8560380935668945, 1.8364975452423096, 1.8224598169326782, 1.8017873764038086, 1.7872158288955688, 1.7714554071426392, 1.750007152557373, 1.736018419265747, 1.7217075824737549, 1.6967270374298096, 1.6803128719329834, 1.671789288520813, 1.6514421701431274, 1.653948426246643, 1.6324007511138916, 1.606655240058899, 1.5935355424880981, 1.5850168466567993, 1.569136142730713, 1.557830810546875, 1.5473467111587524, 1.5892590284347534, 1.5242406129837036, 1.5182609558105469, 1.5034860372543335, 1.4941104650497437, 1.482982873916626, 1.4744288921356201, 1.4656394720077515, 1.4562633037567139, 1.4487427473068237, 1.441756010055542, 1.4289774894714355, 1.4250431060791016, 1.4206225872039795, 1.4083842039108276, 1.3955457210540771, 1.3876031637191772, 1.3824784755706787, 1.3814330101013184, 1.3691939115524292, 1.3578364849090576, 1.3518441915512085, 1.3564684391021729, 1.3411506414413452, 1.3360341787338257, 1.3233906030654907, 1.3187817335128784, 1.3289926052093506, 1.305041790008545, 1.307347297668457, 1.293440341949463, 1.2876988649368286, 1.2826060056686401, 1.2782384157180786, 1.2710541486740112, 1.2659058570861816, 1.2712814807891846, 1.2617233991622925, 1.2549196481704712, 1.2464736700057983, 1.2503859996795654, 1.2421901226043701, 1.2392232418060303, 1.2306989431381226, 1.224501371383667, 1.2218106985092163, 1.2168571949005127, 1.2129631042480469, 1.2109116315841675, 1.208339810371399, 1.2102344036102295, 1.1982975006103516, 1.198378324508667, 1.2254716157913208, 1.1896822452545166, 1.1868571043014526, 1.1844509840011597, 1.1793462038040161, 1.1895830631256104, 1.1748489141464233, 1.171873688697815, 1.1849000453948975, 1.2001395225524902, 1.1679797172546387, 1.18250572681427, 1.1730213165283203, 1.17630934715271, 1.1610615253448486, 1.15708589553833, 1.154459834098816, 1.1578034162521362], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48243802785873413, 0.47830578684806824, 0.48553720116615295, 0.47830578684806824, 0.48243802785873413, 0.48243802785873413, 0.5433884263038635, 0.48553720116615295, 0.5371900796890259, 0.5072314143180847, 0.5103305578231812, 0.5568181872367859, 0.5516529083251953, 0.538223147392273, 0.5847107172012329, 0.5940082669258118, 0.5785123705863953, 0.5960744023323059, 0.5547520518302917, 0.5764462947845459, 0.6188016533851624, 0.6095041036605835, 0.6002066135406494, 0.6219007968902588, 0.6239669322967529, 0.6136363744735718, 0.5413222908973694, 0.6260330677032471, 0.6002066135406494, 0.6239669322967529, 0.6280992031097412, 0.6291322112083435, 0.6198347210884094, 0.6074380278587341, 0.6311983466148376, 0.6260330677032471, 0.6105371713638306, 0.625, 0.6260330677032471, 0.6002066135406494, 0.6219007968902588, 0.6177685856819153, 0.6167355179786682, 0.6136363744735718, 0.6002066135406494, 0.6136363744735718, 0.6177685856819153, 0.6126033067703247, 0.5950413346290588, 0.6105371713638306, 0.6095041036605835, 0.6198347210884094, 0.6136363744735718, 0.5960744023323059, 0.6270661354064941, 0.6095041036605835, 0.6260330677032471, 0.6239669322967529, 0.6146694421768188, 0.6280992031097412, 0.6188016533851624, 0.6188016533851624, 0.6002066135406494, 0.6115702390670776, 0.6105371713638306, 0.6188016533851624, 0.5991735458374023, 0.6115702390670776, 0.6239669322967529, 0.6105371713638306, 0.6239669322967529, 0.6177685856819153, 0.6188016533851624, 0.6280992031097412, 0.6157024502754211, 0.6074380278587341, 0.6229338645935059, 0.6198347210884094, 0.6126033067703247, 0.5816115736961365, 0.6136363744735718, 0.6167355179786682, 0.6167355179786682, 0.6188016533851624, 0.5971074104309082, 0.6136363744735718, 0.6198347210884094, 0.5909090638160706, 0.5919421315193176, 0.6208677887916565, 0.6115702390670776, 0.6136363744735718, 0.5960744023323059, 0.6095041036605835, 0.6177685856819153, 0.6146694421768188, 0.6105371713638306]}\n","32/32 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 1.0414 - accuracy: 0.7296"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 4s 36ms/step - loss: 1.0419 - accuracy: 0.7295 - val_loss: 1.1701 - val_accuracy: 0.5151\n","Epoch 2/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0275 - accuracy: 0.7295 - val_loss: 1.1660 - val_accuracy: 0.5032\n","Epoch 3/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.0146 - accuracy: 0.7408 - val_loss: 1.1599 - val_accuracy: 0.5226\n","Epoch 4/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.0084 - accuracy: 0.7443 - val_loss: 1.1536 - val_accuracy: 0.5399\n","Epoch 5/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0029 - accuracy: 0.7470 - val_loss: 1.1499 - val_accuracy: 0.5280\n","Epoch 6/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9950 - accuracy: 0.7513 - val_loss: 1.1430 - val_accuracy: 0.5517\n","Epoch 7/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9904 - accuracy: 0.7454 - val_loss: 1.1436 - val_accuracy: 0.5205\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9790 - accuracy: 0.7565 - val_loss: 1.1329 - val_accuracy: 0.5517\n","Epoch 9/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9803 - accuracy: 0.7497 - val_loss: 1.1340 - val_accuracy: 0.5269\n","Epoch 10/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9706 - accuracy: 0.7578 - val_loss: 1.1349 - val_accuracy: 0.5194\n","Epoch 11/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9638 - accuracy: 0.7632 - val_loss: 1.1263 - val_accuracy: 0.5377\n","Epoch 12/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9669 - accuracy: 0.7473 - val_loss: 1.1261 - val_accuracy: 0.5345\n","Epoch 13/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9519 - accuracy: 0.7664 - val_loss: 1.1299 - val_accuracy: 0.5302\n","Epoch 14/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9440 - accuracy: 0.7707 - val_loss: 1.1204 - val_accuracy: 0.5485\n","Epoch 15/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.9382 - accuracy: 0.7759 - val_loss: 1.1174 - val_accuracy: 0.5571\n","Epoch 16/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9355 - accuracy: 0.7664 - val_loss: 1.1270 - val_accuracy: 0.5506\n","Epoch 17/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9290 - accuracy: 0.7737 - val_loss: 1.1120 - val_accuracy: 0.5754\n","Epoch 18/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9299 - accuracy: 0.7759 - val_loss: 1.1627 - val_accuracy: 0.5377\n","Epoch 19/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9220 - accuracy: 0.7732 - val_loss: 1.0981 - val_accuracy: 0.5916\n","Epoch 20/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9222 - accuracy: 0.7748 - val_loss: 1.1142 - val_accuracy: 0.5894\n","Epoch 21/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9110 - accuracy: 0.7812 - val_loss: 1.1221 - val_accuracy: 0.5808\n","Epoch 22/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.9073 - accuracy: 0.7845 - val_loss: 1.1059 - val_accuracy: 0.5970\n","Epoch 23/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9013 - accuracy: 0.7869 - val_loss: 1.1578 - val_accuracy: 0.5625\n","Epoch 24/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9044 - accuracy: 0.7748 - val_loss: 1.1029 - val_accuracy: 0.6196\n","Epoch 25/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.8926 - accuracy: 0.7920 - val_loss: 1.0554 - val_accuracy: 0.6476\n","Epoch 26/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.8857 - accuracy: 0.7907 - val_loss: 1.0467 - val_accuracy: 0.6584\n","Epoch 27/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.8840 - accuracy: 0.7904 - val_loss: 1.0481 - val_accuracy: 0.6627\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8831 - accuracy: 0.7848 - val_loss: 1.0679 - val_accuracy: 0.6412\n","Epoch 29/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8723 - accuracy: 0.7980 - val_loss: 1.0526 - val_accuracy: 0.6573\n","Epoch 30/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8676 - accuracy: 0.8025 - val_loss: 1.0690 - val_accuracy: 0.6476\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8638 - accuracy: 0.8036 - val_loss: 1.0481 - val_accuracy: 0.6616\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8549 - accuracy: 0.8082 - val_loss: 1.0704 - val_accuracy: 0.6487\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8612 - accuracy: 0.7998 - val_loss: 1.0547 - val_accuracy: 0.6519\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8667 - accuracy: 0.7842 - val_loss: 1.0484 - val_accuracy: 0.6573\n","Epoch 35/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8483 - accuracy: 0.8066 - val_loss: 1.0613 - val_accuracy: 0.6519\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8465 - accuracy: 0.8066 - val_loss: 1.0594 - val_accuracy: 0.6422\n","Epoch 37/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8489 - accuracy: 0.7990 - val_loss: 1.0729 - val_accuracy: 0.6455\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8457 - accuracy: 0.7998 - val_loss: 1.0486 - val_accuracy: 0.6573\n","Epoch 39/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8329 - accuracy: 0.8133 - val_loss: 1.0482 - val_accuracy: 0.6606\n","Epoch 40/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8319 - accuracy: 0.8079 - val_loss: 1.0509 - val_accuracy: 0.6541\n","Epoch 41/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8263 - accuracy: 0.8184 - val_loss: 1.0607 - val_accuracy: 0.6487\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8188 - accuracy: 0.8200 - val_loss: 1.0512 - val_accuracy: 0.6498\n","Epoch 43/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8143 - accuracy: 0.8168 - val_loss: 1.0677 - val_accuracy: 0.6466\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8048 - accuracy: 0.8284 - val_loss: 1.0585 - val_accuracy: 0.6519\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7982 - accuracy: 0.8376 - val_loss: 1.0488 - val_accuracy: 0.6562\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8043 - accuracy: 0.8262 - val_loss: 1.0659 - val_accuracy: 0.6455\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8014 - accuracy: 0.8249 - val_loss: 1.0623 - val_accuracy: 0.6552\n","Epoch 48/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7976 - accuracy: 0.8270 - val_loss: 1.0515 - val_accuracy: 0.6552\n","Epoch 49/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7907 - accuracy: 0.8324 - val_loss: 1.0511 - val_accuracy: 0.6616\n","Epoch 50/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.7793 - accuracy: 0.8376 - val_loss: 1.0513 - val_accuracy: 0.6670\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7768 - accuracy: 0.8443 - val_loss: 1.0617 - val_accuracy: 0.6530\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7892 - accuracy: 0.8273 - val_loss: 1.0510 - val_accuracy: 0.6659\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7676 - accuracy: 0.8435 - val_loss: 1.0560 - val_accuracy: 0.6562\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7655 - accuracy: 0.8440 - val_loss: 1.0544 - val_accuracy: 0.6595\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7578 - accuracy: 0.8494 - val_loss: 1.0561 - val_accuracy: 0.6573\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7584 - accuracy: 0.8454 - val_loss: 1.0583 - val_accuracy: 0.6606\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7539 - accuracy: 0.8459 - val_loss: 1.0632 - val_accuracy: 0.6509\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7487 - accuracy: 0.8502 - val_loss: 1.0687 - val_accuracy: 0.6498\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7564 - accuracy: 0.8351 - val_loss: 1.0719 - val_accuracy: 0.6552\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7411 - accuracy: 0.8583 - val_loss: 1.0678 - val_accuracy: 0.6519\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7443 - accuracy: 0.8475 - val_loss: 1.0654 - val_accuracy: 0.6606\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7316 - accuracy: 0.8586 - val_loss: 1.0759 - val_accuracy: 0.6552\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7277 - accuracy: 0.8594 - val_loss: 1.0862 - val_accuracy: 0.6444\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7246 - accuracy: 0.8648 - val_loss: 1.0906 - val_accuracy: 0.6412\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7302 - accuracy: 0.8543 - val_loss: 1.0698 - val_accuracy: 0.6595\n","Epoch 66/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7181 - accuracy: 0.8650 - val_loss: 1.0833 - val_accuracy: 0.6498\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7162 - accuracy: 0.8645 - val_loss: 1.0839 - val_accuracy: 0.6530\n","Epoch 68/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7174 - accuracy: 0.8664 - val_loss: 1.0761 - val_accuracy: 0.6552\n","Epoch 69/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7124 - accuracy: 0.8677 - val_loss: 1.0881 - val_accuracy: 0.6466\n","Epoch 70/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7063 - accuracy: 0.8637 - val_loss: 1.0745 - val_accuracy: 0.6573\n","Epoch 71/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6930 - accuracy: 0.8804 - val_loss: 1.0849 - val_accuracy: 0.6498\n","Epoch 72/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6930 - accuracy: 0.8755 - val_loss: 1.0803 - val_accuracy: 0.6562\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6902 - accuracy: 0.8720 - val_loss: 1.1027 - val_accuracy: 0.6466\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6879 - accuracy: 0.8753 - val_loss: 1.0904 - val_accuracy: 0.6530\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6763 - accuracy: 0.8850 - val_loss: 1.0844 - val_accuracy: 0.6498\n","Epoch 76/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6726 - accuracy: 0.8887 - val_loss: 1.0906 - val_accuracy: 0.6638\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6680 - accuracy: 0.8917 - val_loss: 1.0892 - val_accuracy: 0.6530\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6697 - accuracy: 0.8855 - val_loss: 1.0937 - val_accuracy: 0.6476\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6686 - accuracy: 0.8804 - val_loss: 1.0933 - val_accuracy: 0.6606\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6582 - accuracy: 0.8909 - val_loss: 1.1096 - val_accuracy: 0.6498\n","Epoch 81/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6526 - accuracy: 0.8904 - val_loss: 1.0980 - val_accuracy: 0.6509\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6498 - accuracy: 0.8933 - val_loss: 1.1014 - val_accuracy: 0.6541\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6436 - accuracy: 0.8966 - val_loss: 1.1084 - val_accuracy: 0.6455\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6420 - accuracy: 0.8957 - val_loss: 1.1105 - val_accuracy: 0.6606\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6470 - accuracy: 0.8922 - val_loss: 1.1249 - val_accuracy: 0.6466\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6343 - accuracy: 0.9014 - val_loss: 1.1096 - val_accuracy: 0.6552\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6311 - accuracy: 0.8995 - val_loss: 1.1176 - val_accuracy: 0.6509\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6220 - accuracy: 0.9084 - val_loss: 1.1237 - val_accuracy: 0.6433\n","Epoch 89/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6261 - accuracy: 0.9033 - val_loss: 1.1654 - val_accuracy: 0.6444\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6313 - accuracy: 0.8936 - val_loss: 1.1229 - val_accuracy: 0.6487\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6228 - accuracy: 0.9049 - val_loss: 1.1401 - val_accuracy: 0.6476\n","Epoch 92/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6126 - accuracy: 0.9060 - val_loss: 1.1484 - val_accuracy: 0.6541\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6070 - accuracy: 0.9124 - val_loss: 1.1319 - val_accuracy: 0.6455\n","Epoch 94/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6029 - accuracy: 0.9106 - val_loss: 1.1337 - val_accuracy: 0.6466\n","Epoch 95/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6023 - accuracy: 0.9111 - val_loss: 1.1516 - val_accuracy: 0.6422\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5958 - accuracy: 0.9157 - val_loss: 1.1426 - val_accuracy: 0.6476\n","Epoch 97/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5889 - accuracy: 0.9219 - val_loss: 1.1733 - val_accuracy: 0.6422\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5883 - accuracy: 0.9216 - val_loss: 1.1557 - val_accuracy: 0.6487\n","Epoch 99/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5854 - accuracy: 0.9238 - val_loss: 1.1937 - val_accuracy: 0.6466\n","Epoch 100/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5787 - accuracy: 0.9221 - val_loss: 1.1752 - val_accuracy: 0.6455\n","{'loss': [1.0419230461120605, 1.0274780988693237, 1.0145726203918457, 1.0083725452423096, 1.002931833267212, 0.9950008392333984, 0.9903701543807983, 0.979032576084137, 0.9803354144096375, 0.9706394672393799, 0.9638485312461853, 0.9668875932693481, 0.9519280791282654, 0.943994402885437, 0.9381719827651978, 0.9355112314224243, 0.9290493130683899, 0.929873526096344, 0.9220002293586731, 0.9222341179847717, 0.9110099673271179, 0.9072855114936829, 0.9013276100158691, 0.9043771028518677, 0.8926098942756653, 0.885718047618866, 0.8840212821960449, 0.8830660581588745, 0.8723042607307434, 0.867620587348938, 0.8638290762901306, 0.8548552989959717, 0.8611547350883484, 0.8666991591453552, 0.8482846021652222, 0.8464837074279785, 0.8488888740539551, 0.845660924911499, 0.8328795433044434, 0.8319335579872131, 0.826321542263031, 0.8187598586082458, 0.8142572641372681, 0.8047677874565125, 0.7982116341590881, 0.8042868971824646, 0.801392138004303, 0.797610342502594, 0.7907280921936035, 0.7792907357215881, 0.7768312692642212, 0.7891663908958435, 0.7676329016685486, 0.7654612064361572, 0.7578299045562744, 0.7583761811256409, 0.7539442777633667, 0.7487455010414124, 0.7564360499382019, 0.741102933883667, 0.7442580461502075, 0.7316354513168335, 0.7277263402938843, 0.7246037721633911, 0.7302240133285522, 0.7180580496788025, 0.7161632776260376, 0.7173751592636108, 0.7124031186103821, 0.7062535881996155, 0.6929780840873718, 0.6929831504821777, 0.6902117133140564, 0.6879000663757324, 0.6762554049491882, 0.6725716590881348, 0.667953610420227, 0.6696754693984985, 0.6685953736305237, 0.6582164168357849, 0.6525834798812866, 0.6498207449913025, 0.6435938477516174, 0.6419989466667175, 0.6470111608505249, 0.6342724561691284, 0.6311487555503845, 0.6219655275344849, 0.6261354684829712, 0.6313411593437195, 0.6227614879608154, 0.6126441359519958, 0.6069986820220947, 0.6028943657875061, 0.6022971868515015, 0.5958137512207031, 0.5888627171516418, 0.5883417725563049, 0.5854181051254272, 0.5786888003349304], 'accuracy': [0.7295258641242981, 0.7295258641242981, 0.740840494632721, 0.7443426847457886, 0.7470366358757019, 0.751347005367279, 0.7454202771186829, 0.756465494632721, 0.7497305870056152, 0.7578125, 0.7632004022598267, 0.7473060488700867, 0.7664331793785095, 0.7707435488700867, 0.7758620977401733, 0.7664331793785095, 0.7737069129943848, 0.7758620977401733, 0.7731680870056152, 0.774784505367279, 0.78125, 0.7844827771186829, 0.7869073152542114, 0.774784505367279, 0.7920258641242981, 0.790678858757019, 0.790409505367279, 0.7847521305084229, 0.7979525923728943, 0.8025323152542114, 0.8036099076271057, 0.8081896305084229, 0.7998383641242981, 0.7842133641242981, 0.8065732717514038, 0.8065732717514038, 0.7990301847457886, 0.7998383641242981, 0.8133081793785095, 0.8079202771186829, 0.8184267282485962, 0.8200430870056152, 0.8168103694915771, 0.8283944129943848, 0.837553858757019, 0.8262392282485962, 0.8248922228813171, 0.8270474076271057, 0.8324353694915771, 0.837553858757019, 0.8442887663841248, 0.8273168206214905, 0.8434805870056152, 0.8440194129943848, 0.8494073152542114, 0.845366358757019, 0.8459051847457886, 0.850215494632721, 0.8351293206214905, 0.8582974076271057, 0.8475215435028076, 0.8585668206214905, 0.859375, 0.8647629022598267, 0.8542564511299133, 0.8650323152542114, 0.8644935488700867, 0.8663793206214905, 0.8677262663841248, 0.8636853694915771, 0.8803879022598267, 0.8755387663841248, 0.8720366358757019, 0.8752694129943848, 0.8849676847457886, 0.8887392282485962, 0.8917025923728943, 0.8855064511299133, 0.8803879022598267, 0.8908944129943848, 0.8903555870056152, 0.8933189511299133, 0.8965517282485962, 0.8957435488700867, 0.892241358757019, 0.9014008641242981, 0.8995150923728943, 0.9084051847457886, 0.9032866358757019, 0.8935883641242981, 0.904902994632721, 0.9059805870056152, 0.912446141242981, 0.9105603694915771, 0.9110991358757019, 0.915678858757019, 0.921875, 0.9216055870056152, 0.9237607717514038, 0.9221444129943848], 'val_loss': [1.1701356172561646, 1.1659963130950928, 1.1599221229553223, 1.153607964515686, 1.1498782634735107, 1.1430091857910156, 1.1435989141464233, 1.1329331398010254, 1.1339869499206543, 1.1348745822906494, 1.1263169050216675, 1.1260796785354614, 1.1298748254776, 1.1204047203063965, 1.1174194812774658, 1.1270182132720947, 1.111976146697998, 1.1627463102340698, 1.098109483718872, 1.1142345666885376, 1.122122883796692, 1.1058942079544067, 1.1577779054641724, 1.102941632270813, 1.0554007291793823, 1.0466814041137695, 1.048117756843567, 1.067893147468567, 1.0525987148284912, 1.0689657926559448, 1.0481258630752563, 1.0703524351119995, 1.0547453165054321, 1.0483609437942505, 1.0612813234329224, 1.0594310760498047, 1.0728795528411865, 1.04864501953125, 1.0482048988342285, 1.050862431526184, 1.0607118606567383, 1.051156997680664, 1.0677202939987183, 1.0585148334503174, 1.0487929582595825, 1.0658997297286987, 1.0622543096542358, 1.0515031814575195, 1.0511209964752197, 1.051293134689331, 1.061689019203186, 1.05103600025177, 1.056003451347351, 1.054417371749878, 1.0560857057571411, 1.0582927465438843, 1.0631914138793945, 1.068695068359375, 1.0719165802001953, 1.0677539110183716, 1.0654021501541138, 1.0759034156799316, 1.0862421989440918, 1.090612530708313, 1.0698044300079346, 1.0832853317260742, 1.0838555097579956, 1.0761139392852783, 1.0880974531173706, 1.074470043182373, 1.0849335193634033, 1.080321192741394, 1.1026532649993896, 1.0904455184936523, 1.0844266414642334, 1.0905537605285645, 1.0892119407653809, 1.0937368869781494, 1.0932868719100952, 1.1095768213272095, 1.0980050563812256, 1.1014071702957153, 1.1084091663360596, 1.1104546785354614, 1.1248842477798462, 1.1095508337020874, 1.1175578832626343, 1.1236586570739746, 1.1653656959533691, 1.1228892803192139, 1.1400601863861084, 1.148404836654663, 1.1318947076797485, 1.1336807012557983, 1.151638388633728, 1.1425687074661255, 1.173252820968628, 1.1557421684265137, 1.1937358379364014, 1.1751917600631714], 'val_accuracy': [0.5150862336158752, 0.5032327771186829, 0.5226293206214905, 0.5398706793785095, 0.5280172228813171, 0.5517241358757019, 0.5204741358757019, 0.5517241358757019, 0.5269396305084229, 0.5193965435028076, 0.537715494632721, 0.5344827771186829, 0.5301724076271057, 0.548491358757019, 0.5571120977401733, 0.5506465435028076, 0.5754310488700867, 0.537715494632721, 0.5915948152542114, 0.5894396305084229, 0.5808189511299133, 0.5969827771186829, 0.5625, 0.6196120977401733, 0.6476293206214905, 0.6584051847457886, 0.662715494632721, 0.6411637663841248, 0.6573275923728943, 0.6476293206214905, 0.6616379022598267, 0.6487069129943848, 0.6519396305084229, 0.6573275923728943, 0.6519396305084229, 0.642241358757019, 0.6454741358757019, 0.6573275923728943, 0.6605603694915771, 0.6540948152542114, 0.6487069129943848, 0.649784505367279, 0.6465517282485962, 0.6519396305084229, 0.65625, 0.6454741358757019, 0.6551724076271057, 0.6551724076271057, 0.6616379022598267, 0.6670258641242981, 0.6530172228813171, 0.6659482717514038, 0.65625, 0.6594827771186829, 0.6573275923728943, 0.6605603694915771, 0.6508620977401733, 0.649784505367279, 0.6551724076271057, 0.6519396305084229, 0.6605603694915771, 0.6551724076271057, 0.6443965435028076, 0.6411637663841248, 0.6594827771186829, 0.649784505367279, 0.6530172228813171, 0.6551724076271057, 0.6465517282485962, 0.6573275923728943, 0.649784505367279, 0.65625, 0.6465517282485962, 0.6530172228813171, 0.649784505367279, 0.6637930870056152, 0.6530172228813171, 0.6476293206214905, 0.6605603694915771, 0.649784505367279, 0.6508620977401733, 0.6540948152542114, 0.6454741358757019, 0.6605603694915771, 0.6465517282485962, 0.6551724076271057, 0.6508620977401733, 0.6433189511299133, 0.6443965435028076, 0.6487069129943848, 0.6476293206214905, 0.6540948152542114, 0.6454741358757019, 0.6465517282485962, 0.642241358757019, 0.6476293206214905, 0.642241358757019, 0.6487069129943848, 0.6465517282485962, 0.6454741358757019]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 1.0432 - accuracy: 0.7179"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 4s 38ms/step - loss: 1.0432 - accuracy: 0.7179 - val_loss: 1.1691 - val_accuracy: 0.5090\n","Epoch 2/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.0275 - accuracy: 0.7289 - val_loss: 1.1628 - val_accuracy: 0.5328\n","Epoch 3/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.0228 - accuracy: 0.7281 - val_loss: 1.1579 - val_accuracy: 0.5339\n","Epoch 4/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.0098 - accuracy: 0.7402 - val_loss: 1.1532 - val_accuracy: 0.5362\n","Epoch 5/100\n","28/28 [==============================] - 1s 34ms/step - loss: 1.0051 - accuracy: 0.7431 - val_loss: 1.1479 - val_accuracy: 0.5373\n","Epoch 6/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.9947 - accuracy: 0.7555 - val_loss: 1.1406 - val_accuracy: 0.5781\n","Epoch 7/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.9895 - accuracy: 0.7510 - val_loss: 1.1351 - val_accuracy: 0.5803\n","Epoch 8/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9842 - accuracy: 0.7586 - val_loss: 1.1320 - val_accuracy: 0.5566\n","Epoch 9/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9754 - accuracy: 0.7666 - val_loss: 1.1256 - val_accuracy: 0.5690\n","Epoch 10/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9698 - accuracy: 0.7626 - val_loss: 1.1251 - val_accuracy: 0.5554\n","Epoch 11/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9643 - accuracy: 0.7646 - val_loss: 1.1165 - val_accuracy: 0.5667\n","Epoch 12/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9593 - accuracy: 0.7699 - val_loss: 1.1068 - val_accuracy: 0.5939\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9555 - accuracy: 0.7674 - val_loss: 1.1030 - val_accuracy: 0.5848\n","Epoch 14/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9619 - accuracy: 0.7436 - val_loss: 1.0871 - val_accuracy: 0.6471\n","Epoch 15/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9529 - accuracy: 0.7527 - val_loss: 1.1241 - val_accuracy: 0.5520\n","Epoch 16/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9472 - accuracy: 0.7615 - val_loss: 1.1017 - val_accuracy: 0.5747\n","Epoch 17/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9336 - accuracy: 0.7714 - val_loss: 1.0932 - val_accuracy: 0.5928\n","Epoch 18/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9276 - accuracy: 0.7782 - val_loss: 1.0918 - val_accuracy: 0.5973\n","Epoch 19/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9224 - accuracy: 0.7796 - val_loss: 1.1004 - val_accuracy: 0.5848\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9230 - accuracy: 0.7731 - val_loss: 1.1021 - val_accuracy: 0.5826\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9159 - accuracy: 0.7796 - val_loss: 1.0854 - val_accuracy: 0.6233\n","Epoch 22/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9078 - accuracy: 0.7858 - val_loss: 1.0706 - val_accuracy: 0.6357\n","Epoch 23/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9034 - accuracy: 0.7909 - val_loss: 1.0583 - val_accuracy: 0.6527\n","Epoch 24/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9004 - accuracy: 0.7872 - val_loss: 1.0877 - val_accuracy: 0.6312\n","Epoch 25/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.8954 - accuracy: 0.7900 - val_loss: 1.0513 - val_accuracy: 0.6618\n","Epoch 26/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8896 - accuracy: 0.7963 - val_loss: 1.0953 - val_accuracy: 0.6335\n","Epoch 27/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8940 - accuracy: 0.7832 - val_loss: 1.0730 - val_accuracy: 0.6414\n","Epoch 28/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8882 - accuracy: 0.7881 - val_loss: 1.0640 - val_accuracy: 0.6516\n","Epoch 29/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8775 - accuracy: 0.7988 - val_loss: 1.0674 - val_accuracy: 0.6357\n","Epoch 30/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8736 - accuracy: 0.7940 - val_loss: 1.0596 - val_accuracy: 0.6584\n","Epoch 31/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.8665 - accuracy: 0.8045 - val_loss: 1.0521 - val_accuracy: 0.6640\n","Epoch 32/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8615 - accuracy: 0.8036 - val_loss: 1.0788 - val_accuracy: 0.6471\n","Epoch 33/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8634 - accuracy: 0.8042 - val_loss: 1.0554 - val_accuracy: 0.6550\n","Epoch 34/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8542 - accuracy: 0.8025 - val_loss: 1.0612 - val_accuracy: 0.6471\n","Epoch 35/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8553 - accuracy: 0.7977 - val_loss: 1.0921 - val_accuracy: 0.6222\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8427 - accuracy: 0.8155 - val_loss: 1.0573 - val_accuracy: 0.6595\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8398 - accuracy: 0.8158 - val_loss: 1.0593 - val_accuracy: 0.6629\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8346 - accuracy: 0.8155 - val_loss: 1.0846 - val_accuracy: 0.6290\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8337 - accuracy: 0.8067 - val_loss: 1.0615 - val_accuracy: 0.6538\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8274 - accuracy: 0.8138 - val_loss: 1.0656 - val_accuracy: 0.6471\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8224 - accuracy: 0.8164 - val_loss: 1.0657 - val_accuracy: 0.6550\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8276 - accuracy: 0.8104 - val_loss: 1.0618 - val_accuracy: 0.6550\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8173 - accuracy: 0.8186 - val_loss: 1.0643 - val_accuracy: 0.6595\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8221 - accuracy: 0.8107 - val_loss: 1.0678 - val_accuracy: 0.6561\n","Epoch 45/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8124 - accuracy: 0.8166 - val_loss: 1.0704 - val_accuracy: 0.6561\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7993 - accuracy: 0.8305 - val_loss: 1.0654 - val_accuracy: 0.6572\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8018 - accuracy: 0.8285 - val_loss: 1.0683 - val_accuracy: 0.6595\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7936 - accuracy: 0.8319 - val_loss: 1.0677 - val_accuracy: 0.6584\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7965 - accuracy: 0.8265 - val_loss: 1.0823 - val_accuracy: 0.6550\n","Epoch 50/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7953 - accuracy: 0.8277 - val_loss: 1.0734 - val_accuracy: 0.6527\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7787 - accuracy: 0.8356 - val_loss: 1.0867 - val_accuracy: 0.6267\n","Epoch 52/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7803 - accuracy: 0.8384 - val_loss: 1.0722 - val_accuracy: 0.6527\n","Epoch 53/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7850 - accuracy: 0.8314 - val_loss: 1.0834 - val_accuracy: 0.6538\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7825 - accuracy: 0.8325 - val_loss: 1.0757 - val_accuracy: 0.6572\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7659 - accuracy: 0.8452 - val_loss: 1.1047 - val_accuracy: 0.6312\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7670 - accuracy: 0.8404 - val_loss: 1.0799 - val_accuracy: 0.6538\n","Epoch 57/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7571 - accuracy: 0.8495 - val_loss: 1.0773 - val_accuracy: 0.6527\n","Epoch 58/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7498 - accuracy: 0.8512 - val_loss: 1.0816 - val_accuracy: 0.6471\n","Epoch 59/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7452 - accuracy: 0.8568 - val_loss: 1.0916 - val_accuracy: 0.6324\n","Epoch 60/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7412 - accuracy: 0.8563 - val_loss: 1.0898 - val_accuracy: 0.6550\n","Epoch 61/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7393 - accuracy: 0.8565 - val_loss: 1.0925 - val_accuracy: 0.6493\n","Epoch 62/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7540 - accuracy: 0.8398 - val_loss: 1.0886 - val_accuracy: 0.6505\n","Epoch 63/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7323 - accuracy: 0.8596 - val_loss: 1.0917 - val_accuracy: 0.6471\n","Epoch 64/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7315 - accuracy: 0.8596 - val_loss: 1.0961 - val_accuracy: 0.6584\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7265 - accuracy: 0.8608 - val_loss: 1.1368 - val_accuracy: 0.6210\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7371 - accuracy: 0.8497 - val_loss: 1.1213 - val_accuracy: 0.6222\n","Epoch 67/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7210 - accuracy: 0.8596 - val_loss: 1.1380 - val_accuracy: 0.6199\n","Epoch 68/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7250 - accuracy: 0.8543 - val_loss: 1.1015 - val_accuracy: 0.6414\n","Epoch 69/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7111 - accuracy: 0.8667 - val_loss: 1.1338 - val_accuracy: 0.6210\n","Epoch 70/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7156 - accuracy: 0.8599 - val_loss: 1.1156 - val_accuracy: 0.6425\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7201 - accuracy: 0.8585 - val_loss: 1.1033 - val_accuracy: 0.6448\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6986 - accuracy: 0.8741 - val_loss: 1.1130 - val_accuracy: 0.6538\n","Epoch 73/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6963 - accuracy: 0.8673 - val_loss: 1.1433 - val_accuracy: 0.6369\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7060 - accuracy: 0.8642 - val_loss: 1.1347 - val_accuracy: 0.6233\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6886 - accuracy: 0.8729 - val_loss: 1.1431 - val_accuracy: 0.6346\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6959 - accuracy: 0.8676 - val_loss: 1.1130 - val_accuracy: 0.6414\n","Epoch 77/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6816 - accuracy: 0.8783 - val_loss: 1.1441 - val_accuracy: 0.6391\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6805 - accuracy: 0.8829 - val_loss: 1.1164 - val_accuracy: 0.6437\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6682 - accuracy: 0.8874 - val_loss: 1.1260 - val_accuracy: 0.6391\n","Epoch 80/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6640 - accuracy: 0.8882 - val_loss: 1.1288 - val_accuracy: 0.6403\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6599 - accuracy: 0.8956 - val_loss: 1.1286 - val_accuracy: 0.6391\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6592 - accuracy: 0.8868 - val_loss: 1.1286 - val_accuracy: 0.6437\n","Epoch 83/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6559 - accuracy: 0.8916 - val_loss: 1.1327 - val_accuracy: 0.6505\n","Epoch 84/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6490 - accuracy: 0.8930 - val_loss: 1.1429 - val_accuracy: 0.6357\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6468 - accuracy: 0.8947 - val_loss: 1.1386 - val_accuracy: 0.6493\n","Epoch 86/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6458 - accuracy: 0.8964 - val_loss: 1.1451 - val_accuracy: 0.6414\n","Epoch 87/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6352 - accuracy: 0.9032 - val_loss: 1.1378 - val_accuracy: 0.6403\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6357 - accuracy: 0.9015 - val_loss: 1.1651 - val_accuracy: 0.6335\n","Epoch 89/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6423 - accuracy: 0.8871 - val_loss: 1.1568 - val_accuracy: 0.6482\n","Epoch 90/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6265 - accuracy: 0.9032 - val_loss: 1.2397 - val_accuracy: 0.6244\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6442 - accuracy: 0.8891 - val_loss: 1.2135 - val_accuracy: 0.6120\n","Epoch 92/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6298 - accuracy: 0.9024 - val_loss: 1.1690 - val_accuracy: 0.6448\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6260 - accuracy: 0.9021 - val_loss: 1.2013 - val_accuracy: 0.6143\n","Epoch 94/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6196 - accuracy: 0.9055 - val_loss: 1.1719 - val_accuracy: 0.6505\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6187 - accuracy: 0.9041 - val_loss: 1.1683 - val_accuracy: 0.6414\n","Epoch 96/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6074 - accuracy: 0.9157 - val_loss: 1.1816 - val_accuracy: 0.6324\n","Epoch 97/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6045 - accuracy: 0.9148 - val_loss: 1.1790 - val_accuracy: 0.6471\n","Epoch 98/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6017 - accuracy: 0.9154 - val_loss: 1.1767 - val_accuracy: 0.6391\n","Epoch 99/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5921 - accuracy: 0.9205 - val_loss: 1.1782 - val_accuracy: 0.6369\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5955 - accuracy: 0.9188 - val_loss: 1.2129 - val_accuracy: 0.6244\n","{'loss': [1.043188214302063, 1.02745521068573, 1.0228153467178345, 1.0098209381103516, 1.0051028728485107, 0.9946663975715637, 0.9895015954971313, 0.9842081069946289, 0.9753658175468445, 0.9697847366333008, 0.964299738407135, 0.9593059420585632, 0.9554616212844849, 0.9618910551071167, 0.9528619050979614, 0.947217583656311, 0.9336389303207397, 0.9275605082511902, 0.9223825335502625, 0.9230186343193054, 0.9158793687820435, 0.9078023433685303, 0.9033665060997009, 0.9004314541816711, 0.8953611254692078, 0.8896178603172302, 0.8939903378486633, 0.8881889581680298, 0.8774586915969849, 0.8736055493354797, 0.86653733253479, 0.8615396022796631, 0.8633565306663513, 0.8541829586029053, 0.855331540107727, 0.84266197681427, 0.8398107290267944, 0.83464515209198, 0.8337490558624268, 0.827405571937561, 0.822443425655365, 0.827622652053833, 0.8172680139541626, 0.8221043944358826, 0.8123511672019958, 0.7992694973945618, 0.801755964756012, 0.7935741543769836, 0.7964740991592407, 0.795341968536377, 0.7786806225776672, 0.7803157567977905, 0.7850171327590942, 0.7824735641479492, 0.7659454941749573, 0.7669799327850342, 0.7571409344673157, 0.7497845888137817, 0.7451702952384949, 0.7411959171295166, 0.7393047213554382, 0.7540464401245117, 0.7323289513587952, 0.731513500213623, 0.726524293422699, 0.7370875477790833, 0.7209814786911011, 0.7250224947929382, 0.7111425399780273, 0.7156311869621277, 0.7200680375099182, 0.6985813975334167, 0.6963343024253845, 0.7059772610664368, 0.68855881690979, 0.695866048336029, 0.681586503982544, 0.6804513335227966, 0.6682120561599731, 0.6640304327011108, 0.6599352955818176, 0.6591669917106628, 0.6559386849403381, 0.6489856839179993, 0.6467757225036621, 0.645794689655304, 0.6352018117904663, 0.6357007622718811, 0.6423331499099731, 0.6264691948890686, 0.6442058086395264, 0.6297737956047058, 0.6260279417037964, 0.6196286082267761, 0.6187363266944885, 0.6074027419090271, 0.6044749021530151, 0.60173499584198, 0.5921245217323303, 0.5955368280410767], 'accuracy': [0.7178834080696106, 0.7289190888404846, 0.7280701994895935, 0.7402377128601074, 0.7430673241615295, 0.755517840385437, 0.7509903907775879, 0.7586304545402527, 0.7665534615516663, 0.7625919580459595, 0.7645727396011353, 0.7699490785598755, 0.7674023509025574, 0.7436332702636719, 0.7526881694793701, 0.7614601254463196, 0.7713639140129089, 0.7781550884246826, 0.7795698642730713, 0.7730616927146912, 0.7795698642730713, 0.7857951521873474, 0.7908884882926941, 0.7872099876403809, 0.790039598941803, 0.7962648272514343, 0.7832484245300293, 0.788058876991272, 0.7988115549087524, 0.7940011024475098, 0.8044708371162415, 0.8036219477653503, 0.8041878938674927, 0.8024901151657104, 0.7976796627044678, 0.8155065178871155, 0.8157894611358643, 0.8155065178871155, 0.806734561920166, 0.8138087391853333, 0.8163554072380066, 0.810413122177124, 0.8186191320419312, 0.8106960654258728, 0.8166383504867554, 0.8305037021636963, 0.8285229206085205, 0.831918478012085, 0.8265421390533447, 0.8276740312576294, 0.835597038269043, 0.8384267091751099, 0.8313525915145874, 0.8324844241142273, 0.8452178835868835, 0.8404074907302856, 0.8494623899459839, 0.8511601686477661, 0.8568194508552551, 0.8562535643577576, 0.8565365076065063, 0.8398415446281433, 0.859649121761322, 0.859649121761322, 0.8607810139656067, 0.8497453331947327, 0.859649121761322, 0.8542727828025818, 0.8667232394218445, 0.8599320650100708, 0.8585172891616821, 0.8740803599357605, 0.8672891855239868, 0.8641765713691711, 0.8729485273361206, 0.8675721287727356, 0.8783248662948608, 0.88285231590271, 0.8873797655105591, 0.8882286548614502, 0.8955857157707214, 0.8868138194084167, 0.8916242122650146, 0.8930390477180481, 0.8947368264198303, 0.8964346647262573, 0.9032257795333862, 0.901528000831604, 0.8870967626571655, 0.9032257795333862, 0.8890775442123413, 0.9023768901824951, 0.9020939469337463, 0.9054895043373108, 0.9040747284889221, 0.9156762957572937, 0.9148274064064026, 0.9153932929039001, 0.9204866886138916, 0.9187889099121094], 'val_loss': [1.1691477298736572, 1.1627880334854126, 1.1579240560531616, 1.1532350778579712, 1.1479036808013916, 1.1406257152557373, 1.135132908821106, 1.1319748163223267, 1.1255568265914917, 1.125059962272644, 1.1164977550506592, 1.1067819595336914, 1.1029778718948364, 1.087073564529419, 1.1240712404251099, 1.1017394065856934, 1.0932435989379883, 1.091783046722412, 1.1003645658493042, 1.1021082401275635, 1.0854390859603882, 1.0705549716949463, 1.058251976966858, 1.0876511335372925, 1.0512698888778687, 1.0953091382980347, 1.0730196237564087, 1.063977599143982, 1.0673677921295166, 1.0595625638961792, 1.0520533323287964, 1.0787838697433472, 1.055409550666809, 1.0611704587936401, 1.092093586921692, 1.0573338270187378, 1.0592622756958008, 1.0846425294876099, 1.0615075826644897, 1.0655503273010254, 1.0657341480255127, 1.0617908239364624, 1.0642898082733154, 1.0678298473358154, 1.0703933238983154, 1.065398931503296, 1.0683276653289795, 1.0677136182785034, 1.0823241472244263, 1.0733897686004639, 1.0866857767105103, 1.0721524953842163, 1.0834459066390991, 1.0757337808609009, 1.1047483682632446, 1.0798780918121338, 1.0773391723632812, 1.0815807580947876, 1.0915507078170776, 1.0897763967514038, 1.0924807786941528, 1.0886157751083374, 1.0917049646377563, 1.0960986614227295, 1.1367841958999634, 1.1213428974151611, 1.1379905939102173, 1.1014561653137207, 1.1338180303573608, 1.1155612468719482, 1.1033331155776978, 1.1130045652389526, 1.1433130502700806, 1.1346861124038696, 1.1430667638778687, 1.1130406856536865, 1.1440610885620117, 1.1164000034332275, 1.1260335445404053, 1.1287600994110107, 1.1285645961761475, 1.1286224126815796, 1.1326863765716553, 1.1429193019866943, 1.138577938079834, 1.145095705986023, 1.137796401977539, 1.16505765914917, 1.1567611694335938, 1.2396718263626099, 1.2134932279586792, 1.1689627170562744, 1.2013468742370605, 1.171868085861206, 1.1683201789855957, 1.1815719604492188, 1.1790167093276978, 1.1767175197601318, 1.1781907081604004, 1.2129074335098267], 'val_accuracy': [0.5090497732162476, 0.5328054428100586, 0.5339366793632507, 0.5361990928649902, 0.5373303294181824, 0.5780543088912964, 0.5803167223930359, 0.5565611124038696, 0.5690045356750488, 0.5554298758506775, 0.5667420625686646, 0.5938913822174072, 0.5848416090011597, 0.6470588445663452, 0.5520362257957458, 0.5746606588363647, 0.5927602052688599, 0.5972850918769836, 0.5848416090011597, 0.5825791954994202, 0.6233031749725342, 0.6357465982437134, 0.6527149081230164, 0.6312217116355896, 0.6617646813392639, 0.6334841847419739, 0.6414027214050293, 0.651583731174469, 0.6357465982437134, 0.6583710312843323, 0.6640271544456482, 0.6470588445663452, 0.6549773812294006, 0.6470588445663452, 0.622171938419342, 0.6595022678375244, 0.662895917892456, 0.6289592981338501, 0.6538461446762085, 0.6470588445663452, 0.6549773812294006, 0.6549773812294006, 0.6595022678375244, 0.6561086177825928, 0.6561086177825928, 0.6572397947311401, 0.6595022678375244, 0.6583710312843323, 0.6549773812294006, 0.6527149081230164, 0.6266968250274658, 0.6527149081230164, 0.6538461446762085, 0.6572397947311401, 0.6312217116355896, 0.6538461446762085, 0.6527149081230164, 0.6470588445663452, 0.6323529481887817, 0.6549773812294006, 0.6493212580680847, 0.6504524946212769, 0.6470588445663452, 0.6583710312843323, 0.6210407018661499, 0.622171938419342, 0.6199095249176025, 0.6414027214050293, 0.6210407018661499, 0.6425339579582214, 0.6447963714599609, 0.6538461446762085, 0.6368778347969055, 0.6233031749725342, 0.6346153616905212, 0.6414027214050293, 0.639140248298645, 0.6436651349067688, 0.639140248298645, 0.6402714848518372, 0.639140248298645, 0.6436651349067688, 0.6504524946212769, 0.6357465982437134, 0.6493212580680847, 0.6414027214050293, 0.6402714848518372, 0.6334841847419739, 0.6481900215148926, 0.6244344115257263, 0.6119909286499023, 0.6447963714599609, 0.6142534017562866, 0.6504524946212769, 0.6414027214050293, 0.6323529481887817, 0.6470588445663452, 0.639140248298645, 0.6368778347969055, 0.6244344115257263]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 1.0626 - accuracy: 0.7042"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 5s 35ms/step - loss: 1.0602 - accuracy: 0.7065 - val_loss: 1.1716 - val_accuracy: 0.4917\n","Epoch 2/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.0507 - accuracy: 0.7134 - val_loss: 1.1650 - val_accuracy: 0.5176\n","Epoch 3/100\n","31/31 [==============================] - 1s 29ms/step - loss: 1.0368 - accuracy: 0.7189 - val_loss: 1.1596 - val_accuracy: 0.5341\n","Epoch 4/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0328 - accuracy: 0.7227 - val_loss: 1.1539 - val_accuracy: 0.5537\n","Epoch 5/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0234 - accuracy: 0.7233 - val_loss: 1.1499 - val_accuracy: 0.5320\n","Epoch 6/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0215 - accuracy: 0.7225 - val_loss: 1.1408 - val_accuracy: 0.6054\n","Epoch 7/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0203 - accuracy: 0.7183 - val_loss: 1.1414 - val_accuracy: 0.5279\n","Epoch 8/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0052 - accuracy: 0.7300 - val_loss: 1.1355 - val_accuracy: 0.5537\n","Epoch 9/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0004 - accuracy: 0.7333 - val_loss: 1.1267 - val_accuracy: 0.5878\n","Epoch 10/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0062 - accuracy: 0.7134 - val_loss: 1.1205 - val_accuracy: 0.5971\n","Epoch 11/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9882 - accuracy: 0.7336 - val_loss: 1.1241 - val_accuracy: 0.5610\n","Epoch 12/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9820 - accuracy: 0.7395 - val_loss: 1.1217 - val_accuracy: 0.5558\n","Epoch 13/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9778 - accuracy: 0.7421 - val_loss: 1.1118 - val_accuracy: 0.5826\n","Epoch 14/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9714 - accuracy: 0.7452 - val_loss: 1.1015 - val_accuracy: 0.5971\n","Epoch 15/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9677 - accuracy: 0.7455 - val_loss: 1.1052 - val_accuracy: 0.5909\n","Epoch 16/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9622 - accuracy: 0.7463 - val_loss: 1.0906 - val_accuracy: 0.6054\n","Epoch 17/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9606 - accuracy: 0.7501 - val_loss: 1.0895 - val_accuracy: 0.6043\n","Epoch 18/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.9571 - accuracy: 0.7447 - val_loss: 1.0772 - val_accuracy: 0.6126\n","Epoch 19/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9500 - accuracy: 0.7566 - val_loss: 1.1331 - val_accuracy: 0.5682\n","Epoch 20/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.9512 - accuracy: 0.7442 - val_loss: 1.0620 - val_accuracy: 0.6353\n","Epoch 21/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9409 - accuracy: 0.7522 - val_loss: 1.0619 - val_accuracy: 0.6312\n","Epoch 22/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9347 - accuracy: 0.7579 - val_loss: 1.0828 - val_accuracy: 0.6136\n","Epoch 23/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9328 - accuracy: 0.7563 - val_loss: 1.0742 - val_accuracy: 0.6229\n","Epoch 24/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9296 - accuracy: 0.7530 - val_loss: 1.0469 - val_accuracy: 0.6529\n","Epoch 25/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9313 - accuracy: 0.7530 - val_loss: 1.0458 - val_accuracy: 0.6446\n","Epoch 26/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9218 - accuracy: 0.7628 - val_loss: 1.0458 - val_accuracy: 0.6498\n","Epoch 27/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9197 - accuracy: 0.7581 - val_loss: 1.0497 - val_accuracy: 0.6488\n","Epoch 28/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9121 - accuracy: 0.7646 - val_loss: 1.0480 - val_accuracy: 0.6550\n","Epoch 29/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9164 - accuracy: 0.7571 - val_loss: 1.0451 - val_accuracy: 0.6529\n","Epoch 30/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9003 - accuracy: 0.7744 - val_loss: 1.0431 - val_accuracy: 0.6477\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8940 - accuracy: 0.7770 - val_loss: 1.0646 - val_accuracy: 0.6364\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8935 - accuracy: 0.7716 - val_loss: 1.0469 - val_accuracy: 0.6364\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8880 - accuracy: 0.7806 - val_loss: 1.0547 - val_accuracy: 0.6436\n","Epoch 34/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8940 - accuracy: 0.7726 - val_loss: 1.0475 - val_accuracy: 0.6415\n","Epoch 35/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8812 - accuracy: 0.7796 - val_loss: 1.0565 - val_accuracy: 0.6498\n","Epoch 36/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8821 - accuracy: 0.7778 - val_loss: 1.0426 - val_accuracy: 0.6446\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8676 - accuracy: 0.7891 - val_loss: 1.0800 - val_accuracy: 0.6302\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8677 - accuracy: 0.7897 - val_loss: 1.0475 - val_accuracy: 0.6384\n","Epoch 39/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8592 - accuracy: 0.7938 - val_loss: 1.0449 - val_accuracy: 0.6384\n","Epoch 40/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8560 - accuracy: 0.7961 - val_loss: 1.0467 - val_accuracy: 0.6457\n","Epoch 41/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8593 - accuracy: 0.7915 - val_loss: 1.0442 - val_accuracy: 0.6436\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8464 - accuracy: 0.8003 - val_loss: 1.0659 - val_accuracy: 0.6426\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8516 - accuracy: 0.7946 - val_loss: 1.0542 - val_accuracy: 0.6446\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8421 - accuracy: 0.7977 - val_loss: 1.0556 - val_accuracy: 0.6436\n","Epoch 45/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.8437 - accuracy: 0.7964 - val_loss: 1.0525 - val_accuracy: 0.6395\n","Epoch 46/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8361 - accuracy: 0.8018 - val_loss: 1.0528 - val_accuracy: 0.6353\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8356 - accuracy: 0.8013 - val_loss: 1.0668 - val_accuracy: 0.6457\n","Epoch 48/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8278 - accuracy: 0.8036 - val_loss: 1.0511 - val_accuracy: 0.6405\n","Epoch 49/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8265 - accuracy: 0.8000 - val_loss: 1.0486 - val_accuracy: 0.6384\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8124 - accuracy: 0.8158 - val_loss: 1.0545 - val_accuracy: 0.6415\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8084 - accuracy: 0.8152 - val_loss: 1.0520 - val_accuracy: 0.6333\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8053 - accuracy: 0.8183 - val_loss: 1.0556 - val_accuracy: 0.6384\n","Epoch 53/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8056 - accuracy: 0.8155 - val_loss: 1.0548 - val_accuracy: 0.6374\n","Epoch 54/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8038 - accuracy: 0.8116 - val_loss: 1.0715 - val_accuracy: 0.6353\n","Epoch 55/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7924 - accuracy: 0.8204 - val_loss: 1.0569 - val_accuracy: 0.6384\n","Epoch 56/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8138 - accuracy: 0.8034 - val_loss: 1.0901 - val_accuracy: 0.6291\n","Epoch 57/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7905 - accuracy: 0.8240 - val_loss: 1.0677 - val_accuracy: 0.6384\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7906 - accuracy: 0.8217 - val_loss: 1.0593 - val_accuracy: 0.6384\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7906 - accuracy: 0.8194 - val_loss: 1.0713 - val_accuracy: 0.6415\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7760 - accuracy: 0.8297 - val_loss: 1.0951 - val_accuracy: 0.6240\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7822 - accuracy: 0.8233 - val_loss: 1.0615 - val_accuracy: 0.6374\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7686 - accuracy: 0.8320 - val_loss: 1.0644 - val_accuracy: 0.6384\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7600 - accuracy: 0.8331 - val_loss: 1.0686 - val_accuracy: 0.6364\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7577 - accuracy: 0.8452 - val_loss: 1.0732 - val_accuracy: 0.6353\n","Epoch 65/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7497 - accuracy: 0.8421 - val_loss: 1.0681 - val_accuracy: 0.6333\n","Epoch 66/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7613 - accuracy: 0.8307 - val_loss: 1.0774 - val_accuracy: 0.6364\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7520 - accuracy: 0.8390 - val_loss: 1.0813 - val_accuracy: 0.6395\n","Epoch 68/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7474 - accuracy: 0.8450 - val_loss: 1.0753 - val_accuracy: 0.6374\n","Epoch 69/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7369 - accuracy: 0.8465 - val_loss: 1.0768 - val_accuracy: 0.6281\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7459 - accuracy: 0.8388 - val_loss: 1.0876 - val_accuracy: 0.6395\n","Epoch 71/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7324 - accuracy: 0.8463 - val_loss: 1.0802 - val_accuracy: 0.6322\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7254 - accuracy: 0.8537 - val_loss: 1.0848 - val_accuracy: 0.6384\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7204 - accuracy: 0.8522 - val_loss: 1.0848 - val_accuracy: 0.6415\n","Epoch 74/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7216 - accuracy: 0.8517 - val_loss: 1.1203 - val_accuracy: 0.6250\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7131 - accuracy: 0.8594 - val_loss: 1.0886 - val_accuracy: 0.6395\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7218 - accuracy: 0.8455 - val_loss: 1.1034 - val_accuracy: 0.6281\n","Epoch 77/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7019 - accuracy: 0.8612 - val_loss: 1.0967 - val_accuracy: 0.6302\n","Epoch 78/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7000 - accuracy: 0.8643 - val_loss: 1.1041 - val_accuracy: 0.6457\n","Epoch 79/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6949 - accuracy: 0.8687 - val_loss: 1.1865 - val_accuracy: 0.5992\n","Epoch 80/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7272 - accuracy: 0.8310 - val_loss: 1.1486 - val_accuracy: 0.6312\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6939 - accuracy: 0.8651 - val_loss: 1.1061 - val_accuracy: 0.6384\n","Epoch 82/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6839 - accuracy: 0.8739 - val_loss: 1.1493 - val_accuracy: 0.6178\n","Epoch 83/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6893 - accuracy: 0.8638 - val_loss: 1.1037 - val_accuracy: 0.6353\n","Epoch 84/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6811 - accuracy: 0.8708 - val_loss: 1.1152 - val_accuracy: 0.6426\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6798 - accuracy: 0.8656 - val_loss: 1.1104 - val_accuracy: 0.6415\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6631 - accuracy: 0.8817 - val_loss: 1.1165 - val_accuracy: 0.6364\n","Epoch 87/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6644 - accuracy: 0.8760 - val_loss: 1.1530 - val_accuracy: 0.6271\n","Epoch 88/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6749 - accuracy: 0.8734 - val_loss: 1.1256 - val_accuracy: 0.6240\n","Epoch 89/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6937 - accuracy: 0.8517 - val_loss: 1.1346 - val_accuracy: 0.6260\n","Epoch 90/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6526 - accuracy: 0.8855 - val_loss: 1.1274 - val_accuracy: 0.6260\n","Epoch 91/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6500 - accuracy: 0.8879 - val_loss: 1.1619 - val_accuracy: 0.6229\n","Epoch 92/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6476 - accuracy: 0.8837 - val_loss: 1.1312 - val_accuracy: 0.6333\n","Epoch 93/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6414 - accuracy: 0.8910 - val_loss: 1.1325 - val_accuracy: 0.6302\n","Epoch 94/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6404 - accuracy: 0.8925 - val_loss: 1.1336 - val_accuracy: 0.6395\n","Epoch 95/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6316 - accuracy: 0.8910 - val_loss: 1.1417 - val_accuracy: 0.6415\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6311 - accuracy: 0.8920 - val_loss: 1.1519 - val_accuracy: 0.6291\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6274 - accuracy: 0.8910 - val_loss: 1.1473 - val_accuracy: 0.6333\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6282 - accuracy: 0.8902 - val_loss: 1.1550 - val_accuracy: 0.6260\n","Epoch 99/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6296 - accuracy: 0.8897 - val_loss: 1.1500 - val_accuracy: 0.6312\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6149 - accuracy: 0.8990 - val_loss: 1.1674 - val_accuracy: 0.6291\n","{'loss': [1.0601998567581177, 1.050704002380371, 1.0367692708969116, 1.032762885093689, 1.0234302282333374, 1.0215463638305664, 1.0203170776367188, 1.005160927772522, 1.000449299812317, 1.006188154220581, 0.9881998300552368, 0.9820166826248169, 0.9777570962905884, 0.9714165925979614, 0.9677172303199768, 0.9621671438217163, 0.9605931043624878, 0.9571012854576111, 0.9499967694282532, 0.9512287974357605, 0.9409179091453552, 0.9347021579742432, 0.9327642917633057, 0.9295965433120728, 0.9313087463378906, 0.9217500686645508, 0.9196850061416626, 0.9120776653289795, 0.9163983464241028, 0.9003111124038696, 0.8940094709396362, 0.8935341238975525, 0.8879553079605103, 0.8940248489379883, 0.8811976313591003, 0.8820657134056091, 0.8675957322120667, 0.8676983118057251, 0.8592104911804199, 0.8560037016868591, 0.8592501282691956, 0.8464049696922302, 0.8516166806221008, 0.8420962691307068, 0.8437047004699707, 0.8361482620239258, 0.8355950713157654, 0.8278229832649231, 0.8264530301094055, 0.812351644039154, 0.8083680272102356, 0.8052599430084229, 0.8056226968765259, 0.8037682175636292, 0.7923779487609863, 0.8138015866279602, 0.7904892563819885, 0.7906250357627869, 0.7906256318092346, 0.7760117053985596, 0.7822301983833313, 0.7686054110527039, 0.7599775791168213, 0.7577422261238098, 0.7496688365936279, 0.7612993717193604, 0.7520322203636169, 0.7474116683006287, 0.7368651032447815, 0.7458723187446594, 0.7323746085166931, 0.7254289984703064, 0.7204241752624512, 0.7216361165046692, 0.7130807042121887, 0.7217888832092285, 0.7019195556640625, 0.6999740600585938, 0.6948731541633606, 0.7271716594696045, 0.6938920021057129, 0.6838783621788025, 0.6892608404159546, 0.681136965751648, 0.6798492074012756, 0.6631434559822083, 0.6644081473350525, 0.6749340891838074, 0.6936748027801514, 0.6525844931602478, 0.6499723196029663, 0.6476061940193176, 0.6413629651069641, 0.6403560042381287, 0.6316432356834412, 0.6311212778091431, 0.6273651123046875, 0.6281514167785645, 0.6296170949935913, 0.6148974299430847], 'accuracy': [0.7064599394798279, 0.7134366631507874, 0.7188630700111389, 0.722739040851593, 0.7232558131217957, 0.7224805951118469, 0.7183462381362915, 0.7299741506576538, 0.7333333492279053, 0.7134366631507874, 0.7335917353630066, 0.739534854888916, 0.7421188354492188, 0.7452196478843689, 0.7454780340194702, 0.746253252029419, 0.750129222869873, 0.7447028160095215, 0.7565891742706299, 0.7441860437393188, 0.7521963715553284, 0.7578811645507812, 0.7563307285308838, 0.7529715895652771, 0.7529715895652771, 0.7627906799316406, 0.7581395506858826, 0.7645995020866394, 0.7571059465408325, 0.7744185924530029, 0.7770025730133057, 0.7715762257575989, 0.7806201577186584, 0.7726098299026489, 0.7795865535736084, 0.7777777910232544, 0.7891472578048706, 0.789664089679718, 0.7937984466552734, 0.7961240410804749, 0.791472852230072, 0.8002583980560303, 0.7945736646652222, 0.7976744174957275, 0.7963824272155762, 0.801808774471283, 0.8012920022010803, 0.8036175966262817, 0.800000011920929, 0.8157622814178467, 0.8152454495429993, 0.8183462619781494, 0.8155038952827454, 0.8116279244422913, 0.8204134106636047, 0.8033591508865356, 0.8240309953689575, 0.8217054009437561, 0.8193798661231995, 0.8297157883644104, 0.8232558369636536, 0.832041323184967, 0.8330749273300171, 0.845219612121582, 0.8421188592910767, 0.8307493329048157, 0.8390181064605713, 0.8449612259864807, 0.8465116024017334, 0.8387596607208252, 0.8462532162666321, 0.853746771812439, 0.8521963953971863, 0.8516795635223389, 0.8594315052032471, 0.8454780578613281, 0.8612403273582458, 0.8643410801887512, 0.868733823299408, 0.8310077786445618, 0.8651162981987, 0.8739017844200134, 0.8638243079185486, 0.8708010315895081, 0.8656330704689026, 0.8816537261009216, 0.8759689927101135, 0.8733850121498108, 0.8516795635223389, 0.8855296969413757, 0.8878552913665771, 0.8837209343910217, 0.8909560441970825, 0.89250648021698, 0.8909560441970825, 0.8919896483421326, 0.8909560441970825, 0.8901808857917786, 0.8896640539169312, 0.8989664316177368], 'val_loss': [1.1716176271438599, 1.16496741771698, 1.1595854759216309, 1.153892159461975, 1.149898886680603, 1.140785574913025, 1.1414363384246826, 1.1355291604995728, 1.1267406940460205, 1.120490312576294, 1.1241427659988403, 1.1216875314712524, 1.1117788553237915, 1.101480484008789, 1.105151891708374, 1.0906257629394531, 1.0894970893859863, 1.0771654844284058, 1.1330552101135254, 1.0619845390319824, 1.0619189739227295, 1.0828217267990112, 1.0742436647415161, 1.0469281673431396, 1.0458124876022339, 1.0457885265350342, 1.0497291088104248, 1.0479755401611328, 1.0451232194900513, 1.0431040525436401, 1.0645643472671509, 1.0468508005142212, 1.0547083616256714, 1.0475304126739502, 1.0565415620803833, 1.0426057577133179, 1.0800164937973022, 1.047490119934082, 1.044894814491272, 1.0467280149459839, 1.044156551361084, 1.065860390663147, 1.0542097091674805, 1.0555700063705444, 1.0524743795394897, 1.0527905225753784, 1.0668281316757202, 1.051119327545166, 1.0486477613449097, 1.0544531345367432, 1.0519617795944214, 1.0555729866027832, 1.054835557937622, 1.071516990661621, 1.0569416284561157, 1.0901274681091309, 1.067725419998169, 1.0592690706253052, 1.0713417530059814, 1.095110535621643, 1.0615192651748657, 1.064433217048645, 1.0686440467834473, 1.0732123851776123, 1.0681354999542236, 1.0774186849594116, 1.0812746286392212, 1.0752663612365723, 1.0767899751663208, 1.087646722793579, 1.0802381038665771, 1.0847532749176025, 1.0847755670547485, 1.1202553510665894, 1.0885568857192993, 1.1033858060836792, 1.0967140197753906, 1.1040912866592407, 1.1865230798721313, 1.1486352682113647, 1.106059193611145, 1.1493349075317383, 1.1037440299987793, 1.115162968635559, 1.1104416847229004, 1.116503357887268, 1.1530218124389648, 1.1255576610565186, 1.1346170902252197, 1.1274194717407227, 1.161852478981018, 1.1312086582183838, 1.132482886314392, 1.1336472034454346, 1.1416507959365845, 1.1518621444702148, 1.1473350524902344, 1.1549558639526367, 1.1499680280685425, 1.1674097776412964], 'val_accuracy': [0.4917355477809906, 0.5175619721412659, 0.5340909361839294, 0.5537189841270447, 0.5320248007774353, 0.60537189245224, 0.5278925895690918, 0.5537189841270447, 0.5878099203109741, 0.5971074104309082, 0.5609503984451294, 0.5557851195335388, 0.5826446413993835, 0.5971074104309082, 0.5909090638160706, 0.60537189245224, 0.6043388247489929, 0.6126033067703247, 0.5681818127632141, 0.6353305578231812, 0.6311983466148376, 0.6136363744735718, 0.6229338645935059, 0.6528925895690918, 0.64462810754776, 0.6497933864593506, 0.6487603187561035, 0.6549586653709412, 0.6528925895690918, 0.6477272510528564, 0.6363636255264282, 0.6363636255264282, 0.6435950398445129, 0.6415289044380188, 0.6497933864593506, 0.64462810754776, 0.6301652789115906, 0.6384297609329224, 0.6384297609329224, 0.6456611752510071, 0.6435950398445129, 0.6425619721412659, 0.64462810754776, 0.6435950398445129, 0.6394628286361694, 0.6353305578231812, 0.6456611752510071, 0.6404958963394165, 0.6384297609329224, 0.6415289044380188, 0.6332644820213318, 0.6384297609329224, 0.6373966932296753, 0.6353305578231812, 0.6384297609329224, 0.6291322112083435, 0.6384297609329224, 0.6384297609329224, 0.6415289044380188, 0.6239669322967529, 0.6373966932296753, 0.6384297609329224, 0.6363636255264282, 0.6353305578231812, 0.6332644820213318, 0.6363636255264282, 0.6394628286361694, 0.6373966932296753, 0.6280992031097412, 0.6394628286361694, 0.6322314143180847, 0.6384297609329224, 0.6415289044380188, 0.625, 0.6394628286361694, 0.6280992031097412, 0.6301652789115906, 0.6456611752510071, 0.5991735458374023, 0.6311983466148376, 0.6384297609329224, 0.6177685856819153, 0.6353305578231812, 0.6425619721412659, 0.6415289044380188, 0.6363636255264282, 0.6270661354064941, 0.6239669322967529, 0.6260330677032471, 0.6260330677032471, 0.6229338645935059, 0.6332644820213318, 0.6301652789115906, 0.6394628286361694, 0.6415289044380188, 0.6291322112083435, 0.6332644820213318, 0.6260330677032471, 0.6311983466148376, 0.6291322112083435]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.7248 - accuracy: 0.8371"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 4s 43ms/step - loss: 0.7256 - accuracy: 0.8381 - val_loss: 1.0398 - val_accuracy: 0.5086\n","Epoch 2/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.6915 - accuracy: 0.8594 - val_loss: 1.0344 - val_accuracy: 0.5216\n","Epoch 3/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6928 - accuracy: 0.8551 - val_loss: 1.0360 - val_accuracy: 0.5183\n","Epoch 4/100\n","29/29 [==============================] - 1s 39ms/step - loss: 0.6755 - accuracy: 0.8688 - val_loss: 1.0279 - val_accuracy: 0.5420\n","Epoch 5/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6733 - accuracy: 0.8629 - val_loss: 1.0325 - val_accuracy: 0.5280\n","Epoch 6/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6642 - accuracy: 0.8726 - val_loss: 1.0216 - val_accuracy: 0.5647\n","Epoch 7/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6608 - accuracy: 0.8742 - val_loss: 1.0275 - val_accuracy: 0.5560\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6600 - accuracy: 0.8745 - val_loss: 1.0321 - val_accuracy: 0.5528\n","Epoch 9/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6486 - accuracy: 0.8804 - val_loss: 1.0268 - val_accuracy: 0.5722\n","Epoch 10/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6434 - accuracy: 0.8852 - val_loss: 1.0373 - val_accuracy: 0.5647\n","Epoch 11/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6412 - accuracy: 0.8863 - val_loss: 1.0343 - val_accuracy: 0.5808\n","Epoch 12/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6427 - accuracy: 0.8801 - val_loss: 1.0358 - val_accuracy: 0.5862\n","Epoch 13/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6361 - accuracy: 0.8863 - val_loss: 1.0725 - val_accuracy: 0.5733\n","Epoch 14/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6281 - accuracy: 0.8912 - val_loss: 1.0495 - val_accuracy: 0.5981\n","Epoch 15/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6195 - accuracy: 0.8979 - val_loss: 1.1419 - val_accuracy: 0.5625\n","Epoch 16/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6223 - accuracy: 0.8887 - val_loss: 1.0890 - val_accuracy: 0.5970\n","Epoch 17/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6155 - accuracy: 0.8995 - val_loss: 1.1160 - val_accuracy: 0.5991\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6247 - accuracy: 0.8928 - val_loss: 1.1578 - val_accuracy: 0.5948\n","Epoch 19/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6162 - accuracy: 0.8963 - val_loss: 1.1361 - val_accuracy: 0.6045\n","Epoch 20/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6131 - accuracy: 0.8984 - val_loss: 1.1560 - val_accuracy: 0.6045\n","Epoch 21/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6043 - accuracy: 0.9001 - val_loss: 1.0117 - val_accuracy: 0.6584\n","Epoch 22/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5983 - accuracy: 0.9071 - val_loss: 1.0882 - val_accuracy: 0.6250\n","Epoch 23/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.5874 - accuracy: 0.9127 - val_loss: 0.9945 - val_accuracy: 0.6746\n","Epoch 24/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5850 - accuracy: 0.9176 - val_loss: 1.0268 - val_accuracy: 0.6703\n","Epoch 25/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.5804 - accuracy: 0.9146 - val_loss: 0.9680 - val_accuracy: 0.7015\n","Epoch 26/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5799 - accuracy: 0.9151 - val_loss: 1.0545 - val_accuracy: 0.6692\n","Epoch 27/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5845 - accuracy: 0.9106 - val_loss: 1.0450 - val_accuracy: 0.6789\n","Epoch 28/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.5759 - accuracy: 0.9143 - val_loss: 0.9543 - val_accuracy: 0.7166\n","Epoch 29/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.5706 - accuracy: 0.9165 - val_loss: 0.9548 - val_accuracy: 0.7177\n","Epoch 30/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5597 - accuracy: 0.9270 - val_loss: 1.0231 - val_accuracy: 0.6950\n","Epoch 31/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5629 - accuracy: 0.9240 - val_loss: 0.9677 - val_accuracy: 0.7209\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5583 - accuracy: 0.9256 - val_loss: 0.9748 - val_accuracy: 0.7112\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5612 - accuracy: 0.9205 - val_loss: 0.9662 - val_accuracy: 0.7188\n","Epoch 34/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5476 - accuracy: 0.9286 - val_loss: 0.9753 - val_accuracy: 0.7134\n","Epoch 35/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5426 - accuracy: 0.9332 - val_loss: 0.9858 - val_accuracy: 0.7144\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5473 - accuracy: 0.9289 - val_loss: 1.0142 - val_accuracy: 0.7058\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5427 - accuracy: 0.9275 - val_loss: 0.9889 - val_accuracy: 0.7091\n","Epoch 38/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5393 - accuracy: 0.9345 - val_loss: 0.9923 - val_accuracy: 0.7144\n","Epoch 39/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5297 - accuracy: 0.9372 - val_loss: 1.0161 - val_accuracy: 0.7144\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5471 - accuracy: 0.9238 - val_loss: 1.0196 - val_accuracy: 0.7058\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5337 - accuracy: 0.9291 - val_loss: 1.0034 - val_accuracy: 0.7101\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5214 - accuracy: 0.9418 - val_loss: 1.0014 - val_accuracy: 0.7112\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5291 - accuracy: 0.9343 - val_loss: 1.0039 - val_accuracy: 0.7123\n","Epoch 44/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5157 - accuracy: 0.9456 - val_loss: 1.0068 - val_accuracy: 0.7101\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5253 - accuracy: 0.9359 - val_loss: 1.0218 - val_accuracy: 0.7004\n","Epoch 46/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5092 - accuracy: 0.9456 - val_loss: 1.0176 - val_accuracy: 0.7123\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5023 - accuracy: 0.9494 - val_loss: 1.0217 - val_accuracy: 0.7123\n","Epoch 48/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4973 - accuracy: 0.9526 - val_loss: 1.0437 - val_accuracy: 0.7069\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5026 - accuracy: 0.9491 - val_loss: 1.0192 - val_accuracy: 0.7069\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5134 - accuracy: 0.9353 - val_loss: 1.0301 - val_accuracy: 0.7166\n","Epoch 51/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4906 - accuracy: 0.9512 - val_loss: 1.0258 - val_accuracy: 0.7101\n","Epoch 52/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4973 - accuracy: 0.9480 - val_loss: 1.0294 - val_accuracy: 0.7123\n","Epoch 53/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4957 - accuracy: 0.9494 - val_loss: 1.0839 - val_accuracy: 0.7004\n","Epoch 54/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4905 - accuracy: 0.9477 - val_loss: 1.0484 - val_accuracy: 0.7037\n","Epoch 55/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4766 - accuracy: 0.9593 - val_loss: 1.0364 - val_accuracy: 0.7047\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4746 - accuracy: 0.9609 - val_loss: 1.0952 - val_accuracy: 0.7004\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4726 - accuracy: 0.9615 - val_loss: 1.0542 - val_accuracy: 0.6929\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4766 - accuracy: 0.9545 - val_loss: 1.0533 - val_accuracy: 0.7091\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4748 - accuracy: 0.9582 - val_loss: 1.0556 - val_accuracy: 0.7058\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4758 - accuracy: 0.9555 - val_loss: 1.0902 - val_accuracy: 0.7037\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4658 - accuracy: 0.9607 - val_loss: 1.0583 - val_accuracy: 0.7112\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4624 - accuracy: 0.9639 - val_loss: 1.0785 - val_accuracy: 0.6994\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4664 - accuracy: 0.9585 - val_loss: 1.1123 - val_accuracy: 0.6972\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4659 - accuracy: 0.9620 - val_loss: 1.1380 - val_accuracy: 0.6929\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4545 - accuracy: 0.9642 - val_loss: 1.0871 - val_accuracy: 0.7101\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4502 - accuracy: 0.9674 - val_loss: 1.0781 - val_accuracy: 0.7004\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4504 - accuracy: 0.9688 - val_loss: 1.0940 - val_accuracy: 0.7134\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4515 - accuracy: 0.9674 - val_loss: 1.0998 - val_accuracy: 0.7047\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4428 - accuracy: 0.9701 - val_loss: 1.0908 - val_accuracy: 0.6983\n","Epoch 70/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4393 - accuracy: 0.9709 - val_loss: 1.0954 - val_accuracy: 0.7026\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4395 - accuracy: 0.9712 - val_loss: 1.0981 - val_accuracy: 0.6972\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4396 - accuracy: 0.9701 - val_loss: 1.1933 - val_accuracy: 0.6929\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4325 - accuracy: 0.9723 - val_loss: 1.1372 - val_accuracy: 0.7004\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4321 - accuracy: 0.9755 - val_loss: 1.1404 - val_accuracy: 0.7004\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4258 - accuracy: 0.9771 - val_loss: 1.1176 - val_accuracy: 0.7047\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4237 - accuracy: 0.9784 - val_loss: 1.1236 - val_accuracy: 0.7037\n","Epoch 77/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4229 - accuracy: 0.9768 - val_loss: 1.1468 - val_accuracy: 0.7026\n","Epoch 78/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4183 - accuracy: 0.9776 - val_loss: 1.1423 - val_accuracy: 0.6972\n","Epoch 79/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4166 - accuracy: 0.9793 - val_loss: 1.1424 - val_accuracy: 0.7091\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4129 - accuracy: 0.9809 - val_loss: 1.1462 - val_accuracy: 0.7015\n","Epoch 81/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4136 - accuracy: 0.9806 - val_loss: 1.1955 - val_accuracy: 0.7004\n","Epoch 82/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4110 - accuracy: 0.9809 - val_loss: 1.1619 - val_accuracy: 0.7037\n","Epoch 83/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4109 - accuracy: 0.9830 - val_loss: 1.1572 - val_accuracy: 0.6940\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4045 - accuracy: 0.9822 - val_loss: 1.1967 - val_accuracy: 0.7037\n","Epoch 85/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4094 - accuracy: 0.9828 - val_loss: 1.1653 - val_accuracy: 0.7069\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4063 - accuracy: 0.9830 - val_loss: 1.1826 - val_accuracy: 0.7026\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4055 - accuracy: 0.9814 - val_loss: 1.1751 - val_accuracy: 0.6853\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4019 - accuracy: 0.9846 - val_loss: 1.2224 - val_accuracy: 0.6983\n","Epoch 89/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3980 - accuracy: 0.9838 - val_loss: 1.2482 - val_accuracy: 0.6950\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4173 - accuracy: 0.9723 - val_loss: 1.1911 - val_accuracy: 0.6918\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3952 - accuracy: 0.9863 - val_loss: 1.1897 - val_accuracy: 0.6972\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3919 - accuracy: 0.9873 - val_loss: 1.1930 - val_accuracy: 0.7026\n","Epoch 93/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3912 - accuracy: 0.9857 - val_loss: 1.2054 - val_accuracy: 0.6972\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3886 - accuracy: 0.9865 - val_loss: 1.2291 - val_accuracy: 0.6961\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3853 - accuracy: 0.9881 - val_loss: 1.2062 - val_accuracy: 0.6940\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3832 - accuracy: 0.9887 - val_loss: 1.2209 - val_accuracy: 0.7015\n","Epoch 97/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3868 - accuracy: 0.9865 - val_loss: 1.2153 - val_accuracy: 0.6983\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3807 - accuracy: 0.9900 - val_loss: 1.2131 - val_accuracy: 0.6950\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3784 - accuracy: 0.9906 - val_loss: 1.2410 - val_accuracy: 0.7004\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3742 - accuracy: 0.9922 - val_loss: 1.2546 - val_accuracy: 0.6983\n","{'loss': [0.725593090057373, 0.6914563775062561, 0.6928007006645203, 0.6755325794219971, 0.6733396649360657, 0.6641987562179565, 0.6608486771583557, 0.6600190997123718, 0.6486186385154724, 0.6434487700462341, 0.6411504149436951, 0.6427472233772278, 0.6361058354377747, 0.6281145811080933, 0.6195414066314697, 0.6223080158233643, 0.6155250668525696, 0.6247432827949524, 0.6161525249481201, 0.6130608320236206, 0.6043211221694946, 0.598294198513031, 0.587357223033905, 0.5849765539169312, 0.5803731083869934, 0.5799227356910706, 0.5845058560371399, 0.5758968591690063, 0.5705850124359131, 0.5597462058067322, 0.5629039406776428, 0.5583356022834778, 0.5611667633056641, 0.5475812554359436, 0.5426344275474548, 0.5472950339317322, 0.5427059531211853, 0.539294958114624, 0.5297379493713379, 0.5470609068870544, 0.533679187297821, 0.5213609337806702, 0.529141902923584, 0.5156741738319397, 0.5252983570098877, 0.509223461151123, 0.5022599101066589, 0.49732133746147156, 0.502564549446106, 0.513356626033783, 0.4905969798564911, 0.49731847643852234, 0.4956909120082855, 0.49054089188575745, 0.4766428768634796, 0.4745747148990631, 0.47255808115005493, 0.47658663988113403, 0.4748126268386841, 0.475830614566803, 0.4657750427722931, 0.4623696506023407, 0.46644964814186096, 0.46594926714897156, 0.45446109771728516, 0.4502491056919098, 0.450381875038147, 0.45148998498916626, 0.4427811801433563, 0.43927687406539917, 0.43953272700309753, 0.43956512212753296, 0.4325260818004608, 0.43210047483444214, 0.42583516240119934, 0.42374324798583984, 0.4229121804237366, 0.418260782957077, 0.4165617525577545, 0.4128786623477936, 0.41361328959465027, 0.4109532833099365, 0.41088157892227173, 0.40450674295425415, 0.4094228446483612, 0.40627825260162354, 0.40545716881752014, 0.4019361436367035, 0.39797443151474, 0.4173257052898407, 0.39519497752189636, 0.39185911417007446, 0.39123862981796265, 0.3886445462703705, 0.3853071331977844, 0.3832438588142395, 0.386770635843277, 0.3806686997413635, 0.3783557415008545, 0.3741607964038849], 'accuracy': [0.8380926847457886, 0.859375, 0.8550646305084229, 0.868803858757019, 0.8628771305084229, 0.8725754022598267, 0.8741918206214905, 0.8744612336158752, 0.8803879022598267, 0.8852370977401733, 0.8863146305084229, 0.8801185488700867, 0.8863146305084229, 0.8911637663841248, 0.8978987336158752, 0.8887392282485962, 0.8995150923728943, 0.8927801847457886, 0.8962823152542114, 0.8984375, 0.900053858757019, 0.9070581793785095, 0.912715494632721, 0.9175646305084229, 0.9146012663841248, 0.9151400923728943, 0.9105603694915771, 0.9143319129943848, 0.9164870977401733, 0.9269935488700867, 0.9240301847457886, 0.9256465435028076, 0.920527994632721, 0.9286099076271057, 0.9331896305084229, 0.9288793206214905, 0.9275323152542114, 0.9345366358757019, 0.9372305870056152, 0.9237607717514038, 0.9291487336158752, 0.9418103694915771, 0.9342672228813171, 0.9455819129943848, 0.935883641242981, 0.9455819129943848, 0.9493534564971924, 0.9525862336158752, 0.9490840435028076, 0.9353448152542114, 0.9512392282485962, 0.9480064511299133, 0.9493534564971924, 0.9477370977401733, 0.959321141242981, 0.9609375, 0.9614762663841248, 0.954472005367279, 0.9582435488700867, 0.9555495977401733, 0.9606680870056152, 0.9639008641242981, 0.9585129022598267, 0.9620150923728943, 0.9641702771186829, 0.967402994632721, 0.96875, 0.967402994632721, 0.970097005367279, 0.9709051847457886, 0.9711745977401733, 0.970097005367279, 0.9722521305084229, 0.9754849076271057, 0.9771012663841248, 0.9784482717514038, 0.9768319129943848, 0.9776400923728943, 0.9792564511299133, 0.9808728694915771, 0.9806034564971924, 0.9808728694915771, 0.983027994632721, 0.9822198152542114, 0.982758641242981, 0.983027994632721, 0.9814116358757019, 0.9846444129943848, 0.9838362336158752, 0.9722521305084229, 0.9862607717514038, 0.9873383641242981, 0.985722005367279, 0.9865301847457886, 0.9881465435028076, 0.9886853694915771, 0.9865301847457886, 0.9900323152542114, 0.990571141242981, 0.9921875], 'val_loss': [1.0398361682891846, 1.0344003438949585, 1.036043643951416, 1.0279158353805542, 1.0324567556381226, 1.021564245223999, 1.02745521068573, 1.0321317911148071, 1.0267730951309204, 1.0373400449752808, 1.0343340635299683, 1.035843014717102, 1.0724953413009644, 1.0494577884674072, 1.1419316530227661, 1.089005947113037, 1.1159528493881226, 1.1578072309494019, 1.1360831260681152, 1.1560109853744507, 1.0116972923278809, 1.0882165431976318, 0.9945356845855713, 1.0268241167068481, 0.9680199027061462, 1.054513692855835, 1.0450206995010376, 0.954317569732666, 0.9548181891441345, 1.0231480598449707, 0.9677453637123108, 0.9748128652572632, 0.9662494659423828, 0.975330114364624, 0.9858453869819641, 1.0142391920089722, 0.9888591170310974, 0.9923187494277954, 1.0161449909210205, 1.0195521116256714, 1.0034258365631104, 1.0014231204986572, 1.0039080381393433, 1.0067952871322632, 1.0218229293823242, 1.0176373720169067, 1.0216548442840576, 1.043710470199585, 1.0191770792007446, 1.0300995111465454, 1.0257713794708252, 1.0293796062469482, 1.0838738679885864, 1.0483601093292236, 1.0364161729812622, 1.0952004194259644, 1.0541530847549438, 1.0532824993133545, 1.0555843114852905, 1.0902498960494995, 1.0583144426345825, 1.0785181522369385, 1.112274169921875, 1.1379963159561157, 1.0871466398239136, 1.07807457447052, 1.0939764976501465, 1.099791407585144, 1.090787410736084, 1.0953848361968994, 1.0981251001358032, 1.193310022354126, 1.137180209159851, 1.1404097080230713, 1.117555856704712, 1.1235911846160889, 1.146834135055542, 1.142322301864624, 1.1423556804656982, 1.1461507081985474, 1.1955326795578003, 1.1619012355804443, 1.1572070121765137, 1.1966807842254639, 1.1652748584747314, 1.1825721263885498, 1.1750794649124146, 1.2223926782608032, 1.2481722831726074, 1.1911406517028809, 1.189745306968689, 1.1930209398269653, 1.2054046392440796, 1.229148507118225, 1.206242322921753, 1.220927357673645, 1.2153297662734985, 1.2130563259124756, 1.2410273551940918, 1.254636526107788], 'val_accuracy': [0.5086206793785095, 0.5215517282485962, 0.5183189511299133, 0.5420258641242981, 0.5280172228813171, 0.5646551847457886, 0.556034505367279, 0.5528017282485962, 0.5721982717514038, 0.5646551847457886, 0.5808189511299133, 0.5862069129943848, 0.5732758641242981, 0.5980603694915771, 0.5625, 0.5969827771186829, 0.5991379022598267, 0.5948275923728943, 0.6045258641242981, 0.6045258641242981, 0.6584051847457886, 0.625, 0.6745689511299133, 0.670258641242981, 0.701508641242981, 0.6691810488700867, 0.6788793206214905, 0.7165948152542114, 0.7176724076271057, 0.6950430870056152, 0.7209051847457886, 0.7112069129943848, 0.71875, 0.7133620977401733, 0.7144396305084229, 0.7058189511299133, 0.7090517282485962, 0.7144396305084229, 0.7144396305084229, 0.7058189511299133, 0.7101293206214905, 0.7112069129943848, 0.712284505367279, 0.7101293206214905, 0.7004310488700867, 0.712284505367279, 0.712284505367279, 0.7068965435028076, 0.7068965435028076, 0.7165948152542114, 0.7101293206214905, 0.712284505367279, 0.7004310488700867, 0.7036637663841248, 0.704741358757019, 0.7004310488700867, 0.6928879022598267, 0.7090517282485962, 0.7058189511299133, 0.7036637663841248, 0.7112069129943848, 0.6993534564971924, 0.6971982717514038, 0.6928879022598267, 0.7101293206214905, 0.7004310488700867, 0.7133620977401733, 0.704741358757019, 0.6982758641242981, 0.7025862336158752, 0.6971982717514038, 0.6928879022598267, 0.7004310488700867, 0.7004310488700867, 0.704741358757019, 0.7036637663841248, 0.7025862336158752, 0.6971982717514038, 0.7090517282485962, 0.701508641242981, 0.7004310488700867, 0.7036637663841248, 0.693965494632721, 0.7036637663841248, 0.7068965435028076, 0.7025862336158752, 0.6853448152542114, 0.6982758641242981, 0.6950430870056152, 0.6918103694915771, 0.6971982717514038, 0.7025862336158752, 0.6971982717514038, 0.6961206793785095, 0.693965494632721, 0.701508641242981, 0.6982758641242981, 0.6950430870056152, 0.7004310488700867, 0.6982758641242981]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.7376 - accuracy: 0.8303"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 4s 39ms/step - loss: 0.7352 - accuracy: 0.8308 - val_loss: 1.0350 - val_accuracy: 0.5147\n","Epoch 2/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.7013 - accuracy: 0.8492 - val_loss: 1.0302 - val_accuracy: 0.5441\n","Epoch 3/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6876 - accuracy: 0.8588 - val_loss: 1.0278 - val_accuracy: 0.5554\n","Epoch 4/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6853 - accuracy: 0.8582 - val_loss: 1.0258 - val_accuracy: 0.5622\n","Epoch 5/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.6789 - accuracy: 0.8613 - val_loss: 1.0204 - val_accuracy: 0.5769\n","Epoch 6/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.6692 - accuracy: 0.8724 - val_loss: 1.0140 - val_accuracy: 0.5860\n","Epoch 7/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6650 - accuracy: 0.8684 - val_loss: 1.0126 - val_accuracy: 0.5860\n","Epoch 8/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.6600 - accuracy: 0.8752 - val_loss: 1.0082 - val_accuracy: 0.5928\n","Epoch 9/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6523 - accuracy: 0.8834 - val_loss: 1.0115 - val_accuracy: 0.5894\n","Epoch 10/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6486 - accuracy: 0.8817 - val_loss: 1.0087 - val_accuracy: 0.5950\n","Epoch 11/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6437 - accuracy: 0.8829 - val_loss: 1.0293 - val_accuracy: 0.5803\n","Epoch 12/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6387 - accuracy: 0.8911 - val_loss: 1.0271 - val_accuracy: 0.5905\n","Epoch 13/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6354 - accuracy: 0.8891 - val_loss: 1.0213 - val_accuracy: 0.5973\n","Epoch 14/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6321 - accuracy: 0.8925 - val_loss: 1.0640 - val_accuracy: 0.5826\n","Epoch 15/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6274 - accuracy: 0.8956 - val_loss: 1.0548 - val_accuracy: 0.5962\n","Epoch 16/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6290 - accuracy: 0.8840 - val_loss: 1.0391 - val_accuracy: 0.6075\n","Epoch 17/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6259 - accuracy: 0.8908 - val_loss: 1.1081 - val_accuracy: 0.5939\n","Epoch 18/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6282 - accuracy: 0.8862 - val_loss: 1.0366 - val_accuracy: 0.6154\n","Epoch 19/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6232 - accuracy: 0.8862 - val_loss: 1.0546 - val_accuracy: 0.6199\n","Epoch 20/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6115 - accuracy: 0.8973 - val_loss: 1.0521 - val_accuracy: 0.6369\n","Epoch 21/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6033 - accuracy: 0.9072 - val_loss: 1.0317 - val_accuracy: 0.6437\n","Epoch 22/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6083 - accuracy: 0.8990 - val_loss: 1.1896 - val_accuracy: 0.6165\n","Epoch 23/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6075 - accuracy: 0.9027 - val_loss: 1.0319 - val_accuracy: 0.6697\n","Epoch 24/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.5883 - accuracy: 0.9154 - val_loss: 1.0223 - val_accuracy: 0.6810\n","Epoch 25/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5930 - accuracy: 0.9095 - val_loss: 0.9811 - val_accuracy: 0.6968\n","Epoch 26/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5863 - accuracy: 0.9145 - val_loss: 0.9587 - val_accuracy: 0.7048\n","Epoch 27/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5892 - accuracy: 0.9117 - val_loss: 0.9768 - val_accuracy: 0.6991\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5850 - accuracy: 0.9140 - val_loss: 0.9924 - val_accuracy: 0.7025\n","Epoch 29/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5850 - accuracy: 0.9066 - val_loss: 1.0176 - val_accuracy: 0.7025\n","Epoch 30/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5770 - accuracy: 0.9131 - val_loss: 0.9824 - val_accuracy: 0.7014\n","Epoch 31/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5667 - accuracy: 0.9202 - val_loss: 0.9803 - val_accuracy: 0.6946\n","Epoch 32/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5692 - accuracy: 0.9128 - val_loss: 1.0082 - val_accuracy: 0.7002\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5599 - accuracy: 0.9242 - val_loss: 1.0115 - val_accuracy: 0.7036\n","Epoch 34/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5619 - accuracy: 0.9202 - val_loss: 0.9925 - val_accuracy: 0.7025\n","Epoch 35/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5612 - accuracy: 0.9171 - val_loss: 1.0929 - val_accuracy: 0.6900\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5651 - accuracy: 0.9137 - val_loss: 1.0255 - val_accuracy: 0.6867\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5631 - accuracy: 0.9211 - val_loss: 1.0339 - val_accuracy: 0.7036\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5558 - accuracy: 0.9222 - val_loss: 1.0088 - val_accuracy: 0.6968\n","Epoch 39/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5435 - accuracy: 0.9312 - val_loss: 1.0030 - val_accuracy: 0.7093\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5391 - accuracy: 0.9329 - val_loss: 1.0180 - val_accuracy: 0.7025\n","Epoch 41/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5297 - accuracy: 0.9377 - val_loss: 1.0105 - val_accuracy: 0.7002\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5305 - accuracy: 0.9397 - val_loss: 1.0233 - val_accuracy: 0.7014\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5262 - accuracy: 0.9397 - val_loss: 1.0172 - val_accuracy: 0.6968\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5275 - accuracy: 0.9346 - val_loss: 1.0236 - val_accuracy: 0.7059\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5174 - accuracy: 0.9451 - val_loss: 1.0259 - val_accuracy: 0.6957\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5190 - accuracy: 0.9417 - val_loss: 1.0380 - val_accuracy: 0.7025\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5130 - accuracy: 0.9451 - val_loss: 1.0421 - val_accuracy: 0.6867\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5147 - accuracy: 0.9426 - val_loss: 1.0302 - val_accuracy: 0.6957\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5055 - accuracy: 0.9479 - val_loss: 1.0581 - val_accuracy: 0.6821\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5072 - accuracy: 0.9482 - val_loss: 1.0411 - val_accuracy: 0.7059\n","Epoch 51/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4964 - accuracy: 0.9536 - val_loss: 1.0588 - val_accuracy: 0.7014\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4973 - accuracy: 0.9519 - val_loss: 1.0813 - val_accuracy: 0.6991\n","Epoch 53/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4929 - accuracy: 0.9567 - val_loss: 1.0558 - val_accuracy: 0.7014\n","Epoch 54/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4916 - accuracy: 0.9525 - val_loss: 1.0740 - val_accuracy: 0.7036\n","Epoch 55/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4925 - accuracy: 0.9527 - val_loss: 1.0767 - val_accuracy: 0.6991\n","Epoch 56/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4898 - accuracy: 0.9513 - val_loss: 1.0719 - val_accuracy: 0.6867\n","Epoch 57/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4852 - accuracy: 0.9590 - val_loss: 1.0705 - val_accuracy: 0.7036\n","Epoch 58/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4771 - accuracy: 0.9607 - val_loss: 1.0736 - val_accuracy: 0.6844\n","Epoch 59/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4732 - accuracy: 0.9604 - val_loss: 1.1408 - val_accuracy: 0.6867\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4941 - accuracy: 0.9434 - val_loss: 1.0939 - val_accuracy: 0.6980\n","Epoch 61/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4681 - accuracy: 0.9643 - val_loss: 1.0835 - val_accuracy: 0.6810\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4685 - accuracy: 0.9615 - val_loss: 1.1076 - val_accuracy: 0.7002\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4616 - accuracy: 0.9655 - val_loss: 1.0936 - val_accuracy: 0.6821\n","Epoch 64/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4636 - accuracy: 0.9632 - val_loss: 1.0964 - val_accuracy: 0.6912\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4596 - accuracy: 0.9660 - val_loss: 1.1277 - val_accuracy: 0.6753\n","Epoch 66/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4583 - accuracy: 0.9689 - val_loss: 1.1072 - val_accuracy: 0.6844\n","Epoch 67/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4617 - accuracy: 0.9598 - val_loss: 1.1187 - val_accuracy: 0.6968\n","Epoch 68/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4496 - accuracy: 0.9703 - val_loss: 1.1304 - val_accuracy: 0.6934\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4507 - accuracy: 0.9669 - val_loss: 1.1544 - val_accuracy: 0.6912\n","Epoch 70/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4574 - accuracy: 0.9610 - val_loss: 1.1494 - val_accuracy: 0.6991\n","Epoch 71/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4421 - accuracy: 0.9731 - val_loss: 1.1194 - val_accuracy: 0.6946\n","Epoch 72/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4358 - accuracy: 0.9765 - val_loss: 1.1276 - val_accuracy: 0.6980\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4329 - accuracy: 0.9785 - val_loss: 1.1625 - val_accuracy: 0.6878\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4334 - accuracy: 0.9743 - val_loss: 1.1662 - val_accuracy: 0.6980\n","Epoch 75/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4387 - accuracy: 0.9703 - val_loss: 1.1374 - val_accuracy: 0.6810\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4287 - accuracy: 0.9757 - val_loss: 1.1436 - val_accuracy: 0.6968\n","Epoch 77/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4246 - accuracy: 0.9816 - val_loss: 1.2091 - val_accuracy: 0.6900\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4246 - accuracy: 0.9785 - val_loss: 1.1518 - val_accuracy: 0.6912\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4184 - accuracy: 0.9796 - val_loss: 1.1674 - val_accuracy: 0.6980\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4179 - accuracy: 0.9785 - val_loss: 1.1577 - val_accuracy: 0.6867\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4235 - accuracy: 0.9748 - val_loss: 1.1801 - val_accuracy: 0.6742\n","Epoch 82/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4351 - accuracy: 0.9660 - val_loss: 1.1761 - val_accuracy: 0.6923\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4108 - accuracy: 0.9830 - val_loss: 1.1746 - val_accuracy: 0.6833\n","Epoch 84/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4125 - accuracy: 0.9810 - val_loss: 1.1862 - val_accuracy: 0.6799\n","Epoch 85/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4135 - accuracy: 0.9793 - val_loss: 1.1849 - val_accuracy: 0.6980\n","Epoch 86/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4050 - accuracy: 0.9861 - val_loss: 1.1882 - val_accuracy: 0.6855\n","Epoch 87/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4017 - accuracy: 0.9847 - val_loss: 1.2048 - val_accuracy: 0.6742\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4008 - accuracy: 0.9850 - val_loss: 1.2040 - val_accuracy: 0.6867\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4067 - accuracy: 0.9805 - val_loss: 1.2350 - val_accuracy: 0.6787\n","Epoch 90/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4019 - accuracy: 0.9844 - val_loss: 1.2066 - val_accuracy: 0.6821\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3980 - accuracy: 0.9839 - val_loss: 1.2125 - val_accuracy: 0.6833\n","Epoch 92/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3931 - accuracy: 0.9884 - val_loss: 1.2175 - val_accuracy: 0.6968\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3928 - accuracy: 0.9859 - val_loss: 1.2432 - val_accuracy: 0.6946\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3885 - accuracy: 0.9875 - val_loss: 1.2310 - val_accuracy: 0.6968\n","Epoch 95/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3845 - accuracy: 0.9901 - val_loss: 1.2486 - val_accuracy: 0.6968\n","Epoch 96/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3918 - accuracy: 0.9844 - val_loss: 1.2505 - val_accuracy: 0.6799\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4056 - accuracy: 0.9776 - val_loss: 1.2446 - val_accuracy: 0.6787\n","Epoch 98/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3856 - accuracy: 0.9870 - val_loss: 1.2477 - val_accuracy: 0.6810\n","Epoch 99/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3979 - accuracy: 0.9782 - val_loss: 1.2784 - val_accuracy: 0.6787\n","Epoch 100/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3858 - accuracy: 0.9875 - val_loss: 1.2527 - val_accuracy: 0.6799\n","{'loss': [0.7352330088615417, 0.7012825608253479, 0.6875913739204407, 0.6853401064872742, 0.6788831353187561, 0.6691771745681763, 0.6650109887123108, 0.6600190997123718, 0.6523226499557495, 0.6485568881034851, 0.6437471508979797, 0.6386935114860535, 0.6353864073753357, 0.6320540308952332, 0.6274228692054749, 0.6290378570556641, 0.6258558630943298, 0.6281917691230774, 0.6232427954673767, 0.611499011516571, 0.6033369302749634, 0.6083196401596069, 0.6074767112731934, 0.5882677435874939, 0.5930342674255371, 0.5862611532211304, 0.589228093624115, 0.5849623680114746, 0.5849690437316895, 0.5770466923713684, 0.5667207837104797, 0.5692429542541504, 0.5599473714828491, 0.5618599653244019, 0.5611761212348938, 0.5650903582572937, 0.5631007552146912, 0.5558311939239502, 0.5435183644294739, 0.5390713214874268, 0.52970951795578, 0.5305306911468506, 0.5262014865875244, 0.5275174379348755, 0.5174074769020081, 0.5190421342849731, 0.5129669308662415, 0.5146846175193787, 0.5054639577865601, 0.5071820020675659, 0.4964154362678528, 0.4973262548446655, 0.4929218292236328, 0.4915732443332672, 0.49254438281059265, 0.4897686243057251, 0.4852066934108734, 0.4771289825439453, 0.47323518991470337, 0.49413958191871643, 0.4680548906326294, 0.4684516191482544, 0.46164965629577637, 0.46359699964523315, 0.4596436023712158, 0.458274245262146, 0.4617375135421753, 0.4495607912540436, 0.45073580741882324, 0.4574180543422699, 0.4420769512653351, 0.4358242452144623, 0.4329366385936737, 0.4333609640598297, 0.4386626183986664, 0.4287031590938568, 0.4245624542236328, 0.4246252477169037, 0.4183790385723114, 0.41793525218963623, 0.4235094487667084, 0.43514692783355713, 0.4108068346977234, 0.4124951660633087, 0.4134615361690521, 0.40500134229660034, 0.4017159640789032, 0.4007817506790161, 0.4066767990589142, 0.4018983840942383, 0.3979663848876953, 0.3931300640106201, 0.39278173446655273, 0.38851723074913025, 0.3844640851020813, 0.3918282687664032, 0.4056476652622223, 0.3856274485588074, 0.39787477254867554, 0.3857937455177307], 'accuracy': [0.8307866454124451, 0.8491793870925903, 0.8588002324104309, 0.8582342863082886, 0.8613469004631042, 0.8723825812339783, 0.8684210777282715, 0.8752122521400452, 0.8834182024002075, 0.8817204236984253, 0.88285231590271, 0.8910582661628723, 0.8890775442123413, 0.8924731016159058, 0.8955857157707214, 0.8839841485023499, 0.8907753229141235, 0.8862478733062744, 0.8862478733062744, 0.8972835540771484, 0.9071873426437378, 0.8989813327789307, 0.9026598930358887, 0.9153932929039001, 0.9094510674476624, 0.914544403553009, 0.9117147922515869, 0.9139785170555115, 0.9066213965415955, 0.9131296277046204, 0.9202037453651428, 0.9128466248512268, 0.9241652488708496, 0.9202037453651428, 0.9170911312103271, 0.9136955142021179, 0.9210526347160339, 0.9221844673156738, 0.9312393665313721, 0.9329372048377991, 0.937747597694397, 0.9397283792495728, 0.9397283792495728, 0.9346349835395813, 0.945104718208313, 0.9417091012001038, 0.945104718208313, 0.9425579905509949, 0.9479343295097351, 0.9482173323631287, 0.9535936713218689, 0.9518958926200867, 0.9567062854766846, 0.9524617791175842, 0.9527447819709778, 0.9513299465179443, 0.9589700102806091, 0.9606677889823914, 0.9603848457336426, 0.943406879901886, 0.9643463492393494, 0.9615166783332825, 0.965478241443634, 0.9632145166397095, 0.9660441279411316, 0.9688737988471985, 0.9598188996315002, 0.9702886343002319, 0.9668930172920227, 0.9609507918357849, 0.9731183052062988, 0.9765138626098633, 0.9784946441650391, 0.9742501378059387, 0.9702886343002319, 0.9756649732589722, 0.9816072583198547, 0.9784946441650391, 0.979626476764679, 0.9784946441650391, 0.974816083908081, 0.9660441279411316, 0.9830220937728882, 0.9810413122177124, 0.9793435335159302, 0.9861347079277039, 0.9847198724746704, 0.9850028157234192, 0.9804753661155701, 0.9844368696212769, 0.9838709831237793, 0.9883984327316284, 0.9858517050743103, 0.9875495433807373, 0.9900962114334106, 0.9844368696212769, 0.977645754814148, 0.986983597278595, 0.9782116413116455, 0.9875495433807373], 'val_loss': [1.0350130796432495, 1.0301802158355713, 1.0277626514434814, 1.0258208513259888, 1.0203789472579956, 1.0139505863189697, 1.0125529766082764, 1.0082106590270996, 1.0115033388137817, 1.0086954832077026, 1.0292974710464478, 1.0270501375198364, 1.0213282108306885, 1.0639891624450684, 1.054819107055664, 1.0390502214431763, 1.1080726385116577, 1.0365928411483765, 1.0545895099639893, 1.0521190166473389, 1.0317041873931885, 1.1896343231201172, 1.031943917274475, 1.0223197937011719, 0.9810781478881836, 0.9586761593818665, 0.9768078327178955, 0.9923679828643799, 1.0175511837005615, 0.9823781251907349, 0.9803080558776855, 1.0082263946533203, 1.0114860534667969, 0.9925258755683899, 1.0928646326065063, 1.0255426168441772, 1.0339030027389526, 1.0087950229644775, 1.0029529333114624, 1.0180225372314453, 1.010502815246582, 1.0233476161956787, 1.0172193050384521, 1.0236332416534424, 1.025930643081665, 1.03800368309021, 1.0421302318572998, 1.0301839113235474, 1.0581319332122803, 1.0410780906677246, 1.0588171482086182, 1.0812690258026123, 1.0558104515075684, 1.07401442527771, 1.0766912698745728, 1.0719139575958252, 1.0704900026321411, 1.0735572576522827, 1.140834093093872, 1.0938900709152222, 1.0834976434707642, 1.1076130867004395, 1.0935823917388916, 1.096444845199585, 1.1276767253875732, 1.1072404384613037, 1.1187046766281128, 1.130378007888794, 1.1544004678726196, 1.1493566036224365, 1.1194380521774292, 1.1275526285171509, 1.1625105142593384, 1.166152000427246, 1.1373995542526245, 1.143576741218567, 1.2091337442398071, 1.1518275737762451, 1.1673637628555298, 1.1576732397079468, 1.1801036596298218, 1.1760858297348022, 1.1745601892471313, 1.1861684322357178, 1.1848902702331543, 1.1881554126739502, 1.204784870147705, 1.2040129899978638, 1.2349584102630615, 1.2065731287002563, 1.2125097513198853, 1.2175172567367554, 1.2431763410568237, 1.231002688407898, 1.2485603094100952, 1.2504780292510986, 1.2445591688156128, 1.247704267501831, 1.2783591747283936, 1.25266695022583], 'val_accuracy': [0.5147058963775635, 0.5441176295280457, 0.5554298758506775, 0.5622171759605408, 0.5769230723381042, 0.5859728455543518, 0.5859728455543518, 0.5927602052688599, 0.5893664956092834, 0.5950226187705994, 0.5803167223930359, 0.5904977321624756, 0.5972850918769836, 0.5825791954994202, 0.5961538553237915, 0.6074660420417786, 0.5938913822174072, 0.6153846383094788, 0.6199095249176025, 0.6368778347969055, 0.6436651349067688, 0.6165158152580261, 0.6696832776069641, 0.6809954643249512, 0.6968325972557068, 0.7047511339187622, 0.6990950107574463, 0.7024886608123779, 0.7024886608123779, 0.7013574838638306, 0.6945701241493225, 0.7002262473106384, 0.7036198973655701, 0.7024886608123779, 0.6900452375411987, 0.6866515874862671, 0.7036198973655701, 0.6968325972557068, 0.709276020526886, 0.7024886608123779, 0.7002262473106384, 0.7013574838638306, 0.6968325972557068, 0.7058823704719543, 0.6957013607025146, 0.7024886608123779, 0.6866515874862671, 0.6957013607025146, 0.6821267008781433, 0.7058823704719543, 0.7013574838638306, 0.6990950107574463, 0.7013574838638306, 0.7036198973655701, 0.6990950107574463, 0.6866515874862671, 0.7036198973655701, 0.6843891143798828, 0.6866515874862671, 0.6979637742042542, 0.6809954643249512, 0.7002262473106384, 0.6821267008781433, 0.6911764740943909, 0.6753393411636353, 0.6843891143798828, 0.6968325972557068, 0.6934388875961304, 0.6911764740943909, 0.6990950107574463, 0.6945701241493225, 0.6979637742042542, 0.6877828240394592, 0.6979637742042542, 0.6809954643249512, 0.6968325972557068, 0.6900452375411987, 0.6911764740943909, 0.6979637742042542, 0.6866515874862671, 0.6742081642150879, 0.692307710647583, 0.6832579374313354, 0.679864227771759, 0.6979637742042542, 0.685520350933075, 0.6742081642150879, 0.6866515874862671, 0.6787330508232117, 0.6821267008781433, 0.6832579374313354, 0.6968325972557068, 0.6945701241493225, 0.6968325972557068, 0.6968325972557068, 0.679864227771759, 0.6787330508232117, 0.6809954643249512, 0.6787330508232117, 0.679864227771759]}\n","45/45 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.7798 - accuracy: 0.8083"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 4s 35ms/step - loss: 0.7766 - accuracy: 0.8101 - val_loss: 1.0384 - val_accuracy: 0.5062\n","Epoch 2/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.7325 - accuracy: 0.8258 - val_loss: 1.0321 - val_accuracy: 0.5455\n","Epoch 3/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7340 - accuracy: 0.8266 - val_loss: 1.0328 - val_accuracy: 0.5279\n","Epoch 4/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7182 - accuracy: 0.8359 - val_loss: 1.0322 - val_accuracy: 0.5258\n","Epoch 5/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7200 - accuracy: 0.8364 - val_loss: 1.0308 - val_accuracy: 0.5413\n","Epoch 6/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.7094 - accuracy: 0.8442 - val_loss: 1.0194 - val_accuracy: 0.5775\n","Epoch 7/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.7205 - accuracy: 0.8375 - val_loss: 1.0182 - val_accuracy: 0.5795\n","Epoch 8/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6918 - accuracy: 0.8527 - val_loss: 1.0097 - val_accuracy: 0.5940\n","Epoch 9/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7084 - accuracy: 0.8452 - val_loss: 1.0184 - val_accuracy: 0.5816\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6989 - accuracy: 0.8439 - val_loss: 1.0328 - val_accuracy: 0.5620\n","Epoch 11/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6835 - accuracy: 0.8579 - val_loss: 1.0275 - val_accuracy: 0.5764\n","Epoch 12/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6808 - accuracy: 0.8548 - val_loss: 1.0422 - val_accuracy: 0.5723\n","Epoch 13/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6746 - accuracy: 0.8659 - val_loss: 1.0416 - val_accuracy: 0.5847\n","Epoch 14/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6767 - accuracy: 0.8574 - val_loss: 1.0357 - val_accuracy: 0.5950\n","Epoch 15/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.6610 - accuracy: 0.8693 - val_loss: 1.0178 - val_accuracy: 0.6074\n","Epoch 16/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6577 - accuracy: 0.8724 - val_loss: 1.0031 - val_accuracy: 0.6250\n","Epoch 17/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6620 - accuracy: 0.8695 - val_loss: 1.0820 - val_accuracy: 0.5981\n","Epoch 18/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6536 - accuracy: 0.8773 - val_loss: 1.0483 - val_accuracy: 0.6209\n","Epoch 19/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.6497 - accuracy: 0.8744 - val_loss: 1.0327 - val_accuracy: 0.6281\n","Epoch 20/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6456 - accuracy: 0.8775 - val_loss: 0.9859 - val_accuracy: 0.6570\n","Epoch 21/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6444 - accuracy: 0.8783 - val_loss: 0.9721 - val_accuracy: 0.6890\n","Epoch 22/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6403 - accuracy: 0.8726 - val_loss: 0.9727 - val_accuracy: 0.6818\n","Epoch 23/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6280 - accuracy: 0.8848 - val_loss: 0.9666 - val_accuracy: 0.6901\n","Epoch 24/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6394 - accuracy: 0.8796 - val_loss: 0.9649 - val_accuracy: 0.6973\n","Epoch 25/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6251 - accuracy: 0.8868 - val_loss: 0.9766 - val_accuracy: 0.6849\n","Epoch 26/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6196 - accuracy: 0.8964 - val_loss: 1.0366 - val_accuracy: 0.6756\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6204 - accuracy: 0.8912 - val_loss: 0.9807 - val_accuracy: 0.6973\n","Epoch 28/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6156 - accuracy: 0.8964 - val_loss: 0.9909 - val_accuracy: 0.6963\n","Epoch 29/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6054 - accuracy: 0.8972 - val_loss: 0.9859 - val_accuracy: 0.7045\n","Epoch 30/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6023 - accuracy: 0.8982 - val_loss: 0.9926 - val_accuracy: 0.6911\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5979 - accuracy: 0.9023 - val_loss: 0.9956 - val_accuracy: 0.6983\n","Epoch 32/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5972 - accuracy: 0.9065 - val_loss: 0.9998 - val_accuracy: 0.6963\n","Epoch 33/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5948 - accuracy: 0.9013 - val_loss: 1.0433 - val_accuracy: 0.6818\n","Epoch 34/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5925 - accuracy: 0.9067 - val_loss: 1.0138 - val_accuracy: 0.6963\n","Epoch 35/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5911 - accuracy: 0.9088 - val_loss: 1.0842 - val_accuracy: 0.6705\n","Epoch 36/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6056 - accuracy: 0.8868 - val_loss: 1.0641 - val_accuracy: 0.6829\n","Epoch 37/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5922 - accuracy: 0.9039 - val_loss: 1.0169 - val_accuracy: 0.6942\n","Epoch 38/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5821 - accuracy: 0.9052 - val_loss: 1.0191 - val_accuracy: 0.6983\n","Epoch 39/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5805 - accuracy: 0.9072 - val_loss: 1.0207 - val_accuracy: 0.6932\n","Epoch 40/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5758 - accuracy: 0.9080 - val_loss: 1.0516 - val_accuracy: 0.6849\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5722 - accuracy: 0.9093 - val_loss: 1.0352 - val_accuracy: 0.6901\n","Epoch 42/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5706 - accuracy: 0.9124 - val_loss: 1.0335 - val_accuracy: 0.6849\n","Epoch 43/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5555 - accuracy: 0.9258 - val_loss: 1.0351 - val_accuracy: 0.6829\n","Epoch 44/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5523 - accuracy: 0.9292 - val_loss: 1.0385 - val_accuracy: 0.6911\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5482 - accuracy: 0.9279 - val_loss: 1.0458 - val_accuracy: 0.6890\n","Epoch 46/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5473 - accuracy: 0.9269 - val_loss: 1.0499 - val_accuracy: 0.6932\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5530 - accuracy: 0.9212 - val_loss: 1.0504 - val_accuracy: 0.6798\n","Epoch 48/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5359 - accuracy: 0.9331 - val_loss: 1.0586 - val_accuracy: 0.6911\n","Epoch 49/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5387 - accuracy: 0.9264 - val_loss: 1.0669 - val_accuracy: 0.6860\n","Epoch 50/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5375 - accuracy: 0.9300 - val_loss: 1.0597 - val_accuracy: 0.6942\n","Epoch 51/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5315 - accuracy: 0.9318 - val_loss: 1.0960 - val_accuracy: 0.6798\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5333 - accuracy: 0.9302 - val_loss: 1.0738 - val_accuracy: 0.6921\n","Epoch 53/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5372 - accuracy: 0.9245 - val_loss: 1.1020 - val_accuracy: 0.6787\n","Epoch 54/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5246 - accuracy: 0.9354 - val_loss: 1.0839 - val_accuracy: 0.6829\n","Epoch 55/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5181 - accuracy: 0.9351 - val_loss: 1.1188 - val_accuracy: 0.6798\n","Epoch 56/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5329 - accuracy: 0.9243 - val_loss: 1.1528 - val_accuracy: 0.6663\n","Epoch 57/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5205 - accuracy: 0.9388 - val_loss: 1.0897 - val_accuracy: 0.6890\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5049 - accuracy: 0.9444 - val_loss: 1.0885 - val_accuracy: 0.6901\n","Epoch 59/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5099 - accuracy: 0.9416 - val_loss: 1.0856 - val_accuracy: 0.6860\n","Epoch 60/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5000 - accuracy: 0.9475 - val_loss: 1.0912 - val_accuracy: 0.6818\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4992 - accuracy: 0.9478 - val_loss: 1.0972 - val_accuracy: 0.6839\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4943 - accuracy: 0.9499 - val_loss: 1.0998 - val_accuracy: 0.6839\n","Epoch 63/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4959 - accuracy: 0.9457 - val_loss: 1.1031 - val_accuracy: 0.6849\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4882 - accuracy: 0.9543 - val_loss: 1.1153 - val_accuracy: 0.6870\n","Epoch 65/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4861 - accuracy: 0.9553 - val_loss: 1.1249 - val_accuracy: 0.6870\n","Epoch 66/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4823 - accuracy: 0.9553 - val_loss: 1.1169 - val_accuracy: 0.6880\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4754 - accuracy: 0.9587 - val_loss: 1.1260 - val_accuracy: 0.6921\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4761 - accuracy: 0.9579 - val_loss: 1.1517 - val_accuracy: 0.6767\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4750 - accuracy: 0.9571 - val_loss: 1.1475 - val_accuracy: 0.6870\n","Epoch 70/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4788 - accuracy: 0.9527 - val_loss: 1.1345 - val_accuracy: 0.6829\n","Epoch 71/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4638 - accuracy: 0.9623 - val_loss: 1.1341 - val_accuracy: 0.6849\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4602 - accuracy: 0.9656 - val_loss: 1.1432 - val_accuracy: 0.6849\n","Epoch 73/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4648 - accuracy: 0.9628 - val_loss: 1.1825 - val_accuracy: 0.6736\n","Epoch 74/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4654 - accuracy: 0.9587 - val_loss: 1.1687 - val_accuracy: 0.6808\n","Epoch 75/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4544 - accuracy: 0.9656 - val_loss: 1.1596 - val_accuracy: 0.6839\n","Epoch 76/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4541 - accuracy: 0.9664 - val_loss: 1.1609 - val_accuracy: 0.6870\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4487 - accuracy: 0.9685 - val_loss: 1.1953 - val_accuracy: 0.6715\n","Epoch 78/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4522 - accuracy: 0.9646 - val_loss: 1.1770 - val_accuracy: 0.6860\n","Epoch 79/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4443 - accuracy: 0.9690 - val_loss: 1.2041 - val_accuracy: 0.6798\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4434 - accuracy: 0.9716 - val_loss: 1.1774 - val_accuracy: 0.6808\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4397 - accuracy: 0.9703 - val_loss: 1.2210 - val_accuracy: 0.6705\n","Epoch 82/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4696 - accuracy: 0.9463 - val_loss: 1.2700 - val_accuracy: 0.6756\n","Epoch 83/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4618 - accuracy: 0.9566 - val_loss: 1.1939 - val_accuracy: 0.6829\n","Epoch 84/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4337 - accuracy: 0.9690 - val_loss: 1.2915 - val_accuracy: 0.6550\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4368 - accuracy: 0.9703 - val_loss: 1.1971 - val_accuracy: 0.6849\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4287 - accuracy: 0.9724 - val_loss: 1.2363 - val_accuracy: 0.6705\n","Epoch 87/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4413 - accuracy: 0.9602 - val_loss: 1.2227 - val_accuracy: 0.6849\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4260 - accuracy: 0.9731 - val_loss: 1.2144 - val_accuracy: 0.6829\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4236 - accuracy: 0.9752 - val_loss: 1.2715 - val_accuracy: 0.6643\n","Epoch 90/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4228 - accuracy: 0.9760 - val_loss: 1.2442 - val_accuracy: 0.6901\n","Epoch 91/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4181 - accuracy: 0.9788 - val_loss: 1.2367 - val_accuracy: 0.6798\n","Epoch 92/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4122 - accuracy: 0.9814 - val_loss: 1.2296 - val_accuracy: 0.6849\n","Epoch 93/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4139 - accuracy: 0.9793 - val_loss: 1.2510 - val_accuracy: 0.6746\n","Epoch 94/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4130 - accuracy: 0.9773 - val_loss: 1.2462 - val_accuracy: 0.6756\n","Epoch 95/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4050 - accuracy: 0.9824 - val_loss: 1.2557 - val_accuracy: 0.6787\n","Epoch 96/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4017 - accuracy: 0.9853 - val_loss: 1.2561 - val_accuracy: 0.6818\n","Epoch 97/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4011 - accuracy: 0.9850 - val_loss: 1.2591 - val_accuracy: 0.6829\n","Epoch 98/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4027 - accuracy: 0.9819 - val_loss: 1.2710 - val_accuracy: 0.6808\n","Epoch 99/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3978 - accuracy: 0.9858 - val_loss: 1.2675 - val_accuracy: 0.6787\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3949 - accuracy: 0.9863 - val_loss: 1.2851 - val_accuracy: 0.6818\n","{'loss': [0.7766417860984802, 0.7324966788291931, 0.7340367436408997, 0.718176007270813, 0.7200008630752563, 0.7093749642372131, 0.7205415368080139, 0.6917808651924133, 0.7083781361579895, 0.698858380317688, 0.6834741234779358, 0.6807979941368103, 0.6746277809143066, 0.6766797304153442, 0.6610426902770996, 0.6577433347702026, 0.662006676197052, 0.6536158323287964, 0.6497418880462646, 0.6455562114715576, 0.6444133520126343, 0.640256404876709, 0.6279575824737549, 0.6393563151359558, 0.6250921487808228, 0.6195695996284485, 0.6204285025596619, 0.6155641674995422, 0.605355441570282, 0.6023284792900085, 0.5978672504425049, 0.5972431302070618, 0.5947677493095398, 0.5925478339195251, 0.591144859790802, 0.6056069135665894, 0.5921811461448669, 0.5821367502212524, 0.5805274248123169, 0.5757823586463928, 0.5722218155860901, 0.5706145167350769, 0.5554893016815186, 0.5522993206977844, 0.5482101440429688, 0.5473150014877319, 0.5530346632003784, 0.5359339118003845, 0.5387447476387024, 0.5375261902809143, 0.5314680337905884, 0.5332511067390442, 0.5371885299682617, 0.5245596170425415, 0.5180820226669312, 0.5329182744026184, 0.5204902291297913, 0.5049039721488953, 0.5099352598190308, 0.4999646842479706, 0.4992218613624573, 0.4943382740020752, 0.495933473110199, 0.48824456334114075, 0.4860728085041046, 0.48233267664909363, 0.475366473197937, 0.47611889243125916, 0.47500181198120117, 0.47883570194244385, 0.4637892246246338, 0.4601585566997528, 0.46481117606163025, 0.4654393196105957, 0.45444995164871216, 0.4540698528289795, 0.4487077295780182, 0.45220011472702026, 0.4443349540233612, 0.4434058666229248, 0.4397270381450653, 0.4696160554885864, 0.46180397272109985, 0.43368884921073914, 0.4367728531360626, 0.42872384190559387, 0.4412722885608673, 0.42598381638526917, 0.4235704243183136, 0.4227501153945923, 0.4181269109249115, 0.4122105538845062, 0.41385385394096375, 0.4129953384399414, 0.40501269698143005, 0.40170297026634216, 0.4010559022426605, 0.4027446210384369, 0.39776816964149475, 0.394916296005249], 'accuracy': [0.8100775480270386, 0.8258398175239563, 0.8266149759292603, 0.8359172940254211, 0.8364341259002686, 0.8441860675811768, 0.8374677300453186, 0.8527131676673889, 0.845219612121582, 0.8439276218414307, 0.8578811287879944, 0.854780375957489, 0.8658914566040039, 0.8573643565177917, 0.8692506551742554, 0.8723514080047607, 0.8695090413093567, 0.8772609829902649, 0.8744186162948608, 0.8775193691253662, 0.8782945871353149, 0.8726097941398621, 0.8847545385360718, 0.8795865774154663, 0.8868216872215271, 0.8963824510574341, 0.8912144899368286, 0.8963824510574341, 0.897157609462738, 0.8981912136077881, 0.9023255705833435, 0.9064599275588989, 0.9012919664382935, 0.906718373298645, 0.9087855219841003, 0.8868216872215271, 0.9038759469985962, 0.9051679372787476, 0.9072351455688477, 0.9080103635787964, 0.9093023538589478, 0.9124031066894531, 0.9258397817611694, 0.9291989803314209, 0.9279069900512695, 0.9268733859062195, 0.9211886525154114, 0.933074951171875, 0.9263566136360168, 0.9299741387367249, 0.9317829608917236, 0.930232584476471, 0.9245477914810181, 0.9354005455970764, 0.9351420998573303, 0.9242894053459167, 0.9387596845626831, 0.9444444179534912, 0.9416020512580872, 0.9475452303886414, 0.9478036165237427, 0.9498708248138428, 0.9457364082336426, 0.9542635679244995, 0.9552971720695496, 0.9552971720695496, 0.9586563110351562, 0.9578811526298523, 0.9571059346199036, 0.9527131915092468, 0.962273895740509, 0.9656330943107605, 0.9627906680107117, 0.9586563110351562, 0.9656330943107605, 0.9664082527160645, 0.9684754610061646, 0.9645994901657104, 0.9689922332763672, 0.9715762138366699, 0.9702842235565186, 0.94625324010849, 0.9565891623497009, 0.9689922332763672, 0.9702842235565186, 0.9723514318466187, 0.9602067470550537, 0.9731265902519226, 0.9751937985420227, 0.9759690165519714, 0.9788113832473755, 0.9813953638076782, 0.9793281555175781, 0.9772610068321228, 0.9824289679527283, 0.9852713346481323, 0.985012948513031, 0.9819121360778809, 0.985788106918335, 0.9863049387931824], 'val_loss': [1.038425087928772, 1.032108187675476, 1.0327633619308472, 1.032190203666687, 1.0308235883712769, 1.0194056034088135, 1.018236517906189, 1.0097445249557495, 1.0184435844421387, 1.0327645540237427, 1.0275135040283203, 1.0421562194824219, 1.0416333675384521, 1.0357253551483154, 1.0177621841430664, 1.0030837059020996, 1.0820121765136719, 1.0483170747756958, 1.0327215194702148, 0.9859465956687927, 0.9721380472183228, 0.9726948738098145, 0.966593861579895, 0.9649130702018738, 0.9765504598617554, 1.0366162061691284, 0.9806588888168335, 0.9909079074859619, 0.9858875870704651, 0.9925704598426819, 0.9955740571022034, 0.9997795820236206, 1.0432995557785034, 1.0138211250305176, 1.0842396020889282, 1.0641461610794067, 1.0169404745101929, 1.019062876701355, 1.0206828117370605, 1.0515623092651367, 1.0352203845977783, 1.0334612131118774, 1.035098910331726, 1.0385136604309082, 1.0457792282104492, 1.0498628616333008, 1.0503871440887451, 1.05864417552948, 1.066881537437439, 1.0596845149993896, 1.0960229635238647, 1.0737718343734741, 1.1020135879516602, 1.0839124917984009, 1.1187539100646973, 1.152762770652771, 1.08968186378479, 1.0885202884674072, 1.0855547189712524, 1.0912387371063232, 1.0971746444702148, 1.0998308658599854, 1.1030939817428589, 1.1152983903884888, 1.1249005794525146, 1.1168831586837769, 1.1259510517120361, 1.1516646146774292, 1.1474705934524536, 1.1345292329788208, 1.1341270208358765, 1.1432180404663086, 1.1824909448623657, 1.1686601638793945, 1.1595659255981445, 1.1609348058700562, 1.1953120231628418, 1.1769767999649048, 1.2041118144989014, 1.1774109601974487, 1.2210198640823364, 1.2699919939041138, 1.1938591003417969, 1.291488528251648, 1.1970655918121338, 1.2362922430038452, 1.2227013111114502, 1.2144027948379517, 1.2715152502059937, 1.2441892623901367, 1.236722707748413, 1.229615569114685, 1.2510405778884888, 1.2462066411972046, 1.2557069063186646, 1.2560957670211792, 1.2590667009353638, 1.2710169553756714, 1.2675083875656128, 1.2850650548934937], 'val_accuracy': [0.5061983466148376, 0.5454545617103577, 0.5278925895690918, 0.5258264541625977, 0.5413222908973694, 0.577479362487793, 0.5795454382896423, 0.5940082669258118, 0.5816115736961365, 0.5619834661483765, 0.5764462947845459, 0.5723140239715576, 0.5847107172012329, 0.5950413346290588, 0.6074380278587341, 0.625, 0.5981404781341553, 0.6208677887916565, 0.6280992031097412, 0.6570248007774353, 0.6890496015548706, 0.6818181872367859, 0.6900826692581177, 0.6973140239715576, 0.6849173307418823, 0.6756198406219482, 0.6973140239715576, 0.6962810158729553, 0.7045454382896423, 0.69111567735672, 0.6983470916748047, 0.6962810158729553, 0.6818181872367859, 0.6962810158729553, 0.6704545617103577, 0.682851254940033, 0.6942148804664612, 0.6983470916748047, 0.6931818127632141, 0.6849173307418823, 0.6900826692581177, 0.6849173307418823, 0.682851254940033, 0.69111567735672, 0.6890496015548706, 0.6931818127632141, 0.6797520518302917, 0.69111567735672, 0.6859503984451294, 0.6942148804664612, 0.6797520518302917, 0.692148745059967, 0.6787189841270447, 0.682851254940033, 0.6797520518302917, 0.6663222908973694, 0.6890496015548706, 0.6900826692581177, 0.6859503984451294, 0.6818181872367859, 0.68388432264328, 0.68388432264328, 0.6849173307418823, 0.6869834661483765, 0.6869834661483765, 0.6880165338516235, 0.692148745059967, 0.6766529083251953, 0.6869834661483765, 0.682851254940033, 0.6849173307418823, 0.6849173307418823, 0.6735537052154541, 0.6807851195335388, 0.68388432264328, 0.6869834661483765, 0.6714876294136047, 0.6859503984451294, 0.6797520518302917, 0.6807851195335388, 0.6704545617103577, 0.6756198406219482, 0.682851254940033, 0.6549586653709412, 0.6849173307418823, 0.6704545617103577, 0.6849173307418823, 0.682851254940033, 0.66425621509552, 0.6900826692581177, 0.6797520518302917, 0.6849173307418823, 0.6745867729187012, 0.6756198406219482, 0.6787189841270447, 0.6818181872367859, 0.682851254940033, 0.6807851195335388, 0.6787189841270447, 0.6818181872367859]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.5311 - accuracy: 0.9165"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 6s 49ms/step - loss: 0.5266 - accuracy: 0.9170 - val_loss: 1.0119 - val_accuracy: 0.5119\n","Epoch 2/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4855 - accuracy: 0.9356 - val_loss: 1.0160 - val_accuracy: 0.5162\n","Epoch 3/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4798 - accuracy: 0.9407 - val_loss: 1.0127 - val_accuracy: 0.5334\n","Epoch 4/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4733 - accuracy: 0.9429 - val_loss: 1.0161 - val_accuracy: 0.5388\n","Epoch 5/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4609 - accuracy: 0.9483 - val_loss: 1.0190 - val_accuracy: 0.5506\n","Epoch 6/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4704 - accuracy: 0.9461 - val_loss: 1.0058 - val_accuracy: 0.5722\n","Epoch 7/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4552 - accuracy: 0.9485 - val_loss: 1.0582 - val_accuracy: 0.5453\n","Epoch 8/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4483 - accuracy: 0.9572 - val_loss: 1.0467 - val_accuracy: 0.5625\n","Epoch 9/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.4357 - accuracy: 0.9634 - val_loss: 1.0562 - val_accuracy: 0.5787\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4389 - accuracy: 0.9634 - val_loss: 1.0982 - val_accuracy: 0.5722\n","Epoch 11/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4308 - accuracy: 0.9634 - val_loss: 1.1870 - val_accuracy: 0.5550\n","Epoch 12/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4274 - accuracy: 0.9671 - val_loss: 1.1474 - val_accuracy: 0.5884\n","Epoch 13/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4241 - accuracy: 0.9704 - val_loss: 1.1949 - val_accuracy: 0.5862\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4244 - accuracy: 0.9682 - val_loss: 1.4198 - val_accuracy: 0.5560\n","Epoch 15/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4343 - accuracy: 0.9601 - val_loss: 1.4022 - val_accuracy: 0.5711\n","Epoch 16/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4161 - accuracy: 0.9717 - val_loss: 1.3293 - val_accuracy: 0.5959\n","Epoch 17/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4164 - accuracy: 0.9728 - val_loss: 1.3047 - val_accuracy: 0.6196\n","Epoch 18/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4228 - accuracy: 0.9720 - val_loss: 1.2934 - val_accuracy: 0.6325\n","Epoch 19/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4230 - accuracy: 0.9655 - val_loss: 1.2134 - val_accuracy: 0.6562\n","Epoch 20/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4112 - accuracy: 0.9749 - val_loss: 1.2890 - val_accuracy: 0.6487\n","Epoch 21/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.4172 - accuracy: 0.9693 - val_loss: 1.0613 - val_accuracy: 0.6983\n","Epoch 22/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.4129 - accuracy: 0.9682 - val_loss: 1.0399 - val_accuracy: 0.7134\n","Epoch 23/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4054 - accuracy: 0.9744 - val_loss: 1.1011 - val_accuracy: 0.7112\n","Epoch 24/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4128 - accuracy: 0.9690 - val_loss: 1.0276 - val_accuracy: 0.7263\n","Epoch 25/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3968 - accuracy: 0.9795 - val_loss: 1.2223 - val_accuracy: 0.6918\n","Epoch 26/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4007 - accuracy: 0.9768 - val_loss: 1.0240 - val_accuracy: 0.7446\n","Epoch 27/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3902 - accuracy: 0.9828 - val_loss: 0.9872 - val_accuracy: 0.7511\n","Epoch 28/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3876 - accuracy: 0.9836 - val_loss: 0.9722 - val_accuracy: 0.7522\n","Epoch 29/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3857 - accuracy: 0.9841 - val_loss: 0.9372 - val_accuracy: 0.7662\n","Epoch 30/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3896 - accuracy: 0.9822 - val_loss: 0.9861 - val_accuracy: 0.7586\n","Epoch 31/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3871 - accuracy: 0.9820 - val_loss: 0.9768 - val_accuracy: 0.7597\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3829 - accuracy: 0.9846 - val_loss: 1.0416 - val_accuracy: 0.7522\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3937 - accuracy: 0.9806 - val_loss: 1.0187 - val_accuracy: 0.7629\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3811 - accuracy: 0.9863 - val_loss: 0.9889 - val_accuracy: 0.7608\n","Epoch 35/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3798 - accuracy: 0.9863 - val_loss: 0.9976 - val_accuracy: 0.7575\n","Epoch 36/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3753 - accuracy: 0.9879 - val_loss: 1.0488 - val_accuracy: 0.7522\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3773 - accuracy: 0.9868 - val_loss: 1.0141 - val_accuracy: 0.7597\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3702 - accuracy: 0.9890 - val_loss: 1.0280 - val_accuracy: 0.7565\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3727 - accuracy: 0.9873 - val_loss: 0.9980 - val_accuracy: 0.7565\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3737 - accuracy: 0.9890 - val_loss: 1.0089 - val_accuracy: 0.7522\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3694 - accuracy: 0.9895 - val_loss: 1.0796 - val_accuracy: 0.7511\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3678 - accuracy: 0.9914 - val_loss: 1.0052 - val_accuracy: 0.7554\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3687 - accuracy: 0.9884 - val_loss: 1.0142 - val_accuracy: 0.7511\n","Epoch 44/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3718 - accuracy: 0.9871 - val_loss: 1.0034 - val_accuracy: 0.7522\n","Epoch 45/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3629 - accuracy: 0.9911 - val_loss: 1.0232 - val_accuracy: 0.7554\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3677 - accuracy: 0.9876 - val_loss: 1.0206 - val_accuracy: 0.7532\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3597 - accuracy: 0.9908 - val_loss: 1.0354 - val_accuracy: 0.7565\n","Epoch 48/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3633 - accuracy: 0.9887 - val_loss: 1.0501 - val_accuracy: 0.7565\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3627 - accuracy: 0.9898 - val_loss: 1.0799 - val_accuracy: 0.7532\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3677 - accuracy: 0.9887 - val_loss: 1.0874 - val_accuracy: 0.7478\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3549 - accuracy: 0.9927 - val_loss: 1.0311 - val_accuracy: 0.7543\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3524 - accuracy: 0.9933 - val_loss: 1.0815 - val_accuracy: 0.7522\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3565 - accuracy: 0.9903 - val_loss: 1.1091 - val_accuracy: 0.7511\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3556 - accuracy: 0.9908 - val_loss: 1.0654 - val_accuracy: 0.7500\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3514 - accuracy: 0.9911 - val_loss: 1.0697 - val_accuracy: 0.7532\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3589 - accuracy: 0.9881 - val_loss: 1.1415 - val_accuracy: 0.7532\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3507 - accuracy: 0.9914 - val_loss: 1.0881 - val_accuracy: 0.7446\n","Epoch 58/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3459 - accuracy: 0.9946 - val_loss: 1.1009 - val_accuracy: 0.7543\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3441 - accuracy: 0.9943 - val_loss: 1.0827 - val_accuracy: 0.7468\n","Epoch 60/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3434 - accuracy: 0.9933 - val_loss: 1.0668 - val_accuracy: 0.7565\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3451 - accuracy: 0.9930 - val_loss: 1.0740 - val_accuracy: 0.7511\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3463 - accuracy: 0.9927 - val_loss: 1.0865 - val_accuracy: 0.7543\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3437 - accuracy: 0.9938 - val_loss: 1.1035 - val_accuracy: 0.7522\n","Epoch 64/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3449 - accuracy: 0.9935 - val_loss: 1.1186 - val_accuracy: 0.7457\n","Epoch 65/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3395 - accuracy: 0.9943 - val_loss: 1.1632 - val_accuracy: 0.7478\n","Epoch 66/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3389 - accuracy: 0.9949 - val_loss: 1.0859 - val_accuracy: 0.7500\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3381 - accuracy: 0.9946 - val_loss: 1.1000 - val_accuracy: 0.7446\n","Epoch 68/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3339 - accuracy: 0.9962 - val_loss: 1.1110 - val_accuracy: 0.7489\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3386 - accuracy: 0.9965 - val_loss: 1.1123 - val_accuracy: 0.7435\n","Epoch 70/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3350 - accuracy: 0.9957 - val_loss: 1.1176 - val_accuracy: 0.7489\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3387 - accuracy: 0.9933 - val_loss: 1.1407 - val_accuracy: 0.7500\n","Epoch 72/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3367 - accuracy: 0.9943 - val_loss: 1.1149 - val_accuracy: 0.7478\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3310 - accuracy: 0.9973 - val_loss: 1.1227 - val_accuracy: 0.7522\n","Epoch 74/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3316 - accuracy: 0.9968 - val_loss: 1.1175 - val_accuracy: 0.7511\n","Epoch 75/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3283 - accuracy: 0.9968 - val_loss: 1.1377 - val_accuracy: 0.7446\n","Epoch 76/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3304 - accuracy: 0.9965 - val_loss: 1.1157 - val_accuracy: 0.7435\n","Epoch 77/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3274 - accuracy: 0.9970 - val_loss: 1.1230 - val_accuracy: 0.7500\n","Epoch 78/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3275 - accuracy: 0.9970 - val_loss: 1.1563 - val_accuracy: 0.7435\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3262 - accuracy: 0.9960 - val_loss: 1.1280 - val_accuracy: 0.7468\n","Epoch 80/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3283 - accuracy: 0.9954 - val_loss: 1.1337 - val_accuracy: 0.7457\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3259 - accuracy: 0.9978 - val_loss: 1.1810 - val_accuracy: 0.7457\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3251 - accuracy: 0.9962 - val_loss: 1.2118 - val_accuracy: 0.7478\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3274 - accuracy: 0.9970 - val_loss: 1.1596 - val_accuracy: 0.7446\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3235 - accuracy: 0.9968 - val_loss: 1.2222 - val_accuracy: 0.7446\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3228 - accuracy: 0.9976 - val_loss: 1.1603 - val_accuracy: 0.7468\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3294 - accuracy: 0.9938 - val_loss: 1.4316 - val_accuracy: 0.7188\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3477 - accuracy: 0.9863 - val_loss: 1.1705 - val_accuracy: 0.7414\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3257 - accuracy: 0.9954 - val_loss: 1.2404 - val_accuracy: 0.7360\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3227 - accuracy: 0.9965 - val_loss: 1.1782 - val_accuracy: 0.7468\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3186 - accuracy: 0.9973 - val_loss: 1.1725 - val_accuracy: 0.7478\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3176 - accuracy: 0.9976 - val_loss: 1.1886 - val_accuracy: 0.7457\n","Epoch 92/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3188 - accuracy: 0.9976 - val_loss: 1.1946 - val_accuracy: 0.7360\n","Epoch 93/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3193 - accuracy: 0.9962 - val_loss: 1.1945 - val_accuracy: 0.7468\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3171 - accuracy: 0.9981 - val_loss: 1.2311 - val_accuracy: 0.7414\n","Epoch 95/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3168 - accuracy: 0.9978 - val_loss: 1.1740 - val_accuracy: 0.7425\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3163 - accuracy: 0.9978 - val_loss: 1.2186 - val_accuracy: 0.7457\n","Epoch 97/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3145 - accuracy: 0.9973 - val_loss: 1.1876 - val_accuracy: 0.7414\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3136 - accuracy: 0.9984 - val_loss: 1.2378 - val_accuracy: 0.7457\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3134 - accuracy: 0.9978 - val_loss: 1.1857 - val_accuracy: 0.7371\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3139 - accuracy: 0.9976 - val_loss: 1.2315 - val_accuracy: 0.7468\n","{'loss': [0.5265545845031738, 0.4854514002799988, 0.47981375455856323, 0.4732714295387268, 0.46093297004699707, 0.4704170227050781, 0.4551750719547272, 0.4482608437538147, 0.43574726581573486, 0.43891236186027527, 0.43083277344703674, 0.4274418354034424, 0.42405834794044495, 0.42442744970321655, 0.4343114495277405, 0.4161212146282196, 0.41640427708625793, 0.4227902591228485, 0.4229888916015625, 0.4111674427986145, 0.41723009943962097, 0.4129316806793213, 0.4054441750049591, 0.41284701228141785, 0.39681491255760193, 0.4006515443325043, 0.39021992683410645, 0.387577623128891, 0.38574060797691345, 0.3895959258079529, 0.3870522379875183, 0.3829352855682373, 0.3936636745929718, 0.38105955719947815, 0.37983739376068115, 0.37529414892196655, 0.3772745728492737, 0.3702091872692108, 0.3727099299430847, 0.3737088441848755, 0.3694385588169098, 0.36779695749282837, 0.3686668276786804, 0.3718416392803192, 0.3628731966018677, 0.36766254901885986, 0.3596540093421936, 0.3632639944553375, 0.36269646883010864, 0.36768075823783875, 0.35488447546958923, 0.3523685336112976, 0.35650667548179626, 0.355602502822876, 0.351378470659256, 0.3588699400424957, 0.3507087230682373, 0.3459005355834961, 0.3440857529640198, 0.3433898687362671, 0.3450934886932373, 0.34632131457328796, 0.34369587898254395, 0.3449099361896515, 0.33952710032463074, 0.338866651058197, 0.3380585312843323, 0.3339313864707947, 0.3385586440563202, 0.33495545387268066, 0.3387085199356079, 0.3366955518722534, 0.3309580981731415, 0.3316068947315216, 0.3283015489578247, 0.33035919070243835, 0.3273874521255493, 0.32750648260116577, 0.3261702358722687, 0.3283286392688751, 0.32585301995277405, 0.32510432600975037, 0.3273735046386719, 0.32350918650627136, 0.32281380891799927, 0.32936516404151917, 0.3476927876472473, 0.32569316029548645, 0.3227134943008423, 0.3185824453830719, 0.3176003694534302, 0.3188404440879822, 0.31934070587158203, 0.3170967102050781, 0.3168211877346039, 0.3162623643875122, 0.31450650095939636, 0.31359800696372986, 0.3133552670478821, 0.3138754069805145], 'accuracy': [0.9170258641242981, 0.9356142282485962, 0.9407327771186829, 0.9428879022598267, 0.9482758641242981, 0.9461206793785095, 0.9485452771186829, 0.9571659564971924, 0.9633620977401733, 0.9633620977401733, 0.9633620977401733, 0.967133641242981, 0.970366358757019, 0.9682112336158752, 0.9601293206214905, 0.9717133641242981, 0.9727909564971924, 0.9719827771186829, 0.9655172228813171, 0.974946141242981, 0.9692887663841248, 0.9682112336158752, 0.9744073152542114, 0.9690194129943848, 0.9795258641242981, 0.9768319129943848, 0.982758641242981, 0.9835668206214905, 0.9841055870056152, 0.9822198152542114, 0.9819504022598267, 0.9846444129943848, 0.9806034564971924, 0.9862607717514038, 0.9862607717514038, 0.9878771305084229, 0.9867995977401733, 0.9889547228813171, 0.9873383641242981, 0.9889547228813171, 0.9894935488700867, 0.9913793206214905, 0.9884159564971924, 0.9870689511299133, 0.9911099076271057, 0.9876077771186829, 0.990840494632721, 0.9886853694915771, 0.9897629022598267, 0.9886853694915771, 0.9927262663841248, 0.9932650923728943, 0.9903017282485962, 0.990840494632721, 0.9911099076271057, 0.9881465435028076, 0.9913793206214905, 0.9946120977401733, 0.9943426847457886, 0.9932650923728943, 0.9929956793785095, 0.9927262663841248, 0.993803858757019, 0.993534505367279, 0.9943426847457886, 0.9948814511299133, 0.9946120977401733, 0.9962284564971924, 0.9964978694915771, 0.9956896305084229, 0.9932650923728943, 0.9943426847457886, 0.9973060488700867, 0.9967672228813171, 0.9967672228813171, 0.9964978694915771, 0.9970366358757019, 0.9970366358757019, 0.9959590435028076, 0.9954202771186829, 0.9978448152542114, 0.9962284564971924, 0.9970366358757019, 0.9967672228813171, 0.9975754022598267, 0.993803858757019, 0.9862607717514038, 0.9954202771186829, 0.9964978694915771, 0.9973060488700867, 0.9975754022598267, 0.9975754022598267, 0.9962284564971924, 0.9981142282485962, 0.9978448152542114, 0.9978448152542114, 0.9973060488700867, 0.998383641242981, 0.9978448152542114, 0.9975754022598267], 'val_loss': [1.0118591785430908, 1.0159735679626465, 1.0127472877502441, 1.0161139965057373, 1.0189851522445679, 1.005811333656311, 1.0581573247909546, 1.0466742515563965, 1.0561715364456177, 1.0981642007827759, 1.1869710683822632, 1.147385597229004, 1.1948637962341309, 1.4198497533798218, 1.402201533317566, 1.3292912244796753, 1.304707407951355, 1.2934476137161255, 1.2133667469024658, 1.2889772653579712, 1.0612785816192627, 1.039946436882019, 1.101131558418274, 1.0275770425796509, 1.2223384380340576, 1.0239958763122559, 0.9871882200241089, 0.9721672534942627, 0.9372324347496033, 0.9861302375793457, 0.9767584800720215, 1.0416138172149658, 1.018657922744751, 0.9889443516731262, 0.9975749254226685, 1.0488255023956299, 1.0140868425369263, 1.0280197858810425, 0.998042643070221, 1.0089300870895386, 1.0796384811401367, 1.0051568746566772, 1.0141593217849731, 1.0033780336380005, 1.023173213005066, 1.020603060722351, 1.0353809595108032, 1.0500915050506592, 1.0799285173416138, 1.0873777866363525, 1.0310782194137573, 1.0815072059631348, 1.109089970588684, 1.0653513669967651, 1.0696802139282227, 1.1415308713912964, 1.088119387626648, 1.1008820533752441, 1.0827131271362305, 1.0667637586593628, 1.0740257501602173, 1.0864980220794678, 1.1034706830978394, 1.1185647249221802, 1.1632075309753418, 1.085876703262329, 1.1000443696975708, 1.1110128164291382, 1.1122602224349976, 1.1175905466079712, 1.140716314315796, 1.1148972511291504, 1.1226754188537598, 1.1174609661102295, 1.1376879215240479, 1.1156896352767944, 1.1230331659317017, 1.1563249826431274, 1.1279683113098145, 1.1336860656738281, 1.1810277700424194, 1.2118017673492432, 1.159556269645691, 1.2221968173980713, 1.1602773666381836, 1.4316242933273315, 1.1704500913619995, 1.2403969764709473, 1.1781702041625977, 1.1725226640701294, 1.1886019706726074, 1.1946393251419067, 1.1945347785949707, 1.2310711145401, 1.1739587783813477, 1.2186248302459717, 1.1875698566436768, 1.237849235534668, 1.1856589317321777, 1.2314765453338623], 'val_accuracy': [0.5118534564971924, 0.5161637663841248, 0.5334051847457886, 0.5387930870056152, 0.5506465435028076, 0.5721982717514038, 0.545258641242981, 0.5625, 0.5786637663841248, 0.5721982717514038, 0.5549569129943848, 0.5883620977401733, 0.5862069129943848, 0.556034505367279, 0.5711206793785095, 0.5959051847457886, 0.6196120977401733, 0.6325430870056152, 0.65625, 0.6487069129943848, 0.6982758641242981, 0.7133620977401733, 0.7112069129943848, 0.7262930870056152, 0.6918103694915771, 0.7446120977401733, 0.7510775923728943, 0.7521551847457886, 0.7661637663841248, 0.7586206793785095, 0.7596982717514038, 0.7521551847457886, 0.7629310488700867, 0.7607758641242981, 0.7575430870056152, 0.7521551847457886, 0.7596982717514038, 0.756465494632721, 0.756465494632721, 0.7521551847457886, 0.7510775923728943, 0.7553879022598267, 0.7510775923728943, 0.7521551847457886, 0.7553879022598267, 0.7532327771186829, 0.756465494632721, 0.756465494632721, 0.7532327771186829, 0.7478448152542114, 0.7543103694915771, 0.7521551847457886, 0.7510775923728943, 0.75, 0.7532327771186829, 0.7532327771186829, 0.7446120977401733, 0.7543103694915771, 0.7467672228813171, 0.756465494632721, 0.7510775923728943, 0.7543103694915771, 0.7521551847457886, 0.7456896305084229, 0.7478448152542114, 0.75, 0.7446120977401733, 0.7489224076271057, 0.743534505367279, 0.7489224076271057, 0.75, 0.7478448152542114, 0.7521551847457886, 0.7510775923728943, 0.7446120977401733, 0.743534505367279, 0.75, 0.743534505367279, 0.7467672228813171, 0.7456896305084229, 0.7456896305084229, 0.7478448152542114, 0.7446120977401733, 0.7446120977401733, 0.7467672228813171, 0.71875, 0.7413793206214905, 0.735991358757019, 0.7467672228813171, 0.7478448152542114, 0.7456896305084229, 0.735991358757019, 0.7467672228813171, 0.7413793206214905, 0.7424569129943848, 0.7456896305084229, 0.7413793206214905, 0.7456896305084229, 0.7370689511299133, 0.7467672228813171]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.5558 - accuracy: 0.9025"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 4s 38ms/step - loss: 0.5527 - accuracy: 0.9035 - val_loss: 1.0135 - val_accuracy: 0.5136\n","Epoch 2/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4879 - accuracy: 0.9397 - val_loss: 1.0103 - val_accuracy: 0.5249\n","Epoch 3/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.4790 - accuracy: 0.9448 - val_loss: 0.9962 - val_accuracy: 0.5588\n","Epoch 4/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4711 - accuracy: 0.9440 - val_loss: 0.9968 - val_accuracy: 0.5645\n","Epoch 5/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4680 - accuracy: 0.9488 - val_loss: 0.9894 - val_accuracy: 0.5826\n","Epoch 6/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4639 - accuracy: 0.9468 - val_loss: 0.9976 - val_accuracy: 0.5769\n","Epoch 7/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4561 - accuracy: 0.9527 - val_loss: 1.0203 - val_accuracy: 0.5701\n","Epoch 8/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4565 - accuracy: 0.9508 - val_loss: 1.0078 - val_accuracy: 0.5882\n","Epoch 9/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4418 - accuracy: 0.9618 - val_loss: 1.0245 - val_accuracy: 0.5871\n","Epoch 10/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4412 - accuracy: 0.9635 - val_loss: 1.0685 - val_accuracy: 0.5769\n","Epoch 11/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4370 - accuracy: 0.9629 - val_loss: 1.0553 - val_accuracy: 0.5928\n","Epoch 12/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.4470 - accuracy: 0.9553 - val_loss: 1.0864 - val_accuracy: 0.5950\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4438 - accuracy: 0.9573 - val_loss: 1.1445 - val_accuracy: 0.5905\n","Epoch 14/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4230 - accuracy: 0.9697 - val_loss: 1.1683 - val_accuracy: 0.5928\n","Epoch 15/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4207 - accuracy: 0.9697 - val_loss: 1.2062 - val_accuracy: 0.6018\n","Epoch 16/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4206 - accuracy: 0.9711 - val_loss: 1.1617 - val_accuracy: 0.6210\n","Epoch 17/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4189 - accuracy: 0.9700 - val_loss: 1.2063 - val_accuracy: 0.6188\n","Epoch 18/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4140 - accuracy: 0.9737 - val_loss: 1.2419 - val_accuracy: 0.6244\n","Epoch 19/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4119 - accuracy: 0.9740 - val_loss: 1.2094 - val_accuracy: 0.6459\n","Epoch 20/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4090 - accuracy: 0.9768 - val_loss: 1.1621 - val_accuracy: 0.6640\n","Epoch 21/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4076 - accuracy: 0.9762 - val_loss: 1.1419 - val_accuracy: 0.6731\n","Epoch 22/100\n","28/28 [==============================] - 3s 101ms/step - loss: 0.4044 - accuracy: 0.9791 - val_loss: 1.2148 - val_accuracy: 0.6697\n","Epoch 23/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.4015 - accuracy: 0.9779 - val_loss: 1.0837 - val_accuracy: 0.7070\n","Epoch 24/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3960 - accuracy: 0.9788 - val_loss: 1.0148 - val_accuracy: 0.7229\n","Epoch 25/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3993 - accuracy: 0.9779 - val_loss: 1.0058 - val_accuracy: 0.7229\n","Epoch 26/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3986 - accuracy: 0.9796 - val_loss: 0.9958 - val_accuracy: 0.7308\n","Epoch 27/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.3903 - accuracy: 0.9839 - val_loss: 1.0307 - val_accuracy: 0.7364\n","Epoch 28/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.3854 - accuracy: 0.9881 - val_loss: 0.9872 - val_accuracy: 0.7421\n","Epoch 29/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3837 - accuracy: 0.9850 - val_loss: 1.0627 - val_accuracy: 0.7387\n","Epoch 30/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3834 - accuracy: 0.9890 - val_loss: 0.9851 - val_accuracy: 0.7376\n","Epoch 31/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4028 - accuracy: 0.9751 - val_loss: 1.1568 - val_accuracy: 0.7387\n","Epoch 32/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3854 - accuracy: 0.9867 - val_loss: 0.9760 - val_accuracy: 0.7568\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3822 - accuracy: 0.9878 - val_loss: 0.9864 - val_accuracy: 0.7523\n","Epoch 34/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3789 - accuracy: 0.9870 - val_loss: 0.9900 - val_accuracy: 0.7489\n","Epoch 35/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3781 - accuracy: 0.9867 - val_loss: 0.9916 - val_accuracy: 0.7466\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3726 - accuracy: 0.9895 - val_loss: 1.0100 - val_accuracy: 0.7387\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3749 - accuracy: 0.9881 - val_loss: 1.0072 - val_accuracy: 0.7534\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3723 - accuracy: 0.9898 - val_loss: 1.0299 - val_accuracy: 0.7432\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3688 - accuracy: 0.9904 - val_loss: 1.0249 - val_accuracy: 0.7432\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3654 - accuracy: 0.9921 - val_loss: 1.0443 - val_accuracy: 0.7421\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3649 - accuracy: 0.9907 - val_loss: 1.0353 - val_accuracy: 0.7477\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3640 - accuracy: 0.9912 - val_loss: 1.0324 - val_accuracy: 0.7523\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3598 - accuracy: 0.9915 - val_loss: 1.0587 - val_accuracy: 0.7455\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3614 - accuracy: 0.9912 - val_loss: 1.0575 - val_accuracy: 0.7477\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3623 - accuracy: 0.9909 - val_loss: 1.0507 - val_accuracy: 0.7466\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3562 - accuracy: 0.9932 - val_loss: 1.0452 - val_accuracy: 0.7489\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3532 - accuracy: 0.9935 - val_loss: 1.0504 - val_accuracy: 0.7455\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3506 - accuracy: 0.9943 - val_loss: 1.0506 - val_accuracy: 0.7477\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3506 - accuracy: 0.9943 - val_loss: 1.0822 - val_accuracy: 0.7421\n","Epoch 50/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3511 - accuracy: 0.9941 - val_loss: 1.0986 - val_accuracy: 0.7489\n","Epoch 51/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3476 - accuracy: 0.9952 - val_loss: 1.0706 - val_accuracy: 0.7500\n","Epoch 52/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3612 - accuracy: 0.9904 - val_loss: 1.1509 - val_accuracy: 0.7296\n","Epoch 53/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3562 - accuracy: 0.9935 - val_loss: 1.0817 - val_accuracy: 0.7443\n","Epoch 54/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3442 - accuracy: 0.9949 - val_loss: 1.0710 - val_accuracy: 0.7523\n","Epoch 55/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3431 - accuracy: 0.9960 - val_loss: 1.0821 - val_accuracy: 0.7421\n","Epoch 56/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3470 - accuracy: 0.9946 - val_loss: 1.0931 - val_accuracy: 0.7421\n","Epoch 57/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3415 - accuracy: 0.9972 - val_loss: 1.0918 - val_accuracy: 0.7500\n","Epoch 58/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3416 - accuracy: 0.9960 - val_loss: 1.1112 - val_accuracy: 0.7398\n","Epoch 59/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3394 - accuracy: 0.9960 - val_loss: 1.1032 - val_accuracy: 0.7455\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3414 - accuracy: 0.9949 - val_loss: 1.1450 - val_accuracy: 0.7376\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3450 - accuracy: 0.9943 - val_loss: 1.1249 - val_accuracy: 0.7410\n","Epoch 62/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3442 - accuracy: 0.9946 - val_loss: 1.1397 - val_accuracy: 0.7410\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3385 - accuracy: 0.9963 - val_loss: 1.1313 - val_accuracy: 0.7376\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3338 - accuracy: 0.9966 - val_loss: 1.1178 - val_accuracy: 0.7489\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3318 - accuracy: 0.9972 - val_loss: 1.1245 - val_accuracy: 0.7342\n","Epoch 66/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3333 - accuracy: 0.9966 - val_loss: 1.1271 - val_accuracy: 0.7432\n","Epoch 67/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3340 - accuracy: 0.9972 - val_loss: 1.1310 - val_accuracy: 0.7443\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3307 - accuracy: 0.9972 - val_loss: 1.1395 - val_accuracy: 0.7398\n","Epoch 69/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3371 - accuracy: 0.9960 - val_loss: 1.1759 - val_accuracy: 0.7477\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3350 - accuracy: 0.9963 - val_loss: 1.1477 - val_accuracy: 0.7353\n","Epoch 71/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3284 - accuracy: 0.9975 - val_loss: 1.1473 - val_accuracy: 0.7421\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3355 - accuracy: 0.9952 - val_loss: 1.1560 - val_accuracy: 0.7387\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3331 - accuracy: 0.9960 - val_loss: 1.1578 - val_accuracy: 0.7398\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3279 - accuracy: 0.9966 - val_loss: 1.1573 - val_accuracy: 0.7410\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3304 - accuracy: 0.9963 - val_loss: 1.1611 - val_accuracy: 0.7376\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3254 - accuracy: 0.9980 - val_loss: 1.1618 - val_accuracy: 0.7398\n","Epoch 77/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3317 - accuracy: 0.9960 - val_loss: 1.1812 - val_accuracy: 0.7387\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3249 - accuracy: 0.9977 - val_loss: 1.1770 - val_accuracy: 0.7398\n","Epoch 79/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3204 - accuracy: 0.9975 - val_loss: 1.1890 - val_accuracy: 0.7376\n","Epoch 80/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3207 - accuracy: 0.9992 - val_loss: 1.1707 - val_accuracy: 0.7398\n","Epoch 81/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3201 - accuracy: 0.9975 - val_loss: 1.1881 - val_accuracy: 0.7376\n","Epoch 82/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3215 - accuracy: 0.9983 - val_loss: 1.1801 - val_accuracy: 0.7432\n","Epoch 83/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3177 - accuracy: 0.9986 - val_loss: 1.1908 - val_accuracy: 0.7398\n","Epoch 84/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3188 - accuracy: 0.9983 - val_loss: 1.1955 - val_accuracy: 0.7398\n","Epoch 85/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3173 - accuracy: 0.9980 - val_loss: 1.1951 - val_accuracy: 0.7455\n","Epoch 86/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3179 - accuracy: 0.9980 - val_loss: 1.2030 - val_accuracy: 0.7376\n","Epoch 87/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3162 - accuracy: 0.9977 - val_loss: 1.2339 - val_accuracy: 0.7443\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3152 - accuracy: 0.9983 - val_loss: 1.2274 - val_accuracy: 0.7364\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3177 - accuracy: 0.9977 - val_loss: 1.2034 - val_accuracy: 0.7421\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3134 - accuracy: 0.9986 - val_loss: 1.2260 - val_accuracy: 0.7342\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3129 - accuracy: 0.9983 - val_loss: 1.2239 - val_accuracy: 0.7387\n","Epoch 92/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3134 - accuracy: 0.9989 - val_loss: 1.2270 - val_accuracy: 0.7353\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3137 - accuracy: 0.9983 - val_loss: 1.2127 - val_accuracy: 0.7398\n","Epoch 94/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3139 - accuracy: 0.9980 - val_loss: 1.2503 - val_accuracy: 0.7410\n","Epoch 95/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3103 - accuracy: 0.9994 - val_loss: 1.2300 - val_accuracy: 0.7364\n","Epoch 96/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3094 - accuracy: 0.9989 - val_loss: 1.2295 - val_accuracy: 0.7432\n","Epoch 97/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3146 - accuracy: 0.9972 - val_loss: 1.2424 - val_accuracy: 0.7353\n","Epoch 98/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3114 - accuracy: 0.9986 - val_loss: 1.2399 - val_accuracy: 0.7353\n","Epoch 99/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3089 - accuracy: 0.9989 - val_loss: 1.2440 - val_accuracy: 0.7387\n","Epoch 100/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3084 - accuracy: 0.9989 - val_loss: 1.2630 - val_accuracy: 0.7262\n","{'loss': [0.552679181098938, 0.48792409896850586, 0.4790283143520355, 0.4711407423019409, 0.4680078625679016, 0.4639345109462738, 0.45605579018592834, 0.4564523994922638, 0.44175177812576294, 0.44124525785446167, 0.43698158860206604, 0.44704532623291016, 0.44375211000442505, 0.4230062663555145, 0.420677125453949, 0.4206177294254303, 0.4188595414161682, 0.4140051603317261, 0.4118748605251312, 0.40897849202156067, 0.4076493978500366, 0.40438443422317505, 0.4015224277973175, 0.39599135518074036, 0.39934632182121277, 0.3986368179321289, 0.390265554189682, 0.385439395904541, 0.38371631503105164, 0.38344067335128784, 0.40277862548828125, 0.3853703737258911, 0.3822265565395355, 0.37888336181640625, 0.3781251907348633, 0.37255579233169556, 0.37488263845443726, 0.3723377585411072, 0.36883994936943054, 0.36541253328323364, 0.3649093806743622, 0.36399397253990173, 0.3598303198814392, 0.3614180088043213, 0.3622657358646393, 0.356200248003006, 0.3531857132911682, 0.35064417123794556, 0.3505952060222626, 0.3511482775211334, 0.3476305305957794, 0.36116471886634827, 0.35616567730903625, 0.3441714644432068, 0.343072772026062, 0.34699541330337524, 0.341533899307251, 0.3415720760822296, 0.33936235308647156, 0.34138262271881104, 0.34503406286239624, 0.3441603481769562, 0.3384799659252167, 0.3337944447994232, 0.33183568716049194, 0.3333488702774048, 0.33403366804122925, 0.3307194113731384, 0.3371148109436035, 0.33501386642456055, 0.3284405767917633, 0.3354988694190979, 0.3331489562988281, 0.32790452241897583, 0.3304184079170227, 0.32543203234672546, 0.3317336440086365, 0.32490837574005127, 0.320410817861557, 0.32072216272354126, 0.3201417326927185, 0.3214825689792633, 0.31774619221687317, 0.31883251667022705, 0.3173447847366333, 0.3179119825363159, 0.3162401616573334, 0.31520184874534607, 0.317670613527298, 0.3134181499481201, 0.3128620684146881, 0.31344810128211975, 0.3136821687221527, 0.3139001727104187, 0.3102649450302124, 0.3093568682670593, 0.31458860635757446, 0.31138092279434204, 0.3088529407978058, 0.3084249794483185], 'accuracy': [0.9035087823867798, 0.9397283792495728, 0.9448217153549194, 0.9439728260040283, 0.9487832188606262, 0.9468024969100952, 0.9527447819709778, 0.950764000415802, 0.961799681186676, 0.9634974598884583, 0.9629315137863159, 0.9552914500236511, 0.9572722315788269, 0.9697226881980896, 0.9697226881980896, 0.971137523651123, 0.9700056314468384, 0.9736841917037964, 0.9739671945571899, 0.9767968058586121, 0.9762309193611145, 0.9790605306625366, 0.9779286980628967, 0.9787775874137878, 0.9779286980628967, 0.979626476764679, 0.9838709831237793, 0.9881154298782349, 0.9850028157234192, 0.988964319229126, 0.9750990271568298, 0.9867005944252014, 0.9878324866294861, 0.986983597278595, 0.9867005944252014, 0.9895302653312683, 0.9881154298782349, 0.9898132681846619, 0.9903791546821594, 0.9920769929885864, 0.990662157535553, 0.9912280440330505, 0.9915110468864441, 0.9912280440330505, 0.9909451007843018, 0.9932088255882263, 0.9934917688369751, 0.994340717792511, 0.994340717792511, 0.9940577149391174, 0.9951896071434021, 0.9903791546821594, 0.9934917688369751, 0.9949066042900085, 0.9960384964942932, 0.9946236610412598, 0.9971703290939331, 0.9960384964942932, 0.9960384964942932, 0.9949066042900085, 0.994340717792511, 0.9946236610412598, 0.996321439743042, 0.9966044425964355, 0.9971703290939331, 0.9966044425964355, 0.9971703290939331, 0.9971703290939331, 0.9960384964942932, 0.996321439743042, 0.9974533319473267, 0.9951896071434021, 0.9960384964942932, 0.9966044425964355, 0.996321439743042, 0.9980192184448242, 0.9960384964942932, 0.9977362751960754, 0.9974533319473267, 0.9991511106491089, 0.9974533319473267, 0.9983022212982178, 0.9985851645469666, 0.9983022212982178, 0.9980192184448242, 0.9980192184448242, 0.9977362751960754, 0.9983022212982178, 0.9977362751960754, 0.9985851645469666, 0.9983022212982178, 0.9988681674003601, 0.9983022212982178, 0.9980192184448242, 0.9994340538978577, 0.9988681674003601, 0.9971703290939331, 0.9985851645469666, 0.9988681674003601, 0.9988681674003601], 'val_loss': [1.0135329961776733, 1.0102872848510742, 0.9962418079376221, 0.9967774748802185, 0.9894443154335022, 0.9976421594619751, 1.0203344821929932, 1.0078364610671997, 1.0244773626327515, 1.068489909172058, 1.0552736520767212, 1.0864497423171997, 1.1444512605667114, 1.168259859085083, 1.2062195539474487, 1.1617344617843628, 1.206254243850708, 1.241892695426941, 1.2093700170516968, 1.162064790725708, 1.141904354095459, 1.2148218154907227, 1.0836843252182007, 1.0148026943206787, 1.0057523250579834, 0.9957532286643982, 1.0306980609893799, 0.9872400164604187, 1.0627050399780273, 0.9850652813911438, 1.1567986011505127, 0.9759708642959595, 0.9863747358322144, 0.989990770816803, 0.9916464686393738, 1.0099951028823853, 1.007184386253357, 1.0299389362335205, 1.0248725414276123, 1.0443100929260254, 1.0352942943572998, 1.0324074029922485, 1.058693289756775, 1.0575220584869385, 1.0506668090820312, 1.0452338457107544, 1.0504374504089355, 1.0505801439285278, 1.0822076797485352, 1.0985958576202393, 1.0706483125686646, 1.1509292125701904, 1.0816607475280762, 1.0709954500198364, 1.0821396112442017, 1.0931066274642944, 1.0917974710464478, 1.1112127304077148, 1.1032204627990723, 1.1450212001800537, 1.124883770942688, 1.1396621465682983, 1.1313496828079224, 1.1177692413330078, 1.1245183944702148, 1.1270500421524048, 1.1310498714447021, 1.1395432949066162, 1.1759121417999268, 1.147727131843567, 1.147343397140503, 1.156008243560791, 1.1578021049499512, 1.1573375463485718, 1.1611031293869019, 1.1618367433547974, 1.1811890602111816, 1.1770294904708862, 1.1890398263931274, 1.1707344055175781, 1.1881182193756104, 1.1800966262817383, 1.1907854080200195, 1.195538878440857, 1.1951253414154053, 1.2030059099197388, 1.2338625192642212, 1.2273606061935425, 1.2033675909042358, 1.2260361909866333, 1.223922848701477, 1.2270283699035645, 1.2127293348312378, 1.2503360509872437, 1.229958415031433, 1.2295117378234863, 1.2423620223999023, 1.23994779586792, 1.2440446615219116, 1.2629659175872803], 'val_accuracy': [0.5135746598243713, 0.5248869061470032, 0.5588235259056091, 0.564479649066925, 0.5825791954994202, 0.5769230723381042, 0.570135772228241, 0.5882353186607361, 0.587104082107544, 0.5769230723381042, 0.5927602052688599, 0.5950226187705994, 0.5904977321624756, 0.5927602052688599, 0.6018099784851074, 0.6210407018661499, 0.6187782883644104, 0.6244344115257263, 0.6459276080131531, 0.6640271544456482, 0.6730769276618958, 0.6696832776069641, 0.7070135474205017, 0.7228506803512573, 0.7228506803512573, 0.7307692170143127, 0.7364253401756287, 0.7420814633369446, 0.7386877536773682, 0.7375565767288208, 0.7386877536773682, 0.7567873597145081, 0.7522624731063843, 0.7488687634468079, 0.7466063499450684, 0.7386877536773682, 0.7533936500549316, 0.7432126402854919, 0.7432126402854919, 0.7420814633369446, 0.7477375268936157, 0.7522624731063843, 0.7454751133918762, 0.7477375268936157, 0.7466063499450684, 0.7488687634468079, 0.7454751133918762, 0.7477375268936157, 0.7420814633369446, 0.7488687634468079, 0.75, 0.7296379804611206, 0.7443438768386841, 0.7522624731063843, 0.7420814633369446, 0.7420814633369446, 0.75, 0.7398189902305603, 0.7454751133918762, 0.7375565767288208, 0.7409502267837524, 0.7409502267837524, 0.7375565767288208, 0.7488687634468079, 0.7341628670692444, 0.7432126402854919, 0.7443438768386841, 0.7398189902305603, 0.7477375268936157, 0.7352941036224365, 0.7420814633369446, 0.7386877536773682, 0.7398189902305603, 0.7409502267837524, 0.7375565767288208, 0.7398189902305603, 0.7386877536773682, 0.7398189902305603, 0.7375565767288208, 0.7398189902305603, 0.7375565767288208, 0.7432126402854919, 0.7398189902305603, 0.7398189902305603, 0.7454751133918762, 0.7375565767288208, 0.7443438768386841, 0.7364253401756287, 0.7420814633369446, 0.7341628670692444, 0.7386877536773682, 0.7352941036224365, 0.7398189902305603, 0.7409502267837524, 0.7364253401756287, 0.7432126402854919, 0.7352941036224365, 0.7352941036224365, 0.7386877536773682, 0.726244330406189]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.5914 - accuracy: 0.8865"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 5s 37ms/step - loss: 0.5904 - accuracy: 0.8868 - val_loss: 1.0206 - val_accuracy: 0.4990\n","Epoch 2/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5179 - accuracy: 0.9207 - val_loss: 1.0162 - val_accuracy: 0.5155\n","Epoch 3/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5129 - accuracy: 0.9214 - val_loss: 1.0170 - val_accuracy: 0.5248\n","Epoch 4/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5009 - accuracy: 0.9295 - val_loss: 1.0124 - val_accuracy: 0.5362\n","Epoch 5/100\n","31/31 [==============================] - 3s 112ms/step - loss: 0.4990 - accuracy: 0.9336 - val_loss: 1.0163 - val_accuracy: 0.5434\n","Epoch 6/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4856 - accuracy: 0.9354 - val_loss: 1.0222 - val_accuracy: 0.5517\n","Epoch 7/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4818 - accuracy: 0.9344 - val_loss: 1.0433 - val_accuracy: 0.5465\n","Epoch 8/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4816 - accuracy: 0.9349 - val_loss: 1.0702 - val_accuracy: 0.5434\n","Epoch 9/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4894 - accuracy: 0.9279 - val_loss: 1.0423 - val_accuracy: 0.5682\n","Epoch 10/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4652 - accuracy: 0.9470 - val_loss: 1.0322 - val_accuracy: 0.5868\n","Epoch 11/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4701 - accuracy: 0.9460 - val_loss: 1.0850 - val_accuracy: 0.5775\n","Epoch 12/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4562 - accuracy: 0.9563 - val_loss: 1.1862 - val_accuracy: 0.5558\n","Epoch 13/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4561 - accuracy: 0.9491 - val_loss: 1.1474 - val_accuracy: 0.5847\n","Epoch 14/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4520 - accuracy: 0.9568 - val_loss: 1.1760 - val_accuracy: 0.5878\n","Epoch 15/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4462 - accuracy: 0.9568 - val_loss: 1.4135 - val_accuracy: 0.5630\n","Epoch 16/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4595 - accuracy: 0.9463 - val_loss: 1.2884 - val_accuracy: 0.5806\n","Epoch 17/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4445 - accuracy: 0.9618 - val_loss: 1.2806 - val_accuracy: 0.5981\n","Epoch 18/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4391 - accuracy: 0.9602 - val_loss: 1.0821 - val_accuracy: 0.6601\n","Epoch 19/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4537 - accuracy: 0.9509 - val_loss: 1.2091 - val_accuracy: 0.6343\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4537 - accuracy: 0.9496 - val_loss: 1.2619 - val_accuracy: 0.6353\n","Epoch 21/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4276 - accuracy: 0.9716 - val_loss: 1.1389 - val_accuracy: 0.6756\n","Epoch 22/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4215 - accuracy: 0.9731 - val_loss: 1.0616 - val_accuracy: 0.7087\n","Epoch 23/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4330 - accuracy: 0.9581 - val_loss: 0.9949 - val_accuracy: 0.7459\n","Epoch 24/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4273 - accuracy: 0.9690 - val_loss: 1.0603 - val_accuracy: 0.7231\n","Epoch 25/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4193 - accuracy: 0.9724 - val_loss: 1.0655 - val_accuracy: 0.7252\n","Epoch 26/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4308 - accuracy: 0.9612 - val_loss: 1.0267 - val_accuracy: 0.7510\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4352 - accuracy: 0.9550 - val_loss: 1.0129 - val_accuracy: 0.7407\n","Epoch 28/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4125 - accuracy: 0.9755 - val_loss: 1.0006 - val_accuracy: 0.7572\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4190 - accuracy: 0.9713 - val_loss: 1.0244 - val_accuracy: 0.7397\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4129 - accuracy: 0.9705 - val_loss: 1.0235 - val_accuracy: 0.7479\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4005 - accuracy: 0.9809 - val_loss: 1.0794 - val_accuracy: 0.7324\n","Epoch 32/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4054 - accuracy: 0.9773 - val_loss: 1.0373 - val_accuracy: 0.7428\n","Epoch 33/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4006 - accuracy: 0.9798 - val_loss: 1.0657 - val_accuracy: 0.7428\n","Epoch 34/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4100 - accuracy: 0.9726 - val_loss: 1.0698 - val_accuracy: 0.7448\n","Epoch 35/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4019 - accuracy: 0.9786 - val_loss: 1.0516 - val_accuracy: 0.7541\n","Epoch 36/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3914 - accuracy: 0.9853 - val_loss: 1.0553 - val_accuracy: 0.7521\n","Epoch 37/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3879 - accuracy: 0.9858 - val_loss: 1.0642 - val_accuracy: 0.7376\n","Epoch 38/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3887 - accuracy: 0.9837 - val_loss: 1.0615 - val_accuracy: 0.7428\n","Epoch 39/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3837 - accuracy: 0.9860 - val_loss: 1.0823 - val_accuracy: 0.7572\n","Epoch 40/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3909 - accuracy: 0.9829 - val_loss: 1.0905 - val_accuracy: 0.7469\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3873 - accuracy: 0.9842 - val_loss: 1.0986 - val_accuracy: 0.7304\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3882 - accuracy: 0.9842 - val_loss: 1.0801 - val_accuracy: 0.7407\n","Epoch 43/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3810 - accuracy: 0.9850 - val_loss: 1.0783 - val_accuracy: 0.7541\n","Epoch 44/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3766 - accuracy: 0.9889 - val_loss: 1.1097 - val_accuracy: 0.7500\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3860 - accuracy: 0.9840 - val_loss: 1.1336 - val_accuracy: 0.7283\n","Epoch 46/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3900 - accuracy: 0.9806 - val_loss: 1.0851 - val_accuracy: 0.7521\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3725 - accuracy: 0.9891 - val_loss: 1.0859 - val_accuracy: 0.7448\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3747 - accuracy: 0.9873 - val_loss: 1.1294 - val_accuracy: 0.7262\n","Epoch 49/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3864 - accuracy: 0.9824 - val_loss: 1.1177 - val_accuracy: 0.7531\n","Epoch 50/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3739 - accuracy: 0.9889 - val_loss: 1.1385 - val_accuracy: 0.7304\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3723 - accuracy: 0.9876 - val_loss: 1.1032 - val_accuracy: 0.7479\n","Epoch 52/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3703 - accuracy: 0.9879 - val_loss: 1.1440 - val_accuracy: 0.7273\n","Epoch 53/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3751 - accuracy: 0.9863 - val_loss: 1.1176 - val_accuracy: 0.7366\n","Epoch 54/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3644 - accuracy: 0.9902 - val_loss: 1.1446 - val_accuracy: 0.7469\n","Epoch 55/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3636 - accuracy: 0.9925 - val_loss: 1.1499 - val_accuracy: 0.7273\n","Epoch 56/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3695 - accuracy: 0.9879 - val_loss: 1.1332 - val_accuracy: 0.7324\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3589 - accuracy: 0.9915 - val_loss: 1.1293 - val_accuracy: 0.7428\n","Epoch 58/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3573 - accuracy: 0.9941 - val_loss: 1.1505 - val_accuracy: 0.7438\n","Epoch 59/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3599 - accuracy: 0.9915 - val_loss: 1.1346 - val_accuracy: 0.7541\n","Epoch 60/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3520 - accuracy: 0.9941 - val_loss: 1.1381 - val_accuracy: 0.7376\n","Epoch 61/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3561 - accuracy: 0.9925 - val_loss: 1.2062 - val_accuracy: 0.7211\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3722 - accuracy: 0.9837 - val_loss: 1.1451 - val_accuracy: 0.7562\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3514 - accuracy: 0.9951 - val_loss: 1.1534 - val_accuracy: 0.7314\n","Epoch 64/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3484 - accuracy: 0.9946 - val_loss: 1.2113 - val_accuracy: 0.7200\n","Epoch 65/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3494 - accuracy: 0.9956 - val_loss: 1.1819 - val_accuracy: 0.7335\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3455 - accuracy: 0.9959 - val_loss: 1.1738 - val_accuracy: 0.7335\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3471 - accuracy: 0.9943 - val_loss: 1.2584 - val_accuracy: 0.7087\n","Epoch 68/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3574 - accuracy: 0.9910 - val_loss: 1.1755 - val_accuracy: 0.7376\n","Epoch 69/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3474 - accuracy: 0.9943 - val_loss: 1.1665 - val_accuracy: 0.7459\n","Epoch 70/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3455 - accuracy: 0.9943 - val_loss: 1.1713 - val_accuracy: 0.7479\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3887 - accuracy: 0.9713 - val_loss: 1.2003 - val_accuracy: 0.7376\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3472 - accuracy: 0.9933 - val_loss: 1.1786 - val_accuracy: 0.7304\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3415 - accuracy: 0.9956 - val_loss: 1.1884 - val_accuracy: 0.7231\n","Epoch 74/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3374 - accuracy: 0.9964 - val_loss: 1.2059 - val_accuracy: 0.7304\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3401 - accuracy: 0.9961 - val_loss: 1.1907 - val_accuracy: 0.7407\n","Epoch 76/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3431 - accuracy: 0.9935 - val_loss: 1.1886 - val_accuracy: 0.7428\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3557 - accuracy: 0.9891 - val_loss: 1.1973 - val_accuracy: 0.7397\n","Epoch 78/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3347 - accuracy: 0.9974 - val_loss: 1.2041 - val_accuracy: 0.7304\n","Epoch 79/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3343 - accuracy: 0.9959 - val_loss: 1.2162 - val_accuracy: 0.7262\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3383 - accuracy: 0.9946 - val_loss: 1.2035 - val_accuracy: 0.7314\n","Epoch 81/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3310 - accuracy: 0.9979 - val_loss: 1.2120 - val_accuracy: 0.7293\n","Epoch 82/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3301 - accuracy: 0.9977 - val_loss: 1.2729 - val_accuracy: 0.7149\n","Epoch 83/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3318 - accuracy: 0.9969 - val_loss: 1.2643 - val_accuracy: 0.7293\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3362 - accuracy: 0.9951 - val_loss: 1.2164 - val_accuracy: 0.7469\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3308 - accuracy: 0.9974 - val_loss: 1.2196 - val_accuracy: 0.7407\n","Epoch 86/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3290 - accuracy: 0.9969 - val_loss: 1.2656 - val_accuracy: 0.7169\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3287 - accuracy: 0.9977 - val_loss: 1.2251 - val_accuracy: 0.7324\n","Epoch 88/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3248 - accuracy: 0.9984 - val_loss: 1.2305 - val_accuracy: 0.7407\n","Epoch 89/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3308 - accuracy: 0.9966 - val_loss: 1.2296 - val_accuracy: 0.7459\n","Epoch 90/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3263 - accuracy: 0.9977 - val_loss: 1.2367 - val_accuracy: 0.7376\n","Epoch 91/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3266 - accuracy: 0.9959 - val_loss: 1.2382 - val_accuracy: 0.7355\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3241 - accuracy: 0.9987 - val_loss: 1.2450 - val_accuracy: 0.7469\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3276 - accuracy: 0.9961 - val_loss: 1.3480 - val_accuracy: 0.7087\n","Epoch 94/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3305 - accuracy: 0.9948 - val_loss: 1.2636 - val_accuracy: 0.7428\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3252 - accuracy: 0.9974 - val_loss: 1.2581 - val_accuracy: 0.7273\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3309 - accuracy: 0.9966 - val_loss: 1.3911 - val_accuracy: 0.7025\n","Epoch 97/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3312 - accuracy: 0.9948 - val_loss: 1.2566 - val_accuracy: 0.7417\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3215 - accuracy: 0.9977 - val_loss: 1.2656 - val_accuracy: 0.7231\n","Epoch 99/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3221 - accuracy: 0.9972 - val_loss: 1.3829 - val_accuracy: 0.7087\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3232 - accuracy: 0.9964 - val_loss: 1.3216 - val_accuracy: 0.7169\n","{'loss': [0.5903565883636475, 0.5178564786911011, 0.5128811597824097, 0.5009154677391052, 0.4990067183971405, 0.4856259226799011, 0.48176565766334534, 0.4816007614135742, 0.48935481905937195, 0.465233713388443, 0.4701398015022278, 0.4562215209007263, 0.45614588260650635, 0.45200836658477783, 0.4462259113788605, 0.45951107144355774, 0.4445369243621826, 0.43911057710647583, 0.4537120759487152, 0.4536566138267517, 0.4276116192340851, 0.4215143322944641, 0.4330421984195709, 0.42730072140693665, 0.4192630350589752, 0.4307628870010376, 0.43515336513519287, 0.41249358654022217, 0.41900479793548584, 0.4128628671169281, 0.40052342414855957, 0.4053836166858673, 0.40064436197280884, 0.4099799394607544, 0.4018755853176117, 0.3914075493812561, 0.38786566257476807, 0.3887362480163574, 0.38368701934814453, 0.39089709520339966, 0.3872697055339813, 0.388232946395874, 0.3809535801410675, 0.376557320356369, 0.38597676157951355, 0.39000988006591797, 0.3724788427352905, 0.37465324997901917, 0.3863871395587921, 0.3739263415336609, 0.37230896949768066, 0.3703128397464752, 0.3751009702682495, 0.3644431233406067, 0.3636035919189453, 0.36947932839393616, 0.3589242398738861, 0.35729503631591797, 0.35989195108413696, 0.35199466347694397, 0.35607171058654785, 0.3721765875816345, 0.3513513505458832, 0.34836918115615845, 0.3494352698326111, 0.3454906940460205, 0.34706416726112366, 0.3574063777923584, 0.34736767411231995, 0.34546661376953125, 0.38873133063316345, 0.347164511680603, 0.34148111939430237, 0.3373951315879822, 0.34005206823349, 0.3431151211261749, 0.35572507977485657, 0.33468544483184814, 0.33431321382522583, 0.33828508853912354, 0.33097273111343384, 0.3301008343696594, 0.3317610025405884, 0.3362266421318054, 0.3307547867298126, 0.32902711629867554, 0.3287442922592163, 0.32482850551605225, 0.3308226466178894, 0.326290488243103, 0.32663384079933167, 0.3241020441055298, 0.32761436700820923, 0.3305168151855469, 0.32517844438552856, 0.33093681931495667, 0.33117568492889404, 0.3215284049510956, 0.32214367389678955, 0.32324519753456116], 'accuracy': [0.8868216872215271, 0.920671820640564, 0.9214470386505127, 0.9294573664665222, 0.9335917234420776, 0.9354005455970764, 0.9343669414520264, 0.934883713722229, 0.9279069900512695, 0.947028398513794, 0.9459948539733887, 0.9563307762145996, 0.949095606803894, 0.9568475484848022, 0.9568475484848022, 0.94625324010849, 0.9617571234703064, 0.9602067470550537, 0.950904369354248, 0.9496123790740967, 0.9715762138366699, 0.9731265902519226, 0.9581395387649536, 0.9689922332763672, 0.9723514318466187, 0.961240291595459, 0.9550387859344482, 0.975452184677124, 0.9713178277015686, 0.9705426096916199, 0.9808785319328308, 0.9772610068321228, 0.9798449873924255, 0.97260981798172, 0.9785529971122742, 0.9852713346481323, 0.985788106918335, 0.9837209582328796, 0.9860464930534363, 0.9829457402229309, 0.9842377305030823, 0.9842377305030823, 0.985012948513031, 0.9888888597488403, 0.983979344367981, 0.9806201457977295, 0.9891473054885864, 0.9873384833335876, 0.9824289679527283, 0.9888888597488403, 0.987596869468689, 0.9878553152084351, 0.9863049387931824, 0.9901808500289917, 0.9925064444541931, 0.9878553152084351, 0.9914728403091431, 0.9940568208694458, 0.9914728403091431, 0.9940568208694458, 0.9925064444541931, 0.9837209582328796, 0.9950904250144958, 0.9945736527442932, 0.9956072568893433, 0.9958656430244446, 0.9943152666091919, 0.9909560680389404, 0.9943152666091919, 0.9943152666091919, 0.9713178277015686, 0.9932816624641418, 0.9956072568893433, 0.9963824152946472, 0.9961240291595459, 0.9935400485992432, 0.9891473054885864, 0.9974160194396973, 0.9958656430244446, 0.9945736527442932, 0.9979327917098999, 0.9976744055747986, 0.9968992471694946, 0.9950904250144958, 0.9974160194396973, 0.9968992471694946, 0.9976744055747986, 0.9984496235847473, 0.9966408014297485, 0.9976744055747986, 0.9958656430244446, 0.9987080097198486, 0.9961240291595459, 0.9948320388793945, 0.9974160194396973, 0.9966408014297485, 0.9948320388793945, 0.9976744055747986, 0.997157633304596, 0.9963824152946472], 'val_loss': [1.0206427574157715, 1.0161573886871338, 1.017048954963684, 1.0123674869537354, 1.0162897109985352, 1.0222198963165283, 1.043349027633667, 1.0701940059661865, 1.0422801971435547, 1.0321844816207886, 1.0849522352218628, 1.1861923933029175, 1.1473907232284546, 1.1760239601135254, 1.4135366678237915, 1.2883789539337158, 1.2805957794189453, 1.0821160078048706, 1.209139108657837, 1.2618509531021118, 1.1388729810714722, 1.0616222620010376, 0.9948965311050415, 1.0602760314941406, 1.0655137300491333, 1.0267354249954224, 1.0129109621047974, 1.0005513429641724, 1.0244439840316772, 1.0234569311141968, 1.0794159173965454, 1.0372830629348755, 1.0656927824020386, 1.0698410272598267, 1.0516395568847656, 1.055310606956482, 1.0642369985580444, 1.061475396156311, 1.0822627544403076, 1.0904847383499146, 1.098604440689087, 1.0800652503967285, 1.0782523155212402, 1.1096909046173096, 1.1336290836334229, 1.085142731666565, 1.085850477218628, 1.129442811012268, 1.1177281141281128, 1.1384994983673096, 1.1031731367111206, 1.1440128087997437, 1.1175973415374756, 1.1446483135223389, 1.1498868465423584, 1.133160948753357, 1.12930166721344, 1.1505162715911865, 1.1345500946044922, 1.1381148099899292, 1.2062262296676636, 1.1451201438903809, 1.153409719467163, 1.2113088369369507, 1.1818718910217285, 1.1738063097000122, 1.258392095565796, 1.1755157709121704, 1.1665480136871338, 1.1712751388549805, 1.200332760810852, 1.1786327362060547, 1.188440203666687, 1.205895185470581, 1.1907093524932861, 1.18855881690979, 1.1973106861114502, 1.2041239738464355, 1.216224193572998, 1.2034735679626465, 1.211988091468811, 1.2729358673095703, 1.2642892599105835, 1.216363549232483, 1.2195632457733154, 1.265619158744812, 1.2250875234603882, 1.2305405139923096, 1.2295631170272827, 1.2367165088653564, 1.2381998300552368, 1.244954228401184, 1.3480050563812256, 1.263626217842102, 1.2581429481506348, 1.3910810947418213, 1.2565585374832153, 1.265573501586914, 1.382881760597229, 1.3216077089309692], 'val_accuracy': [0.49896693229675293, 0.5154958963394165, 0.5247933864593506, 0.5361570119857788, 0.5433884263038635, 0.5516529083251953, 0.5464876294136047, 0.5433884263038635, 0.5681818127632141, 0.586776852607727, 0.577479362487793, 0.5557851195335388, 0.5847107172012329, 0.5878099203109741, 0.5630165338516235, 0.5805785059928894, 0.5981404781341553, 0.6601239442825317, 0.6342975497245789, 0.6353305578231812, 0.6756198406219482, 0.7086777091026306, 0.7458677887916565, 0.7231404781341553, 0.7252066135406494, 0.7510330677032471, 0.7407024502754211, 0.7572314143180847, 0.7396694421768188, 0.7479338645935059, 0.7324380278587341, 0.7427685856819153, 0.7427685856819153, 0.7448347210884094, 0.7541322112083435, 0.7520661354064941, 0.7376033067703247, 0.7427685856819153, 0.7572314143180847, 0.7469007968902588, 0.73037189245224, 0.7407024502754211, 0.7541322112083435, 0.75, 0.7283057570457458, 0.7520661354064941, 0.7448347210884094, 0.7262396812438965, 0.7530992031097412, 0.73037189245224, 0.7479338645935059, 0.7272727489471436, 0.7365702390670776, 0.7469007968902588, 0.7272727489471436, 0.7324380278587341, 0.7427685856819153, 0.7438016533851624, 0.7541322112083435, 0.7376033067703247, 0.7210744023323059, 0.7561983466148376, 0.7314049601554871, 0.7200413346290588, 0.7334710955619812, 0.7334710955619812, 0.7086777091026306, 0.7376033067703247, 0.7458677887916565, 0.7479338645935059, 0.7376033067703247, 0.73037189245224, 0.7231404781341553, 0.73037189245224, 0.7407024502754211, 0.7427685856819153, 0.7396694421768188, 0.73037189245224, 0.7262396812438965, 0.7314049601554871, 0.7293388247489929, 0.7148760557174683, 0.7293388247489929, 0.7469007968902588, 0.7407024502754211, 0.7169421315193176, 0.7324380278587341, 0.7407024502754211, 0.7458677887916565, 0.7376033067703247, 0.7355371713638306, 0.7469007968902588, 0.7086777091026306, 0.7427685856819153, 0.7272727489471436, 0.702479362487793, 0.7417355179786682, 0.7231404781341553, 0.7086777091026306, 0.7169421315193176]}\n","32/32 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.4584 - accuracy: 0.9397"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 5s 34ms/step - loss: 0.4584 - accuracy: 0.9397 - val_loss: 1.0283 - val_accuracy: 0.5065\n","Epoch 2/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3829 - accuracy: 0.9736 - val_loss: 1.0311 - val_accuracy: 0.5119\n","Epoch 3/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3734 - accuracy: 0.9747 - val_loss: 1.0246 - val_accuracy: 0.5409\n","Epoch 4/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3607 - accuracy: 0.9828 - val_loss: 1.0268 - val_accuracy: 0.5431\n","Epoch 5/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.3595 - accuracy: 0.9846 - val_loss: 1.0269 - val_accuracy: 0.5679\n","Epoch 6/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3530 - accuracy: 0.9841 - val_loss: 1.0624 - val_accuracy: 0.5550\n","Epoch 7/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3548 - accuracy: 0.9836 - val_loss: 1.0673 - val_accuracy: 0.5797\n","Epoch 8/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3572 - accuracy: 0.9838 - val_loss: 1.0501 - val_accuracy: 0.6002\n","Epoch 9/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3498 - accuracy: 0.9857 - val_loss: 1.0726 - val_accuracy: 0.5981\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3468 - accuracy: 0.9860 - val_loss: 1.1584 - val_accuracy: 0.6002\n","Epoch 11/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3430 - accuracy: 0.9892 - val_loss: 1.2149 - val_accuracy: 0.6002\n","Epoch 12/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3383 - accuracy: 0.9906 - val_loss: 1.2349 - val_accuracy: 0.6056\n","Epoch 13/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3351 - accuracy: 0.9930 - val_loss: 1.3622 - val_accuracy: 0.5938\n","Epoch 14/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3342 - accuracy: 0.9930 - val_loss: 1.4766 - val_accuracy: 0.5873\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3464 - accuracy: 0.9860 - val_loss: 1.5993 - val_accuracy: 0.5873\n","Epoch 16/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3465 - accuracy: 0.9863 - val_loss: 1.4922 - val_accuracy: 0.6228\n","Epoch 17/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3425 - accuracy: 0.9884 - val_loss: 1.6323 - val_accuracy: 0.6153\n","Epoch 18/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3314 - accuracy: 0.9957 - val_loss: 1.4254 - val_accuracy: 0.6606\n","Epoch 19/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3421 - accuracy: 0.9879 - val_loss: 1.3427 - val_accuracy: 0.6713\n","Epoch 20/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.3324 - accuracy: 0.9927 - val_loss: 1.4270 - val_accuracy: 0.6746\n","Epoch 21/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3249 - accuracy: 0.9957 - val_loss: 1.3699 - val_accuracy: 0.6907\n","Epoch 22/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3242 - accuracy: 0.9954 - val_loss: 1.1536 - val_accuracy: 0.7381\n","Epoch 23/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3232 - accuracy: 0.9957 - val_loss: 1.1016 - val_accuracy: 0.7489\n","Epoch 24/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3208 - accuracy: 0.9978 - val_loss: 1.0029 - val_accuracy: 0.7716\n","Epoch 25/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3222 - accuracy: 0.9962 - val_loss: 1.0137 - val_accuracy: 0.7737\n","Epoch 26/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3224 - accuracy: 0.9965 - val_loss: 0.9336 - val_accuracy: 0.7856\n","Epoch 27/100\n","29/29 [==============================] - 4s 152ms/step - loss: 0.3208 - accuracy: 0.9968 - val_loss: 0.9652 - val_accuracy: 0.7888\n","Epoch 28/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3252 - accuracy: 0.9933 - val_loss: 0.8919 - val_accuracy: 0.7953\n","Epoch 29/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3188 - accuracy: 0.9973 - val_loss: 0.9735 - val_accuracy: 0.7866\n","Epoch 30/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3196 - accuracy: 0.9962 - val_loss: 0.9132 - val_accuracy: 0.8071\n","Epoch 31/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3178 - accuracy: 0.9968 - val_loss: 0.9858 - val_accuracy: 0.7877\n","Epoch 32/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3177 - accuracy: 0.9968 - val_loss: 0.9653 - val_accuracy: 0.7963\n","Epoch 33/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3140 - accuracy: 0.9978 - val_loss: 0.9716 - val_accuracy: 0.7985\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3167 - accuracy: 0.9965 - val_loss: 0.9353 - val_accuracy: 0.8071\n","Epoch 35/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3155 - accuracy: 0.9973 - val_loss: 0.9476 - val_accuracy: 0.8093\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3121 - accuracy: 0.9973 - val_loss: 0.9424 - val_accuracy: 0.8093\n","Epoch 37/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3116 - accuracy: 0.9981 - val_loss: 0.9927 - val_accuracy: 0.7963\n","Epoch 38/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3139 - accuracy: 0.9984 - val_loss: 0.9461 - val_accuracy: 0.8114\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3176 - accuracy: 0.9970 - val_loss: 0.9556 - val_accuracy: 0.8060\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3153 - accuracy: 0.9968 - val_loss: 1.0035 - val_accuracy: 0.8006\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3105 - accuracy: 0.9976 - val_loss: 0.9683 - val_accuracy: 0.8039\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3097 - accuracy: 0.9978 - val_loss: 0.9759 - val_accuracy: 0.8093\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3141 - accuracy: 0.9970 - val_loss: 0.9611 - val_accuracy: 0.8114\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3085 - accuracy: 0.9984 - val_loss: 0.9521 - val_accuracy: 0.8039\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3262 - accuracy: 0.9916 - val_loss: 0.9763 - val_accuracy: 0.8006\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3118 - accuracy: 0.9970 - val_loss: 0.9855 - val_accuracy: 0.7996\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3066 - accuracy: 0.9981 - val_loss: 0.9787 - val_accuracy: 0.8093\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3058 - accuracy: 0.9981 - val_loss: 1.0015 - val_accuracy: 0.8006\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3059 - accuracy: 0.9978 - val_loss: 1.0009 - val_accuracy: 0.8060\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3054 - accuracy: 0.9978 - val_loss: 0.9821 - val_accuracy: 0.7942\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3042 - accuracy: 0.9976 - val_loss: 0.9852 - val_accuracy: 0.8050\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3045 - accuracy: 0.9973 - val_loss: 0.9967 - val_accuracy: 0.8071\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3032 - accuracy: 0.9978 - val_loss: 1.0298 - val_accuracy: 0.7996\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3044 - accuracy: 0.9978 - val_loss: 0.9793 - val_accuracy: 0.7974\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3030 - accuracy: 0.9989 - val_loss: 1.0100 - val_accuracy: 0.8071\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3045 - accuracy: 0.9981 - val_loss: 0.9995 - val_accuracy: 0.7920\n","Epoch 57/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3123 - accuracy: 0.9952 - val_loss: 1.0644 - val_accuracy: 0.7942\n","Epoch 58/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3030 - accuracy: 0.9978 - val_loss: 1.0243 - val_accuracy: 0.7974\n","Epoch 59/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3016 - accuracy: 0.9984 - val_loss: 0.9949 - val_accuracy: 0.7996\n","Epoch 60/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3004 - accuracy: 0.9973 - val_loss: 1.0530 - val_accuracy: 0.7888\n","Epoch 61/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2995 - accuracy: 0.9984 - val_loss: 0.9980 - val_accuracy: 0.8028\n","Epoch 62/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2987 - accuracy: 0.9984 - val_loss: 1.0424 - val_accuracy: 0.7942\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2995 - accuracy: 0.9976 - val_loss: 1.0271 - val_accuracy: 0.8028\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3011 - accuracy: 0.9978 - val_loss: 1.0840 - val_accuracy: 0.7899\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2988 - accuracy: 0.9978 - val_loss: 1.0239 - val_accuracy: 0.8050\n","Epoch 66/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2999 - accuracy: 0.9984 - val_loss: 1.0223 - val_accuracy: 0.8039\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3075 - accuracy: 0.9943 - val_loss: 1.0581 - val_accuracy: 0.7996\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3115 - accuracy: 0.9954 - val_loss: 1.1324 - val_accuracy: 0.7543\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3173 - accuracy: 0.9935 - val_loss: 1.0136 - val_accuracy: 0.7996\n","Epoch 70/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2984 - accuracy: 0.9978 - val_loss: 1.0296 - val_accuracy: 0.7845\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2948 - accuracy: 0.9984 - val_loss: 1.0823 - val_accuracy: 0.7909\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2921 - accuracy: 0.9989 - val_loss: 1.0801 - val_accuracy: 0.7953\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2924 - accuracy: 0.9987 - val_loss: 1.0918 - val_accuracy: 0.7888\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2949 - accuracy: 0.9978 - val_loss: 1.1011 - val_accuracy: 0.7856\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2931 - accuracy: 0.9981 - val_loss: 1.0427 - val_accuracy: 0.7985\n","Epoch 76/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2904 - accuracy: 0.9987 - val_loss: 1.0382 - val_accuracy: 0.7909\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2896 - accuracy: 0.9987 - val_loss: 1.0589 - val_accuracy: 0.7953\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2883 - accuracy: 0.9995 - val_loss: 1.0437 - val_accuracy: 0.7963\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2889 - accuracy: 0.9981 - val_loss: 1.0598 - val_accuracy: 0.8017\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2873 - accuracy: 0.9992 - val_loss: 1.0425 - val_accuracy: 0.7963\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2879 - accuracy: 0.9992 - val_loss: 1.0558 - val_accuracy: 0.7931\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2875 - accuracy: 0.9989 - val_loss: 1.1691 - val_accuracy: 0.7812\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2878 - accuracy: 0.9989 - val_loss: 1.0618 - val_accuracy: 0.7974\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2864 - accuracy: 0.9984 - val_loss: 1.0505 - val_accuracy: 0.7931\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2919 - accuracy: 0.9976 - val_loss: 1.2750 - val_accuracy: 0.7640\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3036 - accuracy: 0.9935 - val_loss: 1.0703 - val_accuracy: 0.7672\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2931 - accuracy: 0.9970 - val_loss: 1.0554 - val_accuracy: 0.7996\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2864 - accuracy: 0.9987 - val_loss: 1.0738 - val_accuracy: 0.7856\n","Epoch 89/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2842 - accuracy: 0.9995 - val_loss: 1.0660 - val_accuracy: 0.7974\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2834 - accuracy: 0.9987 - val_loss: 1.0836 - val_accuracy: 0.7920\n","Epoch 91/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2830 - accuracy: 0.9992 - val_loss: 1.0692 - val_accuracy: 0.7920\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2831 - accuracy: 0.9989 - val_loss: 1.1047 - val_accuracy: 0.7942\n","Epoch 93/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2833 - accuracy: 0.9989 - val_loss: 1.1751 - val_accuracy: 0.7812\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2928 - accuracy: 0.9965 - val_loss: 1.1218 - val_accuracy: 0.7780\n","Epoch 95/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2831 - accuracy: 0.9989 - val_loss: 1.1469 - val_accuracy: 0.7802\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2820 - accuracy: 0.9987 - val_loss: 1.1187 - val_accuracy: 0.7888\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2812 - accuracy: 0.9995 - val_loss: 1.1888 - val_accuracy: 0.7802\n","Epoch 98/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2821 - accuracy: 0.9987 - val_loss: 1.0800 - val_accuracy: 0.7942\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2791 - accuracy: 0.9997 - val_loss: 1.0958 - val_accuracy: 0.7942\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2805 - accuracy: 0.9987 - val_loss: 1.1162 - val_accuracy: 0.7694\n","{'loss': [0.4583737254142761, 0.38285985589027405, 0.3733616769313812, 0.36071664094924927, 0.35950642824172974, 0.3530455231666565, 0.3548048138618469, 0.3571702837944031, 0.34979113936424255, 0.3468303680419922, 0.34298938512802124, 0.33825016021728516, 0.3350788652896881, 0.33421790599823, 0.34641963243484497, 0.34649741649627686, 0.3424525856971741, 0.3314266502857208, 0.34209778904914856, 0.33235204219818115, 0.32488080859184265, 0.32418131828308105, 0.32319825887680054, 0.3208214342594147, 0.322201669216156, 0.32238447666168213, 0.32082822918891907, 0.32519254088401794, 0.31879156827926636, 0.3196280002593994, 0.3177565932273865, 0.31769025325775146, 0.31397876143455505, 0.3167369067668915, 0.31550800800323486, 0.31207379698753357, 0.311550110578537, 0.313875287771225, 0.31762030720710754, 0.3153466582298279, 0.31046897172927856, 0.30967625975608826, 0.3140677213668823, 0.30849993228912354, 0.32619598507881165, 0.3118246793746948, 0.3066440224647522, 0.3058236837387085, 0.30590149760246277, 0.30540722608566284, 0.3041737377643585, 0.30454421043395996, 0.3032076358795166, 0.30442073941230774, 0.30298423767089844, 0.3045457601547241, 0.31229761242866516, 0.3029610812664032, 0.301637202501297, 0.30039191246032715, 0.29951125383377075, 0.2986789345741272, 0.2994993031024933, 0.3011048436164856, 0.29875171184539795, 0.2998625338077545, 0.3074660897254944, 0.31154921650886536, 0.31725186109542847, 0.2983841300010681, 0.2947887182235718, 0.29206591844558716, 0.2924301326274872, 0.2948661744594574, 0.29307591915130615, 0.2904190123081207, 0.28960222005844116, 0.288273423910141, 0.2888701558113098, 0.28725627064704895, 0.28786489367485046, 0.2875388264656067, 0.28783097863197327, 0.28644320368766785, 0.2919069826602936, 0.3036479949951172, 0.2931331992149353, 0.28639060258865356, 0.28422781825065613, 0.28338661789894104, 0.2830218970775604, 0.28309935331344604, 0.2833326458930969, 0.2928052246570587, 0.28308138251304626, 0.2819799482822418, 0.2812497913837433, 0.28211766481399536, 0.27913975715637207, 0.2804511487483978], 'accuracy': [0.9396551847457886, 0.9735991358757019, 0.9746767282485962, 0.982758641242981, 0.9846444129943848, 0.9841055870056152, 0.9835668206214905, 0.9838362336158752, 0.985722005367279, 0.985991358757019, 0.9892241358757019, 0.990571141242981, 0.9929956793785095, 0.9929956793785095, 0.985991358757019, 0.9862607717514038, 0.9884159564971924, 0.9956896305084229, 0.9878771305084229, 0.9927262663841248, 0.9956896305084229, 0.9954202771186829, 0.9956896305084229, 0.9978448152542114, 0.9962284564971924, 0.9964978694915771, 0.9967672228813171, 0.9932650923728943, 0.9973060488700867, 0.9962284564971924, 0.9967672228813171, 0.9967672228813171, 0.9978448152542114, 0.9964978694915771, 0.9973060488700867, 0.9973060488700867, 0.9981142282485962, 0.998383641242981, 0.9970366358757019, 0.9967672228813171, 0.9975754022598267, 0.9978448152542114, 0.9970366358757019, 0.998383641242981, 0.9916487336158752, 0.9970366358757019, 0.9981142282485962, 0.9981142282485962, 0.9978448152542114, 0.9978448152542114, 0.9975754022598267, 0.9973060488700867, 0.9978448152542114, 0.9978448152542114, 0.9989224076271057, 0.9981142282485962, 0.9951508641242981, 0.9978448152542114, 0.998383641242981, 0.9973060488700867, 0.998383641242981, 0.998383641242981, 0.9975754022598267, 0.9978448152542114, 0.9978448152542114, 0.998383641242981, 0.9943426847457886, 0.9954202771186829, 0.993534505367279, 0.9978448152542114, 0.998383641242981, 0.9989224076271057, 0.998652994632721, 0.9978448152542114, 0.9981142282485962, 0.998652994632721, 0.998652994632721, 0.9994612336158752, 0.9981142282485962, 0.9991918206214905, 0.9991918206214905, 0.9989224076271057, 0.9989224076271057, 0.998383641242981, 0.9975754022598267, 0.993534505367279, 0.9970366358757019, 0.998652994632721, 0.9994612336158752, 0.998652994632721, 0.9991918206214905, 0.9989224076271057, 0.9989224076271057, 0.9964978694915771, 0.9989224076271057, 0.998652994632721, 0.9994612336158752, 0.998652994632721, 0.9997305870056152, 0.998652994632721], 'val_loss': [1.02828049659729, 1.0311434268951416, 1.0245544910430908, 1.0267798900604248, 1.0269383192062378, 1.0623667240142822, 1.0673167705535889, 1.050136685371399, 1.072647213935852, 1.1583552360534668, 1.2149062156677246, 1.2348887920379639, 1.3622273206710815, 1.4766416549682617, 1.5993499755859375, 1.4922127723693848, 1.6323412656784058, 1.4254424571990967, 1.3427116870880127, 1.4270488023757935, 1.3698904514312744, 1.1535810232162476, 1.1015902757644653, 1.002909541130066, 1.0137192010879517, 0.9335951805114746, 0.9651599526405334, 0.8919075727462769, 0.9734624624252319, 0.913180947303772, 0.9858459234237671, 0.9652942419052124, 0.9715678691864014, 0.935330331325531, 0.9476304054260254, 0.942436933517456, 0.9927446246147156, 0.9461447596549988, 0.9556261301040649, 1.0034985542297363, 0.9683266282081604, 0.9758778214454651, 0.9610919952392578, 0.9521140456199646, 0.976316511631012, 0.9854989051818848, 0.9786694049835205, 1.001517415046692, 1.000895619392395, 0.9821282625198364, 0.9851545095443726, 0.9967427849769592, 1.0297948122024536, 0.9792640805244446, 1.010011911392212, 0.9995467066764832, 1.0643976926803589, 1.0242598056793213, 0.9948633909225464, 1.0530253648757935, 0.9979509711265564, 1.0424199104309082, 1.0270791053771973, 1.084041953086853, 1.0238783359527588, 1.0222761631011963, 1.0581393241882324, 1.1324492692947388, 1.0136182308197021, 1.0296460390090942, 1.0823324918746948, 1.0801331996917725, 1.0918480157852173, 1.1010956764221191, 1.0427058935165405, 1.0382142066955566, 1.0588568449020386, 1.0436508655548096, 1.0598230361938477, 1.0424987077713013, 1.0558308362960815, 1.169106364250183, 1.0617793798446655, 1.0504595041275024, 1.2749899625778198, 1.0703125, 1.0553841590881348, 1.0737618207931519, 1.0659501552581787, 1.083564281463623, 1.069226861000061, 1.104697346687317, 1.1751160621643066, 1.1218303442001343, 1.1468870639801025, 1.1186803579330444, 1.188779354095459, 1.079972267150879, 1.0957775115966797, 1.1162320375442505], 'val_accuracy': [0.506465494632721, 0.5118534564971924, 0.5409482717514038, 0.5431034564971924, 0.5678879022598267, 0.5549569129943848, 0.579741358757019, 0.600215494632721, 0.5980603694915771, 0.600215494632721, 0.600215494632721, 0.6056034564971924, 0.59375, 0.587284505367279, 0.587284505367279, 0.6228448152542114, 0.6153017282485962, 0.6605603694915771, 0.6713362336158752, 0.6745689511299133, 0.6907327771186829, 0.7381465435028076, 0.7489224076271057, 0.7715517282485962, 0.7737069129943848, 0.7855603694915771, 0.7887930870056152, 0.795258641242981, 0.7866379022598267, 0.8071120977401733, 0.787715494632721, 0.7963362336158752, 0.798491358757019, 0.8071120977401733, 0.8092672228813171, 0.8092672228813171, 0.7963362336158752, 0.8114224076271057, 0.806034505367279, 0.8006465435028076, 0.8038793206214905, 0.8092672228813171, 0.8114224076271057, 0.8038793206214905, 0.8006465435028076, 0.7995689511299133, 0.8092672228813171, 0.8006465435028076, 0.806034505367279, 0.7941810488700867, 0.8049569129943848, 0.8071120977401733, 0.7995689511299133, 0.7974137663841248, 0.8071120977401733, 0.7920258641242981, 0.7941810488700867, 0.7974137663841248, 0.7995689511299133, 0.7887930870056152, 0.8028017282485962, 0.7941810488700867, 0.8028017282485962, 0.7898706793785095, 0.8049569129943848, 0.8038793206214905, 0.7995689511299133, 0.7543103694915771, 0.7995689511299133, 0.7844827771186829, 0.7909482717514038, 0.795258641242981, 0.7887930870056152, 0.7855603694915771, 0.798491358757019, 0.7909482717514038, 0.795258641242981, 0.7963362336158752, 0.8017241358757019, 0.7963362336158752, 0.7931034564971924, 0.78125, 0.7974137663841248, 0.7931034564971924, 0.764008641242981, 0.767241358757019, 0.7995689511299133, 0.7855603694915771, 0.7974137663841248, 0.7920258641242981, 0.7920258641242981, 0.7941810488700867, 0.78125, 0.7780172228813171, 0.7801724076271057, 0.7887930870056152, 0.7801724076271057, 0.7941810488700867, 0.7941810488700867, 0.7693965435028076]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.4809 - accuracy: 0.9318"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 4s 36ms/step - loss: 0.4763 - accuracy: 0.9341 - val_loss: 1.0192 - val_accuracy: 0.5170\n","Epoch 2/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3852 - accuracy: 0.9663 - val_loss: 0.9971 - val_accuracy: 0.5486\n","Epoch 3/100\n","28/28 [==============================] - 1s 39ms/step - loss: 0.3731 - accuracy: 0.9751 - val_loss: 1.0053 - val_accuracy: 0.5509\n","Epoch 4/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3700 - accuracy: 0.9762 - val_loss: 1.0034 - val_accuracy: 0.5679\n","Epoch 5/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3558 - accuracy: 0.9825 - val_loss: 1.0295 - val_accuracy: 0.5611\n","Epoch 6/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.3531 - accuracy: 0.9844 - val_loss: 1.0280 - val_accuracy: 0.5713\n","Epoch 7/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.3510 - accuracy: 0.9861 - val_loss: 1.0445 - val_accuracy: 0.5747\n","Epoch 8/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.3475 - accuracy: 0.9856 - val_loss: 1.0326 - val_accuracy: 0.5973\n","Epoch 9/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3431 - accuracy: 0.9873 - val_loss: 1.0830 - val_accuracy: 0.5928\n","Epoch 10/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3413 - accuracy: 0.9892 - val_loss: 1.1367 - val_accuracy: 0.5905\n","Epoch 11/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3390 - accuracy: 0.9904 - val_loss: 1.2307 - val_accuracy: 0.5792\n","Epoch 12/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3443 - accuracy: 0.9884 - val_loss: 1.1883 - val_accuracy: 0.6018\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3344 - accuracy: 0.9929 - val_loss: 1.3451 - val_accuracy: 0.5882\n","Epoch 14/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3317 - accuracy: 0.9938 - val_loss: 1.3137 - val_accuracy: 0.6109\n","Epoch 15/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3318 - accuracy: 0.9921 - val_loss: 1.4319 - val_accuracy: 0.6029\n","Epoch 16/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3308 - accuracy: 0.9941 - val_loss: 1.4044 - val_accuracy: 0.6176\n","Epoch 17/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3288 - accuracy: 0.9955 - val_loss: 1.6085 - val_accuracy: 0.6075\n","Epoch 18/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3252 - accuracy: 0.9949 - val_loss: 1.5282 - val_accuracy: 0.6312\n","Epoch 19/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3296 - accuracy: 0.9938 - val_loss: 1.6552 - val_accuracy: 0.6301\n","Epoch 20/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3216 - accuracy: 0.9963 - val_loss: 1.5126 - val_accuracy: 0.6538\n","Epoch 21/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3193 - accuracy: 0.9966 - val_loss: 1.4081 - val_accuracy: 0.6742\n","Epoch 22/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3250 - accuracy: 0.9958 - val_loss: 1.4602 - val_accuracy: 0.6833\n","Epoch 23/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3193 - accuracy: 0.9980 - val_loss: 1.2584 - val_accuracy: 0.7183\n","Epoch 24/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3202 - accuracy: 0.9958 - val_loss: 1.2676 - val_accuracy: 0.7308\n","Epoch 25/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3166 - accuracy: 0.9992 - val_loss: 1.0727 - val_accuracy: 0.7545\n","Epoch 26/100\n","28/28 [==============================] - 3s 111ms/step - loss: 0.3170 - accuracy: 0.9980 - val_loss: 1.0311 - val_accuracy: 0.7613\n","Epoch 27/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3142 - accuracy: 0.9986 - val_loss: 0.9984 - val_accuracy: 0.7636\n","Epoch 28/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3126 - accuracy: 0.9983 - val_loss: 0.9798 - val_accuracy: 0.7760\n","Epoch 29/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3154 - accuracy: 0.9980 - val_loss: 0.9822 - val_accuracy: 0.7738\n","Epoch 30/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3165 - accuracy: 0.9980 - val_loss: 0.9937 - val_accuracy: 0.7771\n","Epoch 31/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3150 - accuracy: 0.9972 - val_loss: 0.9503 - val_accuracy: 0.7783\n","Epoch 32/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3140 - accuracy: 0.9983 - val_loss: 0.9974 - val_accuracy: 0.7794\n","Epoch 33/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3115 - accuracy: 0.9969 - val_loss: 0.9511 - val_accuracy: 0.7885\n","Epoch 34/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3142 - accuracy: 0.9969 - val_loss: 1.0026 - val_accuracy: 0.7805\n","Epoch 35/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3127 - accuracy: 0.9972 - val_loss: 1.0143 - val_accuracy: 0.7885\n","Epoch 36/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3154 - accuracy: 0.9972 - val_loss: 0.9584 - val_accuracy: 0.7919\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3168 - accuracy: 0.9960 - val_loss: 0.9552 - val_accuracy: 0.7817\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3093 - accuracy: 0.9977 - val_loss: 0.9706 - val_accuracy: 0.7839\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3062 - accuracy: 0.9992 - val_loss: 0.9740 - val_accuracy: 0.7919\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3067 - accuracy: 0.9980 - val_loss: 0.9687 - val_accuracy: 0.7828\n","Epoch 41/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3038 - accuracy: 0.9992 - val_loss: 0.9783 - val_accuracy: 0.7839\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3039 - accuracy: 0.9989 - val_loss: 1.0031 - val_accuracy: 0.7862\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3052 - accuracy: 0.9986 - val_loss: 0.9843 - val_accuracy: 0.7873\n","Epoch 44/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3030 - accuracy: 0.9986 - val_loss: 1.0595 - val_accuracy: 0.7839\n","Epoch 45/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3097 - accuracy: 0.9969 - val_loss: 1.1208 - val_accuracy: 0.7794\n","Epoch 46/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3524 - accuracy: 0.9765 - val_loss: 0.9970 - val_accuracy: 0.7885\n","Epoch 47/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3094 - accuracy: 0.9963 - val_loss: 0.9958 - val_accuracy: 0.7828\n","Epoch 48/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3028 - accuracy: 0.9980 - val_loss: 1.0244 - val_accuracy: 0.7862\n","Epoch 49/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3057 - accuracy: 0.9977 - val_loss: 1.0466 - val_accuracy: 0.7805\n","Epoch 50/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3031 - accuracy: 0.9975 - val_loss: 1.0019 - val_accuracy: 0.7805\n","Epoch 51/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3003 - accuracy: 0.9989 - val_loss: 1.0093 - val_accuracy: 0.7805\n","Epoch 52/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2985 - accuracy: 0.9989 - val_loss: 1.0088 - val_accuracy: 0.7828\n","Epoch 53/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2978 - accuracy: 0.9986 - val_loss: 1.0017 - val_accuracy: 0.7839\n","Epoch 54/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2975 - accuracy: 0.9989 - val_loss: 1.0107 - val_accuracy: 0.7794\n","Epoch 55/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2964 - accuracy: 0.9992 - val_loss: 1.0509 - val_accuracy: 0.7749\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2976 - accuracy: 0.9983 - val_loss: 1.0097 - val_accuracy: 0.7817\n","Epoch 57/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2983 - accuracy: 0.9986 - val_loss: 1.0268 - val_accuracy: 0.7783\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2985 - accuracy: 0.9992 - val_loss: 1.0422 - val_accuracy: 0.7896\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2988 - accuracy: 0.9980 - val_loss: 1.0185 - val_accuracy: 0.7771\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2959 - accuracy: 0.9992 - val_loss: 1.0309 - val_accuracy: 0.7760\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2977 - accuracy: 0.9983 - val_loss: 1.0485 - val_accuracy: 0.7760\n","Epoch 62/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2956 - accuracy: 0.9986 - val_loss: 1.0760 - val_accuracy: 0.7805\n","Epoch 63/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2957 - accuracy: 0.9983 - val_loss: 1.0255 - val_accuracy: 0.7851\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2957 - accuracy: 0.9986 - val_loss: 1.0803 - val_accuracy: 0.7805\n","Epoch 65/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2950 - accuracy: 0.9986 - val_loss: 1.0345 - val_accuracy: 0.7805\n","Epoch 66/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2937 - accuracy: 0.9992 - val_loss: 1.0352 - val_accuracy: 0.7839\n","Epoch 67/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2926 - accuracy: 0.9983 - val_loss: 1.0306 - val_accuracy: 0.7839\n","Epoch 68/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2925 - accuracy: 0.9986 - val_loss: 1.0933 - val_accuracy: 0.7805\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2941 - accuracy: 0.9980 - val_loss: 1.0622 - val_accuracy: 0.7704\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2946 - accuracy: 0.9989 - val_loss: 1.1010 - val_accuracy: 0.7805\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2935 - accuracy: 0.9989 - val_loss: 1.0541 - val_accuracy: 0.7783\n","Epoch 72/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2912 - accuracy: 0.9992 - val_loss: 1.0461 - val_accuracy: 0.7738\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2897 - accuracy: 0.9992 - val_loss: 1.0545 - val_accuracy: 0.7817\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2894 - accuracy: 0.9989 - val_loss: 1.0759 - val_accuracy: 0.7794\n","Epoch 75/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2917 - accuracy: 0.9992 - val_loss: 1.0710 - val_accuracy: 0.7783\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2899 - accuracy: 0.9989 - val_loss: 1.1591 - val_accuracy: 0.7817\n","Epoch 77/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2939 - accuracy: 0.9980 - val_loss: 1.0583 - val_accuracy: 0.7749\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2932 - accuracy: 0.9986 - val_loss: 1.0639 - val_accuracy: 0.7760\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2892 - accuracy: 0.9989 - val_loss: 1.0708 - val_accuracy: 0.7760\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2882 - accuracy: 0.9983 - val_loss: 1.0730 - val_accuracy: 0.7749\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2889 - accuracy: 0.9986 - val_loss: 1.0946 - val_accuracy: 0.7749\n","Epoch 82/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2870 - accuracy: 0.9989 - val_loss: 1.1035 - val_accuracy: 0.7726\n","Epoch 83/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2860 - accuracy: 0.9994 - val_loss: 1.1227 - val_accuracy: 0.7817\n","Epoch 84/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2859 - accuracy: 0.9994 - val_loss: 1.0792 - val_accuracy: 0.7794\n","Epoch 85/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2857 - accuracy: 0.9986 - val_loss: 1.0792 - val_accuracy: 0.7805\n","Epoch 86/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2857 - accuracy: 0.9989 - val_loss: 1.1015 - val_accuracy: 0.7760\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2904 - accuracy: 0.9977 - val_loss: 1.1276 - val_accuracy: 0.7692\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2877 - accuracy: 0.9986 - val_loss: 1.1393 - val_accuracy: 0.7715\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2913 - accuracy: 0.9983 - val_loss: 1.0970 - val_accuracy: 0.7783\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2884 - accuracy: 0.9986 - val_loss: 1.0952 - val_accuracy: 0.7704\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2921 - accuracy: 0.9977 - val_loss: 1.0758 - val_accuracy: 0.7760\n","Epoch 92/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2847 - accuracy: 0.9980 - val_loss: 1.0768 - val_accuracy: 0.7760\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2831 - accuracy: 0.9992 - val_loss: 1.1201 - val_accuracy: 0.7817\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2814 - accuracy: 0.9994 - val_loss: 1.1114 - val_accuracy: 0.7771\n","Epoch 95/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2814 - accuracy: 0.9992 - val_loss: 1.0911 - val_accuracy: 0.7760\n","Epoch 96/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2811 - accuracy: 0.9994 - val_loss: 1.1037 - val_accuracy: 0.7749\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2804 - accuracy: 0.9989 - val_loss: 1.0967 - val_accuracy: 0.7783\n","Epoch 98/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2813 - accuracy: 0.9986 - val_loss: 1.1056 - val_accuracy: 0.7760\n","Epoch 99/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2815 - accuracy: 0.9994 - val_loss: 1.1380 - val_accuracy: 0.7738\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2790 - accuracy: 0.9992 - val_loss: 1.1120 - val_accuracy: 0.7805\n","{'loss': [0.4762918949127197, 0.38515183329582214, 0.3731198310852051, 0.36995670199394226, 0.3557848334312439, 0.3530602753162384, 0.3509519100189209, 0.3475009500980377, 0.3430858552455902, 0.34133729338645935, 0.3390120267868042, 0.3442806601524353, 0.3343880772590637, 0.3317013084888458, 0.33179420232772827, 0.3307933509349823, 0.3288029730319977, 0.32522767782211304, 0.3296329975128174, 0.32157236337661743, 0.31932008266448975, 0.3249952495098114, 0.31934744119644165, 0.32019612193107605, 0.3165927529335022, 0.31698253750801086, 0.31417518854141235, 0.312580406665802, 0.31540802121162415, 0.3165382742881775, 0.31504514813423157, 0.31396397948265076, 0.3115295469760895, 0.3141860067844391, 0.312688946723938, 0.31542932987213135, 0.31680312752723694, 0.3093407452106476, 0.306245356798172, 0.30672743916511536, 0.30375608801841736, 0.3038533627986908, 0.3052370846271515, 0.3030007481575012, 0.30967092514038086, 0.35237377882003784, 0.3093850910663605, 0.3028270900249481, 0.30569982528686523, 0.30305516719818115, 0.3003422021865845, 0.2985377609729767, 0.2978260815143585, 0.29750335216522217, 0.2964380085468292, 0.2975650727748871, 0.2983454465866089, 0.2985057830810547, 0.29880380630493164, 0.29589641094207764, 0.2977091372013092, 0.2955573797225952, 0.2956571578979492, 0.2957170307636261, 0.2950204908847809, 0.29366442561149597, 0.2926058769226074, 0.292538046836853, 0.2940838634967804, 0.2945702075958252, 0.2934909462928772, 0.29124200344085693, 0.289692759513855, 0.2893618941307068, 0.2917097508907318, 0.28988611698150635, 0.2938912510871887, 0.29323551058769226, 0.2892206013202667, 0.2882072627544403, 0.2888741195201874, 0.2869771718978882, 0.28602057695388794, 0.285909503698349, 0.2856632471084595, 0.28569331765174866, 0.2904459536075592, 0.28772199153900146, 0.29125723242759705, 0.28838130831718445, 0.2920946776866913, 0.2847352623939514, 0.2831322252750397, 0.281400203704834, 0.28140097856521606, 0.28107425570487976, 0.2803623080253601, 0.28131499886512756, 0.28150877356529236, 0.27899065613746643], 'accuracy': [0.934069037437439, 0.9663271307945251, 0.9750990271568298, 0.9762309193611145, 0.9824561476707458, 0.9844368696212769, 0.9861347079277039, 0.9855687618255615, 0.9872665405273438, 0.9892473220825195, 0.9903791546821594, 0.9883984327316284, 0.9929258823394775, 0.9937747716903687, 0.9920769929885864, 0.9940577149391174, 0.9954725503921509, 0.9949066042900085, 0.9937747716903687, 0.996321439743042, 0.9966044425964355, 0.9957554936408997, 0.9980192184448242, 0.9957554936408997, 0.9991511106491089, 0.9980192184448242, 0.9985851645469666, 0.9983022212982178, 0.9980192184448242, 0.9980192184448242, 0.9971703290939331, 0.9983022212982178, 0.9968873858451843, 0.9968873858451843, 0.9971703290939331, 0.9971703290939331, 0.9960384964942932, 0.9977362751960754, 0.9991511106491089, 0.9980192184448242, 0.9991511106491089, 0.9988681674003601, 0.9985851645469666, 0.9985851645469666, 0.9968873858451843, 0.9765138626098633, 0.996321439743042, 0.9980192184448242, 0.9977362751960754, 0.9974533319473267, 0.9988681674003601, 0.9988681674003601, 0.9985851645469666, 0.9988681674003601, 0.9991511106491089, 0.9983022212982178, 0.9985851645469666, 0.9991511106491089, 0.9980192184448242, 0.9991511106491089, 0.9983022212982178, 0.9985851645469666, 0.9983022212982178, 0.9985851645469666, 0.9985851645469666, 0.9991511106491089, 0.9983022212982178, 0.9985851645469666, 0.9980192184448242, 0.9988681674003601, 0.9988681674003601, 0.9991511106491089, 0.9991511106491089, 0.9988681674003601, 0.9991511106491089, 0.9988681674003601, 0.9980192184448242, 0.9985851645469666, 0.9988681674003601, 0.9983022212982178, 0.9985851645469666, 0.9988681674003601, 0.9994340538978577, 0.9994340538978577, 0.9985851645469666, 0.9988681674003601, 0.9977362751960754, 0.9985851645469666, 0.9983022212982178, 0.9985851645469666, 0.9977362751960754, 0.9980192184448242, 0.9991511106491089, 0.9994340538978577, 0.9991511106491089, 0.9994340538978577, 0.9988681674003601, 0.9985851645469666, 0.9994340538978577, 0.9991511106491089], 'val_loss': [1.0191534757614136, 0.9971317648887634, 1.0053236484527588, 1.0034375190734863, 1.029464602470398, 1.0280187129974365, 1.044521689414978, 1.0325837135314941, 1.0829904079437256, 1.1367344856262207, 1.2306721210479736, 1.1883196830749512, 1.3450778722763062, 1.3137096166610718, 1.4318833351135254, 1.4043999910354614, 1.6085110902786255, 1.5282306671142578, 1.6551976203918457, 1.5125735998153687, 1.4080890417099, 1.4602004289627075, 1.258360743522644, 1.2675784826278687, 1.0726507902145386, 1.0310989618301392, 0.9983676075935364, 0.9797886610031128, 0.9822490811347961, 0.9937325119972229, 0.9503352642059326, 0.9974438548088074, 0.9510856866836548, 1.0026304721832275, 1.0142802000045776, 0.9584395885467529, 0.9552159309387207, 0.970614492893219, 0.9740310311317444, 0.9687354564666748, 0.9783018827438354, 1.003145694732666, 0.9842597842216492, 1.0595107078552246, 1.1208316087722778, 0.9970446825027466, 0.995751678943634, 1.0243810415267944, 1.0466431379318237, 1.0019445419311523, 1.0093094110488892, 1.0088067054748535, 1.0017367601394653, 1.0107275247573853, 1.0508579015731812, 1.0097143650054932, 1.0267541408538818, 1.042197346687317, 1.0185173749923706, 1.0308812856674194, 1.0485079288482666, 1.075982689857483, 1.0254592895507812, 1.080336332321167, 1.0345046520233154, 1.0352097749710083, 1.030572772026062, 1.0933210849761963, 1.062208652496338, 1.100995421409607, 1.0540578365325928, 1.046077847480774, 1.0544613599777222, 1.0759013891220093, 1.0710480213165283, 1.1590980291366577, 1.058320164680481, 1.063895583152771, 1.0708338022232056, 1.072985291481018, 1.0946383476257324, 1.103532314300537, 1.1227459907531738, 1.0791916847229004, 1.079237699508667, 1.1014528274536133, 1.1275955438613892, 1.139336347579956, 1.096983551979065, 1.095238447189331, 1.0758252143859863, 1.0767980813980103, 1.1201378107070923, 1.111436367034912, 1.0911263227462769, 1.1037300825119019, 1.0967249870300293, 1.1056016683578491, 1.1380447149276733, 1.1120100021362305], 'val_accuracy': [0.516968309879303, 0.5486425161361694, 0.5509049892425537, 0.5678732991218567, 0.5610859990119934, 0.5712669491767883, 0.5746606588363647, 0.5972850918769836, 0.5927602052688599, 0.5904977321624756, 0.5791855454444885, 0.6018099784851074, 0.5882353186607361, 0.610859751701355, 0.6029411554336548, 0.6176470518112183, 0.6074660420417786, 0.6312217116355896, 0.6300904750823975, 0.6538461446762085, 0.6742081642150879, 0.6832579374313354, 0.7183257937431335, 0.7307692170143127, 0.7545248866081238, 0.7613122463226318, 0.7635746598243713, 0.7760180830955505, 0.773755669593811, 0.7771493196487427, 0.7782805562019348, 0.779411792755127, 0.7884615659713745, 0.7805429697036743, 0.7884615659713745, 0.7918552160263062, 0.7816742062568665, 0.7839366793632507, 0.7918552160263062, 0.7828054428100586, 0.7839366793632507, 0.7861990928649902, 0.7873303294181824, 0.7839366793632507, 0.779411792755127, 0.7884615659713745, 0.7828054428100586, 0.7861990928649902, 0.7805429697036743, 0.7805429697036743, 0.7805429697036743, 0.7828054428100586, 0.7839366793632507, 0.779411792755127, 0.7748869061470032, 0.7816742062568665, 0.7782805562019348, 0.7895927429199219, 0.7771493196487427, 0.7760180830955505, 0.7760180830955505, 0.7805429697036743, 0.7850678563117981, 0.7805429697036743, 0.7805429697036743, 0.7839366793632507, 0.7839366793632507, 0.7805429697036743, 0.7703620195388794, 0.7805429697036743, 0.7782805562019348, 0.773755669593811, 0.7816742062568665, 0.779411792755127, 0.7782805562019348, 0.7816742062568665, 0.7748869061470032, 0.7760180830955505, 0.7760180830955505, 0.7748869061470032, 0.7748869061470032, 0.7726244330406189, 0.7816742062568665, 0.779411792755127, 0.7805429697036743, 0.7760180830955505, 0.7692307829856873, 0.7714931964874268, 0.7782805562019348, 0.7703620195388794, 0.7760180830955505, 0.7760180830955505, 0.7816742062568665, 0.7771493196487427, 0.7760180830955505, 0.7748869061470032, 0.7782805562019348, 0.7760180830955505, 0.773755669593811, 0.7805429697036743]}\n","45/45 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2621952   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4949569 (18.88 MB)\n","Trainable params: 4949057 (18.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.5173 - accuracy: 0.9170"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 4s 36ms/step - loss: 0.5158 - accuracy: 0.9181 - val_loss: 1.0291 - val_accuracy: 0.5021\n","Epoch 2/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4140 - accuracy: 0.9556 - val_loss: 1.0238 - val_accuracy: 0.5176\n","Epoch 3/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3898 - accuracy: 0.9677 - val_loss: 1.0261 - val_accuracy: 0.5279\n","Epoch 4/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3819 - accuracy: 0.9747 - val_loss: 1.0101 - val_accuracy: 0.5444\n","Epoch 5/100\n","31/31 [==============================] - 5s 155ms/step - loss: 0.3798 - accuracy: 0.9739 - val_loss: 1.0052 - val_accuracy: 0.5692\n","Epoch 6/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.3717 - accuracy: 0.9770 - val_loss: 1.0169 - val_accuracy: 0.5713\n","Epoch 7/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3758 - accuracy: 0.9755 - val_loss: 1.0577 - val_accuracy: 0.5599\n","Epoch 8/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3665 - accuracy: 0.9814 - val_loss: 1.0890 - val_accuracy: 0.5620\n","Epoch 9/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3634 - accuracy: 0.9824 - val_loss: 1.0455 - val_accuracy: 0.5981\n","Epoch 10/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3700 - accuracy: 0.9773 - val_loss: 1.1585 - val_accuracy: 0.5754\n","Epoch 11/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3590 - accuracy: 0.9832 - val_loss: 1.3277 - val_accuracy: 0.5537\n","Epoch 12/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3550 - accuracy: 0.9868 - val_loss: 1.3102 - val_accuracy: 0.5764\n","Epoch 13/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3525 - accuracy: 0.9858 - val_loss: 1.3502 - val_accuracy: 0.5826\n","Epoch 14/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3489 - accuracy: 0.9889 - val_loss: 1.4943 - val_accuracy: 0.5733\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3435 - accuracy: 0.9917 - val_loss: 1.4588 - val_accuracy: 0.5878\n","Epoch 16/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3421 - accuracy: 0.9933 - val_loss: 1.5206 - val_accuracy: 0.5950\n","Epoch 17/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3482 - accuracy: 0.9899 - val_loss: 1.5840 - val_accuracy: 0.6054\n","Epoch 18/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3472 - accuracy: 0.9894 - val_loss: 1.3470 - val_accuracy: 0.6415\n","Epoch 19/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3448 - accuracy: 0.9891 - val_loss: 1.2719 - val_accuracy: 0.6643\n","Epoch 20/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3376 - accuracy: 0.9935 - val_loss: 1.2640 - val_accuracy: 0.6818\n","Epoch 21/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3358 - accuracy: 0.9948 - val_loss: 1.1111 - val_accuracy: 0.7314\n","Epoch 22/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3362 - accuracy: 0.9915 - val_loss: 1.0325 - val_accuracy: 0.7645\n","Epoch 23/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3482 - accuracy: 0.9860 - val_loss: 1.0870 - val_accuracy: 0.7583\n","Epoch 24/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3599 - accuracy: 0.9793 - val_loss: 1.0956 - val_accuracy: 0.7645\n","Epoch 25/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3477 - accuracy: 0.9876 - val_loss: 1.1183 - val_accuracy: 0.7541\n","Epoch 26/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3446 - accuracy: 0.9879 - val_loss: 1.0066 - val_accuracy: 0.7841\n","Epoch 27/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3288 - accuracy: 0.9951 - val_loss: 1.0825 - val_accuracy: 0.7665\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3285 - accuracy: 0.9953 - val_loss: 1.1066 - val_accuracy: 0.7645\n","Epoch 29/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3280 - accuracy: 0.9953 - val_loss: 1.0119 - val_accuracy: 0.7975\n","Epoch 30/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.3245 - accuracy: 0.9966 - val_loss: 1.0121 - val_accuracy: 0.7986\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3252 - accuracy: 0.9959 - val_loss: 1.0141 - val_accuracy: 0.7944\n","Epoch 32/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3234 - accuracy: 0.9972 - val_loss: 1.0834 - val_accuracy: 0.7831\n","Epoch 33/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3262 - accuracy: 0.9959 - val_loss: 1.0277 - val_accuracy: 0.8006\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3197 - accuracy: 0.9974 - val_loss: 1.0294 - val_accuracy: 0.7986\n","Epoch 35/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3202 - accuracy: 0.9982 - val_loss: 1.0742 - val_accuracy: 0.7851\n","Epoch 36/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3278 - accuracy: 0.9948 - val_loss: 1.0475 - val_accuracy: 0.7903\n","Epoch 37/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3190 - accuracy: 0.9977 - val_loss: 1.0534 - val_accuracy: 0.7882\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3175 - accuracy: 0.9977 - val_loss: 1.0506 - val_accuracy: 0.7924\n","Epoch 39/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3180 - accuracy: 0.9984 - val_loss: 1.0624 - val_accuracy: 0.7872\n","Epoch 40/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3215 - accuracy: 0.9972 - val_loss: 1.0564 - val_accuracy: 0.7955\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3169 - accuracy: 0.9982 - val_loss: 1.0573 - val_accuracy: 0.7872\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3170 - accuracy: 0.9982 - val_loss: 1.0590 - val_accuracy: 0.7955\n","Epoch 43/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3138 - accuracy: 0.9979 - val_loss: 1.0550 - val_accuracy: 0.7934\n","Epoch 44/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3123 - accuracy: 0.9979 - val_loss: 1.0678 - val_accuracy: 0.7924\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3136 - accuracy: 0.9979 - val_loss: 1.0920 - val_accuracy: 0.7862\n","Epoch 46/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3135 - accuracy: 0.9987 - val_loss: 1.0740 - val_accuracy: 0.7769\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3129 - accuracy: 0.9977 - val_loss: 1.0820 - val_accuracy: 0.7893\n","Epoch 48/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3112 - accuracy: 0.9979 - val_loss: 1.0912 - val_accuracy: 0.7872\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3172 - accuracy: 0.9959 - val_loss: 1.1245 - val_accuracy: 0.7748\n","Epoch 50/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3197 - accuracy: 0.9951 - val_loss: 1.0861 - val_accuracy: 0.7882\n","Epoch 51/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3171 - accuracy: 0.9972 - val_loss: 1.0795 - val_accuracy: 0.7913\n","Epoch 52/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3104 - accuracy: 0.9984 - val_loss: 1.1004 - val_accuracy: 0.7820\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3088 - accuracy: 0.9979 - val_loss: 1.0976 - val_accuracy: 0.7851\n","Epoch 54/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3121 - accuracy: 0.9977 - val_loss: 1.0881 - val_accuracy: 0.7913\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3071 - accuracy: 0.9982 - val_loss: 1.0906 - val_accuracy: 0.7882\n","Epoch 56/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3107 - accuracy: 0.9977 - val_loss: 1.1050 - val_accuracy: 0.7872\n","Epoch 57/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3112 - accuracy: 0.9979 - val_loss: 1.1754 - val_accuracy: 0.7676\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3076 - accuracy: 0.9974 - val_loss: 1.1223 - val_accuracy: 0.7831\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3053 - accuracy: 0.9982 - val_loss: 1.1202 - val_accuracy: 0.7800\n","Epoch 60/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3038 - accuracy: 0.9987 - val_loss: 1.1098 - val_accuracy: 0.7862\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3049 - accuracy: 0.9982 - val_loss: 1.1487 - val_accuracy: 0.7686\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3046 - accuracy: 0.9982 - val_loss: 1.1121 - val_accuracy: 0.7831\n","Epoch 63/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3021 - accuracy: 0.9990 - val_loss: 1.1153 - val_accuracy: 0.7831\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3011 - accuracy: 0.9984 - val_loss: 1.1226 - val_accuracy: 0.7831\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3006 - accuracy: 0.9987 - val_loss: 1.1267 - val_accuracy: 0.7872\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3026 - accuracy: 0.9990 - val_loss: 1.1427 - val_accuracy: 0.7758\n","Epoch 67/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3043 - accuracy: 0.9974 - val_loss: 1.1315 - val_accuracy: 0.7820\n","Epoch 68/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3038 - accuracy: 0.9982 - val_loss: 1.1425 - val_accuracy: 0.7831\n","Epoch 69/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3001 - accuracy: 0.9990 - val_loss: 1.1295 - val_accuracy: 0.7810\n","Epoch 70/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2997 - accuracy: 0.9987 - val_loss: 1.1373 - val_accuracy: 0.7686\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2986 - accuracy: 0.9982 - val_loss: 1.1732 - val_accuracy: 0.7779\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3002 - accuracy: 0.9987 - val_loss: 1.1308 - val_accuracy: 0.7831\n","Epoch 73/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2962 - accuracy: 0.9990 - val_loss: 1.1727 - val_accuracy: 0.7779\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2993 - accuracy: 0.9990 - val_loss: 1.1500 - val_accuracy: 0.7789\n","Epoch 75/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2994 - accuracy: 0.9979 - val_loss: 1.1452 - val_accuracy: 0.7800\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2963 - accuracy: 0.9987 - val_loss: 1.1399 - val_accuracy: 0.7851\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2951 - accuracy: 0.9990 - val_loss: 1.1485 - val_accuracy: 0.7789\n","Epoch 78/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2977 - accuracy: 0.9979 - val_loss: 1.1558 - val_accuracy: 0.7810\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2950 - accuracy: 0.9987 - val_loss: 1.1434 - val_accuracy: 0.7831\n","Epoch 80/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2956 - accuracy: 0.9984 - val_loss: 1.1849 - val_accuracy: 0.7789\n","Epoch 81/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3035 - accuracy: 0.9961 - val_loss: 1.2183 - val_accuracy: 0.7676\n","Epoch 82/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3073 - accuracy: 0.9953 - val_loss: 1.1628 - val_accuracy: 0.7893\n","Epoch 83/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2985 - accuracy: 0.9974 - val_loss: 1.1553 - val_accuracy: 0.7800\n","Epoch 84/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2918 - accuracy: 0.9990 - val_loss: 1.1581 - val_accuracy: 0.7769\n","Epoch 85/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2951 - accuracy: 0.9990 - val_loss: 1.1832 - val_accuracy: 0.7738\n","Epoch 86/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2929 - accuracy: 0.9987 - val_loss: 1.1937 - val_accuracy: 0.7748\n","Epoch 87/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2890 - accuracy: 0.9990 - val_loss: 1.1855 - val_accuracy: 0.7717\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2881 - accuracy: 0.9992 - val_loss: 1.1699 - val_accuracy: 0.7789\n","Epoch 89/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2923 - accuracy: 0.9979 - val_loss: 1.1822 - val_accuracy: 0.7779\n","Epoch 90/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3030 - accuracy: 0.9961 - val_loss: 1.2237 - val_accuracy: 0.7769\n","Epoch 91/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2924 - accuracy: 0.9977 - val_loss: 1.2636 - val_accuracy: 0.7593\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3065 - accuracy: 0.9935 - val_loss: 1.2027 - val_accuracy: 0.7707\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2914 - accuracy: 0.9984 - val_loss: 1.1734 - val_accuracy: 0.7789\n","Epoch 94/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2863 - accuracy: 0.9990 - val_loss: 1.2120 - val_accuracy: 0.7707\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2867 - accuracy: 0.9987 - val_loss: 1.3212 - val_accuracy: 0.7521\n","Epoch 96/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3059 - accuracy: 0.9925 - val_loss: 1.2036 - val_accuracy: 0.7634\n","Epoch 97/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2896 - accuracy: 0.9982 - val_loss: 1.1979 - val_accuracy: 0.7738\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2855 - accuracy: 0.9992 - val_loss: 1.1945 - val_accuracy: 0.7748\n","Epoch 99/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2846 - accuracy: 0.9992 - val_loss: 1.2313 - val_accuracy: 0.7634\n","Epoch 100/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2847 - accuracy: 0.9992 - val_loss: 1.1982 - val_accuracy: 0.7707\n","{'loss': [0.5158180594444275, 0.41402721405029297, 0.3897673487663269, 0.3819093108177185, 0.37978625297546387, 0.37173551321029663, 0.37581607699394226, 0.36649295687675476, 0.3634340167045593, 0.37003523111343384, 0.35903722047805786, 0.35501888394355774, 0.35245272517204285, 0.3489235043525696, 0.34346479177474976, 0.34209877252578735, 0.34822019934654236, 0.34724658727645874, 0.3448221981525421, 0.3376230299472809, 0.33578425645828247, 0.3361828327178955, 0.3482462763786316, 0.3599383533000946, 0.3477252721786499, 0.3445814549922943, 0.3287501037120819, 0.3284517228603363, 0.3280329704284668, 0.3245347738265991, 0.32521161437034607, 0.32341253757476807, 0.32615798711776733, 0.3197200894355774, 0.3201538622379303, 0.327774316072464, 0.3189966678619385, 0.3175327181816101, 0.3179735243320465, 0.32150471210479736, 0.3168676793575287, 0.3169918358325958, 0.31376755237579346, 0.31234997510910034, 0.31356725096702576, 0.3135361075401306, 0.3129352331161499, 0.31118878722190857, 0.31717684864997864, 0.31968772411346436, 0.31712013483047485, 0.3103533089160919, 0.3087983727455139, 0.3121383488178253, 0.3070935904979706, 0.3107089102268219, 0.3111671507358551, 0.30760762095451355, 0.30534201860427856, 0.303806334733963, 0.30488333106040955, 0.3045594394207001, 0.30205291509628296, 0.3010950982570648, 0.30062979459762573, 0.3025559186935425, 0.30433109402656555, 0.3037978708744049, 0.3000522553920746, 0.29970020055770874, 0.2986396253108978, 0.30024299025535583, 0.2961564064025879, 0.29927048087120056, 0.29941603541374207, 0.2962736487388611, 0.2950659990310669, 0.29773882031440735, 0.29504862427711487, 0.2956116795539856, 0.30348095297813416, 0.3073478937149048, 0.29848355054855347, 0.2918245792388916, 0.2950846552848816, 0.2928859293460846, 0.2889821231365204, 0.288143515586853, 0.2922549247741699, 0.3029555082321167, 0.2924235761165619, 0.30654725432395935, 0.29142042994499207, 0.28632745146751404, 0.28669875860214233, 0.30591148138046265, 0.2895723879337311, 0.2855185568332672, 0.28460898995399475, 0.2847267985343933], 'accuracy': [0.9180878400802612, 0.9555555582046509, 0.9677002429962158, 0.9746770262718201, 0.9739018082618713, 0.9770025610923767, 0.975452184677124, 0.9813953638076782, 0.9824289679527283, 0.9772610068321228, 0.9832041263580322, 0.986821711063385, 0.985788106918335, 0.9888888597488403, 0.9917312860488892, 0.9932816624641418, 0.9899224638938904, 0.9894056916236877, 0.9891473054885864, 0.9935400485992432, 0.9948320388793945, 0.9914728403091431, 0.9860464930534363, 0.9793281555175781, 0.987596869468689, 0.9878553152084351, 0.9950904250144958, 0.9953488111495972, 0.9953488111495972, 0.9966408014297485, 0.9958656430244446, 0.997157633304596, 0.9958656430244446, 0.9974160194396973, 0.998191237449646, 0.9948320388793945, 0.9976744055747986, 0.9976744055747986, 0.9984496235847473, 0.997157633304596, 0.998191237449646, 0.998191237449646, 0.9979327917098999, 0.9979327917098999, 0.9979327917098999, 0.9987080097198486, 0.9976744055747986, 0.9979327917098999, 0.9958656430244446, 0.9950904250144958, 0.997157633304596, 0.9984496235847473, 0.9979327917098999, 0.9976744055747986, 0.998191237449646, 0.9976744055747986, 0.9979327917098999, 0.9974160194396973, 0.998191237449646, 0.9987080097198486, 0.998191237449646, 0.998191237449646, 0.99896639585495, 0.9984496235847473, 0.9987080097198486, 0.99896639585495, 0.9974160194396973, 0.998191237449646, 0.99896639585495, 0.9987080097198486, 0.998191237449646, 0.9987080097198486, 0.99896639585495, 0.99896639585495, 0.9979327917098999, 0.9987080097198486, 0.99896639585495, 0.9979327917098999, 0.9987080097198486, 0.9984496235847473, 0.9961240291595459, 0.9953488111495972, 0.9974160194396973, 0.99896639585495, 0.99896639585495, 0.9987080097198486, 0.99896639585495, 0.9992247819900513, 0.9979327917098999, 0.9961240291595459, 0.9976744055747986, 0.9935400485992432, 0.9984496235847473, 0.99896639585495, 0.9987080097198486, 0.9925064444541931, 0.998191237449646, 0.9992247819900513, 0.9992247819900513, 0.9992247819900513], 'val_loss': [1.0290895700454712, 1.0237891674041748, 1.026082992553711, 1.0100833177566528, 1.0051997900009155, 1.0168887376785278, 1.057690978050232, 1.0890088081359863, 1.0454862117767334, 1.158481240272522, 1.3277065753936768, 1.3102413415908813, 1.3502216339111328, 1.4943456649780273, 1.4587514400482178, 1.5206129550933838, 1.5840367078781128, 1.3470090627670288, 1.2718600034713745, 1.2640306949615479, 1.1110838651657104, 1.0324654579162598, 1.0870243310928345, 1.0955731868743896, 1.1183215379714966, 1.0065866708755493, 1.082521915435791, 1.1065905094146729, 1.0119494199752808, 1.0121222734451294, 1.014147162437439, 1.0834156274795532, 1.027661681175232, 1.0294431447982788, 1.0741972923278809, 1.047472357749939, 1.0534297227859497, 1.0505527257919312, 1.0624221563339233, 1.0564430952072144, 1.057267665863037, 1.0589505434036255, 1.0550047159194946, 1.0677682161331177, 1.0920308828353882, 1.0739705562591553, 1.0820430517196655, 1.0912137031555176, 1.1245061159133911, 1.0860731601715088, 1.079512119293213, 1.1003862619400024, 1.0976210832595825, 1.0880906581878662, 1.0905985832214355, 1.1049598455429077, 1.1754482984542847, 1.1223393678665161, 1.1201512813568115, 1.1098421812057495, 1.1487070322036743, 1.112076759338379, 1.1152925491333008, 1.122560977935791, 1.1267234086990356, 1.1426540613174438, 1.131486177444458, 1.1425034999847412, 1.1294867992401123, 1.1373326778411865, 1.173209547996521, 1.130840539932251, 1.1726685762405396, 1.1499956846237183, 1.1452436447143555, 1.1398876905441284, 1.1485072374343872, 1.15581476688385, 1.1433665752410889, 1.1849133968353271, 1.2183196544647217, 1.1628485918045044, 1.1553336381912231, 1.1580979824066162, 1.1832348108291626, 1.1936837434768677, 1.185487151145935, 1.1698511838912964, 1.1821907758712769, 1.2237052917480469, 1.2635725736618042, 1.2026773691177368, 1.1733660697937012, 1.2120015621185303, 1.3211607933044434, 1.2036250829696655, 1.1978543996810913, 1.1944698095321655, 1.2312744855880737, 1.1982051134109497], 'val_accuracy': [0.5020661354064941, 0.5175619721412659, 0.5278925895690918, 0.5444214940071106, 0.5692148804664612, 0.5712810158729553, 0.5599173307418823, 0.5619834661483765, 0.5981404781341553, 0.5754132270812988, 0.5537189841270447, 0.5764462947845459, 0.5826446413993835, 0.5733470916748047, 0.5878099203109741, 0.5950413346290588, 0.60537189245224, 0.6415289044380188, 0.66425621509552, 0.6818181872367859, 0.7314049601554871, 0.7644628286361694, 0.7582644820213318, 0.7644628286361694, 0.7541322112083435, 0.7840909361839294, 0.7665289044380188, 0.7644628286361694, 0.797520637512207, 0.7985537052154541, 0.7944214940071106, 0.7830578684806824, 0.8006198406219482, 0.7985537052154541, 0.7851239442825317, 0.7902892827987671, 0.788223147392273, 0.7923553586006165, 0.7871900796890259, 0.7954545617103577, 0.7871900796890259, 0.7954545617103577, 0.7933884263038635, 0.7923553586006165, 0.7861570119857788, 0.7768595218658447, 0.78925621509552, 0.7871900796890259, 0.7747933864593506, 0.788223147392273, 0.7913222908973694, 0.7820248007774353, 0.7851239442825317, 0.7913222908973694, 0.788223147392273, 0.7871900796890259, 0.7675619721412659, 0.7830578684806824, 0.7799586653709412, 0.7861570119857788, 0.7685950398445129, 0.7830578684806824, 0.7830578684806824, 0.7830578684806824, 0.7871900796890259, 0.7758264541625977, 0.7820248007774353, 0.7830578684806824, 0.7809917330741882, 0.7685950398445129, 0.7778925895690918, 0.7830578684806824, 0.7778925895690918, 0.7789255976676941, 0.7799586653709412, 0.7851239442825317, 0.7789255976676941, 0.7809917330741882, 0.7830578684806824, 0.7789255976676941, 0.7675619721412659, 0.78925621509552, 0.7799586653709412, 0.7768595218658447, 0.7737603187561035, 0.7747933864593506, 0.7716942429542542, 0.7789255976676941, 0.7778925895690918, 0.7768595218658447, 0.7592975497245789, 0.7706611752510071, 0.7789255976676941, 0.7706611752510071, 0.7520661354064941, 0.7634297609329224, 0.7737603187561035, 0.7747933864593506, 0.7634297609329224, 0.7706611752510071]}\n","32/32 [==============================] - 0s 3ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_CNN.round(3)"],"metadata":{"id":"y3RXIk-qZ7ts","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metrics_df_CNN.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/DWT/CNN/Delta_DWT_CNN.csv', index = False)"],"metadata":{"id":"_iOLsKpkfzdG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# GRU"],"metadata":{"id":"GPlWZUcV48bB"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model_gru(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(GRU(256, return_sequences=True))\n","    model.add(GRU(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning_gru(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model_gru(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model_gru(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Delta/CNN_GRU/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/DWT/Delta/CNN_GRU/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n","\n"],"metadata":{"id":"ieXSN-9PI4Dx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717531595601,"user_tz":-360,"elapsed":778,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"7bfc00db-6dcd-4c7c-b5cc-7945c57cb747"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["global_model_gru, metrics_df_gru = federated_learning_gru(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"lD5S-Pvy5B-r","executionInfo":{"status":"ok","timestamp":1717532947881,"user_tz":-360,"elapsed":1347431,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"19c3eeca-6771-4e81-8318-aecda86b3579"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Train shape: (4640, 52, 29), Test shape: (1194, 52, 29)\n","Train shape: (4418, 52, 29), Test shape: (1416, 52, 29)\n","Train shape: (4838, 52, 29), Test shape: (996, 52, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 1.8175 - accuracy: 0.5040"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 18s 64ms/step - loss: 1.8175 - accuracy: 0.5040 - val_loss: 1.8133 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.8093 - accuracy: 0.5086 - val_loss: 1.8049 - val_accuracy: 0.4860\n","Epoch 3/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.8008 - accuracy: 0.5116 - val_loss: 1.7965 - val_accuracy: 0.5162\n","Epoch 4/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.7922 - accuracy: 0.5148 - val_loss: 1.7881 - val_accuracy: 0.4871\n","Epoch 5/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.7835 - accuracy: 0.5094 - val_loss: 1.7798 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.7749 - accuracy: 0.5213 - val_loss: 1.7713 - val_accuracy: 0.4860\n","Epoch 7/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.7659 - accuracy: 0.5329 - val_loss: 1.7633 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.7575 - accuracy: 0.5377 - val_loss: 1.7550 - val_accuracy: 0.4828\n","Epoch 9/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.7493 - accuracy: 0.5264 - val_loss: 1.7470 - val_accuracy: 0.4849\n","Epoch 10/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.7412 - accuracy: 0.5286 - val_loss: 1.7392 - val_accuracy: 0.4849\n","Epoch 11/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.7324 - accuracy: 0.5358 - val_loss: 1.7304 - val_accuracy: 0.4741\n","Epoch 12/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.7230 - accuracy: 0.5391 - val_loss: 1.7224 - val_accuracy: 0.4709\n","Epoch 13/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.7156 - accuracy: 0.5342 - val_loss: 1.7137 - val_accuracy: 0.4946\n","Epoch 14/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.7061 - accuracy: 0.5539 - val_loss: 1.7066 - val_accuracy: 0.4784\n","Epoch 15/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.6958 - accuracy: 0.5638 - val_loss: 1.6977 - val_accuracy: 0.4763\n","Epoch 16/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.6868 - accuracy: 0.5682 - val_loss: 1.6884 - val_accuracy: 0.4935\n","Epoch 17/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.6760 - accuracy: 0.5676 - val_loss: 1.6831 - val_accuracy: 0.4741\n","Epoch 18/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.6663 - accuracy: 0.5760 - val_loss: 1.6723 - val_accuracy: 0.4892\n","Epoch 19/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.6584 - accuracy: 0.5679 - val_loss: 1.6600 - val_accuracy: 0.5388\n","Epoch 20/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.6481 - accuracy: 0.5789 - val_loss: 1.6495 - val_accuracy: 0.5614\n","Epoch 21/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.6375 - accuracy: 0.5894 - val_loss: 1.6398 - val_accuracy: 0.5700\n","Epoch 22/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.6247 - accuracy: 0.5916 - val_loss: 1.6289 - val_accuracy: 0.5765\n","Epoch 23/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.6149 - accuracy: 0.6032 - val_loss: 1.6190 - val_accuracy: 0.5927\n","Epoch 24/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.6081 - accuracy: 0.5989 - val_loss: 1.6239 - val_accuracy: 0.5496\n","Epoch 25/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.5965 - accuracy: 0.6080 - val_loss: 1.6053 - val_accuracy: 0.5830\n","Epoch 26/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.5901 - accuracy: 0.6043 - val_loss: 1.6093 - val_accuracy: 0.5571\n","Epoch 27/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.5784 - accuracy: 0.6048 - val_loss: 1.5970 - val_accuracy: 0.5754\n","Epoch 28/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.5699 - accuracy: 0.6164 - val_loss: 1.5872 - val_accuracy: 0.5894\n","Epoch 29/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.5631 - accuracy: 0.6175 - val_loss: 1.5756 - val_accuracy: 0.5916\n","Epoch 30/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.5523 - accuracy: 0.6261 - val_loss: 1.5749 - val_accuracy: 0.5862\n","Epoch 31/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.5471 - accuracy: 0.6196 - val_loss: 1.5752 - val_accuracy: 0.5841\n","Epoch 32/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.5390 - accuracy: 0.6253 - val_loss: 1.5566 - val_accuracy: 0.5991\n","Epoch 33/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.5302 - accuracy: 0.6320 - val_loss: 1.5502 - val_accuracy: 0.5981\n","Epoch 34/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.5206 - accuracy: 0.6331 - val_loss: 1.5477 - val_accuracy: 0.5927\n","Epoch 35/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.5131 - accuracy: 0.6342 - val_loss: 1.5435 - val_accuracy: 0.5916\n","Epoch 36/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.5049 - accuracy: 0.6428 - val_loss: 1.5486 - val_accuracy: 0.5862\n","Epoch 37/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.4968 - accuracy: 0.6471 - val_loss: 1.5298 - val_accuracy: 0.6056\n","Epoch 38/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.4919 - accuracy: 0.6447 - val_loss: 1.5192 - val_accuracy: 0.5927\n","Epoch 39/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.4813 - accuracy: 0.6536 - val_loss: 1.5238 - val_accuracy: 0.5927\n","Epoch 40/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4766 - accuracy: 0.6447 - val_loss: 1.5188 - val_accuracy: 0.5927\n","Epoch 41/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.4642 - accuracy: 0.6624 - val_loss: 1.5056 - val_accuracy: 0.6175\n","Epoch 42/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.4601 - accuracy: 0.6522 - val_loss: 1.5004 - val_accuracy: 0.6228\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4545 - accuracy: 0.6573 - val_loss: 1.4936 - val_accuracy: 0.5959\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4433 - accuracy: 0.6649 - val_loss: 1.4880 - val_accuracy: 0.5981\n","Epoch 45/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4374 - accuracy: 0.6635 - val_loss: 1.4841 - val_accuracy: 0.5894\n","Epoch 46/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4297 - accuracy: 0.6633 - val_loss: 1.4814 - val_accuracy: 0.5927\n","Epoch 47/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.4219 - accuracy: 0.6665 - val_loss: 1.4725 - val_accuracy: 0.6056\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4159 - accuracy: 0.6743 - val_loss: 1.4679 - val_accuracy: 0.6110\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4061 - accuracy: 0.6721 - val_loss: 1.4625 - val_accuracy: 0.6121\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4013 - accuracy: 0.6816 - val_loss: 1.4615 - val_accuracy: 0.5927\n","Epoch 51/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.3950 - accuracy: 0.6746 - val_loss: 1.4608 - val_accuracy: 0.5938\n","Epoch 52/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3884 - accuracy: 0.6765 - val_loss: 1.4599 - val_accuracy: 0.5862\n","Epoch 53/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3789 - accuracy: 0.6775 - val_loss: 1.4431 - val_accuracy: 0.6099\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3726 - accuracy: 0.6843 - val_loss: 1.4476 - val_accuracy: 0.5981\n","Epoch 55/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3685 - accuracy: 0.6821 - val_loss: 1.4491 - val_accuracy: 0.5884\n","Epoch 56/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.3685 - accuracy: 0.6732 - val_loss: 1.4378 - val_accuracy: 0.5927\n","Epoch 57/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3514 - accuracy: 0.6956 - val_loss: 1.4251 - val_accuracy: 0.6110\n","Epoch 58/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3508 - accuracy: 0.6883 - val_loss: 1.4276 - val_accuracy: 0.5981\n","Epoch 59/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.3372 - accuracy: 0.6942 - val_loss: 1.4362 - val_accuracy: 0.5873\n","Epoch 60/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.3305 - accuracy: 0.6972 - val_loss: 1.4148 - val_accuracy: 0.6131\n","Epoch 61/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.3265 - accuracy: 0.7002 - val_loss: 1.4113 - val_accuracy: 0.6088\n","Epoch 62/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.3198 - accuracy: 0.6983 - val_loss: 1.4130 - val_accuracy: 0.6024\n","Epoch 63/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.3151 - accuracy: 0.7004 - val_loss: 1.4020 - val_accuracy: 0.6207\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3032 - accuracy: 0.7077 - val_loss: 1.3999 - val_accuracy: 0.6078\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2992 - accuracy: 0.6994 - val_loss: 1.4036 - val_accuracy: 0.6013\n","Epoch 66/100\n","29/29 [==============================] - 2s 59ms/step - loss: 1.2915 - accuracy: 0.7099 - val_loss: 1.3969 - val_accuracy: 0.6239\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2888 - accuracy: 0.7053 - val_loss: 1.4019 - val_accuracy: 0.5948\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2854 - accuracy: 0.7050 - val_loss: 1.3932 - val_accuracy: 0.6002\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2718 - accuracy: 0.7166 - val_loss: 1.3914 - val_accuracy: 0.6088\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2659 - accuracy: 0.7117 - val_loss: 1.3819 - val_accuracy: 0.6056\n","Epoch 71/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.2617 - accuracy: 0.7214 - val_loss: 1.3855 - val_accuracy: 0.5991\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2549 - accuracy: 0.7223 - val_loss: 1.3713 - val_accuracy: 0.6207\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2476 - accuracy: 0.7249 - val_loss: 1.3708 - val_accuracy: 0.6024\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2417 - accuracy: 0.7241 - val_loss: 1.3709 - val_accuracy: 0.6013\n","Epoch 75/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.2433 - accuracy: 0.7182 - val_loss: 1.3588 - val_accuracy: 0.6121\n","Epoch 76/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.2262 - accuracy: 0.7260 - val_loss: 1.3615 - val_accuracy: 0.6034\n","Epoch 77/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2197 - accuracy: 0.7306 - val_loss: 1.3613 - val_accuracy: 0.6034\n","Epoch 78/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2131 - accuracy: 0.7295 - val_loss: 1.3655 - val_accuracy: 0.6056\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2057 - accuracy: 0.7381 - val_loss: 1.3534 - val_accuracy: 0.6110\n","Epoch 80/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2034 - accuracy: 0.7376 - val_loss: 1.3505 - val_accuracy: 0.6045\n","Epoch 81/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.1930 - accuracy: 0.7416 - val_loss: 1.3477 - val_accuracy: 0.6185\n","Epoch 82/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.1871 - accuracy: 0.7387 - val_loss: 1.3445 - val_accuracy: 0.6196\n","Epoch 83/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1810 - accuracy: 0.7438 - val_loss: 1.3433 - val_accuracy: 0.6121\n","Epoch 84/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.1787 - accuracy: 0.7411 - val_loss: 1.3600 - val_accuracy: 0.6121\n","Epoch 85/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.1750 - accuracy: 0.7422 - val_loss: 1.3347 - val_accuracy: 0.6175\n","Epoch 86/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.1620 - accuracy: 0.7470 - val_loss: 1.3486 - val_accuracy: 0.5959\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1557 - accuracy: 0.7522 - val_loss: 1.3375 - val_accuracy: 0.6013\n","Epoch 88/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1550 - accuracy: 0.7460 - val_loss: 1.3292 - val_accuracy: 0.6153\n","Epoch 89/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1415 - accuracy: 0.7524 - val_loss: 1.3289 - val_accuracy: 0.6175\n","Epoch 90/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1361 - accuracy: 0.7487 - val_loss: 1.3346 - val_accuracy: 0.6045\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1247 - accuracy: 0.7648 - val_loss: 1.3267 - val_accuracy: 0.6142\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1264 - accuracy: 0.7602 - val_loss: 1.3274 - val_accuracy: 0.6196\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1224 - accuracy: 0.7567 - val_loss: 1.3358 - val_accuracy: 0.6056\n","Epoch 94/100\n","29/29 [==============================] - 2s 54ms/step - loss: 1.1152 - accuracy: 0.7559 - val_loss: 1.3209 - val_accuracy: 0.6261\n","Epoch 95/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1066 - accuracy: 0.7686 - val_loss: 1.3242 - val_accuracy: 0.6099\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1050 - accuracy: 0.7637 - val_loss: 1.3673 - val_accuracy: 0.5884\n","Epoch 97/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1014 - accuracy: 0.7575 - val_loss: 1.3146 - val_accuracy: 0.6131\n","Epoch 98/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.0852 - accuracy: 0.7759 - val_loss: 1.3141 - val_accuracy: 0.6142\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0890 - accuracy: 0.7697 - val_loss: 1.3166 - val_accuracy: 0.6153\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0907 - accuracy: 0.7624 - val_loss: 1.3141 - val_accuracy: 0.6131\n","{'loss': [1.8175216913223267, 1.809301495552063, 1.800763726234436, 1.7922418117523193, 1.7834980487823486, 1.7748922109603882, 1.765940546989441, 1.757500171661377, 1.7493141889572144, 1.7412331104278564, 1.7324129343032837, 1.7230300903320312, 1.715639591217041, 1.7060520648956299, 1.6958155632019043, 1.6868321895599365, 1.6760386228561401, 1.666283369064331, 1.6584385633468628, 1.6481224298477173, 1.6375409364700317, 1.6247437000274658, 1.6148558855056763, 1.6081056594848633, 1.596502423286438, 1.5900870561599731, 1.5784248113632202, 1.5699323415756226, 1.5631295442581177, 1.5523254871368408, 1.5471196174621582, 1.5389775037765503, 1.5301848649978638, 1.5206263065338135, 1.5130693912506104, 1.504927158355713, 1.4967654943466187, 1.4918978214263916, 1.4813086986541748, 1.4765673875808716, 1.4641904830932617, 1.4601234197616577, 1.4545389413833618, 1.443265438079834, 1.4374390840530396, 1.4297252893447876, 1.421873688697815, 1.4159213304519653, 1.406126618385315, 1.4013371467590332, 1.3949869871139526, 1.3884352445602417, 1.3788591623306274, 1.3725608587265015, 1.3684958219528198, 1.3684786558151245, 1.3513678312301636, 1.3507591485977173, 1.3371981382369995, 1.3304725885391235, 1.3264882564544678, 1.3198257684707642, 1.315132975578308, 1.3032221794128418, 1.299182415008545, 1.2914657592773438, 1.288770079612732, 1.2854474782943726, 1.2718300819396973, 1.2658913135528564, 1.261724591255188, 1.254856824874878, 1.2475801706314087, 1.241661548614502, 1.2432564496994019, 1.22623610496521, 1.2196829319000244, 1.213090181350708, 1.2057347297668457, 1.2034212350845337, 1.192992091178894, 1.1871284246444702, 1.1810297966003418, 1.1787184476852417, 1.1749812364578247, 1.1619888544082642, 1.1557079553604126, 1.15496826171875, 1.1415455341339111, 1.1361483335494995, 1.124650478363037, 1.1263893842697144, 1.1223794221878052, 1.115156888961792, 1.1066352128982544, 1.104958415031433, 1.1014333963394165, 1.085213541984558, 1.088963270187378, 1.0906566381454468], 'accuracy': [0.5040409564971924, 0.5086206793785095, 0.5115840435028076, 0.5148168206214905, 0.509428858757019, 0.5212823152542114, 0.532866358757019, 0.537715494632721, 0.5264008641242981, 0.5285560488700867, 0.5358297228813171, 0.5390625, 0.5342133641242981, 0.5538793206214905, 0.563847005367279, 0.5681573152542114, 0.5676185488700867, 0.5759698152542114, 0.5678879022598267, 0.5789331793785095, 0.5894396305084229, 0.5915948152542114, 0.603178858757019, 0.5988685488700867, 0.608027994632721, 0.6042564511299133, 0.6047952771186829, 0.6163793206214905, 0.6174569129943848, 0.6260775923728943, 0.6196120977401733, 0.6252694129943848, 0.6320043206214905, 0.6330819129943848, 0.634159505367279, 0.6427801847457886, 0.647090494632721, 0.6446659564971924, 0.6535560488700867, 0.6446659564971924, 0.662446141242981, 0.6522090435028076, 0.6573275923728943, 0.6648706793785095, 0.6635237336158752, 0.6632543206214905, 0.6664870977401733, 0.6742995977401733, 0.6721444129943848, 0.6815732717514038, 0.6745689511299133, 0.6764547228813171, 0.6775323152542114, 0.6842672228813171, 0.6821120977401733, 0.673222005367279, 0.6955819129943848, 0.6883081793785095, 0.6942349076271057, 0.6971982717514038, 0.7001616358757019, 0.6982758641242981, 0.7004310488700867, 0.7077047228813171, 0.6993534564971924, 0.7098599076271057, 0.7052801847457886, 0.7050107717514038, 0.7165948152542114, 0.7117456793785095, 0.7214439511299133, 0.7222521305084229, 0.724946141242981, 0.7241379022598267, 0.7182112336158752, 0.7260237336158752, 0.7306034564971924, 0.7295258641242981, 0.7381465435028076, 0.7376077771186829, 0.7416487336158752, 0.7386853694915771, 0.743803858757019, 0.7411099076271057, 0.7421875, 0.7470366358757019, 0.7521551847457886, 0.7459590435028076, 0.7524245977401733, 0.748652994632721, 0.7648168206214905, 0.7602370977401733, 0.7567349076271057, 0.7559267282485962, 0.7685883641242981, 0.7637392282485962, 0.7575430870056152, 0.7758620977401733, 0.7696659564971924, 0.7623922228813171], 'val_loss': [1.8133254051208496, 1.8048862218856812, 1.7964637279510498, 1.7880504131317139, 1.7797917127609253, 1.7713333368301392, 1.7633469104766846, 1.7549582719802856, 1.7469584941864014, 1.739241361618042, 1.7304469347000122, 1.722368597984314, 1.7137115001678467, 1.7066094875335693, 1.6976920366287231, 1.6883822679519653, 1.6831411123275757, 1.672272801399231, 1.6600415706634521, 1.6495369672775269, 1.6397916078567505, 1.6288914680480957, 1.6190025806427002, 1.6239253282546997, 1.6052591800689697, 1.6093238592147827, 1.5969860553741455, 1.587174415588379, 1.5755984783172607, 1.574863314628601, 1.5751888751983643, 1.5565857887268066, 1.5501947402954102, 1.547705888748169, 1.5435017347335815, 1.5486347675323486, 1.5298148393630981, 1.519222378730774, 1.5238021612167358, 1.5188283920288086, 1.5055619478225708, 1.5004217624664307, 1.493641972541809, 1.4879934787750244, 1.484113097190857, 1.4814419746398926, 1.4725143909454346, 1.4678627252578735, 1.4624550342559814, 1.4615083932876587, 1.4608068466186523, 1.4598864316940308, 1.4430533647537231, 1.447564721107483, 1.4490638971328735, 1.4377738237380981, 1.4251022338867188, 1.4276436567306519, 1.4362428188323975, 1.4147958755493164, 1.4113175868988037, 1.4129618406295776, 1.402021884918213, 1.3998574018478394, 1.403626799583435, 1.3968772888183594, 1.4018617868423462, 1.39322030544281, 1.3913626670837402, 1.3819301128387451, 1.3854678869247437, 1.3713167905807495, 1.3707860708236694, 1.370888590812683, 1.35875403881073, 1.361533284187317, 1.3612834215164185, 1.3654617071151733, 1.3534001111984253, 1.3504631519317627, 1.34773588180542, 1.3445340394973755, 1.3433005809783936, 1.3600307703018188, 1.3347022533416748, 1.3486394882202148, 1.3375117778778076, 1.3292086124420166, 1.3289130926132202, 1.334564447402954, 1.3266918659210205, 1.327388882637024, 1.335829496383667, 1.3208935260772705, 1.3241859674453735, 1.3672599792480469, 1.3145602941513062, 1.3140830993652344, 1.3165591955184937, 1.314051866531372], 'val_accuracy': [0.48491379618644714, 0.48599138855934143, 0.5161637663841248, 0.48706895112991333, 0.48491379618644714, 0.48599138855934143, 0.48491379618644714, 0.48275861144065857, 0.48491379618644714, 0.48491379618644714, 0.47413793206214905, 0.4709051847457886, 0.49461206793785095, 0.4784482717514038, 0.4762931168079376, 0.49353447556495667, 0.47413793206214905, 0.4892241358757019, 0.5387930870056152, 0.5614224076271057, 0.5700430870056152, 0.576508641242981, 0.5926724076271057, 0.5495689511299133, 0.5829741358757019, 0.5571120977401733, 0.5754310488700867, 0.5894396305084229, 0.5915948152542114, 0.5862069129943848, 0.5840517282485962, 0.5991379022598267, 0.5980603694915771, 0.5926724076271057, 0.5915948152542114, 0.5862069129943848, 0.6056034564971924, 0.5926724076271057, 0.5926724076271057, 0.5926724076271057, 0.6174569129943848, 0.6228448152542114, 0.5959051847457886, 0.5980603694915771, 0.5894396305084229, 0.5926724076271057, 0.6056034564971924, 0.610991358757019, 0.6120689511299133, 0.5926724076271057, 0.59375, 0.5862069129943848, 0.6099137663841248, 0.5980603694915771, 0.5883620977401733, 0.5926724076271057, 0.610991358757019, 0.5980603694915771, 0.587284505367279, 0.6131465435028076, 0.6088362336158752, 0.6023706793785095, 0.6206896305084229, 0.607758641242981, 0.6012930870056152, 0.6239224076271057, 0.5948275923728943, 0.600215494632721, 0.6088362336158752, 0.6056034564971924, 0.5991379022598267, 0.6206896305084229, 0.6023706793785095, 0.6012930870056152, 0.6120689511299133, 0.6034482717514038, 0.6034482717514038, 0.6056034564971924, 0.610991358757019, 0.6045258641242981, 0.618534505367279, 0.6196120977401733, 0.6120689511299133, 0.6120689511299133, 0.6174569129943848, 0.5959051847457886, 0.6012930870056152, 0.6153017282485962, 0.6174569129943848, 0.6045258641242981, 0.6142241358757019, 0.6196120977401733, 0.6056034564971924, 0.6260775923728943, 0.6099137663841248, 0.5883620977401733, 0.6131465435028076, 0.6142241358757019, 0.6153017282485962, 0.6131465435028076]}\n","38/38 [==============================] - 1s 10ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 1.8185 - accuracy: 0.4938"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 10s 126ms/step - loss: 1.8185 - accuracy: 0.4938 - val_loss: 1.8137 - val_accuracy: 0.5000\n","Epoch 2/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.8099 - accuracy: 0.5059 - val_loss: 1.8057 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.8031 - accuracy: 0.5006 - val_loss: 1.7977 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.7933 - accuracy: 0.5119 - val_loss: 1.7897 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.7854 - accuracy: 0.5116 - val_loss: 1.7818 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 34ms/step - loss: 1.7768 - accuracy: 0.5048 - val_loss: 1.7736 - val_accuracy: 0.5894\n","Epoch 7/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.7695 - accuracy: 0.5170 - val_loss: 1.7658 - val_accuracy: 0.4943\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.7602 - accuracy: 0.5390 - val_loss: 1.7578 - val_accuracy: 0.4921\n","Epoch 9/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.7524 - accuracy: 0.5272 - val_loss: 1.7498 - val_accuracy: 0.5498\n","Epoch 10/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.7439 - accuracy: 0.5291 - val_loss: 1.7419 - val_accuracy: 0.5124\n","Epoch 11/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.7351 - accuracy: 0.5507 - val_loss: 1.7339 - val_accuracy: 0.5283\n","Epoch 12/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.7266 - accuracy: 0.5606 - val_loss: 1.7258 - val_accuracy: 0.4830\n","Epoch 13/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.7180 - accuracy: 0.5540 - val_loss: 1.7171 - val_accuracy: 0.6018\n","Epoch 14/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.7099 - accuracy: 0.5557 - val_loss: 1.7085 - val_accuracy: 0.5566\n","Epoch 15/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.6995 - accuracy: 0.5614 - val_loss: 1.6994 - val_accuracy: 0.5690\n","Epoch 16/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.6901 - accuracy: 0.5702 - val_loss: 1.6910 - val_accuracy: 0.5339\n","Epoch 17/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.6819 - accuracy: 0.5628 - val_loss: 1.6802 - val_accuracy: 0.5814\n","Epoch 18/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.6690 - accuracy: 0.5891 - val_loss: 1.6699 - val_accuracy: 0.5769\n","Epoch 19/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.6595 - accuracy: 0.5914 - val_loss: 1.6610 - val_accuracy: 0.5667\n","Epoch 20/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.6508 - accuracy: 0.5852 - val_loss: 1.6541 - val_accuracy: 0.5656\n","Epoch 21/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.6411 - accuracy: 0.6010 - val_loss: 1.6410 - val_accuracy: 0.5882\n","Epoch 22/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.6337 - accuracy: 0.5962 - val_loss: 1.6340 - val_accuracy: 0.5713\n","Epoch 23/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.6237 - accuracy: 0.5905 - val_loss: 1.6242 - val_accuracy: 0.5882\n","Epoch 24/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.6149 - accuracy: 0.6041 - val_loss: 1.6157 - val_accuracy: 0.6018\n","Epoch 25/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.6111 - accuracy: 0.6002 - val_loss: 1.6173 - val_accuracy: 0.5679\n","Epoch 26/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.5991 - accuracy: 0.6075 - val_loss: 1.6004 - val_accuracy: 0.5973\n","Epoch 27/100\n","28/28 [==============================] - 1s 41ms/step - loss: 1.5913 - accuracy: 0.6067 - val_loss: 1.5943 - val_accuracy: 0.6063\n","Epoch 28/100\n","28/28 [==============================] - 1s 38ms/step - loss: 1.5850 - accuracy: 0.6104 - val_loss: 1.5867 - val_accuracy: 0.5973\n","Epoch 29/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.5781 - accuracy: 0.6044 - val_loss: 1.5847 - val_accuracy: 0.5882\n","Epoch 30/100\n","28/28 [==============================] - 1s 33ms/step - loss: 1.5703 - accuracy: 0.6104 - val_loss: 1.5806 - val_accuracy: 0.6143\n","Epoch 31/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.5598 - accuracy: 0.6180 - val_loss: 1.5678 - val_accuracy: 0.5973\n","Epoch 32/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.5541 - accuracy: 0.6180 - val_loss: 1.5618 - val_accuracy: 0.6029\n","Epoch 33/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5478 - accuracy: 0.6171 - val_loss: 1.5553 - val_accuracy: 0.5950\n","Epoch 34/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5391 - accuracy: 0.6251 - val_loss: 1.5516 - val_accuracy: 0.6109\n","Epoch 35/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.5324 - accuracy: 0.6262 - val_loss: 1.5439 - val_accuracy: 0.6052\n","Epoch 36/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5275 - accuracy: 0.6256 - val_loss: 1.5374 - val_accuracy: 0.6018\n","Epoch 37/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5185 - accuracy: 0.6220 - val_loss: 1.5322 - val_accuracy: 0.6007\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5118 - accuracy: 0.6256 - val_loss: 1.5264 - val_accuracy: 0.6041\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5027 - accuracy: 0.6333 - val_loss: 1.5203 - val_accuracy: 0.6041\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4975 - accuracy: 0.6344 - val_loss: 1.5142 - val_accuracy: 0.6007\n","Epoch 41/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4904 - accuracy: 0.6392 - val_loss: 1.5108 - val_accuracy: 0.6075\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4832 - accuracy: 0.6398 - val_loss: 1.5042 - val_accuracy: 0.6041\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4756 - accuracy: 0.6435 - val_loss: 1.4982 - val_accuracy: 0.6120\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4667 - accuracy: 0.6420 - val_loss: 1.4932 - val_accuracy: 0.6075\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4628 - accuracy: 0.6474 - val_loss: 1.4889 - val_accuracy: 0.6086\n","Epoch 46/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4549 - accuracy: 0.6452 - val_loss: 1.4841 - val_accuracy: 0.6131\n","Epoch 47/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4492 - accuracy: 0.6474 - val_loss: 1.4798 - val_accuracy: 0.6131\n","Epoch 48/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4433 - accuracy: 0.6553 - val_loss: 1.4811 - val_accuracy: 0.6143\n","Epoch 49/100\n","28/28 [==============================] - 2s 59ms/step - loss: 1.4383 - accuracy: 0.6454 - val_loss: 1.4713 - val_accuracy: 0.6199\n","Epoch 50/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.4298 - accuracy: 0.6514 - val_loss: 1.4721 - val_accuracy: 0.6176\n","Epoch 51/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.4232 - accuracy: 0.6576 - val_loss: 1.4596 - val_accuracy: 0.6097\n","Epoch 52/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.4175 - accuracy: 0.6531 - val_loss: 1.4621 - val_accuracy: 0.6131\n","Epoch 53/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.4090 - accuracy: 0.6783 - val_loss: 1.4512 - val_accuracy: 0.6188\n","Epoch 54/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.3984 - accuracy: 0.6723 - val_loss: 1.4600 - val_accuracy: 0.6154\n","Epoch 55/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.3951 - accuracy: 0.6718 - val_loss: 1.4427 - val_accuracy: 0.6176\n","Epoch 56/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.3891 - accuracy: 0.6749 - val_loss: 1.4429 - val_accuracy: 0.6143\n","Epoch 57/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3833 - accuracy: 0.6706 - val_loss: 1.4346 - val_accuracy: 0.6154\n","Epoch 58/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3818 - accuracy: 0.6633 - val_loss: 1.4320 - val_accuracy: 0.6131\n","Epoch 59/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3673 - accuracy: 0.6780 - val_loss: 1.4273 - val_accuracy: 0.6188\n","Epoch 60/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.3637 - accuracy: 0.6817 - val_loss: 1.4362 - val_accuracy: 0.6267\n","Epoch 61/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3575 - accuracy: 0.6808 - val_loss: 1.4186 - val_accuracy: 0.6165\n","Epoch 62/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3464 - accuracy: 0.6828 - val_loss: 1.4160 - val_accuracy: 0.6052\n","Epoch 63/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3454 - accuracy: 0.6859 - val_loss: 1.4168 - val_accuracy: 0.6244\n","Epoch 64/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3416 - accuracy: 0.6814 - val_loss: 1.4080 - val_accuracy: 0.6063\n","Epoch 65/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3305 - accuracy: 0.6919 - val_loss: 1.4071 - val_accuracy: 0.6256\n","Epoch 66/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3289 - accuracy: 0.6882 - val_loss: 1.4005 - val_accuracy: 0.6154\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3225 - accuracy: 0.6964 - val_loss: 1.3983 - val_accuracy: 0.6120\n","Epoch 68/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.3196 - accuracy: 0.6811 - val_loss: 1.3979 - val_accuracy: 0.6290\n","Epoch 69/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.3158 - accuracy: 0.6907 - val_loss: 1.3958 - val_accuracy: 0.6357\n","Epoch 70/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3037 - accuracy: 0.6955 - val_loss: 1.3829 - val_accuracy: 0.6041\n","Epoch 71/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2929 - accuracy: 0.7051 - val_loss: 1.3823 - val_accuracy: 0.6086\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2926 - accuracy: 0.7015 - val_loss: 1.3811 - val_accuracy: 0.6063\n","Epoch 73/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.2769 - accuracy: 0.7074 - val_loss: 1.3761 - val_accuracy: 0.6143\n","Epoch 74/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.2788 - accuracy: 0.7066 - val_loss: 1.3756 - val_accuracy: 0.6199\n","Epoch 75/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.2791 - accuracy: 0.6995 - val_loss: 1.3790 - val_accuracy: 0.6278\n","Epoch 76/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.2661 - accuracy: 0.7131 - val_loss: 1.3662 - val_accuracy: 0.6154\n","Epoch 77/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.2579 - accuracy: 0.7066 - val_loss: 1.3652 - val_accuracy: 0.6086\n","Epoch 78/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.2529 - accuracy: 0.7083 - val_loss: 1.3634 - val_accuracy: 0.6086\n","Epoch 79/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2483 - accuracy: 0.7165 - val_loss: 1.3587 - val_accuracy: 0.6131\n","Epoch 80/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2489 - accuracy: 0.7054 - val_loss: 1.3584 - val_accuracy: 0.6120\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2326 - accuracy: 0.7184 - val_loss: 1.3542 - val_accuracy: 0.6143\n","Epoch 82/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2277 - accuracy: 0.7216 - val_loss: 1.3510 - val_accuracy: 0.6109\n","Epoch 83/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2290 - accuracy: 0.7066 - val_loss: 1.3640 - val_accuracy: 0.5916\n","Epoch 84/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2318 - accuracy: 0.7077 - val_loss: 1.3420 - val_accuracy: 0.6131\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2123 - accuracy: 0.7281 - val_loss: 1.3394 - val_accuracy: 0.6154\n","Epoch 86/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.2032 - accuracy: 0.7233 - val_loss: 1.3387 - val_accuracy: 0.6109\n","Epoch 87/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1994 - accuracy: 0.7241 - val_loss: 1.3422 - val_accuracy: 0.6210\n","Epoch 88/100\n","28/28 [==============================] - 1s 32ms/step - loss: 1.1956 - accuracy: 0.7286 - val_loss: 1.3350 - val_accuracy: 0.6131\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1965 - accuracy: 0.7241 - val_loss: 1.3342 - val_accuracy: 0.6165\n","Epoch 90/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1831 - accuracy: 0.7281 - val_loss: 1.3303 - val_accuracy: 0.6109\n","Epoch 91/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1727 - accuracy: 0.7411 - val_loss: 1.3302 - val_accuracy: 0.6176\n","Epoch 92/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1668 - accuracy: 0.7422 - val_loss: 1.3289 - val_accuracy: 0.6063\n","Epoch 93/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1697 - accuracy: 0.7326 - val_loss: 1.3398 - val_accuracy: 0.6210\n","Epoch 94/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1685 - accuracy: 0.7255 - val_loss: 1.3264 - val_accuracy: 0.6210\n","Epoch 95/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1494 - accuracy: 0.7428 - val_loss: 1.3302 - val_accuracy: 0.6007\n","Epoch 96/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1585 - accuracy: 0.7312 - val_loss: 1.3497 - val_accuracy: 0.6165\n","Epoch 97/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1428 - accuracy: 0.7388 - val_loss: 1.3183 - val_accuracy: 0.6176\n","Epoch 98/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.1340 - accuracy: 0.7499 - val_loss: 1.3192 - val_accuracy: 0.6131\n","Epoch 99/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.1266 - accuracy: 0.7510 - val_loss: 1.3266 - val_accuracy: 0.5973\n","Epoch 100/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.1250 - accuracy: 0.7524 - val_loss: 1.3242 - val_accuracy: 0.6165\n","{'loss': [1.8184607028961182, 1.8099250793457031, 1.8030763864517212, 1.7932713031768799, 1.7854024171829224, 1.7768330574035645, 1.7694799900054932, 1.760225772857666, 1.7523765563964844, 1.7438782453536987, 1.7350780963897705, 1.726586937904358, 1.7180224657058716, 1.7098662853240967, 1.6994726657867432, 1.6901267766952515, 1.6819202899932861, 1.6689695119857788, 1.6595404148101807, 1.6507614850997925, 1.6410744190216064, 1.6337058544158936, 1.6237211227416992, 1.6148635149002075, 1.6110563278198242, 1.5991253852844238, 1.5912574529647827, 1.5850045680999756, 1.5780901908874512, 1.5703098773956299, 1.5598325729370117, 1.5540854930877686, 1.5478497743606567, 1.5390877723693848, 1.5323693752288818, 1.52745521068573, 1.5184578895568848, 1.5117571353912354, 1.5026869773864746, 1.4975197315216064, 1.4903942346572876, 1.4832204580307007, 1.4756138324737549, 1.4667272567749023, 1.462791919708252, 1.454870581626892, 1.4492299556732178, 1.4432957172393799, 1.4382784366607666, 1.4298152923583984, 1.4231808185577393, 1.417513370513916, 1.408968448638916, 1.3983794450759888, 1.3951064348220825, 1.389075756072998, 1.3832908868789673, 1.381760597229004, 1.3673430681228638, 1.3637338876724243, 1.357465386390686, 1.346380591392517, 1.345375657081604, 1.3415988683700562, 1.330527663230896, 1.328871250152588, 1.322515606880188, 1.3195618391036987, 1.3157801628112793, 1.303711175918579, 1.2928634881973267, 1.2925690412521362, 1.2768555879592896, 1.278839111328125, 1.2791250944137573, 1.2661460638046265, 1.2579081058502197, 1.2529187202453613, 1.2482753992080688, 1.2489243745803833, 1.2326323986053467, 1.2276694774627686, 1.2290089130401611, 1.2317835092544556, 1.2123429775238037, 1.2032204866409302, 1.1994260549545288, 1.1956366300582886, 1.1965129375457764, 1.1831294298171997, 1.172743797302246, 1.1667735576629639, 1.1696773767471313, 1.1684542894363403, 1.1494187116622925, 1.1584581136703491, 1.1428133249282837, 1.1340420246124268, 1.1266050338745117, 1.1249604225158691], 'accuracy': [0.49377477169036865, 0.5059422850608826, 0.5005659461021423, 0.5118845701217651, 0.5116015672683716, 0.5048103928565979, 0.5169779062271118, 0.5390492081642151, 0.5271646976470947, 0.5291454195976257, 0.5506508350372314, 0.5605546236038208, 0.5540463924407959, 0.5557441711425781, 0.5614035129547119, 0.5701754093170166, 0.5628183484077454, 0.5891340970993042, 0.5913978219032288, 0.5851725935935974, 0.6010186672210693, 0.5962082743644714, 0.5905489325523376, 0.604131281375885, 0.6001697778701782, 0.6075268983840942, 0.6066780090332031, 0.6103565096855164, 0.6044142842292786, 0.6103565096855164, 0.6179966330528259, 0.6179966330528259, 0.61714768409729, 0.6250707507133484, 0.6262025833129883, 0.6256366968154907, 0.6219581365585327, 0.6256366968154907, 0.6332767605781555, 0.6344085931777954, 0.6392189860343933, 0.6397849321365356, 0.6434634923934937, 0.6420486569404602, 0.6474249958992004, 0.6451612710952759, 0.6474249958992004, 0.6553480625152588, 0.6454442739486694, 0.651386559009552, 0.6576117873191833, 0.6530843377113342, 0.6782682538032532, 0.6723259687423706, 0.6717600226402283, 0.674872636795044, 0.6706281900405884, 0.6632710695266724, 0.6779853105545044, 0.6816638112068176, 0.6808149218559265, 0.6827957034111023, 0.685908317565918, 0.6813808679580688, 0.6918506026268005, 0.6881720423698425, 0.6963780522346497, 0.6810979247093201, 0.6907187104225159, 0.6955291628837585, 0.7051499485969543, 0.7014714479446411, 0.7074136734008789, 0.7065647840499878, 0.6994906663894653, 0.7130730152130127, 0.7065647840499878, 0.70826256275177, 0.7164685726165771, 0.7054329514503479, 0.7184493541717529, 0.7215619683265686, 0.7065647840499878, 0.7076966762542725, 0.7280701994895935, 0.7232597470283508, 0.7241086363792419, 0.7286360859870911, 0.7241086363792419, 0.7280701994895935, 0.7410866022109985, 0.7422184348106384, 0.7325976490974426, 0.7255234718322754, 0.7427843809127808, 0.7311828136444092, 0.738822877407074, 0.7498584985733032, 0.7509903907775879, 0.7524052262306213], 'val_loss': [1.8136943578720093, 1.8057154417037964, 1.7977145910263062, 1.7896852493286133, 1.7817540168762207, 1.773646593093872, 1.7657679319381714, 1.7578328847885132, 1.7497814893722534, 1.741896390914917, 1.7338812351226807, 1.7257723808288574, 1.7171108722686768, 1.7085247039794922, 1.6994398832321167, 1.6910450458526611, 1.6802191734313965, 1.6698765754699707, 1.661001443862915, 1.6541478633880615, 1.6409589052200317, 1.6340032815933228, 1.6242151260375977, 1.6157145500183105, 1.6173063516616821, 1.6003789901733398, 1.5942869186401367, 1.5866867303848267, 1.5847479104995728, 1.5806076526641846, 1.5678006410598755, 1.5618265867233276, 1.5553367137908936, 1.551564335823059, 1.5439194440841675, 1.53743577003479, 1.53223717212677, 1.5263608694076538, 1.520344614982605, 1.5142135620117188, 1.5108388662338257, 1.5042359828948975, 1.4982366561889648, 1.493217945098877, 1.4888843297958374, 1.484078288078308, 1.4797941446304321, 1.4811195135116577, 1.4712629318237305, 1.4720962047576904, 1.4596226215362549, 1.4620908498764038, 1.4512100219726562, 1.460039496421814, 1.4426697492599487, 1.442887544631958, 1.4345701932907104, 1.4320414066314697, 1.4273377656936646, 1.4361921548843384, 1.4186053276062012, 1.416024088859558, 1.4167836904525757, 1.4080150127410889, 1.407090187072754, 1.4004788398742676, 1.3983198404312134, 1.3978925943374634, 1.395795464515686, 1.382916808128357, 1.3823491334915161, 1.381054401397705, 1.3760952949523926, 1.3755897283554077, 1.3790239095687866, 1.3661648035049438, 1.3652293682098389, 1.3633825778961182, 1.3587145805358887, 1.3583791255950928, 1.3541762828826904, 1.3509653806686401, 1.36403226852417, 1.3419746160507202, 1.3394402265548706, 1.3387387990951538, 1.3421682119369507, 1.3349858522415161, 1.3342301845550537, 1.330329418182373, 1.3301697969436646, 1.3288977146148682, 1.3398478031158447, 1.3263663053512573, 1.3302310705184937, 1.3497146368026733, 1.31828773021698, 1.3191800117492676, 1.3265970945358276, 1.3241559267044067], 'val_accuracy': [0.5, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.5893664956092834, 0.4943438768386841, 0.4920814335346222, 0.5497737526893616, 0.5124434232711792, 0.5282805562019348, 0.48303166031837463, 0.6018099784851074, 0.5565611124038696, 0.5690045356750488, 0.5339366793632507, 0.581447958946228, 0.5769230723381042, 0.5667420625686646, 0.5656108856201172, 0.5882353186607361, 0.5712669491767883, 0.5882353186607361, 0.6018099784851074, 0.5678732991218567, 0.5972850918769836, 0.6063348650932312, 0.5972850918769836, 0.5882353186607361, 0.6142534017562866, 0.5972850918769836, 0.6029411554336548, 0.5950226187705994, 0.610859751701355, 0.6052036285400391, 0.6018099784851074, 0.6006787419319153, 0.6040723919868469, 0.6040723919868469, 0.6006787419319153, 0.6074660420417786, 0.6040723919868469, 0.6119909286499023, 0.6074660420417786, 0.6085972785949707, 0.6131221652030945, 0.6131221652030945, 0.6142534017562866, 0.6199095249176025, 0.6176470518112183, 0.6097285151481628, 0.6131221652030945, 0.6187782883644104, 0.6153846383094788, 0.6176470518112183, 0.6142534017562866, 0.6153846383094788, 0.6131221652030945, 0.6187782883644104, 0.6266968250274658, 0.6165158152580261, 0.6052036285400391, 0.6244344115257263, 0.6063348650932312, 0.6255655884742737, 0.6153846383094788, 0.6119909286499023, 0.6289592981338501, 0.6357465982437134, 0.6040723919868469, 0.6085972785949707, 0.6063348650932312, 0.6142534017562866, 0.6199095249176025, 0.627828061580658, 0.6153846383094788, 0.6085972785949707, 0.6085972785949707, 0.6131221652030945, 0.6119909286499023, 0.6142534017562866, 0.610859751701355, 0.5916289687156677, 0.6131221652030945, 0.6153846383094788, 0.610859751701355, 0.6210407018661499, 0.6131221652030945, 0.6165158152580261, 0.610859751701355, 0.6176470518112183, 0.6063348650932312, 0.6210407018661499, 0.6210407018661499, 0.6006787419319153, 0.6165158152580261, 0.6176470518112183, 0.6131221652030945, 0.5972850918769836, 0.6165158152580261]}\n","45/45 [==============================] - 1s 8ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 1.8180 - accuracy: 0.5013"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 9s 76ms/step - loss: 1.8180 - accuracy: 0.5013 - val_loss: 1.8127 - val_accuracy: 0.5145\n","Epoch 2/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.8085 - accuracy: 0.5013 - val_loss: 1.8040 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.7998 - accuracy: 0.5150 - val_loss: 1.7951 - val_accuracy: 0.5692\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.7921 - accuracy: 0.4928 - val_loss: 1.7866 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.7820 - accuracy: 0.5145 - val_loss: 1.7778 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.7738 - accuracy: 0.5111 - val_loss: 1.7694 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.7647 - accuracy: 0.5134 - val_loss: 1.7608 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.7561 - accuracy: 0.5114 - val_loss: 1.7522 - val_accuracy: 0.5610\n","Epoch 9/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.7477 - accuracy: 0.5168 - val_loss: 1.7439 - val_accuracy: 0.4835\n","Epoch 10/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.7398 - accuracy: 0.5070 - val_loss: 1.7358 - val_accuracy: 0.4855\n","Epoch 11/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.7303 - accuracy: 0.5323 - val_loss: 1.7269 - val_accuracy: 0.5795\n","Epoch 12/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.7215 - accuracy: 0.5339 - val_loss: 1.7185 - val_accuracy: 0.5640\n","Epoch 13/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.7135 - accuracy: 0.5341 - val_loss: 1.7106 - val_accuracy: 0.4731\n","Epoch 14/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.7057 - accuracy: 0.5256 - val_loss: 1.7030 - val_accuracy: 0.4855\n","Epoch 15/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.6956 - accuracy: 0.5295 - val_loss: 1.6929 - val_accuracy: 0.5713\n","Epoch 16/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.6881 - accuracy: 0.5408 - val_loss: 1.6847 - val_accuracy: 0.5269\n","Epoch 17/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.6785 - accuracy: 0.5589 - val_loss: 1.6764 - val_accuracy: 0.4979\n","Epoch 18/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.6702 - accuracy: 0.5382 - val_loss: 1.6662 - val_accuracy: 0.5671\n","Epoch 19/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.6616 - accuracy: 0.5447 - val_loss: 1.6573 - val_accuracy: 0.5692\n","Epoch 20/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.6537 - accuracy: 0.5620 - val_loss: 1.6481 - val_accuracy: 0.5950\n","Epoch 21/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.6446 - accuracy: 0.5589 - val_loss: 1.6437 - val_accuracy: 0.4948\n","Epoch 22/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.6338 - accuracy: 0.5623 - val_loss: 1.6290 - val_accuracy: 0.5795\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.6248 - accuracy: 0.5698 - val_loss: 1.6197 - val_accuracy: 0.5919\n","Epoch 24/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.6149 - accuracy: 0.5786 - val_loss: 1.6108 - val_accuracy: 0.5899\n","Epoch 25/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.6067 - accuracy: 0.5760 - val_loss: 1.6057 - val_accuracy: 0.5517\n","Epoch 26/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5954 - accuracy: 0.5953 - val_loss: 1.5998 - val_accuracy: 0.5455\n","Epoch 27/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5883 - accuracy: 0.5796 - val_loss: 1.5846 - val_accuracy: 0.5857\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5810 - accuracy: 0.5817 - val_loss: 1.5858 - val_accuracy: 0.5579\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5704 - accuracy: 0.5858 - val_loss: 1.5738 - val_accuracy: 0.5599\n","Epoch 30/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.5603 - accuracy: 0.5972 - val_loss: 1.5732 - val_accuracy: 0.5599\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.5553 - accuracy: 0.5928 - val_loss: 1.5566 - val_accuracy: 0.5878\n","Epoch 32/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.5469 - accuracy: 0.6003 - val_loss: 1.5577 - val_accuracy: 0.5682\n","Epoch 33/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.5393 - accuracy: 0.6036 - val_loss: 1.5407 - val_accuracy: 0.5847\n","Epoch 34/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.5291 - accuracy: 0.6088 - val_loss: 1.5334 - val_accuracy: 0.5878\n","Epoch 35/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.5206 - accuracy: 0.6150 - val_loss: 1.5339 - val_accuracy: 0.5795\n","Epoch 36/100\n","31/31 [==============================] - 1s 30ms/step - loss: 1.5140 - accuracy: 0.6114 - val_loss: 1.5199 - val_accuracy: 0.5971\n","Epoch 37/100\n","31/31 [==============================] - 1s 33ms/step - loss: 1.5047 - accuracy: 0.6152 - val_loss: 1.5140 - val_accuracy: 0.5992\n","Epoch 38/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.4948 - accuracy: 0.6163 - val_loss: 1.5191 - val_accuracy: 0.5692\n","Epoch 39/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.4941 - accuracy: 0.6147 - val_loss: 1.5010 - val_accuracy: 0.5961\n","Epoch 40/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.4804 - accuracy: 0.6341 - val_loss: 1.4950 - val_accuracy: 0.5971\n","Epoch 41/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.4714 - accuracy: 0.6315 - val_loss: 1.4912 - val_accuracy: 0.6012\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4666 - accuracy: 0.6315 - val_loss: 1.4899 - val_accuracy: 0.5806\n","Epoch 43/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.4585 - accuracy: 0.6331 - val_loss: 1.4770 - val_accuracy: 0.6095\n","Epoch 44/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.4510 - accuracy: 0.6385 - val_loss: 1.4729 - val_accuracy: 0.6116\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4461 - accuracy: 0.6331 - val_loss: 1.4712 - val_accuracy: 0.6064\n","Epoch 46/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4369 - accuracy: 0.6388 - val_loss: 1.4770 - val_accuracy: 0.5692\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4338 - accuracy: 0.6377 - val_loss: 1.4565 - val_accuracy: 0.6095\n","Epoch 48/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4236 - accuracy: 0.6421 - val_loss: 1.4542 - val_accuracy: 0.6085\n","Epoch 49/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4184 - accuracy: 0.6450 - val_loss: 1.4563 - val_accuracy: 0.5816\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4090 - accuracy: 0.6486 - val_loss: 1.4432 - val_accuracy: 0.6116\n","Epoch 51/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4036 - accuracy: 0.6535 - val_loss: 1.4398 - val_accuracy: 0.5950\n","Epoch 52/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3956 - accuracy: 0.6561 - val_loss: 1.4319 - val_accuracy: 0.5981\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3911 - accuracy: 0.6517 - val_loss: 1.4265 - val_accuracy: 0.6023\n","Epoch 54/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.3829 - accuracy: 0.6623 - val_loss: 1.4184 - val_accuracy: 0.6198\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3774 - accuracy: 0.6584 - val_loss: 1.4144 - val_accuracy: 0.6074\n","Epoch 56/100\n","31/31 [==============================] - 1s 30ms/step - loss: 1.3670 - accuracy: 0.6630 - val_loss: 1.4086 - val_accuracy: 0.6229\n","Epoch 57/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.3622 - accuracy: 0.6636 - val_loss: 1.4043 - val_accuracy: 0.6229\n","Epoch 58/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.3525 - accuracy: 0.6726 - val_loss: 1.4000 - val_accuracy: 0.6157\n","Epoch 59/100\n","31/31 [==============================] - 1s 33ms/step - loss: 1.3458 - accuracy: 0.6695 - val_loss: 1.3954 - val_accuracy: 0.6250\n","Epoch 60/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.3400 - accuracy: 0.6664 - val_loss: 1.4007 - val_accuracy: 0.6136\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3376 - accuracy: 0.6633 - val_loss: 1.3919 - val_accuracy: 0.6209\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3324 - accuracy: 0.6698 - val_loss: 1.3828 - val_accuracy: 0.6240\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3207 - accuracy: 0.6770 - val_loss: 1.3792 - val_accuracy: 0.6219\n","Epoch 64/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3179 - accuracy: 0.6685 - val_loss: 1.3732 - val_accuracy: 0.6198\n","Epoch 65/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3071 - accuracy: 0.6773 - val_loss: 1.3770 - val_accuracy: 0.5919\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3013 - accuracy: 0.6822 - val_loss: 1.3661 - val_accuracy: 0.6209\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2940 - accuracy: 0.6809 - val_loss: 1.3614 - val_accuracy: 0.6157\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2951 - accuracy: 0.6817 - val_loss: 1.3575 - val_accuracy: 0.6178\n","Epoch 69/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.2838 - accuracy: 0.6894 - val_loss: 1.3503 - val_accuracy: 0.6343\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2816 - accuracy: 0.6850 - val_loss: 1.3473 - val_accuracy: 0.6260\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2702 - accuracy: 0.6948 - val_loss: 1.3423 - val_accuracy: 0.6333\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2647 - accuracy: 0.6935 - val_loss: 1.3479 - val_accuracy: 0.5981\n","Epoch 73/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.2637 - accuracy: 0.6881 - val_loss: 1.3338 - val_accuracy: 0.6395\n","Epoch 74/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2505 - accuracy: 0.7013 - val_loss: 1.3318 - val_accuracy: 0.6312\n","Epoch 75/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2445 - accuracy: 0.6987 - val_loss: 1.3350 - val_accuracy: 0.6167\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2537 - accuracy: 0.6773 - val_loss: 1.3370 - val_accuracy: 0.5950\n","Epoch 77/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2425 - accuracy: 0.6972 - val_loss: 1.3410 - val_accuracy: 0.5857\n","Epoch 78/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.2298 - accuracy: 0.6974 - val_loss: 1.3209 - val_accuracy: 0.6188\n","Epoch 79/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2260 - accuracy: 0.6995 - val_loss: 1.3181 - val_accuracy: 0.6167\n","Epoch 80/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2163 - accuracy: 0.7010 - val_loss: 1.3129 - val_accuracy: 0.6219\n","Epoch 81/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.2128 - accuracy: 0.7034 - val_loss: 1.3083 - val_accuracy: 0.6271\n","Epoch 82/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2060 - accuracy: 0.7119 - val_loss: 1.3063 - val_accuracy: 0.6281\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1972 - accuracy: 0.7155 - val_loss: 1.3055 - val_accuracy: 0.6209\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1986 - accuracy: 0.7183 - val_loss: 1.2993 - val_accuracy: 0.6281\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1865 - accuracy: 0.7227 - val_loss: 1.2953 - val_accuracy: 0.6291\n","Epoch 86/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.1807 - accuracy: 0.7261 - val_loss: 1.3177 - val_accuracy: 0.6012\n","Epoch 87/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.1767 - accuracy: 0.7165 - val_loss: 1.2898 - val_accuracy: 0.6271\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1630 - accuracy: 0.7212 - val_loss: 1.2954 - val_accuracy: 0.6178\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1648 - accuracy: 0.7178 - val_loss: 1.2893 - val_accuracy: 0.6240\n","Epoch 90/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1576 - accuracy: 0.7220 - val_loss: 1.2842 - val_accuracy: 0.6291\n","Epoch 91/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.1537 - accuracy: 0.7238 - val_loss: 1.2904 - val_accuracy: 0.6209\n","Epoch 92/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1442 - accuracy: 0.7315 - val_loss: 1.2814 - val_accuracy: 0.6281\n","Epoch 93/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1427 - accuracy: 0.7245 - val_loss: 1.2750 - val_accuracy: 0.6364\n","Epoch 94/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1302 - accuracy: 0.7339 - val_loss: 1.2777 - val_accuracy: 0.6353\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1299 - accuracy: 0.7331 - val_loss: 1.2879 - val_accuracy: 0.6012\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1268 - accuracy: 0.7297 - val_loss: 1.2726 - val_accuracy: 0.6219\n","Epoch 97/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1116 - accuracy: 0.7351 - val_loss: 1.2737 - val_accuracy: 0.6333\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1122 - accuracy: 0.7413 - val_loss: 1.2853 - val_accuracy: 0.6126\n","Epoch 99/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.1087 - accuracy: 0.7398 - val_loss: 1.2702 - val_accuracy: 0.6343\n","Epoch 100/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0966 - accuracy: 0.7475 - val_loss: 1.2737 - val_accuracy: 0.6157\n","{'loss': [1.8180086612701416, 1.8085191249847412, 1.7998205423355103, 1.7920536994934082, 1.7820160388946533, 1.773770809173584, 1.7647032737731934, 1.7560654878616333, 1.747744083404541, 1.7398195266723633, 1.730271339416504, 1.7215220928192139, 1.7135422229766846, 1.7057045698165894, 1.6955617666244507, 1.6881489753723145, 1.6785142421722412, 1.6701794862747192, 1.6616114377975464, 1.6537269353866577, 1.6445564031600952, 1.6337772607803345, 1.6247566938400269, 1.614926815032959, 1.6067290306091309, 1.59544837474823, 1.588290810585022, 1.5810256004333496, 1.5703729391098022, 1.5603175163269043, 1.5553309917449951, 1.5468944311141968, 1.5393365621566772, 1.529135823249817, 1.5206069946289062, 1.5139623880386353, 1.504683494567871, 1.4947738647460938, 1.4941340684890747, 1.4804446697235107, 1.4713565111160278, 1.4665744304656982, 1.4585081338882446, 1.450951099395752, 1.4461159706115723, 1.4369388818740845, 1.43381667137146, 1.4235998392105103, 1.4183778762817383, 1.4089807271957397, 1.4036140441894531, 1.395644187927246, 1.3911137580871582, 1.3829267024993896, 1.3773763179779053, 1.366966724395752, 1.3621958494186401, 1.3524770736694336, 1.3458112478256226, 1.340023398399353, 1.3375755548477173, 1.3323825597763062, 1.3206676244735718, 1.3178954124450684, 1.3070679903030396, 1.3012652397155762, 1.294040322303772, 1.2950838804244995, 1.2838356494903564, 1.281598687171936, 1.270180583000183, 1.2647101879119873, 1.2636858224868774, 1.2505189180374146, 1.2445271015167236, 1.2537262439727783, 1.2425156831741333, 1.2298219203948975, 1.2259806394577026, 1.2162765264511108, 1.2128492593765259, 1.2059961557388306, 1.1971535682678223, 1.1985907554626465, 1.1864551305770874, 1.1806526184082031, 1.1766910552978516, 1.163034200668335, 1.1648259162902832, 1.157580018043518, 1.1537071466445923, 1.1442278623580933, 1.1426928043365479, 1.1302322149276733, 1.1299208402633667, 1.1267778873443604, 1.111554503440857, 1.112169861793518, 1.1086771488189697, 1.0966256856918335], 'accuracy': [0.5012919902801514, 0.5012919902801514, 0.514987051486969, 0.4927648603916168, 0.5144702792167664, 0.5111111402511597, 0.5134366750717163, 0.511369526386261, 0.5167958736419678, 0.5069767236709595, 0.5322997570037842, 0.5338501334190369, 0.5341085195541382, 0.525581419467926, 0.5294573903083801, 0.5408268570899963, 0.5589147210121155, 0.5382428765296936, 0.5447028279304504, 0.5620155334472656, 0.5589147210121155, 0.5622739195823669, 0.569767415523529, 0.5785529613494873, 0.5759689807891846, 0.5953488349914551, 0.5795865654945374, 0.5816537737846375, 0.5857881307601929, 0.5971575975418091, 0.5927648544311523, 0.6002584099769592, 0.6036175489425659, 0.6087855100631714, 0.6149870753288269, 0.6113694906234741, 0.6152454614639282, 0.6162790656089783, 0.6147286891937256, 0.6341085433959961, 0.6315245628356934, 0.6315245628356934, 0.633074939250946, 0.6385012865066528, 0.633074939250946, 0.6387596726417542, 0.6377260684967041, 0.6421188712120056, 0.6449612379074097, 0.6485788226127625, 0.6534883975982666, 0.6560723781585693, 0.6516795754432678, 0.6622738838195801, 0.658397912979126, 0.6630491018295288, 0.6635658740997314, 0.672609806060791, 0.6695090532302856, 0.6664082407951355, 0.6633074879646301, 0.669767439365387, 0.6770026087760925, 0.6684754490852356, 0.6772609949111938, 0.682170569896698, 0.6808785796165466, 0.6816537380218506, 0.6894056797027588, 0.685012936592102, 0.6948320269584656, 0.6935400366783142, 0.6881136894226074, 0.7012919783592224, 0.6987079977989197, 0.6772609949111938, 0.697157621383667, 0.6974160075187683, 0.6994832158088684, 0.7010335922241211, 0.7033591866493225, 0.7118862867355347, 0.7155038714408875, 0.7183462381362915, 0.722739040851593, 0.7260981798171997, 0.7165374755859375, 0.7211886048316956, 0.7178294658660889, 0.7219638228416443, 0.7237725853919983, 0.7315245270729065, 0.724547803401947, 0.7338501214981079, 0.733074963092804, 0.7297157645225525, 0.7351421117782593, 0.7413436770439148, 0.7397933006286621, 0.7475452423095703], 'val_loss': [1.812706708908081, 1.803951621055603, 1.7950583696365356, 1.786600112915039, 1.7778360843658447, 1.7693628072738647, 1.7608317136764526, 1.7521650791168213, 1.7438639402389526, 1.7357783317565918, 1.726866364479065, 1.7184735536575317, 1.7105666399002075, 1.7029982805252075, 1.6929383277893066, 1.6847120523452759, 1.6764376163482666, 1.6661546230316162, 1.6572638750076294, 1.6481366157531738, 1.6437207460403442, 1.62901771068573, 1.619727611541748, 1.610783576965332, 1.6056567430496216, 1.5997707843780518, 1.5845897197723389, 1.5857983827590942, 1.5738359689712524, 1.5732369422912598, 1.5566232204437256, 1.5576730966567993, 1.5407227277755737, 1.5334386825561523, 1.533940315246582, 1.5198599100112915, 1.5139992237091064, 1.5190950632095337, 1.501037836074829, 1.4949818849563599, 1.4912476539611816, 1.489912986755371, 1.4769599437713623, 1.472883939743042, 1.471217155456543, 1.476959466934204, 1.4564645290374756, 1.454171895980835, 1.4563182592391968, 1.4431564807891846, 1.4398075342178345, 1.4318737983703613, 1.426491379737854, 1.418360710144043, 1.4144455194473267, 1.4085909128189087, 1.404334306716919, 1.3999788761138916, 1.3953957557678223, 1.4006946086883545, 1.391905426979065, 1.382826805114746, 1.3792006969451904, 1.3731696605682373, 1.3769725561141968, 1.3660775423049927, 1.3613559007644653, 1.35750150680542, 1.3502964973449707, 1.3473275899887085, 1.3422598838806152, 1.3479070663452148, 1.3338247537612915, 1.3317632675170898, 1.3350387811660767, 1.3370014429092407, 1.3409937620162964, 1.3208749294281006, 1.3180674314498901, 1.3128819465637207, 1.308264970779419, 1.3062785863876343, 1.305504322052002, 1.299318552017212, 1.2953178882598877, 1.317739725112915, 1.2898198366165161, 1.2954479455947876, 1.289306402206421, 1.2841899394989014, 1.2904119491577148, 1.2814136743545532, 1.274965763092041, 1.2776614427566528, 1.2878633737564087, 1.2726460695266724, 1.2737085819244385, 1.2853351831436157, 1.2702223062515259, 1.2737159729003906], 'val_accuracy': [0.5144628286361694, 0.48553720116615295, 0.5692148804664612, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.5609503984451294, 0.4834710657596588, 0.48553720116615295, 0.5795454382896423, 0.5640496015548706, 0.47314050793647766, 0.48553720116615295, 0.5712810158729553, 0.5268595218658447, 0.49793389439582825, 0.567148745059967, 0.5692148804664612, 0.5950413346290588, 0.4948347210884094, 0.5795454382896423, 0.5919421315193176, 0.5898760557174683, 0.5516529083251953, 0.5454545617103577, 0.58574378490448, 0.557851254940033, 0.5599173307418823, 0.5599173307418823, 0.5878099203109741, 0.5681818127632141, 0.5847107172012329, 0.5878099203109741, 0.5795454382896423, 0.5971074104309082, 0.5991735458374023, 0.5692148804664612, 0.5960744023323059, 0.5971074104309082, 0.6012396812438965, 0.5805785059928894, 0.6095041036605835, 0.6115702390670776, 0.6064049601554871, 0.5692148804664612, 0.6095041036605835, 0.6084710955619812, 0.5816115736961365, 0.6115702390670776, 0.5950413346290588, 0.5981404781341553, 0.6022727489471436, 0.6198347210884094, 0.6074380278587341, 0.6229338645935059, 0.6229338645935059, 0.6157024502754211, 0.625, 0.6136363744735718, 0.6208677887916565, 0.6239669322967529, 0.6219007968902588, 0.6198347210884094, 0.5919421315193176, 0.6208677887916565, 0.6157024502754211, 0.6177685856819153, 0.6342975497245789, 0.6260330677032471, 0.6332644820213318, 0.5981404781341553, 0.6394628286361694, 0.6311983466148376, 0.6167355179786682, 0.5950413346290588, 0.58574378490448, 0.6188016533851624, 0.6167355179786682, 0.6219007968902588, 0.6270661354064941, 0.6280992031097412, 0.6208677887916565, 0.6280992031097412, 0.6291322112083435, 0.6012396812438965, 0.6270661354064941, 0.6177685856819153, 0.6239669322967529, 0.6291322112083435, 0.6208677887916565, 0.6280992031097412, 0.6363636255264282, 0.6353305578231812, 0.6012396812438965, 0.6219007968902588, 0.6332644820213318, 0.6126033067703247, 0.6342975497245789, 0.6157024502754211]}\n","32/32 [==============================] - 1s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 1.1771 - accuracy: 0.6904"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 9s 61ms/step - loss: 1.1758 - accuracy: 0.6923 - val_loss: 1.2690 - val_accuracy: 0.5011\n","Epoch 2/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.1632 - accuracy: 0.7050 - val_loss: 1.2631 - val_accuracy: 0.5323\n","Epoch 3/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.1544 - accuracy: 0.6994 - val_loss: 1.2597 - val_accuracy: 0.5032\n","Epoch 4/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1478 - accuracy: 0.7066 - val_loss: 1.2539 - val_accuracy: 0.5280\n","Epoch 5/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1356 - accuracy: 0.7128 - val_loss: 1.2522 - val_accuracy: 0.4968\n","Epoch 6/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.1300 - accuracy: 0.7101 - val_loss: 1.2430 - val_accuracy: 0.5409\n","Epoch 7/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.1202 - accuracy: 0.7276 - val_loss: 1.2368 - val_accuracy: 0.5539\n","Epoch 8/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1101 - accuracy: 0.7266 - val_loss: 1.2355 - val_accuracy: 0.5269\n","Epoch 9/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1089 - accuracy: 0.7190 - val_loss: 1.2334 - val_accuracy: 0.5162\n","Epoch 10/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1032 - accuracy: 0.7249 - val_loss: 1.2251 - val_accuracy: 0.5388\n","Epoch 11/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0921 - accuracy: 0.7398 - val_loss: 1.2213 - val_accuracy: 0.5388\n","Epoch 12/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0904 - accuracy: 0.7190 - val_loss: 1.2125 - val_accuracy: 0.5474\n","Epoch 13/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0825 - accuracy: 0.7355 - val_loss: 1.2154 - val_accuracy: 0.5388\n","Epoch 14/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.0771 - accuracy: 0.7330 - val_loss: 1.2194 - val_accuracy: 0.5345\n","Epoch 15/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.0695 - accuracy: 0.7457 - val_loss: 1.1906 - val_accuracy: 0.6034\n","Epoch 16/100\n","29/29 [==============================] - 1s 31ms/step - loss: 1.0714 - accuracy: 0.7263 - val_loss: 1.1728 - val_accuracy: 0.6379\n","Epoch 17/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.0742 - accuracy: 0.7282 - val_loss: 1.2313 - val_accuracy: 0.5323\n","Epoch 18/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0643 - accuracy: 0.7416 - val_loss: 1.2119 - val_accuracy: 0.5603\n","Epoch 19/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.0512 - accuracy: 0.7398 - val_loss: 1.1642 - val_accuracy: 0.6239\n","Epoch 20/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.0473 - accuracy: 0.7497 - val_loss: 1.1711 - val_accuracy: 0.6207\n","Epoch 21/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.0381 - accuracy: 0.7516 - val_loss: 1.1870 - val_accuracy: 0.6034\n","Epoch 22/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.0337 - accuracy: 0.7524 - val_loss: 1.1502 - val_accuracy: 0.6401\n","Epoch 23/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0248 - accuracy: 0.7546 - val_loss: 1.1792 - val_accuracy: 0.6164\n","Epoch 24/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.0222 - accuracy: 0.7651 - val_loss: 1.1488 - val_accuracy: 0.6509\n","Epoch 25/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0115 - accuracy: 0.7600 - val_loss: 1.1606 - val_accuracy: 0.6358\n","Epoch 26/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0117 - accuracy: 0.7600 - val_loss: 1.1664 - val_accuracy: 0.6347\n","Epoch 27/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.0039 - accuracy: 0.7600 - val_loss: 1.1497 - val_accuracy: 0.6584\n","Epoch 28/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0034 - accuracy: 0.7573 - val_loss: 1.1550 - val_accuracy: 0.6466\n","Epoch 29/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9973 - accuracy: 0.7683 - val_loss: 1.1558 - val_accuracy: 0.6519\n","Epoch 30/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9900 - accuracy: 0.7675 - val_loss: 1.1627 - val_accuracy: 0.6412\n","Epoch 31/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9881 - accuracy: 0.7694 - val_loss: 1.1558 - val_accuracy: 0.6541\n","Epoch 32/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9818 - accuracy: 0.7683 - val_loss: 1.1532 - val_accuracy: 0.6552\n","Epoch 33/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9735 - accuracy: 0.7737 - val_loss: 1.1548 - val_accuracy: 0.6498\n","Epoch 34/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9690 - accuracy: 0.7748 - val_loss: 1.1572 - val_accuracy: 0.6519\n","Epoch 35/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9643 - accuracy: 0.7815 - val_loss: 1.1574 - val_accuracy: 0.6487\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9599 - accuracy: 0.7799 - val_loss: 1.1564 - val_accuracy: 0.6509\n","Epoch 37/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9517 - accuracy: 0.7802 - val_loss: 1.1618 - val_accuracy: 0.6422\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9464 - accuracy: 0.7815 - val_loss: 1.2034 - val_accuracy: 0.6239\n","Epoch 39/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9531 - accuracy: 0.7761 - val_loss: 1.1778 - val_accuracy: 0.6379\n","Epoch 40/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9457 - accuracy: 0.7810 - val_loss: 1.1528 - val_accuracy: 0.6509\n","Epoch 41/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9296 - accuracy: 0.7901 - val_loss: 1.1584 - val_accuracy: 0.6369\n","Epoch 42/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9333 - accuracy: 0.7891 - val_loss: 1.1690 - val_accuracy: 0.6401\n","Epoch 43/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.9280 - accuracy: 0.7885 - val_loss: 1.2170 - val_accuracy: 0.6078\n","Epoch 44/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.9332 - accuracy: 0.7807 - val_loss: 1.1503 - val_accuracy: 0.6519\n","Epoch 45/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9124 - accuracy: 0.7931 - val_loss: 1.1651 - val_accuracy: 0.6422\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9131 - accuracy: 0.7990 - val_loss: 1.1630 - val_accuracy: 0.6379\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9093 - accuracy: 0.7864 - val_loss: 1.1572 - val_accuracy: 0.6530\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9116 - accuracy: 0.7901 - val_loss: 1.1669 - val_accuracy: 0.6444\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8997 - accuracy: 0.7953 - val_loss: 1.1619 - val_accuracy: 0.6509\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8851 - accuracy: 0.8085 - val_loss: 1.1527 - val_accuracy: 0.6476\n","Epoch 51/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8826 - accuracy: 0.8082 - val_loss: 1.1557 - val_accuracy: 0.6498\n","Epoch 52/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8750 - accuracy: 0.8130 - val_loss: 1.1617 - val_accuracy: 0.6487\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8780 - accuracy: 0.8085 - val_loss: 1.1605 - val_accuracy: 0.6466\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8680 - accuracy: 0.8160 - val_loss: 1.1568 - val_accuracy: 0.6509\n","Epoch 55/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8650 - accuracy: 0.8082 - val_loss: 1.1729 - val_accuracy: 0.6347\n","Epoch 56/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8593 - accuracy: 0.8144 - val_loss: 1.1618 - val_accuracy: 0.6455\n","Epoch 57/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8595 - accuracy: 0.8160 - val_loss: 1.1848 - val_accuracy: 0.6369\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8600 - accuracy: 0.8114 - val_loss: 1.1753 - val_accuracy: 0.6422\n","Epoch 59/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8463 - accuracy: 0.8187 - val_loss: 1.1766 - val_accuracy: 0.6433\n","Epoch 60/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8404 - accuracy: 0.8144 - val_loss: 1.1704 - val_accuracy: 0.6412\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8279 - accuracy: 0.8311 - val_loss: 1.1747 - val_accuracy: 0.6519\n","Epoch 62/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8282 - accuracy: 0.8206 - val_loss: 1.1804 - val_accuracy: 0.6476\n","Epoch 63/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8219 - accuracy: 0.8305 - val_loss: 1.1856 - val_accuracy: 0.6347\n","Epoch 64/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8109 - accuracy: 0.8432 - val_loss: 1.1781 - val_accuracy: 0.6466\n","Epoch 65/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8105 - accuracy: 0.8303 - val_loss: 1.2030 - val_accuracy: 0.6487\n","Epoch 66/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8063 - accuracy: 0.8397 - val_loss: 1.1858 - val_accuracy: 0.6444\n","Epoch 67/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8130 - accuracy: 0.8281 - val_loss: 1.1907 - val_accuracy: 0.6476\n","Epoch 68/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8230 - accuracy: 0.8276 - val_loss: 1.1784 - val_accuracy: 0.6412\n","Epoch 69/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.7884 - accuracy: 0.8470 - val_loss: 1.1811 - val_accuracy: 0.6401\n","Epoch 70/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7907 - accuracy: 0.8440 - val_loss: 1.1905 - val_accuracy: 0.6422\n","Epoch 71/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7837 - accuracy: 0.8397 - val_loss: 1.1926 - val_accuracy: 0.6466\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7728 - accuracy: 0.8497 - val_loss: 1.2035 - val_accuracy: 0.6304\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7754 - accuracy: 0.8429 - val_loss: 1.2133 - val_accuracy: 0.6261\n","Epoch 74/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7675 - accuracy: 0.8540 - val_loss: 1.2070 - val_accuracy: 0.6466\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7837 - accuracy: 0.8424 - val_loss: 1.2507 - val_accuracy: 0.6530\n","Epoch 76/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7895 - accuracy: 0.8376 - val_loss: 1.1987 - val_accuracy: 0.6455\n","Epoch 77/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7640 - accuracy: 0.8513 - val_loss: 1.2178 - val_accuracy: 0.6218\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7734 - accuracy: 0.8475 - val_loss: 1.2017 - val_accuracy: 0.6530\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7470 - accuracy: 0.8677 - val_loss: 1.2003 - val_accuracy: 0.6422\n","Epoch 80/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7382 - accuracy: 0.8642 - val_loss: 1.2141 - val_accuracy: 0.6347\n","Epoch 81/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7404 - accuracy: 0.8567 - val_loss: 1.2201 - val_accuracy: 0.6422\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7539 - accuracy: 0.8567 - val_loss: 1.2286 - val_accuracy: 0.6476\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7361 - accuracy: 0.8653 - val_loss: 1.2111 - val_accuracy: 0.6476\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7242 - accuracy: 0.8645 - val_loss: 1.2171 - val_accuracy: 0.6390\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7092 - accuracy: 0.8785 - val_loss: 1.2443 - val_accuracy: 0.6466\n","Epoch 86/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7210 - accuracy: 0.8658 - val_loss: 1.2486 - val_accuracy: 0.6347\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7301 - accuracy: 0.8607 - val_loss: 1.2294 - val_accuracy: 0.6433\n","Epoch 88/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7039 - accuracy: 0.8737 - val_loss: 1.2511 - val_accuracy: 0.6433\n","Epoch 89/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7072 - accuracy: 0.8750 - val_loss: 1.2523 - val_accuracy: 0.6282\n","Epoch 90/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7006 - accuracy: 0.8769 - val_loss: 1.2417 - val_accuracy: 0.6433\n","Epoch 91/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6885 - accuracy: 0.8788 - val_loss: 1.2516 - val_accuracy: 0.6412\n","Epoch 92/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6861 - accuracy: 0.8798 - val_loss: 1.2550 - val_accuracy: 0.6422\n","Epoch 93/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6788 - accuracy: 0.8817 - val_loss: 1.2674 - val_accuracy: 0.6444\n","Epoch 94/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6814 - accuracy: 0.8858 - val_loss: 1.2642 - val_accuracy: 0.6369\n","Epoch 95/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6833 - accuracy: 0.8788 - val_loss: 1.2617 - val_accuracy: 0.6455\n","Epoch 96/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6702 - accuracy: 0.8874 - val_loss: 1.2761 - val_accuracy: 0.6379\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6765 - accuracy: 0.8798 - val_loss: 1.2797 - val_accuracy: 0.6466\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6640 - accuracy: 0.8847 - val_loss: 1.3041 - val_accuracy: 0.6455\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6714 - accuracy: 0.8807 - val_loss: 1.2998 - val_accuracy: 0.6218\n","Epoch 100/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6723 - accuracy: 0.8766 - val_loss: 1.2893 - val_accuracy: 0.6433\n","{'loss': [1.1757787466049194, 1.1631813049316406, 1.154375433921814, 1.147757649421692, 1.1355996131896973, 1.130010724067688, 1.1201835870742798, 1.1101292371749878, 1.1088669300079346, 1.1031882762908936, 1.0921279191970825, 1.0903775691986084, 1.0824782848358154, 1.0771054029464722, 1.0695382356643677, 1.071392297744751, 1.074212908744812, 1.0642725229263306, 1.0512028932571411, 1.0472604036331177, 1.038090705871582, 1.0337425470352173, 1.0248026847839355, 1.022181749343872, 1.011538028717041, 1.0116759538650513, 1.003867268562317, 1.0033657550811768, 0.9972949624061584, 0.9900073409080505, 0.9881186485290527, 0.9818090200424194, 0.9735466241836548, 0.9690219163894653, 0.9642707109451294, 0.9598842859268188, 0.951748788356781, 0.9464386701583862, 0.9530801177024841, 0.9457376599311829, 0.9296367764472961, 0.9333473443984985, 0.9280197024345398, 0.9331714510917664, 0.9124010801315308, 0.9130780696868896, 0.9092700481414795, 0.9116230010986328, 0.8997499346733093, 0.8850902318954468, 0.8825832009315491, 0.8749677538871765, 0.877996563911438, 0.8680121898651123, 0.8649919629096985, 0.8592854738235474, 0.859531819820404, 0.860023558139801, 0.8463290929794312, 0.8403843641281128, 0.8279109597206116, 0.8281530737876892, 0.8219141960144043, 0.8108760118484497, 0.8104739189147949, 0.806253969669342, 0.8130459785461426, 0.822950541973114, 0.7884438037872314, 0.7907223105430603, 0.7837401032447815, 0.7728058099746704, 0.775447428226471, 0.767509937286377, 0.7836693525314331, 0.7894725203514099, 0.7640267014503479, 0.7734100818634033, 0.7469774484634399, 0.7382083535194397, 0.7404427528381348, 0.7539273500442505, 0.7360870838165283, 0.7242051362991333, 0.7091702818870544, 0.7209949493408203, 0.7301376461982727, 0.7039344906806946, 0.7072457075119019, 0.7005953788757324, 0.6885387301445007, 0.6860936284065247, 0.6788044571876526, 0.6813692450523376, 0.6832634210586548, 0.6702476739883423, 0.6764914393424988, 0.6640337705612183, 0.6713962554931641, 0.6723428964614868], 'accuracy': [0.6923491358757019, 0.7050107717514038, 0.6993534564971924, 0.7066271305084229, 0.7128232717514038, 0.7101293206214905, 0.7276400923728943, 0.7265625, 0.7190194129943848, 0.724946141242981, 0.7397629022598267, 0.7190194129943848, 0.7354525923728943, 0.733027994632721, 0.7456896305084229, 0.7262930870056152, 0.728178858757019, 0.7416487336158752, 0.7397629022598267, 0.7497305870056152, 0.751616358757019, 0.7524245977401733, 0.7545797228813171, 0.7650862336158752, 0.7599676847457886, 0.7599676847457886, 0.7599676847457886, 0.7572737336158752, 0.7683189511299133, 0.7675107717514038, 0.7693965435028076, 0.7683189511299133, 0.7737069129943848, 0.774784505367279, 0.7815194129943848, 0.779902994632721, 0.7801724076271057, 0.7815194129943848, 0.7761314511299133, 0.7809805870056152, 0.7901400923728943, 0.7890625, 0.7885237336158752, 0.7807112336158752, 0.7931034564971924, 0.7990301847457886, 0.7863685488700867, 0.7901400923728943, 0.795258641242981, 0.8084590435028076, 0.8081896305084229, 0.8130387663841248, 0.8084590435028076, 0.8160021305084229, 0.8081896305084229, 0.8143857717514038, 0.8160021305084229, 0.8114224076271057, 0.818696141242981, 0.8143857717514038, 0.8310883641242981, 0.8205819129943848, 0.8305495977401733, 0.8432112336158752, 0.8302801847457886, 0.8397090435028076, 0.828125, 0.8275862336158752, 0.8469827771186829, 0.8440194129943848, 0.8397090435028076, 0.8496767282485962, 0.8429418206214905, 0.8539870977401733, 0.842402994632721, 0.837553858757019, 0.8512930870056152, 0.8475215435028076, 0.8677262663841248, 0.8642241358757019, 0.8566810488700867, 0.8566810488700867, 0.8653017282485962, 0.8644935488700867, 0.8785021305084229, 0.865840494632721, 0.860722005367279, 0.873652994632721, 0.875, 0.8768857717514038, 0.8787715435028076, 0.8798491358757019, 0.8817349076271057, 0.8857758641242981, 0.8787715435028076, 0.8873922228813171, 0.8798491358757019, 0.8846982717514038, 0.8806573152542114, 0.876616358757019], 'val_loss': [1.2689664363861084, 1.2631222009658813, 1.259650707244873, 1.2539136409759521, 1.2521963119506836, 1.243016004562378, 1.236829161643982, 1.2355399131774902, 1.233404278755188, 1.2251007556915283, 1.22129225730896, 1.212519645690918, 1.2153600454330444, 1.2194406986236572, 1.1905887126922607, 1.1728109121322632, 1.2313376665115356, 1.2119132280349731, 1.1641855239868164, 1.1710752248764038, 1.187005639076233, 1.1501888036727905, 1.179197072982788, 1.148846983909607, 1.16061532497406, 1.166372537612915, 1.14970064163208, 1.1549773216247559, 1.155768632888794, 1.1626940965652466, 1.1557831764221191, 1.1531636714935303, 1.1548329591751099, 1.1572431325912476, 1.1573971509933472, 1.1564005613327026, 1.1618084907531738, 1.2033525705337524, 1.1777939796447754, 1.1528149843215942, 1.1584079265594482, 1.1689727306365967, 1.216976284980774, 1.1502524614334106, 1.1651296615600586, 1.162990927696228, 1.1572084426879883, 1.166862964630127, 1.1618515253067017, 1.1527050733566284, 1.155727505683899, 1.1617344617843628, 1.160547137260437, 1.1568478345870972, 1.1729152202606201, 1.1618229150772095, 1.1847542524337769, 1.175276279449463, 1.1766074895858765, 1.1704148054122925, 1.1746681928634644, 1.1803689002990723, 1.1856207847595215, 1.178094506263733, 1.2030291557312012, 1.1857683658599854, 1.1907012462615967, 1.178382396697998, 1.1811304092407227, 1.1904746294021606, 1.192636251449585, 1.2035385370254517, 1.2132973670959473, 1.2069767713546753, 1.2506608963012695, 1.1987019777297974, 1.2177760601043701, 1.20171058177948, 1.200289011001587, 1.2141214609146118, 1.2200734615325928, 1.228602409362793, 1.2110979557037354, 1.2170723676681519, 1.244305968284607, 1.248557209968567, 1.2293596267700195, 1.2510583400726318, 1.252310037612915, 1.2416660785675049, 1.251556634902954, 1.255009412765503, 1.2674463987350464, 1.2642147541046143, 1.2616864442825317, 1.2761014699935913, 1.279690146446228, 1.3040874004364014, 1.2997814416885376, 1.2893425226211548], 'val_accuracy': [0.5010775923728943, 0.5323275923728943, 0.5032327771186829, 0.5280172228813171, 0.4967672526836395, 0.5409482717514038, 0.5538793206214905, 0.5269396305084229, 0.5161637663841248, 0.5387930870056152, 0.5387930870056152, 0.5474137663841248, 0.5387930870056152, 0.5344827771186829, 0.6034482717514038, 0.6379310488700867, 0.5323275923728943, 0.5603448152542114, 0.6239224076271057, 0.6206896305084229, 0.6034482717514038, 0.6400862336158752, 0.6163793206214905, 0.6508620977401733, 0.6357758641242981, 0.6346982717514038, 0.6584051847457886, 0.6465517282485962, 0.6519396305084229, 0.6411637663841248, 0.6540948152542114, 0.6551724076271057, 0.649784505367279, 0.6519396305084229, 0.6487069129943848, 0.6508620977401733, 0.642241358757019, 0.6239224076271057, 0.6379310488700867, 0.6508620977401733, 0.6368534564971924, 0.6400862336158752, 0.607758641242981, 0.6519396305084229, 0.642241358757019, 0.6379310488700867, 0.6530172228813171, 0.6443965435028076, 0.6508620977401733, 0.6476293206214905, 0.649784505367279, 0.6487069129943848, 0.6465517282485962, 0.6508620977401733, 0.6346982717514038, 0.6454741358757019, 0.6368534564971924, 0.642241358757019, 0.6433189511299133, 0.6411637663841248, 0.6519396305084229, 0.6476293206214905, 0.6346982717514038, 0.6465517282485962, 0.6487069129943848, 0.6443965435028076, 0.6476293206214905, 0.6411637663841248, 0.6400862336158752, 0.642241358757019, 0.6465517282485962, 0.6303879022598267, 0.6260775923728943, 0.6465517282485962, 0.6530172228813171, 0.6454741358757019, 0.6217672228813171, 0.6530172228813171, 0.642241358757019, 0.6346982717514038, 0.642241358757019, 0.6476293206214905, 0.6476293206214905, 0.639008641242981, 0.6465517282485962, 0.6346982717514038, 0.6433189511299133, 0.6433189511299133, 0.6282327771186829, 0.6433189511299133, 0.6411637663841248, 0.642241358757019, 0.6443965435028076, 0.6368534564971924, 0.6454741358757019, 0.6379310488700867, 0.6465517282485962, 0.6454741358757019, 0.6217672228813171, 0.6433189511299133]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 1.1882 - accuracy: 0.6734"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 109ms/step - loss: 1.1870 - accuracy: 0.6740 - val_loss: 1.2683 - val_accuracy: 0.5226\n","Epoch 2/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.1646 - accuracy: 0.6986 - val_loss: 1.2636 - val_accuracy: 0.5226\n","Epoch 3/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.1585 - accuracy: 0.7018 - val_loss: 1.2580 - val_accuracy: 0.5928\n","Epoch 4/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1659 - accuracy: 0.6800 - val_loss: 1.2554 - val_accuracy: 0.5124\n","Epoch 5/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1478 - accuracy: 0.7020 - val_loss: 1.2496 - val_accuracy: 0.5419\n","Epoch 6/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1367 - accuracy: 0.7128 - val_loss: 1.2455 - val_accuracy: 0.5317\n","Epoch 7/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1320 - accuracy: 0.7114 - val_loss: 1.2407 - val_accuracy: 0.5362\n","Epoch 8/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1259 - accuracy: 0.7100 - val_loss: 1.2393 - val_accuracy: 0.5124\n","Epoch 9/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1200 - accuracy: 0.7091 - val_loss: 1.2321 - val_accuracy: 0.5396\n","Epoch 10/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1092 - accuracy: 0.7238 - val_loss: 1.2238 - val_accuracy: 0.5498\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1112 - accuracy: 0.7168 - val_loss: 1.2203 - val_accuracy: 0.5464\n","Epoch 12/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1032 - accuracy: 0.7156 - val_loss: 1.2140 - val_accuracy: 0.5520\n","Epoch 13/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0939 - accuracy: 0.7301 - val_loss: 1.2244 - val_accuracy: 0.5294\n","Epoch 14/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.0900 - accuracy: 0.7281 - val_loss: 1.1971 - val_accuracy: 0.6075\n","Epoch 15/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0891 - accuracy: 0.7196 - val_loss: 1.2016 - val_accuracy: 0.5566\n","Epoch 16/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.0793 - accuracy: 0.7284 - val_loss: 1.1868 - val_accuracy: 0.6097\n","Epoch 17/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0725 - accuracy: 0.7346 - val_loss: 1.1845 - val_accuracy: 0.6075\n","Epoch 18/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0656 - accuracy: 0.7388 - val_loss: 1.1930 - val_accuracy: 0.5792\n","Epoch 19/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.0607 - accuracy: 0.7388 - val_loss: 1.1799 - val_accuracy: 0.6052\n","Epoch 20/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.0597 - accuracy: 0.7374 - val_loss: 1.1896 - val_accuracy: 0.5995\n","Epoch 21/100\n","28/28 [==============================] - 1s 32ms/step - loss: 1.0468 - accuracy: 0.7501 - val_loss: 1.1617 - val_accuracy: 0.6278\n","Epoch 22/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.0421 - accuracy: 0.7417 - val_loss: 1.1900 - val_accuracy: 0.6029\n","Epoch 23/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.0359 - accuracy: 0.7493 - val_loss: 1.1721 - val_accuracy: 0.6165\n","Epoch 24/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.0349 - accuracy: 0.7470 - val_loss: 1.1940 - val_accuracy: 0.6029\n","Epoch 25/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.0297 - accuracy: 0.7436 - val_loss: 1.1534 - val_accuracy: 0.6414\n","Epoch 26/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0269 - accuracy: 0.7550 - val_loss: 1.2053 - val_accuracy: 0.6075\n","Epoch 27/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0189 - accuracy: 0.7555 - val_loss: 1.1547 - val_accuracy: 0.6414\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0129 - accuracy: 0.7581 - val_loss: 1.1582 - val_accuracy: 0.6391\n","Epoch 29/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0102 - accuracy: 0.7566 - val_loss: 1.1595 - val_accuracy: 0.6380\n","Epoch 30/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0035 - accuracy: 0.7572 - val_loss: 1.1613 - val_accuracy: 0.6346\n","Epoch 31/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9912 - accuracy: 0.7666 - val_loss: 1.1676 - val_accuracy: 0.6199\n","Epoch 32/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9898 - accuracy: 0.7629 - val_loss: 1.1687 - val_accuracy: 0.6256\n","Epoch 33/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.9925 - accuracy: 0.7595 - val_loss: 1.1610 - val_accuracy: 0.6493\n","Epoch 34/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.9858 - accuracy: 0.7626 - val_loss: 1.1706 - val_accuracy: 0.6538\n","Epoch 35/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9795 - accuracy: 0.7634 - val_loss: 1.1636 - val_accuracy: 0.6335\n","Epoch 36/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9707 - accuracy: 0.7756 - val_loss: 1.1896 - val_accuracy: 0.6369\n","Epoch 37/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9728 - accuracy: 0.7688 - val_loss: 1.1695 - val_accuracy: 0.6210\n","Epoch 38/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9550 - accuracy: 0.7827 - val_loss: 1.1636 - val_accuracy: 0.6414\n","Epoch 39/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9585 - accuracy: 0.7736 - val_loss: 1.1625 - val_accuracy: 0.6437\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9499 - accuracy: 0.7855 - val_loss: 1.1683 - val_accuracy: 0.6482\n","Epoch 41/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9473 - accuracy: 0.7750 - val_loss: 1.1627 - val_accuracy: 0.6357\n","Epoch 42/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9408 - accuracy: 0.7807 - val_loss: 1.1665 - val_accuracy: 0.6414\n","Epoch 43/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9348 - accuracy: 0.7903 - val_loss: 1.1691 - val_accuracy: 0.6414\n","Epoch 44/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9295 - accuracy: 0.7886 - val_loss: 1.1804 - val_accuracy: 0.6448\n","Epoch 45/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9383 - accuracy: 0.7813 - val_loss: 1.1809 - val_accuracy: 0.6165\n","Epoch 46/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9318 - accuracy: 0.7821 - val_loss: 1.1735 - val_accuracy: 0.6493\n","Epoch 47/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9167 - accuracy: 0.7980 - val_loss: 1.1626 - val_accuracy: 0.6335\n","Epoch 48/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9190 - accuracy: 0.7937 - val_loss: 1.1628 - val_accuracy: 0.6357\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9063 - accuracy: 0.8011 - val_loss: 1.1741 - val_accuracy: 0.6369\n","Epoch 50/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9108 - accuracy: 0.7923 - val_loss: 1.1717 - val_accuracy: 0.6256\n","Epoch 51/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9026 - accuracy: 0.7980 - val_loss: 1.1662 - val_accuracy: 0.6324\n","Epoch 52/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8991 - accuracy: 0.7980 - val_loss: 1.1638 - val_accuracy: 0.6369\n","Epoch 53/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8901 - accuracy: 0.8025 - val_loss: 1.1663 - val_accuracy: 0.6380\n","Epoch 54/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8874 - accuracy: 0.8019 - val_loss: 1.1674 - val_accuracy: 0.6380\n","Epoch 55/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8828 - accuracy: 0.8019 - val_loss: 1.1702 - val_accuracy: 0.6312\n","Epoch 56/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8790 - accuracy: 0.8025 - val_loss: 1.1974 - val_accuracy: 0.6380\n","Epoch 57/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8729 - accuracy: 0.8062 - val_loss: 1.1731 - val_accuracy: 0.6357\n","Epoch 58/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8656 - accuracy: 0.8172 - val_loss: 1.1779 - val_accuracy: 0.6312\n","Epoch 59/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8507 - accuracy: 0.8183 - val_loss: 1.1786 - val_accuracy: 0.6380\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8464 - accuracy: 0.8277 - val_loss: 1.1907 - val_accuracy: 0.6312\n","Epoch 61/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8595 - accuracy: 0.8079 - val_loss: 1.1820 - val_accuracy: 0.6380\n","Epoch 62/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8439 - accuracy: 0.8203 - val_loss: 1.1906 - val_accuracy: 0.6346\n","Epoch 63/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8433 - accuracy: 0.8214 - val_loss: 1.2073 - val_accuracy: 0.6267\n","Epoch 64/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8531 - accuracy: 0.8158 - val_loss: 1.1825 - val_accuracy: 0.6335\n","Epoch 65/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8324 - accuracy: 0.8263 - val_loss: 1.1838 - val_accuracy: 0.6335\n","Epoch 66/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8289 - accuracy: 0.8229 - val_loss: 1.1903 - val_accuracy: 0.6233\n","Epoch 67/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8253 - accuracy: 0.8260 - val_loss: 1.1872 - val_accuracy: 0.6278\n","Epoch 68/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8135 - accuracy: 0.8356 - val_loss: 1.2081 - val_accuracy: 0.6233\n","Epoch 69/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8211 - accuracy: 0.8263 - val_loss: 1.1944 - val_accuracy: 0.6233\n","Epoch 70/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8026 - accuracy: 0.8381 - val_loss: 1.1976 - val_accuracy: 0.6233\n","Epoch 71/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7958 - accuracy: 0.8367 - val_loss: 1.2245 - val_accuracy: 0.6097\n","Epoch 72/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8224 - accuracy: 0.8220 - val_loss: 1.2094 - val_accuracy: 0.6244\n","Epoch 73/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7941 - accuracy: 0.8444 - val_loss: 1.2054 - val_accuracy: 0.6154\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7885 - accuracy: 0.8410 - val_loss: 1.2053 - val_accuracy: 0.6256\n","Epoch 75/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7845 - accuracy: 0.8418 - val_loss: 1.2096 - val_accuracy: 0.6278\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7794 - accuracy: 0.8509 - val_loss: 1.2276 - val_accuracy: 0.6143\n","Epoch 77/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7714 - accuracy: 0.8492 - val_loss: 1.2122 - val_accuracy: 0.6256\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7627 - accuracy: 0.8557 - val_loss: 1.2208 - val_accuracy: 0.6143\n","Epoch 79/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7652 - accuracy: 0.8529 - val_loss: 1.2325 - val_accuracy: 0.6176\n","Epoch 80/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7756 - accuracy: 0.8438 - val_loss: 1.2605 - val_accuracy: 0.6188\n","Epoch 81/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7527 - accuracy: 0.8563 - val_loss: 1.2317 - val_accuracy: 0.6188\n","Epoch 82/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7417 - accuracy: 0.8664 - val_loss: 1.2449 - val_accuracy: 0.6278\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7453 - accuracy: 0.8596 - val_loss: 1.2412 - val_accuracy: 0.6199\n","Epoch 84/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7536 - accuracy: 0.8540 - val_loss: 1.2378 - val_accuracy: 0.6222\n","Epoch 85/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7359 - accuracy: 0.8633 - val_loss: 1.2461 - val_accuracy: 0.6222\n","Epoch 86/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7361 - accuracy: 0.8599 - val_loss: 1.2453 - val_accuracy: 0.6086\n","Epoch 87/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7366 - accuracy: 0.8630 - val_loss: 1.2499 - val_accuracy: 0.6143\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7275 - accuracy: 0.8701 - val_loss: 1.2540 - val_accuracy: 0.6109\n","Epoch 89/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7174 - accuracy: 0.8732 - val_loss: 1.2515 - val_accuracy: 0.6097\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7161 - accuracy: 0.8738 - val_loss: 1.2591 - val_accuracy: 0.6143\n","Epoch 91/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7187 - accuracy: 0.8667 - val_loss: 1.2729 - val_accuracy: 0.6154\n","Epoch 92/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7023 - accuracy: 0.8758 - val_loss: 1.2562 - val_accuracy: 0.6075\n","Epoch 93/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6984 - accuracy: 0.8797 - val_loss: 1.2862 - val_accuracy: 0.6165\n","Epoch 94/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6988 - accuracy: 0.8772 - val_loss: 1.2707 - val_accuracy: 0.6120\n","Epoch 95/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6897 - accuracy: 0.8823 - val_loss: 1.2820 - val_accuracy: 0.6165\n","Epoch 96/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6899 - accuracy: 0.8854 - val_loss: 1.3014 - val_accuracy: 0.6143\n","Epoch 97/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6780 - accuracy: 0.8879 - val_loss: 1.2885 - val_accuracy: 0.6097\n","Epoch 98/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6664 - accuracy: 0.8933 - val_loss: 1.2977 - val_accuracy: 0.6131\n","Epoch 99/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6698 - accuracy: 0.8834 - val_loss: 1.2911 - val_accuracy: 0.6131\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6684 - accuracy: 0.8916 - val_loss: 1.3179 - val_accuracy: 0.6109\n","{'loss': [1.1870403289794922, 1.1645915508270264, 1.158466100692749, 1.1659168004989624, 1.1477735042572021, 1.136696696281433, 1.1319977045059204, 1.1259236335754395, 1.120003342628479, 1.109185814857483, 1.1111890077590942, 1.1031900644302368, 1.0939277410507202, 1.090027093887329, 1.0891380310058594, 1.0793066024780273, 1.0725377798080444, 1.065579891204834, 1.0607348680496216, 1.05968177318573, 1.046796441078186, 1.0421334505081177, 1.0358954668045044, 1.0349034070968628, 1.0297049283981323, 1.026898741722107, 1.0189253091812134, 1.0128792524337769, 1.010244607925415, 1.0035114288330078, 0.9912227392196655, 0.9898478388786316, 0.9924660325050354, 0.9857659935951233, 0.9794909358024597, 0.9707240462303162, 0.9727513790130615, 0.9550425410270691, 0.9585188031196594, 0.9499210715293884, 0.9472691416740417, 0.9407790303230286, 0.9348132610321045, 0.9294558763504028, 0.9382607340812683, 0.9318270683288574, 0.9166801571846008, 0.9190219044685364, 0.9062778949737549, 0.9108452200889587, 0.9025657176971436, 0.8991150259971619, 0.8900525569915771, 0.8873583078384399, 0.8828470706939697, 0.8789716958999634, 0.8728967308998108, 0.8655842542648315, 0.8506806492805481, 0.8464162945747375, 0.8595088720321655, 0.8438684940338135, 0.8432959914207458, 0.8530929088592529, 0.8323918581008911, 0.8288854956626892, 0.8252527117729187, 0.813490629196167, 0.8211009502410889, 0.802561342716217, 0.7958117127418518, 0.8223819136619568, 0.7940788269042969, 0.7884708642959595, 0.7845039367675781, 0.7793843150138855, 0.7713754177093506, 0.7627003788948059, 0.7651914954185486, 0.7756240367889404, 0.752749502658844, 0.7417380213737488, 0.7453314065933228, 0.7535867691040039, 0.7359390258789062, 0.7360592484474182, 0.7365502715110779, 0.7275048494338989, 0.717387855052948, 0.7161181569099426, 0.7186851501464844, 0.7022753357887268, 0.6984097361564636, 0.6987650990486145, 0.6897185444831848, 0.6899291276931763, 0.6779682636260986, 0.6663748025894165, 0.6698253154754639, 0.6683758497238159], 'accuracy': [0.6740237474441528, 0.6986417770385742, 0.7017543911933899, 0.6799660325050354, 0.7020373344421387, 0.7127900123596191, 0.7113752365112305, 0.709960401058197, 0.7091115117073059, 0.7238256931304932, 0.7167515754699707, 0.715619683265686, 0.7300509214401245, 0.7280701994895935, 0.7195811867713928, 0.7283531427383423, 0.7345783710479736, 0.738822877407074, 0.738822877407074, 0.7374080419540405, 0.7501415014266968, 0.7416524887084961, 0.7492926120758057, 0.7470288872718811, 0.7436332702636719, 0.7549518942832947, 0.755517840385437, 0.7580645084381104, 0.7566496729850769, 0.7572156190872192, 0.7665534615516663, 0.7628749012947083, 0.7594793438911438, 0.7625919580459595, 0.7634408473968506, 0.7756083607673645, 0.7688171863555908, 0.7826825380325317, 0.7736276388168335, 0.7855121493339539, 0.7750424742698669, 0.780701756477356, 0.7903226017951965, 0.7886247634887695, 0.7812677025794983, 0.7821165919303894, 0.7979626655578613, 0.793718159198761, 0.801075279712677, 0.7923033237457275, 0.7979626655578613, 0.7979626655578613, 0.8024901151657104, 0.8019241690635681, 0.8019241690635681, 0.8024901151657104, 0.8061686754226685, 0.8172042965888977, 0.8183361887931824, 0.8276740312576294, 0.8078664541244507, 0.8203169107437134, 0.821448802947998, 0.8157894611358643, 0.826259195804596, 0.8228636384010315, 0.8259762525558472, 0.835597038269043, 0.826259195804596, 0.8381437659263611, 0.8367289304733276, 0.8220146894454956, 0.8443689942359924, 0.8409733772277832, 0.8418223261833191, 0.8508771657943726, 0.8491793870925903, 0.8556876182556152, 0.8528579473495483, 0.8438030481338501, 0.8562535643577576, 0.8664402961730957, 0.859649121761322, 0.853989839553833, 0.86332768201828, 0.8599320650100708, 0.8630446791648865, 0.8701188564300537, 0.8732314705848694, 0.8737974166870117, 0.8667232394218445, 0.8757781386375427, 0.8797396421432495, 0.8771929740905762, 0.8822863698005676, 0.8853989839553833, 0.8879456520080566, 0.8933219909667969, 0.8834182024002075, 0.8916242122650146], 'val_loss': [1.2682511806488037, 1.2636290788650513, 1.2579909563064575, 1.2554357051849365, 1.2496311664581299, 1.2455112934112549, 1.240689754486084, 1.2393289804458618, 1.2321213483810425, 1.2238359451293945, 1.22028386592865, 1.2140244245529175, 1.2244338989257812, 1.1970762014389038, 1.2015970945358276, 1.1867990493774414, 1.1845154762268066, 1.1930227279663086, 1.1799147129058838, 1.189611554145813, 1.1616675853729248, 1.189954161643982, 1.1720843315124512, 1.1940410137176514, 1.1533854007720947, 1.205277681350708, 1.1547120809555054, 1.1582330465316772, 1.159530758857727, 1.1613115072250366, 1.1676000356674194, 1.1686738729476929, 1.1610490083694458, 1.170573115348816, 1.163608431816101, 1.1895935535430908, 1.1694647073745728, 1.1635639667510986, 1.1625005006790161, 1.1683353185653687, 1.1626836061477661, 1.1665019989013672, 1.169089913368225, 1.180365800857544, 1.180901288986206, 1.1735285520553589, 1.1625748872756958, 1.162815809249878, 1.1740858554840088, 1.1717007160186768, 1.1662342548370361, 1.163788080215454, 1.166298270225525, 1.167362093925476, 1.1701868772506714, 1.1973501443862915, 1.1730698347091675, 1.1779162883758545, 1.1785935163497925, 1.1907453536987305, 1.1819798946380615, 1.1905518770217896, 1.2073192596435547, 1.1824673414230347, 1.1837984323501587, 1.1903139352798462, 1.1871631145477295, 1.2080744504928589, 1.1943525075912476, 1.1975992918014526, 1.2245311737060547, 1.2093887329101562, 1.2053701877593994, 1.205324649810791, 1.209614872932434, 1.2275981903076172, 1.2122409343719482, 1.2208434343338013, 1.2324753999710083, 1.2605395317077637, 1.2316906452178955, 1.244899868965149, 1.2412463426589966, 1.2377887964248657, 1.2461414337158203, 1.2453159093856812, 1.249871015548706, 1.2540273666381836, 1.2515487670898438, 1.2590867280960083, 1.2729387283325195, 1.256203532218933, 1.2862468957901, 1.2707319259643555, 1.281982421875, 1.3013917207717896, 1.2885282039642334, 1.297701358795166, 1.2911243438720703, 1.3178669214248657], 'val_accuracy': [0.5226244330406189, 0.5226244330406189, 0.5927602052688599, 0.5124434232711792, 0.5418552160263062, 0.5316742062568665, 0.5361990928649902, 0.5124434232711792, 0.5395927429199219, 0.5497737526893616, 0.5463801026344299, 0.5520362257957458, 0.529411792755127, 0.6074660420417786, 0.5565611124038696, 0.6097285151481628, 0.6074660420417786, 0.5791855454444885, 0.6052036285400391, 0.5995475053787231, 0.627828061580658, 0.6029411554336548, 0.6165158152580261, 0.6029411554336548, 0.6414027214050293, 0.6074660420417786, 0.6414027214050293, 0.639140248298645, 0.6380090713500977, 0.6346153616905212, 0.6199095249176025, 0.6255655884742737, 0.6493212580680847, 0.6538461446762085, 0.6334841847419739, 0.6368778347969055, 0.6210407018661499, 0.6414027214050293, 0.6436651349067688, 0.6481900215148926, 0.6357465982437134, 0.6414027214050293, 0.6414027214050293, 0.6447963714599609, 0.6165158152580261, 0.6493212580680847, 0.6334841847419739, 0.6357465982437134, 0.6368778347969055, 0.6255655884742737, 0.6323529481887817, 0.6368778347969055, 0.6380090713500977, 0.6380090713500977, 0.6312217116355896, 0.6380090713500977, 0.6357465982437134, 0.6312217116355896, 0.6380090713500977, 0.6312217116355896, 0.6380090713500977, 0.6346153616905212, 0.6266968250274658, 0.6334841847419739, 0.6334841847419739, 0.6233031749725342, 0.627828061580658, 0.6233031749725342, 0.6233031749725342, 0.6233031749725342, 0.6097285151481628, 0.6244344115257263, 0.6153846383094788, 0.6255655884742737, 0.627828061580658, 0.6142534017562866, 0.6255655884742737, 0.6142534017562866, 0.6176470518112183, 0.6187782883644104, 0.6187782883644104, 0.627828061580658, 0.6199095249176025, 0.622171938419342, 0.622171938419342, 0.6085972785949707, 0.6142534017562866, 0.610859751701355, 0.6097285151481628, 0.6142534017562866, 0.6153846383094788, 0.6074660420417786, 0.6165158152580261, 0.6119909286499023, 0.6165158152580261, 0.6142534017562866, 0.6097285151481628, 0.6131221652030945, 0.6131221652030945, 0.610859751701355]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 1.1943 - accuracy: 0.6789"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 9s 72ms/step - loss: 1.1937 - accuracy: 0.6804 - val_loss: 1.2696 - val_accuracy: 0.4948\n","Epoch 2/100\n","31/31 [==============================] - 1s 30ms/step - loss: 1.1811 - accuracy: 0.6809 - val_loss: 1.2630 - val_accuracy: 0.6291\n","Epoch 3/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1733 - accuracy: 0.6860 - val_loss: 1.2602 - val_accuracy: 0.5041\n","Epoch 4/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1667 - accuracy: 0.6860 - val_loss: 1.2535 - val_accuracy: 0.5610\n","Epoch 5/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1589 - accuracy: 0.6871 - val_loss: 1.2503 - val_accuracy: 0.5114\n","Epoch 6/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1480 - accuracy: 0.7088 - val_loss: 1.2464 - val_accuracy: 0.5083\n","Epoch 7/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1400 - accuracy: 0.7028 - val_loss: 1.2401 - val_accuracy: 0.5289\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1384 - accuracy: 0.7016 - val_loss: 1.2352 - val_accuracy: 0.5300\n","Epoch 9/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1349 - accuracy: 0.6928 - val_loss: 1.2323 - val_accuracy: 0.5134\n","Epoch 10/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1272 - accuracy: 0.7021 - val_loss: 1.2231 - val_accuracy: 0.5444\n","Epoch 11/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1242 - accuracy: 0.7008 - val_loss: 1.2253 - val_accuracy: 0.5196\n","Epoch 12/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1140 - accuracy: 0.7093 - val_loss: 1.2130 - val_accuracy: 0.5486\n","Epoch 13/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.1103 - accuracy: 0.7124 - val_loss: 1.1989 - val_accuracy: 0.6002\n","Epoch 14/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1045 - accuracy: 0.7062 - val_loss: 1.2062 - val_accuracy: 0.5568\n","Epoch 15/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0961 - accuracy: 0.7098 - val_loss: 1.1868 - val_accuracy: 0.6085\n","Epoch 16/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0961 - accuracy: 0.7116 - val_loss: 1.1811 - val_accuracy: 0.6074\n","Epoch 17/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0870 - accuracy: 0.7134 - val_loss: 1.1939 - val_accuracy: 0.5806\n","Epoch 18/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0744 - accuracy: 0.7251 - val_loss: 1.1666 - val_accuracy: 0.6271\n","Epoch 19/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0756 - accuracy: 0.7171 - val_loss: 1.1663 - val_accuracy: 0.6167\n","Epoch 20/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0681 - accuracy: 0.7214 - val_loss: 1.1830 - val_accuracy: 0.5971\n","Epoch 21/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0638 - accuracy: 0.7357 - val_loss: 1.1593 - val_accuracy: 0.6209\n","Epoch 22/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.0521 - accuracy: 0.7359 - val_loss: 1.1661 - val_accuracy: 0.6188\n","Epoch 23/100\n","31/31 [==============================] - 2s 63ms/step - loss: 1.0533 - accuracy: 0.7305 - val_loss: 1.1514 - val_accuracy: 0.6312\n","Epoch 24/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.0588 - accuracy: 0.7220 - val_loss: 1.1456 - val_accuracy: 0.6550\n","Epoch 25/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0457 - accuracy: 0.7326 - val_loss: 1.1465 - val_accuracy: 0.6560\n","Epoch 26/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0420 - accuracy: 0.7320 - val_loss: 1.1421 - val_accuracy: 0.6581\n","Epoch 27/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0299 - accuracy: 0.7403 - val_loss: 1.1431 - val_accuracy: 0.6560\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0268 - accuracy: 0.7393 - val_loss: 1.1555 - val_accuracy: 0.6198\n","Epoch 29/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.0234 - accuracy: 0.7470 - val_loss: 1.1449 - val_accuracy: 0.6601\n","Epoch 30/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0165 - accuracy: 0.7393 - val_loss: 1.1413 - val_accuracy: 0.6632\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0136 - accuracy: 0.7393 - val_loss: 1.1408 - val_accuracy: 0.6550\n","Epoch 32/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0048 - accuracy: 0.7460 - val_loss: 1.1404 - val_accuracy: 0.6529\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9991 - accuracy: 0.7553 - val_loss: 1.1438 - val_accuracy: 0.6395\n","Epoch 34/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9954 - accuracy: 0.7514 - val_loss: 1.1402 - val_accuracy: 0.6601\n","Epoch 35/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9985 - accuracy: 0.7424 - val_loss: 1.1675 - val_accuracy: 0.6116\n","Epoch 36/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9938 - accuracy: 0.7439 - val_loss: 1.1377 - val_accuracy: 0.6467\n","Epoch 37/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9831 - accuracy: 0.7499 - val_loss: 1.1468 - val_accuracy: 0.6384\n","Epoch 38/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9770 - accuracy: 0.7517 - val_loss: 1.1468 - val_accuracy: 0.6395\n","Epoch 39/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9693 - accuracy: 0.7556 - val_loss: 1.1401 - val_accuracy: 0.6405\n","Epoch 40/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9622 - accuracy: 0.7615 - val_loss: 1.1369 - val_accuracy: 0.6457\n","Epoch 41/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9587 - accuracy: 0.7721 - val_loss: 1.1377 - val_accuracy: 0.6405\n","Epoch 42/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9628 - accuracy: 0.7636 - val_loss: 1.1342 - val_accuracy: 0.6384\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9507 - accuracy: 0.7718 - val_loss: 1.1398 - val_accuracy: 0.6364\n","Epoch 44/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9500 - accuracy: 0.7553 - val_loss: 1.1395 - val_accuracy: 0.6374\n","Epoch 45/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9387 - accuracy: 0.7773 - val_loss: 1.1516 - val_accuracy: 0.6302\n","Epoch 46/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9575 - accuracy: 0.7504 - val_loss: 1.1310 - val_accuracy: 0.6384\n","Epoch 47/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9388 - accuracy: 0.7708 - val_loss: 1.1327 - val_accuracy: 0.6395\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9297 - accuracy: 0.7731 - val_loss: 1.1838 - val_accuracy: 0.6353\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9201 - accuracy: 0.7814 - val_loss: 1.1427 - val_accuracy: 0.6374\n","Epoch 50/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9156 - accuracy: 0.7786 - val_loss: 1.1653 - val_accuracy: 0.6085\n","Epoch 51/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9223 - accuracy: 0.7736 - val_loss: 1.1400 - val_accuracy: 0.6374\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9055 - accuracy: 0.7891 - val_loss: 1.1438 - val_accuracy: 0.6384\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9067 - accuracy: 0.7891 - val_loss: 1.1439 - val_accuracy: 0.6312\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8918 - accuracy: 0.7915 - val_loss: 1.1442 - val_accuracy: 0.6384\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8903 - accuracy: 0.7948 - val_loss: 1.1549 - val_accuracy: 0.6229\n","Epoch 56/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8882 - accuracy: 0.7876 - val_loss: 1.1455 - val_accuracy: 0.6374\n","Epoch 57/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8855 - accuracy: 0.7899 - val_loss: 1.1432 - val_accuracy: 0.6281\n","Epoch 58/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8782 - accuracy: 0.7946 - val_loss: 1.1550 - val_accuracy: 0.6343\n","Epoch 59/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8714 - accuracy: 0.8008 - val_loss: 1.1609 - val_accuracy: 0.6240\n","Epoch 60/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8583 - accuracy: 0.8116 - val_loss: 1.1693 - val_accuracy: 0.6374\n","Epoch 61/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8712 - accuracy: 0.7987 - val_loss: 1.1486 - val_accuracy: 0.6312\n","Epoch 62/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.8594 - accuracy: 0.8059 - val_loss: 1.1692 - val_accuracy: 0.6198\n","Epoch 63/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8535 - accuracy: 0.8067 - val_loss: 1.1689 - val_accuracy: 0.6281\n","Epoch 64/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.8564 - accuracy: 0.8000 - val_loss: 1.1573 - val_accuracy: 0.6322\n","Epoch 65/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8338 - accuracy: 0.8189 - val_loss: 1.1591 - val_accuracy: 0.6260\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8345 - accuracy: 0.8183 - val_loss: 1.1639 - val_accuracy: 0.6333\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8385 - accuracy: 0.8116 - val_loss: 1.1873 - val_accuracy: 0.6219\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8312 - accuracy: 0.8176 - val_loss: 1.2144 - val_accuracy: 0.6260\n","Epoch 69/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8280 - accuracy: 0.8150 - val_loss: 1.1590 - val_accuracy: 0.6333\n","Epoch 70/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8158 - accuracy: 0.8238 - val_loss: 1.1695 - val_accuracy: 0.6281\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8086 - accuracy: 0.8333 - val_loss: 1.2101 - val_accuracy: 0.6219\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8085 - accuracy: 0.8248 - val_loss: 1.1943 - val_accuracy: 0.6260\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7985 - accuracy: 0.8315 - val_loss: 1.1859 - val_accuracy: 0.6260\n","Epoch 74/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7934 - accuracy: 0.8297 - val_loss: 1.1910 - val_accuracy: 0.6250\n","Epoch 75/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7808 - accuracy: 0.8406 - val_loss: 1.1850 - val_accuracy: 0.6260\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7907 - accuracy: 0.8279 - val_loss: 1.2389 - val_accuracy: 0.6240\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7817 - accuracy: 0.8284 - val_loss: 1.1921 - val_accuracy: 0.6167\n","Epoch 78/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7801 - accuracy: 0.8359 - val_loss: 1.1960 - val_accuracy: 0.6333\n","Epoch 79/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7764 - accuracy: 0.8411 - val_loss: 1.1970 - val_accuracy: 0.6219\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7659 - accuracy: 0.8499 - val_loss: 1.2018 - val_accuracy: 0.6271\n","Epoch 81/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7655 - accuracy: 0.8419 - val_loss: 1.2904 - val_accuracy: 0.6147\n","Epoch 82/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7643 - accuracy: 0.8429 - val_loss: 1.2056 - val_accuracy: 0.6188\n","Epoch 83/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7584 - accuracy: 0.8475 - val_loss: 1.2072 - val_accuracy: 0.6188\n","Epoch 84/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7593 - accuracy: 0.8390 - val_loss: 1.2706 - val_accuracy: 0.6281\n","Epoch 85/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7519 - accuracy: 0.8450 - val_loss: 1.2167 - val_accuracy: 0.6167\n","Epoch 86/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7439 - accuracy: 0.8581 - val_loss: 1.2174 - val_accuracy: 0.6291\n","Epoch 87/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.7412 - accuracy: 0.8494 - val_loss: 1.2219 - val_accuracy: 0.6219\n","Epoch 88/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7479 - accuracy: 0.8432 - val_loss: 1.2175 - val_accuracy: 0.6209\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7199 - accuracy: 0.8594 - val_loss: 1.2286 - val_accuracy: 0.6229\n","Epoch 90/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7264 - accuracy: 0.8535 - val_loss: 1.3157 - val_accuracy: 0.6116\n","Epoch 91/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7505 - accuracy: 0.8375 - val_loss: 1.2282 - val_accuracy: 0.6250\n","Epoch 92/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7169 - accuracy: 0.8571 - val_loss: 1.2735 - val_accuracy: 0.5940\n","Epoch 93/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7159 - accuracy: 0.8592 - val_loss: 1.2334 - val_accuracy: 0.6271\n","Epoch 94/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7053 - accuracy: 0.8682 - val_loss: 1.2418 - val_accuracy: 0.6250\n","Epoch 95/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6979 - accuracy: 0.8703 - val_loss: 1.2489 - val_accuracy: 0.6219\n","Epoch 96/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6891 - accuracy: 0.8703 - val_loss: 1.2742 - val_accuracy: 0.6302\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6927 - accuracy: 0.8705 - val_loss: 1.2663 - val_accuracy: 0.6198\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6861 - accuracy: 0.8775 - val_loss: 1.2632 - val_accuracy: 0.6167\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6795 - accuracy: 0.8760 - val_loss: 1.3082 - val_accuracy: 0.6229\n","Epoch 100/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6798 - accuracy: 0.8742 - val_loss: 1.2729 - val_accuracy: 0.6147\n","{'loss': [1.1937084197998047, 1.1810545921325684, 1.1732538938522339, 1.1667213439941406, 1.1588672399520874, 1.147999882698059, 1.139998435974121, 1.1384416818618774, 1.1349000930786133, 1.12723708152771, 1.124200463294983, 1.1139994859695435, 1.1103150844573975, 1.1045445203781128, 1.096065878868103, 1.0960640907287598, 1.0869895219802856, 1.074363112449646, 1.0756281614303589, 1.0681371688842773, 1.0637824535369873, 1.0521448850631714, 1.0532596111297607, 1.058750867843628, 1.045688509941101, 1.0420396327972412, 1.029906988143921, 1.026808261871338, 1.023393988609314, 1.0164844989776611, 1.0136187076568604, 1.0048168897628784, 0.9990718960762024, 0.9953954219818115, 0.9985331296920776, 0.9937750697135925, 0.9831359386444092, 0.9770382642745972, 0.9693073630332947, 0.9621978402137756, 0.9587112069129944, 0.9627504348754883, 0.950724720954895, 0.9499654173851013, 0.9386698007583618, 0.9575340151786804, 0.9387932419776917, 0.9297360181808472, 0.9201369285583496, 0.9156258702278137, 0.922330915927887, 0.9054825305938721, 0.9066940546035767, 0.8917922973632812, 0.8903324604034424, 0.8882105350494385, 0.885482668876648, 0.8782097697257996, 0.8714060187339783, 0.8582925796508789, 0.8711754083633423, 0.8594428896903992, 0.8534839749336243, 0.8564441800117493, 0.8337519764900208, 0.8344836235046387, 0.8384643197059631, 0.8311752676963806, 0.828007698059082, 0.8158215284347534, 0.808619499206543, 0.808498203754425, 0.7985202670097351, 0.7934009432792664, 0.7807705402374268, 0.790681004524231, 0.7816787958145142, 0.7800954580307007, 0.7763961553573608, 0.7658694982528687, 0.7655462026596069, 0.7643135190010071, 0.758415937423706, 0.7593305706977844, 0.7519333958625793, 0.7438982725143433, 0.7411643266677856, 0.7479110956192017, 0.7198646068572998, 0.7263849973678589, 0.7504754066467285, 0.7169394493103027, 0.7158956527709961, 0.7053422927856445, 0.697870671749115, 0.6890891194343567, 0.692669153213501, 0.6860806345939636, 0.6794794201850891, 0.679798424243927], 'accuracy': [0.6803617477416992, 0.6808785796165466, 0.6860465407371521, 0.6860465407371521, 0.6870800852775574, 0.7087855339050293, 0.7028423547744751, 0.7015503644943237, 0.6927648782730103, 0.7020671963691711, 0.7007752060890198, 0.7093023061752319, 0.7124031186103821, 0.7062015533447266, 0.7098191380500793, 0.7116279006004333, 0.7134366631507874, 0.7250645756721497, 0.7170542478561401, 0.7214470505714417, 0.7356589436531067, 0.735917329788208, 0.7304909825325012, 0.7219638228416443, 0.7325581312179565, 0.7320413589477539, 0.7403100728988647, 0.7392764687538147, 0.7470284104347229, 0.7392764687538147, 0.7392764687538147, 0.7459948062896729, 0.7552971839904785, 0.7514212131500244, 0.7423772811889648, 0.7439276576042175, 0.749870777130127, 0.7516795992851257, 0.7555555701255798, 0.7614986896514893, 0.7720929980278015, 0.7635658979415894, 0.7718346118927002, 0.7552971839904785, 0.777260959148407, 0.7503876090049744, 0.7708010077476501, 0.7731266021728516, 0.7813953757286072, 0.7785529494285583, 0.773643434047699, 0.7891472578048706, 0.7891472578048706, 0.791472852230072, 0.7948320508003235, 0.7875968813896179, 0.7899224758148193, 0.7945736646652222, 0.8007751703262329, 0.8116279244422913, 0.7987080216407776, 0.8059431314468384, 0.8067183494567871, 0.800000011920929, 0.818863034248352, 0.8183462619781494, 0.8116279244422913, 0.8175710439682007, 0.814987063407898, 0.8237726092338562, 0.8333333134651184, 0.8248062133789062, 0.8315245509147644, 0.8297157883644104, 0.840568482875824, 0.8279069662094116, 0.828423798084259, 0.8359172940254211, 0.8410852551460266, 0.8498708009719849, 0.8418604731559753, 0.8428940773010254, 0.8475452065467834, 0.8390181064605713, 0.8449612259864807, 0.8581395149230957, 0.8493540287017822, 0.8431524634361267, 0.8594315052032471, 0.8534883856773376, 0.8374677300453186, 0.8571059703826904, 0.8591731190681458, 0.8682170510292053, 0.8702842593193054, 0.8702842593193054, 0.8705426454544067, 0.8775193691253662, 0.8759689927101135, 0.8741602301597595], 'val_loss': [1.2695924043655396, 1.2630163431167603, 1.260195016860962, 1.2535004615783691, 1.2502938508987427, 1.2464388608932495, 1.2400561571121216, 1.2351915836334229, 1.232262372970581, 1.2231457233428955, 1.2253220081329346, 1.2129708528518677, 1.1989333629608154, 1.2061728239059448, 1.186759114265442, 1.1810659170150757, 1.1939183473587036, 1.1666359901428223, 1.166279911994934, 1.1829569339752197, 1.1593235731124878, 1.1660867929458618, 1.151386022567749, 1.1455578804016113, 1.1464916467666626, 1.1421147584915161, 1.1431403160095215, 1.1555484533309937, 1.144897222518921, 1.1412782669067383, 1.1407849788665771, 1.1403634548187256, 1.1437708139419556, 1.1402357816696167, 1.167470932006836, 1.1377243995666504, 1.1468299627304077, 1.1468498706817627, 1.1401275396347046, 1.136918067932129, 1.1377195119857788, 1.1341931819915771, 1.1398273706436157, 1.1394610404968262, 1.151578426361084, 1.1310135126113892, 1.132739782333374, 1.1837778091430664, 1.142651915550232, 1.1652911901474, 1.1400023698806763, 1.1437835693359375, 1.143931269645691, 1.1442418098449707, 1.1548988819122314, 1.1455193758010864, 1.1432087421417236, 1.155009150505066, 1.160861611366272, 1.1693382263183594, 1.1486270427703857, 1.1692349910736084, 1.168939232826233, 1.15729558467865, 1.159092903137207, 1.1639163494110107, 1.1873472929000854, 1.2144300937652588, 1.159037709236145, 1.169520616531372, 1.2100586891174316, 1.194300651550293, 1.1859378814697266, 1.190976619720459, 1.1850353479385376, 1.2389440536499023, 1.1920586824417114, 1.195962905883789, 1.1970371007919312, 1.2017560005187988, 1.2904201745986938, 1.205581545829773, 1.207235336303711, 1.2705678939819336, 1.2167186737060547, 1.2174073457717896, 1.221948504447937, 1.2175191640853882, 1.2286280393600464, 1.315691351890564, 1.2282054424285889, 1.2734726667404175, 1.2333904504776, 1.2417709827423096, 1.248937726020813, 1.274221420288086, 1.2663230895996094, 1.2632249593734741, 1.3081989288330078, 1.2728575468063354], 'val_accuracy': [0.4948347210884094, 0.6291322112083435, 0.5041322112083435, 0.5609503984451294, 0.5113636255264282, 0.5082644820213318, 0.5289255976676941, 0.5299586653709412, 0.5134297609329224, 0.5444214940071106, 0.51962810754776, 0.5485537052154541, 0.6002066135406494, 0.5568181872367859, 0.6084710955619812, 0.6074380278587341, 0.5805785059928894, 0.6270661354064941, 0.6167355179786682, 0.5971074104309082, 0.6208677887916565, 0.6188016533851624, 0.6311983466148376, 0.6549586653709412, 0.6559917330741882, 0.6580578684806824, 0.6559917330741882, 0.6198347210884094, 0.6601239442825317, 0.663223147392273, 0.6549586653709412, 0.6528925895690918, 0.6394628286361694, 0.6601239442825317, 0.6115702390670776, 0.6466942429542542, 0.6384297609329224, 0.6394628286361694, 0.6404958963394165, 0.6456611752510071, 0.6404958963394165, 0.6384297609329224, 0.6363636255264282, 0.6373966932296753, 0.6301652789115906, 0.6384297609329224, 0.6394628286361694, 0.6353305578231812, 0.6373966932296753, 0.6084710955619812, 0.6373966932296753, 0.6384297609329224, 0.6311983466148376, 0.6384297609329224, 0.6229338645935059, 0.6373966932296753, 0.6280992031097412, 0.6342975497245789, 0.6239669322967529, 0.6373966932296753, 0.6311983466148376, 0.6198347210884094, 0.6280992031097412, 0.6322314143180847, 0.6260330677032471, 0.6332644820213318, 0.6219007968902588, 0.6260330677032471, 0.6332644820213318, 0.6280992031097412, 0.6219007968902588, 0.6260330677032471, 0.6260330677032471, 0.625, 0.6260330677032471, 0.6239669322967529, 0.6167355179786682, 0.6332644820213318, 0.6219007968902588, 0.6270661354064941, 0.6146694421768188, 0.6188016533851624, 0.6188016533851624, 0.6280992031097412, 0.6167355179786682, 0.6291322112083435, 0.6219007968902588, 0.6208677887916565, 0.6229338645935059, 0.6115702390670776, 0.625, 0.5940082669258118, 0.6270661354064941, 0.625, 0.6219007968902588, 0.6301652789115906, 0.6198347210884094, 0.6167355179786682, 0.6229338645935059, 0.6146694421768188]}\n","32/32 [==============================] - 1s 6ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.7848 - accuracy: 0.8187"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 6s 56ms/step - loss: 0.7848 - accuracy: 0.8187 - val_loss: 1.0618 - val_accuracy: 0.6390\n","Epoch 2/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7653 - accuracy: 0.8343 - val_loss: 1.0578 - val_accuracy: 0.6315\n","Epoch 3/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.7653 - accuracy: 0.8314 - val_loss: 1.0548 - val_accuracy: 0.6412\n","Epoch 4/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7530 - accuracy: 0.8327 - val_loss: 1.0513 - val_accuracy: 0.6379\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7542 - accuracy: 0.8365 - val_loss: 1.0479 - val_accuracy: 0.6196\n","Epoch 6/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7425 - accuracy: 0.8413 - val_loss: 1.0412 - val_accuracy: 0.6142\n","Epoch 7/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7345 - accuracy: 0.8489 - val_loss: 1.0359 - val_accuracy: 0.6218\n","Epoch 8/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7451 - accuracy: 0.8314 - val_loss: 1.0304 - val_accuracy: 0.6369\n","Epoch 9/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7211 - accuracy: 0.8502 - val_loss: 1.0258 - val_accuracy: 0.6369\n","Epoch 10/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7323 - accuracy: 0.8394 - val_loss: 1.0203 - val_accuracy: 0.6282\n","Epoch 11/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.7136 - accuracy: 0.8580 - val_loss: 1.0189 - val_accuracy: 0.6228\n","Epoch 12/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7265 - accuracy: 0.8462 - val_loss: 1.0083 - val_accuracy: 0.6325\n","Epoch 13/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7205 - accuracy: 0.8462 - val_loss: 1.0057 - val_accuracy: 0.6401\n","Epoch 14/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7001 - accuracy: 0.8650 - val_loss: 1.0026 - val_accuracy: 0.6358\n","Epoch 15/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6970 - accuracy: 0.8642 - val_loss: 1.0006 - val_accuracy: 0.6401\n","Epoch 16/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6819 - accuracy: 0.8661 - val_loss: 0.9907 - val_accuracy: 0.6541\n","Epoch 17/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6850 - accuracy: 0.8715 - val_loss: 0.9984 - val_accuracy: 0.6541\n","Epoch 18/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6814 - accuracy: 0.8728 - val_loss: 1.0076 - val_accuracy: 0.6681\n","Epoch 19/100\n","29/29 [==============================] - 1s 38ms/step - loss: 0.6675 - accuracy: 0.8772 - val_loss: 1.0013 - val_accuracy: 0.6735\n","Epoch 20/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6713 - accuracy: 0.8715 - val_loss: 1.0242 - val_accuracy: 0.6778\n","Epoch 21/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6555 - accuracy: 0.8772 - val_loss: 1.0252 - val_accuracy: 0.6789\n","Epoch 22/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6614 - accuracy: 0.8739 - val_loss: 1.0371 - val_accuracy: 0.6843\n","Epoch 23/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6594 - accuracy: 0.8798 - val_loss: 1.0254 - val_accuracy: 0.6886\n","Epoch 24/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6626 - accuracy: 0.8766 - val_loss: 1.0209 - val_accuracy: 0.7004\n","Epoch 25/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6514 - accuracy: 0.8780 - val_loss: 1.0553 - val_accuracy: 0.6907\n","Epoch 26/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6421 - accuracy: 0.8831 - val_loss: 1.0488 - val_accuracy: 0.6929\n","Epoch 27/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6333 - accuracy: 0.8901 - val_loss: 1.0408 - val_accuracy: 0.7015\n","Epoch 28/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.6347 - accuracy: 0.8882 - val_loss: 1.0652 - val_accuracy: 0.7026\n","Epoch 29/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.6426 - accuracy: 0.8817 - val_loss: 1.0561 - val_accuracy: 0.7037\n","Epoch 30/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6238 - accuracy: 0.8930 - val_loss: 1.0649 - val_accuracy: 0.6875\n","Epoch 31/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6166 - accuracy: 0.9044 - val_loss: 1.0614 - val_accuracy: 0.6961\n","Epoch 32/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6142 - accuracy: 0.8952 - val_loss: 1.0788 - val_accuracy: 0.6897\n","Epoch 33/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6256 - accuracy: 0.8887 - val_loss: 1.1048 - val_accuracy: 0.6821\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6148 - accuracy: 0.8966 - val_loss: 1.1100 - val_accuracy: 0.6886\n","Epoch 35/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6027 - accuracy: 0.9027 - val_loss: 1.0953 - val_accuracy: 0.6907\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6114 - accuracy: 0.8909 - val_loss: 1.1003 - val_accuracy: 0.6918\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5928 - accuracy: 0.9030 - val_loss: 1.1105 - val_accuracy: 0.6918\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6014 - accuracy: 0.9009 - val_loss: 1.1149 - val_accuracy: 0.6864\n","Epoch 39/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5851 - accuracy: 0.9106 - val_loss: 1.1527 - val_accuracy: 0.6843\n","Epoch 40/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5954 - accuracy: 0.8987 - val_loss: 1.1612 - val_accuracy: 0.6821\n","Epoch 41/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5849 - accuracy: 0.9089 - val_loss: 1.1224 - val_accuracy: 0.6853\n","Epoch 42/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5769 - accuracy: 0.9111 - val_loss: 1.1382 - val_accuracy: 0.6886\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5733 - accuracy: 0.9098 - val_loss: 1.1473 - val_accuracy: 0.6853\n","Epoch 44/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5778 - accuracy: 0.9084 - val_loss: 1.1417 - val_accuracy: 0.6864\n","Epoch 45/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5632 - accuracy: 0.9154 - val_loss: 1.1633 - val_accuracy: 0.6832\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5621 - accuracy: 0.9157 - val_loss: 1.1515 - val_accuracy: 0.6907\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5592 - accuracy: 0.9138 - val_loss: 1.1609 - val_accuracy: 0.6853\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5653 - accuracy: 0.9119 - val_loss: 1.1821 - val_accuracy: 0.6800\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5597 - accuracy: 0.9130 - val_loss: 1.1913 - val_accuracy: 0.6832\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5453 - accuracy: 0.9265 - val_loss: 1.1692 - val_accuracy: 0.6853\n","Epoch 51/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5442 - accuracy: 0.9232 - val_loss: 1.1791 - val_accuracy: 0.6789\n","Epoch 52/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5391 - accuracy: 0.9246 - val_loss: 1.1738 - val_accuracy: 0.6843\n","Epoch 53/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5535 - accuracy: 0.9173 - val_loss: 1.1835 - val_accuracy: 0.6853\n","Epoch 54/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5465 - accuracy: 0.9208 - val_loss: 1.1958 - val_accuracy: 0.6897\n","Epoch 55/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5268 - accuracy: 0.9262 - val_loss: 1.1923 - val_accuracy: 0.6897\n","Epoch 56/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5238 - accuracy: 0.9316 - val_loss: 1.2112 - val_accuracy: 0.6853\n","Epoch 57/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5228 - accuracy: 0.9267 - val_loss: 1.2156 - val_accuracy: 0.6864\n","Epoch 58/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5377 - accuracy: 0.9173 - val_loss: 1.2327 - val_accuracy: 0.6810\n","Epoch 59/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5264 - accuracy: 0.9297 - val_loss: 1.2196 - val_accuracy: 0.6800\n","Epoch 60/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5189 - accuracy: 0.9313 - val_loss: 1.2393 - val_accuracy: 0.6843\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5131 - accuracy: 0.9353 - val_loss: 1.2384 - val_accuracy: 0.6897\n","Epoch 62/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5037 - accuracy: 0.9402 - val_loss: 1.2660 - val_accuracy: 0.6800\n","Epoch 63/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5141 - accuracy: 0.9310 - val_loss: 1.2420 - val_accuracy: 0.6875\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5105 - accuracy: 0.9313 - val_loss: 1.2548 - val_accuracy: 0.6832\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4974 - accuracy: 0.9429 - val_loss: 1.2423 - val_accuracy: 0.6810\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4961 - accuracy: 0.9429 - val_loss: 1.2577 - val_accuracy: 0.6832\n","Epoch 67/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4973 - accuracy: 0.9418 - val_loss: 1.2435 - val_accuracy: 0.6897\n","Epoch 68/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4868 - accuracy: 0.9421 - val_loss: 1.2810 - val_accuracy: 0.6886\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4913 - accuracy: 0.9402 - val_loss: 1.2850 - val_accuracy: 0.6886\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4974 - accuracy: 0.9332 - val_loss: 1.3322 - val_accuracy: 0.6670\n","Epoch 71/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4980 - accuracy: 0.9318 - val_loss: 1.2723 - val_accuracy: 0.6832\n","Epoch 72/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4790 - accuracy: 0.9480 - val_loss: 1.2753 - val_accuracy: 0.6821\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4744 - accuracy: 0.9477 - val_loss: 1.2985 - val_accuracy: 0.6756\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4835 - accuracy: 0.9405 - val_loss: 1.2997 - val_accuracy: 0.6843\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4798 - accuracy: 0.9426 - val_loss: 1.3149 - val_accuracy: 0.6821\n","Epoch 76/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4808 - accuracy: 0.9386 - val_loss: 1.3388 - val_accuracy: 0.6821\n","Epoch 77/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4861 - accuracy: 0.9399 - val_loss: 1.3048 - val_accuracy: 0.6864\n","Epoch 78/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4652 - accuracy: 0.9534 - val_loss: 1.3160 - val_accuracy: 0.6843\n","Epoch 79/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4603 - accuracy: 0.9496 - val_loss: 1.3215 - val_accuracy: 0.6853\n","Epoch 80/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4588 - accuracy: 0.9545 - val_loss: 1.3302 - val_accuracy: 0.6864\n","Epoch 81/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4572 - accuracy: 0.9537 - val_loss: 1.3622 - val_accuracy: 0.6767\n","Epoch 82/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4677 - accuracy: 0.9453 - val_loss: 1.3349 - val_accuracy: 0.6800\n","Epoch 83/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4570 - accuracy: 0.9510 - val_loss: 1.3443 - val_accuracy: 0.6886\n","Epoch 84/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4452 - accuracy: 0.9593 - val_loss: 1.3459 - val_accuracy: 0.6875\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4392 - accuracy: 0.9593 - val_loss: 1.3730 - val_accuracy: 0.6886\n","Epoch 86/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4544 - accuracy: 0.9499 - val_loss: 1.3813 - val_accuracy: 0.6778\n","Epoch 87/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4412 - accuracy: 0.9617 - val_loss: 1.4057 - val_accuracy: 0.6789\n","Epoch 88/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4520 - accuracy: 0.9488 - val_loss: 1.3669 - val_accuracy: 0.6789\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4353 - accuracy: 0.9626 - val_loss: 1.3766 - val_accuracy: 0.6907\n","Epoch 90/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4336 - accuracy: 0.9599 - val_loss: 1.3872 - val_accuracy: 0.6864\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4298 - accuracy: 0.9631 - val_loss: 1.3885 - val_accuracy: 0.6756\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4408 - accuracy: 0.9574 - val_loss: 1.4107 - val_accuracy: 0.6853\n","Epoch 93/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4376 - accuracy: 0.9599 - val_loss: 1.4500 - val_accuracy: 0.6756\n","Epoch 94/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4360 - accuracy: 0.9591 - val_loss: 1.4170 - val_accuracy: 0.6810\n","Epoch 95/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4286 - accuracy: 0.9620 - val_loss: 1.4208 - val_accuracy: 0.6853\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4228 - accuracy: 0.9650 - val_loss: 1.4551 - val_accuracy: 0.6746\n","Epoch 97/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4348 - accuracy: 0.9582 - val_loss: 1.4483 - val_accuracy: 0.6821\n","Epoch 98/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4235 - accuracy: 0.9620 - val_loss: 1.4386 - val_accuracy: 0.6810\n","Epoch 99/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4098 - accuracy: 0.9679 - val_loss: 1.4504 - val_accuracy: 0.6713\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4135 - accuracy: 0.9682 - val_loss: 1.4457 - val_accuracy: 0.6886\n","{'loss': [0.7847701907157898, 0.7653101086616516, 0.7652608156204224, 0.752970278263092, 0.7541937232017517, 0.7424728870391846, 0.7344784736633301, 0.7450775504112244, 0.721050500869751, 0.7322715520858765, 0.7136229276657104, 0.7265389561653137, 0.7205058336257935, 0.700073778629303, 0.6969727873802185, 0.6818860173225403, 0.6849974989891052, 0.6813954710960388, 0.6675292253494263, 0.671345591545105, 0.6555346250534058, 0.6613742113113403, 0.6594237089157104, 0.6625568866729736, 0.6514057517051697, 0.642065703868866, 0.6332935094833374, 0.6346728801727295, 0.6425692439079285, 0.6237629652023315, 0.6165633201599121, 0.61424720287323, 0.6256133913993835, 0.6147774457931519, 0.6026618480682373, 0.611433744430542, 0.5928041934967041, 0.6014143228530884, 0.5851147770881653, 0.5954095721244812, 0.5848827362060547, 0.5768583416938782, 0.5732899904251099, 0.5777796506881714, 0.5632045865058899, 0.5621200799942017, 0.5592450499534607, 0.565313994884491, 0.5597459673881531, 0.5453271865844727, 0.5442295074462891, 0.5390579700469971, 0.5534726977348328, 0.546545147895813, 0.5268346667289734, 0.523756206035614, 0.5228019952774048, 0.5377231240272522, 0.5263763070106506, 0.5188600420951843, 0.5131492018699646, 0.5036535859107971, 0.5140860080718994, 0.5105068683624268, 0.4974428415298462, 0.49608999490737915, 0.49726271629333496, 0.4867897033691406, 0.4913146197795868, 0.4974406659603119, 0.4980255365371704, 0.47902369499206543, 0.47442373633384705, 0.48352283239364624, 0.4797952175140381, 0.4807758629322052, 0.4860509932041168, 0.4651874601840973, 0.460304319858551, 0.45879194140434265, 0.4572031497955322, 0.46771714091300964, 0.45695117115974426, 0.4451883137226105, 0.4392370581626892, 0.4543982744216919, 0.44118380546569824, 0.4520004093647003, 0.43527260422706604, 0.43364614248275757, 0.42984259128570557, 0.440848708152771, 0.4376464784145355, 0.4360341429710388, 0.42859354615211487, 0.4228178560733795, 0.4348175525665283, 0.4235410690307617, 0.4097776710987091, 0.4134576618671417], 'accuracy': [0.818696141242981, 0.834321141242981, 0.8313577771186829, 0.8327047228813171, 0.8364762663841248, 0.8413254022598267, 0.8488685488700867, 0.8313577771186829, 0.850215494632721, 0.8394396305084229, 0.858027994632721, 0.8461745977401733, 0.8461745977401733, 0.8650323152542114, 0.8642241358757019, 0.8661099076271057, 0.8714978694915771, 0.8728448152542114, 0.8771551847457886, 0.8714978694915771, 0.8771551847457886, 0.8739224076271057, 0.8798491358757019, 0.876616358757019, 0.8779633641242981, 0.8830819129943848, 0.8900862336158752, 0.8882004022598267, 0.8817349076271057, 0.8930495977401733, 0.9043642282485962, 0.8952047228813171, 0.8887392282485962, 0.8965517282485962, 0.9027478694915771, 0.8908944129943848, 0.9030172228813171, 0.9008620977401733, 0.9105603694915771, 0.8987069129943848, 0.9089439511299133, 0.9110991358757019, 0.9097521305084229, 0.9084051847457886, 0.915409505367279, 0.915678858757019, 0.9137930870056152, 0.9119073152542114, 0.9129849076271057, 0.9264547228813171, 0.923222005367279, 0.9245689511299133, 0.9172952771186829, 0.9207974076271057, 0.9261853694915771, 0.9315732717514038, 0.9267241358757019, 0.9172952771186829, 0.9296875, 0.931303858757019, 0.9353448152542114, 0.9401939511299133, 0.931034505367279, 0.931303858757019, 0.9428879022598267, 0.9428879022598267, 0.9418103694915771, 0.9420797228813171, 0.9401939511299133, 0.9331896305084229, 0.9318426847457886, 0.9480064511299133, 0.9477370977401733, 0.9404633641242981, 0.9426185488700867, 0.9385775923728943, 0.9399245977401733, 0.9533944129943848, 0.9496228694915771, 0.954472005367279, 0.9536637663841248, 0.9453125, 0.9509698152542114, 0.959321141242981, 0.959321141242981, 0.9498922228813171, 0.9617456793785095, 0.9488146305084229, 0.962553858757019, 0.9598599076271057, 0.9630926847457886, 0.9574353694915771, 0.9598599076271057, 0.9590517282485962, 0.9620150923728943, 0.9649784564971924, 0.9582435488700867, 0.9620150923728943, 0.9679418206214905, 0.9682112336158752], 'val_loss': [1.061765193939209, 1.057830572128296, 1.0547990798950195, 1.0513077974319458, 1.0478765964508057, 1.041232705116272, 1.0359443426132202, 1.0303735733032227, 1.0258327722549438, 1.0203195810317993, 1.0189261436462402, 1.008284091949463, 1.005694031715393, 1.0025763511657715, 1.0005898475646973, 0.9907440543174744, 0.9983961582183838, 1.0076273679733276, 1.001341700553894, 1.02423894405365, 1.0252273082733154, 1.037064552307129, 1.0254424810409546, 1.0209424495697021, 1.0552668571472168, 1.0487529039382935, 1.0407627820968628, 1.065171241760254, 1.056088924407959, 1.0648794174194336, 1.061367392539978, 1.078832745552063, 1.1047823429107666, 1.110013723373413, 1.0952872037887573, 1.1003209352493286, 1.110473871231079, 1.1148524284362793, 1.1527140140533447, 1.1612036228179932, 1.1223801374435425, 1.1381661891937256, 1.1472582817077637, 1.141692042350769, 1.163333773612976, 1.1514514684677124, 1.160873532295227, 1.1820675134658813, 1.1912866830825806, 1.1692122220993042, 1.1791470050811768, 1.1738404035568237, 1.1834737062454224, 1.1957521438598633, 1.192278265953064, 1.2112388610839844, 1.215611457824707, 1.2326937913894653, 1.2196464538574219, 1.2393419742584229, 1.2383646965026855, 1.2659845352172852, 1.2419912815093994, 1.2548396587371826, 1.2423373460769653, 1.2577265501022339, 1.2435224056243896, 1.2810107469558716, 1.2849724292755127, 1.3322458267211914, 1.2723305225372314, 1.2753418684005737, 1.2984963655471802, 1.299667239189148, 1.3149373531341553, 1.3388373851776123, 1.3047622442245483, 1.315992832183838, 1.3214722871780396, 1.3302146196365356, 1.362209677696228, 1.3349264860153198, 1.3442864418029785, 1.3459193706512451, 1.3730013370513916, 1.3812527656555176, 1.4057130813598633, 1.3668768405914307, 1.3765815496444702, 1.3871785402297974, 1.3885284662246704, 1.4107050895690918, 1.4500397443771362, 1.4169704914093018, 1.4208247661590576, 1.4551331996917725, 1.4482958316802979, 1.4385558366775513, 1.4503974914550781, 1.445724368095398], 'val_accuracy': [0.639008641242981, 0.631465494632721, 0.6411637663841248, 0.6379310488700867, 0.6196120977401733, 0.6142241358757019, 0.6217672228813171, 0.6368534564971924, 0.6368534564971924, 0.6282327771186829, 0.6228448152542114, 0.6325430870056152, 0.6400862336158752, 0.6357758641242981, 0.6400862336158752, 0.6540948152542114, 0.6540948152542114, 0.6681034564971924, 0.673491358757019, 0.6778017282485962, 0.6788793206214905, 0.6842672228813171, 0.6885775923728943, 0.7004310488700867, 0.6907327771186829, 0.6928879022598267, 0.701508641242981, 0.7025862336158752, 0.7036637663841248, 0.6875, 0.6961206793785095, 0.6896551847457886, 0.6821120977401733, 0.6885775923728943, 0.6907327771186829, 0.6918103694915771, 0.6918103694915771, 0.6864224076271057, 0.6842672228813171, 0.6821120977401733, 0.6853448152542114, 0.6885775923728943, 0.6853448152542114, 0.6864224076271057, 0.6831896305084229, 0.6907327771186829, 0.6853448152542114, 0.6799569129943848, 0.6831896305084229, 0.6853448152542114, 0.6788793206214905, 0.6842672228813171, 0.6853448152542114, 0.6896551847457886, 0.6896551847457886, 0.6853448152542114, 0.6864224076271057, 0.681034505367279, 0.6799569129943848, 0.6842672228813171, 0.6896551847457886, 0.6799569129943848, 0.6875, 0.6831896305084229, 0.681034505367279, 0.6831896305084229, 0.6896551847457886, 0.6885775923728943, 0.6885775923728943, 0.6670258641242981, 0.6831896305084229, 0.6821120977401733, 0.6756465435028076, 0.6842672228813171, 0.6821120977401733, 0.6821120977401733, 0.6864224076271057, 0.6842672228813171, 0.6853448152542114, 0.6864224076271057, 0.6767241358757019, 0.6799569129943848, 0.6885775923728943, 0.6875, 0.6885775923728943, 0.6778017282485962, 0.6788793206214905, 0.6788793206214905, 0.6907327771186829, 0.6864224076271057, 0.6756465435028076, 0.6853448152542114, 0.6756465435028076, 0.681034505367279, 0.6853448152542114, 0.6745689511299133, 0.6821120977401733, 0.681034505367279, 0.6713362336158752, 0.6885775923728943]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.8057 - accuracy: 0.8134"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 60ms/step - loss: 0.8043 - accuracy: 0.8138 - val_loss: 1.0621 - val_accuracy: 0.6233\n","Epoch 2/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7765 - accuracy: 0.8254 - val_loss: 1.0600 - val_accuracy: 0.6222\n","Epoch 3/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7659 - accuracy: 0.8322 - val_loss: 1.0572 - val_accuracy: 0.6188\n","Epoch 4/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7572 - accuracy: 0.8345 - val_loss: 1.0531 - val_accuracy: 0.6120\n","Epoch 5/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.7671 - accuracy: 0.8336 - val_loss: 1.0500 - val_accuracy: 0.6278\n","Epoch 6/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.7421 - accuracy: 0.8384 - val_loss: 1.0466 - val_accuracy: 0.6324\n","Epoch 7/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7444 - accuracy: 0.8384 - val_loss: 1.0436 - val_accuracy: 0.6256\n","Epoch 8/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7427 - accuracy: 0.8376 - val_loss: 1.0420 - val_accuracy: 0.6007\n","Epoch 9/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7379 - accuracy: 0.8393 - val_loss: 1.0323 - val_accuracy: 0.6278\n","Epoch 10/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7237 - accuracy: 0.8500 - val_loss: 1.0273 - val_accuracy: 0.6267\n","Epoch 11/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7267 - accuracy: 0.8449 - val_loss: 1.0290 - val_accuracy: 0.6143\n","Epoch 12/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.7210 - accuracy: 0.8503 - val_loss: 1.0193 - val_accuracy: 0.6335\n","Epoch 13/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7085 - accuracy: 0.8599 - val_loss: 1.0130 - val_accuracy: 0.6324\n","Epoch 14/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.7043 - accuracy: 0.8580 - val_loss: 1.0068 - val_accuracy: 0.6425\n","Epoch 15/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.6922 - accuracy: 0.8659 - val_loss: 1.0050 - val_accuracy: 0.6482\n","Epoch 16/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6988 - accuracy: 0.8605 - val_loss: 1.0033 - val_accuracy: 0.6595\n","Epoch 17/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6918 - accuracy: 0.8639 - val_loss: 1.0233 - val_accuracy: 0.6346\n","Epoch 18/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6999 - accuracy: 0.8608 - val_loss: 1.0131 - val_accuracy: 0.6561\n","Epoch 19/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6861 - accuracy: 0.8611 - val_loss: 1.0182 - val_accuracy: 0.6572\n","Epoch 20/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6845 - accuracy: 0.8696 - val_loss: 1.0442 - val_accuracy: 0.6471\n","Epoch 21/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6729 - accuracy: 0.8752 - val_loss: 1.0205 - val_accuracy: 0.6652\n","Epoch 22/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6682 - accuracy: 0.8763 - val_loss: 1.0485 - val_accuracy: 0.6606\n","Epoch 23/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6782 - accuracy: 0.8673 - val_loss: 1.0160 - val_accuracy: 0.6821\n","Epoch 24/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6692 - accuracy: 0.8755 - val_loss: 1.0253 - val_accuracy: 0.6753\n","Epoch 25/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.6673 - accuracy: 0.8724 - val_loss: 1.0233 - val_accuracy: 0.6900\n","Epoch 26/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6450 - accuracy: 0.8865 - val_loss: 1.0349 - val_accuracy: 0.6787\n","Epoch 27/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6512 - accuracy: 0.8786 - val_loss: 1.0483 - val_accuracy: 0.6878\n","Epoch 28/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6447 - accuracy: 0.8809 - val_loss: 1.0384 - val_accuracy: 0.6889\n","Epoch 29/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6434 - accuracy: 0.8837 - val_loss: 1.0429 - val_accuracy: 0.6957\n","Epoch 30/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6390 - accuracy: 0.8806 - val_loss: 1.0592 - val_accuracy: 0.6980\n","Epoch 31/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6392 - accuracy: 0.8865 - val_loss: 1.0621 - val_accuracy: 0.6912\n","Epoch 32/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6299 - accuracy: 0.8930 - val_loss: 1.0665 - val_accuracy: 0.6946\n","Epoch 33/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6309 - accuracy: 0.8879 - val_loss: 1.0696 - val_accuracy: 0.6957\n","Epoch 34/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6102 - accuracy: 0.8959 - val_loss: 1.0749 - val_accuracy: 0.6980\n","Epoch 35/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6243 - accuracy: 0.8888 - val_loss: 1.0847 - val_accuracy: 0.6912\n","Epoch 36/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6382 - accuracy: 0.8803 - val_loss: 1.0788 - val_accuracy: 0.6980\n","Epoch 37/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6164 - accuracy: 0.8939 - val_loss: 1.0935 - val_accuracy: 0.6889\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6135 - accuracy: 0.8976 - val_loss: 1.1277 - val_accuracy: 0.6867\n","Epoch 39/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6055 - accuracy: 0.9004 - val_loss: 1.0980 - val_accuracy: 0.7025\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6074 - accuracy: 0.8993 - val_loss: 1.1046 - val_accuracy: 0.6844\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5986 - accuracy: 0.9035 - val_loss: 1.1256 - val_accuracy: 0.6867\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6117 - accuracy: 0.8950 - val_loss: 1.1004 - val_accuracy: 0.6991\n","Epoch 43/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6040 - accuracy: 0.9001 - val_loss: 1.1081 - val_accuracy: 0.6900\n","Epoch 44/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5790 - accuracy: 0.9154 - val_loss: 1.1118 - val_accuracy: 0.6946\n","Epoch 45/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5676 - accuracy: 0.9182 - val_loss: 1.1696 - val_accuracy: 0.6821\n","Epoch 46/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5734 - accuracy: 0.9123 - val_loss: 1.1140 - val_accuracy: 0.6923\n","Epoch 47/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5644 - accuracy: 0.9208 - val_loss: 1.1168 - val_accuracy: 0.7048\n","Epoch 48/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5699 - accuracy: 0.9143 - val_loss: 1.1436 - val_accuracy: 0.6900\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5581 - accuracy: 0.9202 - val_loss: 1.1337 - val_accuracy: 0.7025\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5647 - accuracy: 0.9120 - val_loss: 1.1546 - val_accuracy: 0.6934\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5629 - accuracy: 0.9205 - val_loss: 1.1433 - val_accuracy: 0.7014\n","Epoch 52/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5447 - accuracy: 0.9273 - val_loss: 1.1441 - val_accuracy: 0.6934\n","Epoch 53/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5628 - accuracy: 0.9143 - val_loss: 1.1616 - val_accuracy: 0.6923\n","Epoch 54/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5499 - accuracy: 0.9228 - val_loss: 1.1524 - val_accuracy: 0.6980\n","Epoch 55/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5508 - accuracy: 0.9194 - val_loss: 1.1549 - val_accuracy: 0.6946\n","Epoch 56/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5474 - accuracy: 0.9196 - val_loss: 1.1582 - val_accuracy: 0.7014\n","Epoch 57/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.5391 - accuracy: 0.9250 - val_loss: 1.1784 - val_accuracy: 0.6912\n","Epoch 58/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5292 - accuracy: 0.9310 - val_loss: 1.1677 - val_accuracy: 0.7025\n","Epoch 59/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5483 - accuracy: 0.9216 - val_loss: 1.2898 - val_accuracy: 0.6674\n","Epoch 60/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.5412 - accuracy: 0.9259 - val_loss: 1.1745 - val_accuracy: 0.6957\n","Epoch 61/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5195 - accuracy: 0.9363 - val_loss: 1.1869 - val_accuracy: 0.6934\n","Epoch 62/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5283 - accuracy: 0.9301 - val_loss: 1.2399 - val_accuracy: 0.6821\n","Epoch 63/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5347 - accuracy: 0.9256 - val_loss: 1.1829 - val_accuracy: 0.6968\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5137 - accuracy: 0.9380 - val_loss: 1.1893 - val_accuracy: 0.6934\n","Epoch 65/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5170 - accuracy: 0.9392 - val_loss: 1.1928 - val_accuracy: 0.7036\n","Epoch 66/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5271 - accuracy: 0.9256 - val_loss: 1.3078 - val_accuracy: 0.6765\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5448 - accuracy: 0.9177 - val_loss: 1.2411 - val_accuracy: 0.6855\n","Epoch 68/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5162 - accuracy: 0.9352 - val_loss: 1.2114 - val_accuracy: 0.6912\n","Epoch 69/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5120 - accuracy: 0.9372 - val_loss: 1.2078 - val_accuracy: 0.6991\n","Epoch 70/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5081 - accuracy: 0.9332 - val_loss: 1.2675 - val_accuracy: 0.6810\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5254 - accuracy: 0.9259 - val_loss: 1.2238 - val_accuracy: 0.6821\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4936 - accuracy: 0.9406 - val_loss: 1.2253 - val_accuracy: 0.6900\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4932 - accuracy: 0.9457 - val_loss: 1.2312 - val_accuracy: 0.6946\n","Epoch 74/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4934 - accuracy: 0.9423 - val_loss: 1.2332 - val_accuracy: 0.6946\n","Epoch 75/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5027 - accuracy: 0.9352 - val_loss: 1.2351 - val_accuracy: 0.6968\n","Epoch 76/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4833 - accuracy: 0.9468 - val_loss: 1.2539 - val_accuracy: 0.6867\n","Epoch 77/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4738 - accuracy: 0.9496 - val_loss: 1.2425 - val_accuracy: 0.6957\n","Epoch 78/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4741 - accuracy: 0.9513 - val_loss: 1.2541 - val_accuracy: 0.6934\n","Epoch 79/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4812 - accuracy: 0.9426 - val_loss: 1.2497 - val_accuracy: 0.6957\n","Epoch 80/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4837 - accuracy: 0.9417 - val_loss: 1.2576 - val_accuracy: 0.6968\n","Epoch 81/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4707 - accuracy: 0.9533 - val_loss: 1.2870 - val_accuracy: 0.6844\n","Epoch 82/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4615 - accuracy: 0.9553 - val_loss: 1.2834 - val_accuracy: 0.6946\n","Epoch 83/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4723 - accuracy: 0.9525 - val_loss: 1.2930 - val_accuracy: 0.6923\n","Epoch 84/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4634 - accuracy: 0.9510 - val_loss: 1.2995 - val_accuracy: 0.6844\n","Epoch 85/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4577 - accuracy: 0.9553 - val_loss: 1.2944 - val_accuracy: 0.6923\n","Epoch 86/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4656 - accuracy: 0.9502 - val_loss: 1.3158 - val_accuracy: 0.6821\n","Epoch 87/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4641 - accuracy: 0.9559 - val_loss: 1.3090 - val_accuracy: 0.6923\n","Epoch 88/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4621 - accuracy: 0.9502 - val_loss: 1.3035 - val_accuracy: 0.6923\n","Epoch 89/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4438 - accuracy: 0.9629 - val_loss: 1.3085 - val_accuracy: 0.6912\n","Epoch 90/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4583 - accuracy: 0.9550 - val_loss: 1.4396 - val_accuracy: 0.6753\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4562 - accuracy: 0.9544 - val_loss: 1.3217 - val_accuracy: 0.6900\n","Epoch 92/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4337 - accuracy: 0.9658 - val_loss: 1.3278 - val_accuracy: 0.6878\n","Epoch 93/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4396 - accuracy: 0.9624 - val_loss: 1.3365 - val_accuracy: 0.6923\n","Epoch 94/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4528 - accuracy: 0.9570 - val_loss: 1.3244 - val_accuracy: 0.6833\n","Epoch 95/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4316 - accuracy: 0.9658 - val_loss: 1.3729 - val_accuracy: 0.6912\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4322 - accuracy: 0.9646 - val_loss: 1.3337 - val_accuracy: 0.6946\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4408 - accuracy: 0.9584 - val_loss: 1.3634 - val_accuracy: 0.6889\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4272 - accuracy: 0.9643 - val_loss: 1.3624 - val_accuracy: 0.6900\n","Epoch 99/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4464 - accuracy: 0.9581 - val_loss: 1.3566 - val_accuracy: 0.6799\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4275 - accuracy: 0.9649 - val_loss: 1.3437 - val_accuracy: 0.6821\n","{'loss': [0.8043199181556702, 0.7764706611633301, 0.7658680081367493, 0.7571685314178467, 0.7671463489532471, 0.7421366572380066, 0.7444484829902649, 0.7426587343215942, 0.7378731966018677, 0.7236528396606445, 0.7267305254936218, 0.7210326790809631, 0.7084981799125671, 0.7043206691741943, 0.6922367811203003, 0.6987642049789429, 0.691804051399231, 0.699891984462738, 0.6861215233802795, 0.6844877600669861, 0.6729302406311035, 0.6682050824165344, 0.6781639456748962, 0.6691833138465881, 0.6673364043235779, 0.6450210213661194, 0.6512312293052673, 0.6447327136993408, 0.6433939933776855, 0.6390063166618347, 0.63920658826828, 0.6299381256103516, 0.6309442520141602, 0.6102402806282043, 0.6242514848709106, 0.6381917595863342, 0.6164355278015137, 0.6134698987007141, 0.6055346131324768, 0.6073756814002991, 0.5985657572746277, 0.6116520762443542, 0.6040034294128418, 0.579035758972168, 0.5675603747367859, 0.5734281539916992, 0.564437210559845, 0.5699100494384766, 0.5580697059631348, 0.5647371411323547, 0.5628944039344788, 0.5446704030036926, 0.5627606511116028, 0.5499396324157715, 0.5508147478103638, 0.5473728179931641, 0.5390500426292419, 0.5292037725448608, 0.5483478307723999, 0.5412293076515198, 0.5195200443267822, 0.5282537341117859, 0.5346519947052002, 0.5136515498161316, 0.5170363187789917, 0.5271320939064026, 0.5447679162025452, 0.5161528587341309, 0.5119768381118774, 0.5081110596656799, 0.5253759622573853, 0.49361079931259155, 0.49318259954452515, 0.4933738112449646, 0.5027160048484802, 0.48333582282066345, 0.4737577438354492, 0.47413983941078186, 0.48119989037513733, 0.4836818277835846, 0.4707120954990387, 0.46149787306785583, 0.47229519486427307, 0.4634073078632355, 0.4577283263206482, 0.4655812382698059, 0.4640544652938843, 0.46208813786506653, 0.4438007175922394, 0.45827069878578186, 0.45617255568504333, 0.4336594045162201, 0.4395938515663147, 0.4527536630630493, 0.43155789375305176, 0.4321664869785309, 0.44083112478256226, 0.42721283435821533, 0.4463713467121124, 0.42752113938331604], 'accuracy': [0.8138087391853333, 0.8254103064537048, 0.8322014808654785, 0.8344652056694031, 0.833616316318512, 0.8384267091751099, 0.8384267091751099, 0.8375778198242188, 0.839275598526001, 0.8500282764434814, 0.8449349403381348, 0.850311279296875, 0.8599320650100708, 0.8579513430595398, 0.8658743500709534, 0.8604980111122131, 0.8638936281204224, 0.8607810139656067, 0.8610639572143555, 0.8695529103279114, 0.8752122521400452, 0.8763440847396851, 0.8672891855239868, 0.875495195388794, 0.8723825812339783, 0.8865308165550232, 0.8786078095436096, 0.8808715343475342, 0.8837012052536011, 0.8805885910987854, 0.8865308165550232, 0.8930390477180481, 0.8879456520080566, 0.895868718624115, 0.8887945413589478, 0.8803055882453918, 0.8938879370689392, 0.8975664973258972, 0.9003961682319641, 0.8992642760276794, 0.9035087823867798, 0.8950198292732239, 0.9001131653785706, 0.9153932929039001, 0.918222963809967, 0.9122806787490845, 0.9207696914672852, 0.9142614603042603, 0.9202037453651428, 0.9119977355003357, 0.9204866886138916, 0.9272778630256653, 0.9142614603042603, 0.9227504134178162, 0.9193548560142517, 0.9196377992630005, 0.9250141382217407, 0.9309564232826233, 0.9216185808181763, 0.9258630275726318, 0.9363327622413635, 0.9301075339317322, 0.9255800843238831, 0.9380305409431458, 0.9391624331474304, 0.9255800843238831, 0.9176570177078247, 0.9352009296417236, 0.9371816515922546, 0.9332201480865479, 0.9258630275726318, 0.9405772686004639, 0.9456706047058105, 0.9422750473022461, 0.9352009296417236, 0.9468024969100952, 0.9496321678161621, 0.9513299465179443, 0.9425579905509949, 0.9417091012001038, 0.9533106684684753, 0.9552914500236511, 0.9524617791175842, 0.9510469436645508, 0.9552914500236511, 0.9501980543136597, 0.9558573961257935, 0.9501980543136597, 0.9629315137863159, 0.9550085067749023, 0.95444256067276, 0.9657611846923828, 0.9623655676841736, 0.9569892287254333, 0.9657611846923828, 0.9646292924880981, 0.9584040641784668, 0.9643463492393494, 0.958121120929718, 0.9649122953414917], 'val_loss': [1.0620670318603516, 1.0600292682647705, 1.0571848154067993, 1.0530844926834106, 1.050012469291687, 1.0465646982192993, 1.0436261892318726, 1.0420328378677368, 1.0322580337524414, 1.0273175239562988, 1.0290143489837646, 1.0193367004394531, 1.0129663944244385, 1.006752371788025, 1.0050204992294312, 1.0032811164855957, 1.0232857465744019, 1.0131149291992188, 1.018166422843933, 1.0441508293151855, 1.020548701286316, 1.0485330820083618, 1.0159759521484375, 1.0252677202224731, 1.023288369178772, 1.0349030494689941, 1.0483276844024658, 1.0384461879730225, 1.0429294109344482, 1.0592083930969238, 1.0620681047439575, 1.0664736032485962, 1.0695946216583252, 1.074878454208374, 1.0846807956695557, 1.0788066387176514, 1.0935041904449463, 1.1276874542236328, 1.0980263948440552, 1.1045609712600708, 1.1255707740783691, 1.1003865003585815, 1.108076810836792, 1.1118147373199463, 1.1696137189865112, 1.1140190362930298, 1.116787075996399, 1.143632411956787, 1.1336792707443237, 1.1546319723129272, 1.143304705619812, 1.1440601348876953, 1.1616491079330444, 1.152443528175354, 1.1548659801483154, 1.1582401990890503, 1.1783920526504517, 1.1677069664001465, 1.2897768020629883, 1.1745116710662842, 1.1869248151779175, 1.239883542060852, 1.182879090309143, 1.1893330812454224, 1.1928454637527466, 1.307811975479126, 1.241070032119751, 1.2113569974899292, 1.2077770233154297, 1.2674877643585205, 1.223785400390625, 1.2253490686416626, 1.2311514616012573, 1.2331806421279907, 1.2351024150848389, 1.2539201974868774, 1.2425415515899658, 1.2541282176971436, 1.2497140169143677, 1.2576100826263428, 1.286999225616455, 1.2834076881408691, 1.2929812669754028, 1.2994961738586426, 1.294374942779541, 1.3157709836959839, 1.308976650238037, 1.303483009338379, 1.308513879776001, 1.4396263360977173, 1.3216700553894043, 1.327799677848816, 1.336540937423706, 1.3244383335113525, 1.3729214668273926, 1.3337239027023315, 1.363358974456787, 1.3623594045639038, 1.3565762042999268, 1.3437215089797974], 'val_accuracy': [0.6233031749725342, 0.622171938419342, 0.6187782883644104, 0.6119909286499023, 0.627828061580658, 0.6323529481887817, 0.6255655884742737, 0.6006787419319153, 0.627828061580658, 0.6266968250274658, 0.6142534017562866, 0.6334841847419739, 0.6323529481887817, 0.6425339579582214, 0.6481900215148926, 0.6595022678375244, 0.6346153616905212, 0.6561086177825928, 0.6572397947311401, 0.6470588445663452, 0.6651583909988403, 0.6606335043907166, 0.6821267008781433, 0.6753393411636353, 0.6900452375411987, 0.6787330508232117, 0.6877828240394592, 0.6889140009880066, 0.6957013607025146, 0.6979637742042542, 0.6911764740943909, 0.6945701241493225, 0.6957013607025146, 0.6979637742042542, 0.6911764740943909, 0.6979637742042542, 0.6889140009880066, 0.6866515874862671, 0.7024886608123779, 0.6843891143798828, 0.6866515874862671, 0.6990950107574463, 0.6900452375411987, 0.6945701241493225, 0.6821267008781433, 0.692307710647583, 0.7047511339187622, 0.6900452375411987, 0.7024886608123779, 0.6934388875961304, 0.7013574838638306, 0.6934388875961304, 0.692307710647583, 0.6979637742042542, 0.6945701241493225, 0.7013574838638306, 0.6911764740943909, 0.7024886608123779, 0.6674208045005798, 0.6957013607025146, 0.6934388875961304, 0.6821267008781433, 0.6968325972557068, 0.6934388875961304, 0.7036198973655701, 0.6764705777168274, 0.685520350933075, 0.6911764740943909, 0.6990950107574463, 0.6809954643249512, 0.6821267008781433, 0.6900452375411987, 0.6945701241493225, 0.6945701241493225, 0.6968325972557068, 0.6866515874862671, 0.6957013607025146, 0.6934388875961304, 0.6957013607025146, 0.6968325972557068, 0.6843891143798828, 0.6945701241493225, 0.692307710647583, 0.6843891143798828, 0.692307710647583, 0.6821267008781433, 0.692307710647583, 0.692307710647583, 0.6911764740943909, 0.6753393411636353, 0.6900452375411987, 0.6877828240394592, 0.692307710647583, 0.6832579374313354, 0.6911764740943909, 0.6945701241493225, 0.6889140009880066, 0.6900452375411987, 0.679864227771759, 0.6821267008781433]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.8499 - accuracy: 0.7917"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 58ms/step - loss: 0.8479 - accuracy: 0.7928 - val_loss: 1.0657 - val_accuracy: 0.6198\n","Epoch 2/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8126 - accuracy: 0.8065 - val_loss: 1.0650 - val_accuracy: 0.5785\n","Epoch 3/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8241 - accuracy: 0.7928 - val_loss: 1.0604 - val_accuracy: 0.6095\n","Epoch 4/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7889 - accuracy: 0.8178 - val_loss: 1.0578 - val_accuracy: 0.6054\n","Epoch 5/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7885 - accuracy: 0.8129 - val_loss: 1.0553 - val_accuracy: 0.6126\n","Epoch 6/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7844 - accuracy: 0.8155 - val_loss: 1.0506 - val_accuracy: 0.6095\n","Epoch 7/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7673 - accuracy: 0.8289 - val_loss: 1.0473 - val_accuracy: 0.6064\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7600 - accuracy: 0.8287 - val_loss: 1.0428 - val_accuracy: 0.6136\n","Epoch 9/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7662 - accuracy: 0.8274 - val_loss: 1.0400 - val_accuracy: 0.6023\n","Epoch 10/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7567 - accuracy: 0.8240 - val_loss: 1.0340 - val_accuracy: 0.6167\n","Epoch 11/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7521 - accuracy: 0.8388 - val_loss: 1.0390 - val_accuracy: 0.5950\n","Epoch 12/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7658 - accuracy: 0.8189 - val_loss: 1.0357 - val_accuracy: 0.6064\n","Epoch 13/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7617 - accuracy: 0.8271 - val_loss: 1.0214 - val_accuracy: 0.6260\n","Epoch 14/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.7391 - accuracy: 0.8434 - val_loss: 1.0192 - val_accuracy: 0.6302\n","Epoch 15/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7448 - accuracy: 0.8326 - val_loss: 1.0182 - val_accuracy: 0.6436\n","Epoch 16/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.7226 - accuracy: 0.8543 - val_loss: 1.0180 - val_accuracy: 0.6550\n","Epoch 17/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7183 - accuracy: 0.8556 - val_loss: 1.0348 - val_accuracy: 0.6364\n","Epoch 18/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7279 - accuracy: 0.8426 - val_loss: 1.0198 - val_accuracy: 0.6539\n","Epoch 19/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7250 - accuracy: 0.8437 - val_loss: 1.0169 - val_accuracy: 0.6519\n","Epoch 20/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.7078 - accuracy: 0.8517 - val_loss: 1.0157 - val_accuracy: 0.6643\n","Epoch 21/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7099 - accuracy: 0.8504 - val_loss: 1.0291 - val_accuracy: 0.6736\n","Epoch 22/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.6918 - accuracy: 0.8618 - val_loss: 1.0418 - val_accuracy: 0.6746\n","Epoch 23/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.6945 - accuracy: 0.8628 - val_loss: 1.0242 - val_accuracy: 0.6777\n","Epoch 24/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.6917 - accuracy: 0.8602 - val_loss: 1.0267 - val_accuracy: 0.6798\n","Epoch 25/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6964 - accuracy: 0.8563 - val_loss: 1.0265 - val_accuracy: 0.6736\n","Epoch 26/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6828 - accuracy: 0.8628 - val_loss: 1.0365 - val_accuracy: 0.6705\n","Epoch 27/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6761 - accuracy: 0.8643 - val_loss: 1.0641 - val_accuracy: 0.6860\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6777 - accuracy: 0.8693 - val_loss: 1.0710 - val_accuracy: 0.6684\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6703 - accuracy: 0.8638 - val_loss: 1.0810 - val_accuracy: 0.6581\n","Epoch 30/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6667 - accuracy: 0.8695 - val_loss: 1.0859 - val_accuracy: 0.6921\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6665 - accuracy: 0.8685 - val_loss: 1.0746 - val_accuracy: 0.6921\n","Epoch 32/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6577 - accuracy: 0.8698 - val_loss: 1.1187 - val_accuracy: 0.6890\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6530 - accuracy: 0.8736 - val_loss: 1.0719 - val_accuracy: 0.6787\n","Epoch 34/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6485 - accuracy: 0.8806 - val_loss: 1.0821 - val_accuracy: 0.6839\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6380 - accuracy: 0.8829 - val_loss: 1.0957 - val_accuracy: 0.6901\n","Epoch 36/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6461 - accuracy: 0.8724 - val_loss: 1.0951 - val_accuracy: 0.6715\n","Epoch 37/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6360 - accuracy: 0.8837 - val_loss: 1.0866 - val_accuracy: 0.6890\n","Epoch 38/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6320 - accuracy: 0.8829 - val_loss: 1.0990 - val_accuracy: 0.6911\n","Epoch 39/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6340 - accuracy: 0.8891 - val_loss: 1.1053 - val_accuracy: 0.6694\n","Epoch 40/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6256 - accuracy: 0.8899 - val_loss: 1.0969 - val_accuracy: 0.6777\n","Epoch 41/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6230 - accuracy: 0.8891 - val_loss: 1.1419 - val_accuracy: 0.6890\n","Epoch 42/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6231 - accuracy: 0.8871 - val_loss: 1.1162 - val_accuracy: 0.6787\n","Epoch 43/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6123 - accuracy: 0.8943 - val_loss: 1.1167 - val_accuracy: 0.6777\n","Epoch 44/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6027 - accuracy: 0.9018 - val_loss: 1.1479 - val_accuracy: 0.6591\n","Epoch 45/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6081 - accuracy: 0.8951 - val_loss: 1.1343 - val_accuracy: 0.6767\n","Epoch 46/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.5911 - accuracy: 0.9075 - val_loss: 1.1780 - val_accuracy: 0.6560\n","Epoch 47/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6051 - accuracy: 0.8964 - val_loss: 1.1644 - val_accuracy: 0.6890\n","Epoch 48/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6011 - accuracy: 0.8964 - val_loss: 1.1401 - val_accuracy: 0.6849\n","Epoch 49/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5968 - accuracy: 0.8974 - val_loss: 1.1742 - val_accuracy: 0.6570\n","Epoch 50/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5928 - accuracy: 0.9036 - val_loss: 1.1370 - val_accuracy: 0.6756\n","Epoch 51/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5843 - accuracy: 0.9065 - val_loss: 1.1433 - val_accuracy: 0.6818\n","Epoch 52/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5841 - accuracy: 0.9065 - val_loss: 1.1566 - val_accuracy: 0.6694\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5744 - accuracy: 0.9152 - val_loss: 1.1635 - val_accuracy: 0.6736\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5671 - accuracy: 0.9152 - val_loss: 1.1801 - val_accuracy: 0.6818\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5779 - accuracy: 0.9023 - val_loss: 1.1871 - val_accuracy: 0.6591\n","Epoch 56/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5666 - accuracy: 0.9103 - val_loss: 1.1780 - val_accuracy: 0.6787\n","Epoch 57/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5938 - accuracy: 0.8979 - val_loss: 1.2086 - val_accuracy: 0.6550\n","Epoch 58/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5749 - accuracy: 0.9036 - val_loss: 1.1831 - val_accuracy: 0.6777\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5531 - accuracy: 0.9214 - val_loss: 1.1838 - val_accuracy: 0.6643\n","Epoch 60/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5482 - accuracy: 0.9222 - val_loss: 1.1978 - val_accuracy: 0.6756\n","Epoch 61/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5485 - accuracy: 0.9168 - val_loss: 1.2338 - val_accuracy: 0.6591\n","Epoch 62/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5675 - accuracy: 0.9124 - val_loss: 1.2019 - val_accuracy: 0.6736\n","Epoch 63/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5411 - accuracy: 0.9217 - val_loss: 1.1868 - val_accuracy: 0.6777\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5396 - accuracy: 0.9217 - val_loss: 1.2183 - val_accuracy: 0.6622\n","Epoch 65/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5360 - accuracy: 0.9271 - val_loss: 1.2168 - val_accuracy: 0.6653\n","Epoch 66/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5527 - accuracy: 0.9173 - val_loss: 1.3119 - val_accuracy: 0.6694\n","Epoch 67/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5324 - accuracy: 0.9274 - val_loss: 1.2141 - val_accuracy: 0.6715\n","Epoch 68/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5375 - accuracy: 0.9222 - val_loss: 1.2256 - val_accuracy: 0.6570\n","Epoch 69/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5253 - accuracy: 0.9305 - val_loss: 1.2276 - val_accuracy: 0.6767\n","Epoch 70/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5162 - accuracy: 0.9331 - val_loss: 1.2418 - val_accuracy: 0.6684\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5283 - accuracy: 0.9251 - val_loss: 1.2373 - val_accuracy: 0.6653\n","Epoch 72/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5099 - accuracy: 0.9333 - val_loss: 1.2462 - val_accuracy: 0.6694\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5051 - accuracy: 0.9413 - val_loss: 1.3050 - val_accuracy: 0.6767\n","Epoch 74/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4988 - accuracy: 0.9401 - val_loss: 1.2678 - val_accuracy: 0.6684\n","Epoch 75/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5102 - accuracy: 0.9328 - val_loss: 1.2691 - val_accuracy: 0.6715\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5037 - accuracy: 0.9377 - val_loss: 1.2758 - val_accuracy: 0.6622\n","Epoch 77/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5051 - accuracy: 0.9349 - val_loss: 1.2958 - val_accuracy: 0.6663\n","Epoch 78/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5052 - accuracy: 0.9344 - val_loss: 1.2846 - val_accuracy: 0.6632\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4969 - accuracy: 0.9398 - val_loss: 1.2891 - val_accuracy: 0.6581\n","Epoch 80/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5124 - accuracy: 0.9276 - val_loss: 1.2863 - val_accuracy: 0.6663\n","Epoch 81/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4936 - accuracy: 0.9416 - val_loss: 1.3001 - val_accuracy: 0.6715\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4947 - accuracy: 0.9380 - val_loss: 1.2969 - val_accuracy: 0.6550\n","Epoch 83/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5100 - accuracy: 0.9289 - val_loss: 1.2885 - val_accuracy: 0.6653\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4832 - accuracy: 0.9437 - val_loss: 1.3310 - val_accuracy: 0.6684\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4829 - accuracy: 0.9429 - val_loss: 1.3170 - val_accuracy: 0.6643\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4825 - accuracy: 0.9429 - val_loss: 1.3865 - val_accuracy: 0.6550\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4835 - accuracy: 0.9424 - val_loss: 1.3879 - val_accuracy: 0.6498\n","Epoch 88/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4878 - accuracy: 0.9385 - val_loss: 1.3228 - val_accuracy: 0.6715\n","Epoch 89/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4881 - accuracy: 0.9372 - val_loss: 1.3448 - val_accuracy: 0.6612\n","Epoch 90/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4726 - accuracy: 0.9460 - val_loss: 1.3410 - val_accuracy: 0.6643\n","Epoch 91/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4687 - accuracy: 0.9468 - val_loss: 1.3813 - val_accuracy: 0.6601\n","Epoch 92/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4839 - accuracy: 0.9380 - val_loss: 1.3596 - val_accuracy: 0.6560\n","Epoch 93/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4825 - accuracy: 0.9408 - val_loss: 1.3710 - val_accuracy: 0.6560\n","Epoch 94/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4549 - accuracy: 0.9563 - val_loss: 1.4251 - val_accuracy: 0.6653\n","Epoch 95/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4686 - accuracy: 0.9460 - val_loss: 1.3669 - val_accuracy: 0.6632\n","Epoch 96/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4598 - accuracy: 0.9509 - val_loss: 1.3723 - val_accuracy: 0.6653\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4470 - accuracy: 0.9587 - val_loss: 1.3892 - val_accuracy: 0.6653\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4609 - accuracy: 0.9501 - val_loss: 1.3608 - val_accuracy: 0.6694\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4518 - accuracy: 0.9530 - val_loss: 1.3979 - val_accuracy: 0.6643\n","Epoch 100/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4513 - accuracy: 0.9506 - val_loss: 1.3898 - val_accuracy: 0.6632\n","{'loss': [0.8478618264198303, 0.812571108341217, 0.8241481781005859, 0.7888659834861755, 0.7884932160377502, 0.7844206094741821, 0.7672861218452454, 0.7600430250167847, 0.7661664485931396, 0.7566738128662109, 0.7520909309387207, 0.765846312046051, 0.7616690397262573, 0.7390615344047546, 0.7447503209114075, 0.7225529551506042, 0.7182945013046265, 0.7278745174407959, 0.7249679565429688, 0.7078313231468201, 0.7099392414093018, 0.6918147206306458, 0.6944663524627686, 0.6917062997817993, 0.6963534951210022, 0.682763934135437, 0.6760997772216797, 0.6776540279388428, 0.670275092124939, 0.6666832566261292, 0.6665162444114685, 0.657658040523529, 0.6530188322067261, 0.6485316157341003, 0.6380402445793152, 0.6460877060890198, 0.6360068917274475, 0.6319519281387329, 0.6339999437332153, 0.6255702972412109, 0.6230494976043701, 0.6230649352073669, 0.6123471856117249, 0.6026652455329895, 0.6080647706985474, 0.5910817980766296, 0.605080246925354, 0.6011444926261902, 0.5967982411384583, 0.5927935242652893, 0.5842591524124146, 0.5840803980827332, 0.5743948817253113, 0.5671165585517883, 0.5779391527175903, 0.5665614008903503, 0.5938354134559631, 0.5749191641807556, 0.5530688166618347, 0.5482320189476013, 0.5485234260559082, 0.5675109624862671, 0.5410917401313782, 0.5396196246147156, 0.5359606146812439, 0.5527374744415283, 0.5323582291603088, 0.5374839305877686, 0.5253086090087891, 0.5161871910095215, 0.5283423066139221, 0.5099441409111023, 0.5051054358482361, 0.4987889230251312, 0.5101758241653442, 0.5037099719047546, 0.5051348209381104, 0.5052456259727478, 0.496858149766922, 0.5124154090881348, 0.4935850501060486, 0.4946771562099457, 0.5099508166313171, 0.4832030236721039, 0.48294809460639954, 0.4824988842010498, 0.48351749777793884, 0.4877556264400482, 0.4880661964416504, 0.4725712537765503, 0.4687215983867645, 0.4838680326938629, 0.4824603796005249, 0.4548713266849518, 0.46860218048095703, 0.4597870111465454, 0.4469946324825287, 0.46086984872817993, 0.4517839848995209, 0.45128771662712097], 'accuracy': [0.7927648425102234, 0.8064599633216858, 0.7927648425102234, 0.817829430103302, 0.8129199147224426, 0.8155038952827454, 0.8289405703544617, 0.8286821842193604, 0.827390193939209, 0.8240309953689575, 0.8387596607208252, 0.818863034248352, 0.8271318078041077, 0.843410849571228, 0.8325581550598145, 0.8542635440826416, 0.855555534362793, 0.8426356315612793, 0.8436692357063293, 0.8516795635223389, 0.8503875732421875, 0.8617570996284485, 0.8627907037734985, 0.8602067232131958, 0.8563307523727417, 0.8627907037734985, 0.8643410801887512, 0.8692506551742554, 0.8638243079185486, 0.8695090413093567, 0.8684754371643066, 0.869767427444458, 0.8736433982849121, 0.8806201815605164, 0.882945716381073, 0.8723514080047607, 0.8837209343910217, 0.882945716381073, 0.8891472816467285, 0.8899224996566772, 0.8891472816467285, 0.8870801329612732, 0.894315242767334, 0.9018087983131409, 0.8950904607772827, 0.907493531703949, 0.8963824510574341, 0.8963824510574341, 0.8974159955978394, 0.9036175608634949, 0.9064599275588989, 0.9064599275588989, 0.9152454733848572, 0.9152454733848572, 0.9023255705833435, 0.910335898399353, 0.8979328274726868, 0.9036175608634949, 0.9214470386505127, 0.9222221970558167, 0.9167958498001099, 0.9124031066894531, 0.921705424785614, 0.921705424785614, 0.9271317720413208, 0.9173126816749573, 0.9273901581764221, 0.9222221970558167, 0.9304909706115723, 0.933074951171875, 0.9250646233558655, 0.9333333373069763, 0.9413436651229858, 0.9400516748428345, 0.9328165650367737, 0.9377260804176331, 0.934883713722229, 0.9343669414520264, 0.9397932887077332, 0.9276486039161682, 0.9416020512580872, 0.9379844665527344, 0.9289405941963196, 0.9436692595481873, 0.9428940415382385, 0.9428940415382385, 0.9423772692680359, 0.9385012984275818, 0.9372093081474304, 0.9459948539733887, 0.9467700123786926, 0.9379844665527344, 0.9408268928527832, 0.9563307762145996, 0.9459948539733887, 0.950904369354248, 0.9586563110351562, 0.9501292109489441, 0.9529715776443481, 0.9506459832191467], 'val_loss': [1.0656815767288208, 1.0650432109832764, 1.0604151487350464, 1.0578497648239136, 1.0552643537521362, 1.0505709648132324, 1.0472781658172607, 1.042809247970581, 1.040021538734436, 1.0339751243591309, 1.0390360355377197, 1.0357369184494019, 1.0214091539382935, 1.0191938877105713, 1.0182231664657593, 1.0179673433303833, 1.0348117351531982, 1.019849181175232, 1.0169037580490112, 1.015675663948059, 1.029126524925232, 1.0417875051498413, 1.0241771936416626, 1.026742696762085, 1.0264513492584229, 1.0365498065948486, 1.064124584197998, 1.0710400342941284, 1.0809624195098877, 1.0858960151672363, 1.0745631456375122, 1.118720293045044, 1.0718728303909302, 1.0820529460906982, 1.0957378149032593, 1.0951075553894043, 1.086637258529663, 1.0990456342697144, 1.1053118705749512, 1.0969454050064087, 1.1419076919555664, 1.116189956665039, 1.1167274713516235, 1.1479473114013672, 1.134321928024292, 1.1779793500900269, 1.1644331216812134, 1.140087366104126, 1.1742284297943115, 1.1369760036468506, 1.1432840824127197, 1.1566237211227417, 1.1634689569473267, 1.1801403760910034, 1.187117099761963, 1.1780331134796143, 1.2086074352264404, 1.1830931901931763, 1.1838124990463257, 1.1978358030319214, 1.2337900400161743, 1.2018933296203613, 1.1868196725845337, 1.2183212041854858, 1.2167623043060303, 1.3118573427200317, 1.2141025066375732, 1.2255820035934448, 1.2275770902633667, 1.2418487071990967, 1.2373143434524536, 1.2461858987808228, 1.3049966096878052, 1.2678351402282715, 1.269094467163086, 1.2757712602615356, 1.2958307266235352, 1.284574031829834, 1.289135456085205, 1.28628408908844, 1.3000953197479248, 1.2968590259552002, 1.288468360900879, 1.3310409784317017, 1.317035436630249, 1.3865063190460205, 1.3879308700561523, 1.3227535486221313, 1.3447836637496948, 1.3410242795944214, 1.3812860250473022, 1.3595936298370361, 1.3709934949874878, 1.4251199960708618, 1.3669264316558838, 1.372287631034851, 1.3892405033111572, 1.3608418703079224, 1.397866129875183, 1.389813780784607], 'val_accuracy': [0.6198347210884094, 0.5785123705863953, 0.6095041036605835, 0.60537189245224, 0.6126033067703247, 0.6095041036605835, 0.6064049601554871, 0.6136363744735718, 0.6022727489471436, 0.6167355179786682, 0.5950413346290588, 0.6064049601554871, 0.6260330677032471, 0.6301652789115906, 0.6435950398445129, 0.6549586653709412, 0.6363636255264282, 0.6539255976676941, 0.6518595218658447, 0.66425621509552, 0.6735537052154541, 0.6745867729187012, 0.6776859760284424, 0.6797520518302917, 0.6735537052154541, 0.6704545617103577, 0.6859503984451294, 0.6683884263038635, 0.6580578684806824, 0.692148745059967, 0.692148745059967, 0.6890496015548706, 0.6787189841270447, 0.68388432264328, 0.6900826692581177, 0.6714876294136047, 0.6890496015548706, 0.69111567735672, 0.6694214940071106, 0.6776859760284424, 0.6890496015548706, 0.6787189841270447, 0.6776859760284424, 0.6590909361839294, 0.6766529083251953, 0.6559917330741882, 0.6890496015548706, 0.6849173307418823, 0.6570248007774353, 0.6756198406219482, 0.6818181872367859, 0.6694214940071106, 0.6735537052154541, 0.6818181872367859, 0.6590909361839294, 0.6787189841270447, 0.6549586653709412, 0.6776859760284424, 0.66425621509552, 0.6756198406219482, 0.6590909361839294, 0.6735537052154541, 0.6776859760284424, 0.6621900796890259, 0.6652892827987671, 0.6694214940071106, 0.6714876294136047, 0.6570248007774353, 0.6766529083251953, 0.6683884263038635, 0.6652892827987671, 0.6694214940071106, 0.6766529083251953, 0.6683884263038635, 0.6714876294136047, 0.6621900796890259, 0.6663222908973694, 0.663223147392273, 0.6580578684806824, 0.6663222908973694, 0.6714876294136047, 0.6549586653709412, 0.6652892827987671, 0.6683884263038635, 0.66425621509552, 0.6549586653709412, 0.6497933864593506, 0.6714876294136047, 0.6611570119857788, 0.66425621509552, 0.6601239442825317, 0.6559917330741882, 0.6559917330741882, 0.6652892827987671, 0.663223147392273, 0.6652892827987671, 0.6652892827987671, 0.6694214940071106, 0.66425621509552, 0.663223147392273]}\n","32/32 [==============================] - 1s 6ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.5856 - accuracy: 0.9006"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 58ms/step - loss: 0.5856 - accuracy: 0.9006 - val_loss: 0.9884 - val_accuracy: 0.6088\n","Epoch 2/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5412 - accuracy: 0.9108 - val_loss: 0.9867 - val_accuracy: 0.5981\n","Epoch 3/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5321 - accuracy: 0.9154 - val_loss: 0.9825 - val_accuracy: 0.6110\n","Epoch 4/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5162 - accuracy: 0.9243 - val_loss: 0.9794 - val_accuracy: 0.6110\n","Epoch 5/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5170 - accuracy: 0.9224 - val_loss: 0.9816 - val_accuracy: 0.5884\n","Epoch 6/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5071 - accuracy: 0.9265 - val_loss: 0.9704 - val_accuracy: 0.6153\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5021 - accuracy: 0.9254 - val_loss: 0.9774 - val_accuracy: 0.6002\n","Epoch 8/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.5115 - accuracy: 0.9195 - val_loss: 0.9698 - val_accuracy: 0.6175\n","Epoch 9/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.5020 - accuracy: 0.9275 - val_loss: 0.9589 - val_accuracy: 0.6347\n","Epoch 10/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.4899 - accuracy: 0.9294 - val_loss: 0.9618 - val_accuracy: 0.6444\n","Epoch 11/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4792 - accuracy: 0.9383 - val_loss: 0.9642 - val_accuracy: 0.6347\n","Epoch 12/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4762 - accuracy: 0.9353 - val_loss: 0.9723 - val_accuracy: 0.6433\n","Epoch 13/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4758 - accuracy: 0.9348 - val_loss: 0.9803 - val_accuracy: 0.6455\n","Epoch 14/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4674 - accuracy: 0.9432 - val_loss: 0.9807 - val_accuracy: 0.6476\n","Epoch 15/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.4801 - accuracy: 0.9367 - val_loss: 1.0196 - val_accuracy: 0.6552\n","Epoch 16/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4594 - accuracy: 0.9469 - val_loss: 1.0303 - val_accuracy: 0.6649\n","Epoch 17/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4652 - accuracy: 0.9418 - val_loss: 1.0330 - val_accuracy: 0.6670\n","Epoch 18/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4581 - accuracy: 0.9464 - val_loss: 1.0392 - val_accuracy: 0.6746\n","Epoch 19/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4692 - accuracy: 0.9391 - val_loss: 1.0458 - val_accuracy: 0.6735\n","Epoch 20/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4478 - accuracy: 0.9480 - val_loss: 1.0580 - val_accuracy: 0.6983\n","Epoch 21/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4572 - accuracy: 0.9415 - val_loss: 1.0478 - val_accuracy: 0.7004\n","Epoch 22/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.4504 - accuracy: 0.9494 - val_loss: 1.0354 - val_accuracy: 0.7134\n","Epoch 23/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4558 - accuracy: 0.9453 - val_loss: 1.0315 - val_accuracy: 0.7317\n","Epoch 24/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4386 - accuracy: 0.9534 - val_loss: 1.0446 - val_accuracy: 0.7392\n","Epoch 25/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.4344 - accuracy: 0.9569 - val_loss: 1.0482 - val_accuracy: 0.7403\n","Epoch 26/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.4436 - accuracy: 0.9515 - val_loss: 1.0325 - val_accuracy: 0.7457\n","Epoch 27/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4376 - accuracy: 0.9531 - val_loss: 1.0472 - val_accuracy: 0.7435\n","Epoch 28/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.4352 - accuracy: 0.9534 - val_loss: 1.0625 - val_accuracy: 0.7468\n","Epoch 29/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4252 - accuracy: 0.9547 - val_loss: 1.0630 - val_accuracy: 0.7403\n","Epoch 30/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.4303 - accuracy: 0.9558 - val_loss: 1.0827 - val_accuracy: 0.7489\n","Epoch 31/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4262 - accuracy: 0.9566 - val_loss: 1.0857 - val_accuracy: 0.7478\n","Epoch 32/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4391 - accuracy: 0.9475 - val_loss: 1.0989 - val_accuracy: 0.7478\n","Epoch 33/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4425 - accuracy: 0.9494 - val_loss: 1.0769 - val_accuracy: 0.7586\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4199 - accuracy: 0.9582 - val_loss: 1.0738 - val_accuracy: 0.7586\n","Epoch 35/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4134 - accuracy: 0.9642 - val_loss: 1.0956 - val_accuracy: 0.7543\n","Epoch 36/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4273 - accuracy: 0.9499 - val_loss: 1.1711 - val_accuracy: 0.7338\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4209 - accuracy: 0.9572 - val_loss: 1.0985 - val_accuracy: 0.7522\n","Epoch 38/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4077 - accuracy: 0.9679 - val_loss: 1.1315 - val_accuracy: 0.7543\n","Epoch 39/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4167 - accuracy: 0.9601 - val_loss: 1.1864 - val_accuracy: 0.7274\n","Epoch 40/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4173 - accuracy: 0.9601 - val_loss: 1.1469 - val_accuracy: 0.7478\n","Epoch 41/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4059 - accuracy: 0.9639 - val_loss: 1.1455 - val_accuracy: 0.7435\n","Epoch 42/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4042 - accuracy: 0.9644 - val_loss: 1.1462 - val_accuracy: 0.7457\n","Epoch 43/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4125 - accuracy: 0.9574 - val_loss: 1.1499 - val_accuracy: 0.7435\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4091 - accuracy: 0.9639 - val_loss: 1.1373 - val_accuracy: 0.7543\n","Epoch 45/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3935 - accuracy: 0.9671 - val_loss: 1.1437 - val_accuracy: 0.7543\n","Epoch 46/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3885 - accuracy: 0.9698 - val_loss: 1.1396 - val_accuracy: 0.7543\n","Epoch 47/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4122 - accuracy: 0.9582 - val_loss: 1.1928 - val_accuracy: 0.7468\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3953 - accuracy: 0.9679 - val_loss: 1.2017 - val_accuracy: 0.7381\n","Epoch 49/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3925 - accuracy: 0.9685 - val_loss: 1.1591 - val_accuracy: 0.7425\n","Epoch 50/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3962 - accuracy: 0.9663 - val_loss: 1.1705 - val_accuracy: 0.7446\n","Epoch 51/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3953 - accuracy: 0.9647 - val_loss: 1.1840 - val_accuracy: 0.7392\n","Epoch 52/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3931 - accuracy: 0.9688 - val_loss: 1.1851 - val_accuracy: 0.7500\n","Epoch 53/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3778 - accuracy: 0.9776 - val_loss: 1.1937 - val_accuracy: 0.7468\n","Epoch 54/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3802 - accuracy: 0.9706 - val_loss: 1.1972 - val_accuracy: 0.7457\n","Epoch 55/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3756 - accuracy: 0.9760 - val_loss: 1.1921 - val_accuracy: 0.7446\n","Epoch 56/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3763 - accuracy: 0.9752 - val_loss: 1.2112 - val_accuracy: 0.7446\n","Epoch 57/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3745 - accuracy: 0.9736 - val_loss: 1.2159 - val_accuracy: 0.7425\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3786 - accuracy: 0.9714 - val_loss: 1.2119 - val_accuracy: 0.7414\n","Epoch 59/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3853 - accuracy: 0.9652 - val_loss: 1.2305 - val_accuracy: 0.7371\n","Epoch 60/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3786 - accuracy: 0.9714 - val_loss: 1.2132 - val_accuracy: 0.7446\n","Epoch 61/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3901 - accuracy: 0.9685 - val_loss: 1.2413 - val_accuracy: 0.7414\n","Epoch 62/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3774 - accuracy: 0.9712 - val_loss: 1.2166 - val_accuracy: 0.7446\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3733 - accuracy: 0.9723 - val_loss: 1.2279 - val_accuracy: 0.7414\n","Epoch 64/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3799 - accuracy: 0.9685 - val_loss: 1.2284 - val_accuracy: 0.7468\n","Epoch 65/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3703 - accuracy: 0.9741 - val_loss: 1.2455 - val_accuracy: 0.7381\n","Epoch 66/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3595 - accuracy: 0.9801 - val_loss: 1.2410 - val_accuracy: 0.7425\n","Epoch 67/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3594 - accuracy: 0.9801 - val_loss: 1.2542 - val_accuracy: 0.7392\n","Epoch 68/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3689 - accuracy: 0.9733 - val_loss: 1.2442 - val_accuracy: 0.7425\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3554 - accuracy: 0.9814 - val_loss: 1.2564 - val_accuracy: 0.7500\n","Epoch 70/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3596 - accuracy: 0.9774 - val_loss: 1.2657 - val_accuracy: 0.7435\n","Epoch 71/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3701 - accuracy: 0.9714 - val_loss: 1.2948 - val_accuracy: 0.7392\n","Epoch 72/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3588 - accuracy: 0.9776 - val_loss: 1.2600 - val_accuracy: 0.7489\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3571 - accuracy: 0.9784 - val_loss: 1.2773 - val_accuracy: 0.7425\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3539 - accuracy: 0.9822 - val_loss: 1.3012 - val_accuracy: 0.7403\n","Epoch 75/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3547 - accuracy: 0.9809 - val_loss: 1.3030 - val_accuracy: 0.7500\n","Epoch 76/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3558 - accuracy: 0.9803 - val_loss: 1.2761 - val_accuracy: 0.7435\n","Epoch 77/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3520 - accuracy: 0.9806 - val_loss: 1.2958 - val_accuracy: 0.7457\n","Epoch 78/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3512 - accuracy: 0.9806 - val_loss: 1.3099 - val_accuracy: 0.7328\n","Epoch 79/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3498 - accuracy: 0.9809 - val_loss: 1.2891 - val_accuracy: 0.7371\n","Epoch 80/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3485 - accuracy: 0.9817 - val_loss: 1.3130 - val_accuracy: 0.7328\n","Epoch 81/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3726 - accuracy: 0.9690 - val_loss: 1.3150 - val_accuracy: 0.7360\n","Epoch 82/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3538 - accuracy: 0.9782 - val_loss: 1.3150 - val_accuracy: 0.7295\n","Epoch 83/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3452 - accuracy: 0.9825 - val_loss: 1.3104 - val_accuracy: 0.7381\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3460 - accuracy: 0.9825 - val_loss: 1.3503 - val_accuracy: 0.7306\n","Epoch 85/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3389 - accuracy: 0.9849 - val_loss: 1.3134 - val_accuracy: 0.7489\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3373 - accuracy: 0.9849 - val_loss: 1.4009 - val_accuracy: 0.7360\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3457 - accuracy: 0.9801 - val_loss: 1.3134 - val_accuracy: 0.7381\n","Epoch 88/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3464 - accuracy: 0.9811 - val_loss: 1.4002 - val_accuracy: 0.7371\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3531 - accuracy: 0.9755 - val_loss: 1.2966 - val_accuracy: 0.7392\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3575 - accuracy: 0.9771 - val_loss: 1.3984 - val_accuracy: 0.7209\n","Epoch 91/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3519 - accuracy: 0.9774 - val_loss: 1.3627 - val_accuracy: 0.7328\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3416 - accuracy: 0.9830 - val_loss: 1.3070 - val_accuracy: 0.7414\n","Epoch 93/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3381 - accuracy: 0.9846 - val_loss: 1.3150 - val_accuracy: 0.7414\n","Epoch 94/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3281 - accuracy: 0.9876 - val_loss: 1.3485 - val_accuracy: 0.7371\n","Epoch 95/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3414 - accuracy: 0.9811 - val_loss: 1.3328 - val_accuracy: 0.7338\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3386 - accuracy: 0.9836 - val_loss: 1.3581 - val_accuracy: 0.7295\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3316 - accuracy: 0.9865 - val_loss: 1.3496 - val_accuracy: 0.7328\n","Epoch 98/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3312 - accuracy: 0.9855 - val_loss: 1.3515 - val_accuracy: 0.7435\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3253 - accuracy: 0.9873 - val_loss: 1.3781 - val_accuracy: 0.7306\n","Epoch 100/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3320 - accuracy: 0.9849 - val_loss: 1.3669 - val_accuracy: 0.7446\n","{'loss': [0.5855897665023804, 0.5411715507507324, 0.532094419002533, 0.5162169933319092, 0.5169695615768433, 0.5071391463279724, 0.502077043056488, 0.5115295648574829, 0.5020409226417542, 0.4899136424064636, 0.4791756272315979, 0.4761504530906677, 0.4758424162864685, 0.4673568904399872, 0.48013997077941895, 0.4593561291694641, 0.4652385413646698, 0.4580517113208771, 0.469165176153183, 0.44780436158180237, 0.4571520686149597, 0.45037585496902466, 0.4558032155036926, 0.43861204385757446, 0.4344371259212494, 0.44356825947761536, 0.4375658631324768, 0.43519407510757446, 0.4251653552055359, 0.43033865094184875, 0.42621007561683655, 0.4390789270401001, 0.4424988925457001, 0.41990604996681213, 0.4134136140346527, 0.4273485839366913, 0.4208514094352722, 0.40771058201789856, 0.41669660806655884, 0.4172596335411072, 0.405905544757843, 0.4042249917984009, 0.4125138223171234, 0.40912264585494995, 0.3934887647628784, 0.38852018117904663, 0.41223227977752686, 0.39532238245010376, 0.3925022780895233, 0.3961738348007202, 0.395348459482193, 0.3930804431438446, 0.3778039813041687, 0.380234956741333, 0.37562936544418335, 0.37633949518203735, 0.3744962513446808, 0.37858766317367554, 0.3853275775909424, 0.37861475348472595, 0.39012932777404785, 0.37741661071777344, 0.3732670843601227, 0.37986356019973755, 0.3702583312988281, 0.359540194272995, 0.3594138026237488, 0.36888453364372253, 0.35543134808540344, 0.35956093668937683, 0.3700542151927948, 0.3587844967842102, 0.35709935426712036, 0.35393717885017395, 0.35473841428756714, 0.3558332324028015, 0.35196197032928467, 0.35119113326072693, 0.34981897473335266, 0.3484879434108734, 0.37264031171798706, 0.3538447618484497, 0.34520742297172546, 0.3459845185279846, 0.33890479803085327, 0.33728596568107605, 0.3456687927246094, 0.3463843762874603, 0.3531244397163391, 0.3574509024620056, 0.351934552192688, 0.34155386686325073, 0.33805909752845764, 0.3280573785305023, 0.3414413630962372, 0.33861616253852844, 0.33164840936660767, 0.3312239944934845, 0.3253363370895386, 0.3319830000400543], 'accuracy': [0.9005926847457886, 0.9108297228813171, 0.915409505367279, 0.9242995977401733, 0.9224137663841248, 0.9264547228813171, 0.9253771305084229, 0.9194504022598267, 0.9275323152542114, 0.9294180870056152, 0.9383081793785095, 0.9353448152542114, 0.9348060488700867, 0.9431573152542114, 0.9366918206214905, 0.946928858757019, 0.9418103694915771, 0.9463900923728943, 0.939116358757019, 0.9480064511299133, 0.9415409564971924, 0.9493534564971924, 0.9453125, 0.9533944129943848, 0.9568965435028076, 0.951508641242981, 0.953125, 0.9533944129943848, 0.954741358757019, 0.9558189511299133, 0.9566271305084229, 0.9474676847457886, 0.9493534564971924, 0.9582435488700867, 0.9641702771186829, 0.9498922228813171, 0.9571659564971924, 0.9679418206214905, 0.9601293206214905, 0.9601293206214905, 0.9639008641242981, 0.9644396305084229, 0.9574353694915771, 0.9639008641242981, 0.967133641242981, 0.9698275923728943, 0.9582435488700867, 0.9679418206214905, 0.9684805870056152, 0.9663254022598267, 0.9647090435028076, 0.96875, 0.9776400923728943, 0.9706357717514038, 0.9760237336158752, 0.975215494632721, 0.9735991358757019, 0.9714439511299133, 0.9652478694915771, 0.9714439511299133, 0.9684805870056152, 0.9711745977401733, 0.9722521305084229, 0.9684805870056152, 0.9741379022598267, 0.9800646305084229, 0.9800646305084229, 0.9733297228813171, 0.9814116358757019, 0.9773706793785095, 0.9714439511299133, 0.9776400923728943, 0.9784482717514038, 0.9822198152542114, 0.9808728694915771, 0.9803340435028076, 0.9806034564971924, 0.9806034564971924, 0.9808728694915771, 0.9816810488700867, 0.9690194129943848, 0.978178858757019, 0.9824892282485962, 0.9824892282485962, 0.9849137663841248, 0.9849137663841248, 0.9800646305084229, 0.9811422228813171, 0.9754849076271057, 0.9771012663841248, 0.9773706793785095, 0.983027994632721, 0.9846444129943848, 0.9876077771186829, 0.9811422228813171, 0.9835668206214905, 0.9865301847457886, 0.9854525923728943, 0.9873383641242981, 0.9849137663841248], 'val_loss': [0.9883779287338257, 0.9867420196533203, 0.9825394153594971, 0.9793683886528015, 0.9815769195556641, 0.970428466796875, 0.9773718118667603, 0.969826877117157, 0.9589424133300781, 0.9617676138877869, 0.9642278552055359, 0.9722829461097717, 0.9802558422088623, 0.9806919097900391, 1.019612193107605, 1.030271053314209, 1.0330252647399902, 1.0391522645950317, 1.0458277463912964, 1.0580216646194458, 1.0478484630584717, 1.0354152917861938, 1.0314537286758423, 1.0446463823318481, 1.048180341720581, 1.0324618816375732, 1.0471789836883545, 1.0624902248382568, 1.0629751682281494, 1.0826542377471924, 1.085747480392456, 1.0988596677780151, 1.0769286155700684, 1.0738182067871094, 1.0955597162246704, 1.1711033582687378, 1.0984752178192139, 1.131476879119873, 1.1864166259765625, 1.1468653678894043, 1.1454721689224243, 1.1461634635925293, 1.14987051486969, 1.1373445987701416, 1.1437259912490845, 1.1396212577819824, 1.192841649055481, 1.201676845550537, 1.1591100692749023, 1.17051100730896, 1.1840389966964722, 1.1850875616073608, 1.1937235593795776, 1.1972289085388184, 1.1920818090438843, 1.2112492322921753, 1.215937852859497, 1.2119112014770508, 1.2305264472961426, 1.2132072448730469, 1.2412762641906738, 1.2165614366531372, 1.2279391288757324, 1.2283921241760254, 1.2455151081085205, 1.2410110235214233, 1.2542071342468262, 1.2441637516021729, 1.2564189434051514, 1.2656779289245605, 1.2948170900344849, 1.2599698305130005, 1.277274250984192, 1.3011786937713623, 1.3030012845993042, 1.2760852575302124, 1.2958259582519531, 1.3099310398101807, 1.2891414165496826, 1.313026785850525, 1.3150198459625244, 1.3150007724761963, 1.3104043006896973, 1.350278377532959, 1.3134217262268066, 1.4008946418762207, 1.3134350776672363, 1.4002206325531006, 1.2965573072433472, 1.398421049118042, 1.3626735210418701, 1.3069597482681274, 1.3149632215499878, 1.3484553098678589, 1.3328163623809814, 1.3580801486968994, 1.349644422531128, 1.3514621257781982, 1.3781014680862427, 1.3668768405914307], 'val_accuracy': [0.6088362336158752, 0.5980603694915771, 0.610991358757019, 0.610991358757019, 0.5883620977401733, 0.6153017282485962, 0.600215494632721, 0.6174569129943848, 0.6346982717514038, 0.6443965435028076, 0.6346982717514038, 0.6433189511299133, 0.6454741358757019, 0.6476293206214905, 0.6551724076271057, 0.6648706793785095, 0.6670258641242981, 0.6745689511299133, 0.673491358757019, 0.6982758641242981, 0.7004310488700867, 0.7133620977401733, 0.7316810488700867, 0.7392241358757019, 0.7403017282485962, 0.7456896305084229, 0.743534505367279, 0.7467672228813171, 0.7403017282485962, 0.7489224076271057, 0.7478448152542114, 0.7478448152542114, 0.7586206793785095, 0.7586206793785095, 0.7543103694915771, 0.7338362336158752, 0.7521551847457886, 0.7543103694915771, 0.7273706793785095, 0.7478448152542114, 0.743534505367279, 0.7456896305084229, 0.743534505367279, 0.7543103694915771, 0.7543103694915771, 0.7543103694915771, 0.7467672228813171, 0.7381465435028076, 0.7424569129943848, 0.7446120977401733, 0.7392241358757019, 0.75, 0.7467672228813171, 0.7456896305084229, 0.7446120977401733, 0.7446120977401733, 0.7424569129943848, 0.7413793206214905, 0.7370689511299133, 0.7446120977401733, 0.7413793206214905, 0.7446120977401733, 0.7413793206214905, 0.7467672228813171, 0.7381465435028076, 0.7424569129943848, 0.7392241358757019, 0.7424569129943848, 0.75, 0.743534505367279, 0.7392241358757019, 0.7489224076271057, 0.7424569129943848, 0.7403017282485962, 0.75, 0.743534505367279, 0.7456896305084229, 0.732758641242981, 0.7370689511299133, 0.732758641242981, 0.735991358757019, 0.7295258641242981, 0.7381465435028076, 0.7306034564971924, 0.7489224076271057, 0.735991358757019, 0.7381465435028076, 0.7370689511299133, 0.7392241358757019, 0.7209051847457886, 0.732758641242981, 0.7413793206214905, 0.7413793206214905, 0.7370689511299133, 0.7338362336158752, 0.7295258641242981, 0.732758641242981, 0.743534505367279, 0.7306034564971924, 0.7446120977401733]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.5642 - accuracy: 0.9039"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 62ms/step - loss: 0.5621 - accuracy: 0.9049 - val_loss: 0.9896 - val_accuracy: 0.6199\n","Epoch 2/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5428 - accuracy: 0.9120 - val_loss: 0.9898 - val_accuracy: 0.5871\n","Epoch 3/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5392 - accuracy: 0.9179 - val_loss: 0.9896 - val_accuracy: 0.5645\n","Epoch 4/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5194 - accuracy: 0.9191 - val_loss: 0.9903 - val_accuracy: 0.5611\n","Epoch 5/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5334 - accuracy: 0.9168 - val_loss: 0.9932 - val_accuracy: 0.5577\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5190 - accuracy: 0.9219 - val_loss: 0.9775 - val_accuracy: 0.5950\n","Epoch 7/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4993 - accuracy: 0.9284 - val_loss: 0.9832 - val_accuracy: 0.5747\n","Epoch 8/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5049 - accuracy: 0.9281 - val_loss: 0.9754 - val_accuracy: 0.5950\n","Epoch 9/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4875 - accuracy: 0.9397 - val_loss: 0.9649 - val_accuracy: 0.6131\n","Epoch 10/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5013 - accuracy: 0.9276 - val_loss: 0.9654 - val_accuracy: 0.6176\n","Epoch 11/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4959 - accuracy: 0.9301 - val_loss: 0.9732 - val_accuracy: 0.6052\n","Epoch 12/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4812 - accuracy: 0.9392 - val_loss: 0.9717 - val_accuracy: 0.6154\n","Epoch 13/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.4928 - accuracy: 0.9324 - val_loss: 0.9641 - val_accuracy: 0.6335\n","Epoch 14/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4998 - accuracy: 0.9310 - val_loss: 0.9925 - val_accuracy: 0.6176\n","Epoch 15/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.4988 - accuracy: 0.9239 - val_loss: 0.9738 - val_accuracy: 0.6482\n","Epoch 16/100\n","28/28 [==============================] - 1s 40ms/step - loss: 0.4733 - accuracy: 0.9420 - val_loss: 0.9813 - val_accuracy: 0.6618\n","Epoch 17/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.5055 - accuracy: 0.9242 - val_loss: 0.9832 - val_accuracy: 0.6719\n","Epoch 18/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.4625 - accuracy: 0.9457 - val_loss: 0.9847 - val_accuracy: 0.6855\n","Epoch 19/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.4747 - accuracy: 0.9386 - val_loss: 1.0021 - val_accuracy: 0.6900\n","Epoch 20/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4595 - accuracy: 0.9465 - val_loss: 1.0419 - val_accuracy: 0.6833\n","Epoch 21/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.4619 - accuracy: 0.9468 - val_loss: 1.0192 - val_accuracy: 0.6934\n","Epoch 22/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.4702 - accuracy: 0.9403 - val_loss: 1.0270 - val_accuracy: 0.7014\n","Epoch 23/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.4529 - accuracy: 0.9471 - val_loss: 0.9979 - val_accuracy: 0.7195\n","Epoch 24/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.4530 - accuracy: 0.9519 - val_loss: 1.0003 - val_accuracy: 0.7206\n","Epoch 25/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4519 - accuracy: 0.9519 - val_loss: 0.9811 - val_accuracy: 0.7364\n","Epoch 26/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.4544 - accuracy: 0.9454 - val_loss: 1.0085 - val_accuracy: 0.7376\n","Epoch 27/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.4535 - accuracy: 0.9485 - val_loss: 0.9823 - val_accuracy: 0.7545\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4421 - accuracy: 0.9499 - val_loss: 0.9896 - val_accuracy: 0.7534\n","Epoch 29/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4368 - accuracy: 0.9573 - val_loss: 1.0138 - val_accuracy: 0.7466\n","Epoch 30/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4339 - accuracy: 0.9547 - val_loss: 1.0107 - val_accuracy: 0.7466\n","Epoch 31/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4360 - accuracy: 0.9570 - val_loss: 1.0111 - val_accuracy: 0.7534\n","Epoch 32/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.4230 - accuracy: 0.9626 - val_loss: 1.0302 - val_accuracy: 0.7568\n","Epoch 33/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4399 - accuracy: 0.9556 - val_loss: 1.0445 - val_accuracy: 0.7477\n","Epoch 34/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4331 - accuracy: 0.9576 - val_loss: 1.0384 - val_accuracy: 0.7511\n","Epoch 35/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4193 - accuracy: 0.9629 - val_loss: 1.0528 - val_accuracy: 0.7523\n","Epoch 36/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4313 - accuracy: 0.9513 - val_loss: 1.0601 - val_accuracy: 0.7511\n","Epoch 37/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4198 - accuracy: 0.9618 - val_loss: 1.0644 - val_accuracy: 0.7568\n","Epoch 38/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4205 - accuracy: 0.9584 - val_loss: 1.0456 - val_accuracy: 0.7500\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4125 - accuracy: 0.9632 - val_loss: 1.0721 - val_accuracy: 0.7511\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4171 - accuracy: 0.9598 - val_loss: 1.0900 - val_accuracy: 0.7523\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4362 - accuracy: 0.9525 - val_loss: 1.1159 - val_accuracy: 0.7398\n","Epoch 42/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4238 - accuracy: 0.9581 - val_loss: 1.0735 - val_accuracy: 0.7534\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4049 - accuracy: 0.9675 - val_loss: 1.0889 - val_accuracy: 0.7489\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4153 - accuracy: 0.9629 - val_loss: 1.0903 - val_accuracy: 0.7443\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4120 - accuracy: 0.9626 - val_loss: 1.0782 - val_accuracy: 0.7466\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4112 - accuracy: 0.9607 - val_loss: 1.0957 - val_accuracy: 0.7534\n","Epoch 47/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3971 - accuracy: 0.9694 - val_loss: 1.0981 - val_accuracy: 0.7477\n","Epoch 48/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4070 - accuracy: 0.9646 - val_loss: 1.1224 - val_accuracy: 0.7466\n","Epoch 49/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4092 - accuracy: 0.9610 - val_loss: 1.1271 - val_accuracy: 0.7455\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3895 - accuracy: 0.9731 - val_loss: 1.1288 - val_accuracy: 0.7376\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3921 - accuracy: 0.9734 - val_loss: 1.1400 - val_accuracy: 0.7410\n","Epoch 52/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3873 - accuracy: 0.9731 - val_loss: 1.1098 - val_accuracy: 0.7658\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3826 - accuracy: 0.9748 - val_loss: 1.1297 - val_accuracy: 0.7523\n","Epoch 54/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3933 - accuracy: 0.9683 - val_loss: 1.1352 - val_accuracy: 0.7534\n","Epoch 55/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3943 - accuracy: 0.9697 - val_loss: 1.1355 - val_accuracy: 0.7500\n","Epoch 56/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3829 - accuracy: 0.9754 - val_loss: 1.1356 - val_accuracy: 0.7443\n","Epoch 57/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3937 - accuracy: 0.9677 - val_loss: 1.1515 - val_accuracy: 0.7489\n","Epoch 58/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3887 - accuracy: 0.9700 - val_loss: 1.1486 - val_accuracy: 0.7500\n","Epoch 59/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3894 - accuracy: 0.9692 - val_loss: 1.1548 - val_accuracy: 0.7466\n","Epoch 60/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3858 - accuracy: 0.9706 - val_loss: 1.1599 - val_accuracy: 0.7477\n","Epoch 61/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3809 - accuracy: 0.9717 - val_loss: 1.1966 - val_accuracy: 0.7443\n","Epoch 62/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3882 - accuracy: 0.9697 - val_loss: 1.2168 - val_accuracy: 0.7353\n","Epoch 63/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3770 - accuracy: 0.9762 - val_loss: 1.1996 - val_accuracy: 0.7387\n","Epoch 64/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3750 - accuracy: 0.9768 - val_loss: 1.1577 - val_accuracy: 0.7500\n","Epoch 65/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3664 - accuracy: 0.9799 - val_loss: 1.1666 - val_accuracy: 0.7455\n","Epoch 66/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3909 - accuracy: 0.9683 - val_loss: 1.1636 - val_accuracy: 0.7466\n","Epoch 67/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3694 - accuracy: 0.9759 - val_loss: 1.2191 - val_accuracy: 0.7376\n","Epoch 68/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3631 - accuracy: 0.9779 - val_loss: 1.1806 - val_accuracy: 0.7511\n","Epoch 69/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3702 - accuracy: 0.9765 - val_loss: 1.1786 - val_accuracy: 0.7466\n","Epoch 70/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3610 - accuracy: 0.9813 - val_loss: 1.2076 - val_accuracy: 0.7455\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3685 - accuracy: 0.9754 - val_loss: 1.2177 - val_accuracy: 0.7342\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3667 - accuracy: 0.9774 - val_loss: 1.2277 - val_accuracy: 0.7387\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3772 - accuracy: 0.9717 - val_loss: 1.1960 - val_accuracy: 0.7545\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3601 - accuracy: 0.9788 - val_loss: 1.1927 - val_accuracy: 0.7466\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3774 - accuracy: 0.9700 - val_loss: 1.2203 - val_accuracy: 0.7534\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3869 - accuracy: 0.9641 - val_loss: 1.1847 - val_accuracy: 0.7421\n","Epoch 77/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3632 - accuracy: 0.9779 - val_loss: 1.2116 - val_accuracy: 0.7443\n","Epoch 78/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3635 - accuracy: 0.9791 - val_loss: 1.2134 - val_accuracy: 0.7432\n","Epoch 79/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3567 - accuracy: 0.9802 - val_loss: 1.2173 - val_accuracy: 0.7421\n","Epoch 80/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3561 - accuracy: 0.9808 - val_loss: 1.2162 - val_accuracy: 0.7534\n","Epoch 81/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3519 - accuracy: 0.9825 - val_loss: 1.2298 - val_accuracy: 0.7421\n","Epoch 82/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3589 - accuracy: 0.9799 - val_loss: 1.2167 - val_accuracy: 0.7500\n","Epoch 83/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3652 - accuracy: 0.9751 - val_loss: 1.3021 - val_accuracy: 0.7387\n","Epoch 84/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3807 - accuracy: 0.9669 - val_loss: 1.2295 - val_accuracy: 0.7466\n","Epoch 85/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3553 - accuracy: 0.9805 - val_loss: 1.2208 - val_accuracy: 0.7500\n","Epoch 86/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3493 - accuracy: 0.9822 - val_loss: 1.2344 - val_accuracy: 0.7410\n","Epoch 87/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3621 - accuracy: 0.9768 - val_loss: 1.2551 - val_accuracy: 0.7477\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3491 - accuracy: 0.9813 - val_loss: 1.2670 - val_accuracy: 0.7443\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3506 - accuracy: 0.9822 - val_loss: 1.2022 - val_accuracy: 0.7500\n","Epoch 90/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3544 - accuracy: 0.9796 - val_loss: 1.2721 - val_accuracy: 0.7432\n","Epoch 91/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3466 - accuracy: 0.9827 - val_loss: 1.2702 - val_accuracy: 0.7342\n","Epoch 92/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3378 - accuracy: 0.9861 - val_loss: 1.2547 - val_accuracy: 0.7387\n","Epoch 93/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3362 - accuracy: 0.9875 - val_loss: 1.2737 - val_accuracy: 0.7387\n","Epoch 94/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3369 - accuracy: 0.9850 - val_loss: 1.2728 - val_accuracy: 0.7410\n","Epoch 95/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3455 - accuracy: 0.9833 - val_loss: 1.3390 - val_accuracy: 0.7387\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3505 - accuracy: 0.9802 - val_loss: 1.2778 - val_accuracy: 0.7421\n","Epoch 97/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3358 - accuracy: 0.9847 - val_loss: 1.2484 - val_accuracy: 0.7421\n","Epoch 98/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3327 - accuracy: 0.9864 - val_loss: 1.2656 - val_accuracy: 0.7477\n","Epoch 99/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3433 - accuracy: 0.9819 - val_loss: 1.2763 - val_accuracy: 0.7443\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3275 - accuracy: 0.9907 - val_loss: 1.2624 - val_accuracy: 0.7443\n","{'loss': [0.5621424913406372, 0.5427947044372559, 0.5391843914985657, 0.5194137096405029, 0.5334111452102661, 0.5189915895462036, 0.49929192662239075, 0.5049421787261963, 0.4874896705150604, 0.5013090372085571, 0.49586746096611023, 0.48121726512908936, 0.4928140640258789, 0.49976322054862976, 0.49875757098197937, 0.47331729531288147, 0.5055051445960999, 0.46245595812797546, 0.47474855184555054, 0.4594839811325073, 0.46193671226501465, 0.4701549708843231, 0.4528748691082001, 0.4529589116573334, 0.45192110538482666, 0.45438170433044434, 0.4535372853279114, 0.44207847118377686, 0.43681269884109497, 0.43393364548683167, 0.43604493141174316, 0.4229881465435028, 0.4398914873600006, 0.43309006094932556, 0.41934654116630554, 0.43133825063705444, 0.4198427200317383, 0.42053458094596863, 0.4124821722507477, 0.4171033203601837, 0.4362378716468811, 0.4237724542617798, 0.40491873025894165, 0.41531336307525635, 0.4119768738746643, 0.41118884086608887, 0.39706525206565857, 0.40704914927482605, 0.4092022478580475, 0.38954469561576843, 0.39205822348594666, 0.3873423933982849, 0.38256219029426575, 0.39327436685562134, 0.3943102955818176, 0.38290220499038696, 0.39367058873176575, 0.38869503140449524, 0.38942161202430725, 0.38583144545555115, 0.3808545768260956, 0.3882277011871338, 0.3769530951976776, 0.37503141164779663, 0.3664364516735077, 0.3908608555793762, 0.3693554103374481, 0.36310482025146484, 0.37019240856170654, 0.3609844446182251, 0.36848416924476624, 0.36674296855926514, 0.37723803520202637, 0.3601335287094116, 0.3774293065071106, 0.38691920042037964, 0.3631865382194519, 0.36345744132995605, 0.35674241185188293, 0.35610535740852356, 0.3519143760204315, 0.3588655889034271, 0.3651837110519409, 0.38072270154953003, 0.3553086519241333, 0.349276602268219, 0.3620966672897339, 0.349106103181839, 0.35058706998825073, 0.3543763756752014, 0.34657275676727295, 0.33779096603393555, 0.3361692726612091, 0.3369072675704956, 0.3454517722129822, 0.35046249628067017, 0.3357725739479065, 0.3327409327030182, 0.3433394134044647, 0.3274975121021271], 'accuracy': [0.9049236178398132, 0.9119977355003357, 0.9179400205612183, 0.9190718531608582, 0.9168081283569336, 0.921901524066925, 0.92840975522995, 0.9281267523765564, 0.9397283792495728, 0.9275608658790588, 0.9301075339317322, 0.9391624331474304, 0.9323712587356567, 0.9309564232826233, 0.9238823056221008, 0.9419921040534973, 0.9241652488708496, 0.9456706047058105, 0.9385964870452881, 0.9465195536613464, 0.9468024969100952, 0.9402942657470703, 0.947085440158844, 0.9518958926200867, 0.9518958926200867, 0.9453876614570618, 0.9485002756118774, 0.9499151110649109, 0.9572722315788269, 0.9547255039215088, 0.9569892287254333, 0.9626485705375671, 0.9555743932723999, 0.9575551748275757, 0.9629315137863159, 0.9513299465179443, 0.961799681186676, 0.9584040641784668, 0.9632145166397095, 0.9598188996315002, 0.9524617791175842, 0.958121120929718, 0.967458963394165, 0.9629315137863159, 0.9626485705375671, 0.9606677889823914, 0.9694397449493408, 0.9646292924880981, 0.9609507918357849, 0.9731183052062988, 0.9734012484550476, 0.9731183052062988, 0.974816083908081, 0.9683078527450562, 0.9697226881980896, 0.9753820300102234, 0.9677419066429138, 0.9700056314468384, 0.9691567420959473, 0.9705715775489807, 0.9717034697532654, 0.9697226881980896, 0.9762309193611145, 0.9767968058586121, 0.9799094796180725, 0.9683078527450562, 0.975947916507721, 0.9779286980628967, 0.9765138626098633, 0.9813242554664612, 0.9753820300102234, 0.9773627519607544, 0.9717034697532654, 0.9787775874137878, 0.9700056314468384, 0.9640634059906006, 0.9779286980628967, 0.9790605306625366, 0.9801924228668213, 0.9807583689689636, 0.9824561476707458, 0.9799094796180725, 0.9750990271568298, 0.9668930172920227, 0.9804753661155701, 0.9821732044219971, 0.9767968058586121, 0.9813242554664612, 0.9821732044219971, 0.979626476764679, 0.9827390909194946, 0.9861347079277039, 0.9875495433807373, 0.9850028157234192, 0.983305037021637, 0.9801924228668213, 0.9847198724746704, 0.9864176511764526, 0.9818902015686035, 0.990662157535553], 'val_loss': [0.9895802736282349, 0.9898216724395752, 0.9896178245544434, 0.9902665615081787, 0.9931603074073792, 0.9775459170341492, 0.9831634163856506, 0.9754070043563843, 0.9648934602737427, 0.9654164910316467, 0.9732246398925781, 0.9717413187026978, 0.9640690684318542, 0.9925240278244019, 0.9737619161605835, 0.9812953472137451, 0.983153760433197, 0.9847245812416077, 1.0021376609802246, 1.0419307947158813, 1.0192476511001587, 1.0269672870635986, 0.9979134202003479, 1.0003485679626465, 0.9811288714408875, 1.0084587335586548, 0.9823111295700073, 0.9895988702774048, 1.013841986656189, 1.010749340057373, 1.0111334323883057, 1.030171275138855, 1.044464111328125, 1.0383683443069458, 1.052773356437683, 1.060107707977295, 1.0643647909164429, 1.0456150770187378, 1.0720670223236084, 1.0900260210037231, 1.1159409284591675, 1.0734601020812988, 1.0888956785202026, 1.0903255939483643, 1.0781664848327637, 1.0956759452819824, 1.0981462001800537, 1.122436285018921, 1.1270571947097778, 1.1288405656814575, 1.1400256156921387, 1.109826922416687, 1.129685640335083, 1.1352092027664185, 1.135481357574463, 1.135648250579834, 1.151495099067688, 1.1486366987228394, 1.1547576189041138, 1.1599023342132568, 1.1965622901916504, 1.2167952060699463, 1.1995755434036255, 1.1576944589614868, 1.1666356325149536, 1.163620948791504, 1.2191202640533447, 1.1805832386016846, 1.1785953044891357, 1.2076375484466553, 1.2177456617355347, 1.2276825904846191, 1.1959797143936157, 1.1927162408828735, 1.2202643156051636, 1.184735894203186, 1.211613416671753, 1.2134331464767456, 1.2173227071762085, 1.2161743640899658, 1.2297996282577515, 1.2167060375213623, 1.3021034002304077, 1.22951078414917, 1.2208102941513062, 1.234411358833313, 1.2550945281982422, 1.267002820968628, 1.2022279500961304, 1.2720894813537598, 1.2702338695526123, 1.2546741962432861, 1.2736918926239014, 1.2727763652801514, 1.338976502418518, 1.277826189994812, 1.2484016418457031, 1.2656196355819702, 1.2762759923934937, 1.2624366283416748], 'val_accuracy': [0.6199095249176025, 0.587104082107544, 0.564479649066925, 0.5610859990119934, 0.557692289352417, 0.5950226187705994, 0.5746606588363647, 0.5950226187705994, 0.6131221652030945, 0.6176470518112183, 0.6052036285400391, 0.6153846383094788, 0.6334841847419739, 0.6176470518112183, 0.6481900215148926, 0.6617646813392639, 0.6719456911087036, 0.685520350933075, 0.6900452375411987, 0.6832579374313354, 0.6934388875961304, 0.7013574838638306, 0.7194570302963257, 0.720588207244873, 0.7364253401756287, 0.7375565767288208, 0.7545248866081238, 0.7533936500549316, 0.7466063499450684, 0.7466063499450684, 0.7533936500549316, 0.7567873597145081, 0.7477375268936157, 0.7511312365531921, 0.7522624731063843, 0.7511312365531921, 0.7567873597145081, 0.75, 0.7511312365531921, 0.7522624731063843, 0.7398189902305603, 0.7533936500549316, 0.7488687634468079, 0.7443438768386841, 0.7466063499450684, 0.7533936500549316, 0.7477375268936157, 0.7466063499450684, 0.7454751133918762, 0.7375565767288208, 0.7409502267837524, 0.7658371329307556, 0.7522624731063843, 0.7533936500549316, 0.75, 0.7443438768386841, 0.7488687634468079, 0.75, 0.7466063499450684, 0.7477375268936157, 0.7443438768386841, 0.7352941036224365, 0.7386877536773682, 0.75, 0.7454751133918762, 0.7466063499450684, 0.7375565767288208, 0.7511312365531921, 0.7466063499450684, 0.7454751133918762, 0.7341628670692444, 0.7386877536773682, 0.7545248866081238, 0.7466063499450684, 0.7533936500549316, 0.7420814633369446, 0.7443438768386841, 0.7432126402854919, 0.7420814633369446, 0.7533936500549316, 0.7420814633369446, 0.75, 0.7386877536773682, 0.7466063499450684, 0.75, 0.7409502267837524, 0.7477375268936157, 0.7443438768386841, 0.75, 0.7432126402854919, 0.7341628670692444, 0.7386877536773682, 0.7386877536773682, 0.7409502267837524, 0.7386877536773682, 0.7420814633369446, 0.7420814633369446, 0.7477375268936157, 0.7443438768386841, 0.7443438768386841]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.6713 - accuracy: 0.8686"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 9s 56ms/step - loss: 0.6592 - accuracy: 0.8731 - val_loss: 0.9989 - val_accuracy: 0.5754\n","Epoch 2/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5835 - accuracy: 0.8920 - val_loss: 0.9974 - val_accuracy: 0.5651\n","Epoch 3/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5526 - accuracy: 0.9047 - val_loss: 0.9937 - val_accuracy: 0.6054\n","Epoch 4/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5557 - accuracy: 0.9049 - val_loss: 0.9932 - val_accuracy: 0.5981\n","Epoch 5/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5668 - accuracy: 0.9013 - val_loss: 0.9981 - val_accuracy: 0.5620\n","Epoch 6/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5365 - accuracy: 0.9168 - val_loss: 0.9921 - val_accuracy: 0.5899\n","Epoch 7/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5437 - accuracy: 0.9080 - val_loss: 1.0016 - val_accuracy: 0.5661\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5397 - accuracy: 0.9134 - val_loss: 0.9881 - val_accuracy: 0.5981\n","Epoch 9/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5362 - accuracy: 0.9114 - val_loss: 1.0201 - val_accuracy: 0.5754\n","Epoch 10/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5249 - accuracy: 0.9171 - val_loss: 1.0444 - val_accuracy: 0.5723\n","Epoch 11/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5184 - accuracy: 0.9186 - val_loss: 1.0814 - val_accuracy: 0.5640\n","Epoch 12/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5225 - accuracy: 0.9178 - val_loss: 1.0888 - val_accuracy: 0.5795\n","Epoch 13/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5212 - accuracy: 0.9165 - val_loss: 1.0926 - val_accuracy: 0.5899\n","Epoch 14/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5166 - accuracy: 0.9183 - val_loss: 1.0947 - val_accuracy: 0.6023\n","Epoch 15/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.5090 - accuracy: 0.9248 - val_loss: 1.1349 - val_accuracy: 0.6085\n","Epoch 16/100\n","31/31 [==============================] - 1s 35ms/step - loss: 0.5017 - accuracy: 0.9248 - val_loss: 1.0561 - val_accuracy: 0.6498\n","Epoch 17/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5037 - accuracy: 0.9269 - val_loss: 1.1555 - val_accuracy: 0.6364\n","Epoch 18/100\n","31/31 [==============================] - 1s 36ms/step - loss: 0.5001 - accuracy: 0.9225 - val_loss: 1.1086 - val_accuracy: 0.6519\n","Epoch 19/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4955 - accuracy: 0.9300 - val_loss: 1.0393 - val_accuracy: 0.6839\n","Epoch 20/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5059 - accuracy: 0.9256 - val_loss: 1.1026 - val_accuracy: 0.6829\n","Epoch 21/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5036 - accuracy: 0.9248 - val_loss: 1.2151 - val_accuracy: 0.6632\n","Epoch 22/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4896 - accuracy: 0.9339 - val_loss: 1.0279 - val_accuracy: 0.7159\n","Epoch 23/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4832 - accuracy: 0.9341 - val_loss: 1.0408 - val_accuracy: 0.7262\n","Epoch 24/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4758 - accuracy: 0.9419 - val_loss: 1.0778 - val_accuracy: 0.7221\n","Epoch 25/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4801 - accuracy: 0.9385 - val_loss: 1.0553 - val_accuracy: 0.7293\n","Epoch 26/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4797 - accuracy: 0.9380 - val_loss: 1.0288 - val_accuracy: 0.7417\n","Epoch 27/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4641 - accuracy: 0.9447 - val_loss: 1.0414 - val_accuracy: 0.7345\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4637 - accuracy: 0.9475 - val_loss: 1.0546 - val_accuracy: 0.7376\n","Epoch 29/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4607 - accuracy: 0.9483 - val_loss: 1.0604 - val_accuracy: 0.7366\n","Epoch 30/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4653 - accuracy: 0.9419 - val_loss: 1.0823 - val_accuracy: 0.7231\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4545 - accuracy: 0.9468 - val_loss: 1.0657 - val_accuracy: 0.7273\n","Epoch 32/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4525 - accuracy: 0.9491 - val_loss: 1.0684 - val_accuracy: 0.7448\n","Epoch 33/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4564 - accuracy: 0.9450 - val_loss: 1.0995 - val_accuracy: 0.7314\n","Epoch 34/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4460 - accuracy: 0.9504 - val_loss: 1.1270 - val_accuracy: 0.7386\n","Epoch 35/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4552 - accuracy: 0.9447 - val_loss: 1.1198 - val_accuracy: 0.7231\n","Epoch 36/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4505 - accuracy: 0.9452 - val_loss: 1.1406 - val_accuracy: 0.7335\n","Epoch 37/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4467 - accuracy: 0.9450 - val_loss: 1.1047 - val_accuracy: 0.7304\n","Epoch 38/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4417 - accuracy: 0.9509 - val_loss: 1.1100 - val_accuracy: 0.7355\n","Epoch 39/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4413 - accuracy: 0.9530 - val_loss: 1.1084 - val_accuracy: 0.7386\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4441 - accuracy: 0.9494 - val_loss: 1.1320 - val_accuracy: 0.7355\n","Epoch 41/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4453 - accuracy: 0.9463 - val_loss: 1.1348 - val_accuracy: 0.7314\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4411 - accuracy: 0.9514 - val_loss: 1.2156 - val_accuracy: 0.7283\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4449 - accuracy: 0.9478 - val_loss: 1.1478 - val_accuracy: 0.7293\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4331 - accuracy: 0.9519 - val_loss: 1.1921 - val_accuracy: 0.7314\n","Epoch 45/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4289 - accuracy: 0.9553 - val_loss: 1.1535 - val_accuracy: 0.7242\n","Epoch 46/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4467 - accuracy: 0.9468 - val_loss: 1.1229 - val_accuracy: 0.7283\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4207 - accuracy: 0.9594 - val_loss: 1.1242 - val_accuracy: 0.7221\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4380 - accuracy: 0.9465 - val_loss: 1.1400 - val_accuracy: 0.7314\n","Epoch 49/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4196 - accuracy: 0.9594 - val_loss: 1.2047 - val_accuracy: 0.7242\n","Epoch 50/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4220 - accuracy: 0.9581 - val_loss: 1.1828 - val_accuracy: 0.7190\n","Epoch 51/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4304 - accuracy: 0.9517 - val_loss: 1.2116 - val_accuracy: 0.7159\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4213 - accuracy: 0.9561 - val_loss: 1.1731 - val_accuracy: 0.7159\n","Epoch 53/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4149 - accuracy: 0.9649 - val_loss: 1.2341 - val_accuracy: 0.7304\n","Epoch 54/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4162 - accuracy: 0.9558 - val_loss: 1.1723 - val_accuracy: 0.7252\n","Epoch 55/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4035 - accuracy: 0.9667 - val_loss: 1.2054 - val_accuracy: 0.7304\n","Epoch 56/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4101 - accuracy: 0.9607 - val_loss: 1.1751 - val_accuracy: 0.7180\n","Epoch 57/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4082 - accuracy: 0.9599 - val_loss: 1.2018 - val_accuracy: 0.7262\n","Epoch 58/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4064 - accuracy: 0.9620 - val_loss: 1.1948 - val_accuracy: 0.7200\n","Epoch 59/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4038 - accuracy: 0.9641 - val_loss: 1.3157 - val_accuracy: 0.7169\n","Epoch 60/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4140 - accuracy: 0.9589 - val_loss: 1.2027 - val_accuracy: 0.7221\n","Epoch 61/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3965 - accuracy: 0.9654 - val_loss: 1.2084 - val_accuracy: 0.7190\n","Epoch 62/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3933 - accuracy: 0.9682 - val_loss: 1.2047 - val_accuracy: 0.7231\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3939 - accuracy: 0.9677 - val_loss: 1.1968 - val_accuracy: 0.7283\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3908 - accuracy: 0.9677 - val_loss: 1.1926 - val_accuracy: 0.7345\n","Epoch 65/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3984 - accuracy: 0.9633 - val_loss: 1.2310 - val_accuracy: 0.7180\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3886 - accuracy: 0.9667 - val_loss: 1.2479 - val_accuracy: 0.7211\n","Epoch 67/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3855 - accuracy: 0.9690 - val_loss: 1.2350 - val_accuracy: 0.7149\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3875 - accuracy: 0.9693 - val_loss: 1.2333 - val_accuracy: 0.7190\n","Epoch 69/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3877 - accuracy: 0.9654 - val_loss: 1.2480 - val_accuracy: 0.7262\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3916 - accuracy: 0.9654 - val_loss: 1.3395 - val_accuracy: 0.7169\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4120 - accuracy: 0.9535 - val_loss: 1.2267 - val_accuracy: 0.7169\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3832 - accuracy: 0.9685 - val_loss: 1.2153 - val_accuracy: 0.7304\n","Epoch 73/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3879 - accuracy: 0.9659 - val_loss: 1.2821 - val_accuracy: 0.7169\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3725 - accuracy: 0.9734 - val_loss: 1.2684 - val_accuracy: 0.7159\n","Epoch 75/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3765 - accuracy: 0.9721 - val_loss: 1.2798 - val_accuracy: 0.7097\n","Epoch 76/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3756 - accuracy: 0.9726 - val_loss: 1.2495 - val_accuracy: 0.7159\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3826 - accuracy: 0.9687 - val_loss: 1.2678 - val_accuracy: 0.7221\n","Epoch 78/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3788 - accuracy: 0.9718 - val_loss: 1.2896 - val_accuracy: 0.7211\n","Epoch 79/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3770 - accuracy: 0.9690 - val_loss: 1.3337 - val_accuracy: 0.7159\n","Epoch 80/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3769 - accuracy: 0.9698 - val_loss: 1.4702 - val_accuracy: 0.7004\n","Epoch 81/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3963 - accuracy: 0.9599 - val_loss: 1.3887 - val_accuracy: 0.7056\n","Epoch 82/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3743 - accuracy: 0.9713 - val_loss: 1.2872 - val_accuracy: 0.7211\n","Epoch 83/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3606 - accuracy: 0.9786 - val_loss: 1.3329 - val_accuracy: 0.7128\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3637 - accuracy: 0.9752 - val_loss: 1.3498 - val_accuracy: 0.7200\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3626 - accuracy: 0.9742 - val_loss: 1.3559 - val_accuracy: 0.7190\n","Epoch 86/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3652 - accuracy: 0.9726 - val_loss: 1.3411 - val_accuracy: 0.7097\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3722 - accuracy: 0.9659 - val_loss: 1.3647 - val_accuracy: 0.7128\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4065 - accuracy: 0.9563 - val_loss: 1.2713 - val_accuracy: 0.7180\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3709 - accuracy: 0.9713 - val_loss: 1.2813 - val_accuracy: 0.7231\n","Epoch 90/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3559 - accuracy: 0.9788 - val_loss: 1.3116 - val_accuracy: 0.7169\n","Epoch 91/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3474 - accuracy: 0.9837 - val_loss: 1.3848 - val_accuracy: 0.7242\n","Epoch 92/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3592 - accuracy: 0.9767 - val_loss: 1.3554 - val_accuracy: 0.7242\n","Epoch 93/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3582 - accuracy: 0.9775 - val_loss: 1.3146 - val_accuracy: 0.7159\n","Epoch 94/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3504 - accuracy: 0.9791 - val_loss: 1.3666 - val_accuracy: 0.7169\n","Epoch 95/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3563 - accuracy: 0.9762 - val_loss: 1.3538 - val_accuracy: 0.7200\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3569 - accuracy: 0.9773 - val_loss: 1.3297 - val_accuracy: 0.7180\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3548 - accuracy: 0.9736 - val_loss: 1.4412 - val_accuracy: 0.7087\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3497 - accuracy: 0.9801 - val_loss: 1.4299 - val_accuracy: 0.7107\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3556 - accuracy: 0.9773 - val_loss: 1.4209 - val_accuracy: 0.7128\n","Epoch 100/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4118 - accuracy: 0.9501 - val_loss: 1.4397 - val_accuracy: 0.6952\n","{'loss': [0.6591824293136597, 0.58353191614151, 0.5526089072227478, 0.5556561946868896, 0.566760241985321, 0.536481499671936, 0.5436943769454956, 0.5397360920906067, 0.5361902117729187, 0.52494215965271, 0.5183733105659485, 0.5224526524543762, 0.5212386846542358, 0.5165774822235107, 0.5089906454086304, 0.5017359256744385, 0.5037196278572083, 0.5001002550125122, 0.4955372214317322, 0.5058853626251221, 0.5036047101020813, 0.48956653475761414, 0.4831618368625641, 0.4758340120315552, 0.48014652729034424, 0.47965043783187866, 0.46405038237571716, 0.46374058723449707, 0.46065405011177063, 0.4653216600418091, 0.45449724793434143, 0.45249634981155396, 0.4564169943332672, 0.4460429251194, 0.4552162289619446, 0.4505400061607361, 0.4467414617538452, 0.4416640102863312, 0.4413435757160187, 0.44408783316612244, 0.44531840085983276, 0.44113048911094666, 0.4449361264705658, 0.43309730291366577, 0.42888668179512024, 0.4467487037181854, 0.4206770360469818, 0.43797188997268677, 0.41960954666137695, 0.4219692051410675, 0.43041402101516724, 0.4212783873081207, 0.41489720344543457, 0.4162067770957947, 0.4034632742404938, 0.4101393222808838, 0.40815216302871704, 0.40635237097740173, 0.4037715792655945, 0.41399985551834106, 0.39647966623306274, 0.39327913522720337, 0.3939000070095062, 0.39079830050468445, 0.39844125509262085, 0.38856011629104614, 0.3854728639125824, 0.3875293433666229, 0.3876711428165436, 0.3915613889694214, 0.412042498588562, 0.3832296133041382, 0.3879019320011139, 0.3724789023399353, 0.3764839470386505, 0.3755550980567932, 0.3826155364513397, 0.37880849838256836, 0.37703433632850647, 0.3769172430038452, 0.39631742238998413, 0.3742722272872925, 0.36064013838768005, 0.3637412488460541, 0.36262229084968567, 0.36520111560821533, 0.37215113639831543, 0.40649738907814026, 0.37086018919944763, 0.35588911175727844, 0.3473849892616272, 0.3592267632484436, 0.3582126498222351, 0.35041260719299316, 0.3562992811203003, 0.3568860590457916, 0.3548065721988678, 0.3496895432472229, 0.35563206672668457, 0.4117746651172638], 'accuracy': [0.8731266260147095, 0.8919896483421326, 0.9046511650085449, 0.9049095511436462, 0.9012919664382935, 0.9167958498001099, 0.9080103635787964, 0.9134367108345032, 0.9113695025444031, 0.9170542359352112, 0.9186046719551086, 0.9178294539451599, 0.9165374636650085, 0.9183462262153625, 0.9248061776161194, 0.9248061776161194, 0.9268733859062195, 0.9224806427955627, 0.9299741387367249, 0.9255813956260681, 0.9248061776161194, 0.933850109577179, 0.934108555316925, 0.9418604373931885, 0.9385012984275818, 0.9379844665527344, 0.9447028636932373, 0.9475452303886414, 0.9483203887939453, 0.9418604373931885, 0.9467700123786926, 0.949095606803894, 0.9449612498283386, 0.9503875970840454, 0.9447028636932373, 0.9452196359634399, 0.9449612498283386, 0.950904369354248, 0.9529715776443481, 0.9493539929389954, 0.94625324010849, 0.9514212012290955, 0.9478036165237427, 0.9519379734992981, 0.9552971720695496, 0.9467700123786926, 0.959431529045105, 0.9465116262435913, 0.959431529045105, 0.9581395387649536, 0.9516795873641968, 0.9560723304748535, 0.9648578763008118, 0.9558139443397522, 0.9666666388511658, 0.9607235193252563, 0.9599483013153076, 0.9620155096054077, 0.964082658290863, 0.9589147567749023, 0.9653746485710144, 0.9682170748710632, 0.9677002429962158, 0.9677002429962158, 0.9633074998855591, 0.9666666388511658, 0.9689922332763672, 0.9692506194114685, 0.9653746485710144, 0.9653746485710144, 0.9534883499145508, 0.9684754610061646, 0.9658914804458618, 0.9733850359916687, 0.9720930457115173, 0.97260981798172, 0.9687338471412659, 0.9718345999717712, 0.9689922332763672, 0.9697674512863159, 0.9599483013153076, 0.9713178277015686, 0.9785529971122742, 0.9751937985420227, 0.9741601943969727, 0.97260981798172, 0.9658914804458618, 0.9563307762145996, 0.9713178277015686, 0.9788113832473755, 0.9837209582328796, 0.9767441749572754, 0.9775193929672241, 0.9790697693824768, 0.9762274026870728, 0.9772610068321228, 0.97364342212677, 0.9801033735275269, 0.9772610068321228, 0.9501292109489441], 'val_loss': [0.9988501071929932, 0.9974361658096313, 0.9937112331390381, 0.9931616187095642, 0.9981362223625183, 0.9921393990516663, 1.0015971660614014, 0.9881325960159302, 1.0201244354248047, 1.044386625289917, 1.0813612937927246, 1.0888135433197021, 1.0925893783569336, 1.0947147607803345, 1.134918451309204, 1.0561200380325317, 1.1554667949676514, 1.1085525751113892, 1.0393315553665161, 1.1025962829589844, 1.2150599956512451, 1.027888536453247, 1.0407623052597046, 1.077828049659729, 1.055255651473999, 1.028784990310669, 1.0413681268692017, 1.0546308755874634, 1.0604262351989746, 1.0823032855987549, 1.0657497644424438, 1.0684208869934082, 1.099527359008789, 1.1270192861557007, 1.1198219060897827, 1.1406084299087524, 1.104696273803711, 1.1099598407745361, 1.1083862781524658, 1.1319818496704102, 1.1348097324371338, 1.2156157493591309, 1.1478410959243774, 1.1920855045318604, 1.1535063982009888, 1.1228630542755127, 1.1241929531097412, 1.139957070350647, 1.204709768295288, 1.182752013206482, 1.2116423845291138, 1.1730985641479492, 1.2341452836990356, 1.172256350517273, 1.205358862876892, 1.1751493215560913, 1.2017773389816284, 1.1947675943374634, 1.315682053565979, 1.2027103900909424, 1.2083767652511597, 1.2046822309494019, 1.1967945098876953, 1.1925777196884155, 1.2309603691101074, 1.2479162216186523, 1.2349737882614136, 1.2332627773284912, 1.248043417930603, 1.339457392692566, 1.2266514301300049, 1.215311884880066, 1.2820788621902466, 1.2683799266815186, 1.2798285484313965, 1.249527096748352, 1.2677987813949585, 1.2896130084991455, 1.3337477445602417, 1.4701695442199707, 1.3887451887130737, 1.2872484922409058, 1.3328713178634644, 1.3498210906982422, 1.3558560609817505, 1.34107506275177, 1.3647449016571045, 1.2712829113006592, 1.281277060508728, 1.311618447303772, 1.384783148765564, 1.3553972244262695, 1.3146276473999023, 1.3666303157806396, 1.3538497686386108, 1.3297255039215088, 1.441177248954773, 1.4299026727676392, 1.4208852052688599, 1.4396603107452393], 'val_accuracy': [0.5754132270812988, 0.5650826692581177, 0.60537189245224, 0.5981404781341553, 0.5619834661483765, 0.5898760557174683, 0.56611567735672, 0.5981404781341553, 0.5754132270812988, 0.5723140239715576, 0.5640496015548706, 0.5795454382896423, 0.5898760557174683, 0.6022727489471436, 0.6084710955619812, 0.6497933864593506, 0.6363636255264282, 0.6518595218658447, 0.68388432264328, 0.682851254940033, 0.663223147392273, 0.7159090638160706, 0.7262396812438965, 0.7221074104309082, 0.7293388247489929, 0.7417355179786682, 0.7345041036605835, 0.7376033067703247, 0.7365702390670776, 0.7231404781341553, 0.7272727489471436, 0.7448347210884094, 0.7314049601554871, 0.7386363744735718, 0.7231404781341553, 0.7334710955619812, 0.73037189245224, 0.7355371713638306, 0.7386363744735718, 0.7355371713638306, 0.7314049601554871, 0.7283057570457458, 0.7293388247489929, 0.7314049601554871, 0.7241735458374023, 0.7283057570457458, 0.7221074104309082, 0.7314049601554871, 0.7241735458374023, 0.7190082669258118, 0.7159090638160706, 0.7159090638160706, 0.73037189245224, 0.7252066135406494, 0.73037189245224, 0.7179751992225647, 0.7262396812438965, 0.7200413346290588, 0.7169421315193176, 0.7221074104309082, 0.7190082669258118, 0.7231404781341553, 0.7283057570457458, 0.7345041036605835, 0.7179751992225647, 0.7210744023323059, 0.7148760557174683, 0.7190082669258118, 0.7262396812438965, 0.7169421315193176, 0.7169421315193176, 0.73037189245224, 0.7169421315193176, 0.7159090638160706, 0.7097107172012329, 0.7159090638160706, 0.7221074104309082, 0.7210744023323059, 0.7159090638160706, 0.7004132270812988, 0.7055785059928894, 0.7210744023323059, 0.7128099203109741, 0.7200413346290588, 0.7190082669258118, 0.7097107172012329, 0.7128099203109741, 0.7179751992225647, 0.7231404781341553, 0.7169421315193176, 0.7241735458374023, 0.7241735458374023, 0.7159090638160706, 0.7169421315193176, 0.7200413346290588, 0.7179751992225647, 0.7086777091026306, 0.71074378490448, 0.7128099203109741, 0.6952479481697083]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.4880 - accuracy: 0.9264"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 57ms/step - loss: 0.4823 - accuracy: 0.9289 - val_loss: 0.9461 - val_accuracy: 0.6282\n","Epoch 2/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4020 - accuracy: 0.9609 - val_loss: 0.9468 - val_accuracy: 0.6002\n","Epoch 3/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3969 - accuracy: 0.9561 - val_loss: 0.9496 - val_accuracy: 0.5905\n","Epoch 4/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4132 - accuracy: 0.9499 - val_loss: 0.9590 - val_accuracy: 0.5754\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3940 - accuracy: 0.9582 - val_loss: 0.9394 - val_accuracy: 0.6185\n","Epoch 6/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3828 - accuracy: 0.9604 - val_loss: 0.9428 - val_accuracy: 0.6131\n","Epoch 7/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3932 - accuracy: 0.9596 - val_loss: 0.9806 - val_accuracy: 0.5690\n","Epoch 8/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4077 - accuracy: 0.9537 - val_loss: 0.9760 - val_accuracy: 0.5927\n","Epoch 9/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3728 - accuracy: 0.9658 - val_loss: 0.9574 - val_accuracy: 0.6164\n","Epoch 10/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3723 - accuracy: 0.9661 - val_loss: 0.9799 - val_accuracy: 0.6175\n","Epoch 11/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3685 - accuracy: 0.9706 - val_loss: 0.9978 - val_accuracy: 0.6272\n","Epoch 12/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3745 - accuracy: 0.9639 - val_loss: 1.0219 - val_accuracy: 0.6282\n","Epoch 13/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3678 - accuracy: 0.9698 - val_loss: 1.0083 - val_accuracy: 0.6433\n","Epoch 14/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.3624 - accuracy: 0.9698 - val_loss: 1.0286 - val_accuracy: 0.6519\n","Epoch 15/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3957 - accuracy: 0.9542 - val_loss: 1.1620 - val_accuracy: 0.6422\n","Epoch 16/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3678 - accuracy: 0.9690 - val_loss: 1.0555 - val_accuracy: 0.6659\n","Epoch 17/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.3769 - accuracy: 0.9636 - val_loss: 1.0538 - val_accuracy: 0.6843\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3793 - accuracy: 0.9617 - val_loss: 1.1589 - val_accuracy: 0.6843\n","Epoch 19/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.3542 - accuracy: 0.9744 - val_loss: 1.1049 - val_accuracy: 0.6940\n","Epoch 20/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.3477 - accuracy: 0.9793 - val_loss: 1.1211 - val_accuracy: 0.7069\n","Epoch 21/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.3578 - accuracy: 0.9752 - val_loss: 1.0885 - val_accuracy: 0.7284\n","Epoch 22/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3463 - accuracy: 0.9755 - val_loss: 1.0658 - val_accuracy: 0.7425\n","Epoch 23/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3461 - accuracy: 0.9790 - val_loss: 1.0652 - val_accuracy: 0.7565\n","Epoch 24/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.3411 - accuracy: 0.9776 - val_loss: 1.0608 - val_accuracy: 0.7726\n","Epoch 25/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3440 - accuracy: 0.9793 - val_loss: 1.0368 - val_accuracy: 0.7791\n","Epoch 26/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3405 - accuracy: 0.9795 - val_loss: 1.0572 - val_accuracy: 0.7769\n","Epoch 27/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3526 - accuracy: 0.9720 - val_loss: 1.0123 - val_accuracy: 0.7856\n","Epoch 28/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3461 - accuracy: 0.9758 - val_loss: 1.0573 - val_accuracy: 0.7823\n","Epoch 29/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3432 - accuracy: 0.9776 - val_loss: 1.0264 - val_accuracy: 0.7909\n","Epoch 30/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3389 - accuracy: 0.9790 - val_loss: 1.0041 - val_accuracy: 0.7953\n","Epoch 31/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3326 - accuracy: 0.9803 - val_loss: 1.0325 - val_accuracy: 0.7985\n","Epoch 32/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3490 - accuracy: 0.9733 - val_loss: 1.1055 - val_accuracy: 0.7899\n","Epoch 33/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3411 - accuracy: 0.9752 - val_loss: 1.0288 - val_accuracy: 0.7963\n","Epoch 34/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3379 - accuracy: 0.9782 - val_loss: 1.0333 - val_accuracy: 0.7985\n","Epoch 35/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3337 - accuracy: 0.9795 - val_loss: 1.0738 - val_accuracy: 0.7953\n","Epoch 36/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3284 - accuracy: 0.9833 - val_loss: 1.0398 - val_accuracy: 0.7996\n","Epoch 37/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3265 - accuracy: 0.9838 - val_loss: 1.0583 - val_accuracy: 0.7963\n","Epoch 38/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3330 - accuracy: 0.9803 - val_loss: 1.0674 - val_accuracy: 0.7920\n","Epoch 39/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3330 - accuracy: 0.9795 - val_loss: 1.0846 - val_accuracy: 0.7899\n","Epoch 40/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3268 - accuracy: 0.9830 - val_loss: 1.1071 - val_accuracy: 0.7899\n","Epoch 41/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3428 - accuracy: 0.9728 - val_loss: 1.0954 - val_accuracy: 0.7920\n","Epoch 42/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.3255 - accuracy: 0.9846 - val_loss: 1.0841 - val_accuracy: 0.8071\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3237 - accuracy: 0.9811 - val_loss: 1.0799 - val_accuracy: 0.8028\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3212 - accuracy: 0.9830 - val_loss: 1.1073 - val_accuracy: 0.8039\n","Epoch 45/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3182 - accuracy: 0.9857 - val_loss: 1.1321 - val_accuracy: 0.7974\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3202 - accuracy: 0.9841 - val_loss: 1.1088 - val_accuracy: 0.7920\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3184 - accuracy: 0.9849 - val_loss: 1.1378 - val_accuracy: 0.7931\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3209 - accuracy: 0.9841 - val_loss: 1.1205 - val_accuracy: 0.7877\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3161 - accuracy: 0.9860 - val_loss: 1.1183 - val_accuracy: 0.7899\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3135 - accuracy: 0.9879 - val_loss: 1.1294 - val_accuracy: 0.7974\n","Epoch 51/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3295 - accuracy: 0.9763 - val_loss: 1.1561 - val_accuracy: 0.7920\n","Epoch 52/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3303 - accuracy: 0.9793 - val_loss: 1.1444 - val_accuracy: 0.7877\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3482 - accuracy: 0.9693 - val_loss: 1.1206 - val_accuracy: 0.7845\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3216 - accuracy: 0.9825 - val_loss: 1.1289 - val_accuracy: 0.7802\n","Epoch 55/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3125 - accuracy: 0.9863 - val_loss: 1.1569 - val_accuracy: 0.7812\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3097 - accuracy: 0.9881 - val_loss: 1.1423 - val_accuracy: 0.7812\n","Epoch 57/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3237 - accuracy: 0.9814 - val_loss: 1.2284 - val_accuracy: 0.7705\n","Epoch 58/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3302 - accuracy: 0.9771 - val_loss: 1.1333 - val_accuracy: 0.7845\n","Epoch 59/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3156 - accuracy: 0.9830 - val_loss: 1.1315 - val_accuracy: 0.7942\n","Epoch 60/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3114 - accuracy: 0.9871 - val_loss: 1.2161 - val_accuracy: 0.7575\n","Epoch 61/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3157 - accuracy: 0.9833 - val_loss: 1.1146 - val_accuracy: 0.7953\n","Epoch 62/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3076 - accuracy: 0.9873 - val_loss: 1.2349 - val_accuracy: 0.7726\n","Epoch 63/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3053 - accuracy: 0.9879 - val_loss: 1.1394 - val_accuracy: 0.7920\n","Epoch 64/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3091 - accuracy: 0.9863 - val_loss: 1.1933 - val_accuracy: 0.7856\n","Epoch 65/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3031 - accuracy: 0.9887 - val_loss: 1.1723 - val_accuracy: 0.7899\n","Epoch 66/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3048 - accuracy: 0.9879 - val_loss: 1.1557 - val_accuracy: 0.7920\n","Epoch 67/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3000 - accuracy: 0.9890 - val_loss: 1.1490 - val_accuracy: 0.7931\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2999 - accuracy: 0.9903 - val_loss: 1.1937 - val_accuracy: 0.7920\n","Epoch 69/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2937 - accuracy: 0.9935 - val_loss: 1.1499 - val_accuracy: 0.8006\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2990 - accuracy: 0.9911 - val_loss: 1.1962 - val_accuracy: 0.7899\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3130 - accuracy: 0.9841 - val_loss: 1.1783 - val_accuracy: 0.7834\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3146 - accuracy: 0.9811 - val_loss: 1.2112 - val_accuracy: 0.7705\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3216 - accuracy: 0.9782 - val_loss: 1.1574 - val_accuracy: 0.7866\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3121 - accuracy: 0.9868 - val_loss: 1.1671 - val_accuracy: 0.7963\n","Epoch 75/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2934 - accuracy: 0.9925 - val_loss: 1.1601 - val_accuracy: 0.7996\n","Epoch 76/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2958 - accuracy: 0.9892 - val_loss: 1.1705 - val_accuracy: 0.7942\n","Epoch 77/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2959 - accuracy: 0.9892 - val_loss: 1.2069 - val_accuracy: 0.7909\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2918 - accuracy: 0.9919 - val_loss: 1.1668 - val_accuracy: 0.7877\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2886 - accuracy: 0.9938 - val_loss: 1.1944 - val_accuracy: 0.7974\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2945 - accuracy: 0.9908 - val_loss: 1.1941 - val_accuracy: 0.7856\n","Epoch 81/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2909 - accuracy: 0.9925 - val_loss: 1.1729 - val_accuracy: 0.7953\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2982 - accuracy: 0.9871 - val_loss: 1.2214 - val_accuracy: 0.7716\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2985 - accuracy: 0.9868 - val_loss: 1.2008 - val_accuracy: 0.7812\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2953 - accuracy: 0.9906 - val_loss: 1.2534 - val_accuracy: 0.7726\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2889 - accuracy: 0.9908 - val_loss: 1.2420 - val_accuracy: 0.7812\n","Epoch 86/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2844 - accuracy: 0.9930 - val_loss: 1.1901 - val_accuracy: 0.7856\n","Epoch 87/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2890 - accuracy: 0.9914 - val_loss: 1.1854 - val_accuracy: 0.7888\n","Epoch 88/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2897 - accuracy: 0.9911 - val_loss: 1.1908 - val_accuracy: 0.7899\n","Epoch 89/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2871 - accuracy: 0.9925 - val_loss: 1.2175 - val_accuracy: 0.7909\n","Epoch 90/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2866 - accuracy: 0.9895 - val_loss: 1.2300 - val_accuracy: 0.7888\n","Epoch 91/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2872 - accuracy: 0.9925 - val_loss: 1.2104 - val_accuracy: 0.7877\n","Epoch 92/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2980 - accuracy: 0.9879 - val_loss: 1.2114 - val_accuracy: 0.7812\n","Epoch 93/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2841 - accuracy: 0.9930 - val_loss: 1.2318 - val_accuracy: 0.7791\n","Epoch 94/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2844 - accuracy: 0.9933 - val_loss: 1.2360 - val_accuracy: 0.7834\n","Epoch 95/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2853 - accuracy: 0.9914 - val_loss: 1.2217 - val_accuracy: 0.7888\n","Epoch 96/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2857 - accuracy: 0.9903 - val_loss: 1.2904 - val_accuracy: 0.7845\n","Epoch 97/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2893 - accuracy: 0.9881 - val_loss: 1.3342 - val_accuracy: 0.7435\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2908 - accuracy: 0.9887 - val_loss: 1.2166 - val_accuracy: 0.7931\n","Epoch 99/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2818 - accuracy: 0.9916 - val_loss: 1.2578 - val_accuracy: 0.7683\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2943 - accuracy: 0.9852 - val_loss: 1.3330 - val_accuracy: 0.7737\n","{'loss': [0.4823211431503296, 0.40197619795799255, 0.3968583345413208, 0.4132150709629059, 0.39398133754730225, 0.38275015354156494, 0.3932478129863739, 0.4076659083366394, 0.37280604243278503, 0.3723408281803131, 0.3685184717178345, 0.3744863271713257, 0.36780041456222534, 0.3623543977737427, 0.39565014839172363, 0.3677861988544464, 0.3768986761569977, 0.37933456897735596, 0.35417428612709045, 0.34765613079071045, 0.3578280508518219, 0.34629252552986145, 0.34608596563339233, 0.34105226397514343, 0.34397467970848083, 0.34054526686668396, 0.35260486602783203, 0.3460542559623718, 0.3431762456893921, 0.3388993740081787, 0.33261528611183167, 0.3490155339241028, 0.3411141037940979, 0.337924987077713, 0.33371391892433167, 0.32837265729904175, 0.3265027105808258, 0.33301660418510437, 0.33302924036979675, 0.3268299102783203, 0.3428400754928589, 0.325503408908844, 0.3237323760986328, 0.3211897015571594, 0.31822964549064636, 0.3202112317085266, 0.31839460134506226, 0.3209371864795685, 0.3160743713378906, 0.3135235607624054, 0.3295402526855469, 0.33034107089042664, 0.34815579652786255, 0.3216194212436676, 0.3124750256538391, 0.3096688985824585, 0.32366591691970825, 0.33017686009407043, 0.3155915439128876, 0.31136035919189453, 0.31573885679244995, 0.3076445162296295, 0.30534178018569946, 0.3090569078922272, 0.30309897661209106, 0.3047883212566376, 0.2999592125415802, 0.2999343276023865, 0.293709397315979, 0.2990054488182068, 0.31303027272224426, 0.314623087644577, 0.3215519189834595, 0.3120695650577545, 0.29338526725769043, 0.29578685760498047, 0.29592767357826233, 0.29178082942962646, 0.2886066436767578, 0.2944519817829132, 0.29088178277015686, 0.2982334494590759, 0.29853957891464233, 0.295330673456192, 0.28891581296920776, 0.28439074754714966, 0.2889517545700073, 0.28973275423049927, 0.28712064027786255, 0.28663551807403564, 0.2872123718261719, 0.2979808747768402, 0.28406792879104614, 0.2844494581222534, 0.28527095913887024, 0.2856549322605133, 0.28934213519096375, 0.2908391058444977, 0.28183263540267944, 0.2942751944065094], 'accuracy': [0.9288793206214905, 0.9609375, 0.9560883641242981, 0.9498922228813171, 0.9582435488700867, 0.9603987336158752, 0.959590494632721, 0.9536637663841248, 0.9657866358757019, 0.9660560488700867, 0.9706357717514038, 0.9639008641242981, 0.9698275923728943, 0.9698275923728943, 0.9542025923728943, 0.9690194129943848, 0.9636314511299133, 0.9617456793785095, 0.9744073152542114, 0.9792564511299133, 0.975215494632721, 0.9754849076271057, 0.9789870977401733, 0.9776400923728943, 0.9792564511299133, 0.9795258641242981, 0.9719827771186829, 0.9757543206214905, 0.9776400923728943, 0.9789870977401733, 0.9803340435028076, 0.9733297228813171, 0.975215494632721, 0.978178858757019, 0.9795258641242981, 0.9832974076271057, 0.9838362336158752, 0.9803340435028076, 0.9795258641242981, 0.983027994632721, 0.9727909564971924, 0.9846444129943848, 0.9811422228813171, 0.983027994632721, 0.985722005367279, 0.9841055870056152, 0.9849137663841248, 0.9841055870056152, 0.985991358757019, 0.9878771305084229, 0.9762930870056152, 0.9792564511299133, 0.9692887663841248, 0.9824892282485962, 0.9862607717514038, 0.9881465435028076, 0.9814116358757019, 0.9771012663841248, 0.983027994632721, 0.9870689511299133, 0.9832974076271057, 0.9873383641242981, 0.9878771305084229, 0.9862607717514038, 0.9886853694915771, 0.9878771305084229, 0.9889547228813171, 0.9903017282485962, 0.993534505367279, 0.9911099076271057, 0.9841055870056152, 0.9811422228813171, 0.978178858757019, 0.9867995977401733, 0.9924569129943848, 0.9892241358757019, 0.9892241358757019, 0.9919180870056152, 0.993803858757019, 0.990840494632721, 0.9924569129943848, 0.9870689511299133, 0.9867995977401733, 0.990571141242981, 0.990840494632721, 0.9929956793785095, 0.9913793206214905, 0.9911099076271057, 0.9924569129943848, 0.9894935488700867, 0.9924569129943848, 0.9878771305084229, 0.9929956793785095, 0.9932650923728943, 0.9913793206214905, 0.9903017282485962, 0.9881465435028076, 0.9886853694915771, 0.9916487336158752, 0.9851831793785095], 'val_loss': [0.9461360573768616, 0.9467807412147522, 0.9495803713798523, 0.9589679837226868, 0.9394482970237732, 0.9428438544273376, 0.9805535674095154, 0.9760064482688904, 0.957443118095398, 0.9799394011497498, 0.9977824687957764, 1.0219045877456665, 1.0082751512527466, 1.02864670753479, 1.1619610786437988, 1.0554522275924683, 1.0537611246109009, 1.1589282751083374, 1.1049259901046753, 1.1210694313049316, 1.088527798652649, 1.0658198595046997, 1.0651953220367432, 1.060821771621704, 1.0367664098739624, 1.0571656227111816, 1.0122721195220947, 1.0572866201400757, 1.0264309644699097, 1.004095435142517, 1.0324866771697998, 1.1055352687835693, 1.028751254081726, 1.0333150625228882, 1.0737611055374146, 1.0398348569869995, 1.0583207607269287, 1.0674477815628052, 1.0845969915390015, 1.1071035861968994, 1.0954227447509766, 1.0840688943862915, 1.0798794031143188, 1.1072676181793213, 1.1320576667785645, 1.1088378429412842, 1.1378304958343506, 1.1205165386199951, 1.118257999420166, 1.129381537437439, 1.1561261415481567, 1.1444023847579956, 1.1206412315368652, 1.128904938697815, 1.1569430828094482, 1.1422781944274902, 1.2283693552017212, 1.1332862377166748, 1.1315467357635498, 1.216093897819519, 1.1146336793899536, 1.2349029779434204, 1.1394071578979492, 1.1933319568634033, 1.1723086833953857, 1.155744194984436, 1.1490468978881836, 1.1936745643615723, 1.1498996019363403, 1.1962162256240845, 1.1782567501068115, 1.2112406492233276, 1.157365322113037, 1.1670953035354614, 1.1601260900497437, 1.170487642288208, 1.2068811655044556, 1.1667808294296265, 1.1943837404251099, 1.1941195726394653, 1.1728829145431519, 1.2214008569717407, 1.2008103132247925, 1.253388524055481, 1.2419954538345337, 1.1900914907455444, 1.185398817062378, 1.190775990486145, 1.2174835205078125, 1.2300418615341187, 1.2104456424713135, 1.2114171981811523, 1.2317982912063599, 1.236006736755371, 1.2217347621917725, 1.2904419898986816, 1.3341560363769531, 1.2165582180023193, 1.2577755451202393, 1.332976222038269], 'val_accuracy': [0.6282327771186829, 0.600215494632721, 0.5905172228813171, 0.5754310488700867, 0.618534505367279, 0.6131465435028076, 0.568965494632721, 0.5926724076271057, 0.6163793206214905, 0.6174569129943848, 0.6271551847457886, 0.6282327771186829, 0.6433189511299133, 0.6519396305084229, 0.642241358757019, 0.6659482717514038, 0.6842672228813171, 0.6842672228813171, 0.693965494632721, 0.7068965435028076, 0.7284482717514038, 0.7424569129943848, 0.756465494632721, 0.7726293206214905, 0.7790948152542114, 0.7769396305084229, 0.7855603694915771, 0.7823275923728943, 0.7909482717514038, 0.795258641242981, 0.798491358757019, 0.7898706793785095, 0.7963362336158752, 0.798491358757019, 0.795258641242981, 0.7995689511299133, 0.7963362336158752, 0.7920258641242981, 0.7898706793785095, 0.7898706793785095, 0.7920258641242981, 0.8071120977401733, 0.8028017282485962, 0.8038793206214905, 0.7974137663841248, 0.7920258641242981, 0.7931034564971924, 0.787715494632721, 0.7898706793785095, 0.7974137663841248, 0.7920258641242981, 0.787715494632721, 0.7844827771186829, 0.7801724076271057, 0.78125, 0.78125, 0.7704741358757019, 0.7844827771186829, 0.7941810488700867, 0.7575430870056152, 0.795258641242981, 0.7726293206214905, 0.7920258641242981, 0.7855603694915771, 0.7898706793785095, 0.7920258641242981, 0.7931034564971924, 0.7920258641242981, 0.8006465435028076, 0.7898706793785095, 0.7834051847457886, 0.7704741358757019, 0.7866379022598267, 0.7963362336158752, 0.7995689511299133, 0.7941810488700867, 0.7909482717514038, 0.787715494632721, 0.7974137663841248, 0.7855603694915771, 0.795258641242981, 0.7715517282485962, 0.78125, 0.7726293206214905, 0.78125, 0.7855603694915771, 0.7887930870056152, 0.7898706793785095, 0.7909482717514038, 0.7887930870056152, 0.787715494632721, 0.78125, 0.7790948152542114, 0.7834051847457886, 0.7887930870056152, 0.7844827771186829, 0.743534505367279, 0.7931034564971924, 0.7683189511299133, 0.7737069129943848]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.4822 - accuracy: 0.9306"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 78ms/step - loss: 0.4863 - accuracy: 0.9295 - val_loss: 0.9507 - val_accuracy: 0.6029\n","Epoch 2/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4184 - accuracy: 0.9522 - val_loss: 0.9533 - val_accuracy: 0.5758\n","Epoch 3/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4100 - accuracy: 0.9567 - val_loss: 0.9497 - val_accuracy: 0.5905\n","Epoch 4/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3998 - accuracy: 0.9590 - val_loss: 0.9500 - val_accuracy: 0.5792\n","Epoch 5/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3895 - accuracy: 0.9658 - val_loss: 0.9473 - val_accuracy: 0.5860\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3957 - accuracy: 0.9621 - val_loss: 0.9579 - val_accuracy: 0.5781\n","Epoch 7/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3961 - accuracy: 0.9621 - val_loss: 0.9593 - val_accuracy: 0.5848\n","Epoch 8/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3957 - accuracy: 0.9593 - val_loss: 0.9446 - val_accuracy: 0.6063\n","Epoch 9/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3868 - accuracy: 0.9615 - val_loss: 0.9630 - val_accuracy: 0.5916\n","Epoch 10/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.3801 - accuracy: 0.9626 - val_loss: 0.9452 - val_accuracy: 0.6199\n","Epoch 11/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3724 - accuracy: 0.9700 - val_loss: 0.9955 - val_accuracy: 0.6041\n","Epoch 12/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3741 - accuracy: 0.9697 - val_loss: 1.0240 - val_accuracy: 0.5995\n","Epoch 13/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3727 - accuracy: 0.9683 - val_loss: 1.0065 - val_accuracy: 0.6199\n","Epoch 14/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3688 - accuracy: 0.9697 - val_loss: 0.9880 - val_accuracy: 0.6437\n","Epoch 15/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3887 - accuracy: 0.9593 - val_loss: 1.0854 - val_accuracy: 0.6210\n","Epoch 16/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.4061 - accuracy: 0.9536 - val_loss: 1.0202 - val_accuracy: 0.6595\n","Epoch 17/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3782 - accuracy: 0.9680 - val_loss: 1.0071 - val_accuracy: 0.6821\n","Epoch 18/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3652 - accuracy: 0.9731 - val_loss: 1.0550 - val_accuracy: 0.6799\n","Epoch 19/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3592 - accuracy: 0.9728 - val_loss: 1.0873 - val_accuracy: 0.6844\n","Epoch 20/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3616 - accuracy: 0.9745 - val_loss: 1.0453 - val_accuracy: 0.7104\n","Epoch 21/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.3680 - accuracy: 0.9666 - val_loss: 1.0112 - val_accuracy: 0.7342\n","Epoch 22/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.3469 - accuracy: 0.9776 - val_loss: 1.0014 - val_accuracy: 0.7376\n","Epoch 23/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.3538 - accuracy: 0.9768 - val_loss: 0.9673 - val_accuracy: 0.7624\n","Epoch 24/100\n","28/28 [==============================] - 1s 39ms/step - loss: 0.3516 - accuracy: 0.9754 - val_loss: 0.9514 - val_accuracy: 0.7715\n","Epoch 25/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3519 - accuracy: 0.9759 - val_loss: 0.9378 - val_accuracy: 0.7817\n","Epoch 26/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3455 - accuracy: 0.9799 - val_loss: 0.9351 - val_accuracy: 0.7851\n","Epoch 27/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3498 - accuracy: 0.9748 - val_loss: 0.9424 - val_accuracy: 0.7975\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3566 - accuracy: 0.9740 - val_loss: 0.9849 - val_accuracy: 0.7941\n","Epoch 29/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3604 - accuracy: 0.9709 - val_loss: 0.9263 - val_accuracy: 0.7964\n","Epoch 30/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3449 - accuracy: 0.9799 - val_loss: 0.9433 - val_accuracy: 0.7952\n","Epoch 31/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3370 - accuracy: 0.9836 - val_loss: 0.9433 - val_accuracy: 0.8032\n","Epoch 32/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3675 - accuracy: 0.9666 - val_loss: 0.9658 - val_accuracy: 0.7941\n","Epoch 33/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3452 - accuracy: 0.9762 - val_loss: 0.9487 - val_accuracy: 0.8043\n","Epoch 34/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3521 - accuracy: 0.9731 - val_loss: 0.9728 - val_accuracy: 0.7975\n","Epoch 35/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3479 - accuracy: 0.9745 - val_loss: 1.0011 - val_accuracy: 0.7986\n","Epoch 36/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3346 - accuracy: 0.9810 - val_loss: 1.0014 - val_accuracy: 0.7964\n","Epoch 37/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3450 - accuracy: 0.9782 - val_loss: 0.9713 - val_accuracy: 0.8020\n","Epoch 38/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3428 - accuracy: 0.9808 - val_loss: 0.9760 - val_accuracy: 0.8020\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3338 - accuracy: 0.9825 - val_loss: 0.9918 - val_accuracy: 0.7975\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3379 - accuracy: 0.9819 - val_loss: 0.9698 - val_accuracy: 0.7964\n","Epoch 41/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3456 - accuracy: 0.9754 - val_loss: 1.0295 - val_accuracy: 0.7885\n","Epoch 42/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3500 - accuracy: 0.9745 - val_loss: 1.0343 - val_accuracy: 0.8009\n","Epoch 43/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3459 - accuracy: 0.9759 - val_loss: 0.9743 - val_accuracy: 0.7941\n","Epoch 44/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3344 - accuracy: 0.9830 - val_loss: 1.0173 - val_accuracy: 0.7873\n","Epoch 45/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3292 - accuracy: 0.9853 - val_loss: 1.0208 - val_accuracy: 0.7885\n","Epoch 46/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3262 - accuracy: 0.9856 - val_loss: 1.0099 - val_accuracy: 0.8009\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3412 - accuracy: 0.9757 - val_loss: 1.1235 - val_accuracy: 0.7647\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3600 - accuracy: 0.9683 - val_loss: 1.0849 - val_accuracy: 0.7873\n","Epoch 49/100\n","28/28 [==============================] - 2s 55ms/step - loss: 0.3350 - accuracy: 0.9791 - val_loss: 0.9846 - val_accuracy: 0.8054\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3291 - accuracy: 0.9833 - val_loss: 1.0109 - val_accuracy: 0.7952\n","Epoch 51/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3293 - accuracy: 0.9819 - val_loss: 0.9990 - val_accuracy: 0.7998\n","Epoch 52/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3190 - accuracy: 0.9873 - val_loss: 1.0002 - val_accuracy: 0.8077\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3138 - accuracy: 0.9895 - val_loss: 1.0157 - val_accuracy: 0.7986\n","Epoch 54/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3240 - accuracy: 0.9813 - val_loss: 1.0132 - val_accuracy: 0.8133\n","Epoch 55/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3233 - accuracy: 0.9830 - val_loss: 1.0245 - val_accuracy: 0.8077\n","Epoch 56/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3205 - accuracy: 0.9859 - val_loss: 1.0669 - val_accuracy: 0.7998\n","Epoch 57/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3251 - accuracy: 0.9833 - val_loss: 1.0123 - val_accuracy: 0.8111\n","Epoch 58/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3181 - accuracy: 0.9873 - val_loss: 1.0508 - val_accuracy: 0.7964\n","Epoch 59/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3154 - accuracy: 0.9844 - val_loss: 1.0278 - val_accuracy: 0.7998\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3114 - accuracy: 0.9884 - val_loss: 1.0133 - val_accuracy: 0.8077\n","Epoch 61/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3090 - accuracy: 0.9892 - val_loss: 1.0544 - val_accuracy: 0.7998\n","Epoch 62/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3157 - accuracy: 0.9881 - val_loss: 1.0351 - val_accuracy: 0.8009\n","Epoch 63/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3069 - accuracy: 0.9890 - val_loss: 1.0470 - val_accuracy: 0.7952\n","Epoch 64/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3231 - accuracy: 0.9808 - val_loss: 1.0382 - val_accuracy: 0.7964\n","Epoch 65/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3188 - accuracy: 0.9833 - val_loss: 1.0607 - val_accuracy: 0.7998\n","Epoch 66/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3136 - accuracy: 0.9867 - val_loss: 1.0413 - val_accuracy: 0.7998\n","Epoch 67/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3079 - accuracy: 0.9875 - val_loss: 1.0769 - val_accuracy: 0.7941\n","Epoch 68/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3083 - accuracy: 0.9878 - val_loss: 1.0426 - val_accuracy: 0.7975\n","Epoch 69/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3016 - accuracy: 0.9926 - val_loss: 1.0583 - val_accuracy: 0.7941\n","Epoch 70/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3060 - accuracy: 0.9881 - val_loss: 1.0775 - val_accuracy: 0.7896\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3120 - accuracy: 0.9850 - val_loss: 1.0898 - val_accuracy: 0.7964\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3084 - accuracy: 0.9856 - val_loss: 1.0706 - val_accuracy: 0.7930\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3128 - accuracy: 0.9847 - val_loss: 1.0761 - val_accuracy: 0.7862\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3168 - accuracy: 0.9842 - val_loss: 1.0976 - val_accuracy: 0.7941\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3104 - accuracy: 0.9856 - val_loss: 1.0859 - val_accuracy: 0.7941\n","Epoch 76/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3071 - accuracy: 0.9870 - val_loss: 1.0676 - val_accuracy: 0.7998\n","Epoch 77/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3044 - accuracy: 0.9878 - val_loss: 1.0998 - val_accuracy: 0.7941\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2997 - accuracy: 0.9901 - val_loss: 1.0723 - val_accuracy: 0.7986\n","Epoch 79/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2957 - accuracy: 0.9915 - val_loss: 1.0616 - val_accuracy: 0.7964\n","Epoch 80/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3133 - accuracy: 0.9833 - val_loss: 1.0706 - val_accuracy: 0.7941\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3091 - accuracy: 0.9844 - val_loss: 1.0687 - val_accuracy: 0.7919\n","Epoch 82/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2957 - accuracy: 0.9915 - val_loss: 1.0749 - val_accuracy: 0.7986\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3023 - accuracy: 0.9875 - val_loss: 1.0833 - val_accuracy: 0.7941\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3028 - accuracy: 0.9864 - val_loss: 1.1108 - val_accuracy: 0.7885\n","Epoch 85/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3117 - accuracy: 0.9844 - val_loss: 1.0702 - val_accuracy: 0.7873\n","Epoch 86/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2945 - accuracy: 0.9881 - val_loss: 1.1184 - val_accuracy: 0.7862\n","Epoch 87/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2911 - accuracy: 0.9932 - val_loss: 1.1154 - val_accuracy: 0.7805\n","Epoch 88/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2954 - accuracy: 0.9898 - val_loss: 1.0900 - val_accuracy: 0.7873\n","Epoch 89/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2972 - accuracy: 0.9890 - val_loss: 1.1107 - val_accuracy: 0.7941\n","Epoch 90/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2931 - accuracy: 0.9895 - val_loss: 1.1343 - val_accuracy: 0.7919\n","Epoch 91/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2892 - accuracy: 0.9918 - val_loss: 1.1228 - val_accuracy: 0.7907\n","Epoch 92/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2966 - accuracy: 0.9892 - val_loss: 1.1412 - val_accuracy: 0.7885\n","Epoch 93/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2916 - accuracy: 0.9909 - val_loss: 1.1562 - val_accuracy: 0.7907\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3139 - accuracy: 0.9810 - val_loss: 1.1563 - val_accuracy: 0.7726\n","Epoch 95/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2967 - accuracy: 0.9890 - val_loss: 1.1125 - val_accuracy: 0.7851\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2959 - accuracy: 0.9870 - val_loss: 1.1199 - val_accuracy: 0.7941\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2899 - accuracy: 0.9915 - val_loss: 1.1194 - val_accuracy: 0.7986\n","Epoch 98/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2912 - accuracy: 0.9898 - val_loss: 1.1299 - val_accuracy: 0.7828\n","Epoch 99/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2907 - accuracy: 0.9901 - val_loss: 1.0883 - val_accuracy: 0.7964\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2850 - accuracy: 0.9918 - val_loss: 1.1087 - val_accuracy: 0.7930\n","{'loss': [0.48631522059440613, 0.4183855652809143, 0.4099522829055786, 0.3998475968837738, 0.3895062506198883, 0.39573976397514343, 0.3961241841316223, 0.3957039713859558, 0.38676249980926514, 0.3801187574863434, 0.3723755478858948, 0.3740927577018738, 0.37266552448272705, 0.36880216002464294, 0.3886576294898987, 0.4060913622379303, 0.37819570302963257, 0.3652111887931824, 0.35920271277427673, 0.3615688383579254, 0.3679915964603424, 0.34687986969947815, 0.3538140654563904, 0.3515743613243103, 0.35193580389022827, 0.34545525908470154, 0.34978801012039185, 0.35656121373176575, 0.36035263538360596, 0.3449003994464874, 0.33704376220703125, 0.36754563450813293, 0.34520941972732544, 0.3521413505077362, 0.34792637825012207, 0.3346235752105713, 0.34501591324806213, 0.34283944964408875, 0.3337816894054413, 0.3379243314266205, 0.34558218717575073, 0.35004228353500366, 0.3459346890449524, 0.334383100271225, 0.329214870929718, 0.3261520564556122, 0.34115415811538696, 0.36001843214035034, 0.3349767327308655, 0.329113632440567, 0.3293313980102539, 0.31897932291030884, 0.3138177990913391, 0.3240225315093994, 0.323338121175766, 0.32047316431999207, 0.32509320974349976, 0.3181415796279907, 0.31542855501174927, 0.31143778562545776, 0.30895498394966125, 0.3157115876674652, 0.3069435954093933, 0.3230889141559601, 0.3188280165195465, 0.3136432468891144, 0.30787044763565063, 0.30830422043800354, 0.30159085988998413, 0.30603083968162537, 0.31203460693359375, 0.30843058228492737, 0.3128262162208557, 0.31684261560440063, 0.3104367256164551, 0.30707478523254395, 0.3043847382068634, 0.299676775932312, 0.2957474887371063, 0.31326305866241455, 0.30909445881843567, 0.2956920862197876, 0.3022729754447937, 0.3027653694152832, 0.3117106854915619, 0.2944709360599518, 0.29105639457702637, 0.29540398716926575, 0.29720327258110046, 0.2930976152420044, 0.28916966915130615, 0.29664674401283264, 0.291550874710083, 0.31394442915916443, 0.2967433035373688, 0.295921266078949, 0.2898671627044678, 0.2912387549877167, 0.2906638979911804, 0.2849586606025696], 'accuracy': [0.9295415878295898, 0.9521788358688354, 0.9567062854766846, 0.9589700102806091, 0.9657611846923828, 0.9620826244354248, 0.9620826244354248, 0.9592529535293579, 0.9615166783332825, 0.9626485705375671, 0.9700056314468384, 0.9697226881980896, 0.9683078527450562, 0.9697226881980896, 0.9592529535293579, 0.9535936713218689, 0.9680249094963074, 0.9731183052062988, 0.9728353023529053, 0.9745330810546875, 0.9666100740432739, 0.977645754814148, 0.9767968058586121, 0.9753820300102234, 0.975947916507721, 0.9799094796180725, 0.974816083908081, 0.9739671945571899, 0.9708545804023743, 0.9799094796180725, 0.9835879802703857, 0.9666100740432739, 0.9762309193611145, 0.9731183052062988, 0.9745330810546875, 0.9810413122177124, 0.9782116413116455, 0.9807583689689636, 0.9824561476707458, 0.9818902015686035, 0.9753820300102234, 0.9745330810546875, 0.975947916507721, 0.9830220937728882, 0.9852858185768127, 0.9855687618255615, 0.9756649732589722, 0.9683078527450562, 0.9790605306625366, 0.983305037021637, 0.9818902015686035, 0.9872665405273438, 0.9895302653312683, 0.9813242554664612, 0.9830220937728882, 0.9858517050743103, 0.983305037021637, 0.9872665405273438, 0.9844368696212769, 0.9883984327316284, 0.9892473220825195, 0.9881154298782349, 0.988964319229126, 0.9807583689689636, 0.983305037021637, 0.9867005944252014, 0.9875495433807373, 0.9878324866294861, 0.992642879486084, 0.9881154298782349, 0.9850028157234192, 0.9855687618255615, 0.9847198724746704, 0.9841539263725281, 0.9855687618255615, 0.986983597278595, 0.9878324866294861, 0.9900962114334106, 0.9915110468864441, 0.983305037021637, 0.9844368696212769, 0.9915110468864441, 0.9875495433807373, 0.9864176511764526, 0.9844368696212769, 0.9881154298782349, 0.9932088255882263, 0.9898132681846619, 0.988964319229126, 0.9895302653312683, 0.9917939901351929, 0.9892473220825195, 0.9909451007843018, 0.9810413122177124, 0.988964319229126, 0.986983597278595, 0.9915110468864441, 0.9898132681846619, 0.9900962114334106, 0.9917939901351929], 'val_loss': [0.9507380127906799, 0.9532729387283325, 0.9496651291847229, 0.9500460624694824, 0.9473415017127991, 0.9579111337661743, 0.9592981934547424, 0.9445824027061462, 0.9630289673805237, 0.9451955556869507, 0.9954838156700134, 1.0239619016647339, 1.0064815282821655, 0.9880178570747375, 1.0854202508926392, 1.0201950073242188, 1.0070714950561523, 1.054970145225525, 1.0872797966003418, 1.0453226566314697, 1.01120924949646, 1.0014328956604004, 0.9672843217849731, 0.9514254331588745, 0.9377532601356506, 0.935136616230011, 0.9423902630805969, 0.984885573387146, 0.926291823387146, 0.9433020949363708, 0.9433422684669495, 0.9657704830169678, 0.9486606121063232, 0.9727531671524048, 1.0010567903518677, 1.001403570175171, 0.9712809324264526, 0.9759519696235657, 0.9918141961097717, 0.9698150157928467, 1.0294544696807861, 1.0343413352966309, 0.9742617607116699, 1.0173059701919556, 1.0207728147506714, 1.009928822517395, 1.1234959363937378, 1.0849274396896362, 0.9846370816230774, 1.0108592510223389, 0.9989703297615051, 1.0002318620681763, 1.015710711479187, 1.0131782293319702, 1.0244547128677368, 1.0669413805007935, 1.012278437614441, 1.0507580041885376, 1.0277769565582275, 1.0133092403411865, 1.0543839931488037, 1.0350854396820068, 1.046959400177002, 1.038240909576416, 1.0607459545135498, 1.041344404220581, 1.0768738985061646, 1.0426455736160278, 1.0582810640335083, 1.0775083303451538, 1.0898185968399048, 1.0706446170806885, 1.076054573059082, 1.0976076126098633, 1.0859159231185913, 1.0676220655441284, 1.0997861623764038, 1.0722815990447998, 1.061556100845337, 1.0706474781036377, 1.0686938762664795, 1.0749092102050781, 1.083322286605835, 1.1108496189117432, 1.0701851844787598, 1.1183578968048096, 1.1154412031173706, 1.0899602174758911, 1.110686182975769, 1.1342668533325195, 1.1227715015411377, 1.1412378549575806, 1.1562429666519165, 1.156266689300537, 1.1125493049621582, 1.1199078559875488, 1.1193944215774536, 1.1298555135726929, 1.0883079767227173, 1.1086924076080322], 'val_accuracy': [0.6029411554336548, 0.5757918357849121, 0.5904977321624756, 0.5791855454444885, 0.5859728455543518, 0.5780543088912964, 0.5848416090011597, 0.6063348650932312, 0.5916289687156677, 0.6199095249176025, 0.6040723919868469, 0.5995475053787231, 0.6199095249176025, 0.6436651349067688, 0.6210407018661499, 0.6595022678375244, 0.6821267008781433, 0.679864227771759, 0.6843891143798828, 0.7104072570800781, 0.7341628670692444, 0.7375565767288208, 0.7624434232711792, 0.7714931964874268, 0.7816742062568665, 0.7850678563117981, 0.7975113391876221, 0.7941176295280457, 0.7963801026344299, 0.7952488660812378, 0.8031674027442932, 0.7941176295280457, 0.8042986392974854, 0.7975113391876221, 0.7986425161361694, 0.7963801026344299, 0.8020362257957458, 0.8020362257957458, 0.7975113391876221, 0.7963801026344299, 0.7884615659713745, 0.8009049892425537, 0.7941176295280457, 0.7873303294181824, 0.7884615659713745, 0.8009049892425537, 0.7647058963775635, 0.7873303294181824, 0.8054298758506775, 0.7952488660812378, 0.7997737526893616, 0.807692289352417, 0.7986425161361694, 0.8133484125137329, 0.807692289352417, 0.7997737526893616, 0.8110859990119934, 0.7963801026344299, 0.7997737526893616, 0.807692289352417, 0.7997737526893616, 0.8009049892425537, 0.7952488660812378, 0.7963801026344299, 0.7997737526893616, 0.7997737526893616, 0.7941176295280457, 0.7975113391876221, 0.7941176295280457, 0.7895927429199219, 0.7963801026344299, 0.7929864525794983, 0.7861990928649902, 0.7941176295280457, 0.7941176295280457, 0.7997737526893616, 0.7941176295280457, 0.7986425161361694, 0.7963801026344299, 0.7941176295280457, 0.7918552160263062, 0.7986425161361694, 0.7941176295280457, 0.7884615659713745, 0.7873303294181824, 0.7861990928649902, 0.7805429697036743, 0.7873303294181824, 0.7941176295280457, 0.7918552160263062, 0.790723979473114, 0.7884615659713745, 0.790723979473114, 0.7726244330406189, 0.7850678563117981, 0.7941176295280457, 0.7986425161361694, 0.7828054428100586, 0.7963801026344299, 0.7929864525794983]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 52, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 52, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 26, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 13, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 13, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 7, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 5, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 5, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 5, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 5, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4362817 (16.64 MB)\n","Trainable params: 4362305 (16.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.4966 - accuracy: 0.9227"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 9s 55ms/step - loss: 0.4962 - accuracy: 0.9233 - val_loss: 0.9610 - val_accuracy: 0.5868\n","Epoch 2/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4553 - accuracy: 0.9346 - val_loss: 0.9674 - val_accuracy: 0.5548\n","Epoch 3/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4423 - accuracy: 0.9424 - val_loss: 0.9631 - val_accuracy: 0.5651\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4210 - accuracy: 0.9504 - val_loss: 0.9776 - val_accuracy: 0.5486\n","Epoch 5/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4135 - accuracy: 0.9532 - val_loss: 0.9639 - val_accuracy: 0.5682\n","Epoch 6/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4226 - accuracy: 0.9442 - val_loss: 0.9763 - val_accuracy: 0.5579\n","Epoch 7/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4126 - accuracy: 0.9553 - val_loss: 0.9827 - val_accuracy: 0.5723\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4013 - accuracy: 0.9571 - val_loss: 1.0090 - val_accuracy: 0.5651\n","Epoch 9/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4053 - accuracy: 0.9587 - val_loss: 1.0732 - val_accuracy: 0.5527\n","Epoch 10/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4328 - accuracy: 0.9447 - val_loss: 1.0184 - val_accuracy: 0.5847\n","Epoch 11/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4246 - accuracy: 0.9491 - val_loss: 1.1015 - val_accuracy: 0.5826\n","Epoch 12/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.3990 - accuracy: 0.9594 - val_loss: 1.0999 - val_accuracy: 0.5930\n","Epoch 13/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.4114 - accuracy: 0.9488 - val_loss: 1.1745 - val_accuracy: 0.5961\n","Epoch 14/100\n","31/31 [==============================] - 1s 35ms/step - loss: 0.3967 - accuracy: 0.9558 - val_loss: 1.2119 - val_accuracy: 0.6023\n","Epoch 15/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3837 - accuracy: 0.9656 - val_loss: 1.2312 - val_accuracy: 0.6240\n","Epoch 16/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3836 - accuracy: 0.9630 - val_loss: 1.2870 - val_accuracy: 0.6281\n","Epoch 17/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3794 - accuracy: 0.9682 - val_loss: 1.2142 - val_accuracy: 0.6705\n","Epoch 18/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3894 - accuracy: 0.9599 - val_loss: 1.2771 - val_accuracy: 0.6591\n","Epoch 19/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3783 - accuracy: 0.9638 - val_loss: 1.1854 - val_accuracy: 0.6973\n","Epoch 20/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3771 - accuracy: 0.9674 - val_loss: 1.1728 - val_accuracy: 0.7025\n","Epoch 21/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3790 - accuracy: 0.9620 - val_loss: 1.0568 - val_accuracy: 0.7314\n","Epoch 22/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3717 - accuracy: 0.9698 - val_loss: 1.0549 - val_accuracy: 0.7438\n","Epoch 23/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3607 - accuracy: 0.9721 - val_loss: 1.0358 - val_accuracy: 0.7603\n","Epoch 24/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3694 - accuracy: 0.9669 - val_loss: 1.0299 - val_accuracy: 0.7645\n","Epoch 25/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3682 - accuracy: 0.9674 - val_loss: 1.0422 - val_accuracy: 0.7727\n","Epoch 26/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3580 - accuracy: 0.9744 - val_loss: 0.9875 - val_accuracy: 0.7758\n","Epoch 27/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3794 - accuracy: 0.9623 - val_loss: 1.0393 - val_accuracy: 0.7738\n","Epoch 28/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3669 - accuracy: 0.9685 - val_loss: 1.0736 - val_accuracy: 0.7738\n","Epoch 29/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3665 - accuracy: 0.9685 - val_loss: 1.0034 - val_accuracy: 0.7727\n","Epoch 30/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3584 - accuracy: 0.9739 - val_loss: 1.0499 - val_accuracy: 0.7676\n","Epoch 31/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.3592 - accuracy: 0.9708 - val_loss: 1.0681 - val_accuracy: 0.7810\n","Epoch 32/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3611 - accuracy: 0.9703 - val_loss: 1.0516 - val_accuracy: 0.7851\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3580 - accuracy: 0.9700 - val_loss: 1.0568 - val_accuracy: 0.7758\n","Epoch 34/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3667 - accuracy: 0.9669 - val_loss: 1.0321 - val_accuracy: 0.7779\n","Epoch 35/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3530 - accuracy: 0.9724 - val_loss: 1.0305 - val_accuracy: 0.7841\n","Epoch 36/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3486 - accuracy: 0.9755 - val_loss: 1.1197 - val_accuracy: 0.7800\n","Epoch 37/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3568 - accuracy: 0.9705 - val_loss: 1.0559 - val_accuracy: 0.7820\n","Epoch 38/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3568 - accuracy: 0.9705 - val_loss: 1.0335 - val_accuracy: 0.7738\n","Epoch 39/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3498 - accuracy: 0.9760 - val_loss: 1.0487 - val_accuracy: 0.7758\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3543 - accuracy: 0.9690 - val_loss: 1.1223 - val_accuracy: 0.7696\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3624 - accuracy: 0.9674 - val_loss: 1.2531 - val_accuracy: 0.7407\n","Epoch 42/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3817 - accuracy: 0.9584 - val_loss: 1.1986 - val_accuracy: 0.7324\n","Epoch 43/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3538 - accuracy: 0.9698 - val_loss: 1.0839 - val_accuracy: 0.7758\n","Epoch 44/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3433 - accuracy: 0.9760 - val_loss: 1.0923 - val_accuracy: 0.7645\n","Epoch 45/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3388 - accuracy: 0.9770 - val_loss: 1.1005 - val_accuracy: 0.7614\n","Epoch 46/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3369 - accuracy: 0.9822 - val_loss: 1.1165 - val_accuracy: 0.7717\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3382 - accuracy: 0.9788 - val_loss: 1.1385 - val_accuracy: 0.7665\n","Epoch 48/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3375 - accuracy: 0.9796 - val_loss: 1.0921 - val_accuracy: 0.7696\n","Epoch 49/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3278 - accuracy: 0.9845 - val_loss: 1.0871 - val_accuracy: 0.7727\n","Epoch 50/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3299 - accuracy: 0.9811 - val_loss: 1.1195 - val_accuracy: 0.7727\n","Epoch 51/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3310 - accuracy: 0.9793 - val_loss: 1.1694 - val_accuracy: 0.7655\n","Epoch 52/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3395 - accuracy: 0.9760 - val_loss: 1.2420 - val_accuracy: 0.7634\n","Epoch 53/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3505 - accuracy: 0.9705 - val_loss: 1.1244 - val_accuracy: 0.7614\n","Epoch 54/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3356 - accuracy: 0.9791 - val_loss: 1.2339 - val_accuracy: 0.7479\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3255 - accuracy: 0.9837 - val_loss: 1.1286 - val_accuracy: 0.7665\n","Epoch 56/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3350 - accuracy: 0.9788 - val_loss: 1.1034 - val_accuracy: 0.7717\n","Epoch 57/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3234 - accuracy: 0.9819 - val_loss: 1.1057 - val_accuracy: 0.7686\n","Epoch 58/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3251 - accuracy: 0.9809 - val_loss: 1.1478 - val_accuracy: 0.7696\n","Epoch 59/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3265 - accuracy: 0.9775 - val_loss: 1.1152 - val_accuracy: 0.7738\n","Epoch 60/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3237 - accuracy: 0.9814 - val_loss: 1.1346 - val_accuracy: 0.7614\n","Epoch 61/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3166 - accuracy: 0.9860 - val_loss: 1.1810 - val_accuracy: 0.7614\n","Epoch 62/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3276 - accuracy: 0.9788 - val_loss: 1.1361 - val_accuracy: 0.7748\n","Epoch 63/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3174 - accuracy: 0.9848 - val_loss: 1.1740 - val_accuracy: 0.7624\n","Epoch 64/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3267 - accuracy: 0.9796 - val_loss: 1.1683 - val_accuracy: 0.7593\n","Epoch 65/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3259 - accuracy: 0.9798 - val_loss: 1.1676 - val_accuracy: 0.7727\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3159 - accuracy: 0.9845 - val_loss: 1.1607 - val_accuracy: 0.7717\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3191 - accuracy: 0.9835 - val_loss: 1.2569 - val_accuracy: 0.7603\n","Epoch 68/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3417 - accuracy: 0.9713 - val_loss: 1.2966 - val_accuracy: 0.7242\n","Epoch 69/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3463 - accuracy: 0.9713 - val_loss: 1.1707 - val_accuracy: 0.7583\n","Epoch 70/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3157 - accuracy: 0.9840 - val_loss: 1.1387 - val_accuracy: 0.7696\n","Epoch 71/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3162 - accuracy: 0.9840 - val_loss: 1.1434 - val_accuracy: 0.7665\n","Epoch 72/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3172 - accuracy: 0.9819 - val_loss: 1.1847 - val_accuracy: 0.7645\n","Epoch 73/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3228 - accuracy: 0.9773 - val_loss: 1.1441 - val_accuracy: 0.7603\n","Epoch 74/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3111 - accuracy: 0.9853 - val_loss: 1.1900 - val_accuracy: 0.7676\n","Epoch 75/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3100 - accuracy: 0.9860 - val_loss: 1.1766 - val_accuracy: 0.7696\n","Epoch 76/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3046 - accuracy: 0.9881 - val_loss: 1.1829 - val_accuracy: 0.7676\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3040 - accuracy: 0.9860 - val_loss: 1.1739 - val_accuracy: 0.7665\n","Epoch 78/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3135 - accuracy: 0.9829 - val_loss: 1.1856 - val_accuracy: 0.7634\n","Epoch 79/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3253 - accuracy: 0.9770 - val_loss: 1.2080 - val_accuracy: 0.7655\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3170 - accuracy: 0.9814 - val_loss: 1.2108 - val_accuracy: 0.7624\n","Epoch 81/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3104 - accuracy: 0.9848 - val_loss: 1.1565 - val_accuracy: 0.7624\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2989 - accuracy: 0.9886 - val_loss: 1.2107 - val_accuracy: 0.7614\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3041 - accuracy: 0.9860 - val_loss: 1.2393 - val_accuracy: 0.7583\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3055 - accuracy: 0.9845 - val_loss: 1.1937 - val_accuracy: 0.7603\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3047 - accuracy: 0.9855 - val_loss: 1.2952 - val_accuracy: 0.7572\n","Epoch 86/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3058 - accuracy: 0.9853 - val_loss: 1.2231 - val_accuracy: 0.7510\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3092 - accuracy: 0.9817 - val_loss: 1.2327 - val_accuracy: 0.7593\n","Epoch 88/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2969 - accuracy: 0.9894 - val_loss: 1.1983 - val_accuracy: 0.7603\n","Epoch 89/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3067 - accuracy: 0.9840 - val_loss: 1.2042 - val_accuracy: 0.7593\n","Epoch 90/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2985 - accuracy: 0.9889 - val_loss: 1.2006 - val_accuracy: 0.7655\n","Epoch 91/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3022 - accuracy: 0.9855 - val_loss: 1.2045 - val_accuracy: 0.7634\n","Epoch 92/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3082 - accuracy: 0.9819 - val_loss: 1.3435 - val_accuracy: 0.7531\n","Epoch 93/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3032 - accuracy: 0.9860 - val_loss: 1.2301 - val_accuracy: 0.7614\n","Epoch 94/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2989 - accuracy: 0.9863 - val_loss: 1.3398 - val_accuracy: 0.7531\n","Epoch 95/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3011 - accuracy: 0.9853 - val_loss: 1.2485 - val_accuracy: 0.7572\n","Epoch 96/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2960 - accuracy: 0.9876 - val_loss: 1.2453 - val_accuracy: 0.7676\n","Epoch 97/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3020 - accuracy: 0.9853 - val_loss: 1.2114 - val_accuracy: 0.7500\n","Epoch 98/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2931 - accuracy: 0.9886 - val_loss: 1.2131 - val_accuracy: 0.7500\n","Epoch 99/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2987 - accuracy: 0.9858 - val_loss: 1.3327 - val_accuracy: 0.7624\n","Epoch 100/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2940 - accuracy: 0.9866 - val_loss: 1.2174 - val_accuracy: 0.7552\n","{'loss': [0.4962235987186432, 0.4553081691265106, 0.44233864545822144, 0.42095261812210083, 0.41348469257354736, 0.42258864641189575, 0.41262343525886536, 0.40132686495780945, 0.40528082847595215, 0.43276354670524597, 0.42457157373428345, 0.3989815413951874, 0.411443293094635, 0.3966608941555023, 0.38373425602912903, 0.3835860788822174, 0.37935709953308105, 0.38940495252609253, 0.3782973885536194, 0.37709107995033264, 0.3789701759815216, 0.3717380464076996, 0.3607279658317566, 0.369406521320343, 0.3681739568710327, 0.3580119013786316, 0.3793990910053253, 0.3669370114803314, 0.3665095269680023, 0.3583603799343109, 0.359216570854187, 0.36105120182037354, 0.35798484086990356, 0.36670824885368347, 0.3529990315437317, 0.3485782742500305, 0.3567873239517212, 0.3568151295185089, 0.34984469413757324, 0.3542725145816803, 0.3624286651611328, 0.38173890113830566, 0.35384032130241394, 0.34331753849983215, 0.33875906467437744, 0.33691421151161194, 0.3381565809249878, 0.33748894929885864, 0.32781997323036194, 0.3299006223678589, 0.3310365676879883, 0.3394908905029297, 0.35047826170921326, 0.335645854473114, 0.3255327045917511, 0.3349987864494324, 0.32340294122695923, 0.32510510087013245, 0.3265300393104553, 0.3236996829509735, 0.31655946373939514, 0.327551007270813, 0.31743335723876953, 0.32666561007499695, 0.32592883706092834, 0.31586968898773193, 0.3191432058811188, 0.34170758724212646, 0.3463455140590668, 0.3157474994659424, 0.316153347492218, 0.3171759247779846, 0.3227674663066864, 0.31109413504600525, 0.3100211024284363, 0.3045703172683716, 0.30396685004234314, 0.3135446608066559, 0.32528823614120483, 0.3169914484024048, 0.31042391061782837, 0.2989261746406555, 0.3041275441646576, 0.30546835064888, 0.304727703332901, 0.3058137893676758, 0.3092401921749115, 0.2969425618648529, 0.30674049258232117, 0.2984669506549835, 0.30217504501342773, 0.3082331418991089, 0.3031761348247528, 0.2988681495189667, 0.30108919739723206, 0.2960039973258972, 0.3019787669181824, 0.293115496635437, 0.29873421788215637, 0.2939951717853546], 'accuracy': [0.9232558012008667, 0.9346253275871277, 0.9423772692680359, 0.9503875970840454, 0.9532299637794495, 0.9441860318183899, 0.9552971720695496, 0.9571059346199036, 0.9586563110351562, 0.9447028636932373, 0.949095606803894, 0.959431529045105, 0.9488372206687927, 0.9558139443397522, 0.9656330943107605, 0.9630491137504578, 0.9682170748710632, 0.9599483013153076, 0.9638242721557617, 0.9674418568611145, 0.9620155096054077, 0.9697674512863159, 0.9720930457115173, 0.9669250845909119, 0.9674418568611145, 0.974418580532074, 0.962273895740509, 0.9684754610061646, 0.9684754610061646, 0.9739018082618713, 0.970801055431366, 0.9702842235565186, 0.9700258374214172, 0.9669250845909119, 0.9723514318466187, 0.975452184677124, 0.9705426096916199, 0.9705426096916199, 0.9759690165519714, 0.9689922332763672, 0.9674418568611145, 0.9583979249000549, 0.9697674512863159, 0.9759690165519714, 0.9770025610923767, 0.9821705222129822, 0.9788113832473755, 0.9795865416526794, 0.9844961166381836, 0.9811369776725769, 0.9793281555175781, 0.9759690165519714, 0.9705426096916199, 0.9790697693824768, 0.9837209582328796, 0.9788113832473755, 0.9819121360778809, 0.9808785319328308, 0.9775193929672241, 0.9813953638076782, 0.9860464930534363, 0.9788113832473755, 0.9847545027732849, 0.9795865416526794, 0.9798449873924255, 0.9844961166381836, 0.9834625124931335, 0.9713178277015686, 0.9713178277015686, 0.983979344367981, 0.983979344367981, 0.9819121360778809, 0.9772610068321228, 0.9852713346481323, 0.9860464930534363, 0.9881137013435364, 0.9860464930534363, 0.9829457402229309, 0.9770025610923767, 0.9813953638076782, 0.9847545027732849, 0.988630473613739, 0.9860464930534363, 0.9844961166381836, 0.9855297207832336, 0.9852713346481323, 0.9816537499427795, 0.9894056916236877, 0.983979344367981, 0.9888888597488403, 0.9855297207832336, 0.9819121360778809, 0.9860464930534363, 0.9863049387931824, 0.9852713346481323, 0.987596869468689, 0.9852713346481323, 0.988630473613739, 0.985788106918335, 0.9865633249282837], 'val_loss': [0.9610138535499573, 0.967382550239563, 0.9630712270736694, 0.9775885343551636, 0.9638916254043579, 0.9763166904449463, 0.9827370047569275, 1.0089869499206543, 1.0732145309448242, 1.0184216499328613, 1.1014899015426636, 1.0999181270599365, 1.1745448112487793, 1.2119032144546509, 1.2311632633209229, 1.2870064973831177, 1.2142093181610107, 1.2771495580673218, 1.1854453086853027, 1.1727851629257202, 1.056760311126709, 1.0548515319824219, 1.0358201265335083, 1.029850721359253, 1.042201280593872, 0.9875416159629822, 1.0392987728118896, 1.0736080408096313, 1.003385066986084, 1.0499264001846313, 1.068070650100708, 1.0515519380569458, 1.056847095489502, 1.0321303606033325, 1.0305240154266357, 1.119691252708435, 1.055856466293335, 1.0334861278533936, 1.0486513376235962, 1.1223108768463135, 1.2531139850616455, 1.1986230611801147, 1.083866834640503, 1.092326045036316, 1.100489854812622, 1.116537094116211, 1.1385446786880493, 1.0920945405960083, 1.0871272087097168, 1.1194781064987183, 1.1693716049194336, 1.242045283317566, 1.1243959665298462, 1.2338500022888184, 1.1286282539367676, 1.103389859199524, 1.1057207584381104, 1.1478314399719238, 1.115198016166687, 1.1346049308776855, 1.1810133457183838, 1.1360816955566406, 1.1739786863327026, 1.168317437171936, 1.1675992012023926, 1.1606906652450562, 1.2569102048873901, 1.296571135520935, 1.1706863641738892, 1.1386802196502686, 1.1433680057525635, 1.1847447156906128, 1.1440669298171997, 1.189978837966919, 1.1766337156295776, 1.1828835010528564, 1.1738555431365967, 1.185600757598877, 1.2080196142196655, 1.2108467817306519, 1.1565442085266113, 1.2107107639312744, 1.239336371421814, 1.193737506866455, 1.2951526641845703, 1.2231321334838867, 1.2326956987380981, 1.1983380317687988, 1.2041795253753662, 1.200583577156067, 1.2044790983200073, 1.3435218334197998, 1.23014497756958, 1.3398346900939941, 1.2485227584838867, 1.2453148365020752, 1.2113573551177979, 1.2130862474441528, 1.3326987028121948, 1.2174408435821533], 'val_accuracy': [0.586776852607727, 0.5547520518302917, 0.5650826692581177, 0.5485537052154541, 0.5681818127632141, 0.557851254940033, 0.5723140239715576, 0.5650826692581177, 0.5526859760284424, 0.5847107172012329, 0.5826446413993835, 0.5929751992225647, 0.5960744023323059, 0.6022727489471436, 0.6239669322967529, 0.6280992031097412, 0.6704545617103577, 0.6590909361839294, 0.6973140239715576, 0.702479362487793, 0.7314049601554871, 0.7438016533851624, 0.7603305578231812, 0.7644628286361694, 0.7727272510528564, 0.7758264541625977, 0.7737603187561035, 0.7737603187561035, 0.7727272510528564, 0.7675619721412659, 0.7809917330741882, 0.7851239442825317, 0.7758264541625977, 0.7778925895690918, 0.7840909361839294, 0.7799586653709412, 0.7820248007774353, 0.7737603187561035, 0.7758264541625977, 0.76962810754776, 0.7407024502754211, 0.7324380278587341, 0.7758264541625977, 0.7644628286361694, 0.7613636255264282, 0.7716942429542542, 0.7665289044380188, 0.76962810754776, 0.7727272510528564, 0.7727272510528564, 0.7654958963394165, 0.7634297609329224, 0.7613636255264282, 0.7479338645935059, 0.7665289044380188, 0.7716942429542542, 0.7685950398445129, 0.76962810754776, 0.7737603187561035, 0.7613636255264282, 0.7613636255264282, 0.7747933864593506, 0.7623966932296753, 0.7592975497245789, 0.7727272510528564, 0.7716942429542542, 0.7603305578231812, 0.7241735458374023, 0.7582644820213318, 0.76962810754776, 0.7665289044380188, 0.7644628286361694, 0.7603305578231812, 0.7675619721412659, 0.76962810754776, 0.7675619721412659, 0.7665289044380188, 0.7634297609329224, 0.7654958963394165, 0.7623966932296753, 0.7623966932296753, 0.7613636255264282, 0.7582644820213318, 0.7603305578231812, 0.7572314143180847, 0.7510330677032471, 0.7592975497245789, 0.7603305578231812, 0.7592975497245789, 0.7654958963394165, 0.7634297609329224, 0.7530992031097412, 0.7613636255264282, 0.7530992031097412, 0.7572314143180847, 0.7675619721412659, 0.75, 0.75, 0.7623966932296753, 0.7551652789115906]}\n","32/32 [==============================] - 1s 4ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_gru"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":519},"collapsed":true,"id":"kleLoWSV5B7Y","executionInfo":{"status":"ok","timestamp":1717532947882,"user_tz":-360,"elapsed":28,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}},"outputId":"ccf2869a-13d4-4466-f5c8-e29144aaea3e"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision    Recall        F1  Sensitivity  Specificity  \\\n","0        0  0.588777   0.601923  0.524288  0.560430     0.524288     0.653266   \n","1        1  0.596045   0.661137  0.394068  0.493805     0.394068     0.798023   \n","2        2  0.629518   0.640523  0.590361  0.614420     0.590361     0.668675   \n","3        0  0.613903   0.617647  0.597990  0.607660     0.597990     0.629816   \n","4        1  0.651836   0.697248  0.536723  0.606544     0.536723     0.766949   \n","5        2  0.682731   0.688017  0.668675  0.678208     0.668675     0.696787   \n","6        0  0.675042   0.688288  0.639866  0.663194     0.639866     0.710218   \n","7        1  0.687147   0.679783  0.707627  0.693426     0.707627     0.666667   \n","8        2  0.736948   0.774419  0.668675  0.717672     0.668675     0.805221   \n","9        0  0.739531   0.742373  0.733668  0.737995     0.733668     0.745394   \n","10       1  0.746469   0.742698  0.754237  0.748423     0.754237     0.738701   \n","11       2  0.770080   0.768463  0.773092  0.770771     0.773092     0.767068   \n","12       0  0.785595   0.781818  0.792295  0.787022     0.792295     0.778894   \n","13       1  0.793079   0.811094  0.764124  0.786909     0.764124     0.822034   \n","14       2  0.800201   0.842105  0.738956  0.787166     0.738956     0.861446   \n","\n","       Kappa  \n","0   0.177554  \n","1   0.192090  \n","2   0.259036  \n","3   0.227806  \n","4   0.303672  \n","5   0.365462  \n","6   0.350084  \n","7   0.374294  \n","8   0.473896  \n","9   0.479062  \n","10  0.492938  \n","11  0.540161  \n","12  0.571189  \n","13  0.586158  \n","14  0.600402  "],"text/html":["\n","  <div id=\"df-a6bb48da-a5eb-4bc9-aa4c-0cab837236c8\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.588777</td>\n","      <td>0.601923</td>\n","      <td>0.524288</td>\n","      <td>0.560430</td>\n","      <td>0.524288</td>\n","      <td>0.653266</td>\n","      <td>0.177554</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.596045</td>\n","      <td>0.661137</td>\n","      <td>0.394068</td>\n","      <td>0.493805</td>\n","      <td>0.394068</td>\n","      <td>0.798023</td>\n","      <td>0.192090</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.629518</td>\n","      <td>0.640523</td>\n","      <td>0.590361</td>\n","      <td>0.614420</td>\n","      <td>0.590361</td>\n","      <td>0.668675</td>\n","      <td>0.259036</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.613903</td>\n","      <td>0.617647</td>\n","      <td>0.597990</td>\n","      <td>0.607660</td>\n","      <td>0.597990</td>\n","      <td>0.629816</td>\n","      <td>0.227806</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.651836</td>\n","      <td>0.697248</td>\n","      <td>0.536723</td>\n","      <td>0.606544</td>\n","      <td>0.536723</td>\n","      <td>0.766949</td>\n","      <td>0.303672</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.682731</td>\n","      <td>0.688017</td>\n","      <td>0.668675</td>\n","      <td>0.678208</td>\n","      <td>0.668675</td>\n","      <td>0.696787</td>\n","      <td>0.365462</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.675042</td>\n","      <td>0.688288</td>\n","      <td>0.639866</td>\n","      <td>0.663194</td>\n","      <td>0.639866</td>\n","      <td>0.710218</td>\n","      <td>0.350084</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.687147</td>\n","      <td>0.679783</td>\n","      <td>0.707627</td>\n","      <td>0.693426</td>\n","      <td>0.707627</td>\n","      <td>0.666667</td>\n","      <td>0.374294</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.736948</td>\n","      <td>0.774419</td>\n","      <td>0.668675</td>\n","      <td>0.717672</td>\n","      <td>0.668675</td>\n","      <td>0.805221</td>\n","      <td>0.473896</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.739531</td>\n","      <td>0.742373</td>\n","      <td>0.733668</td>\n","      <td>0.737995</td>\n","      <td>0.733668</td>\n","      <td>0.745394</td>\n","      <td>0.479062</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.746469</td>\n","      <td>0.742698</td>\n","      <td>0.754237</td>\n","      <td>0.748423</td>\n","      <td>0.754237</td>\n","      <td>0.738701</td>\n","      <td>0.492938</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.770080</td>\n","      <td>0.768463</td>\n","      <td>0.773092</td>\n","      <td>0.770771</td>\n","      <td>0.773092</td>\n","      <td>0.767068</td>\n","      <td>0.540161</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.785595</td>\n","      <td>0.781818</td>\n","      <td>0.792295</td>\n","      <td>0.787022</td>\n","      <td>0.792295</td>\n","      <td>0.778894</td>\n","      <td>0.571189</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.793079</td>\n","      <td>0.811094</td>\n","      <td>0.764124</td>\n","      <td>0.786909</td>\n","      <td>0.764124</td>\n","      <td>0.822034</td>\n","      <td>0.586158</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.800201</td>\n","      <td>0.842105</td>\n","      <td>0.738956</td>\n","      <td>0.787166</td>\n","      <td>0.738956</td>\n","      <td>0.861446</td>\n","      <td>0.600402</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6bb48da-a5eb-4bc9-aa4c-0cab837236c8')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a6bb48da-a5eb-4bc9-aa4c-0cab837236c8 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a6bb48da-a5eb-4bc9-aa4c-0cab837236c8');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-18266210-8d83-4098-91b6-f48f7210c4f5\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-18266210-8d83-4098-91b6-f48f7210c4f5')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-18266210-8d83-4098-91b6-f48f7210c4f5 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_a11651d1-7f7f-4a20-8aae-7fa7ee551e21\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metrics_df_gru')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_a11651d1-7f7f-4a20-8aae-7fa7ee551e21 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('metrics_df_gru');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"metrics_df_gru","summary":"{\n  \"name\": \"metrics_df_gru\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07318849879587033,\n        \"min\": 0.5887772194304858,\n        \"max\": 0.8002008032128514,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7395309882747069,\n          0.7700803212851406,\n          0.5887772194304858\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07144350062066034,\n        \"min\": 0.6019230769230769,\n        \"max\": 0.8421052631578947,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7423728813559322,\n          0.7684630738522954,\n          0.6019230769230769\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.112603442611035,\n        \"min\": 0.3940677966101695,\n        \"max\": 0.7922948073701842,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.7542372881355932,\n          0.7922948073701842,\n          0.52428810720268\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09112022791497953,\n        \"min\": 0.49380530973451325,\n        \"max\": 0.7871657754010696,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.737994945240101,\n          0.7707707707707707,\n          0.5604297224709042\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.112603442611035,\n        \"min\": 0.3940677966101695,\n        \"max\": 0.7922948073701842,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.7542372881355932,\n          0.7922948073701842,\n          0.52428810720268\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06812732290577228,\n        \"min\": 0.6298157453936348,\n        \"max\": 0.8614457831325302,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7453936348408711,\n          0.7670682730923695,\n          0.6532663316582915\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14637699759174067,\n        \"min\": 0.17755443886097155,\n        \"max\": 0.6004016064257028,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.47906197654941374,\n          0.5401606425702812,\n          0.17755443886097155\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["metrics_df_gru.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/DWT/CNN_GRU/Delta_DWT_GRU.csv', index = False)"],"metadata":{"id":"QWSx6aHR5Bwr","executionInfo":{"status":"ok","timestamp":1717532947883,"user_tz":-360,"elapsed":11,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"j22QNwk33In1"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"collapsed_sections":["ZUR_QwblhNjJ"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}