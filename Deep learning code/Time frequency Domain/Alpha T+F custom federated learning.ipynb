{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Mbfw8uvdftFM","executionInfo":{"status":"ok","timestamp":1717589234793,"user_tz":-360,"elapsed":1713,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sb"]},{"cell_type":"code","source":["from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"INiFJfLjgOkx","executionInfo":{"status":"ok","timestamp":1717589236694,"user_tz":-360,"elapsed":588,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score, cross_val_predict"],"metadata":{"id":"lYo2Uq77gQSH","executionInfo":{"status":"ok","timestamp":1717589240372,"user_tz":-360,"elapsed":3680,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPool1D, Flatten, Dropout,LSTM"],"metadata":{"id":"g66575_xgVzz","executionInfo":{"status":"ok","timestamp":1717589251879,"user_tz":-360,"elapsed":11515,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MOCNWlamfr3v","executionInfo":{"status":"ok","timestamp":1717589272031,"user_tz":-360,"elapsed":20158,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}},"outputId":"438f98b4-a92c-45d1-de3b-b6fdd49f3d89"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Raw_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/only data/raw_data.npz'\n","\n","Theta_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/time frequency domain/RAW/Alpha_merged_features.npz'\n","\n","\n","\n","# RAW = np.load(Raw_data, allow_pickle=True)  # Allow loading pickled object arrays\n","# X = RAW['X'].astype('float64')\n","# Y = RAW['Y'].astype('float64')\n","# group = RAW['Group'].astype('float64')"],"metadata":{"id":"iNy9eOGMf2qO","executionInfo":{"status":"ok","timestamp":1717589272032,"user_tz":-360,"elapsed":7,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["This is a good performing model"],"metadata":{"id":"PzeABzSyHgKg"}},{"cell_type":"markdown","source":["# CNN-LSTM"],"metadata":{"id":"6DhAYwXUSE9z"}},{"cell_type":"code","source":["%%capture\n","!pip install tensorflow_addons"],"metadata":{"id":"uHeXXTotHRbF","executionInfo":{"status":"ok","timestamp":1717589289555,"user_tz":-360,"elapsed":17529,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time+Frequency/Alpha/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time+Frequency/Alpha/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"VvjC2xCQNHLP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716898675700,"user_tz":-360,"elapsed":699,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}},"outputId":"8cc0ede4-2231-4b2a-ed86-12c459f0e2ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["global_model, metrics_df = federated_learning(Theta_data)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVURUnmYNNNg","outputId":"302b5727-a1c8-4445-c507-77e5d38c6c8b","executionInfo":{"status":"ok","timestamp":1716899934012,"user_tz":-360,"elapsed":1022497,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train shape: (4640, 37, 29), Test shape: (1194, 37, 29)\n","Train shape: (4418, 37, 29), Test shape: (1416, 37, 29)\n","Train shape: (4838, 37, 29), Test shape: (996, 37, 29)\n","Train shape: (4640, 37, 29), Test shape: (1194, 37, 29)\n","Train shape: (4418, 37, 29), Test shape: (1416, 37, 29)\n","Train shape: (4838, 37, 29), Test shape: (996, 37, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 1.7003 - accuracy: 0.4891"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 27s 192ms/step - loss: 1.7001 - accuracy: 0.4884 - val_loss: 1.6948 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.6899 - accuracy: 0.5040 - val_loss: 1.6847 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.6798 - accuracy: 0.5059 - val_loss: 1.6747 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.6699 - accuracy: 0.5040 - val_loss: 1.6648 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.6599 - accuracy: 0.5046 - val_loss: 1.6549 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.6502 - accuracy: 0.5030 - val_loss: 1.6452 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.6405 - accuracy: 0.5046 - val_loss: 1.6356 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.6308 - accuracy: 0.5040 - val_loss: 1.6261 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.6214 - accuracy: 0.5040 - val_loss: 1.6167 - val_accuracy: 0.4849\n","Epoch 10/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.6120 - accuracy: 0.5032 - val_loss: 1.6073 - val_accuracy: 0.4849\n","Epoch 11/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.6026 - accuracy: 0.5102 - val_loss: 1.5980 - val_accuracy: 0.4838\n","Epoch 12/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.5935 - accuracy: 0.5038 - val_loss: 1.5889 - val_accuracy: 0.4849\n","Epoch 13/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.5843 - accuracy: 0.5065 - val_loss: 1.5798 - val_accuracy: 0.4849\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5752 - accuracy: 0.5067 - val_loss: 1.5708 - val_accuracy: 0.4838\n","Epoch 15/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5663 - accuracy: 0.5070 - val_loss: 1.5620 - val_accuracy: 0.4849\n","Epoch 16/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5574 - accuracy: 0.5129 - val_loss: 1.5531 - val_accuracy: 0.4849\n","Epoch 17/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5486 - accuracy: 0.5070 - val_loss: 1.5444 - val_accuracy: 0.4849\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5399 - accuracy: 0.5105 - val_loss: 1.5357 - val_accuracy: 0.4828\n","Epoch 19/100\n","29/29 [==============================] - 1s 50ms/step - loss: 1.5312 - accuracy: 0.5092 - val_loss: 1.5272 - val_accuracy: 0.4860\n","Epoch 20/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.5227 - accuracy: 0.5248 - val_loss: 1.5187 - val_accuracy: 0.4828\n","Epoch 21/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.5142 - accuracy: 0.5067 - val_loss: 1.5103 - val_accuracy: 0.4838\n","Epoch 22/100\n","29/29 [==============================] - 1s 31ms/step - loss: 1.5058 - accuracy: 0.5116 - val_loss: 1.5019 - val_accuracy: 0.4968\n","Epoch 23/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.4975 - accuracy: 0.5264 - val_loss: 1.4936 - val_accuracy: 0.4957\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4892 - accuracy: 0.5167 - val_loss: 1.4855 - val_accuracy: 0.4881\n","Epoch 25/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4811 - accuracy: 0.5097 - val_loss: 1.4774 - val_accuracy: 0.4957\n","Epoch 26/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4729 - accuracy: 0.5423 - val_loss: 1.4696 - val_accuracy: 0.4838\n","Epoch 27/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.4648 - accuracy: 0.5242 - val_loss: 1.4613 - val_accuracy: 0.5011\n","Epoch 28/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4567 - accuracy: 0.5356 - val_loss: 1.4538 - val_accuracy: 0.4838\n","Epoch 29/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.4488 - accuracy: 0.5304 - val_loss: 1.4456 - val_accuracy: 0.5151\n","Epoch 30/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4409 - accuracy: 0.5361 - val_loss: 1.4380 - val_accuracy: 0.4978\n","Epoch 31/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4336 - accuracy: 0.5237 - val_loss: 1.4304 - val_accuracy: 0.4978\n","Epoch 32/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4254 - accuracy: 0.5547 - val_loss: 1.4230 - val_accuracy: 0.4957\n","Epoch 33/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.4177 - accuracy: 0.5380 - val_loss: 1.4149 - val_accuracy: 0.5280\n","Epoch 34/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4100 - accuracy: 0.5595 - val_loss: 1.4076 - val_accuracy: 0.5183\n","Epoch 35/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.4023 - accuracy: 0.5482 - val_loss: 1.3999 - val_accuracy: 0.5399\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3946 - accuracy: 0.5692 - val_loss: 1.3942 - val_accuracy: 0.4881\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3870 - accuracy: 0.5544 - val_loss: 1.3855 - val_accuracy: 0.5302\n","Epoch 38/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.3794 - accuracy: 0.5571 - val_loss: 1.3776 - val_accuracy: 0.5431\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3714 - accuracy: 0.5690 - val_loss: 1.3725 - val_accuracy: 0.5043\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3643 - accuracy: 0.5539 - val_loss: 1.3643 - val_accuracy: 0.5269\n","Epoch 41/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.3565 - accuracy: 0.5552 - val_loss: 1.3561 - val_accuracy: 0.5474\n","Epoch 42/100\n","29/29 [==============================] - 1s 32ms/step - loss: 1.3481 - accuracy: 0.5757 - val_loss: 1.3488 - val_accuracy: 0.5517\n","Epoch 43/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3406 - accuracy: 0.5692 - val_loss: 1.3413 - val_accuracy: 0.5463\n","Epoch 44/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3321 - accuracy: 0.5703 - val_loss: 1.3376 - val_accuracy: 0.5237\n","Epoch 45/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3241 - accuracy: 0.5827 - val_loss: 1.3284 - val_accuracy: 0.5496\n","Epoch 46/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.3151 - accuracy: 0.5884 - val_loss: 1.3202 - val_accuracy: 0.5582\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3101 - accuracy: 0.5735 - val_loss: 1.3134 - val_accuracy: 0.5528\n","Epoch 48/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.2995 - accuracy: 0.5884 - val_loss: 1.3080 - val_accuracy: 0.5733\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2916 - accuracy: 0.5892 - val_loss: 1.3005 - val_accuracy: 0.5517\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2809 - accuracy: 0.5951 - val_loss: 1.3018 - val_accuracy: 0.5528\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2735 - accuracy: 0.5964 - val_loss: 1.2896 - val_accuracy: 0.5496\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2652 - accuracy: 0.6021 - val_loss: 1.2836 - val_accuracy: 0.5517\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2572 - accuracy: 0.6078 - val_loss: 1.2776 - val_accuracy: 0.5506\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2492 - accuracy: 0.6142 - val_loss: 1.2777 - val_accuracy: 0.5668\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2421 - accuracy: 0.6110 - val_loss: 1.2764 - val_accuracy: 0.5636\n","Epoch 56/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.2359 - accuracy: 0.6040 - val_loss: 1.2642 - val_accuracy: 0.5754\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2285 - accuracy: 0.6202 - val_loss: 1.2585 - val_accuracy: 0.5722\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2159 - accuracy: 0.6263 - val_loss: 1.2646 - val_accuracy: 0.5657\n","Epoch 59/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.2112 - accuracy: 0.6293 - val_loss: 1.2518 - val_accuracy: 0.5787\n","Epoch 60/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2075 - accuracy: 0.6307 - val_loss: 1.2693 - val_accuracy: 0.5582\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2020 - accuracy: 0.6188 - val_loss: 1.2790 - val_accuracy: 0.5496\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1927 - accuracy: 0.6288 - val_loss: 1.2392 - val_accuracy: 0.5787\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1832 - accuracy: 0.6363 - val_loss: 1.2322 - val_accuracy: 0.5787\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1767 - accuracy: 0.6406 - val_loss: 1.2329 - val_accuracy: 0.5754\n","Epoch 65/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.1730 - accuracy: 0.6323 - val_loss: 1.2229 - val_accuracy: 0.5873\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1634 - accuracy: 0.6420 - val_loss: 1.2201 - val_accuracy: 0.5733\n","Epoch 67/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1577 - accuracy: 0.6420 - val_loss: 1.2219 - val_accuracy: 0.5776\n","Epoch 68/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1485 - accuracy: 0.6463 - val_loss: 1.2116 - val_accuracy: 0.5841\n","Epoch 69/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1418 - accuracy: 0.6487 - val_loss: 1.2225 - val_accuracy: 0.5711\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1294 - accuracy: 0.6703 - val_loss: 1.2058 - val_accuracy: 0.5851\n","Epoch 71/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1331 - accuracy: 0.6571 - val_loss: 1.2064 - val_accuracy: 0.5765\n","Epoch 72/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.1234 - accuracy: 0.6622 - val_loss: 1.1995 - val_accuracy: 0.5884\n","Epoch 73/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.1175 - accuracy: 0.6622 - val_loss: 1.1966 - val_accuracy: 0.5894\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1085 - accuracy: 0.6608 - val_loss: 1.2099 - val_accuracy: 0.5744\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0955 - accuracy: 0.6721 - val_loss: 1.1919 - val_accuracy: 0.5830\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0997 - accuracy: 0.6638 - val_loss: 1.2006 - val_accuracy: 0.5744\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0891 - accuracy: 0.6684 - val_loss: 1.1856 - val_accuracy: 0.5884\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0887 - accuracy: 0.6635 - val_loss: 1.1862 - val_accuracy: 0.5787\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0829 - accuracy: 0.6665 - val_loss: 1.1996 - val_accuracy: 0.5733\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0737 - accuracy: 0.6775 - val_loss: 1.1802 - val_accuracy: 0.5797\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0668 - accuracy: 0.6810 - val_loss: 1.1703 - val_accuracy: 0.5862\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0617 - accuracy: 0.6808 - val_loss: 1.1698 - val_accuracy: 0.5873\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0592 - accuracy: 0.6743 - val_loss: 1.1684 - val_accuracy: 0.5873\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0611 - accuracy: 0.6727 - val_loss: 1.1847 - val_accuracy: 0.5700\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0507 - accuracy: 0.6778 - val_loss: 1.1574 - val_accuracy: 0.5884\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0368 - accuracy: 0.6902 - val_loss: 1.1752 - val_accuracy: 0.5722\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0329 - accuracy: 0.6942 - val_loss: 1.1555 - val_accuracy: 0.5862\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0233 - accuracy: 0.6988 - val_loss: 1.1713 - val_accuracy: 0.5614\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0283 - accuracy: 0.6945 - val_loss: 1.1615 - val_accuracy: 0.5830\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0189 - accuracy: 0.6886 - val_loss: 1.1692 - val_accuracy: 0.5657\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0135 - accuracy: 0.6967 - val_loss: 1.1450 - val_accuracy: 0.5830\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0047 - accuracy: 0.7010 - val_loss: 1.1428 - val_accuracy: 0.5819\n","Epoch 93/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0002 - accuracy: 0.7055 - val_loss: 1.1406 - val_accuracy: 0.5830\n","Epoch 94/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9929 - accuracy: 0.7134 - val_loss: 1.1448 - val_accuracy: 0.5862\n","Epoch 95/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9906 - accuracy: 0.7055 - val_loss: 1.1434 - val_accuracy: 0.5797\n","Epoch 96/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9823 - accuracy: 0.7147 - val_loss: 1.1365 - val_accuracy: 0.5765\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0069 - accuracy: 0.6773 - val_loss: 1.1640 - val_accuracy: 0.5657\n","Epoch 98/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9878 - accuracy: 0.6994 - val_loss: 1.1488 - val_accuracy: 0.5744\n","Epoch 99/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9780 - accuracy: 0.7050 - val_loss: 1.1455 - val_accuracy: 0.5808\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9738 - accuracy: 0.7058 - val_loss: 1.1218 - val_accuracy: 0.5830\n","{'loss': [1.7001099586486816, 1.6898818016052246, 1.6798192262649536, 1.6698708534240723, 1.659928798675537, 1.6501576900482178, 1.6404697895050049, 1.6308437585830688, 1.62135910987854, 1.6119664907455444, 1.6025934219360352, 1.5934561491012573, 1.5842782258987427, 1.5752053260803223, 1.5662789344787598, 1.5574127435684204, 1.548565149307251, 1.5399037599563599, 1.5312496423721313, 1.52266526222229, 1.5142261981964111, 1.5057741403579712, 1.4974573850631714, 1.4891780614852905, 1.4810794591903687, 1.472907543182373, 1.4647529125213623, 1.456701636314392, 1.4487740993499756, 1.4409444332122803, 1.4336485862731934, 1.4254333972930908, 1.417718768119812, 1.409950613975525, 1.4022819995880127, 1.3945586681365967, 1.3870244026184082, 1.3793771266937256, 1.3713898658752441, 1.3643492460250854, 1.3565173149108887, 1.348125696182251, 1.3406082391738892, 1.332114338874817, 1.3240532875061035, 1.3150707483291626, 1.3100801706314087, 1.2994729280471802, 1.2916489839553833, 1.2808986902236938, 1.273459553718567, 1.265179991722107, 1.2572264671325684, 1.2491565942764282, 1.242074728012085, 1.2358883619308472, 1.2284916639328003, 1.2159032821655273, 1.2111916542053223, 1.2074826955795288, 1.201989769935608, 1.1926649808883667, 1.1831507682800293, 1.1766587495803833, 1.1729590892791748, 1.163404107093811, 1.1576517820358276, 1.1485191583633423, 1.1417860984802246, 1.129409670829773, 1.1330691576004028, 1.1234203577041626, 1.117537260055542, 1.1084622144699097, 1.0954527854919434, 1.09971022605896, 1.0891095399856567, 1.0887051820755005, 1.0828734636306763, 1.07370126247406, 1.0668448209762573, 1.061653733253479, 1.0592012405395508, 1.0610905885696411, 1.0507206916809082, 1.036832332611084, 1.0328593254089355, 1.0232574939727783, 1.0282584428787231, 1.018939733505249, 1.0134682655334473, 1.004694938659668, 1.000213861465454, 0.9929460883140564, 0.9906181693077087, 0.9823263883590698, 1.0068608522415161, 0.987775981426239, 0.9779852628707886, 0.9737626910209656], 'accuracy': [0.4884159564971924, 0.5040409564971924, 0.5059267282485962, 0.5040409564971924, 0.5045797228813171, 0.5029633641242981, 0.5045797228813171, 0.5040409564971924, 0.5040409564971924, 0.5032327771186829, 0.5102370977401733, 0.5037715435028076, 0.506465494632721, 0.5067349076271057, 0.5070043206214905, 0.5129310488700867, 0.5070043206214905, 0.5105064511299133, 0.509159505367279, 0.524784505367279, 0.5067349076271057, 0.5115840435028076, 0.5264008641242981, 0.5167025923728943, 0.5096982717514038, 0.5422952771186829, 0.5242456793785095, 0.5355603694915771, 0.5304418206214905, 0.5360991358757019, 0.5237069129943848, 0.5546875, 0.5379849076271057, 0.5595366358757019, 0.548222005367279, 0.5692349076271057, 0.5544180870056152, 0.5571120977401733, 0.568965494632721, 0.5538793206214905, 0.5552262663841248, 0.5757004022598267, 0.5692349076271057, 0.5703125, 0.5827047228813171, 0.5883620977401733, 0.5735452771186829, 0.5883620977401733, 0.5891702771186829, 0.595097005367279, 0.5964439511299133, 0.6021012663841248, 0.607758641242981, 0.6142241358757019, 0.610991358757019, 0.6039870977401733, 0.6201508641242981, 0.626347005367279, 0.6293103694915771, 0.6306573152542114, 0.618803858757019, 0.6287715435028076, 0.6363146305084229, 0.640625, 0.6322737336158752, 0.641972005367279, 0.641972005367279, 0.6462823152542114, 0.6487069129943848, 0.670258641242981, 0.6570581793785095, 0.6621767282485962, 0.6621767282485962, 0.6608297228813171, 0.6721444129943848, 0.6637930870056152, 0.6683728694915771, 0.6635237336158752, 0.6664870977401733, 0.6775323152542114, 0.681034505367279, 0.6807650923728943, 0.6742995977401733, 0.6726831793785095, 0.6778017282485962, 0.6901939511299133, 0.6942349076271057, 0.6988146305084229, 0.6945043206214905, 0.6885775923728943, 0.696659505367279, 0.7009698152542114, 0.7055495977401733, 0.7133620977401733, 0.7055495977401733, 0.7147090435028076, 0.6772629022598267, 0.6993534564971924, 0.7050107717514038, 0.7058189511299133], 'val_loss': [1.6948037147521973, 1.6846952438354492, 1.6746803522109985, 1.664757251739502, 1.6549456119537354, 1.6452265977859497, 1.635614275932312, 1.6260812282562256, 1.6166539192199707, 1.6073054075241089, 1.5980241298675537, 1.5889190435409546, 1.579819679260254, 1.5708168745040894, 1.561962366104126, 1.5531069040298462, 1.5444058179855347, 1.5357275009155273, 1.5272268056869507, 1.5186896324157715, 1.5103020668029785, 1.5019147396087646, 1.49363112449646, 1.48550283908844, 1.4773900508880615, 1.4695595502853394, 1.4613276720046997, 1.453797698020935, 1.445579171180725, 1.4380196332931519, 1.4304497241973877, 1.4229739904403687, 1.4149221181869507, 1.4076021909713745, 1.3998823165893555, 1.3942033052444458, 1.385451316833496, 1.377569317817688, 1.372469186782837, 1.36431884765625, 1.3561136722564697, 1.3488185405731201, 1.341313362121582, 1.3375909328460693, 1.328427791595459, 1.3202377557754517, 1.3134078979492188, 1.3079781532287598, 1.3004980087280273, 1.3017652034759521, 1.2896167039871216, 1.283610224723816, 1.2775561809539795, 1.277712106704712, 1.2764294147491455, 1.2641505002975464, 1.258510947227478, 1.264607548713684, 1.2518340349197388, 1.269344449043274, 1.2790390253067017, 1.2392258644104004, 1.2321891784667969, 1.232904076576233, 1.2229453325271606, 1.2200524806976318, 1.221878170967102, 1.2116024494171143, 1.2225146293640137, 1.2057894468307495, 1.2063875198364258, 1.1995327472686768, 1.1965562105178833, 1.2098922729492188, 1.1919496059417725, 1.2006466388702393, 1.185642957687378, 1.1861646175384521, 1.199610710144043, 1.1801785230636597, 1.170259952545166, 1.16978919506073, 1.1683876514434814, 1.1847189664840698, 1.1573524475097656, 1.1752326488494873, 1.1555110216140747, 1.1712864637374878, 1.1614924669265747, 1.1692001819610596, 1.1449533700942993, 1.1427526473999023, 1.140607476234436, 1.1448172330856323, 1.1434228420257568, 1.1365333795547485, 1.1639975309371948, 1.148829460144043, 1.1454592943191528, 1.1217963695526123], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48383620381355286, 0.48491379618644714, 0.48491379618644714, 0.48383620381355286, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48275861144065857, 0.48599138855934143, 0.48275861144065857, 0.48383620381355286, 0.4967672526836395, 0.49568966031074524, 0.4881465435028076, 0.49568966031074524, 0.48383620381355286, 0.5010775923728943, 0.48383620381355286, 0.5150862336158752, 0.4978448152542114, 0.4978448152542114, 0.49568966031074524, 0.5280172228813171, 0.5183189511299133, 0.5398706793785095, 0.4881465435028076, 0.5301724076271057, 0.5431034564971924, 0.5043103694915771, 0.5269396305084229, 0.5474137663841248, 0.5517241358757019, 0.5463362336158752, 0.5237069129943848, 0.5495689511299133, 0.5581896305084229, 0.5528017282485962, 0.5732758641242981, 0.5517241358757019, 0.5528017282485962, 0.5495689511299133, 0.5517241358757019, 0.5506465435028076, 0.5668103694915771, 0.5635775923728943, 0.5754310488700867, 0.5721982717514038, 0.5657327771186829, 0.5786637663841248, 0.5581896305084229, 0.5495689511299133, 0.5786637663841248, 0.5786637663841248, 0.5754310488700867, 0.587284505367279, 0.5732758641242981, 0.5775862336158752, 0.5840517282485962, 0.5711206793785095, 0.5851293206214905, 0.576508641242981, 0.5883620977401733, 0.5894396305084229, 0.5743534564971924, 0.5829741358757019, 0.5743534564971924, 0.5883620977401733, 0.5786637663841248, 0.5732758641242981, 0.579741358757019, 0.5862069129943848, 0.587284505367279, 0.587284505367279, 0.5700430870056152, 0.5883620977401733, 0.5721982717514038, 0.5862069129943848, 0.5614224076271057, 0.5829741358757019, 0.5657327771186829, 0.5829741358757019, 0.5818965435028076, 0.5829741358757019, 0.5862069129943848, 0.579741358757019, 0.576508641242981, 0.5657327771186829, 0.5743534564971924, 0.5808189511299133, 0.5829741358757019]}\n","38/38 [==============================] - 1s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 1.7003 - accuracy: 0.4909"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 88ms/step - loss: 1.7003 - accuracy: 0.4909 - val_loss: 1.6951 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.6905 - accuracy: 0.5108 - val_loss: 1.6854 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.6808 - accuracy: 0.4833 - val_loss: 1.6757 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.6711 - accuracy: 0.4924 - val_loss: 1.6661 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.6615 - accuracy: 0.5008 - val_loss: 1.6566 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.6521 - accuracy: 0.5003 - val_loss: 1.6472 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.6427 - accuracy: 0.5209 - val_loss: 1.6379 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 31ms/step - loss: 1.6334 - accuracy: 0.5266 - val_loss: 1.6286 - val_accuracy: 0.4966\n","Epoch 9/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.6242 - accuracy: 0.5105 - val_loss: 1.6195 - val_accuracy: 0.4955\n","Epoch 10/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.6150 - accuracy: 0.5136 - val_loss: 1.6104 - val_accuracy: 0.4977\n","Epoch 11/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.6060 - accuracy: 0.5246 - val_loss: 1.6015 - val_accuracy: 0.4955\n","Epoch 12/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5971 - accuracy: 0.5113 - val_loss: 1.5926 - val_accuracy: 0.4966\n","Epoch 13/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.5882 - accuracy: 0.5102 - val_loss: 1.5838 - val_accuracy: 0.4977\n","Epoch 14/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.5794 - accuracy: 0.5204 - val_loss: 1.5751 - val_accuracy: 0.5000\n","Epoch 15/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.5707 - accuracy: 0.5374 - val_loss: 1.5664 - val_accuracy: 0.4977\n","Epoch 16/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5620 - accuracy: 0.5158 - val_loss: 1.5579 - val_accuracy: 0.4989\n","Epoch 17/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.5535 - accuracy: 0.5133 - val_loss: 1.5494 - val_accuracy: 0.5000\n","Epoch 18/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.5450 - accuracy: 0.5362 - val_loss: 1.5410 - val_accuracy: 0.5034\n","Epoch 19/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.5366 - accuracy: 0.5170 - val_loss: 1.5327 - val_accuracy: 0.4989\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5283 - accuracy: 0.5300 - val_loss: 1.5244 - val_accuracy: 0.5011\n","Epoch 21/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5200 - accuracy: 0.5371 - val_loss: 1.5163 - val_accuracy: 0.5000\n","Epoch 22/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.5118 - accuracy: 0.5422 - val_loss: 1.5082 - val_accuracy: 0.5045\n","Epoch 23/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.5037 - accuracy: 0.5351 - val_loss: 1.5002 - val_accuracy: 0.5023\n","Epoch 24/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4955 - accuracy: 0.5371 - val_loss: 1.4922 - val_accuracy: 0.5023\n","Epoch 25/100\n","28/28 [==============================] - 1s 30ms/step - loss: 1.4876 - accuracy: 0.5521 - val_loss: 1.4843 - val_accuracy: 0.5090\n","Epoch 26/100\n","28/28 [==============================] - 1s 31ms/step - loss: 1.4796 - accuracy: 0.5453 - val_loss: 1.4764 - val_accuracy: 0.5113\n","Epoch 27/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.4719 - accuracy: 0.5419 - val_loss: 1.4690 - val_accuracy: 0.5023\n","Epoch 28/100\n","28/28 [==============================] - 1s 34ms/step - loss: 1.4640 - accuracy: 0.5396 - val_loss: 1.4610 - val_accuracy: 0.5181\n","Epoch 29/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.4562 - accuracy: 0.5523 - val_loss: 1.4535 - val_accuracy: 0.5090\n","Epoch 30/100\n","28/28 [==============================] - 1s 34ms/step - loss: 1.4484 - accuracy: 0.5475 - val_loss: 1.4458 - val_accuracy: 0.5452\n","Epoch 31/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4407 - accuracy: 0.5586 - val_loss: 1.4388 - val_accuracy: 0.5000\n","Epoch 32/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4332 - accuracy: 0.5376 - val_loss: 1.4309 - val_accuracy: 0.5136\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4257 - accuracy: 0.5453 - val_loss: 1.4235 - val_accuracy: 0.5260\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4183 - accuracy: 0.5374 - val_loss: 1.4163 - val_accuracy: 0.5294\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4102 - accuracy: 0.5591 - val_loss: 1.4095 - val_accuracy: 0.5090\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4030 - accuracy: 0.5535 - val_loss: 1.4018 - val_accuracy: 0.5339\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3957 - accuracy: 0.5526 - val_loss: 1.3948 - val_accuracy: 0.5204\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3881 - accuracy: 0.5532 - val_loss: 1.3881 - val_accuracy: 0.5158\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3798 - accuracy: 0.5685 - val_loss: 1.3811 - val_accuracy: 0.5226\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3717 - accuracy: 0.5645 - val_loss: 1.3741 - val_accuracy: 0.5260\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3634 - accuracy: 0.5758 - val_loss: 1.3672 - val_accuracy: 0.5385\n","Epoch 42/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.3569 - accuracy: 0.5656 - val_loss: 1.3613 - val_accuracy: 0.5305\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3492 - accuracy: 0.5688 - val_loss: 1.3535 - val_accuracy: 0.5339\n","Epoch 44/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.3418 - accuracy: 0.5767 - val_loss: 1.3469 - val_accuracy: 0.5452\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3341 - accuracy: 0.5722 - val_loss: 1.3469 - val_accuracy: 0.5090\n","Epoch 46/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3281 - accuracy: 0.5671 - val_loss: 1.3342 - val_accuracy: 0.5385\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3190 - accuracy: 0.5855 - val_loss: 1.3288 - val_accuracy: 0.5407\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3114 - accuracy: 0.5809 - val_loss: 1.3225 - val_accuracy: 0.5441\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3053 - accuracy: 0.5798 - val_loss: 1.3167 - val_accuracy: 0.5452\n","Epoch 50/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.3021 - accuracy: 0.5724 - val_loss: 1.3121 - val_accuracy: 0.5532\n","Epoch 51/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2907 - accuracy: 0.5801 - val_loss: 1.3131 - val_accuracy: 0.5441\n","Epoch 52/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.2862 - accuracy: 0.5843 - val_loss: 1.2984 - val_accuracy: 0.5452\n","Epoch 53/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.2756 - accuracy: 0.5959 - val_loss: 1.2928 - val_accuracy: 0.5430\n","Epoch 54/100\n","28/28 [==============================] - 1s 45ms/step - loss: 1.2718 - accuracy: 0.5911 - val_loss: 1.2883 - val_accuracy: 0.5498\n","Epoch 55/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2626 - accuracy: 0.5920 - val_loss: 1.2860 - val_accuracy: 0.5419\n","Epoch 56/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.2612 - accuracy: 0.5931 - val_loss: 1.2785 - val_accuracy: 0.5430\n","Epoch 57/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2515 - accuracy: 0.5971 - val_loss: 1.2713 - val_accuracy: 0.5532\n","Epoch 58/100\n","28/28 [==============================] - 1s 30ms/step - loss: 1.2447 - accuracy: 0.6038 - val_loss: 1.2650 - val_accuracy: 0.5577\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2386 - accuracy: 0.6033 - val_loss: 1.2600 - val_accuracy: 0.5486\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2347 - accuracy: 0.5999 - val_loss: 1.2552 - val_accuracy: 0.5520\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2312 - accuracy: 0.5976 - val_loss: 1.2495 - val_accuracy: 0.5532\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2176 - accuracy: 0.6177 - val_loss: 1.2445 - val_accuracy: 0.5577\n","Epoch 63/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.2116 - accuracy: 0.6092 - val_loss: 1.2396 - val_accuracy: 0.5611\n","Epoch 64/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.2105 - accuracy: 0.6191 - val_loss: 1.2381 - val_accuracy: 0.5667\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2074 - accuracy: 0.6038 - val_loss: 1.2294 - val_accuracy: 0.5566\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1956 - accuracy: 0.6174 - val_loss: 1.2270 - val_accuracy: 0.5419\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1908 - accuracy: 0.6154 - val_loss: 1.2201 - val_accuracy: 0.5656\n","Epoch 68/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.1828 - accuracy: 0.6177 - val_loss: 1.2162 - val_accuracy: 0.5803\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1763 - accuracy: 0.6265 - val_loss: 1.2165 - val_accuracy: 0.5724\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1745 - accuracy: 0.6203 - val_loss: 1.2076 - val_accuracy: 0.5781\n","Epoch 71/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1622 - accuracy: 0.6307 - val_loss: 1.2301 - val_accuracy: 0.5283\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1641 - accuracy: 0.6290 - val_loss: 1.1974 - val_accuracy: 0.5735\n","Epoch 73/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1561 - accuracy: 0.6248 - val_loss: 1.2018 - val_accuracy: 0.5486\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1491 - accuracy: 0.6333 - val_loss: 1.1896 - val_accuracy: 0.5713\n","Epoch 75/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.1465 - accuracy: 0.6341 - val_loss: 1.1865 - val_accuracy: 0.5894\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1339 - accuracy: 0.6398 - val_loss: 1.1820 - val_accuracy: 0.5792\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1299 - accuracy: 0.6398 - val_loss: 1.2059 - val_accuracy: 0.5464\n","Epoch 78/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1250 - accuracy: 0.6449 - val_loss: 1.1741 - val_accuracy: 0.5871\n","Epoch 79/100\n","28/28 [==============================] - 1s 31ms/step - loss: 1.1133 - accuracy: 0.6585 - val_loss: 1.1719 - val_accuracy: 0.5939\n","Epoch 80/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1081 - accuracy: 0.6587 - val_loss: 1.1757 - val_accuracy: 0.5509\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1108 - accuracy: 0.6404 - val_loss: 1.1795 - val_accuracy: 0.5452\n","Epoch 82/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.0970 - accuracy: 0.6553 - val_loss: 1.1667 - val_accuracy: 0.5600\n","Epoch 83/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.0951 - accuracy: 0.6548 - val_loss: 1.1716 - val_accuracy: 0.5532\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0961 - accuracy: 0.6454 - val_loss: 1.1579 - val_accuracy: 0.5735\n","Epoch 85/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0778 - accuracy: 0.6661 - val_loss: 1.1495 - val_accuracy: 0.5928\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0777 - accuracy: 0.6621 - val_loss: 1.1577 - val_accuracy: 0.5645\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0716 - accuracy: 0.6621 - val_loss: 1.1548 - val_accuracy: 0.5667\n","Epoch 88/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.0719 - accuracy: 0.6568 - val_loss: 1.1435 - val_accuracy: 0.5973\n","Epoch 89/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.0687 - accuracy: 0.6619 - val_loss: 1.1419 - val_accuracy: 0.5984\n","Epoch 90/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.0549 - accuracy: 0.6667 - val_loss: 1.1346 - val_accuracy: 0.6052\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0504 - accuracy: 0.6667 - val_loss: 1.1370 - val_accuracy: 0.5792\n","Epoch 92/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.0409 - accuracy: 0.6774 - val_loss: 1.1305 - val_accuracy: 0.6075\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0383 - accuracy: 0.6703 - val_loss: 1.1285 - val_accuracy: 0.5995\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0342 - accuracy: 0.6706 - val_loss: 1.1290 - val_accuracy: 0.5995\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0278 - accuracy: 0.6794 - val_loss: 1.1242 - val_accuracy: 0.5984\n","Epoch 96/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0236 - accuracy: 0.6831 - val_loss: 1.1265 - val_accuracy: 0.5837\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0138 - accuracy: 0.6848 - val_loss: 1.1244 - val_accuracy: 0.5837\n","Epoch 98/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.0092 - accuracy: 0.6862 - val_loss: 1.1197 - val_accuracy: 0.6086\n","Epoch 99/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0145 - accuracy: 0.6769 - val_loss: 1.1291 - val_accuracy: 0.5769\n","Epoch 100/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0014 - accuracy: 0.6921 - val_loss: 1.1134 - val_accuracy: 0.5973\n","{'loss': [1.7003309726715088, 1.6904757022857666, 1.6807751655578613, 1.6711331605911255, 1.6615447998046875, 1.6521151065826416, 1.6426520347595215, 1.6334056854248047, 1.624153733253479, 1.6150189638137817, 1.6059786081314087, 1.597062110900879, 1.588191270828247, 1.5794271230697632, 1.5706533193588257, 1.5620430707931519, 1.5535117387771606, 1.5450305938720703, 1.5365996360778809, 1.5282626152038574, 1.5200297832489014, 1.511821985244751, 1.5036735534667969, 1.49551260471344, 1.4875680208206177, 1.4795634746551514, 1.471855878829956, 1.4640312194824219, 1.4561705589294434, 1.4483693838119507, 1.4407068490982056, 1.4332270622253418, 1.4257489442825317, 1.4183142185211182, 1.4101999998092651, 1.4030057191848755, 1.3957014083862305, 1.388148546218872, 1.3798062801361084, 1.3716561794281006, 1.3633830547332764, 1.3569267988204956, 1.3492493629455566, 1.3418434858322144, 1.3341217041015625, 1.328141450881958, 1.3189529180526733, 1.311379313468933, 1.3052889108657837, 1.3020504713058472, 1.2906841039657593, 1.2861661911010742, 1.275644302368164, 1.2718442678451538, 1.2626452445983887, 1.2612427473068237, 1.2515289783477783, 1.2446744441986084, 1.2386391162872314, 1.2347489595413208, 1.2311875820159912, 1.217624306678772, 1.2116395235061646, 1.2104915380477905, 1.2074224948883057, 1.1955615282058716, 1.1908422708511353, 1.1827914714813232, 1.176321029663086, 1.1745249032974243, 1.162152886390686, 1.164069414138794, 1.156103253364563, 1.1491029262542725, 1.1465070247650146, 1.1339277029037476, 1.129926085472107, 1.125048279762268, 1.1133049726486206, 1.108063817024231, 1.110796332359314, 1.0970195531845093, 1.0950673818588257, 1.0960599184036255, 1.0778189897537231, 1.077738881111145, 1.0716228485107422, 1.0718504190444946, 1.0687403678894043, 1.0548864603042603, 1.0504287481307983, 1.0409311056137085, 1.038265585899353, 1.0341945886611938, 1.027825951576233, 1.0236356258392334, 1.0138399600982666, 1.0092285871505737, 1.0144680738449097, 1.0014458894729614], 'accuracy': [0.49094510078430176, 0.5107526779174805, 0.48330503702163696, 0.4923599362373352, 0.5008488893508911, 0.5002829432487488, 0.5209394693374634, 0.5265987515449524, 0.5104697346687317, 0.5135823488235474, 0.5246179699897766, 0.5113186240196228, 0.5101867318153381, 0.520373523235321, 0.5373514294624329, 0.5158460736274719, 0.5132994055747986, 0.536219596862793, 0.5169779062271118, 0.5299943685531616, 0.5370684862136841, 0.5421618819236755, 0.5350877046585083, 0.5370684862136841, 0.5520656704902649, 0.5452744960784912, 0.541878879070282, 0.5396151542663574, 0.5523486137390137, 0.5475382208824158, 0.558573842048645, 0.5376344323158264, 0.5452744960784912, 0.5373514294624329, 0.5591397881507874, 0.5534804463386536, 0.5526315569877625, 0.5531975030899048, 0.5684776306152344, 0.5645161271095276, 0.5758347511291504, 0.5656480193138123, 0.5687606334686279, 0.5766836404800415, 0.5721561908721924, 0.5670627951622009, 0.585455596446991, 0.5809281468391418, 0.5797962546348572, 0.5724391341209412, 0.5800792574882507, 0.5843237042427063, 0.5959252715110779, 0.59111487865448, 0.5919637680053711, 0.5930956602096558, 0.5970571637153625, 0.6038483381271362, 0.6032823920249939, 0.5998868346214294, 0.5976231098175049, 0.6177136301994324, 0.6092246770858765, 0.6191284656524658, 0.6038483381271362, 0.6174306869506836, 0.6154499053955078, 0.6177136301994324, 0.6264855861663818, 0.6202603578567505, 0.6307300329208374, 0.6290322542190552, 0.6247877478599548, 0.6332767605781555, 0.6341256499290466, 0.6397849321365356, 0.6397849321365356, 0.6448783278465271, 0.6584606766700745, 0.6587436199188232, 0.640350878238678, 0.6553480625152588, 0.6547821164131165, 0.6454442739486694, 0.6661007404327393, 0.6621392369270325, 0.6621392369270325, 0.6567628979682922, 0.6618562340736389, 0.6666666865348816, 0.6666666865348816, 0.6774193644523621, 0.6703452467918396, 0.6706281900405884, 0.6794000864028931, 0.6830786466598511, 0.6847764849662781, 0.6861912608146667, 0.6768534183502197, 0.6921335458755493], 'val_loss': [1.6951370239257812, 1.6853634119033813, 1.6756807565689087, 1.6660959720611572, 1.6565998792648315, 1.6471916437149048, 1.6378741264343262, 1.6286418437957764, 1.6195027828216553, 1.6104432344436646, 1.6014806032180786, 1.5925886631011963, 1.583791732788086, 1.5750619173049927, 1.5664401054382324, 1.5578908920288086, 1.5494086742401123, 1.5410186052322388, 1.532711148262024, 1.5244402885437012, 1.5162701606750488, 1.5081651210784912, 1.500172734260559, 1.492163896560669, 1.4842628240585327, 1.476426124572754, 1.46898353099823, 1.4609932899475098, 1.4535201787948608, 1.4458472728729248, 1.4387991428375244, 1.4309227466583252, 1.4235401153564453, 1.4162535667419434, 1.409451961517334, 1.401838779449463, 1.394838809967041, 1.3880608081817627, 1.3810731172561646, 1.374083399772644, 1.367160439491272, 1.3613245487213135, 1.353475570678711, 1.3469491004943848, 1.3469325304031372, 1.3341689109802246, 1.3287595510482788, 1.3225353956222534, 1.3167009353637695, 1.3121309280395508, 1.3131194114685059, 1.2984027862548828, 1.2928268909454346, 1.2882992029190063, 1.2860405445098877, 1.2785006761550903, 1.2712987661361694, 1.264957070350647, 1.260024070739746, 1.2552272081375122, 1.2494728565216064, 1.2445234060287476, 1.2395522594451904, 1.2381154298782349, 1.2294050455093384, 1.2269548177719116, 1.2200881242752075, 1.2162439823150635, 1.2165007591247559, 1.2076280117034912, 1.2301380634307861, 1.1973613500595093, 1.2018334865570068, 1.189630150794983, 1.186543583869934, 1.1819803714752197, 1.2059149742126465, 1.1740702390670776, 1.1718909740447998, 1.175700306892395, 1.1795073747634888, 1.166658878326416, 1.1716430187225342, 1.157921552658081, 1.1494704484939575, 1.1577476263046265, 1.1547856330871582, 1.143517255783081, 1.1419156789779663, 1.134629726409912, 1.137031078338623, 1.1305060386657715, 1.1284599304199219, 1.128998041152954, 1.1242048740386963, 1.126523494720459, 1.1244173049926758, 1.1196849346160889, 1.1290605068206787, 1.1134352684020996], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.4954751133918762, 0.4977375566959381, 0.4954751133918762, 0.49660632014274597, 0.4977375566959381, 0.5, 0.4977375566959381, 0.49886876344680786, 0.5, 0.5033936500549316, 0.49886876344680786, 0.5011312365531921, 0.5, 0.5045248866081238, 0.5022624731063843, 0.5022624731063843, 0.5090497732162476, 0.5113122463226318, 0.5022624731063843, 0.5180995464324951, 0.5090497732162476, 0.5452488660812378, 0.5, 0.5135746598243713, 0.5260180830955505, 0.529411792755127, 0.5090497732162476, 0.5339366793632507, 0.5203620195388794, 0.5158371329307556, 0.5226244330406189, 0.5260180830955505, 0.5384615659713745, 0.5305429697036743, 0.5339366793632507, 0.5452488660812378, 0.5090497732162476, 0.5384615659713745, 0.540723979473114, 0.5441176295280457, 0.5452488660812378, 0.5531674027442932, 0.5441176295280457, 0.5452488660812378, 0.5429864525794983, 0.5497737526893616, 0.5418552160263062, 0.5429864525794983, 0.5531674027442932, 0.557692289352417, 0.5486425161361694, 0.5520362257957458, 0.5531674027442932, 0.557692289352417, 0.5610859990119934, 0.5667420625686646, 0.5565611124038696, 0.5418552160263062, 0.5656108856201172, 0.5803167223930359, 0.5723981857299805, 0.5780543088912964, 0.5282805562019348, 0.5735294222831726, 0.5486425161361694, 0.5712669491767883, 0.5893664956092834, 0.5791855454444885, 0.5463801026344299, 0.587104082107544, 0.5938913822174072, 0.5509049892425537, 0.5452488660812378, 0.5599547624588013, 0.5531674027442932, 0.5735294222831726, 0.5927602052688599, 0.564479649066925, 0.5667420625686646, 0.5972850918769836, 0.598416268825531, 0.6052036285400391, 0.5791855454444885, 0.6074660420417786, 0.5995475053787231, 0.5995475053787231, 0.598416268825531, 0.5837104320526123, 0.5837104320526123, 0.6085972785949707, 0.5769230723381042, 0.5972850918769836]}\n","45/45 [==============================] - 1s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 1.6998 - accuracy: 0.4982"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 8s 70ms/step - loss: 1.6998 - accuracy: 0.4982 - val_loss: 1.6941 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.6889 - accuracy: 0.5114 - val_loss: 1.6833 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.6782 - accuracy: 0.5008 - val_loss: 1.6726 - val_accuracy: 0.4928\n","Epoch 4/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.6675 - accuracy: 0.4974 - val_loss: 1.6620 - val_accuracy: 0.4897\n","Epoch 5/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.6569 - accuracy: 0.4959 - val_loss: 1.6516 - val_accuracy: 0.4886\n","Epoch 6/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.6465 - accuracy: 0.5088 - val_loss: 1.6412 - val_accuracy: 0.4876\n","Epoch 7/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.6361 - accuracy: 0.5119 - val_loss: 1.6310 - val_accuracy: 0.4876\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.6258 - accuracy: 0.5364 - val_loss: 1.6209 - val_accuracy: 0.4886\n","Epoch 9/100\n","31/31 [==============================] - 1s 46ms/step - loss: 1.6156 - accuracy: 0.5370 - val_loss: 1.6109 - val_accuracy: 0.4876\n","Epoch 10/100\n","31/31 [==============================] - 1s 35ms/step - loss: 1.6055 - accuracy: 0.5403 - val_loss: 1.6011 - val_accuracy: 0.4886\n","Epoch 11/100\n","31/31 [==============================] - 1s 41ms/step - loss: 1.5956 - accuracy: 0.5199 - val_loss: 1.5912 - val_accuracy: 0.4959\n","Epoch 12/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.5857 - accuracy: 0.5377 - val_loss: 1.5817 - val_accuracy: 0.4886\n","Epoch 13/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.5759 - accuracy: 0.5351 - val_loss: 1.5721 - val_accuracy: 0.4979\n","Epoch 14/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.5662 - accuracy: 0.5416 - val_loss: 1.5626 - val_accuracy: 0.5000\n","Epoch 15/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.5565 - accuracy: 0.5424 - val_loss: 1.5534 - val_accuracy: 0.4969\n","Epoch 16/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.5469 - accuracy: 0.5395 - val_loss: 1.5440 - val_accuracy: 0.4969\n","Epoch 17/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5370 - accuracy: 0.5566 - val_loss: 1.5350 - val_accuracy: 0.4948\n","Epoch 18/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.5277 - accuracy: 0.5429 - val_loss: 1.5259 - val_accuracy: 0.5083\n","Epoch 19/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.5184 - accuracy: 0.5452 - val_loss: 1.5171 - val_accuracy: 0.5062\n","Epoch 20/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.5090 - accuracy: 0.5364 - val_loss: 1.5084 - val_accuracy: 0.5021\n","Epoch 21/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.4998 - accuracy: 0.5447 - val_loss: 1.4990 - val_accuracy: 0.5103\n","Epoch 22/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.4908 - accuracy: 0.5483 - val_loss: 1.4915 - val_accuracy: 0.5103\n","Epoch 23/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.4817 - accuracy: 0.5380 - val_loss: 1.4830 - val_accuracy: 0.5145\n","Epoch 24/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.4723 - accuracy: 0.5525 - val_loss: 1.4742 - val_accuracy: 0.4917\n","Epoch 25/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4628 - accuracy: 0.5566 - val_loss: 1.4666 - val_accuracy: 0.5083\n","Epoch 26/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.4559 - accuracy: 0.5473 - val_loss: 1.4586 - val_accuracy: 0.5072\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.4464 - accuracy: 0.5612 - val_loss: 1.4513 - val_accuracy: 0.5031\n","Epoch 28/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.4383 - accuracy: 0.5589 - val_loss: 1.4443 - val_accuracy: 0.5093\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4298 - accuracy: 0.5584 - val_loss: 1.4374 - val_accuracy: 0.5093\n","Epoch 30/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.4218 - accuracy: 0.5605 - val_loss: 1.4304 - val_accuracy: 0.5103\n","Epoch 31/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.4134 - accuracy: 0.5628 - val_loss: 1.4227 - val_accuracy: 0.5052\n","Epoch 32/100\n","31/31 [==============================] - 1s 30ms/step - loss: 1.4056 - accuracy: 0.5623 - val_loss: 1.4193 - val_accuracy: 0.5227\n","Epoch 33/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.3995 - accuracy: 0.5563 - val_loss: 1.4110 - val_accuracy: 0.5176\n","Epoch 34/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.3907 - accuracy: 0.5674 - val_loss: 1.4013 - val_accuracy: 0.5052\n","Epoch 35/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3837 - accuracy: 0.5607 - val_loss: 1.3946 - val_accuracy: 0.5103\n","Epoch 36/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3747 - accuracy: 0.5677 - val_loss: 1.3879 - val_accuracy: 0.5103\n","Epoch 37/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3676 - accuracy: 0.5780 - val_loss: 1.3819 - val_accuracy: 0.5196\n","Epoch 38/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3592 - accuracy: 0.5786 - val_loss: 1.3750 - val_accuracy: 0.5186\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3525 - accuracy: 0.5713 - val_loss: 1.3689 - val_accuracy: 0.5176\n","Epoch 40/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3457 - accuracy: 0.5767 - val_loss: 1.3625 - val_accuracy: 0.5155\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3396 - accuracy: 0.5705 - val_loss: 1.3561 - val_accuracy: 0.5196\n","Epoch 42/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.3309 - accuracy: 0.5809 - val_loss: 1.3550 - val_accuracy: 0.5393\n","Epoch 43/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.3250 - accuracy: 0.5762 - val_loss: 1.3446 - val_accuracy: 0.5331\n","Epoch 44/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3181 - accuracy: 0.5767 - val_loss: 1.3376 - val_accuracy: 0.5196\n","Epoch 45/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3097 - accuracy: 0.5783 - val_loss: 1.3321 - val_accuracy: 0.5227\n","Epoch 46/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.3040 - accuracy: 0.5832 - val_loss: 1.3289 - val_accuracy: 0.5403\n","Epoch 47/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3024 - accuracy: 0.5724 - val_loss: 1.3286 - val_accuracy: 0.5372\n","Epoch 48/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2991 - accuracy: 0.5620 - val_loss: 1.3127 - val_accuracy: 0.5351\n","Epoch 49/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2856 - accuracy: 0.5848 - val_loss: 1.3075 - val_accuracy: 0.5186\n","Epoch 50/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2779 - accuracy: 0.5894 - val_loss: 1.3013 - val_accuracy: 0.5269\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2714 - accuracy: 0.5842 - val_loss: 1.2966 - val_accuracy: 0.5207\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2649 - accuracy: 0.5928 - val_loss: 1.2918 - val_accuracy: 0.5186\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2581 - accuracy: 0.5946 - val_loss: 1.2857 - val_accuracy: 0.5238\n","Epoch 54/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2518 - accuracy: 0.5915 - val_loss: 1.2851 - val_accuracy: 0.5341\n","Epoch 55/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.2433 - accuracy: 0.5987 - val_loss: 1.2774 - val_accuracy: 0.5362\n","Epoch 56/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2381 - accuracy: 0.5964 - val_loss: 1.2713 - val_accuracy: 0.5258\n","Epoch 57/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2317 - accuracy: 0.6010 - val_loss: 1.2671 - val_accuracy: 0.5207\n","Epoch 58/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.2247 - accuracy: 0.5959 - val_loss: 1.2609 - val_accuracy: 0.5310\n","Epoch 59/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2181 - accuracy: 0.6044 - val_loss: 1.2588 - val_accuracy: 0.5320\n","Epoch 60/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2121 - accuracy: 0.6031 - val_loss: 1.2512 - val_accuracy: 0.5372\n","Epoch 61/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2073 - accuracy: 0.6070 - val_loss: 1.2463 - val_accuracy: 0.5382\n","Epoch 62/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2071 - accuracy: 0.6018 - val_loss: 1.2417 - val_accuracy: 0.5362\n","Epoch 63/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1928 - accuracy: 0.6163 - val_loss: 1.2361 - val_accuracy: 0.5362\n","Epoch 64/100\n","31/31 [==============================] - 1s 48ms/step - loss: 1.1870 - accuracy: 0.6173 - val_loss: 1.2364 - val_accuracy: 0.5444\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1831 - accuracy: 0.6189 - val_loss: 1.2283 - val_accuracy: 0.5320\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1743 - accuracy: 0.6199 - val_loss: 1.2241 - val_accuracy: 0.5393\n","Epoch 67/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1702 - accuracy: 0.6160 - val_loss: 1.2198 - val_accuracy: 0.5362\n","Epoch 68/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1587 - accuracy: 0.6181 - val_loss: 1.2190 - val_accuracy: 0.5393\n","Epoch 69/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1553 - accuracy: 0.6230 - val_loss: 1.2165 - val_accuracy: 0.5341\n","Epoch 70/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1471 - accuracy: 0.6377 - val_loss: 1.2110 - val_accuracy: 0.5403\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1389 - accuracy: 0.6364 - val_loss: 1.2145 - val_accuracy: 0.5279\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1436 - accuracy: 0.6098 - val_loss: 1.2053 - val_accuracy: 0.5362\n","Epoch 73/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1323 - accuracy: 0.6279 - val_loss: 1.2039 - val_accuracy: 0.5331\n","Epoch 74/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.1245 - accuracy: 0.6287 - val_loss: 1.1952 - val_accuracy: 0.5496\n","Epoch 75/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.1139 - accuracy: 0.6382 - val_loss: 1.1940 - val_accuracy: 0.5506\n","Epoch 76/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.1124 - accuracy: 0.6266 - val_loss: 1.1976 - val_accuracy: 0.5372\n","Epoch 77/100\n","31/31 [==============================] - 1s 29ms/step - loss: 1.1023 - accuracy: 0.6413 - val_loss: 1.1883 - val_accuracy: 0.5558\n","Epoch 78/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0965 - accuracy: 0.6486 - val_loss: 1.1856 - val_accuracy: 0.5506\n","Epoch 79/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0874 - accuracy: 0.6478 - val_loss: 1.1854 - val_accuracy: 0.5496\n","Epoch 80/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0903 - accuracy: 0.6388 - val_loss: 1.1877 - val_accuracy: 0.5413\n","Epoch 81/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0789 - accuracy: 0.6455 - val_loss: 1.1829 - val_accuracy: 0.5331\n","Epoch 82/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0753 - accuracy: 0.6517 - val_loss: 1.1789 - val_accuracy: 0.5537\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0665 - accuracy: 0.6607 - val_loss: 1.1786 - val_accuracy: 0.5527\n","Epoch 84/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0640 - accuracy: 0.6571 - val_loss: 1.1716 - val_accuracy: 0.5455\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0587 - accuracy: 0.6460 - val_loss: 1.2123 - val_accuracy: 0.5124\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0584 - accuracy: 0.6561 - val_loss: 1.1659 - val_accuracy: 0.5548\n","Epoch 87/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0477 - accuracy: 0.6571 - val_loss: 1.1591 - val_accuracy: 0.5465\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0390 - accuracy: 0.6571 - val_loss: 1.1595 - val_accuracy: 0.5527\n","Epoch 89/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0297 - accuracy: 0.6736 - val_loss: 1.1589 - val_accuracy: 0.5475\n","Epoch 90/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0313 - accuracy: 0.6610 - val_loss: 1.1554 - val_accuracy: 0.5579\n","Epoch 91/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.0179 - accuracy: 0.6726 - val_loss: 1.1575 - val_accuracy: 0.5640\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0163 - accuracy: 0.6760 - val_loss: 1.1542 - val_accuracy: 0.5465\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0091 - accuracy: 0.6780 - val_loss: 1.1525 - val_accuracy: 0.5496\n","Epoch 94/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0036 - accuracy: 0.6822 - val_loss: 1.1773 - val_accuracy: 0.5362\n","Epoch 95/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0057 - accuracy: 0.6705 - val_loss: 1.1642 - val_accuracy: 0.5527\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9947 - accuracy: 0.6806 - val_loss: 1.1583 - val_accuracy: 0.5558\n","Epoch 97/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9974 - accuracy: 0.6669 - val_loss: 1.1447 - val_accuracy: 0.5589\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9926 - accuracy: 0.6778 - val_loss: 1.1565 - val_accuracy: 0.5444\n","Epoch 99/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9800 - accuracy: 0.6925 - val_loss: 1.1360 - val_accuracy: 0.5444\n","Epoch 100/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9708 - accuracy: 0.6915 - val_loss: 1.1423 - val_accuracy: 0.5620\n","{'loss': [1.6998354196548462, 1.688940167427063, 1.678154706954956, 1.6674795150756836, 1.6569321155548096, 1.6464942693710327, 1.636096477508545, 1.6258293390274048, 1.6155725717544556, 1.6055467128753662, 1.5955854654312134, 1.5856863260269165, 1.5759046077728271, 1.566150426864624, 1.5565359592437744, 1.5468555688858032, 1.537042498588562, 1.5277438163757324, 1.5183589458465576, 1.50904381275177, 1.4997788667678833, 1.4907678365707397, 1.4816612005233765, 1.4722535610198975, 1.4627516269683838, 1.4559098482131958, 1.4464137554168701, 1.4382928609848022, 1.4298169612884521, 1.4217954874038696, 1.4134165048599243, 1.4056426286697388, 1.399513840675354, 1.3907477855682373, 1.3837445974349976, 1.3746826648712158, 1.3675693273544312, 1.3592089414596558, 1.3525258302688599, 1.3456535339355469, 1.3396170139312744, 1.3308759927749634, 1.3250476121902466, 1.3181211948394775, 1.3097232580184937, 1.3039700984954834, 1.302433729171753, 1.2991067171096802, 1.285644292831421, 1.277913212776184, 1.2713741064071655, 1.264882206916809, 1.258054256439209, 1.251763939857483, 1.2432695627212524, 1.2381256818771362, 1.2316714525222778, 1.2247363328933716, 1.2180994749069214, 1.2121104001998901, 1.207319974899292, 1.2071373462677002, 1.1928240060806274, 1.1869553327560425, 1.183146357536316, 1.174282431602478, 1.1702477931976318, 1.1587018966674805, 1.1553171873092651, 1.1471456289291382, 1.1389223337173462, 1.1435651779174805, 1.1323407888412476, 1.1245094537734985, 1.1139464378356934, 1.112436294555664, 1.1022785902023315, 1.0965172052383423, 1.0874125957489014, 1.0902621746063232, 1.0788698196411133, 1.0753414630889893, 1.066498875617981, 1.0639686584472656, 1.0587081909179688, 1.058436393737793, 1.0477018356323242, 1.0390141010284424, 1.0297094583511353, 1.031267762184143, 1.0179245471954346, 1.016274333000183, 1.0090923309326172, 1.0035576820373535, 1.0057021379470825, 0.9947317838668823, 0.9973663091659546, 0.9926053285598755, 0.9800146818161011, 0.9707639813423157], 'accuracy': [0.4981912076473236, 0.511369526386261, 0.5007752180099487, 0.49741601943969727, 0.4958656430244446, 0.5087855458259583, 0.5118862986564636, 0.5364341139793396, 0.5369508862495422, 0.5403100848197937, 0.5198966264724731, 0.537726104259491, 0.5351421236991882, 0.5416020750999451, 0.542377233505249, 0.539534866809845, 0.5565891265869141, 0.5428940653800964, 0.5452196598052979, 0.5364341139793396, 0.5447028279304504, 0.5483204126358032, 0.5379844903945923, 0.5524547696113586, 0.5565891265869141, 0.5472868084907532, 0.5612403154373169, 0.5589147210121155, 0.5583979487419128, 0.5604650974273682, 0.5627906918525696, 0.5622739195823669, 0.5563307404518127, 0.5674418807029724, 0.5607235431671143, 0.5677002668380737, 0.5780361890792847, 0.5785529613494873, 0.5713178515434265, 0.5767441987991333, 0.5705426335334778, 0.5808785557746887, 0.5762273669242859, 0.5767441987991333, 0.578294575214386, 0.5832041501998901, 0.5723513960838318, 0.5620155334472656, 0.5847545266151428, 0.5894056558609009, 0.5842377543449402, 0.5927648544311523, 0.5945736169815063, 0.591472864151001, 0.5987080335617065, 0.5963824391365051, 0.6010335683822632, 0.5958656072616577, 0.6043927669525146, 0.6031007766723633, 0.6069767475128174, 0.6018087863922119, 0.6162790656089783, 0.6173126697540283, 0.618863046169281, 0.619896650314331, 0.616020679473877, 0.6180878281593323, 0.6229974031448364, 0.6377260684967041, 0.6364341378211975, 0.6098191142082214, 0.6279069781303406, 0.6286821961402893, 0.6382429003715515, 0.6266149878501892, 0.6413436532020569, 0.6485788226127625, 0.6478036046028137, 0.6387596726417542, 0.6454780101776123, 0.6516795754432678, 0.6607235074043274, 0.6571059226989746, 0.6459948420524597, 0.6560723781585693, 0.6571059226989746, 0.6571059226989746, 0.6736434102058411, 0.6609818935394287, 0.672609806060791, 0.6759690046310425, 0.6780361533164978, 0.682170569896698, 0.6705426573753357, 0.6806201338768005, 0.6669250726699829, 0.6777777671813965, 0.6925064325332642, 0.6914728879928589], 'val_loss': [1.6940953731536865, 1.6832963228225708, 1.6725963354110718, 1.662027359008789, 1.6515636444091797, 1.6412376165390015, 1.6310216188430786, 1.6209214925765991, 1.6109243631362915, 1.6010512113571167, 1.5912495851516724, 1.581672191619873, 1.5720769166946411, 1.562645435333252, 1.5533583164215088, 1.5440495014190674, 1.535042643547058, 1.5258506536483765, 1.5170515775680542, 1.5084308385849, 1.4990261793136597, 1.4914981126785278, 1.4830169677734375, 1.4742414951324463, 1.4666355848312378, 1.4586282968521118, 1.451332449913025, 1.4442968368530273, 1.4373588562011719, 1.4303667545318604, 1.4227163791656494, 1.4193286895751953, 1.4109662771224976, 1.4012651443481445, 1.3946202993392944, 1.3878650665283203, 1.381927251815796, 1.3750114440917969, 1.3688751459121704, 1.362541675567627, 1.356054425239563, 1.3549549579620361, 1.344616413116455, 1.3375519514083862, 1.3320966958999634, 1.3289270401000977, 1.3285690546035767, 1.312748908996582, 1.307503581047058, 1.3012971878051758, 1.2965952157974243, 1.2918444871902466, 1.2857252359390259, 1.2850841283798218, 1.277384638786316, 1.2712703943252563, 1.2670913934707642, 1.2608546018600464, 1.2587699890136719, 1.2512093782424927, 1.2462667226791382, 1.2417371273040771, 1.236142873764038, 1.2364383935928345, 1.2282803058624268, 1.2241277694702148, 1.2197617292404175, 1.2190498113632202, 1.2165206670761108, 1.211006760597229, 1.2145086526870728, 1.205340027809143, 1.2038559913635254, 1.1952028274536133, 1.1940099000930786, 1.1975908279418945, 1.1883373260498047, 1.1856251955032349, 1.1853854656219482, 1.1876996755599976, 1.1829078197479248, 1.1789355278015137, 1.178564429283142, 1.1715997457504272, 1.212275505065918, 1.1659438610076904, 1.1590834856033325, 1.159528374671936, 1.1589466333389282, 1.155421257019043, 1.1574631929397583, 1.1541697978973389, 1.1525098085403442, 1.1772712469100952, 1.164160132408142, 1.1583476066589355, 1.1446975469589233, 1.156545877456665, 1.136006236076355, 1.14234459400177], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.4927685856819153, 0.48966941237449646, 0.4886363744735718, 0.4876033067703247, 0.4876033067703247, 0.4886363744735718, 0.4876033067703247, 0.4886363744735718, 0.4958677589893341, 0.4886363744735718, 0.49793389439582825, 0.5, 0.4969008266925812, 0.4969008266925812, 0.4948347210884094, 0.5082644820213318, 0.5061983466148376, 0.5020661354064941, 0.5103305578231812, 0.5103305578231812, 0.5144628286361694, 0.4917355477809906, 0.5082644820213318, 0.5072314143180847, 0.5030992031097412, 0.5092975497245789, 0.5092975497245789, 0.5103305578231812, 0.5051652789115906, 0.5227272510528564, 0.5175619721412659, 0.5051652789115906, 0.5103305578231812, 0.5103305578231812, 0.51962810754776, 0.5185950398445129, 0.5175619721412659, 0.5154958963394165, 0.51962810754776, 0.53925621509552, 0.5330578684806824, 0.51962810754776, 0.5227272510528564, 0.5402892827987671, 0.5371900796890259, 0.5351239442825317, 0.5185950398445129, 0.5268595218658447, 0.5206611752510071, 0.5185950398445129, 0.5237603187561035, 0.5340909361839294, 0.5361570119857788, 0.5258264541625977, 0.5206611752510071, 0.5309917330741882, 0.5320248007774353, 0.5371900796890259, 0.538223147392273, 0.5361570119857788, 0.5361570119857788, 0.5444214940071106, 0.5320248007774353, 0.53925621509552, 0.5361570119857788, 0.53925621509552, 0.5340909361839294, 0.5402892827987671, 0.5278925895690918, 0.5361570119857788, 0.5330578684806824, 0.5495867729187012, 0.5506198406219482, 0.5371900796890259, 0.5557851195335388, 0.5506198406219482, 0.5495867729187012, 0.5413222908973694, 0.5330578684806824, 0.5537189841270447, 0.5526859760284424, 0.5454545617103577, 0.5123966932296753, 0.5547520518302917, 0.5464876294136047, 0.5526859760284424, 0.547520637512207, 0.557851254940033, 0.5640496015548706, 0.5464876294136047, 0.5495867729187012, 0.5361570119857788, 0.5526859760284424, 0.5557851195335388, 0.55888432264328, 0.5444214940071106, 0.5444214940071106, 0.5619834661483765]}\n","32/32 [==============================] - 1s 10ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 1.0595 - accuracy: 0.6290"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 59ms/step - loss: 1.0595 - accuracy: 0.6290 - val_loss: 1.0980 - val_accuracy: 0.5172\n","Epoch 2/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.0507 - accuracy: 0.6325 - val_loss: 1.0943 - val_accuracy: 0.5205\n","Epoch 3/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.0446 - accuracy: 0.6347 - val_loss: 1.0906 - val_accuracy: 0.5237\n","Epoch 4/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0351 - accuracy: 0.6428 - val_loss: 1.0869 - val_accuracy: 0.5194\n","Epoch 5/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.0246 - accuracy: 0.6522 - val_loss: 1.0833 - val_accuracy: 0.5280\n","Epoch 6/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0205 - accuracy: 0.6511 - val_loss: 1.0797 - val_accuracy: 0.5259\n","Epoch 7/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.0119 - accuracy: 0.6503 - val_loss: 1.0760 - val_accuracy: 0.5334\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0082 - accuracy: 0.6603 - val_loss: 1.0724 - val_accuracy: 0.5334\n","Epoch 9/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.9952 - accuracy: 0.6654 - val_loss: 1.0686 - val_accuracy: 0.5356\n","Epoch 10/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.9949 - accuracy: 0.6546 - val_loss: 1.0647 - val_accuracy: 0.5420\n","Epoch 11/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9844 - accuracy: 0.6619 - val_loss: 1.0609 - val_accuracy: 0.5420\n","Epoch 12/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9851 - accuracy: 0.6684 - val_loss: 1.0568 - val_accuracy: 0.5409\n","Epoch 13/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.9828 - accuracy: 0.6600 - val_loss: 1.0523 - val_accuracy: 0.5765\n","Epoch 14/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.9781 - accuracy: 0.6681 - val_loss: 1.0478 - val_accuracy: 0.5808\n","Epoch 15/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.9651 - accuracy: 0.6721 - val_loss: 1.0430 - val_accuracy: 0.5873\n","Epoch 16/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9560 - accuracy: 0.6786 - val_loss: 1.0376 - val_accuracy: 0.5884\n","Epoch 17/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9558 - accuracy: 0.6716 - val_loss: 1.0319 - val_accuracy: 0.6045\n","Epoch 18/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.9516 - accuracy: 0.6797 - val_loss: 1.0260 - val_accuracy: 0.6088\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9421 - accuracy: 0.6843 - val_loss: 1.0194 - val_accuracy: 0.6078\n","Epoch 20/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9442 - accuracy: 0.6810 - val_loss: 1.0170 - val_accuracy: 0.5959\n","Epoch 21/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9383 - accuracy: 0.6797 - val_loss: 1.0079 - val_accuracy: 0.6142\n","Epoch 22/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.9294 - accuracy: 0.6848 - val_loss: 1.0017 - val_accuracy: 0.6207\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9331 - accuracy: 0.6859 - val_loss: 0.9977 - val_accuracy: 0.6088\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9245 - accuracy: 0.6835 - val_loss: 0.9987 - val_accuracy: 0.6024\n","Epoch 25/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9171 - accuracy: 0.6948 - val_loss: 0.9902 - val_accuracy: 0.6121\n","Epoch 26/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9148 - accuracy: 0.6937 - val_loss: 0.9909 - val_accuracy: 0.6088\n","Epoch 27/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9103 - accuracy: 0.6996 - val_loss: 0.9915 - val_accuracy: 0.6088\n","Epoch 28/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9039 - accuracy: 0.6910 - val_loss: 0.9849 - val_accuracy: 0.6131\n","Epoch 29/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9056 - accuracy: 0.6905 - val_loss: 0.9840 - val_accuracy: 0.6131\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8914 - accuracy: 0.7018 - val_loss: 0.9823 - val_accuracy: 0.6207\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8950 - accuracy: 0.7004 - val_loss: 1.0010 - val_accuracy: 0.5991\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8932 - accuracy: 0.7055 - val_loss: 0.9836 - val_accuracy: 0.6067\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8826 - accuracy: 0.7029 - val_loss: 0.9825 - val_accuracy: 0.6078\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8885 - accuracy: 0.6988 - val_loss: 0.9811 - val_accuracy: 0.6002\n","Epoch 35/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8752 - accuracy: 0.7134 - val_loss: 1.0295 - val_accuracy: 0.6024\n","Epoch 36/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.8699 - accuracy: 0.7123 - val_loss: 0.9832 - val_accuracy: 0.6056\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8688 - accuracy: 0.7126 - val_loss: 0.9785 - val_accuracy: 0.6121\n","Epoch 38/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8639 - accuracy: 0.7055 - val_loss: 0.9899 - val_accuracy: 0.6131\n","Epoch 39/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8575 - accuracy: 0.7185 - val_loss: 0.9991 - val_accuracy: 0.6013\n","Epoch 40/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8692 - accuracy: 0.7099 - val_loss: 0.9750 - val_accuracy: 0.6110\n","Epoch 41/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8588 - accuracy: 0.7069 - val_loss: 0.9990 - val_accuracy: 0.6013\n","Epoch 42/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8504 - accuracy: 0.7290 - val_loss: 0.9899 - val_accuracy: 0.6099\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8401 - accuracy: 0.7263 - val_loss: 0.9683 - val_accuracy: 0.6142\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8385 - accuracy: 0.7279 - val_loss: 1.0173 - val_accuracy: 0.5927\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8323 - accuracy: 0.7276 - val_loss: 0.9908 - val_accuracy: 0.6067\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8293 - accuracy: 0.7279 - val_loss: 0.9701 - val_accuracy: 0.6121\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8338 - accuracy: 0.7201 - val_loss: 0.9676 - val_accuracy: 0.6153\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8210 - accuracy: 0.7390 - val_loss: 0.9668 - val_accuracy: 0.6175\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8277 - accuracy: 0.7252 - val_loss: 0.9926 - val_accuracy: 0.6013\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8109 - accuracy: 0.7398 - val_loss: 1.0018 - val_accuracy: 0.5991\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8114 - accuracy: 0.7330 - val_loss: 0.9646 - val_accuracy: 0.6164\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8166 - accuracy: 0.7392 - val_loss: 0.9682 - val_accuracy: 0.6099\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7992 - accuracy: 0.7465 - val_loss: 0.9686 - val_accuracy: 0.6131\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7990 - accuracy: 0.7454 - val_loss: 0.9785 - val_accuracy: 0.6121\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7931 - accuracy: 0.7416 - val_loss: 0.9671 - val_accuracy: 0.6185\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7872 - accuracy: 0.7548 - val_loss: 0.9694 - val_accuracy: 0.6131\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7884 - accuracy: 0.7446 - val_loss: 1.0083 - val_accuracy: 0.5916\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7861 - accuracy: 0.7454 - val_loss: 0.9842 - val_accuracy: 0.6121\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7773 - accuracy: 0.7505 - val_loss: 0.9989 - val_accuracy: 0.6002\n","Epoch 60/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7826 - accuracy: 0.7403 - val_loss: 0.9646 - val_accuracy: 0.6175\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7867 - accuracy: 0.7392 - val_loss: 0.9607 - val_accuracy: 0.6153\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7735 - accuracy: 0.7562 - val_loss: 1.0258 - val_accuracy: 0.5851\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7714 - accuracy: 0.7524 - val_loss: 0.9627 - val_accuracy: 0.6099\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7682 - accuracy: 0.7495 - val_loss: 0.9713 - val_accuracy: 0.6056\n","Epoch 65/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7673 - accuracy: 0.7470 - val_loss: 0.9761 - val_accuracy: 0.6131\n","Epoch 66/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7644 - accuracy: 0.7505 - val_loss: 1.0579 - val_accuracy: 0.5873\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7713 - accuracy: 0.7489 - val_loss: 0.9611 - val_accuracy: 0.6153\n","Epoch 68/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7488 - accuracy: 0.7645 - val_loss: 0.9612 - val_accuracy: 0.6142\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7567 - accuracy: 0.7581 - val_loss: 1.0061 - val_accuracy: 0.5916\n","Epoch 70/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7423 - accuracy: 0.7654 - val_loss: 0.9723 - val_accuracy: 0.6185\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7337 - accuracy: 0.7729 - val_loss: 1.0055 - val_accuracy: 0.5991\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7309 - accuracy: 0.7721 - val_loss: 1.0284 - val_accuracy: 0.5916\n","Epoch 73/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7360 - accuracy: 0.7686 - val_loss: 0.9867 - val_accuracy: 0.6110\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7404 - accuracy: 0.7637 - val_loss: 0.9833 - val_accuracy: 0.6185\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7197 - accuracy: 0.7729 - val_loss: 0.9631 - val_accuracy: 0.6121\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7326 - accuracy: 0.7670 - val_loss: 0.9636 - val_accuracy: 0.6164\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7173 - accuracy: 0.7775 - val_loss: 1.0100 - val_accuracy: 0.6034\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7109 - accuracy: 0.7823 - val_loss: 0.9593 - val_accuracy: 0.6164\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7145 - accuracy: 0.7788 - val_loss: 0.9637 - val_accuracy: 0.6056\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7198 - accuracy: 0.7705 - val_loss: 0.9947 - val_accuracy: 0.6088\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7024 - accuracy: 0.7812 - val_loss: 0.9701 - val_accuracy: 0.6207\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6983 - accuracy: 0.7818 - val_loss: 1.0326 - val_accuracy: 0.5905\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7068 - accuracy: 0.7799 - val_loss: 1.0510 - val_accuracy: 0.5884\n","Epoch 84/100\n","29/29 [==============================] - 3s 101ms/step - loss: 0.7087 - accuracy: 0.7721 - val_loss: 0.9877 - val_accuracy: 0.6218\n","Epoch 85/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6864 - accuracy: 0.7896 - val_loss: 0.9630 - val_accuracy: 0.6088\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6898 - accuracy: 0.7923 - val_loss: 0.9621 - val_accuracy: 0.6142\n","Epoch 87/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6906 - accuracy: 0.7907 - val_loss: 0.9696 - val_accuracy: 0.6196\n","Epoch 88/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6869 - accuracy: 0.7901 - val_loss: 0.9648 - val_accuracy: 0.6110\n","Epoch 89/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6723 - accuracy: 0.7961 - val_loss: 0.9705 - val_accuracy: 0.6185\n","Epoch 90/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.6731 - accuracy: 0.7945 - val_loss: 0.9710 - val_accuracy: 0.6239\n","Epoch 91/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6734 - accuracy: 0.7966 - val_loss: 1.0422 - val_accuracy: 0.5959\n","Epoch 92/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6784 - accuracy: 0.7839 - val_loss: 0.9902 - val_accuracy: 0.6196\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6618 - accuracy: 0.8052 - val_loss: 0.9753 - val_accuracy: 0.6228\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6603 - accuracy: 0.8025 - val_loss: 0.9929 - val_accuracy: 0.6228\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6571 - accuracy: 0.8009 - val_loss: 1.0376 - val_accuracy: 0.6142\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6510 - accuracy: 0.8017 - val_loss: 0.9883 - val_accuracy: 0.6153\n","Epoch 97/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6484 - accuracy: 0.8090 - val_loss: 0.9881 - val_accuracy: 0.6207\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6446 - accuracy: 0.8050 - val_loss: 0.9911 - val_accuracy: 0.6175\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6391 - accuracy: 0.8117 - val_loss: 0.9974 - val_accuracy: 0.6142\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6395 - accuracy: 0.8138 - val_loss: 0.9954 - val_accuracy: 0.6110\n","{'loss': [1.0595495700836182, 1.0506515502929688, 1.0445904731750488, 1.0350724458694458, 1.0246317386627197, 1.0204623937606812, 1.011895775794983, 1.008212685585022, 0.9952087998390198, 0.9949479699134827, 0.9843520522117615, 0.9851108193397522, 0.9827593564987183, 0.9781447649002075, 0.9651279449462891, 0.9560108780860901, 0.9558362364768982, 0.9516451358795166, 0.9421199560165405, 0.9442048668861389, 0.9382815361022949, 0.9293766617774963, 0.9330834150314331, 0.9244922399520874, 0.9171141982078552, 0.914790689945221, 0.9102959036827087, 0.9039452075958252, 0.9055506587028503, 0.8913971185684204, 0.8949528932571411, 0.8932375311851501, 0.8826410174369812, 0.8884684443473816, 0.8751926422119141, 0.8698808550834656, 0.8687565922737122, 0.8638986945152283, 0.8575252890586853, 0.8691518306732178, 0.8587631583213806, 0.8504188656806946, 0.8401200771331787, 0.8384513854980469, 0.8322882652282715, 0.8292971253395081, 0.8338201642036438, 0.8209643363952637, 0.8276559114456177, 0.8109011054039001, 0.8114331364631653, 0.8166366219520569, 0.7992168664932251, 0.7989783883094788, 0.7931331992149353, 0.787150502204895, 0.7884377837181091, 0.7861309051513672, 0.7773045301437378, 0.7825512290000916, 0.7866781949996948, 0.773502767086029, 0.771363377571106, 0.7682111859321594, 0.76731276512146, 0.7644292712211609, 0.7713386416435242, 0.7488119006156921, 0.7567196488380432, 0.7422863245010376, 0.7336722612380981, 0.7309430837631226, 0.7360422611236572, 0.7404392957687378, 0.7196661829948425, 0.7326420545578003, 0.7172567844390869, 0.7108940482139587, 0.714469313621521, 0.7198002338409424, 0.70235675573349, 0.6983104348182678, 0.7068406939506531, 0.7086726427078247, 0.6864150762557983, 0.6898170709609985, 0.6905573010444641, 0.6868518590927124, 0.6722604036331177, 0.6731458902359009, 0.6734390258789062, 0.6784056425094604, 0.6618489027023315, 0.6603116393089294, 0.6571374535560608, 0.6510123610496521, 0.6484226584434509, 0.6446009874343872, 0.6391321420669556, 0.6395225524902344], 'accuracy': [0.6290409564971924, 0.6325430870056152, 0.6346982717514038, 0.6427801847457886, 0.6522090435028076, 0.6511314511299133, 0.6503232717514038, 0.6602909564971924, 0.665409505367279, 0.654633641242981, 0.6619073152542114, 0.6683728694915771, 0.6600215435028076, 0.6681034564971924, 0.6721444129943848, 0.6786099076271057, 0.6716055870056152, 0.6796875, 0.6842672228813171, 0.681034505367279, 0.6796875, 0.6848060488700867, 0.685883641242981, 0.6834590435028076, 0.6947737336158752, 0.693696141242981, 0.6996228694915771, 0.6910021305084229, 0.6904633641242981, 0.701777994632721, 0.7004310488700867, 0.7055495977401733, 0.7028555870056152, 0.6988146305084229, 0.7133620977401733, 0.712284505367279, 0.712553858757019, 0.7055495977401733, 0.7184805870056152, 0.7098599076271057, 0.7068965435028076, 0.7289870977401733, 0.7262930870056152, 0.727909505367279, 0.7276400923728943, 0.727909505367279, 0.720097005367279, 0.7389547228813171, 0.725215494632721, 0.7397629022598267, 0.733027994632721, 0.7392241358757019, 0.7464978694915771, 0.7454202771186829, 0.7416487336158752, 0.7548491358757019, 0.7446120977401733, 0.7454202771186829, 0.7505387663841248, 0.7403017282485962, 0.7392241358757019, 0.756196141242981, 0.7524245977401733, 0.7494612336158752, 0.7470366358757019, 0.7505387663841248, 0.7489224076271057, 0.7645474076271057, 0.7580819129943848, 0.7653555870056152, 0.7728987336158752, 0.772090494632721, 0.7685883641242981, 0.7637392282485962, 0.7728987336158752, 0.766972005367279, 0.7774784564971924, 0.7823275923728943, 0.7788254022598267, 0.7704741358757019, 0.78125, 0.7817887663841248, 0.779902994632721, 0.772090494632721, 0.7896012663841248, 0.7922952771186829, 0.790678858757019, 0.7901400923728943, 0.7960668206214905, 0.7944504022598267, 0.7966055870056152, 0.7839439511299133, 0.8052262663841248, 0.8025323152542114, 0.8009159564971924, 0.8017241358757019, 0.8089978694915771, 0.8049569129943848, 0.8116918206214905, 0.813847005367279], 'val_loss': [1.0980010032653809, 1.0943217277526855, 1.090640902519226, 1.086940884590149, 1.0833346843719482, 1.0797005891799927, 1.0760374069213867, 1.0723780393600464, 1.068622350692749, 1.0647130012512207, 1.0608599185943604, 1.0567700862884521, 1.0522704124450684, 1.0478253364562988, 1.042967677116394, 1.0375908613204956, 1.0318588018417358, 1.0260218381881714, 1.0194332599639893, 1.0169649124145508, 1.0078890323638916, 1.0017194747924805, 0.9976502656936646, 0.9986671209335327, 0.990180492401123, 0.9909275770187378, 0.9915006160736084, 0.9848681092262268, 0.98399817943573, 0.9823258519172668, 1.001043438911438, 0.9836021065711975, 0.9824994206428528, 0.9811010956764221, 1.0295145511627197, 0.9832109808921814, 0.9784615635871887, 0.9898812770843506, 0.9990659356117249, 0.9750176668167114, 0.9990090131759644, 0.9899405837059021, 0.9683074355125427, 1.0172607898712158, 0.9908490180969238, 0.9701395630836487, 0.9675564765930176, 0.9667525887489319, 0.992628276348114, 1.0017503499984741, 0.9646078944206238, 0.9681582450866699, 0.968594491481781, 0.9785078763961792, 0.9671408534049988, 0.9694460034370422, 1.0083115100860596, 0.9841998815536499, 0.9988962411880493, 0.9645694494247437, 0.9607130289077759, 1.025771141052246, 0.962716817855835, 0.9713409543037415, 0.976081371307373, 1.057862401008606, 0.9611059427261353, 0.9612195491790771, 1.0061312913894653, 0.9723187685012817, 1.00546133518219, 1.028357744216919, 0.986692488193512, 0.9832994341850281, 0.9630889892578125, 0.9636234045028687, 1.0099523067474365, 0.9592660069465637, 0.9636645913124084, 0.9947134256362915, 0.9700623750686646, 1.03264582157135, 1.0509930849075317, 0.9877394437789917, 0.9629727005958557, 0.9621351361274719, 0.9695735573768616, 0.9647884368896484, 0.9704788327217102, 0.9709579944610596, 1.0421582460403442, 0.9902262091636658, 0.9753411412239075, 0.992893397808075, 1.0375640392303467, 0.9882619976997375, 0.9880519509315491, 0.9911254644393921, 0.9974170923233032, 0.9954304695129395], 'val_accuracy': [0.517241358757019, 0.5204741358757019, 0.5237069129943848, 0.5193965435028076, 0.5280172228813171, 0.5258620977401733, 0.5334051847457886, 0.5334051847457886, 0.5355603694915771, 0.5420258641242981, 0.5420258641242981, 0.5409482717514038, 0.576508641242981, 0.5808189511299133, 0.587284505367279, 0.5883620977401733, 0.6045258641242981, 0.6088362336158752, 0.607758641242981, 0.5959051847457886, 0.6142241358757019, 0.6206896305084229, 0.6088362336158752, 0.6023706793785095, 0.6120689511299133, 0.6088362336158752, 0.6088362336158752, 0.6131465435028076, 0.6131465435028076, 0.6206896305084229, 0.5991379022598267, 0.6066810488700867, 0.607758641242981, 0.600215494632721, 0.6023706793785095, 0.6056034564971924, 0.6120689511299133, 0.6131465435028076, 0.6012930870056152, 0.610991358757019, 0.6012930870056152, 0.6099137663841248, 0.6142241358757019, 0.5926724076271057, 0.6066810488700867, 0.6120689511299133, 0.6153017282485962, 0.6174569129943848, 0.6012930870056152, 0.5991379022598267, 0.6163793206214905, 0.6099137663841248, 0.6131465435028076, 0.6120689511299133, 0.618534505367279, 0.6131465435028076, 0.5915948152542114, 0.6120689511299133, 0.600215494632721, 0.6174569129943848, 0.6153017282485962, 0.5851293206214905, 0.6099137663841248, 0.6056034564971924, 0.6131465435028076, 0.587284505367279, 0.6153017282485962, 0.6142241358757019, 0.5915948152542114, 0.618534505367279, 0.5991379022598267, 0.5915948152542114, 0.610991358757019, 0.618534505367279, 0.6120689511299133, 0.6163793206214905, 0.6034482717514038, 0.6163793206214905, 0.6056034564971924, 0.6088362336158752, 0.6206896305084229, 0.5905172228813171, 0.5883620977401733, 0.6217672228813171, 0.6088362336158752, 0.6142241358757019, 0.6196120977401733, 0.610991358757019, 0.618534505367279, 0.6239224076271057, 0.5959051847457886, 0.6196120977401733, 0.6228448152542114, 0.6228448152542114, 0.6142241358757019, 0.6153017282485962, 0.6206896305084229, 0.6174569129943848, 0.6142241358757019, 0.610991358757019]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 1.0592 - accuracy: 0.6281"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 57ms/step - loss: 1.0586 - accuracy: 0.6273 - val_loss: 1.0985 - val_accuracy: 0.5328\n","Epoch 2/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0515 - accuracy: 0.6214 - val_loss: 1.0949 - val_accuracy: 0.5147\n","Epoch 3/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0454 - accuracy: 0.6273 - val_loss: 1.0914 - val_accuracy: 0.5090\n","Epoch 4/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0334 - accuracy: 0.6398 - val_loss: 1.0879 - val_accuracy: 0.5170\n","Epoch 5/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0285 - accuracy: 0.6480 - val_loss: 1.0843 - val_accuracy: 0.5170\n","Epoch 6/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0230 - accuracy: 0.6440 - val_loss: 1.0807 - val_accuracy: 0.5249\n","Epoch 7/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0169 - accuracy: 0.6553 - val_loss: 1.0772 - val_accuracy: 0.5226\n","Epoch 8/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0148 - accuracy: 0.6409 - val_loss: 1.0736 - val_accuracy: 0.5226\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0107 - accuracy: 0.6412 - val_loss: 1.0699 - val_accuracy: 0.5260\n","Epoch 10/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9991 - accuracy: 0.6520 - val_loss: 1.0660 - val_accuracy: 0.5498\n","Epoch 11/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9956 - accuracy: 0.6454 - val_loss: 1.0624 - val_accuracy: 0.5339\n","Epoch 12/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9922 - accuracy: 0.6528 - val_loss: 1.0590 - val_accuracy: 0.5249\n","Epoch 13/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.9910 - accuracy: 0.6491 - val_loss: 1.0540 - val_accuracy: 0.5622\n","Epoch 14/100\n","28/28 [==============================] - 1s 39ms/step - loss: 0.9813 - accuracy: 0.6579 - val_loss: 1.0491 - val_accuracy: 0.5962\n","Epoch 15/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9807 - accuracy: 0.6582 - val_loss: 1.0443 - val_accuracy: 0.5984\n","Epoch 16/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.9763 - accuracy: 0.6505 - val_loss: 1.0389 - val_accuracy: 0.6256\n","Epoch 17/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9653 - accuracy: 0.6551 - val_loss: 1.0333 - val_accuracy: 0.6131\n","Epoch 18/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9648 - accuracy: 0.6667 - val_loss: 1.0292 - val_accuracy: 0.5928\n","Epoch 19/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.9607 - accuracy: 0.6686 - val_loss: 1.0204 - val_accuracy: 0.6437\n","Epoch 20/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9546 - accuracy: 0.6706 - val_loss: 1.0141 - val_accuracy: 0.6324\n","Epoch 21/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9535 - accuracy: 0.6636 - val_loss: 1.0063 - val_accuracy: 0.6369\n","Epoch 22/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9389 - accuracy: 0.6819 - val_loss: 1.0022 - val_accuracy: 0.6097\n","Epoch 23/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9469 - accuracy: 0.6641 - val_loss: 0.9936 - val_accuracy: 0.6244\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9274 - accuracy: 0.6859 - val_loss: 0.9860 - val_accuracy: 0.6312\n","Epoch 25/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.9282 - accuracy: 0.6856 - val_loss: 0.9787 - val_accuracy: 0.6482\n","Epoch 26/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9211 - accuracy: 0.6927 - val_loss: 0.9747 - val_accuracy: 0.6380\n","Epoch 27/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9134 - accuracy: 0.6819 - val_loss: 0.9701 - val_accuracy: 0.6459\n","Epoch 28/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9116 - accuracy: 0.6916 - val_loss: 0.9691 - val_accuracy: 0.6403\n","Epoch 29/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9087 - accuracy: 0.6879 - val_loss: 0.9635 - val_accuracy: 0.6550\n","Epoch 30/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9028 - accuracy: 0.6952 - val_loss: 0.9640 - val_accuracy: 0.6391\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9021 - accuracy: 0.6933 - val_loss: 0.9592 - val_accuracy: 0.6482\n","Epoch 32/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8962 - accuracy: 0.6972 - val_loss: 0.9619 - val_accuracy: 0.6357\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8933 - accuracy: 0.6975 - val_loss: 0.9638 - val_accuracy: 0.6369\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8913 - accuracy: 0.6921 - val_loss: 0.9600 - val_accuracy: 0.6335\n","Epoch 35/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8851 - accuracy: 0.6944 - val_loss: 0.9553 - val_accuracy: 0.6459\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8967 - accuracy: 0.6865 - val_loss: 0.9508 - val_accuracy: 0.6516\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8807 - accuracy: 0.7029 - val_loss: 0.9574 - val_accuracy: 0.6301\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8712 - accuracy: 0.7088 - val_loss: 0.9635 - val_accuracy: 0.6188\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8752 - accuracy: 0.6989 - val_loss: 0.9496 - val_accuracy: 0.6403\n","Epoch 40/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8666 - accuracy: 0.7035 - val_loss: 0.9451 - val_accuracy: 0.6437\n","Epoch 41/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8630 - accuracy: 0.7097 - val_loss: 0.9799 - val_accuracy: 0.6029\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8617 - accuracy: 0.7094 - val_loss: 0.9444 - val_accuracy: 0.6369\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8512 - accuracy: 0.7190 - val_loss: 0.9433 - val_accuracy: 0.6425\n","Epoch 44/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8490 - accuracy: 0.7119 - val_loss: 0.9404 - val_accuracy: 0.6493\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8501 - accuracy: 0.7136 - val_loss: 0.9396 - val_accuracy: 0.6459\n","Epoch 46/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8309 - accuracy: 0.7334 - val_loss: 0.9377 - val_accuracy: 0.6471\n","Epoch 47/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.8347 - accuracy: 0.7179 - val_loss: 0.9434 - val_accuracy: 0.6380\n","Epoch 48/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8337 - accuracy: 0.7179 - val_loss: 0.9481 - val_accuracy: 0.6391\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8252 - accuracy: 0.7303 - val_loss: 0.9479 - val_accuracy: 0.6267\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8243 - accuracy: 0.7247 - val_loss: 0.9435 - val_accuracy: 0.6357\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8233 - accuracy: 0.7224 - val_loss: 0.9513 - val_accuracy: 0.6290\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8220 - accuracy: 0.7230 - val_loss: 0.9341 - val_accuracy: 0.6471\n","Epoch 53/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8059 - accuracy: 0.7400 - val_loss: 0.9335 - val_accuracy: 0.6459\n","Epoch 54/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8069 - accuracy: 0.7377 - val_loss: 0.9327 - val_accuracy: 0.6437\n","Epoch 55/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8045 - accuracy: 0.7346 - val_loss: 0.9300 - val_accuracy: 0.6493\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8069 - accuracy: 0.7244 - val_loss: 0.9711 - val_accuracy: 0.6222\n","Epoch 57/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8035 - accuracy: 0.7374 - val_loss: 0.9274 - val_accuracy: 0.6414\n","Epoch 58/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7934 - accuracy: 0.7383 - val_loss: 0.9549 - val_accuracy: 0.6312\n","Epoch 59/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7889 - accuracy: 0.7374 - val_loss: 0.9357 - val_accuracy: 0.6357\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7923 - accuracy: 0.7377 - val_loss: 0.9243 - val_accuracy: 0.6448\n","Epoch 61/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7801 - accuracy: 0.7490 - val_loss: 0.9267 - val_accuracy: 0.6471\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7767 - accuracy: 0.7445 - val_loss: 0.9353 - val_accuracy: 0.6369\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7820 - accuracy: 0.7380 - val_loss: 0.9477 - val_accuracy: 0.6290\n","Epoch 64/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7728 - accuracy: 0.7501 - val_loss: 0.9265 - val_accuracy: 0.6335\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7633 - accuracy: 0.7476 - val_loss: 0.9529 - val_accuracy: 0.6278\n","Epoch 66/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7641 - accuracy: 0.7516 - val_loss: 0.9261 - val_accuracy: 0.6425\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7628 - accuracy: 0.7516 - val_loss: 0.9764 - val_accuracy: 0.6222\n","Epoch 68/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7947 - accuracy: 0.7255 - val_loss: 0.9398 - val_accuracy: 0.6301\n","Epoch 69/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7598 - accuracy: 0.7445 - val_loss: 0.9176 - val_accuracy: 0.6357\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7474 - accuracy: 0.7643 - val_loss: 0.9372 - val_accuracy: 0.6437\n","Epoch 71/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7407 - accuracy: 0.7629 - val_loss: 0.9219 - val_accuracy: 0.6437\n","Epoch 72/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7433 - accuracy: 0.7612 - val_loss: 0.9316 - val_accuracy: 0.6391\n","Epoch 73/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7377 - accuracy: 0.7629 - val_loss: 0.9254 - val_accuracy: 0.6425\n","Epoch 74/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7343 - accuracy: 0.7649 - val_loss: 0.9235 - val_accuracy: 0.6448\n","Epoch 75/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7314 - accuracy: 0.7762 - val_loss: 0.9271 - val_accuracy: 0.6278\n","Epoch 76/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7345 - accuracy: 0.7533 - val_loss: 0.9372 - val_accuracy: 0.6357\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7222 - accuracy: 0.7694 - val_loss: 0.9328 - val_accuracy: 0.6403\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7201 - accuracy: 0.7714 - val_loss: 0.9203 - val_accuracy: 0.6437\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7202 - accuracy: 0.7683 - val_loss: 0.9354 - val_accuracy: 0.6188\n","Epoch 80/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7269 - accuracy: 0.7640 - val_loss: 0.9302 - val_accuracy: 0.6199\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7136 - accuracy: 0.7816 - val_loss: 0.9216 - val_accuracy: 0.6437\n","Epoch 82/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7033 - accuracy: 0.7739 - val_loss: 0.9312 - val_accuracy: 0.6256\n","Epoch 83/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7055 - accuracy: 0.7807 - val_loss: 0.9218 - val_accuracy: 0.6448\n","Epoch 84/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7015 - accuracy: 0.7813 - val_loss: 0.9199 - val_accuracy: 0.6448\n","Epoch 85/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7007 - accuracy: 0.7748 - val_loss: 0.9211 - val_accuracy: 0.6459\n","Epoch 86/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6904 - accuracy: 0.7875 - val_loss: 0.9285 - val_accuracy: 0.6493\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6894 - accuracy: 0.7841 - val_loss: 0.9240 - val_accuracy: 0.6448\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6860 - accuracy: 0.7881 - val_loss: 0.9287 - val_accuracy: 0.6369\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6876 - accuracy: 0.7759 - val_loss: 0.9311 - val_accuracy: 0.6505\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6810 - accuracy: 0.7827 - val_loss: 0.9286 - val_accuracy: 0.6290\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6843 - accuracy: 0.7881 - val_loss: 0.9274 - val_accuracy: 0.6391\n","Epoch 92/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6710 - accuracy: 0.7957 - val_loss: 0.9317 - val_accuracy: 0.6414\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6843 - accuracy: 0.7861 - val_loss: 0.9236 - val_accuracy: 0.6448\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6742 - accuracy: 0.7932 - val_loss: 0.9264 - val_accuracy: 0.6471\n","Epoch 95/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6623 - accuracy: 0.7971 - val_loss: 0.9239 - val_accuracy: 0.6425\n","Epoch 96/100\n","28/28 [==============================] - 1s 54ms/step - loss: 0.6614 - accuracy: 0.7988 - val_loss: 0.9269 - val_accuracy: 0.6595\n","Epoch 97/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6576 - accuracy: 0.8090 - val_loss: 0.9306 - val_accuracy: 0.6505\n","Epoch 98/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6619 - accuracy: 0.8033 - val_loss: 0.9657 - val_accuracy: 0.6324\n","Epoch 99/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6510 - accuracy: 0.8039 - val_loss: 0.9314 - val_accuracy: 0.6505\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6496 - accuracy: 0.8045 - val_loss: 0.9307 - val_accuracy: 0.6459\n","{'loss': [1.0586034059524536, 1.0514624118804932, 1.045434594154358, 1.0334084033966064, 1.0284972190856934, 1.022951602935791, 1.0169111490249634, 1.0147935152053833, 1.0107228755950928, 0.9991208910942078, 0.9956130385398865, 0.992174506187439, 0.9909831285476685, 0.9813426733016968, 0.9806851744651794, 0.9763199687004089, 0.965276300907135, 0.9647578001022339, 0.9607239365577698, 0.95461505651474, 0.9534691572189331, 0.9389455914497375, 0.9468764662742615, 0.9274182319641113, 0.9281784892082214, 0.9211215972900391, 0.9133899807929993, 0.9115753769874573, 0.90869140625, 0.9027653932571411, 0.9021390080451965, 0.8961687088012695, 0.8932729363441467, 0.8912641406059265, 0.8850855231285095, 0.8967267274856567, 0.8806841373443604, 0.8711950182914734, 0.8752436637878418, 0.8665580749511719, 0.8630468249320984, 0.8617461919784546, 0.8511820435523987, 0.8490010499954224, 0.8500556349754333, 0.8308720588684082, 0.834700882434845, 0.8337199091911316, 0.825174868106842, 0.8243120312690735, 0.8233170509338379, 0.8220325112342834, 0.8059059977531433, 0.8069455623626709, 0.8045199513435364, 0.8069290518760681, 0.8034905195236206, 0.7934208512306213, 0.7888910174369812, 0.7923448085784912, 0.7800801396369934, 0.7767345905303955, 0.7820162773132324, 0.7727659940719604, 0.7633032202720642, 0.7641289830207825, 0.762820839881897, 0.7946796417236328, 0.7597779035568237, 0.7474273443222046, 0.740657389163971, 0.7433290481567383, 0.737684428691864, 0.7342665195465088, 0.7313715219497681, 0.7344760894775391, 0.7221619486808777, 0.7201417088508606, 0.7201593518257141, 0.7269107699394226, 0.7135990262031555, 0.7033434510231018, 0.7054559588432312, 0.7014613747596741, 0.7006630301475525, 0.6904458403587341, 0.6894465088844299, 0.6860319375991821, 0.6875988841056824, 0.6810173392295837, 0.6842782497406006, 0.6709541082382202, 0.6842800378799438, 0.6741639971733093, 0.6622545123100281, 0.6614122986793518, 0.6576220393180847, 0.6618635654449463, 0.6509732007980347, 0.6495998501777649], 'accuracy': [0.627334475517273, 0.6213921904563904, 0.627334475517273, 0.6397849321365356, 0.6479909420013428, 0.644029438495636, 0.6553480625152588, 0.6409168243408203, 0.6411997675895691, 0.6519524455070496, 0.6454442739486694, 0.6528013348579407, 0.6491228342056274, 0.6578947305679321, 0.6581776738166809, 0.6505376100540161, 0.6550650596618652, 0.6666666865348816, 0.6686474084854126, 0.6706281900405884, 0.6635540723800659, 0.6819468140602112, 0.6641199588775635, 0.685908317565918, 0.6856253743171692, 0.6926994919776917, 0.6819468140602112, 0.691567599773407, 0.6878890991210938, 0.695246160030365, 0.693265438079834, 0.6972269415855408, 0.6975098848342896, 0.6921335458755493, 0.6943972706794739, 0.6864742636680603, 0.7028862237930298, 0.7088285088539124, 0.698924720287323, 0.7034521698951721, 0.7096773982048035, 0.7093944549560547, 0.7190153002738953, 0.711941123008728, 0.713638961315155, 0.7334465384483337, 0.7178834080696106, 0.7178834080696106, 0.7303339242935181, 0.7246745824813843, 0.7224108576774597, 0.722976803779602, 0.7399547100067139, 0.7376909852027893, 0.7345783710479736, 0.7243916392326355, 0.7374080419540405, 0.7382569313049316, 0.7374080419540405, 0.7376909852027893, 0.7490096092224121, 0.744482159614563, 0.7379739880561829, 0.7501415014266968, 0.7475947737693787, 0.7515563368797302, 0.7515563368797302, 0.7255234718322754, 0.744482159614563, 0.7642897367477417, 0.7628749012947083, 0.761177122592926, 0.7628749012947083, 0.764855682849884, 0.7761743068695068, 0.7532541155815125, 0.7693831324577332, 0.7713639140129089, 0.7682512998580933, 0.7640067934989929, 0.7815506458282471, 0.7739105820655823, 0.780701756477356, 0.7812677025794983, 0.7747594714164734, 0.7874929308891296, 0.7840973138809204, 0.788058876991272, 0.7758913636207581, 0.7826825380325317, 0.788058876991272, 0.7956989407539368, 0.7860780954360962, 0.7931522130966187, 0.7971137762069702, 0.7988115549087524, 0.8089982867240906, 0.8033390045166016, 0.8039049506187439, 0.8044708371162415], 'val_loss': [1.0984790325164795, 1.0949333906173706, 1.091423749923706, 1.087873935699463, 1.084335446357727, 1.080743432044983, 1.0772088766098022, 1.0736021995544434, 1.0699349641799927, 1.0660403966903687, 1.0623669624328613, 1.05899977684021, 1.053968906402588, 1.049111247062683, 1.044272541999817, 1.0388778448104858, 1.0333298444747925, 1.0292202234268188, 1.0204368829727173, 1.01414954662323, 1.006295919418335, 1.0022165775299072, 0.9936431646347046, 0.9859929084777832, 0.9786669611930847, 0.9747183918952942, 0.9701367616653442, 0.9690506458282471, 0.9635364413261414, 0.9640218615531921, 0.9592455625534058, 0.9618686437606812, 0.9638413190841675, 0.959965169429779, 0.9552835822105408, 0.9507655501365662, 0.9574448466300964, 0.9634621143341064, 0.9496172666549683, 0.945090651512146, 0.9798672199249268, 0.9444444179534912, 0.9433162212371826, 0.9404089450836182, 0.9395923614501953, 0.9376527667045593, 0.9434473514556885, 0.9480589628219604, 0.9478520750999451, 0.943479597568512, 0.9513490200042725, 0.9340737462043762, 0.9335044026374817, 0.9326783418655396, 0.9300087094306946, 0.9710556864738464, 0.9274489283561707, 0.9548860192298889, 0.935666024684906, 0.924310028553009, 0.9266613125801086, 0.9353317618370056, 0.9477120041847229, 0.9265282154083252, 0.9528681039810181, 0.9260945320129395, 0.9763913154602051, 0.9398397207260132, 0.9175543189048767, 0.9372496008872986, 0.921861469745636, 0.9315966963768005, 0.9253962635993958, 0.9234595894813538, 0.9271095395088196, 0.9371891021728516, 0.9328420758247375, 0.9203445911407471, 0.9354456663131714, 0.9302166104316711, 0.9216460585594177, 0.9311606287956238, 0.921848714351654, 0.9199203848838806, 0.9211346507072449, 0.9284505248069763, 0.9239794611930847, 0.9287447929382324, 0.9310630559921265, 0.9286349415779114, 0.9273918867111206, 0.9316798448562622, 0.9235832095146179, 0.9264138340950012, 0.9239053726196289, 0.9268678426742554, 0.9306029677391052, 0.9657148718833923, 0.9313580393791199, 0.9307055473327637], 'val_accuracy': [0.5328054428100586, 0.5147058963775635, 0.5090497732162476, 0.516968309879303, 0.516968309879303, 0.5248869061470032, 0.5226244330406189, 0.5226244330406189, 0.5260180830955505, 0.5497737526893616, 0.5339366793632507, 0.5248869061470032, 0.5622171759605408, 0.5961538553237915, 0.598416268825531, 0.6255655884742737, 0.6131221652030945, 0.5927602052688599, 0.6436651349067688, 0.6323529481887817, 0.6368778347969055, 0.6097285151481628, 0.6244344115257263, 0.6312217116355896, 0.6481900215148926, 0.6380090713500977, 0.6459276080131531, 0.6402714848518372, 0.6549773812294006, 0.639140248298645, 0.6481900215148926, 0.6357465982437134, 0.6368778347969055, 0.6334841847419739, 0.6459276080131531, 0.651583731174469, 0.6300904750823975, 0.6187782883644104, 0.6402714848518372, 0.6436651349067688, 0.6029411554336548, 0.6368778347969055, 0.6425339579582214, 0.6493212580680847, 0.6459276080131531, 0.6470588445663452, 0.6380090713500977, 0.639140248298645, 0.6266968250274658, 0.6357465982437134, 0.6289592981338501, 0.6470588445663452, 0.6459276080131531, 0.6436651349067688, 0.6493212580680847, 0.622171938419342, 0.6414027214050293, 0.6312217116355896, 0.6357465982437134, 0.6447963714599609, 0.6470588445663452, 0.6368778347969055, 0.6289592981338501, 0.6334841847419739, 0.627828061580658, 0.6425339579582214, 0.622171938419342, 0.6300904750823975, 0.6357465982437134, 0.6436651349067688, 0.6436651349067688, 0.639140248298645, 0.6425339579582214, 0.6447963714599609, 0.627828061580658, 0.6357465982437134, 0.6402714848518372, 0.6436651349067688, 0.6187782883644104, 0.6199095249176025, 0.6436651349067688, 0.6255655884742737, 0.6447963714599609, 0.6447963714599609, 0.6459276080131531, 0.6493212580680847, 0.6447963714599609, 0.6368778347969055, 0.6504524946212769, 0.6289592981338501, 0.639140248298645, 0.6414027214050293, 0.6447963714599609, 0.6470588445663452, 0.6425339579582214, 0.6595022678375244, 0.6504524946212769, 0.6323529481887817, 0.6504524946212769, 0.6459276080131531]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 1.0521 - accuracy: 0.6360"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 9s 76ms/step - loss: 1.0528 - accuracy: 0.6367 - val_loss: 1.0980 - val_accuracy: 0.5310\n","Epoch 2/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0456 - accuracy: 0.6339 - val_loss: 1.0941 - val_accuracy: 0.5351\n","Epoch 3/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0368 - accuracy: 0.6380 - val_loss: 1.0904 - val_accuracy: 0.5847\n","Epoch 4/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0303 - accuracy: 0.6447 - val_loss: 1.0865 - val_accuracy: 0.5496\n","Epoch 5/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0256 - accuracy: 0.6336 - val_loss: 1.0828 - val_accuracy: 0.5878\n","Epoch 6/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0239 - accuracy: 0.6323 - val_loss: 1.0789 - val_accuracy: 0.5723\n","Epoch 7/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0114 - accuracy: 0.6468 - val_loss: 1.0752 - val_accuracy: 0.5599\n","Epoch 8/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0050 - accuracy: 0.6486 - val_loss: 1.0713 - val_accuracy: 0.5630\n","Epoch 9/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9947 - accuracy: 0.6558 - val_loss: 1.0676 - val_accuracy: 0.5682\n","Epoch 10/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9898 - accuracy: 0.6545 - val_loss: 1.0641 - val_accuracy: 0.5909\n","Epoch 11/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9897 - accuracy: 0.6501 - val_loss: 1.0596 - val_accuracy: 0.5723\n","Epoch 12/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9836 - accuracy: 0.6566 - val_loss: 1.0560 - val_accuracy: 0.5785\n","Epoch 13/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9761 - accuracy: 0.6659 - val_loss: 1.0516 - val_accuracy: 0.5857\n","Epoch 14/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9734 - accuracy: 0.6656 - val_loss: 1.0474 - val_accuracy: 0.5744\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9653 - accuracy: 0.6643 - val_loss: 1.0435 - val_accuracy: 0.5888\n","Epoch 16/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9573 - accuracy: 0.6677 - val_loss: 1.0392 - val_accuracy: 0.5640\n","Epoch 17/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9635 - accuracy: 0.6630 - val_loss: 1.0351 - val_accuracy: 0.5847\n","Epoch 18/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9514 - accuracy: 0.6656 - val_loss: 1.0299 - val_accuracy: 0.5826\n","Epoch 19/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9475 - accuracy: 0.6731 - val_loss: 1.0252 - val_accuracy: 0.5847\n","Epoch 20/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9463 - accuracy: 0.6747 - val_loss: 1.0217 - val_accuracy: 0.5744\n","Epoch 21/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9326 - accuracy: 0.6804 - val_loss: 1.0179 - val_accuracy: 0.5733\n","Epoch 22/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9272 - accuracy: 0.6814 - val_loss: 1.0172 - val_accuracy: 0.5733\n","Epoch 23/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9358 - accuracy: 0.6711 - val_loss: 1.0186 - val_accuracy: 0.5899\n","Epoch 24/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9253 - accuracy: 0.6798 - val_loss: 1.0157 - val_accuracy: 0.5857\n","Epoch 25/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9218 - accuracy: 0.6783 - val_loss: 1.0211 - val_accuracy: 0.5806\n","Epoch 26/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9203 - accuracy: 0.6752 - val_loss: 1.0125 - val_accuracy: 0.5919\n","Epoch 27/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9166 - accuracy: 0.6767 - val_loss: 1.0135 - val_accuracy: 0.5961\n","Epoch 28/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9155 - accuracy: 0.6786 - val_loss: 1.0159 - val_accuracy: 0.5992\n","Epoch 29/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9014 - accuracy: 0.6902 - val_loss: 1.0128 - val_accuracy: 0.5930\n","Epoch 30/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9007 - accuracy: 0.6899 - val_loss: 1.0206 - val_accuracy: 0.5837\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8957 - accuracy: 0.6956 - val_loss: 1.0153 - val_accuracy: 0.5961\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8873 - accuracy: 0.6974 - val_loss: 1.0103 - val_accuracy: 0.5764\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8800 - accuracy: 0.7008 - val_loss: 1.0380 - val_accuracy: 0.5837\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8841 - accuracy: 0.6922 - val_loss: 1.0138 - val_accuracy: 0.5981\n","Epoch 35/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8768 - accuracy: 0.7023 - val_loss: 1.0153 - val_accuracy: 0.5723\n","Epoch 36/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8738 - accuracy: 0.7031 - val_loss: 1.0231 - val_accuracy: 0.5857\n","Epoch 37/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8734 - accuracy: 0.7023 - val_loss: 1.0096 - val_accuracy: 0.5713\n","Epoch 38/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8647 - accuracy: 0.7116 - val_loss: 1.0066 - val_accuracy: 0.5930\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8611 - accuracy: 0.7005 - val_loss: 1.0063 - val_accuracy: 0.5919\n","Epoch 40/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8593 - accuracy: 0.7049 - val_loss: 1.0065 - val_accuracy: 0.5919\n","Epoch 41/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8582 - accuracy: 0.7005 - val_loss: 1.0106 - val_accuracy: 0.5930\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8449 - accuracy: 0.7183 - val_loss: 1.0247 - val_accuracy: 0.5888\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8395 - accuracy: 0.7243 - val_loss: 1.0077 - val_accuracy: 0.5940\n","Epoch 44/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8363 - accuracy: 0.7248 - val_loss: 1.0098 - val_accuracy: 0.5671\n","Epoch 45/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.8385 - accuracy: 0.7225 - val_loss: 1.0277 - val_accuracy: 0.5837\n","Epoch 46/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8278 - accuracy: 0.7207 - val_loss: 1.0117 - val_accuracy: 0.5992\n","Epoch 47/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8214 - accuracy: 0.7297 - val_loss: 1.0058 - val_accuracy: 0.5981\n","Epoch 48/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8224 - accuracy: 0.7261 - val_loss: 1.0155 - val_accuracy: 0.5702\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8216 - accuracy: 0.7274 - val_loss: 1.0097 - val_accuracy: 0.5775\n","Epoch 50/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8241 - accuracy: 0.7165 - val_loss: 1.0069 - val_accuracy: 0.5682\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8200 - accuracy: 0.7251 - val_loss: 1.0146 - val_accuracy: 0.5899\n","Epoch 52/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8112 - accuracy: 0.7269 - val_loss: 1.0124 - val_accuracy: 0.5930\n","Epoch 53/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8041 - accuracy: 0.7395 - val_loss: 1.0748 - val_accuracy: 0.5455\n","Epoch 54/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8059 - accuracy: 0.7297 - val_loss: 1.0115 - val_accuracy: 0.5940\n","Epoch 55/100\n","31/31 [==============================] - 1s 47ms/step - loss: 0.7938 - accuracy: 0.7382 - val_loss: 1.0136 - val_accuracy: 0.6002\n","Epoch 56/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7901 - accuracy: 0.7398 - val_loss: 1.0080 - val_accuracy: 0.5992\n","Epoch 57/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7832 - accuracy: 0.7416 - val_loss: 1.0089 - val_accuracy: 0.5692\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7874 - accuracy: 0.7305 - val_loss: 1.0262 - val_accuracy: 0.5857\n","Epoch 59/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7774 - accuracy: 0.7499 - val_loss: 1.0091 - val_accuracy: 0.6012\n","Epoch 60/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7912 - accuracy: 0.7331 - val_loss: 1.0054 - val_accuracy: 0.5971\n","Epoch 61/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7784 - accuracy: 0.7452 - val_loss: 1.0058 - val_accuracy: 0.5661\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7694 - accuracy: 0.7483 - val_loss: 1.0282 - val_accuracy: 0.5878\n","Epoch 63/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7636 - accuracy: 0.7506 - val_loss: 1.0064 - val_accuracy: 0.5930\n","Epoch 64/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7573 - accuracy: 0.7592 - val_loss: 1.0307 - val_accuracy: 0.5671\n","Epoch 65/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7618 - accuracy: 0.7478 - val_loss: 1.0134 - val_accuracy: 0.6054\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7475 - accuracy: 0.7623 - val_loss: 1.0305 - val_accuracy: 0.5847\n","Epoch 67/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7459 - accuracy: 0.7607 - val_loss: 1.0578 - val_accuracy: 0.5671\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7504 - accuracy: 0.7519 - val_loss: 1.0196 - val_accuracy: 0.6033\n","Epoch 69/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7457 - accuracy: 0.7543 - val_loss: 1.0290 - val_accuracy: 0.6002\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7361 - accuracy: 0.7638 - val_loss: 1.0266 - val_accuracy: 0.5971\n","Epoch 71/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7472 - accuracy: 0.7522 - val_loss: 1.0500 - val_accuracy: 0.5640\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7378 - accuracy: 0.7620 - val_loss: 1.0113 - val_accuracy: 0.5816\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7351 - accuracy: 0.7628 - val_loss: 1.0559 - val_accuracy: 0.5744\n","Epoch 74/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7331 - accuracy: 0.7669 - val_loss: 1.0128 - val_accuracy: 0.5981\n","Epoch 75/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7220 - accuracy: 0.7736 - val_loss: 1.0178 - val_accuracy: 0.5950\n","Epoch 76/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7205 - accuracy: 0.7682 - val_loss: 1.0357 - val_accuracy: 0.5909\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7124 - accuracy: 0.7708 - val_loss: 1.0588 - val_accuracy: 0.5795\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7115 - accuracy: 0.7767 - val_loss: 1.0708 - val_accuracy: 0.5671\n","Epoch 79/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7044 - accuracy: 0.7765 - val_loss: 1.0514 - val_accuracy: 0.5878\n","Epoch 80/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7062 - accuracy: 0.7744 - val_loss: 1.0815 - val_accuracy: 0.5713\n","Epoch 81/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7074 - accuracy: 0.7713 - val_loss: 1.0344 - val_accuracy: 0.5651\n","Epoch 82/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6997 - accuracy: 0.7770 - val_loss: 1.0272 - val_accuracy: 0.5971\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6905 - accuracy: 0.7879 - val_loss: 1.0316 - val_accuracy: 0.5899\n","Epoch 84/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6887 - accuracy: 0.7814 - val_loss: 1.0585 - val_accuracy: 0.5919\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6885 - accuracy: 0.7866 - val_loss: 1.0398 - val_accuracy: 0.5940\n","Epoch 86/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.7793 - val_loss: 1.0695 - val_accuracy: 0.5806\n","Epoch 87/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6808 - accuracy: 0.7917 - val_loss: 1.0338 - val_accuracy: 0.5930\n","Epoch 88/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6838 - accuracy: 0.7860 - val_loss: 1.0488 - val_accuracy: 0.5899\n","Epoch 89/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6764 - accuracy: 0.7928 - val_loss: 1.0991 - val_accuracy: 0.5733\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6763 - accuracy: 0.7917 - val_loss: 1.0878 - val_accuracy: 0.5702\n","Epoch 91/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6663 - accuracy: 0.7941 - val_loss: 1.0968 - val_accuracy: 0.5661\n","Epoch 92/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6647 - accuracy: 0.7941 - val_loss: 1.0465 - val_accuracy: 0.5909\n","Epoch 93/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6677 - accuracy: 0.7845 - val_loss: 1.0778 - val_accuracy: 0.5754\n","Epoch 94/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6607 - accuracy: 0.7992 - val_loss: 1.0441 - val_accuracy: 0.5847\n","Epoch 95/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6595 - accuracy: 0.7979 - val_loss: 1.0510 - val_accuracy: 0.5795\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6452 - accuracy: 0.8054 - val_loss: 1.1303 - val_accuracy: 0.5692\n","Epoch 97/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6600 - accuracy: 0.7961 - val_loss: 1.0721 - val_accuracy: 0.5816\n","Epoch 98/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6380 - accuracy: 0.8106 - val_loss: 1.0738 - val_accuracy: 0.5826\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6503 - accuracy: 0.8021 - val_loss: 1.0627 - val_accuracy: 0.5826\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6351 - accuracy: 0.8119 - val_loss: 1.0572 - val_accuracy: 0.5940\n","{'loss': [1.052762746810913, 1.045582890510559, 1.0367836952209473, 1.0303013324737549, 1.0256319046020508, 1.0238887071609497, 1.0113582611083984, 1.0050485134124756, 0.9947302937507629, 0.9897934794425964, 0.9896683692932129, 0.983613908290863, 0.9761423468589783, 0.9734184741973877, 0.965335488319397, 0.9573358297348022, 0.963462769985199, 0.9513773322105408, 0.9474760890007019, 0.9463315606117249, 0.9325610995292664, 0.9271665811538696, 0.9357618689537048, 0.9253085255622864, 0.9217943549156189, 0.9202977418899536, 0.9165505170822144, 0.9154582619667053, 0.9014375805854797, 0.9007286429405212, 0.8956931233406067, 0.8873029947280884, 0.8800212740898132, 0.88410484790802, 0.8768385052680969, 0.8737890720367432, 0.8733658790588379, 0.8647276759147644, 0.8610960245132446, 0.8592507243156433, 0.8582358956336975, 0.8448788523674011, 0.839531660079956, 0.8362787365913391, 0.8384646773338318, 0.8278350830078125, 0.8214365839958191, 0.8224349617958069, 0.8215503692626953, 0.8241267800331116, 0.8200493454933167, 0.8112303018569946, 0.804093599319458, 0.8059177994728088, 0.7938255667686462, 0.7901433706283569, 0.7832486629486084, 0.7873876094818115, 0.7774178385734558, 0.7912260293960571, 0.7784154415130615, 0.7693503499031067, 0.7636252045631409, 0.757275402545929, 0.7617909908294678, 0.7475064396858215, 0.7458691000938416, 0.7503832578659058, 0.7456552982330322, 0.7361097931861877, 0.7472476363182068, 0.7377760410308838, 0.7351157665252686, 0.7331432104110718, 0.721967875957489, 0.7205098867416382, 0.7124292850494385, 0.7114743590354919, 0.7044339179992676, 0.7061911225318909, 0.7074028849601746, 0.6996932029724121, 0.6905251741409302, 0.6886841058731079, 0.6885033249855042, 0.6931015253067017, 0.6807806491851807, 0.6837506890296936, 0.6763988137245178, 0.6763119101524353, 0.6662956476211548, 0.6647194623947144, 0.6677432060241699, 0.6606520414352417, 0.6595127582550049, 0.645236074924469, 0.6599785089492798, 0.6379905343055725, 0.6503415703773499, 0.6351237893104553], 'accuracy': [0.6366925239562988, 0.6338501572608948, 0.6379845142364502, 0.6447028517723083, 0.6335917115211487, 0.6322997212409973, 0.6467700004577637, 0.6485788226127625, 0.6558139324188232, 0.6545219421386719, 0.6501291990280151, 0.656589150428772, 0.6658914685249329, 0.6656330823898315, 0.6643410921096802, 0.6677002310752869, 0.6630491018295288, 0.6656330823898315, 0.6731266379356384, 0.6746770143508911, 0.6803617477416992, 0.6813953518867493, 0.6710594296455383, 0.6798449754714966, 0.6782945990562439, 0.6751937866210938, 0.6767441630363464, 0.6785529851913452, 0.6901808977127075, 0.6899224519729614, 0.6956072449684143, 0.6974160075187683, 0.7007752060890198, 0.6922480463981628, 0.7023255825042725, 0.7031008005142212, 0.7023255825042725, 0.7116279006004333, 0.7005168199539185, 0.7049095630645752, 0.7005168199539185, 0.7183462381362915, 0.7242894172668457, 0.7248061895370483, 0.7224805951118469, 0.7206718325614929, 0.7297157645225525, 0.7260981798171997, 0.7273901700973511, 0.7165374755859375, 0.7250645756721497, 0.7268733978271484, 0.739534854888916, 0.7297157645225525, 0.7382428646087646, 0.7397933006286621, 0.7416020631790161, 0.7304909825325012, 0.749870777130127, 0.733074963092804, 0.7452196478843689, 0.7483204007148743, 0.7506459951400757, 0.7591731548309326, 0.7478036284446716, 0.762273907661438, 0.7607235312461853, 0.751937985420227, 0.7542635798454285, 0.7638242840766907, 0.7521963715553284, 0.7620155215263367, 0.7627906799316406, 0.766925036907196, 0.773643434047699, 0.7682170271873474, 0.7708010077476501, 0.7767441868782043, 0.776485800743103, 0.7744185924530029, 0.7713178396224976, 0.7770025730133057, 0.7878552675247192, 0.7813953757286072, 0.7865633368492126, 0.7793281674385071, 0.7917312383651733, 0.7860465049743652, 0.7927648425102234, 0.7917312383651733, 0.7940568327903748, 0.7940568327903748, 0.7844961285591125, 0.7992247939109802, 0.7979328036308289, 0.8054263591766357, 0.7961240410804749, 0.8105943202972412, 0.8020671606063843, 0.8118863105773926], 'val_loss': [1.0980156660079956, 1.0940957069396973, 1.0904101133346558, 1.0864722728729248, 1.0828206539154053, 1.0789482593536377, 1.075155258178711, 1.0713454484939575, 1.0676041841506958, 1.0640652179718018, 1.0596199035644531, 1.0560060739517212, 1.0516108274459839, 1.0473511219024658, 1.0435460805892944, 1.0391771793365479, 1.035110354423523, 1.029859185218811, 1.0251953601837158, 1.021734595298767, 1.0178929567337036, 1.0171934366226196, 1.0185924768447876, 1.015674352645874, 1.0211069583892822, 1.0124872922897339, 1.0134893655776978, 1.015939712524414, 1.0127925872802734, 1.0205713510513306, 1.0153484344482422, 1.0102834701538086, 1.0379955768585205, 1.013761043548584, 1.0152678489685059, 1.0230501890182495, 1.0095744132995605, 1.0065710544586182, 1.0062979459762573, 1.0065110921859741, 1.0106327533721924, 1.0246965885162354, 1.007671594619751, 1.0098137855529785, 1.0276875495910645, 1.0117125511169434, 1.005752682685852, 1.0154951810836792, 1.0096701383590698, 1.0069347620010376, 1.014587640762329, 1.0124096870422363, 1.0747601985931396, 1.0114794969558716, 1.013578176498413, 1.0079560279846191, 1.0088943243026733, 1.026179552078247, 1.0090972185134888, 1.0053989887237549, 1.0058174133300781, 1.028160572052002, 1.0063754320144653, 1.0306578874588013, 1.0133702754974365, 1.0304862260818481, 1.0578265190124512, 1.0196129083633423, 1.028968334197998, 1.0265759229660034, 1.0499855279922485, 1.011288046836853, 1.055859088897705, 1.0127754211425781, 1.0177773237228394, 1.0356897115707397, 1.0587728023529053, 1.0707591772079468, 1.0514076948165894, 1.0815401077270508, 1.0344080924987793, 1.0272175073623657, 1.0315619707107544, 1.0584667921066284, 1.039817214012146, 1.0695351362228394, 1.033756136894226, 1.0488085746765137, 1.0990595817565918, 1.087762475013733, 1.096750020980835, 1.0464808940887451, 1.0778416395187378, 1.0440813302993774, 1.050969123840332, 1.1302683353424072, 1.0721263885498047, 1.0737777948379517, 1.062662124633789, 1.0571895837783813], 'val_accuracy': [0.5309917330741882, 0.5351239442825317, 0.5847107172012329, 0.5495867729187012, 0.5878099203109741, 0.5723140239715576, 0.5599173307418823, 0.5630165338516235, 0.5681818127632141, 0.5909090638160706, 0.5723140239715576, 0.5785123705863953, 0.58574378490448, 0.5743801593780518, 0.5888429880142212, 0.5640496015548706, 0.5847107172012329, 0.5826446413993835, 0.5847107172012329, 0.5743801593780518, 0.5733470916748047, 0.5733470916748047, 0.5898760557174683, 0.58574378490448, 0.5805785059928894, 0.5919421315193176, 0.5960744023323059, 0.5991735458374023, 0.5929751992225647, 0.5836777091026306, 0.5960744023323059, 0.5764462947845459, 0.5836777091026306, 0.5981404781341553, 0.5723140239715576, 0.58574378490448, 0.5712810158729553, 0.5929751992225647, 0.5919421315193176, 0.5919421315193176, 0.5929751992225647, 0.5888429880142212, 0.5940082669258118, 0.567148745059967, 0.5836777091026306, 0.5991735458374023, 0.5981404781341553, 0.5702479481697083, 0.577479362487793, 0.5681818127632141, 0.5898760557174683, 0.5929751992225647, 0.5454545617103577, 0.5940082669258118, 0.6002066135406494, 0.5991735458374023, 0.5692148804664612, 0.58574378490448, 0.6012396812438965, 0.5971074104309082, 0.56611567735672, 0.5878099203109741, 0.5929751992225647, 0.567148745059967, 0.60537189245224, 0.5847107172012329, 0.567148745059967, 0.6033057570457458, 0.6002066135406494, 0.5971074104309082, 0.5640496015548706, 0.5816115736961365, 0.5743801593780518, 0.5981404781341553, 0.5950413346290588, 0.5909090638160706, 0.5795454382896423, 0.567148745059967, 0.5878099203109741, 0.5712810158729553, 0.5650826692581177, 0.5971074104309082, 0.5898760557174683, 0.5919421315193176, 0.5940082669258118, 0.5805785059928894, 0.5929751992225647, 0.5898760557174683, 0.5733470916748047, 0.5702479481697083, 0.56611567735672, 0.5909090638160706, 0.5754132270812988, 0.5847107172012329, 0.5795454382896423, 0.5692148804664612, 0.5816115736961365, 0.5826446413993835, 0.5826446413993835, 0.5940082669258118]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 0.7190 - accuracy: 0.7584"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 60ms/step - loss: 0.7215 - accuracy: 0.7557 - val_loss: 0.9217 - val_accuracy: 0.4881\n","Epoch 2/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7031 - accuracy: 0.7718 - val_loss: 0.9209 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6989 - accuracy: 0.7699 - val_loss: 0.9195 - val_accuracy: 0.4871\n","Epoch 4/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6999 - accuracy: 0.7732 - val_loss: 0.9175 - val_accuracy: 0.4871\n","Epoch 5/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6950 - accuracy: 0.7737 - val_loss: 0.9162 - val_accuracy: 0.4860\n","Epoch 6/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6894 - accuracy: 0.7726 - val_loss: 0.9139 - val_accuracy: 0.4881\n","Epoch 7/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6799 - accuracy: 0.7853 - val_loss: 0.9122 - val_accuracy: 0.4881\n","Epoch 8/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6717 - accuracy: 0.7872 - val_loss: 0.9090 - val_accuracy: 0.5022\n","Epoch 9/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6734 - accuracy: 0.7799 - val_loss: 0.9086 - val_accuracy: 0.4871\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6794 - accuracy: 0.7826 - val_loss: 0.9067 - val_accuracy: 0.4892\n","Epoch 11/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6736 - accuracy: 0.7883 - val_loss: 0.8995 - val_accuracy: 0.5312\n","Epoch 12/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6587 - accuracy: 0.7880 - val_loss: 0.8942 - val_accuracy: 0.5560\n","Epoch 13/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6470 - accuracy: 0.8028 - val_loss: 0.8875 - val_accuracy: 0.6002\n","Epoch 14/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6548 - accuracy: 0.7915 - val_loss: 0.8862 - val_accuracy: 0.5560\n","Epoch 15/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6539 - accuracy: 0.7934 - val_loss: 0.8745 - val_accuracy: 0.6175\n","Epoch 16/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6509 - accuracy: 0.7888 - val_loss: 0.8766 - val_accuracy: 0.5679\n","Epoch 17/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6395 - accuracy: 0.8052 - val_loss: 0.8653 - val_accuracy: 0.6067\n","Epoch 18/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6513 - accuracy: 0.7966 - val_loss: 0.8576 - val_accuracy: 0.6142\n","Epoch 19/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.6452 - accuracy: 0.7947 - val_loss: 0.8365 - val_accuracy: 0.6584\n","Epoch 20/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6330 - accuracy: 0.8050 - val_loss: 0.8361 - val_accuracy: 0.6390\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6279 - accuracy: 0.8109 - val_loss: 0.8302 - val_accuracy: 0.6466\n","Epoch 22/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6294 - accuracy: 0.8095 - val_loss: 0.8549 - val_accuracy: 0.6164\n","Epoch 23/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6270 - accuracy: 0.8109 - val_loss: 0.8329 - val_accuracy: 0.6444\n","Epoch 24/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.6195 - accuracy: 0.8133 - val_loss: 0.8033 - val_accuracy: 0.6853\n","Epoch 25/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6157 - accuracy: 0.8184 - val_loss: 0.8085 - val_accuracy: 0.6767\n","Epoch 26/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6208 - accuracy: 0.8160 - val_loss: 0.8043 - val_accuracy: 0.6756\n","Epoch 27/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6150 - accuracy: 0.8122 - val_loss: 0.8093 - val_accuracy: 0.6713\n","Epoch 28/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6107 - accuracy: 0.8157 - val_loss: 0.8201 - val_accuracy: 0.6800\n","Epoch 29/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5979 - accuracy: 0.8238 - val_loss: 0.8373 - val_accuracy: 0.6756\n","Epoch 30/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5998 - accuracy: 0.8265 - val_loss: 0.8305 - val_accuracy: 0.6843\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5910 - accuracy: 0.8305 - val_loss: 0.8333 - val_accuracy: 0.6756\n","Epoch 32/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6015 - accuracy: 0.8136 - val_loss: 0.8890 - val_accuracy: 0.6627\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6014 - accuracy: 0.8133 - val_loss: 0.8379 - val_accuracy: 0.6778\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5851 - accuracy: 0.8273 - val_loss: 0.8421 - val_accuracy: 0.6821\n","Epoch 35/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5912 - accuracy: 0.8297 - val_loss: 0.9687 - val_accuracy: 0.6369\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6178 - accuracy: 0.8071 - val_loss: 0.8429 - val_accuracy: 0.6832\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5841 - accuracy: 0.8268 - val_loss: 0.8456 - val_accuracy: 0.6853\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5820 - accuracy: 0.8316 - val_loss: 0.8553 - val_accuracy: 0.6853\n","Epoch 39/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5774 - accuracy: 0.8308 - val_loss: 0.8521 - val_accuracy: 0.6821\n","Epoch 40/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5713 - accuracy: 0.8365 - val_loss: 0.8551 - val_accuracy: 0.6918\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5626 - accuracy: 0.8402 - val_loss: 0.8569 - val_accuracy: 0.6907\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5772 - accuracy: 0.8330 - val_loss: 0.9120 - val_accuracy: 0.6670\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5679 - accuracy: 0.8308 - val_loss: 0.8657 - val_accuracy: 0.6843\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5593 - accuracy: 0.8367 - val_loss: 0.8878 - val_accuracy: 0.6767\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5519 - accuracy: 0.8413 - val_loss: 0.8957 - val_accuracy: 0.6724\n","Epoch 46/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5539 - accuracy: 0.8400 - val_loss: 0.9107 - val_accuracy: 0.6541\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5526 - accuracy: 0.8451 - val_loss: 0.8697 - val_accuracy: 0.6832\n","Epoch 48/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5488 - accuracy: 0.8438 - val_loss: 0.8667 - val_accuracy: 0.6864\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5440 - accuracy: 0.8459 - val_loss: 0.9060 - val_accuracy: 0.6713\n","Epoch 50/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5378 - accuracy: 0.8481 - val_loss: 0.8876 - val_accuracy: 0.6821\n","Epoch 51/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5242 - accuracy: 0.8610 - val_loss: 0.9024 - val_accuracy: 0.6756\n","Epoch 52/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5266 - accuracy: 0.8607 - val_loss: 0.8803 - val_accuracy: 0.6821\n","Epoch 53/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5324 - accuracy: 0.8543 - val_loss: 0.9583 - val_accuracy: 0.6595\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5373 - accuracy: 0.8462 - val_loss: 0.8880 - val_accuracy: 0.6789\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5272 - accuracy: 0.8502 - val_loss: 0.9283 - val_accuracy: 0.6703\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5221 - accuracy: 0.8586 - val_loss: 0.9551 - val_accuracy: 0.6638\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5366 - accuracy: 0.8475 - val_loss: 0.9328 - val_accuracy: 0.6541\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5452 - accuracy: 0.8421 - val_loss: 1.0095 - val_accuracy: 0.6519\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5276 - accuracy: 0.8540 - val_loss: 0.9618 - val_accuracy: 0.6616\n","Epoch 60/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5256 - accuracy: 0.8537 - val_loss: 0.9626 - val_accuracy: 0.6627\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5227 - accuracy: 0.8570 - val_loss: 0.8912 - val_accuracy: 0.6789\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5203 - accuracy: 0.8599 - val_loss: 0.8983 - val_accuracy: 0.6649\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5151 - accuracy: 0.8607 - val_loss: 0.8902 - val_accuracy: 0.6756\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5142 - accuracy: 0.8578 - val_loss: 0.8937 - val_accuracy: 0.6800\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4885 - accuracy: 0.8782 - val_loss: 0.8943 - val_accuracy: 0.6767\n","Epoch 66/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4926 - accuracy: 0.8745 - val_loss: 0.9018 - val_accuracy: 0.6843\n","Epoch 67/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5010 - accuracy: 0.8634 - val_loss: 0.9225 - val_accuracy: 0.6735\n","Epoch 68/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5095 - accuracy: 0.8602 - val_loss: 0.9897 - val_accuracy: 0.6606\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5196 - accuracy: 0.8567 - val_loss: 0.9787 - val_accuracy: 0.6487\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5198 - accuracy: 0.8499 - val_loss: 0.8888 - val_accuracy: 0.6832\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4855 - accuracy: 0.8707 - val_loss: 0.8954 - val_accuracy: 0.6789\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4782 - accuracy: 0.8804 - val_loss: 0.9042 - val_accuracy: 0.6778\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4939 - accuracy: 0.8699 - val_loss: 0.9524 - val_accuracy: 0.6562\n","Epoch 74/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5097 - accuracy: 0.8607 - val_loss: 0.9080 - val_accuracy: 0.6864\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4892 - accuracy: 0.8683 - val_loss: 0.9460 - val_accuracy: 0.6735\n","Epoch 76/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4782 - accuracy: 0.8774 - val_loss: 0.9154 - val_accuracy: 0.6843\n","Epoch 77/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4770 - accuracy: 0.8807 - val_loss: 0.9122 - val_accuracy: 0.6800\n","Epoch 78/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4795 - accuracy: 0.8745 - val_loss: 0.9179 - val_accuracy: 0.6789\n","Epoch 79/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4854 - accuracy: 0.8707 - val_loss: 0.9628 - val_accuracy: 0.6552\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4745 - accuracy: 0.8788 - val_loss: 0.9650 - val_accuracy: 0.6703\n","Epoch 81/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4924 - accuracy: 0.8640 - val_loss: 0.9166 - val_accuracy: 0.6789\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4657 - accuracy: 0.8758 - val_loss: 0.9591 - val_accuracy: 0.6767\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4724 - accuracy: 0.8823 - val_loss: 0.9520 - val_accuracy: 0.6649\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4581 - accuracy: 0.8869 - val_loss: 0.9273 - val_accuracy: 0.6767\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4605 - accuracy: 0.8858 - val_loss: 0.9288 - val_accuracy: 0.6778\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4472 - accuracy: 0.8941 - val_loss: 0.9349 - val_accuracy: 0.6789\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4430 - accuracy: 0.8976 - val_loss: 0.9355 - val_accuracy: 0.6843\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4376 - accuracy: 0.9038 - val_loss: 0.9901 - val_accuracy: 0.6659\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4524 - accuracy: 0.8885 - val_loss: 0.9429 - val_accuracy: 0.6789\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4320 - accuracy: 0.9038 - val_loss: 0.9546 - val_accuracy: 0.6800\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4385 - accuracy: 0.8944 - val_loss: 0.9489 - val_accuracy: 0.6778\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4406 - accuracy: 0.8925 - val_loss: 0.9542 - val_accuracy: 0.6756\n","Epoch 93/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4241 - accuracy: 0.9017 - val_loss: 0.9512 - val_accuracy: 0.6843\n","Epoch 94/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4304 - accuracy: 0.8982 - val_loss: 0.9609 - val_accuracy: 0.6800\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4463 - accuracy: 0.8920 - val_loss: 0.9771 - val_accuracy: 0.6659\n","Epoch 96/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4627 - accuracy: 0.8804 - val_loss: 0.9544 - val_accuracy: 0.6756\n","Epoch 97/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4206 - accuracy: 0.9041 - val_loss: 0.9647 - val_accuracy: 0.6767\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4180 - accuracy: 0.9076 - val_loss: 0.9926 - val_accuracy: 0.6810\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4157 - accuracy: 0.9089 - val_loss: 0.9714 - val_accuracy: 0.6800\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4271 - accuracy: 0.9011 - val_loss: 0.9651 - val_accuracy: 0.6821\n","{'loss': [0.7214534878730774, 0.7031087279319763, 0.6989431977272034, 0.6998748183250427, 0.6950344443321228, 0.6893996000289917, 0.6799285411834717, 0.6716750860214233, 0.6733783483505249, 0.6793909668922424, 0.6735750436782837, 0.6587239503860474, 0.6470417976379395, 0.6548463106155396, 0.6538811922073364, 0.650858461856842, 0.639532208442688, 0.651349663734436, 0.6452049612998962, 0.633012592792511, 0.6279224157333374, 0.6293898224830627, 0.6270443201065063, 0.6194686889648438, 0.6157031059265137, 0.6207886934280396, 0.6150118708610535, 0.6106979846954346, 0.597935140132904, 0.5998085141181946, 0.5910324454307556, 0.6015346646308899, 0.6014103293418884, 0.5850741863250732, 0.5912476181983948, 0.6177997589111328, 0.5840706825256348, 0.5819903612136841, 0.5773608684539795, 0.5713158249855042, 0.562640905380249, 0.5771598219871521, 0.5679352879524231, 0.5592930316925049, 0.5519278049468994, 0.5538672208786011, 0.5526133179664612, 0.548806369304657, 0.5439892411231995, 0.5378031730651855, 0.5242214202880859, 0.5266497135162354, 0.5323866605758667, 0.537286639213562, 0.5272188782691956, 0.5220504999160767, 0.5366031527519226, 0.5451568961143494, 0.5276071429252625, 0.5255812406539917, 0.522678554058075, 0.5203391313552856, 0.5151095986366272, 0.5141801834106445, 0.4884897470474243, 0.4926479160785675, 0.5009985566139221, 0.5094774961471558, 0.5196365118026733, 0.5198233127593994, 0.48549261689186096, 0.47815659642219543, 0.4939366281032562, 0.5096712708473206, 0.4892270267009735, 0.4781908392906189, 0.47702258825302124, 0.4794652760028839, 0.48540574312210083, 0.4745340943336487, 0.49241676926612854, 0.46569910645484924, 0.4724251329898834, 0.458138108253479, 0.4604676067829132, 0.447163462638855, 0.4429776966571808, 0.43756774067878723, 0.45237189531326294, 0.43202462792396545, 0.4384988844394684, 0.44061005115509033, 0.4241304099559784, 0.43040013313293457, 0.4463363289833069, 0.4626942276954651, 0.4206230044364929, 0.41804295778274536, 0.41568028926849365, 0.42705875635147095], 'accuracy': [0.7556573152542114, 0.771821141242981, 0.7699353694915771, 0.7731680870056152, 0.7737069129943848, 0.7726293206214905, 0.7852909564971924, 0.7871767282485962, 0.779902994632721, 0.782597005367279, 0.7882543206214905, 0.7879849076271057, 0.8028017282485962, 0.7914870977401733, 0.7933728694915771, 0.7887930870056152, 0.8052262663841248, 0.7966055870056152, 0.7947198152542114, 0.8049569129943848, 0.810883641242981, 0.8095366358757019, 0.810883641242981, 0.8133081793785095, 0.8184267282485962, 0.8160021305084229, 0.8122305870056152, 0.8157327771186829, 0.8238146305084229, 0.826508641242981, 0.8305495977401733, 0.8135775923728943, 0.8133081793785095, 0.8273168206214905, 0.829741358757019, 0.8071120977401733, 0.826777994632721, 0.8316271305084229, 0.8308189511299133, 0.8364762663841248, 0.8402478694915771, 0.8329741358757019, 0.8308189511299133, 0.8367456793785095, 0.8413254022598267, 0.8399784564971924, 0.845097005367279, 0.84375, 0.8459051847457886, 0.8480603694915771, 0.860991358757019, 0.860722005367279, 0.8542564511299133, 0.8461745977401733, 0.850215494632721, 0.8585668206214905, 0.8475215435028076, 0.842133641242981, 0.8539870977401733, 0.8537176847457886, 0.8569504022598267, 0.8599137663841248, 0.860722005367279, 0.857758641242981, 0.8782327771186829, 0.8744612336158752, 0.8634159564971924, 0.8601831793785095, 0.8566810488700867, 0.849946141242981, 0.8706896305084229, 0.8803879022598267, 0.8698814511299133, 0.860722005367279, 0.8682650923728943, 0.8774245977401733, 0.8806573152542114, 0.8744612336158752, 0.8706896305084229, 0.8787715435028076, 0.8639547228813171, 0.8758081793785095, 0.8822737336158752, 0.8868534564971924, 0.8857758641242981, 0.8941271305084229, 0.8976293206214905, 0.9038254022598267, 0.8884698152542114, 0.9038254022598267, 0.8943965435028076, 0.8925107717514038, 0.9016702771186829, 0.8981680870056152, 0.891972005367279, 0.8803879022598267, 0.9040948152542114, 0.907597005367279, 0.9089439511299133, 0.9011314511299133], 'val_loss': [0.9216774106025696, 0.9209276437759399, 0.9194844365119934, 0.9175181984901428, 0.9162342548370361, 0.913939893245697, 0.912223756313324, 0.9089802503585815, 0.9086247682571411, 0.906660258769989, 0.8994591236114502, 0.8942244052886963, 0.8874976634979248, 0.8862431645393372, 0.8744598627090454, 0.8766257166862488, 0.8652763366699219, 0.8575839400291443, 0.8365345597267151, 0.8361104726791382, 0.8301982879638672, 0.8549484610557556, 0.8328679203987122, 0.8032740950584412, 0.8085116147994995, 0.8042675256729126, 0.809314489364624, 0.8201407194137573, 0.837327778339386, 0.8304756879806519, 0.8333296775817871, 0.8889883756637573, 0.837914764881134, 0.8420714139938354, 0.9686738848686218, 0.8429294228553772, 0.8456405997276306, 0.8552749752998352, 0.85208660364151, 0.8550862073898315, 0.8569369912147522, 0.9119789004325867, 0.8657214641571045, 0.887808620929718, 0.8956998586654663, 0.9106776118278503, 0.8697400689125061, 0.8666906952857971, 0.9059557318687439, 0.8876304626464844, 0.9024021625518799, 0.8802731037139893, 0.95827716588974, 0.8880412578582764, 0.9282925724983215, 0.9550965428352356, 0.9328210353851318, 1.0094609260559082, 0.9618162512779236, 0.9626225829124451, 0.8911703824996948, 0.8983097672462463, 0.8901818990707397, 0.8936780691146851, 0.8943426012992859, 0.9018420577049255, 0.9225417971611023, 0.9897453784942627, 0.9787091612815857, 0.8887699246406555, 0.8953601121902466, 0.9041993618011475, 0.9524420499801636, 0.9079888463020325, 0.9460073709487915, 0.9153826236724854, 0.9122342467308044, 0.9179375767707825, 0.9627742171287537, 0.965013861656189, 0.916609525680542, 0.9591221213340759, 0.9519952535629272, 0.9273098111152649, 0.9287762641906738, 0.934884250164032, 0.935515820980072, 0.9901322722434998, 0.9428744316101074, 0.9545851945877075, 0.9488784670829773, 0.9542382955551147, 0.9511984586715698, 0.9609017968177795, 0.9771497249603271, 0.9544326663017273, 0.9647490382194519, 0.9926434755325317, 0.9714144468307495, 0.9651057720184326], 'val_accuracy': [0.4881465435028076, 0.48491379618644714, 0.48706895112991333, 0.48706895112991333, 0.48599138855934143, 0.4881465435028076, 0.4881465435028076, 0.5021551847457886, 0.48706895112991333, 0.4892241358757019, 0.53125, 0.556034505367279, 0.600215494632721, 0.556034505367279, 0.6174569129943848, 0.5678879022598267, 0.6066810488700867, 0.6142241358757019, 0.6584051847457886, 0.639008641242981, 0.6465517282485962, 0.6163793206214905, 0.6443965435028076, 0.6853448152542114, 0.6767241358757019, 0.6756465435028076, 0.6713362336158752, 0.6799569129943848, 0.6756465435028076, 0.6842672228813171, 0.6756465435028076, 0.662715494632721, 0.6778017282485962, 0.6821120977401733, 0.6368534564971924, 0.6831896305084229, 0.6853448152542114, 0.6853448152542114, 0.6821120977401733, 0.6918103694915771, 0.6907327771186829, 0.6670258641242981, 0.6842672228813171, 0.6767241358757019, 0.6724137663841248, 0.6540948152542114, 0.6831896305084229, 0.6864224076271057, 0.6713362336158752, 0.6821120977401733, 0.6756465435028076, 0.6821120977401733, 0.6594827771186829, 0.6788793206214905, 0.670258641242981, 0.6637930870056152, 0.6540948152542114, 0.6519396305084229, 0.6616379022598267, 0.662715494632721, 0.6788793206214905, 0.6648706793785095, 0.6756465435028076, 0.6799569129943848, 0.6767241358757019, 0.6842672228813171, 0.673491358757019, 0.6605603694915771, 0.6487069129943848, 0.6831896305084229, 0.6788793206214905, 0.6778017282485962, 0.65625, 0.6864224076271057, 0.673491358757019, 0.6842672228813171, 0.6799569129943848, 0.6788793206214905, 0.6551724076271057, 0.670258641242981, 0.6788793206214905, 0.6767241358757019, 0.6648706793785095, 0.6767241358757019, 0.6778017282485962, 0.6788793206214905, 0.6842672228813171, 0.6659482717514038, 0.6788793206214905, 0.6799569129943848, 0.6778017282485962, 0.6756465435028076, 0.6842672228813171, 0.6799569129943848, 0.6659482717514038, 0.6756465435028076, 0.6767241358757019, 0.681034505367279, 0.6799569129943848, 0.6821120977401733]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.7355 - accuracy: 0.7416"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 76ms/step - loss: 0.7361 - accuracy: 0.7402 - val_loss: 0.9211 - val_accuracy: 0.5057\n","Epoch 2/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7133 - accuracy: 0.7632 - val_loss: 0.9197 - val_accuracy: 0.5023\n","Epoch 3/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7013 - accuracy: 0.7626 - val_loss: 0.9184 - val_accuracy: 0.4989\n","Epoch 4/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.7077 - accuracy: 0.7575 - val_loss: 0.9160 - val_accuracy: 0.5124\n","Epoch 5/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.7759 - val_loss: 0.9148 - val_accuracy: 0.5000\n","Epoch 6/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7008 - accuracy: 0.7688 - val_loss: 0.9125 - val_accuracy: 0.5068\n","Epoch 7/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6839 - accuracy: 0.7767 - val_loss: 0.9105 - val_accuracy: 0.5068\n","Epoch 8/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6876 - accuracy: 0.7719 - val_loss: 0.9076 - val_accuracy: 0.5136\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6770 - accuracy: 0.7883 - val_loss: 0.9059 - val_accuracy: 0.5068\n","Epoch 10/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6810 - accuracy: 0.7801 - val_loss: 0.9019 - val_accuracy: 0.5147\n","Epoch 11/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6678 - accuracy: 0.7965 - val_loss: 0.8980 - val_accuracy: 0.5226\n","Epoch 12/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6685 - accuracy: 0.7801 - val_loss: 0.8913 - val_accuracy: 0.5916\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6733 - accuracy: 0.7824 - val_loss: 0.8870 - val_accuracy: 0.5826\n","Epoch 14/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6651 - accuracy: 0.7844 - val_loss: 0.8829 - val_accuracy: 0.5667\n","Epoch 15/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6575 - accuracy: 0.7929 - val_loss: 0.8736 - val_accuracy: 0.6233\n","Epoch 16/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6556 - accuracy: 0.7949 - val_loss: 0.8664 - val_accuracy: 0.6278\n","Epoch 17/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6503 - accuracy: 0.7920 - val_loss: 0.8623 - val_accuracy: 0.5928\n","Epoch 18/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6548 - accuracy: 0.7903 - val_loss: 0.8443 - val_accuracy: 0.6799\n","Epoch 19/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6436 - accuracy: 0.7977 - val_loss: 0.8305 - val_accuracy: 0.7025\n","Epoch 20/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6443 - accuracy: 0.7968 - val_loss: 0.8253 - val_accuracy: 0.6799\n","Epoch 21/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.6439 - accuracy: 0.7943 - val_loss: 0.8053 - val_accuracy: 0.7104\n","Epoch 22/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.6366 - accuracy: 0.8118 - val_loss: 0.7974 - val_accuracy: 0.7138\n","Epoch 23/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6278 - accuracy: 0.8056 - val_loss: 0.7932 - val_accuracy: 0.7036\n","Epoch 24/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6225 - accuracy: 0.8144 - val_loss: 0.7911 - val_accuracy: 0.7002\n","Epoch 25/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6284 - accuracy: 0.8014 - val_loss: 0.7937 - val_accuracy: 0.7014\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6210 - accuracy: 0.8022 - val_loss: 0.8261 - val_accuracy: 0.6663\n","Epoch 27/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6499 - accuracy: 0.7915 - val_loss: 0.8576 - val_accuracy: 0.6538\n","Epoch 28/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6233 - accuracy: 0.8138 - val_loss: 0.7814 - val_accuracy: 0.6799\n","Epoch 29/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6269 - accuracy: 0.8076 - val_loss: 0.7883 - val_accuracy: 0.7161\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6118 - accuracy: 0.8118 - val_loss: 0.7884 - val_accuracy: 0.7070\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6161 - accuracy: 0.8121 - val_loss: 0.8295 - val_accuracy: 0.6923\n","Epoch 32/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5999 - accuracy: 0.8158 - val_loss: 0.7931 - val_accuracy: 0.7127\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6064 - accuracy: 0.8144 - val_loss: 0.8293 - val_accuracy: 0.6708\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5994 - accuracy: 0.8203 - val_loss: 0.8123 - val_accuracy: 0.6799\n","Epoch 35/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6207 - accuracy: 0.7991 - val_loss: 0.7991 - val_accuracy: 0.7002\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5974 - accuracy: 0.8198 - val_loss: 0.7987 - val_accuracy: 0.6900\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5861 - accuracy: 0.8302 - val_loss: 0.8037 - val_accuracy: 0.7104\n","Epoch 38/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5825 - accuracy: 0.8291 - val_loss: 0.8157 - val_accuracy: 0.7206\n","Epoch 39/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5874 - accuracy: 0.8209 - val_loss: 0.8569 - val_accuracy: 0.6968\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5902 - accuracy: 0.8234 - val_loss: 0.8113 - val_accuracy: 0.6900\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5759 - accuracy: 0.8331 - val_loss: 0.8503 - val_accuracy: 0.7081\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5764 - accuracy: 0.8277 - val_loss: 0.8116 - val_accuracy: 0.7014\n","Epoch 43/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5841 - accuracy: 0.8234 - val_loss: 0.9119 - val_accuracy: 0.6663\n","Epoch 44/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5790 - accuracy: 0.8260 - val_loss: 0.8224 - val_accuracy: 0.7104\n","Epoch 45/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5766 - accuracy: 0.8322 - val_loss: 0.8124 - val_accuracy: 0.6946\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5724 - accuracy: 0.8339 - val_loss: 0.8180 - val_accuracy: 0.6912\n","Epoch 47/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5535 - accuracy: 0.8381 - val_loss: 0.8448 - val_accuracy: 0.7059\n","Epoch 48/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5539 - accuracy: 0.8441 - val_loss: 0.8290 - val_accuracy: 0.6799\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5692 - accuracy: 0.8299 - val_loss: 0.8178 - val_accuracy: 0.6934\n","Epoch 50/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5476 - accuracy: 0.8435 - val_loss: 0.8205 - val_accuracy: 0.6810\n","Epoch 51/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5436 - accuracy: 0.8503 - val_loss: 0.8325 - val_accuracy: 0.7048\n","Epoch 52/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5436 - accuracy: 0.8486 - val_loss: 0.8327 - val_accuracy: 0.7183\n","Epoch 53/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5638 - accuracy: 0.8345 - val_loss: 0.8249 - val_accuracy: 0.6923\n","Epoch 54/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5549 - accuracy: 0.8381 - val_loss: 0.8419 - val_accuracy: 0.7048\n","Epoch 55/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5377 - accuracy: 0.8520 - val_loss: 0.8347 - val_accuracy: 0.7127\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5359 - accuracy: 0.8526 - val_loss: 0.8308 - val_accuracy: 0.6787\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5335 - accuracy: 0.8537 - val_loss: 0.8433 - val_accuracy: 0.6753\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5331 - accuracy: 0.8472 - val_loss: 0.8499 - val_accuracy: 0.7059\n","Epoch 59/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5272 - accuracy: 0.8580 - val_loss: 0.8983 - val_accuracy: 0.6753\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5308 - accuracy: 0.8478 - val_loss: 0.8366 - val_accuracy: 0.6889\n","Epoch 61/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5232 - accuracy: 0.8633 - val_loss: 0.8442 - val_accuracy: 0.6991\n","Epoch 62/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5312 - accuracy: 0.8486 - val_loss: 0.8535 - val_accuracy: 0.6799\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5385 - accuracy: 0.8432 - val_loss: 0.8385 - val_accuracy: 0.6912\n","Epoch 64/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5258 - accuracy: 0.8571 - val_loss: 0.8465 - val_accuracy: 0.7104\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5109 - accuracy: 0.8645 - val_loss: 0.9065 - val_accuracy: 0.6742\n","Epoch 66/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5161 - accuracy: 0.8565 - val_loss: 0.8451 - val_accuracy: 0.7059\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5102 - accuracy: 0.8681 - val_loss: 0.8578 - val_accuracy: 0.6821\n","Epoch 68/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5153 - accuracy: 0.8650 - val_loss: 0.8595 - val_accuracy: 0.7036\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4912 - accuracy: 0.8763 - val_loss: 0.8522 - val_accuracy: 0.7025\n","Epoch 70/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4931 - accuracy: 0.8664 - val_loss: 0.8819 - val_accuracy: 0.6742\n","Epoch 71/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5019 - accuracy: 0.8664 - val_loss: 0.8611 - val_accuracy: 0.6968\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4963 - accuracy: 0.8701 - val_loss: 0.8693 - val_accuracy: 0.6844\n","Epoch 73/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5208 - accuracy: 0.8531 - val_loss: 0.8845 - val_accuracy: 0.7002\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5085 - accuracy: 0.8602 - val_loss: 0.8916 - val_accuracy: 0.6697\n","Epoch 75/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4908 - accuracy: 0.8707 - val_loss: 0.8818 - val_accuracy: 0.7036\n","Epoch 76/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4764 - accuracy: 0.8763 - val_loss: 0.8682 - val_accuracy: 0.6980\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4727 - accuracy: 0.8820 - val_loss: 0.8797 - val_accuracy: 0.6991\n","Epoch 78/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5054 - accuracy: 0.8565 - val_loss: 1.0146 - val_accuracy: 0.6584\n","Epoch 79/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4945 - accuracy: 0.8679 - val_loss: 0.8976 - val_accuracy: 0.6991\n","Epoch 80/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4959 - accuracy: 0.8636 - val_loss: 0.8836 - val_accuracy: 0.6810\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4697 - accuracy: 0.8857 - val_loss: 0.8848 - val_accuracy: 0.7025\n","Epoch 82/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4824 - accuracy: 0.8738 - val_loss: 0.9423 - val_accuracy: 0.6980\n","Epoch 83/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4787 - accuracy: 0.8783 - val_loss: 0.8817 - val_accuracy: 0.6946\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4720 - accuracy: 0.8789 - val_loss: 0.9204 - val_accuracy: 0.6652\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4551 - accuracy: 0.8899 - val_loss: 0.9219 - val_accuracy: 0.6742\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4552 - accuracy: 0.8933 - val_loss: 0.8921 - val_accuracy: 0.6923\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4649 - accuracy: 0.8871 - val_loss: 0.9674 - val_accuracy: 0.6765\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4591 - accuracy: 0.8865 - val_loss: 0.9149 - val_accuracy: 0.7014\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4557 - accuracy: 0.8877 - val_loss: 0.9687 - val_accuracy: 0.6719\n","Epoch 90/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4756 - accuracy: 0.8684 - val_loss: 1.0219 - val_accuracy: 0.6787\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4774 - accuracy: 0.8710 - val_loss: 0.9035 - val_accuracy: 0.7036\n","Epoch 92/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4337 - accuracy: 0.8967 - val_loss: 0.9010 - val_accuracy: 0.6923\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4435 - accuracy: 0.8925 - val_loss: 0.9119 - val_accuracy: 0.6900\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4425 - accuracy: 0.8882 - val_loss: 0.9855 - val_accuracy: 0.6934\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4528 - accuracy: 0.8942 - val_loss: 0.9175 - val_accuracy: 0.6855\n","Epoch 96/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4337 - accuracy: 0.9001 - val_loss: 0.9124 - val_accuracy: 0.6912\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4239 - accuracy: 0.9055 - val_loss: 0.9208 - val_accuracy: 0.6991\n","Epoch 98/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4291 - accuracy: 0.9041 - val_loss: 0.9325 - val_accuracy: 0.6934\n","Epoch 99/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4208 - accuracy: 0.9018 - val_loss: 0.9344 - val_accuracy: 0.6991\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4543 - accuracy: 0.8820 - val_loss: 1.0210 - val_accuracy: 0.6867\n","{'loss': [0.7361321449279785, 0.713347315788269, 0.7013429403305054, 0.7076683640480042, 0.6931278705596924, 0.7007567286491394, 0.6838878393173218, 0.6875547766685486, 0.6770013570785522, 0.680980384349823, 0.6677969694137573, 0.6684516668319702, 0.6732705235481262, 0.6651031970977783, 0.6574742197990417, 0.6556444764137268, 0.6502821445465088, 0.6548080444335938, 0.6436304450035095, 0.6442514061927795, 0.6438742876052856, 0.636562705039978, 0.6278127431869507, 0.62251216173172, 0.6284403800964355, 0.6210153698921204, 0.6499436497688293, 0.6233088374137878, 0.6268976926803589, 0.6117501258850098, 0.6160519123077393, 0.5998877286911011, 0.6063950061798096, 0.5994125604629517, 0.6207361221313477, 0.597396969795227, 0.5861368775367737, 0.5825337171554565, 0.5873690247535706, 0.590214729309082, 0.5758830904960632, 0.5764098167419434, 0.5840926170349121, 0.5789836645126343, 0.5765888094902039, 0.5724323987960815, 0.5534510612487793, 0.5538859963417053, 0.5692456364631653, 0.5476169586181641, 0.543590247631073, 0.5435751676559448, 0.563759446144104, 0.5548861026763916, 0.537721574306488, 0.535862922668457, 0.53353351354599, 0.5331277847290039, 0.5271502733230591, 0.5307955145835876, 0.5231931805610657, 0.5312390327453613, 0.5384841561317444, 0.5257529616355896, 0.5108819007873535, 0.5161387920379639, 0.510243833065033, 0.5152817368507385, 0.49122828245162964, 0.4930517077445984, 0.5019232630729675, 0.496254026889801, 0.5207688212394714, 0.5084595084190369, 0.49077799916267395, 0.4764028489589691, 0.47270292043685913, 0.5053662657737732, 0.4945070147514343, 0.4958837330341339, 0.4697142541408539, 0.48244166374206543, 0.4786531329154968, 0.4719538688659668, 0.4550755023956299, 0.4552125930786133, 0.4648665487766266, 0.4590778350830078, 0.4557400941848755, 0.4755796492099762, 0.47739019989967346, 0.43374332785606384, 0.44346997141838074, 0.4425181746482849, 0.4528244733810425, 0.4337192475795746, 0.42388468980789185, 0.4290540814399719, 0.4208308160305023, 0.45431074500083923], 'accuracy': [0.7402377128601074, 0.7631579041481018, 0.7625919580459595, 0.757498562335968, 0.7758913636207581, 0.7688171863555908, 0.7767402529716492, 0.7719298005104065, 0.7883418202400208, 0.7801358103752136, 0.7965478301048279, 0.7801358103752136, 0.7823995351791382, 0.784380316734314, 0.7928692698478699, 0.7948500514030457, 0.7920203804969788, 0.7903226017951965, 0.7976796627044678, 0.7968307733535767, 0.7942841053009033, 0.8118279576301575, 0.8056027293205261, 0.8143746256828308, 0.8013582229614258, 0.8022071123123169, 0.7914544343948364, 0.8138087391853333, 0.8075834512710571, 0.8118279576301575, 0.8121109008789062, 0.8157894611358643, 0.8143746256828308, 0.8203169107437134, 0.7990944981575012, 0.819750964641571, 0.8302206993103027, 0.8290888667106628, 0.8208828568458557, 0.823429524898529, 0.8330503702163696, 0.8276740312576294, 0.823429524898529, 0.8259762525558472, 0.8322014808654785, 0.8338992595672607, 0.8381437659263611, 0.8440860509872437, 0.829937756061554, 0.8435201048851013, 0.850311279296875, 0.848613440990448, 0.8344652056694031, 0.8381437659263611, 0.8520090579986572, 0.8525750041007996, 0.8537068367004395, 0.8471986651420593, 0.8579513430595398, 0.8477645516395569, 0.86332768201828, 0.848613440990448, 0.8432371020317078, 0.8571024537086487, 0.8644595146179199, 0.8565365076065063, 0.8681380748748779, 0.8650254607200623, 0.8763440847396851, 0.8664402961730957, 0.8664402961730957, 0.8701188564300537, 0.8531408905982971, 0.8602150678634644, 0.870684802532196, 0.8763440847396851, 0.8820033669471741, 0.8565365076065063, 0.8678551316261292, 0.8636106252670288, 0.8856819272041321, 0.8737974166870117, 0.8783248662948608, 0.8788907527923584, 0.8899264335632324, 0.8933219909667969, 0.8870967626571655, 0.8865308165550232, 0.8876627087593079, 0.8684210777282715, 0.8709677457809448, 0.8967176079750061, 0.8924731016159058, 0.8882286548614502, 0.8941709399223328, 0.9001131653785706, 0.9054895043373108, 0.9040747284889221, 0.9018110036849976, 0.8820033669471741], 'val_loss': [0.9210543632507324, 0.9197365641593933, 0.9184009432792664, 0.9159807562828064, 0.9148343205451965, 0.9125139713287354, 0.9104996919631958, 0.9076035618782043, 0.9058586359024048, 0.9019244909286499, 0.8980070352554321, 0.8913164138793945, 0.887009859085083, 0.8829111456871033, 0.8735575675964355, 0.866447925567627, 0.8622907400131226, 0.8442625999450684, 0.8305246829986572, 0.8252556324005127, 0.8052820563316345, 0.7973732948303223, 0.7932226061820984, 0.7911354303359985, 0.7936539649963379, 0.8261431455612183, 0.8575581908226013, 0.781429648399353, 0.7883251309394836, 0.7883960008621216, 0.8295167684555054, 0.7931418418884277, 0.8292685151100159, 0.8123475909233093, 0.7990623116493225, 0.7986997961997986, 0.8037132620811462, 0.8157423734664917, 0.8569251298904419, 0.8113065958023071, 0.8502641916275024, 0.8116374015808105, 0.911858320236206, 0.8223738074302673, 0.8123791217803955, 0.8179721832275391, 0.8448401689529419, 0.8289771676063538, 0.8177850246429443, 0.8205260634422302, 0.8324680924415588, 0.8326602578163147, 0.8248639106750488, 0.8419322967529297, 0.8347046375274658, 0.8308271169662476, 0.8432660698890686, 0.8498700261116028, 0.8982837796211243, 0.8365530967712402, 0.8441635966300964, 0.8534599542617798, 0.8384861350059509, 0.8465219736099243, 0.9064687490463257, 0.8451396822929382, 0.8577597737312317, 0.8595143556594849, 0.8521616458892822, 0.8818545937538147, 0.8610889315605164, 0.8693450093269348, 0.8844984173774719, 0.8916099071502686, 0.8818292617797852, 0.8681759238243103, 0.8796709775924683, 1.0145890712738037, 0.8976206183433533, 0.8835633993148804, 0.8848481774330139, 0.9423251152038574, 0.8816677927970886, 0.9204283952713013, 0.9219185709953308, 0.8921017050743103, 0.9673741459846497, 0.9148892164230347, 0.9686545133590698, 1.0219223499298096, 0.9034972190856934, 0.9010027647018433, 0.9118862748146057, 0.9855002760887146, 0.9174736738204956, 0.9124159812927246, 0.920750617980957, 0.9325300455093384, 0.9343600869178772, 1.0210057497024536], 'val_accuracy': [0.5056561231613159, 0.5022624731063843, 0.49886876344680786, 0.5124434232711792, 0.5, 0.5067873597145081, 0.5067873597145081, 0.5135746598243713, 0.5067873597145081, 0.5147058963775635, 0.5226244330406189, 0.5916289687156677, 0.5825791954994202, 0.5667420625686646, 0.6233031749725342, 0.627828061580658, 0.5927602052688599, 0.679864227771759, 0.7024886608123779, 0.679864227771759, 0.7104072570800781, 0.7138009071350098, 0.7036198973655701, 0.7002262473106384, 0.7013574838638306, 0.6662895679473877, 0.6538461446762085, 0.679864227771759, 0.7160633206367493, 0.7070135474205017, 0.692307710647583, 0.7126696705818176, 0.6708144545555115, 0.679864227771759, 0.7002262473106384, 0.6900452375411987, 0.7104072570800781, 0.720588207244873, 0.6968325972557068, 0.6900452375411987, 0.7081447839736938, 0.7013574838638306, 0.6662895679473877, 0.7104072570800781, 0.6945701241493225, 0.6911764740943909, 0.7058823704719543, 0.679864227771759, 0.6934388875961304, 0.6809954643249512, 0.7047511339187622, 0.7183257937431335, 0.692307710647583, 0.7047511339187622, 0.7126696705818176, 0.6787330508232117, 0.6753393411636353, 0.7058823704719543, 0.6753393411636353, 0.6889140009880066, 0.6990950107574463, 0.679864227771759, 0.6911764740943909, 0.7104072570800781, 0.6742081642150879, 0.7058823704719543, 0.6821267008781433, 0.7036198973655701, 0.7024886608123779, 0.6742081642150879, 0.6968325972557068, 0.6843891143798828, 0.7002262473106384, 0.6696832776069641, 0.7036198973655701, 0.6979637742042542, 0.6990950107574463, 0.6583710312843323, 0.6990950107574463, 0.6809954643249512, 0.7024886608123779, 0.6979637742042542, 0.6945701241493225, 0.6651583909988403, 0.6742081642150879, 0.692307710647583, 0.6764705777168274, 0.7013574838638306, 0.6719456911087036, 0.6787330508232117, 0.7036198973655701, 0.692307710647583, 0.6900452375411987, 0.6934388875961304, 0.685520350933075, 0.6911764740943909, 0.6990950107574463, 0.6934388875961304, 0.6990950107574463, 0.6866515874862671]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.7312 - accuracy: 0.7480"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 57ms/step - loss: 0.7306 - accuracy: 0.7488 - val_loss: 0.9223 - val_accuracy: 0.4917\n","Epoch 2/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7345 - accuracy: 0.7483 - val_loss: 0.9216 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7150 - accuracy: 0.7620 - val_loss: 0.9205 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6988 - accuracy: 0.7659 - val_loss: 0.9184 - val_accuracy: 0.4907\n","Epoch 5/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6926 - accuracy: 0.7767 - val_loss: 0.9167 - val_accuracy: 0.4928\n","Epoch 6/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7052 - accuracy: 0.7610 - val_loss: 0.9154 - val_accuracy: 0.4928\n","Epoch 7/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6913 - accuracy: 0.7775 - val_loss: 0.9130 - val_accuracy: 0.4959\n","Epoch 8/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6832 - accuracy: 0.7780 - val_loss: 0.9103 - val_accuracy: 0.5031\n","Epoch 9/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6777 - accuracy: 0.7835 - val_loss: 0.9120 - val_accuracy: 0.4907\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6807 - accuracy: 0.7780 - val_loss: 0.9064 - val_accuracy: 0.5031\n","Epoch 11/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6749 - accuracy: 0.7780 - val_loss: 0.9038 - val_accuracy: 0.5072\n","Epoch 12/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6642 - accuracy: 0.7863 - val_loss: 0.8986 - val_accuracy: 0.5289\n","Epoch 13/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6729 - accuracy: 0.7791 - val_loss: 0.8957 - val_accuracy: 0.5300\n","Epoch 14/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6639 - accuracy: 0.7910 - val_loss: 0.8960 - val_accuracy: 0.5217\n","Epoch 15/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6650 - accuracy: 0.7876 - val_loss: 0.8864 - val_accuracy: 0.5682\n","Epoch 16/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6610 - accuracy: 0.7814 - val_loss: 0.8822 - val_accuracy: 0.5744\n","Epoch 17/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6616 - accuracy: 0.7879 - val_loss: 0.8800 - val_accuracy: 0.5775\n","Epoch 18/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6460 - accuracy: 0.7995 - val_loss: 0.8822 - val_accuracy: 0.5764\n","Epoch 19/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6506 - accuracy: 0.7871 - val_loss: 0.8701 - val_accuracy: 0.6043\n","Epoch 20/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6424 - accuracy: 0.7979 - val_loss: 0.8701 - val_accuracy: 0.6147\n","Epoch 21/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6377 - accuracy: 0.8021 - val_loss: 0.8772 - val_accuracy: 0.6126\n","Epoch 22/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6389 - accuracy: 0.7977 - val_loss: 0.8870 - val_accuracy: 0.6136\n","Epoch 23/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.6374 - accuracy: 0.7984 - val_loss: 0.8635 - val_accuracy: 0.6457\n","Epoch 24/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6381 - accuracy: 0.7992 - val_loss: 0.8748 - val_accuracy: 0.6353\n","Epoch 25/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.6303 - accuracy: 0.7969 - val_loss: 0.8801 - val_accuracy: 0.6488\n","Epoch 26/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6192 - accuracy: 0.8119 - val_loss: 0.8866 - val_accuracy: 0.6508\n","Epoch 27/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6188 - accuracy: 0.8101 - val_loss: 0.9404 - val_accuracy: 0.6157\n","Epoch 28/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6264 - accuracy: 0.8062 - val_loss: 0.8975 - val_accuracy: 0.6498\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6175 - accuracy: 0.8047 - val_loss: 0.9095 - val_accuracy: 0.6384\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6130 - accuracy: 0.8075 - val_loss: 0.9203 - val_accuracy: 0.6291\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6240 - accuracy: 0.7964 - val_loss: 0.9171 - val_accuracy: 0.6457\n","Epoch 32/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6072 - accuracy: 0.8116 - val_loss: 0.9245 - val_accuracy: 0.6395\n","Epoch 33/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6034 - accuracy: 0.8134 - val_loss: 0.9341 - val_accuracy: 0.6322\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6026 - accuracy: 0.8171 - val_loss: 0.9418 - val_accuracy: 0.6322\n","Epoch 35/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6117 - accuracy: 0.8129 - val_loss: 0.9941 - val_accuracy: 0.6302\n","Epoch 36/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5898 - accuracy: 0.8217 - val_loss: 0.9316 - val_accuracy: 0.6436\n","Epoch 37/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5906 - accuracy: 0.8256 - val_loss: 0.9341 - val_accuracy: 0.6477\n","Epoch 38/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5833 - accuracy: 0.8269 - val_loss: 0.9537 - val_accuracy: 0.6302\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5857 - accuracy: 0.8212 - val_loss: 0.9657 - val_accuracy: 0.6333\n","Epoch 40/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5784 - accuracy: 0.8266 - val_loss: 0.9665 - val_accuracy: 0.6333\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5848 - accuracy: 0.8264 - val_loss: 0.9542 - val_accuracy: 0.6312\n","Epoch 42/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5761 - accuracy: 0.8284 - val_loss: 0.9507 - val_accuracy: 0.6415\n","Epoch 43/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5788 - accuracy: 0.8253 - val_loss: 1.0512 - val_accuracy: 0.6116\n","Epoch 44/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5727 - accuracy: 0.8315 - val_loss: 0.9669 - val_accuracy: 0.6446\n","Epoch 45/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5658 - accuracy: 0.8341 - val_loss: 1.0334 - val_accuracy: 0.6188\n","Epoch 46/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5596 - accuracy: 0.8372 - val_loss: 0.9614 - val_accuracy: 0.6322\n","Epoch 47/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5744 - accuracy: 0.8261 - val_loss: 1.0187 - val_accuracy: 0.6219\n","Epoch 48/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5831 - accuracy: 0.8168 - val_loss: 0.9780 - val_accuracy: 0.6333\n","Epoch 49/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5514 - accuracy: 0.8447 - val_loss: 1.0014 - val_accuracy: 0.6291\n","Epoch 50/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5453 - accuracy: 0.8460 - val_loss: 0.9867 - val_accuracy: 0.6333\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5489 - accuracy: 0.8419 - val_loss: 0.9675 - val_accuracy: 0.6426\n","Epoch 52/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5556 - accuracy: 0.8372 - val_loss: 0.9773 - val_accuracy: 0.6467\n","Epoch 53/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5367 - accuracy: 0.8468 - val_loss: 0.9700 - val_accuracy: 0.6457\n","Epoch 54/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5452 - accuracy: 0.8359 - val_loss: 1.0566 - val_accuracy: 0.6116\n","Epoch 55/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5423 - accuracy: 0.8434 - val_loss: 0.9736 - val_accuracy: 0.6436\n","Epoch 56/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5392 - accuracy: 0.8475 - val_loss: 0.9999 - val_accuracy: 0.6312\n","Epoch 57/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5356 - accuracy: 0.8444 - val_loss: 1.0349 - val_accuracy: 0.6240\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5309 - accuracy: 0.8579 - val_loss: 0.9857 - val_accuracy: 0.6436\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5202 - accuracy: 0.8610 - val_loss: 0.9907 - val_accuracy: 0.6384\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5411 - accuracy: 0.8377 - val_loss: 0.9959 - val_accuracy: 0.6426\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5200 - accuracy: 0.8574 - val_loss: 1.0121 - val_accuracy: 0.6333\n","Epoch 62/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5125 - accuracy: 0.8584 - val_loss: 1.0039 - val_accuracy: 0.6322\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5107 - accuracy: 0.8643 - val_loss: 1.0134 - val_accuracy: 0.6343\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5101 - accuracy: 0.8643 - val_loss: 1.0259 - val_accuracy: 0.6343\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5034 - accuracy: 0.8651 - val_loss: 1.0351 - val_accuracy: 0.6271\n","Epoch 66/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5402 - accuracy: 0.8359 - val_loss: 1.1295 - val_accuracy: 0.6095\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5026 - accuracy: 0.8649 - val_loss: 1.0670 - val_accuracy: 0.6343\n","Epoch 68/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4948 - accuracy: 0.8700 - val_loss: 1.0351 - val_accuracy: 0.6302\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4981 - accuracy: 0.8656 - val_loss: 1.0305 - val_accuracy: 0.6395\n","Epoch 70/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5078 - accuracy: 0.8566 - val_loss: 1.0373 - val_accuracy: 0.6302\n","Epoch 71/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4895 - accuracy: 0.8721 - val_loss: 1.0267 - val_accuracy: 0.6384\n","Epoch 72/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4848 - accuracy: 0.8749 - val_loss: 1.2337 - val_accuracy: 0.5930\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5238 - accuracy: 0.8504 - val_loss: 1.1371 - val_accuracy: 0.6074\n","Epoch 74/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4821 - accuracy: 0.8724 - val_loss: 1.0516 - val_accuracy: 0.6219\n","Epoch 75/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4987 - accuracy: 0.8620 - val_loss: 1.0416 - val_accuracy: 0.6395\n","Epoch 76/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4884 - accuracy: 0.8708 - val_loss: 1.0421 - val_accuracy: 0.6374\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4794 - accuracy: 0.8819 - val_loss: 1.0333 - val_accuracy: 0.6467\n","Epoch 78/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4786 - accuracy: 0.8760 - val_loss: 1.0394 - val_accuracy: 0.6467\n","Epoch 79/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4692 - accuracy: 0.8835 - val_loss: 1.0557 - val_accuracy: 0.6353\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4904 - accuracy: 0.8669 - val_loss: 1.0443 - val_accuracy: 0.6426\n","Epoch 81/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4756 - accuracy: 0.8770 - val_loss: 1.0470 - val_accuracy: 0.6446\n","Epoch 82/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4678 - accuracy: 0.8783 - val_loss: 1.0575 - val_accuracy: 0.6446\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4627 - accuracy: 0.8863 - val_loss: 1.0568 - val_accuracy: 0.6384\n","Epoch 84/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4648 - accuracy: 0.8811 - val_loss: 1.0557 - val_accuracy: 0.6353\n","Epoch 85/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4543 - accuracy: 0.8871 - val_loss: 1.0598 - val_accuracy: 0.6415\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4531 - accuracy: 0.8897 - val_loss: 1.1082 - val_accuracy: 0.6302\n","Epoch 87/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4803 - accuracy: 0.8669 - val_loss: 1.2140 - val_accuracy: 0.6085\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4657 - accuracy: 0.8814 - val_loss: 1.1706 - val_accuracy: 0.6095\n","Epoch 89/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4472 - accuracy: 0.8902 - val_loss: 1.0703 - val_accuracy: 0.6488\n","Epoch 90/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4579 - accuracy: 0.8868 - val_loss: 1.0750 - val_accuracy: 0.6457\n","Epoch 91/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4376 - accuracy: 0.8928 - val_loss: 1.0904 - val_accuracy: 0.6405\n","Epoch 92/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4417 - accuracy: 0.8915 - val_loss: 1.1111 - val_accuracy: 0.6374\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4409 - accuracy: 0.8951 - val_loss: 1.0980 - val_accuracy: 0.6436\n","Epoch 94/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4685 - accuracy: 0.8713 - val_loss: 1.0987 - val_accuracy: 0.6343\n","Epoch 95/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4489 - accuracy: 0.8837 - val_loss: 1.1322 - val_accuracy: 0.6219\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4360 - accuracy: 0.8992 - val_loss: 1.0933 - val_accuracy: 0.6426\n","Epoch 97/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4383 - accuracy: 0.8964 - val_loss: 1.1333 - val_accuracy: 0.6374\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4378 - accuracy: 0.8902 - val_loss: 1.1350 - val_accuracy: 0.6281\n","Epoch 99/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4281 - accuracy: 0.8964 - val_loss: 1.1200 - val_accuracy: 0.6364\n","Epoch 100/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4238 - accuracy: 0.8982 - val_loss: 1.1352 - val_accuracy: 0.6364\n","{'loss': [0.7306056022644043, 0.7345036864280701, 0.7149854302406311, 0.6987976431846619, 0.6926190257072449, 0.7052238583564758, 0.6913336515426636, 0.6832223534584045, 0.6777375340461731, 0.6807018518447876, 0.6748715043067932, 0.6642093658447266, 0.6728922128677368, 0.6639209389686584, 0.6650486588478088, 0.660958468914032, 0.6616004109382629, 0.6460174322128296, 0.650600016117096, 0.6423578858375549, 0.637697160243988, 0.638917863368988, 0.637393057346344, 0.6380577087402344, 0.630316436290741, 0.6191560626029968, 0.6188141703605652, 0.6264076232910156, 0.617466926574707, 0.6130049228668213, 0.6239772439002991, 0.6071597337722778, 0.6033504605293274, 0.6025932431221008, 0.6116530895233154, 0.5898154377937317, 0.5905879139900208, 0.5832942724227905, 0.5856987833976746, 0.5783808827400208, 0.5848070979118347, 0.5761236548423767, 0.5787535905838013, 0.5727439522743225, 0.5657871961593628, 0.5596222281455994, 0.5743914246559143, 0.5830973982810974, 0.5513550639152527, 0.5452556014060974, 0.5488841533660889, 0.555602490901947, 0.536676824092865, 0.5452059507369995, 0.5423253178596497, 0.5392047762870789, 0.5355831980705261, 0.5309175848960876, 0.5201837420463562, 0.5411434173583984, 0.5199615359306335, 0.5125221610069275, 0.5106925964355469, 0.5100769996643066, 0.503446638584137, 0.5401798486709595, 0.5026184320449829, 0.49481379985809326, 0.4981268048286438, 0.5077710151672363, 0.4895217716693878, 0.48480430245399475, 0.5238266587257385, 0.48208141326904297, 0.4987056851387024, 0.4883701503276825, 0.47942084074020386, 0.4786151349544525, 0.46924635767936707, 0.49035772681236267, 0.4755747616291046, 0.4678296148777008, 0.46266302466392517, 0.4647761881351471, 0.4542534053325653, 0.4530719220638275, 0.4803217649459839, 0.4657197892665863, 0.4471990168094635, 0.45785364508628845, 0.4376404285430908, 0.44173917174339294, 0.44090476632118225, 0.468515008687973, 0.44888368248939514, 0.43600359559059143, 0.4382656216621399, 0.4378429055213928, 0.4280775189399719, 0.42381903529167175], 'accuracy': [0.7488372325897217, 0.7483204007148743, 0.7620155215263367, 0.7658914923667908, 0.7767441868782043, 0.7609819173812866, 0.7775194048881531, 0.7780361771583557, 0.7834625244140625, 0.7780361771583557, 0.7780361771583557, 0.7863048911094666, 0.7790697813034058, 0.7909560799598694, 0.7875968813896179, 0.7813953757286072, 0.7878552675247192, 0.7994831800460815, 0.7870801091194153, 0.7979328036308289, 0.8020671606063843, 0.7976744174957275, 0.7984496355056763, 0.7992247939109802, 0.7968991994857788, 0.8118863105773926, 0.8100775480270386, 0.8062015771865845, 0.804651141166687, 0.8074935674667358, 0.7963824272155762, 0.8116279244422913, 0.8134366869926453, 0.817054271697998, 0.8129199147224426, 0.8217054009437561, 0.8255813717842102, 0.8268733620643616, 0.8211886286735535, 0.8266149759292603, 0.8263565897941589, 0.828423798084259, 0.8253229856491089, 0.8315245509147644, 0.8341085314750671, 0.8372092843055725, 0.8260982036590576, 0.8167958855628967, 0.8447028398513794, 0.8459948301315308, 0.8418604731559753, 0.8372092843055725, 0.8467700481414795, 0.8359172940254211, 0.843410849571228, 0.8475452065467834, 0.8444444537162781, 0.8578811287879944, 0.8609819412231445, 0.8377261161804199, 0.8573643565177917, 0.8583979606628418, 0.8643410801887512, 0.8643410801887512, 0.8651162981987, 0.8359172940254211, 0.8648578524589539, 0.8700258135795593, 0.8656330704689026, 0.856589138507843, 0.8720930218696594, 0.8749353885650635, 0.8503875732421875, 0.8723514080047607, 0.8620154857635498, 0.8708010315895081, 0.8819121718406677, 0.8759689927101135, 0.8834625482559204, 0.866925060749054, 0.8770025968551636, 0.8782945871353149, 0.8863049149513245, 0.881136953830719, 0.8870801329612732, 0.8896640539169312, 0.866925060749054, 0.8813953399658203, 0.8901808857917786, 0.8868216872215271, 0.8927648663520813, 0.8914728760719299, 0.8950904607772827, 0.8713178038597107, 0.8837209343910217, 0.8992248177528381, 0.8963824510574341, 0.8901808857917786, 0.8963824510574341, 0.8981912136077881], 'val_loss': [0.922284722328186, 0.9216443300247192, 0.9204714894294739, 0.9183846712112427, 0.9167225956916809, 0.915397047996521, 0.9129749536514282, 0.9102533459663391, 0.912045419216156, 0.9064463376998901, 0.9037616848945618, 0.8985617160797119, 0.8957492709159851, 0.8959939479827881, 0.8864188194274902, 0.882159948348999, 0.8799785375595093, 0.8822322487831116, 0.8700690865516663, 0.8700776100158691, 0.8771637678146362, 0.8869526982307434, 0.863480806350708, 0.8748226165771484, 0.8801031708717346, 0.8865840435028076, 0.9403923749923706, 0.897535502910614, 0.9095485210418701, 0.9202651381492615, 0.9171249866485596, 0.9244825839996338, 0.9340692162513733, 0.9418267607688904, 0.9940900206565857, 0.9315693974494934, 0.9341086149215698, 0.9537241458892822, 0.9656623601913452, 0.9665427803993225, 0.9541501402854919, 0.9507278800010681, 1.0511976480484009, 0.9669166207313538, 1.0334376096725464, 0.9613619446754456, 1.018709659576416, 0.978007435798645, 1.00136399269104, 0.9866694808006287, 0.9675138592720032, 0.977327823638916, 0.9699890613555908, 1.0566246509552002, 0.9736185669898987, 0.9999104738235474, 1.0349427461624146, 0.9857133030891418, 0.9906898736953735, 0.9959343075752258, 1.012090802192688, 1.0039317607879639, 1.0133780241012573, 1.0259218215942383, 1.0351125001907349, 1.1295009851455688, 1.0670430660247803, 1.0350701808929443, 1.0304691791534424, 1.0373152494430542, 1.0266574621200562, 1.2337357997894287, 1.1371268033981323, 1.0515810251235962, 1.0415544509887695, 1.0420893430709839, 1.0333467721939087, 1.03939688205719, 1.0557217597961426, 1.0442895889282227, 1.0469880104064941, 1.0575143098831177, 1.0568419694900513, 1.0556902885437012, 1.0597846508026123, 1.1082205772399902, 1.2139759063720703, 1.170591950416565, 1.0702729225158691, 1.0750318765640259, 1.0903750658035278, 1.1111139059066772, 1.0980154275894165, 1.098698377609253, 1.1322252750396729, 1.0933411121368408, 1.1332874298095703, 1.1349565982818604, 1.120034098625183, 1.1352064609527588], 'val_accuracy': [0.4917355477809906, 0.48553720116615295, 0.48553720116615295, 0.49070248007774353, 0.4927685856819153, 0.4927685856819153, 0.4958677589893341, 0.5030992031097412, 0.49070248007774353, 0.5030992031097412, 0.5072314143180847, 0.5289255976676941, 0.5299586653709412, 0.5216942429542542, 0.5681818127632141, 0.5743801593780518, 0.577479362487793, 0.5764462947845459, 0.6043388247489929, 0.6146694421768188, 0.6126033067703247, 0.6136363744735718, 0.6456611752510071, 0.6353305578231812, 0.6487603187561035, 0.6508264541625977, 0.6157024502754211, 0.6497933864593506, 0.6384297609329224, 0.6291322112083435, 0.6456611752510071, 0.6394628286361694, 0.6322314143180847, 0.6322314143180847, 0.6301652789115906, 0.6435950398445129, 0.6477272510528564, 0.6301652789115906, 0.6332644820213318, 0.6332644820213318, 0.6311983466148376, 0.6415289044380188, 0.6115702390670776, 0.64462810754776, 0.6188016533851624, 0.6322314143180847, 0.6219007968902588, 0.6332644820213318, 0.6291322112083435, 0.6332644820213318, 0.6425619721412659, 0.6466942429542542, 0.6456611752510071, 0.6115702390670776, 0.6435950398445129, 0.6311983466148376, 0.6239669322967529, 0.6435950398445129, 0.6384297609329224, 0.6425619721412659, 0.6332644820213318, 0.6322314143180847, 0.6342975497245789, 0.6342975497245789, 0.6270661354064941, 0.6095041036605835, 0.6342975497245789, 0.6301652789115906, 0.6394628286361694, 0.6301652789115906, 0.6384297609329224, 0.5929751992225647, 0.6074380278587341, 0.6219007968902588, 0.6394628286361694, 0.6373966932296753, 0.6466942429542542, 0.6466942429542542, 0.6353305578231812, 0.6425619721412659, 0.64462810754776, 0.64462810754776, 0.6384297609329224, 0.6353305578231812, 0.6415289044380188, 0.6301652789115906, 0.6084710955619812, 0.6095041036605835, 0.6487603187561035, 0.6456611752510071, 0.6404958963394165, 0.6373966932296753, 0.6435950398445129, 0.6342975497245789, 0.6219007968902588, 0.6425619721412659, 0.6373966932296753, 0.6280992031097412, 0.6363636255264282, 0.6363636255264282]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.5717 - accuracy: 0.8296"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 8s 73ms/step - loss: 0.5667 - accuracy: 0.8324 - val_loss: 0.8838 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4951 - accuracy: 0.8699 - val_loss: 0.8847 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4960 - accuracy: 0.8723 - val_loss: 0.8836 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4989 - accuracy: 0.8637 - val_loss: 0.8843 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4809 - accuracy: 0.8720 - val_loss: 0.8826 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5003 - accuracy: 0.8623 - val_loss: 0.8799 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4900 - accuracy: 0.8675 - val_loss: 0.8767 - val_accuracy: 0.4860\n","Epoch 8/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4694 - accuracy: 0.8825 - val_loss: 0.8784 - val_accuracy: 0.4860\n","Epoch 9/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4882 - accuracy: 0.8661 - val_loss: 0.8770 - val_accuracy: 0.4860\n","Epoch 10/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4714 - accuracy: 0.8820 - val_loss: 0.8661 - val_accuracy: 0.4903\n","Epoch 11/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4652 - accuracy: 0.8834 - val_loss: 0.8674 - val_accuracy: 0.4914\n","Epoch 12/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4707 - accuracy: 0.8739 - val_loss: 0.8538 - val_accuracy: 0.5043\n","Epoch 13/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4651 - accuracy: 0.8807 - val_loss: 0.8506 - val_accuracy: 0.5054\n","Epoch 14/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4569 - accuracy: 0.8823 - val_loss: 0.8517 - val_accuracy: 0.5086\n","Epoch 15/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4561 - accuracy: 0.8825 - val_loss: 0.8381 - val_accuracy: 0.5334\n","Epoch 16/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4569 - accuracy: 0.8871 - val_loss: 0.8201 - val_accuracy: 0.5625\n","Epoch 17/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4541 - accuracy: 0.8844 - val_loss: 0.8321 - val_accuracy: 0.5496\n","Epoch 18/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4595 - accuracy: 0.8828 - val_loss: 0.7748 - val_accuracy: 0.6584\n","Epoch 19/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.4566 - accuracy: 0.8858 - val_loss: 0.7398 - val_accuracy: 0.7295\n","Epoch 20/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4755 - accuracy: 0.8696 - val_loss: 0.8518 - val_accuracy: 0.5830\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4603 - accuracy: 0.8831 - val_loss: 0.7752 - val_accuracy: 0.6649\n","Epoch 22/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4349 - accuracy: 0.8992 - val_loss: 0.7493 - val_accuracy: 0.6994\n","Epoch 23/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4397 - accuracy: 0.8941 - val_loss: 0.7720 - val_accuracy: 0.6853\n","Epoch 24/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.4366 - accuracy: 0.8901 - val_loss: 0.7050 - val_accuracy: 0.7468\n","Epoch 25/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4414 - accuracy: 0.8906 - val_loss: 0.8925 - val_accuracy: 0.6573\n","Epoch 26/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4443 - accuracy: 0.8912 - val_loss: 0.7477 - val_accuracy: 0.7317\n","Epoch 27/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4267 - accuracy: 0.8995 - val_loss: 0.7296 - val_accuracy: 0.7435\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4144 - accuracy: 0.9017 - val_loss: 0.7743 - val_accuracy: 0.7403\n","Epoch 29/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4168 - accuracy: 0.9076 - val_loss: 0.7805 - val_accuracy: 0.7360\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4135 - accuracy: 0.9044 - val_loss: 0.8272 - val_accuracy: 0.7274\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4300 - accuracy: 0.8941 - val_loss: 0.8721 - val_accuracy: 0.7069\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4335 - accuracy: 0.8968 - val_loss: 0.8228 - val_accuracy: 0.7349\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4149 - accuracy: 0.9041 - val_loss: 0.7759 - val_accuracy: 0.7403\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4086 - accuracy: 0.9103 - val_loss: 0.9727 - val_accuracy: 0.6821\n","Epoch 35/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4205 - accuracy: 0.9044 - val_loss: 0.7888 - val_accuracy: 0.7414\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4125 - accuracy: 0.9049 - val_loss: 0.9755 - val_accuracy: 0.6897\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4378 - accuracy: 0.8879 - val_loss: 0.8628 - val_accuracy: 0.7091\n","Epoch 38/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3998 - accuracy: 0.9114 - val_loss: 0.8525 - val_accuracy: 0.7295\n","Epoch 39/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3937 - accuracy: 0.9108 - val_loss: 0.8037 - val_accuracy: 0.7500\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3872 - accuracy: 0.9203 - val_loss: 0.8234 - val_accuracy: 0.7252\n","Epoch 41/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3868 - accuracy: 0.9205 - val_loss: 0.8157 - val_accuracy: 0.7371\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3918 - accuracy: 0.9143 - val_loss: 0.8210 - val_accuracy: 0.7392\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3989 - accuracy: 0.9103 - val_loss: 0.9500 - val_accuracy: 0.7069\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4034 - accuracy: 0.9006 - val_loss: 0.8162 - val_accuracy: 0.7414\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3793 - accuracy: 0.9240 - val_loss: 0.8159 - val_accuracy: 0.7446\n","Epoch 46/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3807 - accuracy: 0.9157 - val_loss: 0.8308 - val_accuracy: 0.7328\n","Epoch 47/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3849 - accuracy: 0.9173 - val_loss: 0.8333 - val_accuracy: 0.7349\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3958 - accuracy: 0.9135 - val_loss: 0.8964 - val_accuracy: 0.7080\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4334 - accuracy: 0.8820 - val_loss: 0.8361 - val_accuracy: 0.7338\n","Epoch 50/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3744 - accuracy: 0.9224 - val_loss: 0.8237 - val_accuracy: 0.7403\n","Epoch 51/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3663 - accuracy: 0.9302 - val_loss: 0.9070 - val_accuracy: 0.7198\n","Epoch 52/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3688 - accuracy: 0.9224 - val_loss: 0.8737 - val_accuracy: 0.7241\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3833 - accuracy: 0.9130 - val_loss: 0.9071 - val_accuracy: 0.7274\n","Epoch 54/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3714 - accuracy: 0.9240 - val_loss: 0.8532 - val_accuracy: 0.7381\n","Epoch 55/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3671 - accuracy: 0.9262 - val_loss: 0.8511 - val_accuracy: 0.7371\n","Epoch 56/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3612 - accuracy: 0.9310 - val_loss: 1.0105 - val_accuracy: 0.6972\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3624 - accuracy: 0.9289 - val_loss: 0.8509 - val_accuracy: 0.7328\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3619 - accuracy: 0.9289 - val_loss: 0.8663 - val_accuracy: 0.7381\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3808 - accuracy: 0.9170 - val_loss: 1.0166 - val_accuracy: 0.6843\n","Epoch 60/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3777 - accuracy: 0.9151 - val_loss: 0.8870 - val_accuracy: 0.7317\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3725 - accuracy: 0.9178 - val_loss: 0.8625 - val_accuracy: 0.7392\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3481 - accuracy: 0.9321 - val_loss: 0.9823 - val_accuracy: 0.7101\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3605 - accuracy: 0.9308 - val_loss: 0.8635 - val_accuracy: 0.7328\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3441 - accuracy: 0.9340 - val_loss: 0.9060 - val_accuracy: 0.7338\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3523 - accuracy: 0.9300 - val_loss: 0.8600 - val_accuracy: 0.7414\n","Epoch 66/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3641 - accuracy: 0.9256 - val_loss: 0.9136 - val_accuracy: 0.7274\n","Epoch 67/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3543 - accuracy: 0.9321 - val_loss: 0.8793 - val_accuracy: 0.7328\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3285 - accuracy: 0.9434 - val_loss: 0.8740 - val_accuracy: 0.7295\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3550 - accuracy: 0.9278 - val_loss: 0.8936 - val_accuracy: 0.7263\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3343 - accuracy: 0.9402 - val_loss: 0.8819 - val_accuracy: 0.7252\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3476 - accuracy: 0.9318 - val_loss: 0.8698 - val_accuracy: 0.7371\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3732 - accuracy: 0.9168 - val_loss: 0.9648 - val_accuracy: 0.7198\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3461 - accuracy: 0.9335 - val_loss: 0.8829 - val_accuracy: 0.7371\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3420 - accuracy: 0.9305 - val_loss: 0.8746 - val_accuracy: 0.7284\n","Epoch 75/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3447 - accuracy: 0.9359 - val_loss: 0.9186 - val_accuracy: 0.7284\n","Epoch 76/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3574 - accuracy: 0.9246 - val_loss: 0.8782 - val_accuracy: 0.7403\n","Epoch 77/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3410 - accuracy: 0.9359 - val_loss: 0.9225 - val_accuracy: 0.7177\n","Epoch 78/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3131 - accuracy: 0.9523 - val_loss: 0.9873 - val_accuracy: 0.7123\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3214 - accuracy: 0.9472 - val_loss: 1.0223 - val_accuracy: 0.7123\n","Epoch 80/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3523 - accuracy: 0.9281 - val_loss: 0.9347 - val_accuracy: 0.7155\n","Epoch 81/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3225 - accuracy: 0.9445 - val_loss: 1.0087 - val_accuracy: 0.7112\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3250 - accuracy: 0.9423 - val_loss: 0.8957 - val_accuracy: 0.7306\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3497 - accuracy: 0.9267 - val_loss: 1.1693 - val_accuracy: 0.6907\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3473 - accuracy: 0.9262 - val_loss: 0.9299 - val_accuracy: 0.7263\n","Epoch 85/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3092 - accuracy: 0.9494 - val_loss: 0.9322 - val_accuracy: 0.7241\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3165 - accuracy: 0.9469 - val_loss: 0.9029 - val_accuracy: 0.7381\n","Epoch 87/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3025 - accuracy: 0.9566 - val_loss: 0.9713 - val_accuracy: 0.7263\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3152 - accuracy: 0.9445 - val_loss: 1.0452 - val_accuracy: 0.6940\n","Epoch 89/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3575 - accuracy: 0.9176 - val_loss: 0.9116 - val_accuracy: 0.7328\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3071 - accuracy: 0.9507 - val_loss: 0.9174 - val_accuracy: 0.7349\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3131 - accuracy: 0.9440 - val_loss: 0.9184 - val_accuracy: 0.7371\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3093 - accuracy: 0.9499 - val_loss: 1.0126 - val_accuracy: 0.7155\n","Epoch 93/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2991 - accuracy: 0.9539 - val_loss: 0.9281 - val_accuracy: 0.7274\n","Epoch 94/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2935 - accuracy: 0.9545 - val_loss: 0.9215 - val_accuracy: 0.7328\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2899 - accuracy: 0.9596 - val_loss: 0.9503 - val_accuracy: 0.7209\n","Epoch 96/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3094 - accuracy: 0.9450 - val_loss: 0.9503 - val_accuracy: 0.7231\n","Epoch 97/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2992 - accuracy: 0.9515 - val_loss: 0.9344 - val_accuracy: 0.7284\n","Epoch 98/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2876 - accuracy: 0.9588 - val_loss: 0.9394 - val_accuracy: 0.7274\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2972 - accuracy: 0.9523 - val_loss: 0.9537 - val_accuracy: 0.7371\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2879 - accuracy: 0.9574 - val_loss: 0.9778 - val_accuracy: 0.7274\n","{'loss': [0.5667430758476257, 0.4951198101043701, 0.4959559142589569, 0.49887150526046753, 0.4808911979198456, 0.5002756714820862, 0.4899751842021942, 0.4694161117076874, 0.4882357716560364, 0.471352219581604, 0.46518346667289734, 0.4706707000732422, 0.46513041853904724, 0.4568939208984375, 0.45614898204803467, 0.4568907916545868, 0.45414042472839355, 0.45952504873275757, 0.45657452940940857, 0.475508451461792, 0.46029067039489746, 0.43486714363098145, 0.4397319555282593, 0.4366346597671509, 0.44141414761543274, 0.44430220127105713, 0.42668670415878296, 0.41439974308013916, 0.41680148243904114, 0.41354507207870483, 0.42998531460762024, 0.4334585964679718, 0.4149366617202759, 0.40860769152641296, 0.4205470681190491, 0.4124959111213684, 0.4378369152545929, 0.399786114692688, 0.3937169015407562, 0.3871704041957855, 0.3867837190628052, 0.39178934693336487, 0.39887532591819763, 0.40341949462890625, 0.3793434500694275, 0.3806764483451843, 0.38493338227272034, 0.3957841098308563, 0.4333973228931427, 0.37440937757492065, 0.36627867817878723, 0.36875566840171814, 0.3832642436027527, 0.3713904619216919, 0.36708056926727295, 0.3611527383327484, 0.36241772770881653, 0.3619301915168762, 0.3808368742465973, 0.37770941853523254, 0.3724595308303833, 0.3481180965900421, 0.36045515537261963, 0.34414035081863403, 0.35228630900382996, 0.36406633257865906, 0.3542728126049042, 0.3285280168056488, 0.35500282049179077, 0.33434751629829407, 0.3475554287433624, 0.37318792939186096, 0.3461053669452667, 0.3419637084007263, 0.34470799565315247, 0.3573935031890869, 0.34097862243652344, 0.3130941092967987, 0.3213766813278198, 0.3523488938808441, 0.32245883345603943, 0.32495012879371643, 0.34972164034843445, 0.3472955524921417, 0.30915501713752747, 0.3164542317390442, 0.30250290036201477, 0.31520503759384155, 0.3575131595134735, 0.3070679008960724, 0.3131450116634369, 0.3093215227127075, 0.2991284728050232, 0.29350242018699646, 0.28991514444351196, 0.30943942070007324, 0.29915493726730347, 0.2875618040561676, 0.2972007393836975, 0.2879408895969391], 'accuracy': [0.8324353694915771, 0.8698814511299133, 0.8723060488700867, 0.8636853694915771, 0.8720366358757019, 0.8623383641242981, 0.8674569129943848, 0.8825430870056152, 0.8661099076271057, 0.8820043206214905, 0.8833512663841248, 0.8739224076271057, 0.8806573152542114, 0.8822737336158752, 0.8825430870056152, 0.8871228694915771, 0.884428858757019, 0.8828125, 0.8857758641242981, 0.8696120977401733, 0.8830819129943848, 0.8992456793785095, 0.8941271305084229, 0.8900862336158752, 0.890625, 0.8911637663841248, 0.8995150923728943, 0.9016702771186829, 0.907597005367279, 0.9043642282485962, 0.8941271305084229, 0.896821141242981, 0.9040948152542114, 0.9102909564971924, 0.9043642282485962, 0.904902994632721, 0.8879310488700867, 0.9113685488700867, 0.9108297228813171, 0.920258641242981, 0.920527994632721, 0.9143319129943848, 0.9102909564971924, 0.9005926847457886, 0.9240301847457886, 0.915678858757019, 0.9172952771186829, 0.9135237336158752, 0.8820043206214905, 0.9224137663841248, 0.9302262663841248, 0.9224137663841248, 0.9129849076271057, 0.9240301847457886, 0.9261853694915771, 0.931034505367279, 0.9288793206214905, 0.9288793206214905, 0.9170258641242981, 0.9151400923728943, 0.9178340435028076, 0.9321120977401733, 0.9307650923728943, 0.9339978694915771, 0.9299569129943848, 0.9256465435028076, 0.9321120977401733, 0.9434267282485962, 0.9278017282485962, 0.9401939511299133, 0.9318426847457886, 0.9167564511299133, 0.9334590435028076, 0.9304956793785095, 0.935883641242981, 0.9245689511299133, 0.935883641242981, 0.9523168206214905, 0.9471982717514038, 0.928071141242981, 0.9445043206214905, 0.9423491358757019, 0.9267241358757019, 0.9261853694915771, 0.9493534564971924, 0.946928858757019, 0.9566271305084229, 0.9445043206214905, 0.9175646305084229, 0.9507004022598267, 0.943965494632721, 0.9498922228813171, 0.9539331793785095, 0.954472005367279, 0.959590494632721, 0.9450430870056152, 0.951508641242981, 0.9587823152542114, 0.9523168206214905, 0.9574353694915771], 'val_loss': [0.8837953209877014, 0.8847095370292664, 0.8836235404014587, 0.884340763092041, 0.8825678825378418, 0.8798847198486328, 0.8766579627990723, 0.8783596158027649, 0.8770079612731934, 0.8660841584205627, 0.8674070835113525, 0.8537729382514954, 0.8505850434303284, 0.8517366051673889, 0.8381199836730957, 0.8201049566268921, 0.8321467041969299, 0.7748231291770935, 0.7397810220718384, 0.8518214821815491, 0.7752279043197632, 0.7493258118629456, 0.7720035910606384, 0.7050315141677856, 0.8925057649612427, 0.7477328777313232, 0.7295863628387451, 0.7743468880653381, 0.78046053647995, 0.827158510684967, 0.872124433517456, 0.8228461146354675, 0.7758768796920776, 0.9726920127868652, 0.7888132333755493, 0.9754800200462341, 0.8628236651420593, 0.8525059819221497, 0.8037112951278687, 0.823352038860321, 0.8156651854515076, 0.8209847807884216, 0.9500122666358948, 0.8161807656288147, 0.8158511519432068, 0.8308132290840149, 0.8333039879798889, 0.8964467644691467, 0.836134135723114, 0.8237449526786804, 0.9069680571556091, 0.8736976385116577, 0.9071024060249329, 0.8531728982925415, 0.8510591983795166, 1.0105277299880981, 0.8508864641189575, 0.8662874102592468, 1.0166335105895996, 0.8869568109512329, 0.8625267744064331, 0.9822587370872498, 0.8635128140449524, 0.9060332775115967, 0.8599715232849121, 0.9136048555374146, 0.8792598247528076, 0.8740382790565491, 0.8935841917991638, 0.8818587064743042, 0.8698204159736633, 0.9647590517997742, 0.8829225301742554, 0.8746454119682312, 0.91862952709198, 0.8781786561012268, 0.9224685430526733, 0.9873440861701965, 1.0222877264022827, 0.9346551299095154, 1.0086811780929565, 0.8956812620162964, 1.1693098545074463, 0.9299143552780151, 0.9322325587272644, 0.9028548002243042, 0.9712764024734497, 1.045161485671997, 0.911605954170227, 0.9174176454544067, 0.9184271097183228, 1.0126259326934814, 0.928092360496521, 0.9214912056922913, 0.9503495693206787, 0.9502673149108887, 0.9344357848167419, 0.9393513202667236, 0.9537201523780823, 0.977763295173645], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.4903017282485962, 0.4913793206214905, 0.5043103694915771, 0.5053879022598267, 0.5086206793785095, 0.5334051847457886, 0.5625, 0.5495689511299133, 0.6584051847457886, 0.7295258641242981, 0.5829741358757019, 0.6648706793785095, 0.6993534564971924, 0.6853448152542114, 0.7467672228813171, 0.6573275923728943, 0.7316810488700867, 0.743534505367279, 0.7403017282485962, 0.735991358757019, 0.7273706793785095, 0.7068965435028076, 0.7349137663841248, 0.7403017282485962, 0.6821120977401733, 0.7413793206214905, 0.6896551847457886, 0.7090517282485962, 0.7295258641242981, 0.75, 0.725215494632721, 0.7370689511299133, 0.7392241358757019, 0.7068965435028076, 0.7413793206214905, 0.7446120977401733, 0.732758641242981, 0.7349137663841248, 0.7079741358757019, 0.7338362336158752, 0.7403017282485962, 0.7198275923728943, 0.7241379022598267, 0.7273706793785095, 0.7381465435028076, 0.7370689511299133, 0.6971982717514038, 0.732758641242981, 0.7381465435028076, 0.6842672228813171, 0.7316810488700867, 0.7392241358757019, 0.7101293206214905, 0.732758641242981, 0.7338362336158752, 0.7413793206214905, 0.7273706793785095, 0.732758641242981, 0.7295258641242981, 0.7262930870056152, 0.725215494632721, 0.7370689511299133, 0.7198275923728943, 0.7370689511299133, 0.7284482717514038, 0.7284482717514038, 0.7403017282485962, 0.7176724076271057, 0.712284505367279, 0.712284505367279, 0.7155172228813171, 0.7112069129943848, 0.7306034564971924, 0.6907327771186829, 0.7262930870056152, 0.7241379022598267, 0.7381465435028076, 0.7262930870056152, 0.693965494632721, 0.732758641242981, 0.7349137663841248, 0.7370689511299133, 0.7155172228813171, 0.7273706793785095, 0.732758641242981, 0.7209051847457886, 0.7230603694915771, 0.7284482717514038, 0.7273706793785095, 0.7370689511299133, 0.7273706793785095]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.5415 - accuracy: 0.8393"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 7s 61ms/step - loss: 0.5415 - accuracy: 0.8393 - val_loss: 0.8819 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5079 - accuracy: 0.8594 - val_loss: 0.8826 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.5126 - accuracy: 0.8526 - val_loss: 0.8809 - val_accuracy: 0.4966\n","Epoch 4/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4975 - accuracy: 0.8653 - val_loss: 0.8821 - val_accuracy: 0.4966\n","Epoch 5/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.4957 - accuracy: 0.8662 - val_loss: 0.8788 - val_accuracy: 0.4989\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4784 - accuracy: 0.8741 - val_loss: 0.8758 - val_accuracy: 0.4989\n","Epoch 7/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5190 - accuracy: 0.8480 - val_loss: 0.8748 - val_accuracy: 0.4989\n","Epoch 8/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5069 - accuracy: 0.8591 - val_loss: 0.8723 - val_accuracy: 0.4989\n","Epoch 9/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4826 - accuracy: 0.8755 - val_loss: 0.8709 - val_accuracy: 0.5000\n","Epoch 10/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4744 - accuracy: 0.8806 - val_loss: 0.8638 - val_accuracy: 0.5034\n","Epoch 11/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4824 - accuracy: 0.8718 - val_loss: 0.8590 - val_accuracy: 0.5057\n","Epoch 12/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4790 - accuracy: 0.8741 - val_loss: 0.8473 - val_accuracy: 0.5192\n","Epoch 13/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4639 - accuracy: 0.8865 - val_loss: 0.8426 - val_accuracy: 0.5192\n","Epoch 14/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4637 - accuracy: 0.8806 - val_loss: 0.8303 - val_accuracy: 0.5419\n","Epoch 15/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4817 - accuracy: 0.8727 - val_loss: 0.8294 - val_accuracy: 0.5396\n","Epoch 16/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4596 - accuracy: 0.8803 - val_loss: 0.8146 - val_accuracy: 0.5611\n","Epoch 17/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4575 - accuracy: 0.8846 - val_loss: 0.7847 - val_accuracy: 0.6312\n","Epoch 18/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4577 - accuracy: 0.8851 - val_loss: 0.7632 - val_accuracy: 0.6663\n","Epoch 19/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4384 - accuracy: 0.8967 - val_loss: 0.7868 - val_accuracy: 0.6052\n","Epoch 20/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.4523 - accuracy: 0.8874 - val_loss: 0.7091 - val_accuracy: 0.7613\n","Epoch 21/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4654 - accuracy: 0.8752 - val_loss: 0.7084 - val_accuracy: 0.7421\n","Epoch 22/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4386 - accuracy: 0.8879 - val_loss: 0.7660 - val_accuracy: 0.6584\n","Epoch 23/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4626 - accuracy: 0.8780 - val_loss: 0.6939 - val_accuracy: 0.7545\n","Epoch 24/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4386 - accuracy: 0.8928 - val_loss: 0.7365 - val_accuracy: 0.7149\n","Epoch 25/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.4421 - accuracy: 0.8916 - val_loss: 0.6811 - val_accuracy: 0.7692\n","Epoch 26/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4289 - accuracy: 0.9024 - val_loss: 0.6720 - val_accuracy: 0.7534\n","Epoch 27/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4261 - accuracy: 0.8993 - val_loss: 0.7116 - val_accuracy: 0.7624\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4489 - accuracy: 0.8814 - val_loss: 0.7794 - val_accuracy: 0.7319\n","Epoch 29/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4731 - accuracy: 0.8696 - val_loss: 0.6975 - val_accuracy: 0.7681\n","Epoch 30/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4278 - accuracy: 0.9044 - val_loss: 0.6970 - val_accuracy: 0.7624\n","Epoch 31/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4227 - accuracy: 0.9027 - val_loss: 0.7010 - val_accuracy: 0.7511\n","Epoch 32/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4178 - accuracy: 0.9049 - val_loss: 0.7109 - val_accuracy: 0.7579\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4042 - accuracy: 0.9123 - val_loss: 0.7282 - val_accuracy: 0.7636\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4091 - accuracy: 0.9117 - val_loss: 0.7314 - val_accuracy: 0.7624\n","Epoch 35/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4158 - accuracy: 0.9046 - val_loss: 0.7317 - val_accuracy: 0.7523\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4048 - accuracy: 0.9137 - val_loss: 0.7406 - val_accuracy: 0.7534\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4130 - accuracy: 0.9049 - val_loss: 0.7467 - val_accuracy: 0.7523\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4030 - accuracy: 0.9131 - val_loss: 0.7532 - val_accuracy: 0.7545\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4048 - accuracy: 0.9061 - val_loss: 0.7721 - val_accuracy: 0.7590\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4283 - accuracy: 0.8993 - val_loss: 0.8155 - val_accuracy: 0.7296\n","Epoch 41/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4209 - accuracy: 0.8984 - val_loss: 0.7799 - val_accuracy: 0.7647\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4109 - accuracy: 0.9041 - val_loss: 0.7951 - val_accuracy: 0.7602\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3985 - accuracy: 0.9128 - val_loss: 0.8164 - val_accuracy: 0.7262\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4112 - accuracy: 0.9063 - val_loss: 0.8394 - val_accuracy: 0.7534\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4476 - accuracy: 0.8803 - val_loss: 0.7690 - val_accuracy: 0.7443\n","Epoch 46/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3984 - accuracy: 0.9086 - val_loss: 0.7652 - val_accuracy: 0.7568\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3920 - accuracy: 0.9179 - val_loss: 0.8517 - val_accuracy: 0.7534\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4030 - accuracy: 0.9080 - val_loss: 0.7724 - val_accuracy: 0.7489\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3827 - accuracy: 0.9140 - val_loss: 0.7705 - val_accuracy: 0.7523\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3861 - accuracy: 0.9134 - val_loss: 0.7791 - val_accuracy: 0.7466\n","Epoch 51/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3771 - accuracy: 0.9194 - val_loss: 0.8110 - val_accuracy: 0.7500\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3692 - accuracy: 0.9256 - val_loss: 0.7936 - val_accuracy: 0.7466\n","Epoch 53/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3704 - accuracy: 0.9247 - val_loss: 0.7887 - val_accuracy: 0.7477\n","Epoch 54/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3722 - accuracy: 0.9236 - val_loss: 0.7945 - val_accuracy: 0.7500\n","Epoch 55/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3618 - accuracy: 0.9281 - val_loss: 0.9083 - val_accuracy: 0.7466\n","Epoch 56/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3720 - accuracy: 0.9205 - val_loss: 0.8080 - val_accuracy: 0.7398\n","Epoch 57/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3823 - accuracy: 0.9148 - val_loss: 0.8462 - val_accuracy: 0.7523\n","Epoch 58/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3635 - accuracy: 0.9256 - val_loss: 0.9445 - val_accuracy: 0.7376\n","Epoch 59/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3785 - accuracy: 0.9117 - val_loss: 0.8086 - val_accuracy: 0.7557\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3740 - accuracy: 0.9222 - val_loss: 0.8116 - val_accuracy: 0.7511\n","Epoch 61/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3592 - accuracy: 0.9335 - val_loss: 0.8051 - val_accuracy: 0.7557\n","Epoch 62/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3554 - accuracy: 0.9278 - val_loss: 0.8073 - val_accuracy: 0.7523\n","Epoch 63/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3755 - accuracy: 0.9179 - val_loss: 0.8111 - val_accuracy: 0.7545\n","Epoch 64/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3774 - accuracy: 0.9140 - val_loss: 0.8125 - val_accuracy: 0.7534\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3570 - accuracy: 0.9304 - val_loss: 0.8412 - val_accuracy: 0.7477\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3454 - accuracy: 0.9363 - val_loss: 0.8741 - val_accuracy: 0.7455\n","Epoch 67/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3575 - accuracy: 0.9284 - val_loss: 0.8281 - val_accuracy: 0.7455\n","Epoch 68/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3492 - accuracy: 0.9310 - val_loss: 0.8485 - val_accuracy: 0.7443\n","Epoch 69/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3318 - accuracy: 0.9414 - val_loss: 0.8450 - val_accuracy: 0.7489\n","Epoch 70/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3525 - accuracy: 0.9304 - val_loss: 0.8281 - val_accuracy: 0.7523\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3435 - accuracy: 0.9346 - val_loss: 0.8305 - val_accuracy: 0.7545\n","Epoch 72/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3369 - accuracy: 0.9383 - val_loss: 0.8415 - val_accuracy: 0.7511\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3318 - accuracy: 0.9428 - val_loss: 0.8639 - val_accuracy: 0.7421\n","Epoch 74/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3471 - accuracy: 0.9290 - val_loss: 0.8592 - val_accuracy: 0.7477\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3358 - accuracy: 0.9403 - val_loss: 1.0365 - val_accuracy: 0.7070\n","Epoch 76/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3528 - accuracy: 0.9290 - val_loss: 0.9551 - val_accuracy: 0.7262\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3646 - accuracy: 0.9250 - val_loss: 0.8472 - val_accuracy: 0.7466\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3280 - accuracy: 0.9423 - val_loss: 0.8715 - val_accuracy: 0.7398\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3246 - accuracy: 0.9431 - val_loss: 0.8581 - val_accuracy: 0.7455\n","Epoch 80/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3246 - accuracy: 0.9420 - val_loss: 0.8823 - val_accuracy: 0.7489\n","Epoch 81/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3322 - accuracy: 0.9377 - val_loss: 0.8661 - val_accuracy: 0.7579\n","Epoch 82/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3303 - accuracy: 0.9383 - val_loss: 0.8851 - val_accuracy: 0.7398\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3168 - accuracy: 0.9460 - val_loss: 0.9472 - val_accuracy: 0.7319\n","Epoch 84/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3214 - accuracy: 0.9434 - val_loss: 0.9135 - val_accuracy: 0.7330\n","Epoch 85/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3188 - accuracy: 0.9465 - val_loss: 0.9638 - val_accuracy: 0.7251\n","Epoch 86/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3310 - accuracy: 0.9360 - val_loss: 0.9005 - val_accuracy: 0.7387\n","Epoch 87/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3260 - accuracy: 0.9377 - val_loss: 0.9200 - val_accuracy: 0.7364\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3093 - accuracy: 0.9505 - val_loss: 0.8831 - val_accuracy: 0.7489\n","Epoch 89/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3076 - accuracy: 0.9539 - val_loss: 0.8985 - val_accuracy: 0.7511\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3127 - accuracy: 0.9460 - val_loss: 0.9104 - val_accuracy: 0.7432\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3162 - accuracy: 0.9479 - val_loss: 0.9336 - val_accuracy: 0.7364\n","Epoch 92/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3220 - accuracy: 0.9431 - val_loss: 0.9511 - val_accuracy: 0.7319\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3226 - accuracy: 0.9428 - val_loss: 0.9590 - val_accuracy: 0.7376\n","Epoch 94/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3127 - accuracy: 0.9482 - val_loss: 0.9098 - val_accuracy: 0.7466\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2988 - accuracy: 0.9533 - val_loss: 0.9130 - val_accuracy: 0.7376\n","Epoch 96/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3029 - accuracy: 0.9547 - val_loss: 0.9442 - val_accuracy: 0.7376\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3074 - accuracy: 0.9471 - val_loss: 0.9649 - val_accuracy: 0.7342\n","Epoch 98/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3303 - accuracy: 0.9355 - val_loss: 0.9515 - val_accuracy: 0.7376\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3042 - accuracy: 0.9522 - val_loss: 0.9538 - val_accuracy: 0.7387\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3097 - accuracy: 0.9485 - val_loss: 0.9453 - val_accuracy: 0.7364\n","{'loss': [0.5415135622024536, 0.5078712105751038, 0.5125702023506165, 0.4974942207336426, 0.49570345878601074, 0.4784257411956787, 0.5190194845199585, 0.5068840980529785, 0.4825860261917114, 0.47441259026527405, 0.48240044713020325, 0.47897571325302124, 0.4639326333999634, 0.46374157071113586, 0.4817174971103668, 0.45959946513175964, 0.4575241804122925, 0.45766615867614746, 0.4383932054042816, 0.4522934854030609, 0.46542322635650635, 0.4386419355869293, 0.46255627274513245, 0.43864020705223083, 0.442058265209198, 0.42894506454467773, 0.4261407256126404, 0.44886451959609985, 0.4730730652809143, 0.4277758300304413, 0.42271336913108826, 0.4178484082221985, 0.4042052924633026, 0.409066766500473, 0.41577520966529846, 0.404796838760376, 0.4130072295665741, 0.4029640853404999, 0.40484097599983215, 0.4282778203487396, 0.4209372401237488, 0.4108545184135437, 0.3985212743282318, 0.4112487733364105, 0.447624146938324, 0.39835256338119507, 0.3919866979122162, 0.4030430018901825, 0.38266634941101074, 0.38614967465400696, 0.3770706057548523, 0.36915379762649536, 0.37042292952537537, 0.3721945881843567, 0.3618414103984833, 0.3720146715641022, 0.3822519779205322, 0.3634541928768158, 0.3784801661968231, 0.373973548412323, 0.35918742418289185, 0.35540255904197693, 0.37548306584358215, 0.37736836075782776, 0.3569926917552948, 0.34537366032600403, 0.3574954867362976, 0.3492291271686554, 0.33182039856910706, 0.3524978756904602, 0.3434542119503021, 0.3368617296218872, 0.331780344247818, 0.3470636308193207, 0.33581799268722534, 0.35282379388809204, 0.3645659387111664, 0.3279567062854767, 0.3245987892150879, 0.32464614510536194, 0.3322283923625946, 0.33028215169906616, 0.316760390996933, 0.32135841250419617, 0.31876325607299805, 0.33097603917121887, 0.32598385214805603, 0.30928656458854675, 0.30764707922935486, 0.3127233684062958, 0.31617674231529236, 0.3219718039035797, 0.32259148359298706, 0.312709778547287, 0.2988154888153076, 0.3029284179210663, 0.3074146807193756, 0.3302987813949585, 0.3041594624519348, 0.3097379505634308], 'accuracy': [0.839275598526001, 0.8593661785125732, 0.8525750041007996, 0.865308403968811, 0.8661573529243469, 0.8740803599357605, 0.8480475544929504, 0.8590831756591797, 0.875495195388794, 0.8805885910987854, 0.8718166351318359, 0.8740803599357605, 0.8865308165550232, 0.8805885910987854, 0.872665524482727, 0.8803055882453918, 0.8845500946044922, 0.8851160407066345, 0.8967176079750061, 0.8873797655105591, 0.8752122521400452, 0.8879456520080566, 0.8780418634414673, 0.8927561044692993, 0.8916242122650146, 0.9023768901824951, 0.8992642760276794, 0.8814374804496765, 0.8695529103279114, 0.9043576717376709, 0.9026598930358887, 0.9049236178398132, 0.9122806787490845, 0.9117147922515869, 0.9046406149864197, 0.9136955142021179, 0.9049236178398132, 0.9131296277046204, 0.9060554504394531, 0.8992642760276794, 0.8984153866767883, 0.9040747284889221, 0.9128466248512268, 0.9063384532928467, 0.8803055882453918, 0.9086021780967712, 0.9179400205612183, 0.9080362319946289, 0.9139785170555115, 0.9134125709533691, 0.9193548560142517, 0.9255800843238831, 0.9247311949729919, 0.9235993027687073, 0.9281267523765564, 0.9204866886138916, 0.9148274064064026, 0.9255800843238831, 0.9117147922515869, 0.9221844673156738, 0.9335030913352966, 0.9278438091278076, 0.9179400205612183, 0.9139785170555115, 0.930390477180481, 0.9363327622413635, 0.92840975522995, 0.9309564232826233, 0.941426157951355, 0.930390477180481, 0.9346349835395813, 0.9383135437965393, 0.9428409934043884, 0.9289756417274475, 0.9402942657470703, 0.9289756417274475, 0.9250141382217407, 0.9422750473022461, 0.9431239366531372, 0.9419921040534973, 0.937747597694397, 0.9383135437965393, 0.9459536075592041, 0.943406879901886, 0.9465195536613464, 0.9360498189926147, 0.937747597694397, 0.9504810571670532, 0.9538766145706177, 0.9459536075592041, 0.9479343295097351, 0.9431239366531372, 0.9428409934043884, 0.9482173323631287, 0.9533106684684753, 0.9547255039215088, 0.947085440158844, 0.9354838728904724, 0.9521788358688354, 0.9485002756118774], 'val_loss': [0.8819365501403809, 0.8826441168785095, 0.880865216255188, 0.8820581436157227, 0.8787738680839539, 0.8758234977722168, 0.8748428821563721, 0.8723165392875671, 0.8708992004394531, 0.8637990355491638, 0.8589746952056885, 0.8472962975502014, 0.8426013588905334, 0.8303087949752808, 0.8293883204460144, 0.8145568370819092, 0.784714937210083, 0.7631906867027283, 0.7868022918701172, 0.7090764045715332, 0.7084448337554932, 0.7659628987312317, 0.6939366459846497, 0.7364926338195801, 0.6810724139213562, 0.6720454096794128, 0.711582362651825, 0.7794010639190674, 0.6974914073944092, 0.6970298290252686, 0.7010102868080139, 0.7108578085899353, 0.7282122373580933, 0.731402575969696, 0.7316889762878418, 0.7406377792358398, 0.7467264533042908, 0.7531830072402954, 0.7720854878425598, 0.8155126571655273, 0.7798743844032288, 0.7950830459594727, 0.81641685962677, 0.8393576741218567, 0.7689625024795532, 0.7652226090431213, 0.851681113243103, 0.7723821401596069, 0.7704682946205139, 0.7791268825531006, 0.8109938502311707, 0.793569803237915, 0.7887454628944397, 0.7944941520690918, 0.9082673192024231, 0.8080235123634338, 0.8462346196174622, 0.944523811340332, 0.8085626363754272, 0.8115928173065186, 0.8051185607910156, 0.8073036670684814, 0.8111316561698914, 0.8125167489051819, 0.8412415981292725, 0.8741166591644287, 0.8280882239341736, 0.8484504818916321, 0.8450430035591125, 0.8280684351921082, 0.830513060092926, 0.8415161967277527, 0.8639434576034546, 0.8591526746749878, 1.0364549160003662, 0.955051839351654, 0.847207248210907, 0.8715062737464905, 0.8581119775772095, 0.8823304176330566, 0.8660916090011597, 0.8850721120834351, 0.9472247362136841, 0.9135071635246277, 0.9637718796730042, 0.9005154967308044, 0.9199897050857544, 0.8830640316009521, 0.8984723091125488, 0.9103713631629944, 0.9336395859718323, 0.9510517120361328, 0.9590311646461487, 0.9097564220428467, 0.9130352139472961, 0.9442206621170044, 0.9649269580841064, 0.9515419602394104, 0.9537798762321472, 0.9453328847885132], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.49660632014274597, 0.49886876344680786, 0.49886876344680786, 0.49886876344680786, 0.49886876344680786, 0.5, 0.5033936500549316, 0.5056561231613159, 0.5192307829856873, 0.5192307829856873, 0.5418552160263062, 0.5395927429199219, 0.5610859990119934, 0.6312217116355896, 0.6662895679473877, 0.6052036285400391, 0.7613122463226318, 0.7420814633369446, 0.6583710312843323, 0.7545248866081238, 0.7149321436882019, 0.7692307829856873, 0.7533936500549316, 0.7624434232711792, 0.7319004535675049, 0.7680995464324951, 0.7624434232711792, 0.7511312365531921, 0.7579185366630554, 0.7635746598243713, 0.7624434232711792, 0.7522624731063843, 0.7533936500549316, 0.7522624731063843, 0.7545248866081238, 0.7590497732162476, 0.7296379804611206, 0.7647058963775635, 0.7601810097694397, 0.726244330406189, 0.7533936500549316, 0.7443438768386841, 0.7567873597145081, 0.7533936500549316, 0.7488687634468079, 0.7522624731063843, 0.7466063499450684, 0.75, 0.7466063499450684, 0.7477375268936157, 0.75, 0.7466063499450684, 0.7398189902305603, 0.7522624731063843, 0.7375565767288208, 0.7556561231613159, 0.7511312365531921, 0.7556561231613159, 0.7522624731063843, 0.7545248866081238, 0.7533936500549316, 0.7477375268936157, 0.7454751133918762, 0.7454751133918762, 0.7443438768386841, 0.7488687634468079, 0.7522624731063843, 0.7545248866081238, 0.7511312365531921, 0.7420814633369446, 0.7477375268936157, 0.7070135474205017, 0.726244330406189, 0.7466063499450684, 0.7398189902305603, 0.7454751133918762, 0.7488687634468079, 0.7579185366630554, 0.7398189902305603, 0.7319004535675049, 0.733031690120697, 0.7251130938529968, 0.7386877536773682, 0.7364253401756287, 0.7488687634468079, 0.7511312365531921, 0.7432126402854919, 0.7364253401756287, 0.7319004535675049, 0.7375565767288208, 0.7466063499450684, 0.7375565767288208, 0.7375565767288208, 0.7341628670692444, 0.7375565767288208, 0.7386877536773682, 0.7364253401756287]}\n","45/45 [==============================] - 1s 6ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.5233 - accuracy: 0.8537"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 7s 54ms/step - loss: 0.5233 - accuracy: 0.8537 - val_loss: 0.8847 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5179 - accuracy: 0.8581 - val_loss: 0.8860 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5237 - accuracy: 0.8568 - val_loss: 0.8871 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5234 - accuracy: 0.8439 - val_loss: 0.8836 - val_accuracy: 0.4866\n","Epoch 5/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4948 - accuracy: 0.8685 - val_loss: 0.8866 - val_accuracy: 0.4866\n","Epoch 6/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4950 - accuracy: 0.8649 - val_loss: 0.8847 - val_accuracy: 0.4866\n","Epoch 7/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4948 - accuracy: 0.8716 - val_loss: 0.8802 - val_accuracy: 0.4886\n","Epoch 8/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5242 - accuracy: 0.8491 - val_loss: 0.8826 - val_accuracy: 0.4886\n","Epoch 9/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4920 - accuracy: 0.8602 - val_loss: 0.8760 - val_accuracy: 0.4928\n","Epoch 10/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4905 - accuracy: 0.8669 - val_loss: 0.8694 - val_accuracy: 0.4928\n","Epoch 11/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4740 - accuracy: 0.8793 - val_loss: 0.8788 - val_accuracy: 0.4917\n","Epoch 12/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4812 - accuracy: 0.8731 - val_loss: 0.8664 - val_accuracy: 0.5000\n","Epoch 13/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4818 - accuracy: 0.8669 - val_loss: 0.8684 - val_accuracy: 0.5052\n","Epoch 14/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4682 - accuracy: 0.8804 - val_loss: 0.8425 - val_accuracy: 0.5486\n","Epoch 15/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4779 - accuracy: 0.8680 - val_loss: 0.8770 - val_accuracy: 0.5165\n","Epoch 16/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5155 - accuracy: 0.8403 - val_loss: 0.8155 - val_accuracy: 0.6322\n","Epoch 17/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4706 - accuracy: 0.8819 - val_loss: 0.8336 - val_accuracy: 0.5878\n","Epoch 18/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4559 - accuracy: 0.8840 - val_loss: 0.8414 - val_accuracy: 0.5919\n","Epoch 19/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4594 - accuracy: 0.8845 - val_loss: 0.7893 - val_accuracy: 0.6860\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4419 - accuracy: 0.8907 - val_loss: 0.8642 - val_accuracy: 0.6167\n","Epoch 21/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4563 - accuracy: 0.8824 - val_loss: 0.7978 - val_accuracy: 0.6818\n","Epoch 22/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4554 - accuracy: 0.8842 - val_loss: 0.7887 - val_accuracy: 0.7035\n","Epoch 23/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4560 - accuracy: 0.8817 - val_loss: 0.8296 - val_accuracy: 0.6818\n","Epoch 24/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4634 - accuracy: 0.8806 - val_loss: 0.8661 - val_accuracy: 0.6746\n","Epoch 25/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4368 - accuracy: 0.8933 - val_loss: 0.8336 - val_accuracy: 0.7118\n","Epoch 26/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4569 - accuracy: 0.8801 - val_loss: 0.8516 - val_accuracy: 0.7045\n","Epoch 27/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4492 - accuracy: 0.8817 - val_loss: 0.9696 - val_accuracy: 0.6663\n","Epoch 28/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4264 - accuracy: 0.9005 - val_loss: 0.8852 - val_accuracy: 0.6983\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4493 - accuracy: 0.8809 - val_loss: 0.9048 - val_accuracy: 0.6932\n","Epoch 30/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4309 - accuracy: 0.8956 - val_loss: 0.9025 - val_accuracy: 0.6963\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4334 - accuracy: 0.8946 - val_loss: 0.9351 - val_accuracy: 0.6890\n","Epoch 32/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4305 - accuracy: 0.9013 - val_loss: 0.9166 - val_accuracy: 0.7066\n","Epoch 33/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4244 - accuracy: 0.8972 - val_loss: 0.9112 - val_accuracy: 0.7056\n","Epoch 34/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4170 - accuracy: 0.9016 - val_loss: 0.9442 - val_accuracy: 0.6942\n","Epoch 35/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4185 - accuracy: 0.9039 - val_loss: 0.9440 - val_accuracy: 0.6901\n","Epoch 36/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4186 - accuracy: 0.8987 - val_loss: 0.9485 - val_accuracy: 0.7025\n","Epoch 37/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4034 - accuracy: 0.9111 - val_loss: 0.9531 - val_accuracy: 0.6963\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4189 - accuracy: 0.8959 - val_loss: 0.9490 - val_accuracy: 0.7025\n","Epoch 39/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4170 - accuracy: 0.8992 - val_loss: 0.9397 - val_accuracy: 0.6942\n","Epoch 40/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4058 - accuracy: 0.9093 - val_loss: 0.9561 - val_accuracy: 0.6921\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4150 - accuracy: 0.8997 - val_loss: 0.9561 - val_accuracy: 0.6983\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4124 - accuracy: 0.9052 - val_loss: 1.0120 - val_accuracy: 0.6890\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4440 - accuracy: 0.8845 - val_loss: 0.9842 - val_accuracy: 0.6911\n","Epoch 44/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4451 - accuracy: 0.8822 - val_loss: 1.0266 - val_accuracy: 0.6829\n","Epoch 45/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4340 - accuracy: 0.8925 - val_loss: 0.9601 - val_accuracy: 0.6901\n","Epoch 46/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4064 - accuracy: 0.9031 - val_loss: 0.9731 - val_accuracy: 0.6880\n","Epoch 47/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3874 - accuracy: 0.9181 - val_loss: 0.9565 - val_accuracy: 0.6994\n","Epoch 48/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3792 - accuracy: 0.9233 - val_loss: 0.9636 - val_accuracy: 0.6942\n","Epoch 49/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3888 - accuracy: 0.9191 - val_loss: 0.9899 - val_accuracy: 0.6963\n","Epoch 50/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3875 - accuracy: 0.9160 - val_loss: 0.9678 - val_accuracy: 0.7004\n","Epoch 51/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3819 - accuracy: 0.9222 - val_loss: 0.9936 - val_accuracy: 0.6880\n","Epoch 52/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3825 - accuracy: 0.9220 - val_loss: 0.9901 - val_accuracy: 0.6911\n","Epoch 53/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3977 - accuracy: 0.9075 - val_loss: 1.0192 - val_accuracy: 0.6839\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3954 - accuracy: 0.9065 - val_loss: 1.0595 - val_accuracy: 0.6736\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3674 - accuracy: 0.9310 - val_loss: 0.9893 - val_accuracy: 0.7025\n","Epoch 56/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3757 - accuracy: 0.9196 - val_loss: 1.1501 - val_accuracy: 0.6632\n","Epoch 57/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4269 - accuracy: 0.8917 - val_loss: 1.0352 - val_accuracy: 0.6849\n","Epoch 58/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3653 - accuracy: 0.9274 - val_loss: 0.9846 - val_accuracy: 0.7014\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3662 - accuracy: 0.9289 - val_loss: 1.0082 - val_accuracy: 0.6973\n","Epoch 60/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3637 - accuracy: 0.9240 - val_loss: 1.0279 - val_accuracy: 0.6890\n","Epoch 61/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4053 - accuracy: 0.9034 - val_loss: 1.0006 - val_accuracy: 0.6963\n","Epoch 62/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3561 - accuracy: 0.9318 - val_loss: 1.0748 - val_accuracy: 0.6746\n","Epoch 63/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3626 - accuracy: 0.9258 - val_loss: 1.0100 - val_accuracy: 0.6932\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3526 - accuracy: 0.9339 - val_loss: 1.0245 - val_accuracy: 0.7004\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3590 - accuracy: 0.9279 - val_loss: 1.1475 - val_accuracy: 0.6684\n","Epoch 66/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3677 - accuracy: 0.9269 - val_loss: 1.0534 - val_accuracy: 0.6798\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3515 - accuracy: 0.9315 - val_loss: 1.0330 - val_accuracy: 0.6983\n","Epoch 68/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3580 - accuracy: 0.9251 - val_loss: 1.0382 - val_accuracy: 0.6921\n","Epoch 69/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3580 - accuracy: 0.9269 - val_loss: 1.0412 - val_accuracy: 0.6911\n","Epoch 70/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3424 - accuracy: 0.9364 - val_loss: 1.1491 - val_accuracy: 0.6663\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3610 - accuracy: 0.9276 - val_loss: 1.0493 - val_accuracy: 0.6890\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3607 - accuracy: 0.9256 - val_loss: 1.0462 - val_accuracy: 0.6983\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3562 - accuracy: 0.9284 - val_loss: 1.0522 - val_accuracy: 0.6911\n","Epoch 74/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3375 - accuracy: 0.9375 - val_loss: 1.2338 - val_accuracy: 0.6632\n","Epoch 75/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3730 - accuracy: 0.9178 - val_loss: 1.0504 - val_accuracy: 0.6952\n","Epoch 76/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3733 - accuracy: 0.9204 - val_loss: 1.0489 - val_accuracy: 0.6901\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3321 - accuracy: 0.9442 - val_loss: 1.0913 - val_accuracy: 0.6839\n","Epoch 78/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3604 - accuracy: 0.9230 - val_loss: 1.1533 - val_accuracy: 0.6736\n","Epoch 79/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3320 - accuracy: 0.9416 - val_loss: 1.0886 - val_accuracy: 0.6921\n","Epoch 80/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3451 - accuracy: 0.9331 - val_loss: 1.0677 - val_accuracy: 0.6952\n","Epoch 81/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3353 - accuracy: 0.9354 - val_loss: 1.1029 - val_accuracy: 0.6901\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3641 - accuracy: 0.9183 - val_loss: 1.0587 - val_accuracy: 0.6870\n","Epoch 83/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3256 - accuracy: 0.9450 - val_loss: 1.0669 - val_accuracy: 0.6942\n","Epoch 84/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3388 - accuracy: 0.9362 - val_loss: 1.0705 - val_accuracy: 0.6952\n","Epoch 85/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3503 - accuracy: 0.9307 - val_loss: 1.0773 - val_accuracy: 0.6901\n","Epoch 86/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3288 - accuracy: 0.9372 - val_loss: 1.0824 - val_accuracy: 0.6870\n","Epoch 87/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3386 - accuracy: 0.9331 - val_loss: 1.2035 - val_accuracy: 0.6653\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3130 - accuracy: 0.9530 - val_loss: 1.1360 - val_accuracy: 0.6839\n","Epoch 89/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3223 - accuracy: 0.9424 - val_loss: 1.0928 - val_accuracy: 0.7035\n","Epoch 90/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3322 - accuracy: 0.9375 - val_loss: 1.0965 - val_accuracy: 0.6932\n","Epoch 91/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3156 - accuracy: 0.9512 - val_loss: 1.1191 - val_accuracy: 0.6839\n","Epoch 92/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3181 - accuracy: 0.9447 - val_loss: 1.2006 - val_accuracy: 0.6684\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3233 - accuracy: 0.9452 - val_loss: 1.1019 - val_accuracy: 0.6911\n","Epoch 94/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3197 - accuracy: 0.9473 - val_loss: 1.1250 - val_accuracy: 0.6798\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3197 - accuracy: 0.9426 - val_loss: 1.1814 - val_accuracy: 0.6767\n","Epoch 96/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3073 - accuracy: 0.9473 - val_loss: 1.1342 - val_accuracy: 0.6860\n","Epoch 97/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3283 - accuracy: 0.9382 - val_loss: 1.2506 - val_accuracy: 0.6756\n","Epoch 98/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3088 - accuracy: 0.9512 - val_loss: 1.2008 - val_accuracy: 0.6787\n","Epoch 99/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3139 - accuracy: 0.9465 - val_loss: 1.1729 - val_accuracy: 0.6777\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3144 - accuracy: 0.9473 - val_loss: 1.2032 - val_accuracy: 0.6725\n","{'loss': [0.5232720971107483, 0.5178797841072083, 0.5237168073654175, 0.5233511924743652, 0.4948231875896454, 0.49495869874954224, 0.49480968713760376, 0.5242204666137695, 0.49196964502334595, 0.49048230051994324, 0.4740389287471771, 0.48123782873153687, 0.4818408489227295, 0.4681752622127533, 0.4778917729854584, 0.515460729598999, 0.4705638885498047, 0.4559398591518402, 0.45935606956481934, 0.4419270157814026, 0.45627567172050476, 0.45541200041770935, 0.45599740743637085, 0.4633621871471405, 0.43675497174263, 0.45693185925483704, 0.4492045044898987, 0.4264216423034668, 0.4492923319339752, 0.43089616298675537, 0.43336182832717896, 0.430472195148468, 0.42441326379776, 0.41701540350914, 0.418521910905838, 0.41864490509033203, 0.4034060537815094, 0.41889768838882446, 0.41698962450027466, 0.4057771563529968, 0.41495102643966675, 0.4124312400817871, 0.44396182894706726, 0.4450637400150299, 0.43404582142829895, 0.40635251998901367, 0.3873727023601532, 0.37922391295433044, 0.38878515362739563, 0.3874828517436981, 0.3818623125553131, 0.3824506103992462, 0.39772969484329224, 0.39544573426246643, 0.36737918853759766, 0.3757425844669342, 0.42691758275032043, 0.36532068252563477, 0.3662179410457611, 0.36367037892341614, 0.405300110578537, 0.35608360171318054, 0.36263158917427063, 0.3526199460029602, 0.35899755358695984, 0.36771515011787415, 0.351476788520813, 0.35802826285362244, 0.3580252528190613, 0.34242480993270874, 0.3610335886478424, 0.3607318103313446, 0.3561568558216095, 0.33752888441085815, 0.3730325996875763, 0.3732684552669525, 0.3321153521537781, 0.36036524176597595, 0.3319908380508423, 0.34514319896698, 0.3352864682674408, 0.36409449577331543, 0.3255896270275116, 0.3388209640979767, 0.3502561151981354, 0.328753262758255, 0.3386472463607788, 0.31303560733795166, 0.3223350942134857, 0.33221742510795593, 0.3156406283378601, 0.31814044713974, 0.32328251004219055, 0.3196881115436554, 0.31973883509635925, 0.3072962760925293, 0.32825443148612976, 0.30880188941955566, 0.313944548368454, 0.3144049048423767], 'accuracy': [0.853746771812439, 0.8581395149230957, 0.8568475246429443, 0.8439276218414307, 0.8684754371643066, 0.8648578524589539, 0.8715762495994568, 0.8490955829620361, 0.8602067232131958, 0.866925060749054, 0.879328191280365, 0.8731266260147095, 0.866925060749054, 0.8803617358207703, 0.867958664894104, 0.8403100967407227, 0.8819121718406677, 0.883979320526123, 0.8844961524009705, 0.8906976580619812, 0.8824289441108704, 0.8842377066612244, 0.8816537261009216, 0.8806201815605164, 0.8932816386222839, 0.880103349685669, 0.8816537261009216, 0.9005168080329895, 0.8808785676956177, 0.8956072330474854, 0.8945736289024353, 0.9012919664382935, 0.897157609462738, 0.9015504121780396, 0.9038759469985962, 0.8987079858779907, 0.9111111164093018, 0.8958656191825867, 0.8992248177528381, 0.9093023538589478, 0.8997415900230408, 0.9051679372787476, 0.8844961524009705, 0.882170557975769, 0.89250648021698, 0.9031007885932922, 0.9180878400802612, 0.9232558012008667, 0.9191214442253113, 0.9160206913948059, 0.9222221970558167, 0.9219638109207153, 0.907493531703949, 0.9064599275588989, 0.9310077428817749, 0.9196382164955139, 0.8917312622070312, 0.9273901581764221, 0.9289405941963196, 0.9240310192108154, 0.9033591747283936, 0.9317829608917236, 0.9258397817611694, 0.933850109577179, 0.9279069900512695, 0.9268733859062195, 0.9315245747566223, 0.9250646233558655, 0.9268733859062195, 0.9364340901374817, 0.9276486039161682, 0.9255813956260681, 0.9284237623214722, 0.9374676942825317, 0.9178294539451599, 0.9204134345054626, 0.9441860318183899, 0.9229974150657654, 0.9416020512580872, 0.933074951171875, 0.9354005455970764, 0.9183462262153625, 0.9449612498283386, 0.9361757040023804, 0.9307493567466736, 0.9372093081474304, 0.933074951171875, 0.9529715776443481, 0.9423772692680359, 0.9374676942825317, 0.9511628150939941, 0.9447028636932373, 0.9452196359634399, 0.94728684425354, 0.9426356554031372, 0.94728684425354, 0.9382429122924805, 0.9511628150939941, 0.9465116262435913, 0.94728684425354], 'val_loss': [0.8847286105155945, 0.8860111236572266, 0.8871034979820251, 0.8836408257484436, 0.8865753412246704, 0.8846531510353088, 0.8802067637443542, 0.8825973272323608, 0.8759977221488953, 0.869361937046051, 0.8787769675254822, 0.8663886189460754, 0.8683618307113647, 0.8425368666648865, 0.8770188093185425, 0.8155104517936707, 0.8336010575294495, 0.8413708209991455, 0.7892947793006897, 0.8642067313194275, 0.7978336215019226, 0.7887264490127563, 0.8295868039131165, 0.8660546541213989, 0.8335997462272644, 0.8515607118606567, 0.9695850610733032, 0.8852035999298096, 0.9048197269439697, 0.9024646282196045, 0.9350961446762085, 0.9165922999382019, 0.9111713767051697, 0.944163978099823, 0.9439828395843506, 0.9485133290290833, 0.953084409236908, 0.9490184187889099, 0.9396564364433289, 0.9561272859573364, 0.956062912940979, 1.0120344161987305, 0.984155535697937, 1.0266293287277222, 0.9601004123687744, 0.9730885028839111, 0.9565056562423706, 0.9636125564575195, 0.9899237751960754, 0.9678488373756409, 0.9936414361000061, 0.9900882840156555, 1.0192086696624756, 1.059468388557434, 0.9893071055412292, 1.1501137018203735, 1.035199522972107, 0.9846047163009644, 1.0081899166107178, 1.0278784036636353, 1.0006035566329956, 1.0747500658035278, 1.0099529027938843, 1.024460792541504, 1.1475169658660889, 1.0533924102783203, 1.0330039262771606, 1.0381619930267334, 1.041232943534851, 1.1490861177444458, 1.0493206977844238, 1.0461663007736206, 1.0521694421768188, 1.233783483505249, 1.0504364967346191, 1.048943281173706, 1.0912576913833618, 1.1532899141311646, 1.0885875225067139, 1.0676544904708862, 1.102895736694336, 1.0586735010147095, 1.0668506622314453, 1.0705136060714722, 1.0772727727890015, 1.08243727684021, 1.203529953956604, 1.1359562873840332, 1.0927660465240479, 1.096450924873352, 1.1190547943115234, 1.2005703449249268, 1.1018742322921753, 1.125033974647522, 1.1813890933990479, 1.1342403888702393, 1.2505913972854614, 1.2008308172225952, 1.1728689670562744, 1.2032251358032227], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.48657023906707764, 0.48657023906707764, 0.4886363744735718, 0.4886363744735718, 0.4927685856819153, 0.4927685856819153, 0.4917355477809906, 0.5, 0.5051652789115906, 0.5485537052154541, 0.5165289044380188, 0.6322314143180847, 0.5878099203109741, 0.5919421315193176, 0.6859503984451294, 0.6167355179786682, 0.6818181872367859, 0.7035123705863953, 0.6818181872367859, 0.6745867729187012, 0.711776852607727, 0.7045454382896423, 0.6663222908973694, 0.6983470916748047, 0.6931818127632141, 0.6962810158729553, 0.6890496015548706, 0.7066115736961365, 0.7055785059928894, 0.6942148804664612, 0.6900826692581177, 0.702479362487793, 0.6962810158729553, 0.702479362487793, 0.6942148804664612, 0.692148745059967, 0.6983470916748047, 0.6890496015548706, 0.69111567735672, 0.682851254940033, 0.6900826692581177, 0.6880165338516235, 0.6993801593780518, 0.6942148804664612, 0.6962810158729553, 0.7004132270812988, 0.6880165338516235, 0.69111567735672, 0.68388432264328, 0.6735537052154541, 0.702479362487793, 0.663223147392273, 0.6849173307418823, 0.7014462947845459, 0.6973140239715576, 0.6890496015548706, 0.6962810158729553, 0.6745867729187012, 0.6931818127632141, 0.7004132270812988, 0.6683884263038635, 0.6797520518302917, 0.6983470916748047, 0.692148745059967, 0.69111567735672, 0.6663222908973694, 0.6890496015548706, 0.6983470916748047, 0.69111567735672, 0.663223147392273, 0.6952479481697083, 0.6900826692581177, 0.68388432264328, 0.6735537052154541, 0.692148745059967, 0.6952479481697083, 0.6900826692581177, 0.6869834661483765, 0.6942148804664612, 0.6952479481697083, 0.6900826692581177, 0.6869834661483765, 0.6652892827987671, 0.68388432264328, 0.7035123705863953, 0.6931818127632141, 0.68388432264328, 0.6683884263038635, 0.69111567735672, 0.6797520518302917, 0.6766529083251953, 0.6859503984451294, 0.6756198406219482, 0.6787189841270447, 0.6776859760284424, 0.672520637512207]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.4731 - accuracy: 0.8798"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 7s 57ms/step - loss: 0.4731 - accuracy: 0.8798 - val_loss: 0.8828 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3851 - accuracy: 0.9154 - val_loss: 0.8847 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3762 - accuracy: 0.9178 - val_loss: 0.8853 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3633 - accuracy: 0.9219 - val_loss: 0.8875 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3963 - accuracy: 0.9089 - val_loss: 0.8864 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4231 - accuracy: 0.8941 - val_loss: 0.8804 - val_accuracy: 0.4860\n","Epoch 7/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3791 - accuracy: 0.9151 - val_loss: 0.8840 - val_accuracy: 0.4860\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3627 - accuracy: 0.9256 - val_loss: 0.8869 - val_accuracy: 0.4860\n","Epoch 9/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3452 - accuracy: 0.9340 - val_loss: 0.8807 - val_accuracy: 0.4871\n","Epoch 10/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3492 - accuracy: 0.9270 - val_loss: 0.8759 - val_accuracy: 0.4903\n","Epoch 11/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3531 - accuracy: 0.9265 - val_loss: 0.8692 - val_accuracy: 0.4903\n","Epoch 12/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3518 - accuracy: 0.9324 - val_loss: 0.8677 - val_accuracy: 0.4968\n","Epoch 13/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.3359 - accuracy: 0.9397 - val_loss: 0.8511 - val_accuracy: 0.5022\n","Epoch 14/100\n","29/29 [==============================] - 1s 42ms/step - loss: 0.3383 - accuracy: 0.9388 - val_loss: 0.8345 - val_accuracy: 0.5129\n","Epoch 15/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.3394 - accuracy: 0.9335 - val_loss: 0.8349 - val_accuracy: 0.5237\n","Epoch 16/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3368 - accuracy: 0.9348 - val_loss: 0.8078 - val_accuracy: 0.5582\n","Epoch 17/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3349 - accuracy: 0.9378 - val_loss: 0.8624 - val_accuracy: 0.5334\n","Epoch 18/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3523 - accuracy: 0.9283 - val_loss: 0.7520 - val_accuracy: 0.6369\n","Epoch 19/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3272 - accuracy: 0.9394 - val_loss: 0.7670 - val_accuracy: 0.6358\n","Epoch 20/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3190 - accuracy: 0.9442 - val_loss: 0.7803 - val_accuracy: 0.6444\n","Epoch 21/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3204 - accuracy: 0.9450 - val_loss: 0.6685 - val_accuracy: 0.7565\n","Epoch 22/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3238 - accuracy: 0.9413 - val_loss: 0.6313 - val_accuracy: 0.7974\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3370 - accuracy: 0.9337 - val_loss: 0.6386 - val_accuracy: 0.7866\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3193 - accuracy: 0.9407 - val_loss: 0.7052 - val_accuracy: 0.7565\n","Epoch 25/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3077 - accuracy: 0.9515 - val_loss: 0.6666 - val_accuracy: 0.7877\n","Epoch 26/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3325 - accuracy: 0.9321 - val_loss: 0.6659 - val_accuracy: 0.7920\n","Epoch 27/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3194 - accuracy: 0.9399 - val_loss: 0.7058 - val_accuracy: 0.7845\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3234 - accuracy: 0.9399 - val_loss: 0.7123 - val_accuracy: 0.7748\n","Epoch 29/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3139 - accuracy: 0.9434 - val_loss: 0.8375 - val_accuracy: 0.7425\n","Epoch 30/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3090 - accuracy: 0.9450 - val_loss: 0.8576 - val_accuracy: 0.7489\n","Epoch 31/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3190 - accuracy: 0.9421 - val_loss: 0.7292 - val_accuracy: 0.7920\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2981 - accuracy: 0.9518 - val_loss: 0.7591 - val_accuracy: 0.7812\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2990 - accuracy: 0.9518 - val_loss: 0.8777 - val_accuracy: 0.7511\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3169 - accuracy: 0.9413 - val_loss: 0.7574 - val_accuracy: 0.7856\n","Epoch 35/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2951 - accuracy: 0.9485 - val_loss: 0.8394 - val_accuracy: 0.7651\n","Epoch 36/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3276 - accuracy: 0.9327 - val_loss: 0.7580 - val_accuracy: 0.7866\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2948 - accuracy: 0.9553 - val_loss: 0.8148 - val_accuracy: 0.7759\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2926 - accuracy: 0.9531 - val_loss: 0.7799 - val_accuracy: 0.7877\n","Epoch 39/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3056 - accuracy: 0.9448 - val_loss: 1.1699 - val_accuracy: 0.6961\n","Epoch 40/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3030 - accuracy: 0.9469 - val_loss: 0.8387 - val_accuracy: 0.7791\n","Epoch 41/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2851 - accuracy: 0.9558 - val_loss: 0.7815 - val_accuracy: 0.7845\n","Epoch 42/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2861 - accuracy: 0.9555 - val_loss: 0.7930 - val_accuracy: 0.7909\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2843 - accuracy: 0.9604 - val_loss: 0.7815 - val_accuracy: 0.7856\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2944 - accuracy: 0.9518 - val_loss: 0.9389 - val_accuracy: 0.7425\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2972 - accuracy: 0.9507 - val_loss: 0.7871 - val_accuracy: 0.7845\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2879 - accuracy: 0.9520 - val_loss: 0.8043 - val_accuracy: 0.7823\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2844 - accuracy: 0.9564 - val_loss: 0.7986 - val_accuracy: 0.7899\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2738 - accuracy: 0.9623 - val_loss: 0.9379 - val_accuracy: 0.7468\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2914 - accuracy: 0.9523 - val_loss: 0.8559 - val_accuracy: 0.7608\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2864 - accuracy: 0.9529 - val_loss: 0.8345 - val_accuracy: 0.7759\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2779 - accuracy: 0.9564 - val_loss: 0.8031 - val_accuracy: 0.7877\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2794 - accuracy: 0.9607 - val_loss: 0.8386 - val_accuracy: 0.7769\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2722 - accuracy: 0.9620 - val_loss: 0.8103 - val_accuracy: 0.7791\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2740 - accuracy: 0.9615 - val_loss: 0.8147 - val_accuracy: 0.7866\n","Epoch 55/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2694 - accuracy: 0.9626 - val_loss: 0.8082 - val_accuracy: 0.7856\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2759 - accuracy: 0.9617 - val_loss: 0.8002 - val_accuracy: 0.7802\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2701 - accuracy: 0.9591 - val_loss: 0.8597 - val_accuracy: 0.7694\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2593 - accuracy: 0.9706 - val_loss: 0.8360 - val_accuracy: 0.7812\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2735 - accuracy: 0.9591 - val_loss: 0.9015 - val_accuracy: 0.7640\n","Epoch 60/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3193 - accuracy: 0.9378 - val_loss: 0.9951 - val_accuracy: 0.7349\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3311 - accuracy: 0.9302 - val_loss: 1.4999 - val_accuracy: 0.6455\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3112 - accuracy: 0.9415 - val_loss: 0.8183 - val_accuracy: 0.7834\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2940 - accuracy: 0.9475 - val_loss: 0.7999 - val_accuracy: 0.7877\n","Epoch 64/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2527 - accuracy: 0.9717 - val_loss: 0.8286 - val_accuracy: 0.7780\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2481 - accuracy: 0.9728 - val_loss: 0.8687 - val_accuracy: 0.7662\n","Epoch 66/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2699 - accuracy: 0.9615 - val_loss: 0.8470 - val_accuracy: 0.7672\n","Epoch 67/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2537 - accuracy: 0.9717 - val_loss: 0.8470 - val_accuracy: 0.7759\n","Epoch 68/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2623 - accuracy: 0.9636 - val_loss: 0.8628 - val_accuracy: 0.7705\n","Epoch 69/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2587 - accuracy: 0.9652 - val_loss: 0.8297 - val_accuracy: 0.7812\n","Epoch 70/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2737 - accuracy: 0.9531 - val_loss: 0.8248 - val_accuracy: 0.7856\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2551 - accuracy: 0.9642 - val_loss: 0.8367 - val_accuracy: 0.7780\n","Epoch 72/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2451 - accuracy: 0.9709 - val_loss: 0.8406 - val_accuracy: 0.7899\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2508 - accuracy: 0.9717 - val_loss: 0.8989 - val_accuracy: 0.7672\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2885 - accuracy: 0.9496 - val_loss: 0.9087 - val_accuracy: 0.7629\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2619 - accuracy: 0.9644 - val_loss: 0.8461 - val_accuracy: 0.7856\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2520 - accuracy: 0.9682 - val_loss: 0.8665 - val_accuracy: 0.7759\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2642 - accuracy: 0.9639 - val_loss: 0.8517 - val_accuracy: 0.7812\n","Epoch 78/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2480 - accuracy: 0.9688 - val_loss: 0.9015 - val_accuracy: 0.7619\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2424 - accuracy: 0.9733 - val_loss: 0.8634 - val_accuracy: 0.7759\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2434 - accuracy: 0.9709 - val_loss: 0.9992 - val_accuracy: 0.7446\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2510 - accuracy: 0.9688 - val_loss: 0.8700 - val_accuracy: 0.7748\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2433 - accuracy: 0.9717 - val_loss: 0.9766 - val_accuracy: 0.7575\n","Epoch 83/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2384 - accuracy: 0.9752 - val_loss: 0.9267 - val_accuracy: 0.7683\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2521 - accuracy: 0.9698 - val_loss: 0.8778 - val_accuracy: 0.7640\n","Epoch 85/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2415 - accuracy: 0.9714 - val_loss: 0.9473 - val_accuracy: 0.7672\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2499 - accuracy: 0.9688 - val_loss: 0.9004 - val_accuracy: 0.7629\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2404 - accuracy: 0.9736 - val_loss: 0.8852 - val_accuracy: 0.7769\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2342 - accuracy: 0.9774 - val_loss: 0.8838 - val_accuracy: 0.7748\n","Epoch 89/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2328 - accuracy: 0.9784 - val_loss: 0.9287 - val_accuracy: 0.7651\n","Epoch 90/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2417 - accuracy: 0.9701 - val_loss: 0.9178 - val_accuracy: 0.7683\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2500 - accuracy: 0.9639 - val_loss: 0.8969 - val_accuracy: 0.7845\n","Epoch 92/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2260 - accuracy: 0.9782 - val_loss: 0.9189 - val_accuracy: 0.7780\n","Epoch 93/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2360 - accuracy: 0.9739 - val_loss: 0.9632 - val_accuracy: 0.7597\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2420 - accuracy: 0.9712 - val_loss: 0.9180 - val_accuracy: 0.7748\n","Epoch 95/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2894 - accuracy: 0.9450 - val_loss: 0.9339 - val_accuracy: 0.7737\n","Epoch 96/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2935 - accuracy: 0.9423 - val_loss: 1.1050 - val_accuracy: 0.7381\n","Epoch 97/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2408 - accuracy: 0.9723 - val_loss: 0.9093 - val_accuracy: 0.7694\n","Epoch 98/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2472 - accuracy: 0.9669 - val_loss: 0.8980 - val_accuracy: 0.7748\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2315 - accuracy: 0.9744 - val_loss: 0.9182 - val_accuracy: 0.7683\n","Epoch 100/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2558 - accuracy: 0.9650 - val_loss: 0.9821 - val_accuracy: 0.7575\n","{'loss': [0.4730948507785797, 0.3851303458213806, 0.3761705160140991, 0.3633210361003876, 0.39629432559013367, 0.4230528175830841, 0.3790934979915619, 0.36270737648010254, 0.3451661169528961, 0.3492106795310974, 0.35314810276031494, 0.3518212139606476, 0.33590924739837646, 0.3382969796657562, 0.3393917381763458, 0.33684390783309937, 0.33491095900535583, 0.35230553150177, 0.3272235095500946, 0.3189801275730133, 0.3204079270362854, 0.32380250096321106, 0.33698904514312744, 0.3193025588989258, 0.30772528052330017, 0.3325044810771942, 0.31936296820640564, 0.32343608140945435, 0.3138619363307953, 0.30898648500442505, 0.31896644830703735, 0.2981453835964203, 0.2989675998687744, 0.3168543577194214, 0.29511672258377075, 0.3276258111000061, 0.2947969436645508, 0.29262587428092957, 0.30558067560195923, 0.3029927611351013, 0.2850708067417145, 0.28608906269073486, 0.28433048725128174, 0.29435819387435913, 0.297171026468277, 0.287920206785202, 0.28437647223472595, 0.27382609248161316, 0.29140007495880127, 0.286373108625412, 0.2778981924057007, 0.27942466735839844, 0.27216506004333496, 0.2739865183830261, 0.26935699582099915, 0.2758561372756958, 0.2701248526573181, 0.259346604347229, 0.2735241949558258, 0.31931641697883606, 0.33111998438835144, 0.31122341752052307, 0.293962687253952, 0.2526763081550598, 0.2480936050415039, 0.26986438035964966, 0.25370752811431885, 0.26228153705596924, 0.2587241530418396, 0.2737106382846832, 0.25510168075561523, 0.2451389878988266, 0.2508343458175659, 0.2884995639324188, 0.2619396150112152, 0.2520243525505066, 0.26416414976119995, 0.24802793562412262, 0.2423587143421173, 0.2434406876564026, 0.25095418095588684, 0.24334046244621277, 0.2383992224931717, 0.25209757685661316, 0.24148832261562347, 0.24990785121917725, 0.24037498235702515, 0.23417797684669495, 0.2328416407108307, 0.24169082939624786, 0.24997159838676453, 0.22597621381282806, 0.23601043224334717, 0.24202655255794525, 0.28938519954681396, 0.2935197055339813, 0.24077537655830383, 0.24723361432552338, 0.23151005804538727, 0.2557620406150818], 'accuracy': [0.8798491358757019, 0.915409505367279, 0.9178340435028076, 0.921875, 0.9089439511299133, 0.8941271305084229, 0.9151400923728943, 0.9256465435028076, 0.9339978694915771, 0.9269935488700867, 0.9264547228813171, 0.9323814511299133, 0.9396551847457886, 0.938847005367279, 0.9334590435028076, 0.9348060488700867, 0.9377694129943848, 0.928340494632721, 0.9393857717514038, 0.9442349076271057, 0.9450430870056152, 0.9412715435028076, 0.9337284564971924, 0.9407327771186829, 0.951508641242981, 0.9321120977401733, 0.9399245977401733, 0.9399245977401733, 0.9434267282485962, 0.9450430870056152, 0.9420797228813171, 0.951777994632721, 0.951777994632721, 0.9412715435028076, 0.9485452771186829, 0.9326508641242981, 0.9552801847457886, 0.953125, 0.9447737336158752, 0.946928858757019, 0.9558189511299133, 0.9555495977401733, 0.9603987336158752, 0.951777994632721, 0.9507004022598267, 0.9520474076271057, 0.9563577771186829, 0.962284505367279, 0.9523168206214905, 0.9528555870056152, 0.9563577771186829, 0.9606680870056152, 0.9620150923728943, 0.9614762663841248, 0.962553858757019, 0.9617456793785095, 0.9590517282485962, 0.9706357717514038, 0.9590517282485962, 0.9377694129943848, 0.9302262663841248, 0.9415409564971924, 0.9474676847457886, 0.9717133641242981, 0.9727909564971924, 0.9614762663841248, 0.9717133641242981, 0.9636314511299133, 0.9652478694915771, 0.953125, 0.9641702771186829, 0.9709051847457886, 0.9717133641242981, 0.9496228694915771, 0.9644396305084229, 0.9682112336158752, 0.9639008641242981, 0.96875, 0.9733297228813171, 0.9709051847457886, 0.96875, 0.9717133641242981, 0.975215494632721, 0.9698275923728943, 0.9714439511299133, 0.96875, 0.9735991358757019, 0.9773706793785095, 0.9784482717514038, 0.970097005367279, 0.9639008641242981, 0.978178858757019, 0.9738685488700867, 0.9711745977401733, 0.9450430870056152, 0.9423491358757019, 0.9722521305084229, 0.9668642282485962, 0.9744073152542114, 0.9649784564971924], 'val_loss': [0.8827909231185913, 0.8847005367279053, 0.8852729201316833, 0.8874834179878235, 0.8863718509674072, 0.8804351091384888, 0.8839876055717468, 0.8868578672409058, 0.8806976675987244, 0.8759446740150452, 0.8692174553871155, 0.8677094578742981, 0.8510730862617493, 0.8345272541046143, 0.8349253535270691, 0.8077937364578247, 0.8624348640441895, 0.7520152926445007, 0.7669918537139893, 0.7802612781524658, 0.668493926525116, 0.6313474774360657, 0.6386007070541382, 0.7052490711212158, 0.6666001677513123, 0.6658980846405029, 0.7058435082435608, 0.7122725248336792, 0.8375446796417236, 0.8575872778892517, 0.729234516620636, 0.759139358997345, 0.8777141571044922, 0.7574119567871094, 0.8394469618797302, 0.7580193281173706, 0.8148214221000671, 0.7799080014228821, 1.1699048280715942, 0.8387349843978882, 0.781501829624176, 0.7930163741111755, 0.7815130949020386, 0.9388878345489502, 0.7871090173721313, 0.8043110966682434, 0.7985672950744629, 0.9379189014434814, 0.8559116125106812, 0.8344900608062744, 0.8030766248703003, 0.8386157751083374, 0.8102777004241943, 0.8146529793739319, 0.8081997632980347, 0.8001623749732971, 0.8596996068954468, 0.8359790444374084, 0.901540994644165, 0.9951497316360474, 1.4998939037322998, 0.8182960748672485, 0.7998720407485962, 0.8285613656044006, 0.8687352538108826, 0.8469970226287842, 0.8469902276992798, 0.8628076910972595, 0.8296644687652588, 0.8248322010040283, 0.8366679549217224, 0.8405869007110596, 0.8989347219467163, 0.9086588621139526, 0.8461056351661682, 0.8664595484733582, 0.8517220616340637, 0.9014781713485718, 0.8634143471717834, 0.999189555644989, 0.8699520230293274, 0.9766125679016113, 0.9267033934593201, 0.8777525424957275, 0.9473084807395935, 0.9004367589950562, 0.8851953148841858, 0.8838337063789368, 0.9286850690841675, 0.9177828431129456, 0.8969385623931885, 0.9189389944076538, 0.9632107019424438, 0.9179808497428894, 0.9338527917861938, 1.1050140857696533, 0.909299373626709, 0.8980286121368408, 0.9181764721870422, 0.9820953607559204], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.48599138855934143, 0.48599138855934143, 0.48706895112991333, 0.4903017282485962, 0.4903017282485962, 0.4967672526836395, 0.5021551847457886, 0.5129310488700867, 0.5237069129943848, 0.5581896305084229, 0.5334051847457886, 0.6368534564971924, 0.6357758641242981, 0.6443965435028076, 0.756465494632721, 0.7974137663841248, 0.7866379022598267, 0.756465494632721, 0.787715494632721, 0.7920258641242981, 0.7844827771186829, 0.774784505367279, 0.7424569129943848, 0.7489224076271057, 0.7920258641242981, 0.78125, 0.7510775923728943, 0.7855603694915771, 0.7650862336158752, 0.7866379022598267, 0.7758620977401733, 0.787715494632721, 0.6961206793785095, 0.7790948152542114, 0.7844827771186829, 0.7909482717514038, 0.7855603694915771, 0.7424569129943848, 0.7844827771186829, 0.7823275923728943, 0.7898706793785095, 0.7467672228813171, 0.7607758641242981, 0.7758620977401733, 0.787715494632721, 0.7769396305084229, 0.7790948152542114, 0.7866379022598267, 0.7855603694915771, 0.7801724076271057, 0.7693965435028076, 0.78125, 0.764008641242981, 0.7349137663841248, 0.6454741358757019, 0.7834051847457886, 0.787715494632721, 0.7780172228813171, 0.7661637663841248, 0.767241358757019, 0.7758620977401733, 0.7704741358757019, 0.78125, 0.7855603694915771, 0.7780172228813171, 0.7898706793785095, 0.767241358757019, 0.7629310488700867, 0.7855603694915771, 0.7758620977401733, 0.78125, 0.7618534564971924, 0.7758620977401733, 0.7446120977401733, 0.774784505367279, 0.7575430870056152, 0.7683189511299133, 0.764008641242981, 0.767241358757019, 0.7629310488700867, 0.7769396305084229, 0.774784505367279, 0.7650862336158752, 0.7683189511299133, 0.7844827771186829, 0.7780172228813171, 0.7596982717514038, 0.774784505367279, 0.7737069129943848, 0.7381465435028076, 0.7693965435028076, 0.774784505367279, 0.7683189511299133, 0.7575430870056152]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.4987 - accuracy: 0.8639"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 80ms/step - loss: 0.4941 - accuracy: 0.8659 - val_loss: 0.8780 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4041 - accuracy: 0.9055 - val_loss: 0.8778 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3668 - accuracy: 0.9256 - val_loss: 0.8780 - val_accuracy: 0.4966\n","Epoch 4/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3690 - accuracy: 0.9211 - val_loss: 0.8797 - val_accuracy: 0.4977\n","Epoch 5/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3669 - accuracy: 0.9208 - val_loss: 0.8812 - val_accuracy: 0.4977\n","Epoch 6/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3621 - accuracy: 0.9222 - val_loss: 0.8801 - val_accuracy: 0.4989\n","Epoch 7/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3540 - accuracy: 0.9247 - val_loss: 0.8787 - val_accuracy: 0.4989\n","Epoch 8/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3722 - accuracy: 0.9194 - val_loss: 0.8721 - val_accuracy: 0.4989\n","Epoch 9/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3796 - accuracy: 0.9134 - val_loss: 0.8673 - val_accuracy: 0.5011\n","Epoch 10/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3637 - accuracy: 0.9191 - val_loss: 0.8620 - val_accuracy: 0.5011\n","Epoch 11/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3454 - accuracy: 0.9298 - val_loss: 0.8553 - val_accuracy: 0.5057\n","Epoch 12/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3362 - accuracy: 0.9360 - val_loss: 0.8486 - val_accuracy: 0.5124\n","Epoch 13/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3555 - accuracy: 0.9259 - val_loss: 0.8339 - val_accuracy: 0.5181\n","Epoch 14/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3594 - accuracy: 0.9247 - val_loss: 0.8220 - val_accuracy: 0.5328\n","Epoch 15/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3329 - accuracy: 0.9409 - val_loss: 0.8098 - val_accuracy: 0.5441\n","Epoch 16/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3299 - accuracy: 0.9394 - val_loss: 0.8065 - val_accuracy: 0.5475\n","Epoch 17/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3381 - accuracy: 0.9369 - val_loss: 0.8140 - val_accuracy: 0.5577\n","Epoch 18/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.3286 - accuracy: 0.9437 - val_loss: 0.7390 - val_accuracy: 0.6301\n","Epoch 19/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.3206 - accuracy: 0.9460 - val_loss: 0.7241 - val_accuracy: 0.6572\n","Epoch 20/100\n","28/28 [==============================] - 1s 42ms/step - loss: 0.3407 - accuracy: 0.9298 - val_loss: 0.6754 - val_accuracy: 0.7274\n","Epoch 21/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3223 - accuracy: 0.9420 - val_loss: 0.6488 - val_accuracy: 0.7715\n","Epoch 22/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3438 - accuracy: 0.9278 - val_loss: 0.6700 - val_accuracy: 0.7455\n","Epoch 23/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3099 - accuracy: 0.9462 - val_loss: 0.6221 - val_accuracy: 0.7873\n","Epoch 24/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3495 - accuracy: 0.9250 - val_loss: 0.5974 - val_accuracy: 0.8133\n","Epoch 25/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3523 - accuracy: 0.9208 - val_loss: 0.6019 - val_accuracy: 0.8190\n","Epoch 26/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3284 - accuracy: 0.9389 - val_loss: 0.6191 - val_accuracy: 0.8111\n","Epoch 27/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3133 - accuracy: 0.9440 - val_loss: 0.6332 - val_accuracy: 0.8145\n","Epoch 28/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3204 - accuracy: 0.9394 - val_loss: 0.6424 - val_accuracy: 0.7998\n","Epoch 29/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3125 - accuracy: 0.9493 - val_loss: 0.7130 - val_accuracy: 0.7851\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3080 - accuracy: 0.9479 - val_loss: 0.6558 - val_accuracy: 0.8054\n","Epoch 31/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3041 - accuracy: 0.9491 - val_loss: 0.6676 - val_accuracy: 0.8201\n","Epoch 32/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3016 - accuracy: 0.9510 - val_loss: 0.6822 - val_accuracy: 0.8122\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3290 - accuracy: 0.9324 - val_loss: 0.7731 - val_accuracy: 0.7817\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3340 - accuracy: 0.9307 - val_loss: 0.6956 - val_accuracy: 0.8077\n","Epoch 35/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3119 - accuracy: 0.9474 - val_loss: 0.7067 - val_accuracy: 0.8009\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2955 - accuracy: 0.9559 - val_loss: 0.7030 - val_accuracy: 0.8020\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3114 - accuracy: 0.9443 - val_loss: 0.7204 - val_accuracy: 0.8088\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3165 - accuracy: 0.9414 - val_loss: 0.7099 - val_accuracy: 0.7998\n","Epoch 39/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3121 - accuracy: 0.9440 - val_loss: 0.7761 - val_accuracy: 0.7828\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2907 - accuracy: 0.9544 - val_loss: 0.7699 - val_accuracy: 0.7839\n","Epoch 41/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2991 - accuracy: 0.9462 - val_loss: 0.7196 - val_accuracy: 0.8077\n","Epoch 42/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2973 - accuracy: 0.9505 - val_loss: 0.7384 - val_accuracy: 0.7964\n","Epoch 43/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2884 - accuracy: 0.9576 - val_loss: 0.7237 - val_accuracy: 0.8100\n","Epoch 44/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2898 - accuracy: 0.9530 - val_loss: 0.7854 - val_accuracy: 0.7896\n","Epoch 45/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2995 - accuracy: 0.9505 - val_loss: 0.7331 - val_accuracy: 0.8054\n","Epoch 46/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3064 - accuracy: 0.9465 - val_loss: 0.8080 - val_accuracy: 0.7839\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3197 - accuracy: 0.9380 - val_loss: 0.7389 - val_accuracy: 0.8032\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2799 - accuracy: 0.9621 - val_loss: 0.8076 - val_accuracy: 0.7862\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2778 - accuracy: 0.9593 - val_loss: 0.7388 - val_accuracy: 0.8043\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2929 - accuracy: 0.9474 - val_loss: 0.8518 - val_accuracy: 0.7805\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3112 - accuracy: 0.9420 - val_loss: 1.1930 - val_accuracy: 0.6923\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3766 - accuracy: 0.9123 - val_loss: 0.7880 - val_accuracy: 0.7873\n","Epoch 53/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3059 - accuracy: 0.9462 - val_loss: 0.7350 - val_accuracy: 0.8145\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2858 - accuracy: 0.9559 - val_loss: 0.8407 - val_accuracy: 0.7794\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2799 - accuracy: 0.9567 - val_loss: 0.7404 - val_accuracy: 0.8066\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2720 - accuracy: 0.9626 - val_loss: 0.7740 - val_accuracy: 0.7998\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2839 - accuracy: 0.9573 - val_loss: 0.7447 - val_accuracy: 0.8009\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2833 - accuracy: 0.9576 - val_loss: 0.7626 - val_accuracy: 0.7975\n","Epoch 59/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2715 - accuracy: 0.9590 - val_loss: 0.8829 - val_accuracy: 0.7704\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2956 - accuracy: 0.9488 - val_loss: 1.0002 - val_accuracy: 0.7421\n","Epoch 61/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3555 - accuracy: 0.9225 - val_loss: 0.7882 - val_accuracy: 0.8009\n","Epoch 62/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2882 - accuracy: 0.9544 - val_loss: 0.7658 - val_accuracy: 0.8020\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2960 - accuracy: 0.9465 - val_loss: 0.7578 - val_accuracy: 0.8009\n","Epoch 64/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2661 - accuracy: 0.9641 - val_loss: 0.7663 - val_accuracy: 0.7941\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2640 - accuracy: 0.9638 - val_loss: 0.7630 - val_accuracy: 0.8020\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2545 - accuracy: 0.9692 - val_loss: 0.7677 - val_accuracy: 0.7941\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2596 - accuracy: 0.9680 - val_loss: 0.7980 - val_accuracy: 0.7862\n","Epoch 68/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2561 - accuracy: 0.9675 - val_loss: 0.7960 - val_accuracy: 0.7952\n","Epoch 69/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2533 - accuracy: 0.9692 - val_loss: 0.8727 - val_accuracy: 0.7805\n","Epoch 70/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2539 - accuracy: 0.9694 - val_loss: 0.8543 - val_accuracy: 0.7749\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2683 - accuracy: 0.9584 - val_loss: 0.7963 - val_accuracy: 0.7930\n","Epoch 72/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2444 - accuracy: 0.9740 - val_loss: 0.8740 - val_accuracy: 0.7749\n","Epoch 73/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2694 - accuracy: 0.9618 - val_loss: 0.9175 - val_accuracy: 0.7636\n","Epoch 74/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2547 - accuracy: 0.9669 - val_loss: 0.9779 - val_accuracy: 0.7590\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2555 - accuracy: 0.9658 - val_loss: 0.8657 - val_accuracy: 0.7771\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2529 - accuracy: 0.9706 - val_loss: 0.8718 - val_accuracy: 0.7794\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2542 - accuracy: 0.9652 - val_loss: 0.9204 - val_accuracy: 0.7647\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2453 - accuracy: 0.9737 - val_loss: 0.8369 - val_accuracy: 0.7998\n","Epoch 79/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2440 - accuracy: 0.9714 - val_loss: 0.9232 - val_accuracy: 0.7647\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2465 - accuracy: 0.9711 - val_loss: 0.8277 - val_accuracy: 0.7907\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2436 - accuracy: 0.9731 - val_loss: 0.9053 - val_accuracy: 0.7749\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2443 - accuracy: 0.9720 - val_loss: 0.8333 - val_accuracy: 0.7964\n","Epoch 83/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2341 - accuracy: 0.9788 - val_loss: 0.8635 - val_accuracy: 0.7873\n","Epoch 84/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2415 - accuracy: 0.9751 - val_loss: 0.9626 - val_accuracy: 0.7704\n","Epoch 85/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2532 - accuracy: 0.9663 - val_loss: 0.8447 - val_accuracy: 0.7941\n","Epoch 86/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2705 - accuracy: 0.9567 - val_loss: 1.3838 - val_accuracy: 0.7002\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2647 - accuracy: 0.9561 - val_loss: 0.8647 - val_accuracy: 0.7873\n","Epoch 88/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2370 - accuracy: 0.9751 - val_loss: 0.8577 - val_accuracy: 0.7896\n","Epoch 89/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2479 - accuracy: 0.9677 - val_loss: 0.8619 - val_accuracy: 0.7828\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2669 - accuracy: 0.9564 - val_loss: 0.8887 - val_accuracy: 0.7805\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2540 - accuracy: 0.9683 - val_loss: 0.8600 - val_accuracy: 0.7839\n","Epoch 92/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2276 - accuracy: 0.9802 - val_loss: 0.9758 - val_accuracy: 0.7658\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2434 - accuracy: 0.9700 - val_loss: 0.8684 - val_accuracy: 0.7873\n","Epoch 94/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2407 - accuracy: 0.9703 - val_loss: 0.8625 - val_accuracy: 0.7873\n","Epoch 95/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2469 - accuracy: 0.9672 - val_loss: 0.8969 - val_accuracy: 0.7760\n","Epoch 96/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2276 - accuracy: 0.9779 - val_loss: 0.9314 - val_accuracy: 0.7749\n","Epoch 97/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2299 - accuracy: 0.9762 - val_loss: 0.8923 - val_accuracy: 0.7771\n","Epoch 98/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2421 - accuracy: 0.9692 - val_loss: 0.9035 - val_accuracy: 0.7783\n","Epoch 99/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2327 - accuracy: 0.9748 - val_loss: 0.8780 - val_accuracy: 0.7896\n","Epoch 100/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2285 - accuracy: 0.9785 - val_loss: 0.9151 - val_accuracy: 0.7817\n","{'loss': [0.4941422939300537, 0.404148131608963, 0.36676025390625, 0.3690069913864136, 0.36689266562461853, 0.36210957169532776, 0.35404422879219055, 0.372200071811676, 0.3796122372150421, 0.36368680000305176, 0.3453523814678192, 0.3362278938293457, 0.3555368185043335, 0.35944607853889465, 0.3329026699066162, 0.3299392759799957, 0.33808204531669617, 0.3286248743534088, 0.3206302523612976, 0.3406752347946167, 0.322257399559021, 0.34382694959640503, 0.30986645817756653, 0.3494894206523895, 0.35233375430107117, 0.3283843398094177, 0.31325605511665344, 0.3204231858253479, 0.31252041459083557, 0.30801403522491455, 0.3040556013584137, 0.3016253113746643, 0.3289753496646881, 0.3340047597885132, 0.3118751347064972, 0.29547813534736633, 0.31143316626548767, 0.3165108859539032, 0.3121180236339569, 0.29067903757095337, 0.29910948872566223, 0.29730889201164246, 0.2884093225002289, 0.2898472845554352, 0.2995324730873108, 0.30636361241340637, 0.3196788728237152, 0.27988770604133606, 0.2777671217918396, 0.29293763637542725, 0.311165452003479, 0.37659621238708496, 0.3058820962905884, 0.2858127951622009, 0.2799297273159027, 0.27196812629699707, 0.2839128375053406, 0.28325575590133667, 0.2714775502681732, 0.29561498761177063, 0.35546576976776123, 0.2882271409034729, 0.29601573944091797, 0.26614245772361755, 0.26396143436431885, 0.25448915362358093, 0.2595648765563965, 0.2560507655143738, 0.2532750070095062, 0.2538636028766632, 0.2682645320892334, 0.24435953795909882, 0.2694369852542877, 0.2547089755535126, 0.25552165508270264, 0.2528681755065918, 0.25419190526008606, 0.24532008171081543, 0.24400681257247925, 0.24654193222522736, 0.24357487261295319, 0.2443459928035736, 0.23413865268230438, 0.24148431420326233, 0.25318643450737, 0.27047112584114075, 0.2646635174751282, 0.23696202039718628, 0.24789895117282867, 0.26688602566719055, 0.25400540232658386, 0.2276231348514557, 0.24338939785957336, 0.24065524339675903, 0.2469332218170166, 0.22762948274612427, 0.22990857064723969, 0.24214687943458557, 0.2327014058828354, 0.2285037487745285], 'accuracy': [0.8658743500709534, 0.9054895043373108, 0.9255800843238831, 0.9210526347160339, 0.9207696914672852, 0.9221844673156738, 0.9247311949729919, 0.9193548560142517, 0.9134125709533691, 0.9190718531608582, 0.9298245906829834, 0.9360498189926147, 0.9258630275726318, 0.9247311949729919, 0.9408602118492126, 0.9394453763961792, 0.9368987083435059, 0.9436898827552795, 0.9459536075592041, 0.9298245906829834, 0.9419921040534973, 0.9278438091278076, 0.9462365508079529, 0.9250141382217407, 0.9207696914672852, 0.9388794302940369, 0.9439728260040283, 0.9394453763961792, 0.9493491649627686, 0.9479343295097351, 0.9490662217140198, 0.9510469436645508, 0.9323712587356567, 0.9306734800338745, 0.9473684430122375, 0.9558573961257935, 0.9442558288574219, 0.941426157951355, 0.9439728260040283, 0.95444256067276, 0.9462365508079529, 0.9504810571670532, 0.9575551748275757, 0.9530277252197266, 0.9504810571670532, 0.9465195536613464, 0.9380305409431458, 0.9620826244354248, 0.9592529535293579, 0.9473684430122375, 0.9419921040534973, 0.9122806787490845, 0.9462365508079529, 0.9558573961257935, 0.9567062854766846, 0.9626485705375671, 0.9572722315788269, 0.9575551748275757, 0.9589700102806091, 0.9487832188606262, 0.9224674701690674, 0.95444256067276, 0.9465195536613464, 0.9640634059906006, 0.963780403137207, 0.9691567420959473, 0.9680249094963074, 0.967458963394165, 0.9691567420959473, 0.9694397449493408, 0.9584040641784668, 0.9739671945571899, 0.961799681186676, 0.9668930172920227, 0.9657611846923828, 0.9705715775489807, 0.9651952385902405, 0.9736841917037964, 0.9714204668998718, 0.971137523651123, 0.9731183052062988, 0.9719864130020142, 0.9787775874137878, 0.9750990271568298, 0.9663271307945251, 0.9567062854766846, 0.9561403393745422, 0.9750990271568298, 0.9677419066429138, 0.9564233422279358, 0.9683078527450562, 0.9801924228668213, 0.9700056314468384, 0.9702886343002319, 0.9671760201454163, 0.9779286980628967, 0.9762309193611145, 0.9691567420959473, 0.974816083908081, 0.9784946441650391], 'val_loss': [0.8779561519622803, 0.8778485059738159, 0.8780043125152588, 0.8796860575675964, 0.8812412619590759, 0.8801140189170837, 0.8787167072296143, 0.8720645904541016, 0.8672882914543152, 0.8620431423187256, 0.8552947640419006, 0.8486175537109375, 0.8339439630508423, 0.8220275044441223, 0.8097912669181824, 0.8065320253372192, 0.8139917850494385, 0.738950788974762, 0.7240551710128784, 0.6753595471382141, 0.648757815361023, 0.67002272605896, 0.6221355199813843, 0.59736168384552, 0.6018845438957214, 0.6190965175628662, 0.633228063583374, 0.6424359679222107, 0.7129867076873779, 0.6558222770690918, 0.6676146388053894, 0.6822460889816284, 0.773066520690918, 0.6955569386482239, 0.7066856026649475, 0.7030494809150696, 0.7204049825668335, 0.7099407911300659, 0.7761040329933167, 0.7698805928230286, 0.7195761799812317, 0.7384222149848938, 0.7236945629119873, 0.7853546738624573, 0.7330777049064636, 0.8080030083656311, 0.7388884425163269, 0.8075918555259705, 0.7388272285461426, 0.8517991900444031, 1.1929576396942139, 0.7880286574363708, 0.7350381016731262, 0.8407284021377563, 0.7404312491416931, 0.7739551663398743, 0.7446914315223694, 0.7626487016677856, 0.8828502893447876, 1.0001715421676636, 0.7882031798362732, 0.7658477425575256, 0.7578455209732056, 0.7663156390190125, 0.7630131244659424, 0.7677440643310547, 0.7980312705039978, 0.7959850430488586, 0.8726640343666077, 0.8542527556419373, 0.7962629795074463, 0.8740181922912598, 0.9174565076828003, 0.9778836369514465, 0.8657386898994446, 0.871833860874176, 0.9203796982765198, 0.8369436264038086, 0.9231818914413452, 0.8276548981666565, 0.9053426384925842, 0.8333094120025635, 0.8635483384132385, 0.962591826915741, 0.8447000980377197, 1.383838415145874, 0.8646860718727112, 0.8577335476875305, 0.8618600368499756, 0.8886672258377075, 0.8600309491157532, 0.9757581353187561, 0.8683861494064331, 0.86247718334198, 0.896923840045929, 0.9313550591468811, 0.8923340439796448, 0.903516948223114, 0.8780341744422913, 0.9150688052177429], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.4977375566959381, 0.4977375566959381, 0.49886876344680786, 0.49886876344680786, 0.49886876344680786, 0.5011312365531921, 0.5011312365531921, 0.5056561231613159, 0.5124434232711792, 0.5180995464324951, 0.5328054428100586, 0.5441176295280457, 0.5475113391876221, 0.557692289352417, 0.6300904750823975, 0.6572397947311401, 0.7273755669593811, 0.7714931964874268, 0.7454751133918762, 0.7873303294181824, 0.8133484125137329, 0.8190045356750488, 0.8110859990119934, 0.814479649066925, 0.7997737526893616, 0.7850678563117981, 0.8054298758506775, 0.820135772228241, 0.8122171759605408, 0.7816742062568665, 0.807692289352417, 0.8009049892425537, 0.8020362257957458, 0.8088235259056091, 0.7997737526893616, 0.7828054428100586, 0.7839366793632507, 0.807692289352417, 0.7963801026344299, 0.8099547624588013, 0.7895927429199219, 0.8054298758506775, 0.7839366793632507, 0.8031674027442932, 0.7861990928649902, 0.8042986392974854, 0.7805429697036743, 0.692307710647583, 0.7873303294181824, 0.814479649066925, 0.779411792755127, 0.8065611124038696, 0.7997737526893616, 0.8009049892425537, 0.7975113391876221, 0.7703620195388794, 0.7420814633369446, 0.8009049892425537, 0.8020362257957458, 0.8009049892425537, 0.7941176295280457, 0.8020362257957458, 0.7941176295280457, 0.7861990928649902, 0.7952488660812378, 0.7805429697036743, 0.7748869061470032, 0.7929864525794983, 0.7748869061470032, 0.7635746598243713, 0.7590497732162476, 0.7771493196487427, 0.779411792755127, 0.7647058963775635, 0.7997737526893616, 0.7647058963775635, 0.790723979473114, 0.7748869061470032, 0.7963801026344299, 0.7873303294181824, 0.7703620195388794, 0.7941176295280457, 0.7002262473106384, 0.7873303294181824, 0.7895927429199219, 0.7828054428100586, 0.7805429697036743, 0.7839366793632507, 0.7658371329307556, 0.7873303294181824, 0.7873303294181824, 0.7760180830955505, 0.7748869061470032, 0.7771493196487427, 0.7782805562019348, 0.7895927429199219, 0.7816742062568665]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.5119 - accuracy: 0.8633"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 8s 65ms/step - loss: 0.5119 - accuracy: 0.8633 - val_loss: 0.8838 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3998 - accuracy: 0.9096 - val_loss: 0.8844 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.3760 - accuracy: 0.9194 - val_loss: 0.8858 - val_accuracy: 0.4876\n","Epoch 4/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3761 - accuracy: 0.9225 - val_loss: 0.8866 - val_accuracy: 0.4876\n","Epoch 5/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3724 - accuracy: 0.9181 - val_loss: 0.8904 - val_accuracy: 0.4866\n","Epoch 6/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3813 - accuracy: 0.9093 - val_loss: 0.8877 - val_accuracy: 0.4866\n","Epoch 7/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3919 - accuracy: 0.9065 - val_loss: 0.8858 - val_accuracy: 0.4876\n","Epoch 8/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3747 - accuracy: 0.9220 - val_loss: 0.8882 - val_accuracy: 0.4897\n","Epoch 9/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3646 - accuracy: 0.9191 - val_loss: 0.9044 - val_accuracy: 0.4886\n","Epoch 10/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3894 - accuracy: 0.9106 - val_loss: 0.8818 - val_accuracy: 0.4928\n","Epoch 11/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3599 - accuracy: 0.9269 - val_loss: 0.8721 - val_accuracy: 0.4938\n","Epoch 12/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3471 - accuracy: 0.9354 - val_loss: 0.8688 - val_accuracy: 0.4990\n","Epoch 13/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3652 - accuracy: 0.9225 - val_loss: 0.8629 - val_accuracy: 0.5114\n","Epoch 14/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3447 - accuracy: 0.9282 - val_loss: 0.8465 - val_accuracy: 0.5289\n","Epoch 15/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3721 - accuracy: 0.9194 - val_loss: 0.8624 - val_accuracy: 0.5320\n","Epoch 16/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3564 - accuracy: 0.9300 - val_loss: 0.9203 - val_accuracy: 0.5238\n","Epoch 17/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3464 - accuracy: 0.9341 - val_loss: 0.8694 - val_accuracy: 0.5589\n","Epoch 18/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3453 - accuracy: 0.9315 - val_loss: 0.8979 - val_accuracy: 0.5723\n","Epoch 19/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3728 - accuracy: 0.9183 - val_loss: 0.8491 - val_accuracy: 0.6178\n","Epoch 20/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3466 - accuracy: 0.9274 - val_loss: 0.7538 - val_accuracy: 0.7200\n","Epoch 21/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3597 - accuracy: 0.9194 - val_loss: 0.7928 - val_accuracy: 0.7056\n","Epoch 22/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3306 - accuracy: 0.9380 - val_loss: 0.8245 - val_accuracy: 0.7045\n","Epoch 23/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3302 - accuracy: 0.9398 - val_loss: 0.8240 - val_accuracy: 0.7242\n","Epoch 24/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3314 - accuracy: 0.9367 - val_loss: 0.8689 - val_accuracy: 0.7190\n","Epoch 25/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3426 - accuracy: 0.9307 - val_loss: 1.1964 - val_accuracy: 0.6312\n","Epoch 26/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3808 - accuracy: 0.9072 - val_loss: 0.8362 - val_accuracy: 0.7500\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3300 - accuracy: 0.9377 - val_loss: 0.9209 - val_accuracy: 0.7283\n","Epoch 28/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3287 - accuracy: 0.9372 - val_loss: 0.8588 - val_accuracy: 0.7531\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3274 - accuracy: 0.9390 - val_loss: 0.9899 - val_accuracy: 0.7128\n","Epoch 30/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3269 - accuracy: 0.9380 - val_loss: 0.9917 - val_accuracy: 0.7159\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3095 - accuracy: 0.9463 - val_loss: 0.9132 - val_accuracy: 0.7459\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3197 - accuracy: 0.9401 - val_loss: 0.8970 - val_accuracy: 0.7500\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3212 - accuracy: 0.9432 - val_loss: 0.9827 - val_accuracy: 0.7376\n","Epoch 34/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3035 - accuracy: 0.9527 - val_loss: 0.9238 - val_accuracy: 0.7500\n","Epoch 35/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3350 - accuracy: 0.9367 - val_loss: 1.2597 - val_accuracy: 0.6787\n","Epoch 36/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3253 - accuracy: 0.9375 - val_loss: 0.9357 - val_accuracy: 0.7417\n","Epoch 37/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3083 - accuracy: 0.9488 - val_loss: 0.9699 - val_accuracy: 0.7345\n","Epoch 38/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3195 - accuracy: 0.9432 - val_loss: 0.9348 - val_accuracy: 0.7490\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3089 - accuracy: 0.9483 - val_loss: 0.9783 - val_accuracy: 0.7324\n","Epoch 40/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3101 - accuracy: 0.9437 - val_loss: 0.9537 - val_accuracy: 0.7428\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3099 - accuracy: 0.9499 - val_loss: 0.9623 - val_accuracy: 0.7428\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3279 - accuracy: 0.9341 - val_loss: 0.9966 - val_accuracy: 0.7366\n","Epoch 43/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2973 - accuracy: 0.9532 - val_loss: 0.9861 - val_accuracy: 0.7345\n","Epoch 44/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2914 - accuracy: 0.9535 - val_loss: 0.9802 - val_accuracy: 0.7366\n","Epoch 45/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2899 - accuracy: 0.9563 - val_loss: 0.9649 - val_accuracy: 0.7386\n","Epoch 46/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2917 - accuracy: 0.9530 - val_loss: 0.9631 - val_accuracy: 0.7397\n","Epoch 47/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2915 - accuracy: 0.9553 - val_loss: 1.1651 - val_accuracy: 0.6983\n","Epoch 48/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3087 - accuracy: 0.9434 - val_loss: 0.9759 - val_accuracy: 0.7386\n","Epoch 49/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2949 - accuracy: 0.9548 - val_loss: 0.9848 - val_accuracy: 0.7417\n","Epoch 50/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3285 - accuracy: 0.9318 - val_loss: 1.0505 - val_accuracy: 0.7242\n","Epoch 51/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2805 - accuracy: 0.9574 - val_loss: 1.2936 - val_accuracy: 0.6808\n","Epoch 52/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3319 - accuracy: 0.9310 - val_loss: 0.9778 - val_accuracy: 0.7428\n","Epoch 53/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2828 - accuracy: 0.9607 - val_loss: 0.9776 - val_accuracy: 0.7469\n","Epoch 54/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2946 - accuracy: 0.9514 - val_loss: 0.9826 - val_accuracy: 0.7500\n","Epoch 55/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2842 - accuracy: 0.9587 - val_loss: 1.0054 - val_accuracy: 0.7335\n","Epoch 56/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2865 - accuracy: 0.9563 - val_loss: 1.0172 - val_accuracy: 0.7355\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2948 - accuracy: 0.9530 - val_loss: 0.9910 - val_accuracy: 0.7376\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2883 - accuracy: 0.9558 - val_loss: 1.0445 - val_accuracy: 0.7293\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2702 - accuracy: 0.9659 - val_loss: 0.9954 - val_accuracy: 0.7438\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2917 - accuracy: 0.9514 - val_loss: 1.0014 - val_accuracy: 0.7397\n","Epoch 61/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2679 - accuracy: 0.9623 - val_loss: 1.1843 - val_accuracy: 0.7149\n","Epoch 62/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2767 - accuracy: 0.9597 - val_loss: 1.0785 - val_accuracy: 0.7242\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2776 - accuracy: 0.9592 - val_loss: 1.0253 - val_accuracy: 0.7397\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2749 - accuracy: 0.9605 - val_loss: 1.0386 - val_accuracy: 0.7345\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2660 - accuracy: 0.9664 - val_loss: 1.1101 - val_accuracy: 0.7180\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2823 - accuracy: 0.9522 - val_loss: 1.0385 - val_accuracy: 0.7366\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2634 - accuracy: 0.9677 - val_loss: 1.0307 - val_accuracy: 0.7407\n","Epoch 68/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2845 - accuracy: 0.9558 - val_loss: 1.3800 - val_accuracy: 0.6756\n","Epoch 69/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3314 - accuracy: 0.9295 - val_loss: 1.0291 - val_accuracy: 0.7376\n","Epoch 70/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2819 - accuracy: 0.9566 - val_loss: 1.1258 - val_accuracy: 0.7180\n","Epoch 71/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2955 - accuracy: 0.9491 - val_loss: 1.0182 - val_accuracy: 0.7407\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2690 - accuracy: 0.9607 - val_loss: 1.3049 - val_accuracy: 0.6901\n","Epoch 73/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2946 - accuracy: 0.9512 - val_loss: 1.1529 - val_accuracy: 0.7200\n","Epoch 74/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2734 - accuracy: 0.9615 - val_loss: 1.0890 - val_accuracy: 0.7200\n","Epoch 75/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3014 - accuracy: 0.9452 - val_loss: 1.3715 - val_accuracy: 0.6808\n","Epoch 76/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3057 - accuracy: 0.9408 - val_loss: 1.0364 - val_accuracy: 0.7376\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3188 - accuracy: 0.9333 - val_loss: 1.0265 - val_accuracy: 0.7314\n","Epoch 78/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2584 - accuracy: 0.9680 - val_loss: 1.0148 - val_accuracy: 0.7386\n","Epoch 79/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2487 - accuracy: 0.9742 - val_loss: 1.0567 - val_accuracy: 0.7304\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2641 - accuracy: 0.9630 - val_loss: 1.0345 - val_accuracy: 0.7355\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2565 - accuracy: 0.9667 - val_loss: 1.0574 - val_accuracy: 0.7283\n","Epoch 82/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2697 - accuracy: 0.9625 - val_loss: 1.2789 - val_accuracy: 0.6973\n","Epoch 83/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2634 - accuracy: 0.9659 - val_loss: 1.0257 - val_accuracy: 0.7407\n","Epoch 84/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2514 - accuracy: 0.9716 - val_loss: 1.0416 - val_accuracy: 0.7376\n","Epoch 85/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2492 - accuracy: 0.9742 - val_loss: 1.1170 - val_accuracy: 0.7262\n","Epoch 86/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2502 - accuracy: 0.9680 - val_loss: 1.0588 - val_accuracy: 0.7314\n","Epoch 87/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2772 - accuracy: 0.9550 - val_loss: 1.1921 - val_accuracy: 0.7056\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2559 - accuracy: 0.9643 - val_loss: 1.0875 - val_accuracy: 0.7283\n","Epoch 89/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2526 - accuracy: 0.9690 - val_loss: 1.0828 - val_accuracy: 0.7314\n","Epoch 90/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2451 - accuracy: 0.9749 - val_loss: 1.1636 - val_accuracy: 0.7128\n","Epoch 91/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2492 - accuracy: 0.9685 - val_loss: 1.1135 - val_accuracy: 0.7397\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2572 - accuracy: 0.9649 - val_loss: 1.1465 - val_accuracy: 0.7221\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2447 - accuracy: 0.9708 - val_loss: 1.1511 - val_accuracy: 0.7293\n","Epoch 94/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2517 - accuracy: 0.9669 - val_loss: 1.2392 - val_accuracy: 0.7118\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2536 - accuracy: 0.9669 - val_loss: 1.4872 - val_accuracy: 0.6777\n","Epoch 96/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2896 - accuracy: 0.9501 - val_loss: 1.0877 - val_accuracy: 0.7283\n","Epoch 97/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2489 - accuracy: 0.9685 - val_loss: 1.2153 - val_accuracy: 0.7159\n","Epoch 98/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2733 - accuracy: 0.9556 - val_loss: 1.1023 - val_accuracy: 0.7221\n","Epoch 99/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2609 - accuracy: 0.9592 - val_loss: 1.0987 - val_accuracy: 0.7252\n","Epoch 100/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2443 - accuracy: 0.9700 - val_loss: 1.1255 - val_accuracy: 0.7283\n","{'loss': [0.5118550062179565, 0.3997661769390106, 0.37604230642318726, 0.37607741355895996, 0.372357040643692, 0.38131383061408997, 0.39185085892677307, 0.3747462034225464, 0.364562451839447, 0.38938623666763306, 0.3598639965057373, 0.3471275568008423, 0.36520200967788696, 0.34467613697052, 0.3720605671405792, 0.3564017415046692, 0.3463504910469055, 0.34531307220458984, 0.37280622124671936, 0.3465982675552368, 0.3596910834312439, 0.3305722773075104, 0.33021798729896545, 0.3313615322113037, 0.3426140248775482, 0.3808271288871765, 0.3299950361251831, 0.3286852240562439, 0.3273961544036865, 0.32689279317855835, 0.30954426527023315, 0.3197290897369385, 0.3212261199951172, 0.3035050928592682, 0.334970623254776, 0.32529959082603455, 0.3083045482635498, 0.3194761276245117, 0.3089248538017273, 0.3100827932357788, 0.30988073348999023, 0.3279331624507904, 0.2973480522632599, 0.29136282205581665, 0.28991758823394775, 0.29171401262283325, 0.2915033996105194, 0.3086785674095154, 0.29493448138237, 0.3284701108932495, 0.2804539203643799, 0.33189618587493896, 0.2828013598918915, 0.29460370540618896, 0.28415513038635254, 0.28651857376098633, 0.294781357049942, 0.28834301233291626, 0.2701939344406128, 0.2916750907897949, 0.2678564190864563, 0.27674126625061035, 0.27761363983154297, 0.2748665511608124, 0.2659970819950104, 0.2823396921157837, 0.26343223452568054, 0.2845350205898285, 0.33138254284858704, 0.2819134294986725, 0.29548731446266174, 0.26899388432502747, 0.2946241796016693, 0.2734386920928955, 0.30142343044281006, 0.30570513010025024, 0.3188071548938751, 0.25835853815078735, 0.24872995913028717, 0.26409104466438293, 0.25648507475852966, 0.2697405219078064, 0.2634350061416626, 0.251362681388855, 0.24917609989643097, 0.2501995265483856, 0.27720311284065247, 0.2559230923652649, 0.252603679895401, 0.24509234726428986, 0.24919329583644867, 0.25723353028297424, 0.24473875761032104, 0.25172868371009827, 0.25363487005233765, 0.2895796597003937, 0.24890883266925812, 0.2733342945575714, 0.2608931064605713, 0.24426603317260742], 'accuracy': [0.8633074760437012, 0.9095607399940491, 0.9193798303604126, 0.9224806427955627, 0.9180878400802612, 0.9093023538589478, 0.9064599275588989, 0.9219638109207153, 0.9191214442253113, 0.9105943441390991, 0.9268733859062195, 0.9354005455970764, 0.9224806427955627, 0.9281653761863708, 0.9193798303604126, 0.9299741387367249, 0.934108555316925, 0.9315245747566223, 0.9183462262153625, 0.9273901581764221, 0.9193798303604126, 0.9379844665527344, 0.9397932887077332, 0.9366925358772278, 0.9307493567466736, 0.9072351455688477, 0.9377260804176331, 0.9372093081474304, 0.9390180706977844, 0.9379844665527344, 0.94625324010849, 0.9400516748428345, 0.9431524276733398, 0.9527131915092468, 0.9366925358772278, 0.9374676942825317, 0.9488372206687927, 0.9431524276733398, 0.9483203887939453, 0.9436692595481873, 0.9498708248138428, 0.934108555316925, 0.9532299637794495, 0.9534883499145508, 0.9563307762145996, 0.9529715776443481, 0.9552971720695496, 0.9434108734130859, 0.9547803401947021, 0.9317829608917236, 0.9573643207550049, 0.9310077428817749, 0.9607235193252563, 0.9514212012290955, 0.9586563110351562, 0.9563307762145996, 0.9529715776443481, 0.9558139443397522, 0.9658914804458618, 0.9514212012290955, 0.962273895740509, 0.9596899151802063, 0.9591731429100037, 0.960465133190155, 0.9664082527160645, 0.9521963596343994, 0.9677002429962158, 0.9558139443397522, 0.9294573664665222, 0.9565891623497009, 0.949095606803894, 0.9607235193252563, 0.9511628150939941, 0.9614987373352051, 0.9452196359634399, 0.9408268928527832, 0.9333333373069763, 0.9679586291313171, 0.9741601943969727, 0.9630491137504578, 0.9666666388511658, 0.9625322818756104, 0.9658914804458618, 0.9715762138366699, 0.9741601943969727, 0.9679586291313171, 0.9550387859344482, 0.9643411040306091, 0.9689922332763672, 0.9749354124069214, 0.9684754610061646, 0.9648578763008118, 0.970801055431366, 0.9669250845909119, 0.9669250845909119, 0.9501292109489441, 0.9684754610061646, 0.9555555582046509, 0.9591731429100037, 0.9700258374214172], 'val_loss': [0.8838469982147217, 0.8844417333602905, 0.8858316540718079, 0.8865962624549866, 0.8903697729110718, 0.8877038955688477, 0.8857904076576233, 0.8882240056991577, 0.9043828248977661, 0.8818202614784241, 0.8721346259117126, 0.8688457012176514, 0.8628774881362915, 0.8465186357498169, 0.8624005317687988, 0.9203032851219177, 0.8694357872009277, 0.8978540897369385, 0.8491281270980835, 0.7538397908210754, 0.7928142547607422, 0.824496328830719, 0.8239914178848267, 0.8688613772392273, 1.1963789463043213, 0.8361541628837585, 0.9208807945251465, 0.8588255047798157, 0.9898784160614014, 0.9917125105857849, 0.9132350087165833, 0.8970034718513489, 0.9827055931091309, 0.9238004684448242, 1.2597146034240723, 0.9356915950775146, 0.9698519706726074, 0.9348422884941101, 0.978251039981842, 0.9536503553390503, 0.9622693657875061, 0.9966016411781311, 0.9861321449279785, 0.9802484512329102, 0.9649295806884766, 0.9630941152572632, 1.1650712490081787, 0.9759096503257751, 0.9848155975341797, 1.0504953861236572, 1.293622374534607, 0.9777839183807373, 0.9776017665863037, 0.9825639128684998, 1.0053684711456299, 1.0172193050384521, 0.9909521341323853, 1.0444704294204712, 0.9954481720924377, 1.0014305114746094, 1.1842595338821411, 1.078539252281189, 1.0252599716186523, 1.0386348962783813, 1.110128402709961, 1.0385208129882812, 1.0306897163391113, 1.3800455331802368, 1.0290613174438477, 1.1257550716400146, 1.018241286277771, 1.3048772811889648, 1.152907371520996, 1.0889617204666138, 1.3715053796768188, 1.0363777875900269, 1.0264694690704346, 1.014803409576416, 1.0567232370376587, 1.0345484018325806, 1.0574290752410889, 1.2789437770843506, 1.0256901979446411, 1.041553258895874, 1.1170176267623901, 1.0587815046310425, 1.1921296119689941, 1.0874649286270142, 1.0828489065170288, 1.1635972261428833, 1.1134631633758545, 1.146459698677063, 1.151115894317627, 1.2391881942749023, 1.4871814250946045, 1.0876624584197998, 1.2153066396713257, 1.1022990942001343, 1.0987000465393066, 1.1255050897598267], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.4876033067703247, 0.4876033067703247, 0.48657023906707764, 0.48657023906707764, 0.4876033067703247, 0.48966941237449646, 0.4886363744735718, 0.4927685856819153, 0.49380165338516235, 0.49896693229675293, 0.5113636255264282, 0.5289255976676941, 0.5320248007774353, 0.5237603187561035, 0.55888432264328, 0.5723140239715576, 0.6177685856819153, 0.7200413346290588, 0.7055785059928894, 0.7045454382896423, 0.7241735458374023, 0.7190082669258118, 0.6311983466148376, 0.75, 0.7283057570457458, 0.7530992031097412, 0.7128099203109741, 0.7159090638160706, 0.7458677887916565, 0.75, 0.7376033067703247, 0.75, 0.6787189841270447, 0.7417355179786682, 0.7345041036605835, 0.7489669322967529, 0.7324380278587341, 0.7427685856819153, 0.7427685856819153, 0.7365702390670776, 0.7345041036605835, 0.7365702390670776, 0.7386363744735718, 0.7396694421768188, 0.6983470916748047, 0.7386363744735718, 0.7417355179786682, 0.7241735458374023, 0.6807851195335388, 0.7427685856819153, 0.7469007968902588, 0.75, 0.7334710955619812, 0.7355371713638306, 0.7376033067703247, 0.7293388247489929, 0.7438016533851624, 0.7396694421768188, 0.7148760557174683, 0.7241735458374023, 0.7396694421768188, 0.7345041036605835, 0.7179751992225647, 0.7365702390670776, 0.7407024502754211, 0.6756198406219482, 0.7376033067703247, 0.7179751992225647, 0.7407024502754211, 0.6900826692581177, 0.7200413346290588, 0.7200413346290588, 0.6807851195335388, 0.7376033067703247, 0.7314049601554871, 0.7386363744735718, 0.73037189245224, 0.7355371713638306, 0.7283057570457458, 0.6973140239715576, 0.7407024502754211, 0.7376033067703247, 0.7262396812438965, 0.7314049601554871, 0.7055785059928894, 0.7283057570457458, 0.7314049601554871, 0.7128099203109741, 0.7396694421768188, 0.7221074104309082, 0.7293388247489929, 0.711776852607727, 0.6776859760284424, 0.7283057570457458, 0.7159090638160706, 0.7221074104309082, 0.7252066135406494, 0.7283057570457458]}\n","32/32 [==============================] - 1s 4ms/step\n"]}]},{"cell_type":"code","source":["\n","metrics_df.round(3)"],"metadata":{"id":"Ik5JoVP2NPvY","colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"status":"ok","timestamp":1716899934015,"user_tz":-360,"elapsed":6,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}},"outputId":"e7aaaa96-076e-451f-8d20-0f68446b25ae"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.532      0.544   0.390  0.455        0.390        0.673   \n","1        1     0.537      0.546   0.442  0.489        0.442        0.633   \n","2        2     0.561      0.555   0.616  0.584        0.616        0.506   \n","3        0     0.580      0.585   0.556  0.570        0.556        0.605   \n","4        1     0.602      0.601   0.610  0.605        0.610        0.595   \n","5        2     0.624      0.618   0.651  0.634        0.651        0.598   \n","6        0     0.642      0.641   0.645  0.643        0.645        0.638   \n","7        1     0.665      0.645   0.732  0.686        0.732        0.597   \n","8        2     0.688      0.680   0.709  0.694        0.709        0.667   \n","9        0     0.708      0.718   0.683  0.700        0.683        0.732   \n","10       1     0.720      0.687   0.809  0.743        0.809        0.631   \n","11       2     0.738      0.749   0.715  0.732        0.715        0.761   \n","12       0     0.755      0.744   0.776  0.760        0.776        0.734   \n","13       1     0.761      0.762   0.760  0.761        0.760        0.763   \n","14       2     0.786      0.783   0.791  0.787        0.791        0.781   \n","\n","    Kappa  \n","0   0.064  \n","1   0.075  \n","2   0.122  \n","3   0.161  \n","4   0.205  \n","5   0.249  \n","6   0.283  \n","7   0.329  \n","8   0.376  \n","9   0.415  \n","10  0.441  \n","11  0.476  \n","12  0.509  \n","13  0.523  \n","14  0.572  "],"text/html":["\n","  <div id=\"df-31fbea9f-17e2-4b4d-8924-684921ebac7a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.532</td>\n","      <td>0.544</td>\n","      <td>0.390</td>\n","      <td>0.455</td>\n","      <td>0.390</td>\n","      <td>0.673</td>\n","      <td>0.064</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.537</td>\n","      <td>0.546</td>\n","      <td>0.442</td>\n","      <td>0.489</td>\n","      <td>0.442</td>\n","      <td>0.633</td>\n","      <td>0.075</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.561</td>\n","      <td>0.555</td>\n","      <td>0.616</td>\n","      <td>0.584</td>\n","      <td>0.616</td>\n","      <td>0.506</td>\n","      <td>0.122</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.580</td>\n","      <td>0.585</td>\n","      <td>0.556</td>\n","      <td>0.570</td>\n","      <td>0.556</td>\n","      <td>0.605</td>\n","      <td>0.161</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.602</td>\n","      <td>0.601</td>\n","      <td>0.610</td>\n","      <td>0.605</td>\n","      <td>0.610</td>\n","      <td>0.595</td>\n","      <td>0.205</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.624</td>\n","      <td>0.618</td>\n","      <td>0.651</td>\n","      <td>0.634</td>\n","      <td>0.651</td>\n","      <td>0.598</td>\n","      <td>0.249</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.642</td>\n","      <td>0.641</td>\n","      <td>0.645</td>\n","      <td>0.643</td>\n","      <td>0.645</td>\n","      <td>0.638</td>\n","      <td>0.283</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.665</td>\n","      <td>0.645</td>\n","      <td>0.732</td>\n","      <td>0.686</td>\n","      <td>0.732</td>\n","      <td>0.597</td>\n","      <td>0.329</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.688</td>\n","      <td>0.680</td>\n","      <td>0.709</td>\n","      <td>0.694</td>\n","      <td>0.709</td>\n","      <td>0.667</td>\n","      <td>0.376</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.708</td>\n","      <td>0.718</td>\n","      <td>0.683</td>\n","      <td>0.700</td>\n","      <td>0.683</td>\n","      <td>0.732</td>\n","      <td>0.415</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.720</td>\n","      <td>0.687</td>\n","      <td>0.809</td>\n","      <td>0.743</td>\n","      <td>0.809</td>\n","      <td>0.631</td>\n","      <td>0.441</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.738</td>\n","      <td>0.749</td>\n","      <td>0.715</td>\n","      <td>0.732</td>\n","      <td>0.715</td>\n","      <td>0.761</td>\n","      <td>0.476</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.755</td>\n","      <td>0.744</td>\n","      <td>0.776</td>\n","      <td>0.760</td>\n","      <td>0.776</td>\n","      <td>0.734</td>\n","      <td>0.509</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.761</td>\n","      <td>0.762</td>\n","      <td>0.760</td>\n","      <td>0.761</td>\n","      <td>0.760</td>\n","      <td>0.763</td>\n","      <td>0.523</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.786</td>\n","      <td>0.783</td>\n","      <td>0.791</td>\n","      <td>0.787</td>\n","      <td>0.791</td>\n","      <td>0.781</td>\n","      <td>0.572</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31fbea9f-17e2-4b4d-8924-684921ebac7a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-31fbea9f-17e2-4b4d-8924-684921ebac7a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-31fbea9f-17e2-4b4d-8924-684921ebac7a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-7d25e094-8f94-4dc2-94fa-566ac1eded1d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d25e094-8f94-4dc2-94fa-566ac1eded1d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-7d25e094-8f94-4dc2-94fa-566ac1eded1d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08476730052381777,\n        \"min\": 0.532,\n        \"max\": 0.786,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.708,\n          0.738,\n          0.532\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08186155560282424,\n        \"min\": 0.544,\n        \"max\": 0.783,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.718,\n          0.749,\n          0.544\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12245232308360438,\n        \"min\": 0.39,\n        \"max\": 0.809,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.683,\n          0.715,\n          0.39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10026764183922947,\n        \"min\": 0.455,\n        \"max\": 0.787,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7,\n          0.732,\n          0.455\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12245232308360438,\n        \"min\": 0.39,\n        \"max\": 0.809,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.683,\n          0.715,\n          0.39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07889818635129588,\n        \"min\": 0.506,\n        \"max\": 0.781,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.732,\n          0.761,\n          0.673\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1693124752808082,\n        \"min\": 0.064,\n        \"max\": 0.572,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.415,\n          0.476,\n          0.064\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["metrics_df.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/TF Domain/Alpha_CNN_LSTM.csv', index = False)"],"metadata":{"id":"Ncf_cMAQF6g4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CNN"],"metadata":{"id":"QUuWzfMHSNmi"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    # model.add(Dropout(0.5))\n","    # model.add(LSTM(256, return_sequences=True))\n","    # model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time+Frequency/Alpha/CNN/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time+Frequency/Alpha/CNN/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"8xrx_fxBSWGd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717502740196,"user_tz":-360,"elapsed":8,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}},"outputId":"4a3f1fe5-a860-472c-aa82-e0db245290a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["global_model_CNN, metrics_df_CNN = federated_learning(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1TaNdIbSfkq","outputId":"8493bf99-4e2d-4ddd-aa13-be597b4e80a5","executionInfo":{"status":"ok","timestamp":1717503869743,"user_tz":-360,"elapsed":1126947,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 37, 29), Test shape: (1194, 37, 29)\n","Train shape: (4418, 37, 29), Test shape: (1416, 37, 29)\n","Train shape: (4838, 37, 29), Test shape: (996, 37, 29)\n","Train shape: (4640, 37, 29), Test shape: (1194, 37, 29)\n","Train shape: (4418, 37, 29), Test shape: (1416, 37, 29)\n","Train shape: (4838, 37, 29), Test shape: (996, 37, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 10s 59ms/step - loss: 1.9640 - accuracy: 0.5035 - val_loss: 1.9548 - val_accuracy: 0.5216\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 12ms/step - loss: 1.9464 - accuracy: 0.5210 - val_loss: 1.9383 - val_accuracy: 0.5108\n","Epoch 3/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.9291 - accuracy: 0.5207 - val_loss: 1.9221 - val_accuracy: 0.5539\n","Epoch 4/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.9124 - accuracy: 0.5415 - val_loss: 1.9063 - val_accuracy: 0.4838\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.8957 - accuracy: 0.5471 - val_loss: 1.8905 - val_accuracy: 0.5377\n","Epoch 6/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.8801 - accuracy: 0.5361 - val_loss: 1.8751 - val_accuracy: 0.5259\n","Epoch 7/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.8635 - accuracy: 0.5577 - val_loss: 1.8600 - val_accuracy: 0.5496\n","Epoch 8/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.8478 - accuracy: 0.5625 - val_loss: 1.8453 - val_accuracy: 0.4946\n","Epoch 9/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.8321 - accuracy: 0.5665 - val_loss: 1.8304 - val_accuracy: 0.5593\n","Epoch 10/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.8167 - accuracy: 0.5727 - val_loss: 1.8160 - val_accuracy: 0.5453\n","Epoch 11/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.8023 - accuracy: 0.5797 - val_loss: 1.8019 - val_accuracy: 0.5431\n","Epoch 12/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.7868 - accuracy: 0.5808 - val_loss: 1.7879 - val_accuracy: 0.5409\n","Epoch 13/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.7722 - accuracy: 0.5870 - val_loss: 1.7739 - val_accuracy: 0.5571\n","Epoch 14/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.7577 - accuracy: 0.5878 - val_loss: 1.7608 - val_accuracy: 0.5366\n","Epoch 15/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.7437 - accuracy: 0.5835 - val_loss: 1.7472 - val_accuracy: 0.5442\n","Epoch 16/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.7294 - accuracy: 0.5816 - val_loss: 1.7340 - val_accuracy: 0.5388\n","Epoch 17/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.7154 - accuracy: 0.5983 - val_loss: 1.7208 - val_accuracy: 0.5474\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.7021 - accuracy: 0.5854 - val_loss: 1.7078 - val_accuracy: 0.5711\n","Epoch 19/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.6880 - accuracy: 0.5959 - val_loss: 1.6950 - val_accuracy: 0.5593\n","Epoch 20/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.6759 - accuracy: 0.5870 - val_loss: 1.6826 - val_accuracy: 0.5603\n","Epoch 21/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.6622 - accuracy: 0.5894 - val_loss: 1.6709 - val_accuracy: 0.5474\n","Epoch 22/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.6500 - accuracy: 0.5884 - val_loss: 1.6597 - val_accuracy: 0.5517\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.6355 - accuracy: 0.6156 - val_loss: 1.6482 - val_accuracy: 0.5539\n","Epoch 24/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.6250 - accuracy: 0.5857 - val_loss: 1.6351 - val_accuracy: 0.5647\n","Epoch 25/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.6103 - accuracy: 0.6134 - val_loss: 1.6237 - val_accuracy: 0.5593\n","Epoch 26/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.5988 - accuracy: 0.6140 - val_loss: 1.6166 - val_accuracy: 0.5377\n","Epoch 27/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.5852 - accuracy: 0.6226 - val_loss: 1.6011 - val_accuracy: 0.5657\n","Epoch 28/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.5732 - accuracy: 0.6234 - val_loss: 1.5921 - val_accuracy: 0.5603\n","Epoch 29/100\n","29/29 [==============================] - 1s 32ms/step - loss: 1.5602 - accuracy: 0.6277 - val_loss: 1.5802 - val_accuracy: 0.5593\n","Epoch 30/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.5478 - accuracy: 0.6277 - val_loss: 1.5776 - val_accuracy: 0.5388\n","Epoch 31/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.5370 - accuracy: 0.6304 - val_loss: 1.5591 - val_accuracy: 0.5647\n","Epoch 32/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.5222 - accuracy: 0.6339 - val_loss: 1.5500 - val_accuracy: 0.5603\n","Epoch 33/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.5130 - accuracy: 0.6317 - val_loss: 1.5406 - val_accuracy: 0.5700\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.5003 - accuracy: 0.6377 - val_loss: 1.5316 - val_accuracy: 0.5625\n","Epoch 35/100\n","29/29 [==============================] - 2s 62ms/step - loss: 1.4916 - accuracy: 0.6199 - val_loss: 1.5224 - val_accuracy: 0.5819\n","Epoch 36/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.4785 - accuracy: 0.6420 - val_loss: 1.5133 - val_accuracy: 0.5776\n","Epoch 37/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.4680 - accuracy: 0.6312 - val_loss: 1.5100 - val_accuracy: 0.5711\n","Epoch 38/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.4531 - accuracy: 0.6557 - val_loss: 1.4939 - val_accuracy: 0.5700\n","Epoch 39/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.4423 - accuracy: 0.6581 - val_loss: 1.4863 - val_accuracy: 0.5797\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4324 - accuracy: 0.6525 - val_loss: 1.4776 - val_accuracy: 0.5797\n","Epoch 41/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.4208 - accuracy: 0.6541 - val_loss: 1.4716 - val_accuracy: 0.5862\n","Epoch 42/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.4076 - accuracy: 0.6689 - val_loss: 1.4676 - val_accuracy: 0.5765\n","Epoch 43/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4020 - accuracy: 0.6538 - val_loss: 1.4532 - val_accuracy: 0.5765\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3905 - accuracy: 0.6579 - val_loss: 1.4473 - val_accuracy: 0.5765\n","Epoch 45/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3755 - accuracy: 0.6797 - val_loss: 1.4424 - val_accuracy: 0.5862\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3661 - accuracy: 0.6743 - val_loss: 1.4329 - val_accuracy: 0.5830\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3548 - accuracy: 0.6746 - val_loss: 1.4464 - val_accuracy: 0.5463\n","Epoch 48/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3501 - accuracy: 0.6616 - val_loss: 1.4335 - val_accuracy: 0.5733\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3415 - accuracy: 0.6700 - val_loss: 1.4300 - val_accuracy: 0.5571\n","Epoch 50/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.3245 - accuracy: 0.6845 - val_loss: 1.4067 - val_accuracy: 0.5884\n","Epoch 51/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.3132 - accuracy: 0.6899 - val_loss: 1.3987 - val_accuracy: 0.5873\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3041 - accuracy: 0.6891 - val_loss: 1.3980 - val_accuracy: 0.5830\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3034 - accuracy: 0.6805 - val_loss: 1.4125 - val_accuracy: 0.5571\n","Epoch 54/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.2862 - accuracy: 0.7018 - val_loss: 1.3826 - val_accuracy: 0.5894\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2780 - accuracy: 0.6915 - val_loss: 1.3758 - val_accuracy: 0.5873\n","Epoch 56/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.2715 - accuracy: 0.6932 - val_loss: 1.3702 - val_accuracy: 0.5948\n","Epoch 57/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2590 - accuracy: 0.6988 - val_loss: 1.3645 - val_accuracy: 0.5970\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2465 - accuracy: 0.7069 - val_loss: 1.3618 - val_accuracy: 0.5916\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2348 - accuracy: 0.7247 - val_loss: 1.3569 - val_accuracy: 0.5851\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2252 - accuracy: 0.7166 - val_loss: 1.3577 - val_accuracy: 0.5851\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2219 - accuracy: 0.7107 - val_loss: 1.3459 - val_accuracy: 0.5927\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2094 - accuracy: 0.7233 - val_loss: 1.3426 - val_accuracy: 0.5884\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2012 - accuracy: 0.7196 - val_loss: 1.3378 - val_accuracy: 0.5830\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1880 - accuracy: 0.7284 - val_loss: 1.3330 - val_accuracy: 0.5959\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1810 - accuracy: 0.7303 - val_loss: 1.3305 - val_accuracy: 0.5905\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1777 - accuracy: 0.7271 - val_loss: 1.3249 - val_accuracy: 0.5948\n","Epoch 67/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1620 - accuracy: 0.7449 - val_loss: 1.3270 - val_accuracy: 0.5819\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1565 - accuracy: 0.7373 - val_loss: 1.3552 - val_accuracy: 0.5603\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1490 - accuracy: 0.7387 - val_loss: 1.3145 - val_accuracy: 0.5970\n","Epoch 70/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.1500 - accuracy: 0.7274 - val_loss: 1.3105 - val_accuracy: 0.5991\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1284 - accuracy: 0.7570 - val_loss: 1.3076 - val_accuracy: 0.5981\n","Epoch 72/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.1214 - accuracy: 0.7497 - val_loss: 1.3258 - val_accuracy: 0.5700\n","Epoch 73/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1147 - accuracy: 0.7592 - val_loss: 1.3071 - val_accuracy: 0.5981\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1048 - accuracy: 0.7530 - val_loss: 1.3107 - val_accuracy: 0.5754\n","Epoch 75/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0960 - accuracy: 0.7648 - val_loss: 1.3108 - val_accuracy: 0.5819\n","Epoch 76/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0861 - accuracy: 0.7672 - val_loss: 1.2950 - val_accuracy: 0.5970\n","Epoch 77/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.0758 - accuracy: 0.7729 - val_loss: 1.2931 - val_accuracy: 0.5959\n","Epoch 78/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0688 - accuracy: 0.7775 - val_loss: 1.2903 - val_accuracy: 0.5948\n","Epoch 79/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0619 - accuracy: 0.7772 - val_loss: 1.3055 - val_accuracy: 0.5841\n","Epoch 80/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.0527 - accuracy: 0.7775 - val_loss: 1.3174 - val_accuracy: 0.5787\n","Epoch 81/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.0471 - accuracy: 0.7753 - val_loss: 1.2873 - val_accuracy: 0.5851\n","Epoch 82/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.0373 - accuracy: 0.7861 - val_loss: 1.2884 - val_accuracy: 0.5873\n","Epoch 83/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0276 - accuracy: 0.7891 - val_loss: 1.2852 - val_accuracy: 0.5787\n","Epoch 84/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.0237 - accuracy: 0.7834 - val_loss: 1.2916 - val_accuracy: 0.5797\n","Epoch 85/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.0149 - accuracy: 0.7923 - val_loss: 1.2834 - val_accuracy: 0.5905\n","Epoch 86/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.0071 - accuracy: 0.7912 - val_loss: 1.2796 - val_accuracy: 0.5948\n","Epoch 87/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9994 - accuracy: 0.7945 - val_loss: 1.2892 - val_accuracy: 0.5841\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0069 - accuracy: 0.7775 - val_loss: 1.3057 - val_accuracy: 0.5776\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9853 - accuracy: 0.7961 - val_loss: 1.2795 - val_accuracy: 0.5916\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9833 - accuracy: 0.7950 - val_loss: 1.2868 - val_accuracy: 0.5830\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9742 - accuracy: 0.8055 - val_loss: 1.2833 - val_accuracy: 0.5787\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9641 - accuracy: 0.8085 - val_loss: 1.2750 - val_accuracy: 0.5938\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9534 - accuracy: 0.8114 - val_loss: 1.2764 - val_accuracy: 0.5905\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9504 - accuracy: 0.8093 - val_loss: 1.3091 - val_accuracy: 0.5797\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9422 - accuracy: 0.8149 - val_loss: 1.2817 - val_accuracy: 0.5819\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9305 - accuracy: 0.8211 - val_loss: 1.2867 - val_accuracy: 0.5873\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9354 - accuracy: 0.7982 - val_loss: 1.2761 - val_accuracy: 0.5927\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9163 - accuracy: 0.8265 - val_loss: 1.2793 - val_accuracy: 0.5938\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9166 - accuracy: 0.8203 - val_loss: 1.2783 - val_accuracy: 0.5991\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9164 - accuracy: 0.8187 - val_loss: 1.3317 - val_accuracy: 0.5765\n","{'loss': [1.9640239477157593, 1.946412444114685, 1.9291107654571533, 1.9123847484588623, 1.8956663608551025, 1.8801028728485107, 1.8635369539260864, 1.8478443622589111, 1.8320971727371216, 1.816729187965393, 1.8023208379745483, 1.786755084991455, 1.772242546081543, 1.7577004432678223, 1.743688702583313, 1.7294179201126099, 1.7153651714324951, 1.7020928859710693, 1.688012957572937, 1.6759421825408936, 1.6622226238250732, 1.6499662399291992, 1.6355140209197998, 1.6250317096710205, 1.6103169918060303, 1.5988250970840454, 1.5851644277572632, 1.573211908340454, 1.5602302551269531, 1.5477811098098755, 1.5370194911956787, 1.5221779346466064, 1.5129547119140625, 1.5003396272659302, 1.4915540218353271, 1.4785301685333252, 1.4679672718048096, 1.4531173706054688, 1.4423013925552368, 1.4324071407318115, 1.4207779169082642, 1.4075690507888794, 1.4020143747329712, 1.3904962539672852, 1.3755282163619995, 1.3661086559295654, 1.3547736406326294, 1.3501410484313965, 1.3414642810821533, 1.3244658708572388, 1.3131908178329468, 1.3040581941604614, 1.3033522367477417, 1.2861777544021606, 1.2780396938323975, 1.271454095840454, 1.2590322494506836, 1.2465440034866333, 1.234787940979004, 1.2251535654067993, 1.2218822240829468, 1.2094107866287231, 1.2011603116989136, 1.1879898309707642, 1.1809645891189575, 1.177661418914795, 1.161974549293518, 1.156538963317871, 1.1489704847335815, 1.149983525276184, 1.1284244060516357, 1.1214393377304077, 1.1147364377975464, 1.1048474311828613, 1.0959645509719849, 1.086106300354004, 1.0757824182510376, 1.068803071975708, 1.0619417428970337, 1.0526779890060425, 1.047127604484558, 1.0372533798217773, 1.0276308059692383, 1.0236761569976807, 1.0149322748184204, 1.0071425437927246, 0.9994481801986694, 1.0068589448928833, 0.9852554202079773, 0.9833272695541382, 0.974248468875885, 0.9640926122665405, 0.9534157514572144, 0.9503680467605591, 0.9422429203987122, 0.9305151104927063, 0.9354144930839539, 0.9162533283233643, 0.9166499376296997, 0.9163506627082825], 'accuracy': [0.5035021305084229, 0.5210129022598267, 0.5207435488700867, 0.5414870977401733, 0.5471444129943848, 0.5360991358757019, 0.5576508641242981, 0.5625, 0.5665409564971924, 0.5727370977401733, 0.579741358757019, 0.5808189511299133, 0.5870150923728943, 0.5878232717514038, 0.5835129022598267, 0.5816271305084229, 0.5983297228813171, 0.5853987336158752, 0.5959051847457886, 0.5870150923728943, 0.5894396305084229, 0.5883620977401733, 0.615571141242981, 0.5856680870056152, 0.6134159564971924, 0.6139547228813171, 0.6225754022598267, 0.623383641242981, 0.6276939511299133, 0.6276939511299133, 0.6303879022598267, 0.6338900923728943, 0.6317349076271057, 0.6376616358757019, 0.6198814511299133, 0.641972005367279, 0.631196141242981, 0.6557112336158752, 0.6581357717514038, 0.6524784564971924, 0.6540948152542114, 0.6689116358757019, 0.6538254022598267, 0.657866358757019, 0.6796875, 0.6742995977401733, 0.6745689511299133, 0.6616379022598267, 0.6699892282485962, 0.6845366358757019, 0.6899245977401733, 0.689116358757019, 0.6804956793785095, 0.701777994632721, 0.6915409564971924, 0.6931573152542114, 0.6988146305084229, 0.7068965435028076, 0.7246767282485962, 0.7165948152542114, 0.7106680870056152, 0.7233297228813171, 0.7195581793785095, 0.7284482717514038, 0.7303340435028076, 0.7271012663841248, 0.7448814511299133, 0.7373383641242981, 0.7386853694915771, 0.7273706793785095, 0.7570043206214905, 0.7497305870056152, 0.759159505367279, 0.7529633641242981, 0.7648168206214905, 0.767241358757019, 0.7728987336158752, 0.7774784564971924, 0.7772090435028076, 0.7774784564971924, 0.7753232717514038, 0.7860991358757019, 0.7890625, 0.7834051847457886, 0.7922952771186829, 0.7912176847457886, 0.7944504022598267, 0.7774784564971924, 0.7960668206214905, 0.7949892282485962, 0.8054956793785095, 0.8084590435028076, 0.8114224076271057, 0.8092672228813171, 0.8149245977401733, 0.8211206793785095, 0.798222005367279, 0.826508641242981, 0.8203125, 0.818696141242981], 'val_loss': [1.95481538772583, 1.9383481740951538, 1.9221097230911255, 1.9062588214874268, 1.890486717224121, 1.8750638961791992, 1.8600249290466309, 1.8452941179275513, 1.8303920030593872, 1.815972089767456, 1.8018511533737183, 1.7878735065460205, 1.7739259004592896, 1.7608169317245483, 1.7472152709960938, 1.7339930534362793, 1.7207611799240112, 1.7078365087509155, 1.694995403289795, 1.682632565498352, 1.6709078550338745, 1.6596653461456299, 1.6481739282608032, 1.6350576877593994, 1.6237002611160278, 1.616601586341858, 1.6010998487472534, 1.5921056270599365, 1.5802226066589355, 1.5776187181472778, 1.5590555667877197, 1.5500342845916748, 1.5406031608581543, 1.5315951108932495, 1.5224201679229736, 1.5133417844772339, 1.5099693536758423, 1.4938966035842896, 1.4863017797470093, 1.4776396751403809, 1.4715713262557983, 1.4675500392913818, 1.4532148838043213, 1.4473365545272827, 1.442387342453003, 1.4328557252883911, 1.4463555812835693, 1.4334620237350464, 1.4300100803375244, 1.4067200422286987, 1.3987003564834595, 1.3980484008789062, 1.4124997854232788, 1.3825591802597046, 1.3758224248886108, 1.3701823949813843, 1.364506721496582, 1.361810326576233, 1.3569118976593018, 1.357722520828247, 1.3458746671676636, 1.3425713777542114, 1.3377690315246582, 1.3329720497131348, 1.3304524421691895, 1.3248796463012695, 1.3270418643951416, 1.3551620244979858, 1.3145287036895752, 1.3105387687683105, 1.307550311088562, 1.32577383518219, 1.307105541229248, 1.3107082843780518, 1.3108117580413818, 1.2950234413146973, 1.2930513620376587, 1.290326476097107, 1.3055479526519775, 1.3173712491989136, 1.2873315811157227, 1.2883644104003906, 1.2851804494857788, 1.2915871143341064, 1.2834495306015015, 1.279578447341919, 1.2891662120819092, 1.3056848049163818, 1.2794852256774902, 1.286841869354248, 1.2833266258239746, 1.2750033140182495, 1.27643883228302, 1.309091329574585, 1.2816517353057861, 1.2866804599761963, 1.2761030197143555, 1.279345989227295, 1.2783334255218506, 1.3317315578460693], 'val_accuracy': [0.5215517282485962, 0.5107758641242981, 0.5538793206214905, 0.48383620381355286, 0.537715494632721, 0.5258620977401733, 0.5495689511299133, 0.49461206793785095, 0.5592672228813171, 0.545258641242981, 0.5431034564971924, 0.5409482717514038, 0.5571120977401733, 0.5366379022598267, 0.5441810488700867, 0.5387930870056152, 0.5474137663841248, 0.5711206793785095, 0.5592672228813171, 0.5603448152542114, 0.5474137663841248, 0.5517241358757019, 0.5538793206214905, 0.5646551847457886, 0.5592672228813171, 0.537715494632721, 0.5657327771186829, 0.5603448152542114, 0.5592672228813171, 0.5387930870056152, 0.5646551847457886, 0.5603448152542114, 0.5700430870056152, 0.5625, 0.5818965435028076, 0.5775862336158752, 0.5711206793785095, 0.5700430870056152, 0.579741358757019, 0.579741358757019, 0.5862069129943848, 0.576508641242981, 0.576508641242981, 0.576508641242981, 0.5862069129943848, 0.5829741358757019, 0.5463362336158752, 0.5732758641242981, 0.5571120977401733, 0.5883620977401733, 0.587284505367279, 0.5829741358757019, 0.5571120977401733, 0.5894396305084229, 0.587284505367279, 0.5948275923728943, 0.5969827771186829, 0.5915948152542114, 0.5851293206214905, 0.5851293206214905, 0.5926724076271057, 0.5883620977401733, 0.5829741358757019, 0.5959051847457886, 0.5905172228813171, 0.5948275923728943, 0.5818965435028076, 0.5603448152542114, 0.5969827771186829, 0.5991379022598267, 0.5980603694915771, 0.5700430870056152, 0.5980603694915771, 0.5754310488700867, 0.5818965435028076, 0.5969827771186829, 0.5959051847457886, 0.5948275923728943, 0.5840517282485962, 0.5786637663841248, 0.5851293206214905, 0.587284505367279, 0.5786637663841248, 0.579741358757019, 0.5905172228813171, 0.5948275923728943, 0.5840517282485962, 0.5775862336158752, 0.5915948152542114, 0.5829741358757019, 0.5786637663841248, 0.59375, 0.5905172228813171, 0.579741358757019, 0.5818965435028076, 0.587284505367279, 0.5926724076271057, 0.59375, 0.5991379022598267, 0.576508641242981]}\n","38/38 [==============================] - 1s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 5s 60ms/step - loss: 1.9642 - accuracy: 0.5048 - val_loss: 1.9551 - val_accuracy: 0.5136\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 1.9556 - accuracy: 0.4922"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 1s 23ms/step - loss: 1.9467 - accuracy: 0.5294 - val_loss: 1.9387 - val_accuracy: 0.5385\n","Epoch 3/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.9297 - accuracy: 0.5461 - val_loss: 1.9226 - val_accuracy: 0.5124\n","Epoch 4/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.9141 - accuracy: 0.5068 - val_loss: 1.9067 - val_accuracy: 0.5136\n","Epoch 5/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.8969 - accuracy: 0.5501 - val_loss: 1.8912 - val_accuracy: 0.5226\n","Epoch 6/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.8806 - accuracy: 0.5656 - val_loss: 1.8759 - val_accuracy: 0.5362\n","Epoch 7/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.8649 - accuracy: 0.5617 - val_loss: 1.8609 - val_accuracy: 0.5113\n","Epoch 8/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.8494 - accuracy: 0.5600 - val_loss: 1.8461 - val_accuracy: 0.5441\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.8341 - accuracy: 0.5532 - val_loss: 1.8315 - val_accuracy: 0.5260\n","Epoch 10/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.8196 - accuracy: 0.5606 - val_loss: 1.8173 - val_accuracy: 0.5351\n","Epoch 11/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.8040 - accuracy: 0.5696 - val_loss: 1.8033 - val_accuracy: 0.5532\n","Epoch 12/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.7893 - accuracy: 0.5815 - val_loss: 1.7894 - val_accuracy: 0.5249\n","Epoch 13/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.7750 - accuracy: 0.5829 - val_loss: 1.7758 - val_accuracy: 0.5249\n","Epoch 14/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.7605 - accuracy: 0.5792 - val_loss: 1.7625 - val_accuracy: 0.5339\n","Epoch 15/100\n","28/28 [==============================] - 1s 32ms/step - loss: 1.7471 - accuracy: 0.5750 - val_loss: 1.7493 - val_accuracy: 0.5260\n","Epoch 16/100\n","28/28 [==============================] - 1s 30ms/step - loss: 1.7328 - accuracy: 0.5835 - val_loss: 1.7362 - val_accuracy: 0.5441\n","Epoch 17/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.7191 - accuracy: 0.5911 - val_loss: 1.7233 - val_accuracy: 0.5317\n","Epoch 18/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.7057 - accuracy: 0.5897 - val_loss: 1.7106 - val_accuracy: 0.5351\n","Epoch 19/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.6919 - accuracy: 0.5962 - val_loss: 1.6980 - val_accuracy: 0.5317\n","Epoch 20/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.6792 - accuracy: 0.5920 - val_loss: 1.6857 - val_accuracy: 0.5294\n","Epoch 21/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.6658 - accuracy: 0.5993 - val_loss: 1.6738 - val_accuracy: 0.5238\n","Epoch 22/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.6534 - accuracy: 0.5829 - val_loss: 1.6611 - val_accuracy: 0.5419\n","Epoch 23/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.6393 - accuracy: 0.6005 - val_loss: 1.6493 - val_accuracy: 0.5385\n","Epoch 24/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.6265 - accuracy: 0.5990 - val_loss: 1.6376 - val_accuracy: 0.5430\n","Epoch 25/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.6134 - accuracy: 0.6053 - val_loss: 1.6263 - val_accuracy: 0.5520\n","Epoch 26/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.6001 - accuracy: 0.6064 - val_loss: 1.6157 - val_accuracy: 0.5486\n","Epoch 27/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.5890 - accuracy: 0.6132 - val_loss: 1.6049 - val_accuracy: 0.5452\n","Epoch 28/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.5751 - accuracy: 0.6138 - val_loss: 1.5934 - val_accuracy: 0.5351\n","Epoch 29/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.5631 - accuracy: 0.6251 - val_loss: 1.5840 - val_accuracy: 0.5486\n","Epoch 30/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.5522 - accuracy: 0.6154 - val_loss: 1.5755 - val_accuracy: 0.5430\n","Epoch 31/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5392 - accuracy: 0.6228 - val_loss: 1.5633 - val_accuracy: 0.5441\n","Epoch 32/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.5275 - accuracy: 0.6350 - val_loss: 1.5532 - val_accuracy: 0.5430\n","Epoch 33/100\n","28/28 [==============================] - 2s 55ms/step - loss: 1.5160 - accuracy: 0.6327 - val_loss: 1.5482 - val_accuracy: 0.5543\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.5056 - accuracy: 0.6251 - val_loss: 1.5345 - val_accuracy: 0.5475\n","Epoch 35/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.4937 - accuracy: 0.6327 - val_loss: 1.5257 - val_accuracy: 0.5622\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.4835 - accuracy: 0.6370 - val_loss: 1.5191 - val_accuracy: 0.5532\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.4710 - accuracy: 0.6378 - val_loss: 1.5116 - val_accuracy: 0.5600\n","Epoch 38/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4606 - accuracy: 0.6497 - val_loss: 1.5003 - val_accuracy: 0.5679\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.4490 - accuracy: 0.6469 - val_loss: 1.4930 - val_accuracy: 0.5475\n","Epoch 40/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.4393 - accuracy: 0.6443 - val_loss: 1.4843 - val_accuracy: 0.5475\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4296 - accuracy: 0.6443 - val_loss: 1.4752 - val_accuracy: 0.5645\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4185 - accuracy: 0.6553 - val_loss: 1.4676 - val_accuracy: 0.5566\n","Epoch 43/100\n","28/28 [==============================] - 1s 36ms/step - loss: 1.4108 - accuracy: 0.6452 - val_loss: 1.4622 - val_accuracy: 0.5701\n","Epoch 44/100\n","28/28 [==============================] - 1s 17ms/step - loss: 1.4012 - accuracy: 0.6539 - val_loss: 1.4591 - val_accuracy: 0.5633\n","Epoch 45/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.3877 - accuracy: 0.6630 - val_loss: 1.4445 - val_accuracy: 0.5814\n","Epoch 46/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3802 - accuracy: 0.6610 - val_loss: 1.4449 - val_accuracy: 0.5679\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3673 - accuracy: 0.6692 - val_loss: 1.4345 - val_accuracy: 0.5656\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3571 - accuracy: 0.6749 - val_loss: 1.4260 - val_accuracy: 0.5633\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3470 - accuracy: 0.6723 - val_loss: 1.4173 - val_accuracy: 0.5814\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3371 - accuracy: 0.6771 - val_loss: 1.4163 - val_accuracy: 0.5724\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3312 - accuracy: 0.6769 - val_loss: 1.4086 - val_accuracy: 0.5848\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3194 - accuracy: 0.6752 - val_loss: 1.4033 - val_accuracy: 0.5566\n","Epoch 53/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.3094 - accuracy: 0.6817 - val_loss: 1.3914 - val_accuracy: 0.5916\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3100 - accuracy: 0.6590 - val_loss: 1.4215 - val_accuracy: 0.5283\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2958 - accuracy: 0.6788 - val_loss: 1.3807 - val_accuracy: 0.5803\n","Epoch 56/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.2802 - accuracy: 0.6981 - val_loss: 1.3778 - val_accuracy: 0.5928\n","Epoch 57/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2726 - accuracy: 0.6947 - val_loss: 1.3738 - val_accuracy: 0.5724\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2627 - accuracy: 0.6907 - val_loss: 1.3645 - val_accuracy: 0.5713\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2542 - accuracy: 0.7057 - val_loss: 1.3650 - val_accuracy: 0.5928\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2540 - accuracy: 0.6933 - val_loss: 1.3542 - val_accuracy: 0.5916\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2369 - accuracy: 0.7049 - val_loss: 1.3500 - val_accuracy: 0.5792\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2286 - accuracy: 0.7105 - val_loss: 1.3435 - val_accuracy: 0.5894\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2189 - accuracy: 0.7117 - val_loss: 1.3419 - val_accuracy: 0.5905\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2120 - accuracy: 0.7134 - val_loss: 1.3348 - val_accuracy: 0.5973\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1985 - accuracy: 0.7247 - val_loss: 1.3439 - val_accuracy: 0.5679\n","Epoch 66/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1937 - accuracy: 0.7199 - val_loss: 1.3268 - val_accuracy: 0.5995\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1814 - accuracy: 0.7303 - val_loss: 1.3238 - val_accuracy: 0.5950\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1737 - accuracy: 0.7286 - val_loss: 1.3303 - val_accuracy: 0.5769\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1713 - accuracy: 0.7201 - val_loss: 1.3160 - val_accuracy: 0.5905\n","Epoch 70/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.1575 - accuracy: 0.7391 - val_loss: 1.3116 - val_accuracy: 0.6018\n","Epoch 71/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1475 - accuracy: 0.7317 - val_loss: 1.3072 - val_accuracy: 0.5973\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1438 - accuracy: 0.7349 - val_loss: 1.3122 - val_accuracy: 0.5814\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1328 - accuracy: 0.7385 - val_loss: 1.3048 - val_accuracy: 0.5962\n","Epoch 74/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.1220 - accuracy: 0.7436 - val_loss: 1.2967 - val_accuracy: 0.6052\n","Epoch 75/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1157 - accuracy: 0.7482 - val_loss: 1.3008 - val_accuracy: 0.5950\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1079 - accuracy: 0.7487 - val_loss: 1.2944 - val_accuracy: 0.5973\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1086 - accuracy: 0.7431 - val_loss: 1.2898 - val_accuracy: 0.5973\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0991 - accuracy: 0.7479 - val_loss: 1.2850 - val_accuracy: 0.6052\n","Epoch 79/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.0846 - accuracy: 0.7620 - val_loss: 1.2815 - val_accuracy: 0.6063\n","Epoch 80/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.0780 - accuracy: 0.7547 - val_loss: 1.2801 - val_accuracy: 0.6097\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0690 - accuracy: 0.7663 - val_loss: 1.2884 - val_accuracy: 0.5882\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0656 - accuracy: 0.7632 - val_loss: 1.2739 - val_accuracy: 0.5995\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0588 - accuracy: 0.7606 - val_loss: 1.2710 - val_accuracy: 0.6063\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0489 - accuracy: 0.7668 - val_loss: 1.2774 - val_accuracy: 0.5871\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0513 - accuracy: 0.7564 - val_loss: 1.2703 - val_accuracy: 0.6097\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0308 - accuracy: 0.7779 - val_loss: 1.2685 - val_accuracy: 0.6063\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0312 - accuracy: 0.7750 - val_loss: 1.2699 - val_accuracy: 0.6086\n","Epoch 88/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0192 - accuracy: 0.7844 - val_loss: 1.2623 - val_accuracy: 0.6120\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0121 - accuracy: 0.7841 - val_loss: 1.2728 - val_accuracy: 0.5962\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0037 - accuracy: 0.7844 - val_loss: 1.2652 - val_accuracy: 0.6041\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9955 - accuracy: 0.7926 - val_loss: 1.2583 - val_accuracy: 0.6041\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9912 - accuracy: 0.7861 - val_loss: 1.2630 - val_accuracy: 0.6097\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9802 - accuracy: 0.7920 - val_loss: 1.2549 - val_accuracy: 0.6120\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9809 - accuracy: 0.7920 - val_loss: 1.2742 - val_accuracy: 0.5905\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9821 - accuracy: 0.7835 - val_loss: 1.2545 - val_accuracy: 0.6063\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9709 - accuracy: 0.7949 - val_loss: 1.2602 - val_accuracy: 0.6052\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9562 - accuracy: 0.8081 - val_loss: 1.2628 - val_accuracy: 0.6007\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9486 - accuracy: 0.8101 - val_loss: 1.2543 - val_accuracy: 0.6120\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9532 - accuracy: 0.7951 - val_loss: 1.2766 - val_accuracy: 0.5848\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9377 - accuracy: 0.8098 - val_loss: 1.2557 - val_accuracy: 0.6143\n","{'loss': [1.9642165899276733, 1.946720004081726, 1.9296573400497437, 1.9140803813934326, 1.8969045877456665, 1.8806366920471191, 1.8649412393569946, 1.8494384288787842, 1.8340927362442017, 1.8195945024490356, 1.8039660453796387, 1.7892683744430542, 1.7750225067138672, 1.7605187892913818, 1.7471258640289307, 1.7327792644500732, 1.7190861701965332, 1.7056913375854492, 1.6919150352478027, 1.6791737079620361, 1.6657705307006836, 1.6533774137496948, 1.6392652988433838, 1.6264692544937134, 1.6133768558502197, 1.6001001596450806, 1.5889925956726074, 1.575119972229004, 1.5631043910980225, 1.5521970987319946, 1.5392224788665771, 1.527545690536499, 1.5160160064697266, 1.5056424140930176, 1.4937163591384888, 1.4834707975387573, 1.4710288047790527, 1.460571527481079, 1.448968768119812, 1.4392515420913696, 1.4295865297317505, 1.4185127019882202, 1.4108105897903442, 1.4012104272842407, 1.3876795768737793, 1.3802167177200317, 1.3673006296157837, 1.3571351766586304, 1.3470497131347656, 1.3370790481567383, 1.331239938735962, 1.3194483518600464, 1.3094449043273926, 1.3099795579910278, 1.295788049697876, 1.2802122831344604, 1.2725574970245361, 1.2627075910568237, 1.2541831731796265, 1.253989338874817, 1.2369465827941895, 1.2285685539245605, 1.2189388275146484, 1.2119824886322021, 1.1985477209091187, 1.193709373474121, 1.1814466714859009, 1.1736985445022583, 1.1713361740112305, 1.157541275024414, 1.1475210189819336, 1.143792986869812, 1.1328113079071045, 1.121976613998413, 1.115698218345642, 1.1079096794128418, 1.108585000038147, 1.0990761518478394, 1.0846149921417236, 1.0780447721481323, 1.0689563751220703, 1.0655635595321655, 1.0587867498397827, 1.0489155054092407, 1.0513018369674683, 1.0307633876800537, 1.031195878982544, 1.0192371606826782, 1.012117624282837, 1.0036767721176147, 0.9955498576164246, 0.9911954402923584, 0.9801620841026306, 0.980915904045105, 0.9821056723594666, 0.9708842635154724, 0.9561967253684998, 0.9485535025596619, 0.9532334804534912, 0.9376980066299438], 'accuracy': [0.5048103928565979, 0.5294284224510193, 0.5461233854293823, 0.5067911744117737, 0.5500848889350891, 0.5656480193138123, 0.5616864562034607, 0.5599886775016785, 0.5531975030899048, 0.5605546236038208, 0.569609522819519, 0.5814940333366394, 0.5829088687896729, 0.5792303085327148, 0.5749858617782593, 0.5834748148918152, 0.59111487865448, 0.5897000432014465, 0.5962082743644714, 0.5919637680053711, 0.5993208885192871, 0.5829088687896729, 0.600452721118927, 0.5990379452705383, 0.6052631735801697, 0.6063950061798096, 0.6131861805915833, 0.6137521266937256, 0.6250707507133484, 0.6154499053955078, 0.6228070259094238, 0.6349745392799377, 0.6327108144760132, 0.6250707507133484, 0.6327108144760132, 0.6369553208351135, 0.6378042101860046, 0.649688720703125, 0.6468591094017029, 0.6443123817443848, 0.6443123817443848, 0.6553480625152588, 0.6451612710952759, 0.6539332270622253, 0.6629881262779236, 0.6610073447227478, 0.6692133545875549, 0.674872636795044, 0.6723259687423706, 0.6771363615989685, 0.6768534183502197, 0.6751556396484375, 0.6816638112068176, 0.6590266227722168, 0.6788341999053955, 0.6980758309364319, 0.6946802735328674, 0.6907187104225159, 0.7057158946990967, 0.693265438079834, 0.7048670053482056, 0.7105262875556946, 0.7116581797599792, 0.7133559584617615, 0.7246745824813843, 0.7198641896247864, 0.7303339242935181, 0.7286360859870911, 0.7201471328735352, 0.7391058206558228, 0.7317487001419067, 0.7348613739013672, 0.7385398745536804, 0.7436332702636719, 0.748160719871521, 0.7487266659736633, 0.7430673241615295, 0.7478777766227722, 0.7620260119438171, 0.7546689510345459, 0.7662705183029175, 0.7631579041481018, 0.7606111764907837, 0.7668364644050598, 0.7563667297363281, 0.7778720855712891, 0.7750424742698669, 0.784380316734314, 0.7840973138809204, 0.784380316734314, 0.7925863265991211, 0.7860780954360962, 0.7920203804969788, 0.7920203804969788, 0.7835314273834229, 0.7948500514030457, 0.8081493973731995, 0.8101301789283752, 0.7951329946517944, 0.8098471760749817], 'val_loss': [1.9550577402114868, 1.9386838674545288, 1.9225775003433228, 1.906738519668579, 1.8911935091018677, 1.875901222229004, 1.8608815670013428, 1.8460553884506226, 1.8315272331237793, 1.8172593116760254, 1.803256869316101, 1.7894331216812134, 1.775844931602478, 1.762473225593567, 1.7492554187774658, 1.7361726760864258, 1.7233448028564453, 1.7106215953826904, 1.698015570640564, 1.6857099533081055, 1.673790693283081, 1.6611028909683228, 1.649330496788025, 1.6375536918640137, 1.6262853145599365, 1.615728735923767, 1.6049084663391113, 1.5934205055236816, 1.5840084552764893, 1.5754890441894531, 1.5632545948028564, 1.5532252788543701, 1.548237919807434, 1.5344656705856323, 1.5257192850112915, 1.5190916061401367, 1.5116130113601685, 1.5003407001495361, 1.4930390119552612, 1.484326720237732, 1.4752089977264404, 1.467577576637268, 1.4621959924697876, 1.4590989351272583, 1.4445269107818604, 1.4448519945144653, 1.4345256090164185, 1.4260413646697998, 1.4172626733779907, 1.4163076877593994, 1.4086201190948486, 1.403299331665039, 1.3914467096328735, 1.421461820602417, 1.3807200193405151, 1.3778153657913208, 1.3737621307373047, 1.3644835948944092, 1.3649582862854004, 1.3541884422302246, 1.3499749898910522, 1.3435039520263672, 1.3418843746185303, 1.3348389863967896, 1.3439003229141235, 1.326827049255371, 1.3237521648406982, 1.3302842378616333, 1.3159635066986084, 1.3116130828857422, 1.3072028160095215, 1.3121836185455322, 1.304836630821228, 1.2967220544815063, 1.3008394241333008, 1.2944189310073853, 1.2897802591323853, 1.2850301265716553, 1.2814650535583496, 1.2801276445388794, 1.288406491279602, 1.2739336490631104, 1.2709704637527466, 1.2774001359939575, 1.270321011543274, 1.2684718370437622, 1.2699041366577148, 1.2622767686843872, 1.272753119468689, 1.2651681900024414, 1.2582660913467407, 1.2630388736724854, 1.254930019378662, 1.2742397785186768, 1.2545251846313477, 1.2601937055587769, 1.2627512216567993, 1.2543206214904785, 1.2766329050064087, 1.2556852102279663], 'val_accuracy': [0.5135746598243713, 0.5384615659713745, 0.5124434232711792, 0.5135746598243713, 0.5226244330406189, 0.5361990928649902, 0.5113122463226318, 0.5441176295280457, 0.5260180830955505, 0.5350678563117981, 0.5531674027442932, 0.5248869061470032, 0.5248869061470032, 0.5339366793632507, 0.5260180830955505, 0.5441176295280457, 0.5316742062568665, 0.5350678563117981, 0.5316742062568665, 0.529411792755127, 0.523755669593811, 0.5418552160263062, 0.5384615659713745, 0.5429864525794983, 0.5520362257957458, 0.5486425161361694, 0.5452488660812378, 0.5350678563117981, 0.5486425161361694, 0.5429864525794983, 0.5441176295280457, 0.5429864525794983, 0.5542986392974854, 0.5475113391876221, 0.5622171759605408, 0.5531674027442932, 0.5599547624588013, 0.5678732991218567, 0.5475113391876221, 0.5475113391876221, 0.564479649066925, 0.5565611124038696, 0.570135772228241, 0.5633484125137329, 0.581447958946228, 0.5678732991218567, 0.5656108856201172, 0.5633484125137329, 0.581447958946228, 0.5723981857299805, 0.5848416090011597, 0.5565611124038696, 0.5916289687156677, 0.5282805562019348, 0.5803167223930359, 0.5927602052688599, 0.5723981857299805, 0.5712669491767883, 0.5927602052688599, 0.5916289687156677, 0.5791855454444885, 0.5893664956092834, 0.5904977321624756, 0.5972850918769836, 0.5678732991218567, 0.5995475053787231, 0.5950226187705994, 0.5769230723381042, 0.5904977321624756, 0.6018099784851074, 0.5972850918769836, 0.581447958946228, 0.5961538553237915, 0.6052036285400391, 0.5950226187705994, 0.5972850918769836, 0.5972850918769836, 0.6052036285400391, 0.6063348650932312, 0.6097285151481628, 0.5882353186607361, 0.5995475053787231, 0.6063348650932312, 0.587104082107544, 0.6097285151481628, 0.6063348650932312, 0.6085972785949707, 0.6119909286499023, 0.5961538553237915, 0.6040723919868469, 0.6040723919868469, 0.6097285151481628, 0.6119909286499023, 0.5904977321624756, 0.6063348650932312, 0.6052036285400391, 0.6006787419319153, 0.6119909286499023, 0.5848416090011597, 0.6142534017562866]}\n","45/45 [==============================] - 0s 7ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 1.9642 - accuracy: 0.5078"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 4s 59ms/step - loss: 1.9642 - accuracy: 0.5078 - val_loss: 1.9541 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.9441 - accuracy: 0.5235 - val_loss: 1.9365 - val_accuracy: 0.5083\n","Epoch 3/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.9249 - accuracy: 0.5357 - val_loss: 1.9192 - val_accuracy: 0.4948\n","Epoch 4/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.9068 - accuracy: 0.5395 - val_loss: 1.9024 - val_accuracy: 0.5114\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.8888 - accuracy: 0.5375 - val_loss: 1.8859 - val_accuracy: 0.5062\n","Epoch 6/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.8715 - accuracy: 0.5589 - val_loss: 1.8697 - val_accuracy: 0.4990\n","Epoch 7/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.8551 - accuracy: 0.5413 - val_loss: 1.8537 - val_accuracy: 0.5083\n","Epoch 8/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.8382 - accuracy: 0.5568 - val_loss: 1.8381 - val_accuracy: 0.5134\n","Epoch 9/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.8217 - accuracy: 0.5592 - val_loss: 1.8230 - val_accuracy: 0.4990\n","Epoch 10/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.8056 - accuracy: 0.5638 - val_loss: 1.8079 - val_accuracy: 0.5155\n","Epoch 11/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.7888 - accuracy: 0.5680 - val_loss: 1.7935 - val_accuracy: 0.5000\n","Epoch 12/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.7747 - accuracy: 0.5656 - val_loss: 1.7788 - val_accuracy: 0.5186\n","Epoch 13/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.7583 - accuracy: 0.5739 - val_loss: 1.7644 - val_accuracy: 0.5124\n","Epoch 14/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.7426 - accuracy: 0.5835 - val_loss: 1.7510 - val_accuracy: 0.5176\n","Epoch 15/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.7280 - accuracy: 0.5793 - val_loss: 1.7376 - val_accuracy: 0.5176\n","Epoch 16/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.7141 - accuracy: 0.5811 - val_loss: 1.7236 - val_accuracy: 0.5176\n","Epoch 17/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.6992 - accuracy: 0.5855 - val_loss: 1.7100 - val_accuracy: 0.5176\n","Epoch 18/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.6857 - accuracy: 0.5860 - val_loss: 1.6979 - val_accuracy: 0.5186\n","Epoch 19/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.6714 - accuracy: 0.5922 - val_loss: 1.6850 - val_accuracy: 0.5258\n","Epoch 20/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.6565 - accuracy: 0.5995 - val_loss: 1.6731 - val_accuracy: 0.5207\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.6445 - accuracy: 0.5858 - val_loss: 1.6608 - val_accuracy: 0.5155\n","Epoch 22/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.6300 - accuracy: 0.5964 - val_loss: 1.6495 - val_accuracy: 0.5269\n","Epoch 23/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.6165 - accuracy: 0.6052 - val_loss: 1.6378 - val_accuracy: 0.5186\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.6054 - accuracy: 0.6026 - val_loss: 1.6272 - val_accuracy: 0.5269\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5941 - accuracy: 0.5953 - val_loss: 1.6160 - val_accuracy: 0.5227\n","Epoch 26/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5794 - accuracy: 0.6134 - val_loss: 1.6066 - val_accuracy: 0.5238\n","Epoch 27/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.5651 - accuracy: 0.6178 - val_loss: 1.5959 - val_accuracy: 0.5382\n","Epoch 28/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.5530 - accuracy: 0.6163 - val_loss: 1.5868 - val_accuracy: 0.5403\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.5418 - accuracy: 0.6137 - val_loss: 1.5765 - val_accuracy: 0.5238\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.5306 - accuracy: 0.6202 - val_loss: 1.5669 - val_accuracy: 0.5372\n","Epoch 31/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.5180 - accuracy: 0.6152 - val_loss: 1.5604 - val_accuracy: 0.5289\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.5054 - accuracy: 0.6214 - val_loss: 1.5499 - val_accuracy: 0.5320\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4939 - accuracy: 0.6276 - val_loss: 1.5420 - val_accuracy: 0.5279\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.4820 - accuracy: 0.6297 - val_loss: 1.5340 - val_accuracy: 0.5320\n","Epoch 35/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4702 - accuracy: 0.6333 - val_loss: 1.5222 - val_accuracy: 0.5434\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.4590 - accuracy: 0.6354 - val_loss: 1.5177 - val_accuracy: 0.5320\n","Epoch 37/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4469 - accuracy: 0.6364 - val_loss: 1.5065 - val_accuracy: 0.5475\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.4356 - accuracy: 0.6351 - val_loss: 1.5009 - val_accuracy: 0.5362\n","Epoch 39/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4243 - accuracy: 0.6388 - val_loss: 1.4929 - val_accuracy: 0.5506\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.4136 - accuracy: 0.6499 - val_loss: 1.4868 - val_accuracy: 0.5331\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.4021 - accuracy: 0.6512 - val_loss: 1.4805 - val_accuracy: 0.5475\n","Epoch 42/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3914 - accuracy: 0.6574 - val_loss: 1.4689 - val_accuracy: 0.5517\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3812 - accuracy: 0.6587 - val_loss: 1.4644 - val_accuracy: 0.5568\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3726 - accuracy: 0.6576 - val_loss: 1.4598 - val_accuracy: 0.5227\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3613 - accuracy: 0.6620 - val_loss: 1.4482 - val_accuracy: 0.5475\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3492 - accuracy: 0.6690 - val_loss: 1.4425 - val_accuracy: 0.5517\n","Epoch 47/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.3434 - accuracy: 0.6633 - val_loss: 1.4359 - val_accuracy: 0.5651\n","Epoch 48/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.3318 - accuracy: 0.6693 - val_loss: 1.4305 - val_accuracy: 0.5692\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3210 - accuracy: 0.6729 - val_loss: 1.4223 - val_accuracy: 0.5640\n","Epoch 50/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.3078 - accuracy: 0.6842 - val_loss: 1.4172 - val_accuracy: 0.5692\n","Epoch 51/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2992 - accuracy: 0.6842 - val_loss: 1.4183 - val_accuracy: 0.5444\n","Epoch 52/100\n","31/31 [==============================] - 1s 29ms/step - loss: 1.2941 - accuracy: 0.6848 - val_loss: 1.4074 - val_accuracy: 0.5651\n","Epoch 53/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2772 - accuracy: 0.6948 - val_loss: 1.4036 - val_accuracy: 0.5610\n","Epoch 54/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2694 - accuracy: 0.7000 - val_loss: 1.3981 - val_accuracy: 0.5640\n","Epoch 55/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2586 - accuracy: 0.7021 - val_loss: 1.3920 - val_accuracy: 0.5579\n","Epoch 56/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2496 - accuracy: 0.6959 - val_loss: 1.3962 - val_accuracy: 0.5496\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2443 - accuracy: 0.6881 - val_loss: 1.3830 - val_accuracy: 0.5599\n","Epoch 58/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2326 - accuracy: 0.7023 - val_loss: 1.3900 - val_accuracy: 0.5434\n","Epoch 59/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2231 - accuracy: 0.7098 - val_loss: 1.3830 - val_accuracy: 0.5506\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2147 - accuracy: 0.7078 - val_loss: 1.3769 - val_accuracy: 0.5496\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2042 - accuracy: 0.7160 - val_loss: 1.3658 - val_accuracy: 0.5527\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1932 - accuracy: 0.7287 - val_loss: 1.3724 - val_accuracy: 0.5444\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1866 - accuracy: 0.7111 - val_loss: 1.3649 - val_accuracy: 0.5434\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1733 - accuracy: 0.7214 - val_loss: 1.3792 - val_accuracy: 0.5279\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1701 - accuracy: 0.7186 - val_loss: 1.3546 - val_accuracy: 0.5548\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1554 - accuracy: 0.7295 - val_loss: 1.3550 - val_accuracy: 0.5506\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1480 - accuracy: 0.7385 - val_loss: 1.3637 - val_accuracy: 0.5424\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1444 - accuracy: 0.7243 - val_loss: 1.3511 - val_accuracy: 0.5599\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1305 - accuracy: 0.7421 - val_loss: 1.3508 - val_accuracy: 0.5434\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1211 - accuracy: 0.7452 - val_loss: 1.3442 - val_accuracy: 0.5444\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1186 - accuracy: 0.7421 - val_loss: 1.3432 - val_accuracy: 0.5558\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1025 - accuracy: 0.7499 - val_loss: 1.3387 - val_accuracy: 0.5475\n","Epoch 73/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.1040 - accuracy: 0.7370 - val_loss: 1.3847 - val_accuracy: 0.5248\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0974 - accuracy: 0.7403 - val_loss: 1.3330 - val_accuracy: 0.5496\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0829 - accuracy: 0.7537 - val_loss: 1.3587 - val_accuracy: 0.5248\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0755 - accuracy: 0.7597 - val_loss: 1.3300 - val_accuracy: 0.5517\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0732 - accuracy: 0.7561 - val_loss: 1.3761 - val_accuracy: 0.5310\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0613 - accuracy: 0.7540 - val_loss: 1.3261 - val_accuracy: 0.5527\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0512 - accuracy: 0.7682 - val_loss: 1.3484 - val_accuracy: 0.5289\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0453 - accuracy: 0.7703 - val_loss: 1.3654 - val_accuracy: 0.5331\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0384 - accuracy: 0.7672 - val_loss: 1.3281 - val_accuracy: 0.5475\n","Epoch 82/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0292 - accuracy: 0.7747 - val_loss: 1.3404 - val_accuracy: 0.5372\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0202 - accuracy: 0.7755 - val_loss: 1.3224 - val_accuracy: 0.5434\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0124 - accuracy: 0.7842 - val_loss: 1.3263 - val_accuracy: 0.5424\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0091 - accuracy: 0.7729 - val_loss: 1.3365 - val_accuracy: 0.5413\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0069 - accuracy: 0.7736 - val_loss: 1.3453 - val_accuracy: 0.5351\n","Epoch 87/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9926 - accuracy: 0.7866 - val_loss: 1.3311 - val_accuracy: 0.5393\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9860 - accuracy: 0.7889 - val_loss: 1.3242 - val_accuracy: 0.5393\n","Epoch 89/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9793 - accuracy: 0.7891 - val_loss: 1.3263 - val_accuracy: 0.5372\n","Epoch 90/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9686 - accuracy: 0.8018 - val_loss: 1.3238 - val_accuracy: 0.5413\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9615 - accuracy: 0.8041 - val_loss: 1.3238 - val_accuracy: 0.5393\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9557 - accuracy: 0.7966 - val_loss: 1.3614 - val_accuracy: 0.5320\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9549 - accuracy: 0.7938 - val_loss: 1.3257 - val_accuracy: 0.5455\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9418 - accuracy: 0.8075 - val_loss: 1.3274 - val_accuracy: 0.5362\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9390 - accuracy: 0.8054 - val_loss: 1.3501 - val_accuracy: 0.5217\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9299 - accuracy: 0.8078 - val_loss: 1.3278 - val_accuracy: 0.5413\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9169 - accuracy: 0.8251 - val_loss: 1.3394 - val_accuracy: 0.5351\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9196 - accuracy: 0.8072 - val_loss: 1.3336 - val_accuracy: 0.5382\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9163 - accuracy: 0.8031 - val_loss: 1.3288 - val_accuracy: 0.5382\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9070 - accuracy: 0.8189 - val_loss: 1.3317 - val_accuracy: 0.5341\n","{'loss': [1.9641542434692383, 1.9440791606903076, 1.924865484237671, 1.9068269729614258, 1.8888139724731445, 1.8715366125106812, 1.855089783668518, 1.8382251262664795, 1.8216774463653564, 1.8056215047836304, 1.788750410079956, 1.7746502161026, 1.7582857608795166, 1.7425613403320312, 1.7279775142669678, 1.7141265869140625, 1.6992071866989136, 1.6857059001922607, 1.671404242515564, 1.656497597694397, 1.6445152759552002, 1.630015254020691, 1.6164686679840088, 1.6053625345230103, 1.5941210985183716, 1.579370379447937, 1.5651280879974365, 1.553011417388916, 1.5418425798416138, 1.5306073427200317, 1.5180317163467407, 1.5054420232772827, 1.4939228296279907, 1.4820351600646973, 1.4702154397964478, 1.4590134620666504, 1.4469258785247803, 1.4356108903884888, 1.424315094947815, 1.4135944843292236, 1.4020864963531494, 1.3913533687591553, 1.3811967372894287, 1.37263023853302, 1.361345648765564, 1.3492306470870972, 1.3433746099472046, 1.3318219184875488, 1.32097327709198, 1.3077569007873535, 1.2991633415222168, 1.2941185235977173, 1.2771748304367065, 1.269386887550354, 1.258649468421936, 1.2495555877685547, 1.244277000427246, 1.2325786352157593, 1.2231495380401611, 1.2147252559661865, 1.2041652202606201, 1.1931744813919067, 1.186600685119629, 1.1732980012893677, 1.1701451539993286, 1.1553865671157837, 1.1480287313461304, 1.144361138343811, 1.1304545402526855, 1.1210875511169434, 1.1186267137527466, 1.1025073528289795, 1.1040174961090088, 1.0974336862564087, 1.082873821258545, 1.0754978656768799, 1.0731624364852905, 1.0612870454788208, 1.051203727722168, 1.045292854309082, 1.0384153127670288, 1.0292294025421143, 1.0201927423477173, 1.0124022960662842, 1.0091145038604736, 1.0069224834442139, 0.9926472902297974, 0.9860390424728394, 0.9792846441268921, 0.9685688614845276, 0.9615325331687927, 0.9556561708450317, 0.9549062848091125, 0.9418002367019653, 0.9389885067939758, 0.929893970489502, 0.9169325232505798, 0.9196268320083618, 0.9163060188293457, 0.9070408344268799], 'accuracy': [0.5077519416809082, 0.5235142111778259, 0.5356588959693909, 0.539534866809845, 0.5374677181243896, 0.5589147210121155, 0.5413436889648438, 0.5568475723266602, 0.5591731071472168, 0.5638242959976196, 0.567958652973175, 0.5656330585479736, 0.5739018321037292, 0.5834625363349915, 0.579328179359436, 0.58113694190979, 0.5855297446250916, 0.5860465168952942, 0.5922480821609497, 0.5994831919670105, 0.5857881307601929, 0.5963824391365051, 0.6051679849624634, 0.6025840044021606, 0.5953488349914551, 0.6134366989135742, 0.617829442024231, 0.6162790656089783, 0.6136950850486755, 0.6201550364494324, 0.6152454614639282, 0.6214470267295837, 0.6276485919952393, 0.6297157406806946, 0.6333333253860474, 0.6354005336761475, 0.6364341378211975, 0.6351421475410461, 0.6387596726417542, 0.6498708128929138, 0.6511628031730652, 0.6573643684387207, 0.6586563587188721, 0.657622754573822, 0.6620154976844788, 0.6689922213554382, 0.6633074879646301, 0.6692506670951843, 0.6728681921958923, 0.6842377185821533, 0.6842377185821533, 0.6847545504570007, 0.6948320269584656, 0.699999988079071, 0.7020671963691711, 0.6958656311035156, 0.6881136894226074, 0.7023255825042725, 0.7098191380500793, 0.7077519297599792, 0.7160206437110901, 0.7286821603775024, 0.7111111283302307, 0.7214470505714417, 0.7186046242713928, 0.7294573783874512, 0.7385013103485107, 0.7242894172668457, 0.7421188354492188, 0.7452196478843689, 0.7421188354492188, 0.749870777130127, 0.7369509339332581, 0.7403100728988647, 0.753746747970581, 0.7596899271011353, 0.7560723423957825, 0.7540051937103271, 0.7682170271873474, 0.7702842354774475, 0.7671834826469421, 0.7746769785881042, 0.775452196598053, 0.7842377424240112, 0.7728682160377502, 0.773643434047699, 0.7865633368492126, 0.7888888716697693, 0.7891472578048706, 0.801808774471283, 0.8041343688964844, 0.7966408133506775, 0.7937984466552734, 0.8074935674667358, 0.8054263591766357, 0.8077519536018372, 0.8250645995140076, 0.8072351217269897, 0.8031007647514343, 0.818863034248352], 'val_loss': [1.954136848449707, 1.9364973306655884, 1.9192249774932861, 1.9024040699005127, 1.8858619928359985, 1.8697235584259033, 1.8537309169769287, 1.8380937576293945, 1.8229962587356567, 1.8078731298446655, 1.7934966087341309, 1.778787612915039, 1.7644346952438354, 1.7509894371032715, 1.7375600337982178, 1.7236175537109375, 1.7099781036376953, 1.697921872138977, 1.6849536895751953, 1.673115611076355, 1.660818338394165, 1.6495006084442139, 1.6378169059753418, 1.6272460222244263, 1.6160250902175903, 1.606595516204834, 1.5958802700042725, 1.5867563486099243, 1.5765291452407837, 1.566946268081665, 1.5604475736618042, 1.5499250888824463, 1.5419790744781494, 1.534015417098999, 1.5222299098968506, 1.5176926851272583, 1.5064505338668823, 1.5008682012557983, 1.4929468631744385, 1.4867879152297974, 1.4804645776748657, 1.4688923358917236, 1.4643921852111816, 1.4597759246826172, 1.448226809501648, 1.442489743232727, 1.4358667135238647, 1.430506706237793, 1.4223461151123047, 1.417165756225586, 1.418319821357727, 1.407435655593872, 1.4036198854446411, 1.3980690240859985, 1.3920475244522095, 1.396242380142212, 1.3829638957977295, 1.3899537324905396, 1.3830454349517822, 1.3768590688705444, 1.365844488143921, 1.372438669204712, 1.3649042844772339, 1.3792246580123901, 1.3545942306518555, 1.35499906539917, 1.3636746406555176, 1.351124882698059, 1.350791096687317, 1.344222903251648, 1.3431683778762817, 1.3387497663497925, 1.3846851587295532, 1.3329932689666748, 1.3586745262145996, 1.329976201057434, 1.376137614250183, 1.326112985610962, 1.3484365940093994, 1.3653786182403564, 1.3280938863754272, 1.340436339378357, 1.3223563432693481, 1.3262509107589722, 1.336492896080017, 1.345260739326477, 1.3310778141021729, 1.3242031335830688, 1.3262966871261597, 1.3238270282745361, 1.323760747909546, 1.3614245653152466, 1.3257445096969604, 1.3274401426315308, 1.3501091003417969, 1.327771782875061, 1.3393592834472656, 1.3335561752319336, 1.3287512063980103, 1.3316540718078613], 'val_accuracy': [0.48553720116615295, 0.5082644820213318, 0.4948347210884094, 0.5113636255264282, 0.5061983466148376, 0.49896693229675293, 0.5082644820213318, 0.5134297609329224, 0.49896693229675293, 0.5154958963394165, 0.5, 0.5185950398445129, 0.5123966932296753, 0.5175619721412659, 0.5175619721412659, 0.5175619721412659, 0.5175619721412659, 0.5185950398445129, 0.5258264541625977, 0.5206611752510071, 0.5154958963394165, 0.5268595218658447, 0.5185950398445129, 0.5268595218658447, 0.5227272510528564, 0.5237603187561035, 0.538223147392273, 0.5402892827987671, 0.5237603187561035, 0.5371900796890259, 0.5289255976676941, 0.5320248007774353, 0.5278925895690918, 0.5320248007774353, 0.5433884263038635, 0.5320248007774353, 0.547520637512207, 0.5361570119857788, 0.5506198406219482, 0.5330578684806824, 0.547520637512207, 0.5516529083251953, 0.5568181872367859, 0.5227272510528564, 0.547520637512207, 0.5516529083251953, 0.5650826692581177, 0.5692148804664612, 0.5640496015548706, 0.5692148804664612, 0.5444214940071106, 0.5650826692581177, 0.5609503984451294, 0.5640496015548706, 0.557851254940033, 0.5495867729187012, 0.5599173307418823, 0.5433884263038635, 0.5506198406219482, 0.5495867729187012, 0.5526859760284424, 0.5444214940071106, 0.5433884263038635, 0.5278925895690918, 0.5547520518302917, 0.5506198406219482, 0.5423553586006165, 0.5599173307418823, 0.5433884263038635, 0.5444214940071106, 0.5557851195335388, 0.547520637512207, 0.5247933864593506, 0.5495867729187012, 0.5247933864593506, 0.5516529083251953, 0.5309917330741882, 0.5526859760284424, 0.5289255976676941, 0.5330578684806824, 0.547520637512207, 0.5371900796890259, 0.5433884263038635, 0.5423553586006165, 0.5413222908973694, 0.5351239442825317, 0.53925621509552, 0.53925621509552, 0.5371900796890259, 0.5413222908973694, 0.53925621509552, 0.5320248007774353, 0.5454545617103577, 0.5361570119857788, 0.5216942429542542, 0.5413222908973694, 0.5351239442825317, 0.538223147392273, 0.538223147392273, 0.5340909361839294]}\n","32/32 [==============================] - 0s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 5s 36ms/step - loss: 1.0421 - accuracy: 0.7109 - val_loss: 1.1772 - val_accuracy: 0.5851\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 1.0784 - accuracy: 0.6953"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 13ms/step - loss: 1.0237 - accuracy: 0.7395 - val_loss: 1.1730 - val_accuracy: 0.5668\n","Epoch 3/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0078 - accuracy: 0.7519 - val_loss: 1.1686 - val_accuracy: 0.5808\n","Epoch 4/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0031 - accuracy: 0.7532 - val_loss: 1.1646 - val_accuracy: 0.5668\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9908 - accuracy: 0.7699 - val_loss: 1.1596 - val_accuracy: 0.5787\n","Epoch 6/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9853 - accuracy: 0.7535 - val_loss: 1.1548 - val_accuracy: 0.5797\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9764 - accuracy: 0.7651 - val_loss: 1.1491 - val_accuracy: 0.6024\n","Epoch 8/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9695 - accuracy: 0.7697 - val_loss: 1.1441 - val_accuracy: 0.5927\n","Epoch 9/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9634 - accuracy: 0.7699 - val_loss: 1.1385 - val_accuracy: 0.6056\n","Epoch 10/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.9520 - accuracy: 0.7842 - val_loss: 1.1321 - val_accuracy: 0.6207\n","Epoch 11/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9455 - accuracy: 0.7823 - val_loss: 1.1260 - val_accuracy: 0.6185\n","Epoch 12/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9387 - accuracy: 0.7918 - val_loss: 1.1191 - val_accuracy: 0.6433\n","Epoch 13/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9341 - accuracy: 0.7936 - val_loss: 1.1127 - val_accuracy: 0.6228\n","Epoch 14/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9285 - accuracy: 0.7904 - val_loss: 1.1059 - val_accuracy: 0.6401\n","Epoch 15/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9227 - accuracy: 0.7912 - val_loss: 1.0983 - val_accuracy: 0.6703\n","Epoch 16/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9200 - accuracy: 0.7899 - val_loss: 1.0915 - val_accuracy: 0.6519\n","Epoch 17/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9079 - accuracy: 0.8060 - val_loss: 1.0845 - val_accuracy: 0.6530\n","Epoch 18/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9013 - accuracy: 0.8052 - val_loss: 1.0790 - val_accuracy: 0.6422\n","Epoch 19/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8996 - accuracy: 0.7953 - val_loss: 1.0747 - val_accuracy: 0.6476\n","Epoch 20/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8907 - accuracy: 0.8114 - val_loss: 1.0673 - val_accuracy: 0.6595\n","Epoch 21/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8865 - accuracy: 0.8095 - val_loss: 1.0666 - val_accuracy: 0.6444\n","Epoch 22/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8819 - accuracy: 0.8025 - val_loss: 1.0628 - val_accuracy: 0.6455\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8870 - accuracy: 0.7926 - val_loss: 1.0787 - val_accuracy: 0.6261\n","Epoch 24/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8693 - accuracy: 0.8155 - val_loss: 1.0590 - val_accuracy: 0.6509\n","Epoch 25/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8639 - accuracy: 0.8168 - val_loss: 1.0884 - val_accuracy: 0.6207\n","Epoch 26/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8546 - accuracy: 0.8225 - val_loss: 1.0722 - val_accuracy: 0.6444\n","Epoch 27/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8515 - accuracy: 0.8246 - val_loss: 1.0731 - val_accuracy: 0.6422\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8434 - accuracy: 0.8287 - val_loss: 1.0727 - val_accuracy: 0.6433\n","Epoch 29/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8388 - accuracy: 0.8303 - val_loss: 1.0703 - val_accuracy: 0.6466\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8365 - accuracy: 0.8300 - val_loss: 1.0692 - val_accuracy: 0.6412\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8431 - accuracy: 0.8160 - val_loss: 1.0791 - val_accuracy: 0.6455\n","Epoch 32/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8306 - accuracy: 0.8270 - val_loss: 1.0833 - val_accuracy: 0.6455\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8186 - accuracy: 0.8367 - val_loss: 1.0703 - val_accuracy: 0.6412\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8222 - accuracy: 0.8252 - val_loss: 1.0770 - val_accuracy: 0.6422\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8176 - accuracy: 0.8324 - val_loss: 1.0693 - val_accuracy: 0.6552\n","Epoch 36/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8083 - accuracy: 0.8359 - val_loss: 1.0692 - val_accuracy: 0.6541\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8030 - accuracy: 0.8392 - val_loss: 1.0709 - val_accuracy: 0.6466\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7996 - accuracy: 0.8427 - val_loss: 1.0725 - val_accuracy: 0.6347\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7871 - accuracy: 0.8499 - val_loss: 1.0736 - val_accuracy: 0.6444\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7843 - accuracy: 0.8478 - val_loss: 1.0866 - val_accuracy: 0.6476\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7771 - accuracy: 0.8548 - val_loss: 1.0738 - val_accuracy: 0.6422\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7756 - accuracy: 0.8516 - val_loss: 1.0746 - val_accuracy: 0.6422\n","Epoch 43/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7681 - accuracy: 0.8629 - val_loss: 1.0867 - val_accuracy: 0.6412\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7599 - accuracy: 0.8658 - val_loss: 1.0803 - val_accuracy: 0.6325\n","Epoch 45/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7597 - accuracy: 0.8613 - val_loss: 1.0818 - val_accuracy: 0.6455\n","Epoch 46/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7531 - accuracy: 0.8653 - val_loss: 1.0814 - val_accuracy: 0.6433\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7483 - accuracy: 0.8653 - val_loss: 1.0989 - val_accuracy: 0.6412\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7467 - accuracy: 0.8658 - val_loss: 1.0913 - val_accuracy: 0.6401\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7403 - accuracy: 0.8739 - val_loss: 1.0863 - val_accuracy: 0.6412\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7335 - accuracy: 0.8742 - val_loss: 1.0980 - val_accuracy: 0.6401\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7289 - accuracy: 0.8750 - val_loss: 1.1253 - val_accuracy: 0.6282\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7230 - accuracy: 0.8790 - val_loss: 1.0910 - val_accuracy: 0.6272\n","Epoch 53/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7188 - accuracy: 0.8804 - val_loss: 1.1036 - val_accuracy: 0.6444\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7378 - accuracy: 0.8551 - val_loss: 1.0895 - val_accuracy: 0.6390\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7100 - accuracy: 0.8871 - val_loss: 1.0971 - val_accuracy: 0.6325\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7020 - accuracy: 0.8885 - val_loss: 1.0927 - val_accuracy: 0.6455\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7043 - accuracy: 0.8834 - val_loss: 1.1006 - val_accuracy: 0.6358\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7005 - accuracy: 0.8871 - val_loss: 1.0978 - val_accuracy: 0.6401\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6950 - accuracy: 0.8909 - val_loss: 1.0991 - val_accuracy: 0.6358\n","Epoch 60/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6866 - accuracy: 0.8939 - val_loss: 1.1149 - val_accuracy: 0.6325\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6860 - accuracy: 0.8866 - val_loss: 1.1061 - val_accuracy: 0.6336\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6770 - accuracy: 0.8963 - val_loss: 1.1080 - val_accuracy: 0.6347\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6737 - accuracy: 0.8941 - val_loss: 1.1568 - val_accuracy: 0.6293\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6704 - accuracy: 0.8974 - val_loss: 1.1163 - val_accuracy: 0.6304\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6658 - accuracy: 0.8982 - val_loss: 1.1136 - val_accuracy: 0.6369\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6644 - accuracy: 0.9014 - val_loss: 1.1131 - val_accuracy: 0.6401\n","Epoch 67/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6548 - accuracy: 0.9052 - val_loss: 1.1131 - val_accuracy: 0.6498\n","Epoch 68/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6512 - accuracy: 0.9041 - val_loss: 1.1189 - val_accuracy: 0.6379\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6482 - accuracy: 0.9100 - val_loss: 1.1193 - val_accuracy: 0.6369\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6458 - accuracy: 0.9068 - val_loss: 1.1257 - val_accuracy: 0.6390\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6412 - accuracy: 0.9087 - val_loss: 1.1488 - val_accuracy: 0.6272\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6321 - accuracy: 0.9186 - val_loss: 1.1328 - val_accuracy: 0.6325\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6300 - accuracy: 0.9146 - val_loss: 1.1352 - val_accuracy: 0.6336\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6250 - accuracy: 0.9168 - val_loss: 1.1594 - val_accuracy: 0.6315\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6250 - accuracy: 0.9133 - val_loss: 1.1406 - val_accuracy: 0.6379\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6228 - accuracy: 0.9149 - val_loss: 1.1459 - val_accuracy: 0.6304\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6108 - accuracy: 0.9230 - val_loss: 1.1403 - val_accuracy: 0.6315\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6082 - accuracy: 0.9240 - val_loss: 1.1504 - val_accuracy: 0.6466\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6062 - accuracy: 0.9251 - val_loss: 1.1786 - val_accuracy: 0.6315\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6004 - accuracy: 0.9273 - val_loss: 1.1552 - val_accuracy: 0.6455\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5975 - accuracy: 0.9240 - val_loss: 1.1591 - val_accuracy: 0.6358\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5904 - accuracy: 0.9324 - val_loss: 1.1582 - val_accuracy: 0.6369\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5963 - accuracy: 0.9251 - val_loss: 1.1558 - val_accuracy: 0.6336\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6152 - accuracy: 0.9073 - val_loss: 1.1619 - val_accuracy: 0.6358\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5788 - accuracy: 0.9391 - val_loss: 1.1753 - val_accuracy: 0.6325\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5766 - accuracy: 0.9353 - val_loss: 1.1744 - val_accuracy: 0.6358\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5700 - accuracy: 0.9418 - val_loss: 1.1768 - val_accuracy: 0.6304\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5651 - accuracy: 0.9448 - val_loss: 1.1803 - val_accuracy: 0.6347\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5634 - accuracy: 0.9429 - val_loss: 1.1847 - val_accuracy: 0.6412\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5633 - accuracy: 0.9413 - val_loss: 1.1897 - val_accuracy: 0.6282\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5588 - accuracy: 0.9394 - val_loss: 1.2007 - val_accuracy: 0.6282\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5557 - accuracy: 0.9418 - val_loss: 1.2075 - val_accuracy: 0.6336\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5550 - accuracy: 0.9429 - val_loss: 1.2527 - val_accuracy: 0.6239\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5534 - accuracy: 0.9418 - val_loss: 1.2102 - val_accuracy: 0.6315\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5479 - accuracy: 0.9423 - val_loss: 1.2220 - val_accuracy: 0.6347\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5381 - accuracy: 0.9534 - val_loss: 1.2132 - val_accuracy: 0.6325\n","Epoch 97/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5343 - accuracy: 0.9569 - val_loss: 1.2320 - val_accuracy: 0.6228\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5344 - accuracy: 0.9585 - val_loss: 1.2391 - val_accuracy: 0.6272\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5331 - accuracy: 0.9539 - val_loss: 1.2178 - val_accuracy: 0.6401\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5308 - accuracy: 0.9555 - val_loss: 1.2774 - val_accuracy: 0.6185\n","{'loss': [1.0420992374420166, 1.0236669778823853, 1.0077948570251465, 1.0030580759048462, 0.9907995462417603, 0.985283613204956, 0.9764381647109985, 0.9695132970809937, 0.9634179472923279, 0.9519647359848022, 0.9454811215400696, 0.9387007355690002, 0.9340516924858093, 0.9285246133804321, 0.9227204918861389, 0.9199987649917603, 0.9078795313835144, 0.9012691974639893, 0.8996286988258362, 0.8906772136688232, 0.886519193649292, 0.8818548321723938, 0.8869646787643433, 0.8692940473556519, 0.8639023303985596, 0.8545986413955688, 0.8515044450759888, 0.843426525592804, 0.8388289213180542, 0.83647221326828, 0.843108594417572, 0.8306340575218201, 0.818603515625, 0.8221688866615295, 0.8176311254501343, 0.8082711696624756, 0.8029691576957703, 0.7995895147323608, 0.7870761752128601, 0.7843235731124878, 0.7771320343017578, 0.7755985260009766, 0.7681124210357666, 0.7599465847015381, 0.7596729397773743, 0.7531133890151978, 0.7482816576957703, 0.7467001676559448, 0.7403343915939331, 0.7335230708122253, 0.7288705706596375, 0.723003625869751, 0.718835175037384, 0.7377723455429077, 0.7099654674530029, 0.7020313143730164, 0.7042505145072937, 0.7005466222763062, 0.6950059533119202, 0.6866165399551392, 0.6860396862030029, 0.677029550075531, 0.6736963391304016, 0.6704321503639221, 0.6657556891441345, 0.6644102931022644, 0.6548135280609131, 0.6512424945831299, 0.6482360363006592, 0.6457501649856567, 0.6411899328231812, 0.6320543885231018, 0.6300168037414551, 0.6249662637710571, 0.624967098236084, 0.6227959990501404, 0.6108347773551941, 0.6081809401512146, 0.6062036752700806, 0.6004007458686829, 0.5975494384765625, 0.5903955101966858, 0.5963443517684937, 0.6151686310768127, 0.5787860155105591, 0.5765734910964966, 0.5700032711029053, 0.5651045441627502, 0.5633602738380432, 0.5633439421653748, 0.5587887167930603, 0.5557110905647278, 0.5550364255905151, 0.5533758401870728, 0.5478583574295044, 0.5380802154541016, 0.5342817902565002, 0.5344414114952087, 0.533148467540741, 0.5308114886283875], 'accuracy': [0.7109375, 0.7394935488700867, 0.7518857717514038, 0.7532327771186829, 0.7699353694915771, 0.7535021305084229, 0.7650862336158752, 0.7696659564971924, 0.7699353694915771, 0.7842133641242981, 0.7823275923728943, 0.7917564511299133, 0.7936422228813171, 0.790409505367279, 0.7912176847457886, 0.7898706793785095, 0.806034505367279, 0.8052262663841248, 0.795258641242981, 0.8114224076271057, 0.8095366358757019, 0.8025323152542114, 0.7925646305084229, 0.8154633641242981, 0.8168103694915771, 0.8224676847457886, 0.8246228694915771, 0.8286637663841248, 0.8302801847457886, 0.8300107717514038, 0.8160021305084229, 0.8270474076271057, 0.8367456793785095, 0.8251616358757019, 0.8324353694915771, 0.8359375, 0.8391702771186829, 0.8426724076271057, 0.849946141242981, 0.8477909564971924, 0.8547952771186829, 0.8515625, 0.8628771305084229, 0.865840494632721, 0.8612607717514038, 0.8653017282485962, 0.8653017282485962, 0.865840494632721, 0.8739224076271057, 0.8741918206214905, 0.875, 0.8790409564971924, 0.8803879022598267, 0.8550646305084229, 0.8871228694915771, 0.8884698152542114, 0.8833512663841248, 0.8871228694915771, 0.8908944129943848, 0.8938577771186829, 0.8865840435028076, 0.8962823152542114, 0.8941271305084229, 0.8973599076271057, 0.8981680870056152, 0.9014008641242981, 0.9051724076271057, 0.9040948152542114, 0.9100215435028076, 0.9067887663841248, 0.9086745977401733, 0.9186422228813171, 0.9146012663841248, 0.9167564511299133, 0.9132543206214905, 0.9148706793785095, 0.9229525923728943, 0.9240301847457886, 0.9251077771186829, 0.9272629022598267, 0.9240301847457886, 0.9323814511299133, 0.9251077771186829, 0.9073275923728943, 0.939116358757019, 0.9353448152542114, 0.9418103694915771, 0.9447737336158752, 0.9428879022598267, 0.9412715435028076, 0.9393857717514038, 0.9418103694915771, 0.9428879022598267, 0.9418103694915771, 0.9423491358757019, 0.9533944129943848, 0.9568965435028076, 0.9585129022598267, 0.9539331793785095, 0.9555495977401733], 'val_loss': [1.177198886871338, 1.1729880571365356, 1.168560266494751, 1.164604663848877, 1.1595536470413208, 1.1547549962997437, 1.1490551233291626, 1.1440718173980713, 1.1384706497192383, 1.1320693492889404, 1.1259673833847046, 1.1190595626831055, 1.1127105951309204, 1.1058681011199951, 1.0982855558395386, 1.091507911682129, 1.0844825506210327, 1.0790451765060425, 1.074710726737976, 1.0673282146453857, 1.0666453838348389, 1.0627713203430176, 1.0787066221237183, 1.0589513778686523, 1.0884270668029785, 1.0721864700317383, 1.0730584859848022, 1.0727213621139526, 1.0702848434448242, 1.0691900253295898, 1.0790616273880005, 1.0832703113555908, 1.0703266859054565, 1.077022910118103, 1.0692821741104126, 1.0691508054733276, 1.0709220170974731, 1.0725091695785522, 1.0735865831375122, 1.0866206884384155, 1.0738188028335571, 1.0745611190795898, 1.0867451429367065, 1.0802597999572754, 1.0817875862121582, 1.081446647644043, 1.0988521575927734, 1.0913443565368652, 1.0863193273544312, 1.0980374813079834, 1.1253304481506348, 1.0909684896469116, 1.1036278009414673, 1.0895007848739624, 1.0970786809921265, 1.0927436351776123, 1.1005767583847046, 1.0977596044540405, 1.0991003513336182, 1.1149100065231323, 1.1061100959777832, 1.1079767942428589, 1.1567580699920654, 1.116347312927246, 1.1135623455047607, 1.1130812168121338, 1.1131086349487305, 1.1189312934875488, 1.11934494972229, 1.1256624460220337, 1.1487557888031006, 1.1328225135803223, 1.1352051496505737, 1.1594254970550537, 1.1405998468399048, 1.1458933353424072, 1.1403424739837646, 1.150383710861206, 1.17863929271698, 1.155205488204956, 1.1590826511383057, 1.1581933498382568, 1.1558451652526855, 1.161921501159668, 1.1753017902374268, 1.1743519306182861, 1.1768176555633545, 1.180281639099121, 1.1847401857376099, 1.1897145509719849, 1.2006629705429077, 1.2074521780014038, 1.252657175064087, 1.2102054357528687, 1.221998929977417, 1.2131619453430176, 1.2319854497909546, 1.2391064167022705, 1.2177799940109253, 1.2773635387420654], 'val_accuracy': [0.5851293206214905, 0.5668103694915771, 0.5808189511299133, 0.5668103694915771, 0.5786637663841248, 0.579741358757019, 0.6023706793785095, 0.5926724076271057, 0.6056034564971924, 0.6206896305084229, 0.618534505367279, 0.6433189511299133, 0.6228448152542114, 0.6400862336158752, 0.670258641242981, 0.6519396305084229, 0.6530172228813171, 0.642241358757019, 0.6476293206214905, 0.6594827771186829, 0.6443965435028076, 0.6454741358757019, 0.6260775923728943, 0.6508620977401733, 0.6206896305084229, 0.6443965435028076, 0.642241358757019, 0.6433189511299133, 0.6465517282485962, 0.6411637663841248, 0.6454741358757019, 0.6454741358757019, 0.6411637663841248, 0.642241358757019, 0.6551724076271057, 0.6540948152542114, 0.6465517282485962, 0.6346982717514038, 0.6443965435028076, 0.6476293206214905, 0.642241358757019, 0.642241358757019, 0.6411637663841248, 0.6325430870056152, 0.6454741358757019, 0.6433189511299133, 0.6411637663841248, 0.6400862336158752, 0.6411637663841248, 0.6400862336158752, 0.6282327771186829, 0.6271551847457886, 0.6443965435028076, 0.639008641242981, 0.6325430870056152, 0.6454741358757019, 0.6357758641242981, 0.6400862336158752, 0.6357758641242981, 0.6325430870056152, 0.6336206793785095, 0.6346982717514038, 0.6293103694915771, 0.6303879022598267, 0.6368534564971924, 0.6400862336158752, 0.649784505367279, 0.6379310488700867, 0.6368534564971924, 0.639008641242981, 0.6271551847457886, 0.6325430870056152, 0.6336206793785095, 0.631465494632721, 0.6379310488700867, 0.6303879022598267, 0.631465494632721, 0.6465517282485962, 0.631465494632721, 0.6454741358757019, 0.6357758641242981, 0.6368534564971924, 0.6336206793785095, 0.6357758641242981, 0.6325430870056152, 0.6357758641242981, 0.6303879022598267, 0.6346982717514038, 0.6411637663841248, 0.6282327771186829, 0.6282327771186829, 0.6336206793785095, 0.6239224076271057, 0.631465494632721, 0.6346982717514038, 0.6325430870056152, 0.6228448152542114, 0.6271551847457886, 0.6400862336158752, 0.618534505367279]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 33ms/step - loss: 1.0383 - accuracy: 0.7264 - val_loss: 1.1780 - val_accuracy: 0.5441\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.9880 - accuracy: 0.7812"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 1s 21ms/step - loss: 1.0182 - accuracy: 0.7450 - val_loss: 1.1737 - val_accuracy: 0.5452\n","Epoch 3/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0091 - accuracy: 0.7470 - val_loss: 1.1692 - val_accuracy: 0.5486\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.0002 - accuracy: 0.7541 - val_loss: 1.1640 - val_accuracy: 0.5713\n","Epoch 5/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9961 - accuracy: 0.7547 - val_loss: 1.1597 - val_accuracy: 0.5633\n","Epoch 6/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9832 - accuracy: 0.7569 - val_loss: 1.1559 - val_accuracy: 0.5577\n","Epoch 7/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9771 - accuracy: 0.7598 - val_loss: 1.1488 - val_accuracy: 0.5860\n","Epoch 8/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9676 - accuracy: 0.7643 - val_loss: 1.1424 - val_accuracy: 0.6301\n","Epoch 9/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.9680 - accuracy: 0.7657 - val_loss: 1.1362 - val_accuracy: 0.6482\n","Epoch 10/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9581 - accuracy: 0.7702 - val_loss: 1.1318 - val_accuracy: 0.6210\n","Epoch 11/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.9509 - accuracy: 0.7711 - val_loss: 1.1248 - val_accuracy: 0.6459\n","Epoch 12/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9431 - accuracy: 0.7801 - val_loss: 1.1204 - val_accuracy: 0.6029\n","Epoch 13/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.9393 - accuracy: 0.7807 - val_loss: 1.1098 - val_accuracy: 0.6753\n","Epoch 14/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9317 - accuracy: 0.7804 - val_loss: 1.1062 - val_accuracy: 0.6278\n","Epoch 15/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9268 - accuracy: 0.7779 - val_loss: 1.0966 - val_accuracy: 0.6505\n","Epoch 16/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9208 - accuracy: 0.7866 - val_loss: 1.0869 - val_accuracy: 0.6731\n","Epoch 17/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9174 - accuracy: 0.7810 - val_loss: 1.0847 - val_accuracy: 0.6437\n","Epoch 18/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9065 - accuracy: 0.7965 - val_loss: 1.0716 - val_accuracy: 0.6810\n","Epoch 19/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9077 - accuracy: 0.7906 - val_loss: 1.0672 - val_accuracy: 0.6731\n","Epoch 20/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8957 - accuracy: 0.8014 - val_loss: 1.0579 - val_accuracy: 0.6765\n","Epoch 21/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8894 - accuracy: 0.8025 - val_loss: 1.0539 - val_accuracy: 0.6753\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8825 - accuracy: 0.8107 - val_loss: 1.0511 - val_accuracy: 0.6810\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8787 - accuracy: 0.8067 - val_loss: 1.0448 - val_accuracy: 0.6742\n","Epoch 24/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8714 - accuracy: 0.8124 - val_loss: 1.0435 - val_accuracy: 0.6821\n","Epoch 25/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8668 - accuracy: 0.8169 - val_loss: 1.0433 - val_accuracy: 0.6765\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8612 - accuracy: 0.8175 - val_loss: 1.0419 - val_accuracy: 0.6719\n","Epoch 27/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8637 - accuracy: 0.8118 - val_loss: 1.0497 - val_accuracy: 0.6719\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8582 - accuracy: 0.8110 - val_loss: 1.0478 - val_accuracy: 0.6765\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8422 - accuracy: 0.8282 - val_loss: 1.0477 - val_accuracy: 0.6765\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8384 - accuracy: 0.8260 - val_loss: 1.0456 - val_accuracy: 0.6776\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8368 - accuracy: 0.8322 - val_loss: 1.0642 - val_accuracy: 0.6629\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8377 - accuracy: 0.8169 - val_loss: 1.0578 - val_accuracy: 0.6708\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8262 - accuracy: 0.8331 - val_loss: 1.0543 - val_accuracy: 0.6753\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8211 - accuracy: 0.8277 - val_loss: 1.0484 - val_accuracy: 0.6799\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8125 - accuracy: 0.8379 - val_loss: 1.0476 - val_accuracy: 0.6776\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8059 - accuracy: 0.8410 - val_loss: 1.0474 - val_accuracy: 0.6810\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8030 - accuracy: 0.8463 - val_loss: 1.0595 - val_accuracy: 0.6742\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8080 - accuracy: 0.8285 - val_loss: 1.0491 - val_accuracy: 0.6708\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7949 - accuracy: 0.8379 - val_loss: 1.0508 - val_accuracy: 0.6810\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7871 - accuracy: 0.8509 - val_loss: 1.0515 - val_accuracy: 0.6753\n","Epoch 41/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7860 - accuracy: 0.8489 - val_loss: 1.0526 - val_accuracy: 0.6697\n","Epoch 42/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7770 - accuracy: 0.8591 - val_loss: 1.0576 - val_accuracy: 0.6719\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7717 - accuracy: 0.8582 - val_loss: 1.0577 - val_accuracy: 0.6776\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7660 - accuracy: 0.8596 - val_loss: 1.0687 - val_accuracy: 0.6674\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7663 - accuracy: 0.8591 - val_loss: 1.0584 - val_accuracy: 0.6686\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7597 - accuracy: 0.8557 - val_loss: 1.0567 - val_accuracy: 0.6753\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7534 - accuracy: 0.8650 - val_loss: 1.0635 - val_accuracy: 0.6742\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7460 - accuracy: 0.8710 - val_loss: 1.0588 - val_accuracy: 0.6686\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7478 - accuracy: 0.8628 - val_loss: 1.0612 - val_accuracy: 0.6719\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7547 - accuracy: 0.8458 - val_loss: 1.0659 - val_accuracy: 0.6776\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7354 - accuracy: 0.8763 - val_loss: 1.0989 - val_accuracy: 0.6527\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7429 - accuracy: 0.8613 - val_loss: 1.1172 - val_accuracy: 0.6357\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7334 - accuracy: 0.8650 - val_loss: 1.0730 - val_accuracy: 0.6618\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7285 - accuracy: 0.8707 - val_loss: 1.0685 - val_accuracy: 0.6640\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7156 - accuracy: 0.8817 - val_loss: 1.0723 - val_accuracy: 0.6663\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7108 - accuracy: 0.8843 - val_loss: 1.0703 - val_accuracy: 0.6652\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7054 - accuracy: 0.8837 - val_loss: 1.0743 - val_accuracy: 0.6674\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7036 - accuracy: 0.8862 - val_loss: 1.0747 - val_accuracy: 0.6686\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7014 - accuracy: 0.8843 - val_loss: 1.0760 - val_accuracy: 0.6663\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6917 - accuracy: 0.8945 - val_loss: 1.0856 - val_accuracy: 0.6584\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6896 - accuracy: 0.8902 - val_loss: 1.0800 - val_accuracy: 0.6686\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6820 - accuracy: 0.8998 - val_loss: 1.0835 - val_accuracy: 0.6606\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6774 - accuracy: 0.8990 - val_loss: 1.0841 - val_accuracy: 0.6697\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6761 - accuracy: 0.8987 - val_loss: 1.0853 - val_accuracy: 0.6663\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6690 - accuracy: 0.9052 - val_loss: 1.0924 - val_accuracy: 0.6708\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6695 - accuracy: 0.8919 - val_loss: 1.0885 - val_accuracy: 0.6708\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6627 - accuracy: 0.9049 - val_loss: 1.1174 - val_accuracy: 0.6403\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6671 - accuracy: 0.8962 - val_loss: 1.1117 - val_accuracy: 0.6538\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6558 - accuracy: 0.9100 - val_loss: 1.1322 - val_accuracy: 0.6414\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6500 - accuracy: 0.9066 - val_loss: 1.1011 - val_accuracy: 0.6595\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6430 - accuracy: 0.9137 - val_loss: 1.1011 - val_accuracy: 0.6753\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6433 - accuracy: 0.9143 - val_loss: 1.1066 - val_accuracy: 0.6606\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6348 - accuracy: 0.9182 - val_loss: 1.1081 - val_accuracy: 0.6629\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6328 - accuracy: 0.9123 - val_loss: 1.1308 - val_accuracy: 0.6425\n","Epoch 75/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6265 - accuracy: 0.9213 - val_loss: 1.1109 - val_accuracy: 0.6640\n","Epoch 76/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6203 - accuracy: 0.9236 - val_loss: 1.1146 - val_accuracy: 0.6618\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6233 - accuracy: 0.9188 - val_loss: 1.1778 - val_accuracy: 0.6301\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6281 - accuracy: 0.9066 - val_loss: 1.1216 - val_accuracy: 0.6629\n","Epoch 79/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6155 - accuracy: 0.9256 - val_loss: 1.1231 - val_accuracy: 0.6686\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6108 - accuracy: 0.9281 - val_loss: 1.1326 - val_accuracy: 0.6493\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6023 - accuracy: 0.9298 - val_loss: 1.1295 - val_accuracy: 0.6538\n","Epoch 82/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5972 - accuracy: 0.9329 - val_loss: 1.1302 - val_accuracy: 0.6708\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5958 - accuracy: 0.9327 - val_loss: 1.1305 - val_accuracy: 0.6686\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5925 - accuracy: 0.9329 - val_loss: 1.1304 - val_accuracy: 0.6708\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5843 - accuracy: 0.9392 - val_loss: 1.1473 - val_accuracy: 0.6697\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5831 - accuracy: 0.9400 - val_loss: 1.1452 - val_accuracy: 0.6640\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5822 - accuracy: 0.9358 - val_loss: 1.1475 - val_accuracy: 0.6595\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5780 - accuracy: 0.9394 - val_loss: 1.1495 - val_accuracy: 0.6652\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5761 - accuracy: 0.9403 - val_loss: 1.1821 - val_accuracy: 0.6301\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5765 - accuracy: 0.9360 - val_loss: 1.1534 - val_accuracy: 0.6719\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5699 - accuracy: 0.9414 - val_loss: 1.1531 - val_accuracy: 0.6686\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5606 - accuracy: 0.9505 - val_loss: 1.1660 - val_accuracy: 0.6550\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5598 - accuracy: 0.9457 - val_loss: 1.1615 - val_accuracy: 0.6618\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5503 - accuracy: 0.9539 - val_loss: 1.2023 - val_accuracy: 0.6403\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5612 - accuracy: 0.9394 - val_loss: 1.1781 - val_accuracy: 0.6697\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5478 - accuracy: 0.9496 - val_loss: 1.1729 - val_accuracy: 0.6731\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5425 - accuracy: 0.9553 - val_loss: 1.1741 - val_accuracy: 0.6595\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5367 - accuracy: 0.9590 - val_loss: 1.1825 - val_accuracy: 0.6595\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5361 - accuracy: 0.9567 - val_loss: 1.2192 - val_accuracy: 0.6414\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5392 - accuracy: 0.9502 - val_loss: 1.1847 - val_accuracy: 0.6719\n","{'loss': [1.0382596254348755, 1.0181562900543213, 1.0091239213943481, 1.0001765489578247, 0.9961362481117249, 0.9831898808479309, 0.9770662784576416, 0.9675843715667725, 0.9680270552635193, 0.9580797553062439, 0.9508935213088989, 0.9430567026138306, 0.9392949938774109, 0.9317249059677124, 0.9267812371253967, 0.9208041429519653, 0.9174240827560425, 0.9064639806747437, 0.9077162742614746, 0.8957424163818359, 0.8894480466842651, 0.8824532628059387, 0.8786958456039429, 0.8713778853416443, 0.8668084144592285, 0.8612333536148071, 0.8637405037879944, 0.8582294583320618, 0.842240035533905, 0.8384256958961487, 0.8368208408355713, 0.8377271294593811, 0.8262379765510559, 0.8211065530776978, 0.8124508261680603, 0.8059008717536926, 0.8029654622077942, 0.8079832196235657, 0.7949278354644775, 0.7870984077453613, 0.78600013256073, 0.776965320110321, 0.7717418670654297, 0.7659861445426941, 0.7662866711616516, 0.759708821773529, 0.7534200549125671, 0.7460041642189026, 0.7478064894676208, 0.754662036895752, 0.735390305519104, 0.7429431080818176, 0.7333561182022095, 0.7284688949584961, 0.715595543384552, 0.7108238339424133, 0.7054312825202942, 0.7035818696022034, 0.7013706564903259, 0.6916502118110657, 0.6895503401756287, 0.681986391544342, 0.6774129867553711, 0.6761496663093567, 0.6690090298652649, 0.6694872975349426, 0.6627355217933655, 0.6670563817024231, 0.655805766582489, 0.6500422358512878, 0.6429760456085205, 0.6433479189872742, 0.6348421573638916, 0.6327829360961914, 0.6265126466751099, 0.6203429102897644, 0.6233312487602234, 0.6281339526176453, 0.6154794096946716, 0.6108012795448303, 0.6023045778274536, 0.5972462296485901, 0.5958061218261719, 0.592459499835968, 0.5843313932418823, 0.5830684900283813, 0.5822069048881531, 0.5780011415481567, 0.5761052370071411, 0.5765107274055481, 0.5698528289794922, 0.5606095790863037, 0.5597729682922363, 0.5503220558166504, 0.5611898899078369, 0.54776930809021, 0.5424976348876953, 0.5367270708084106, 0.5361028909683228, 0.5391594171524048], 'accuracy': [0.7263723611831665, 0.7450481057167053, 0.7470288872718811, 0.7541030049324036, 0.7546689510345459, 0.7569326758384705, 0.7597622871398926, 0.7642897367477417, 0.7657045722007751, 0.7702320218086243, 0.7710809111595154, 0.7801358103752136, 0.780701756477356, 0.7804188132286072, 0.7778720855712891, 0.7866440415382385, 0.7809846997261047, 0.7965478301048279, 0.7906055450439453, 0.8013582229614258, 0.8024901151657104, 0.8106960654258728, 0.806734561920166, 0.8123939037322998, 0.8169213533401489, 0.8174872398376465, 0.8118279576301575, 0.8109790682792664, 0.8282399773597717, 0.8259762525558472, 0.8322014808654785, 0.8169213533401489, 0.8330503702163696, 0.8276740312576294, 0.8378607630729675, 0.8409733772277832, 0.8463497161865234, 0.8285229206085205, 0.8378607630729675, 0.8508771657943726, 0.8488964438438416, 0.8590831756591797, 0.8582342863082886, 0.859649121761322, 0.8590831756591797, 0.8556876182556152, 0.8650254607200623, 0.8709677457809448, 0.8627617359161377, 0.8457838296890259, 0.8763440847396851, 0.8613469004631042, 0.8650254607200623, 0.870684802532196, 0.8817204236984253, 0.8842670917510986, 0.8837012052536011, 0.8862478733062744, 0.8842670917510986, 0.8944538831710815, 0.8902093768119812, 0.8998302221298218, 0.8989813327789307, 0.8986983299255371, 0.905206561088562, 0.8919072151184082, 0.9049236178398132, 0.8961516618728638, 0.9100169539451599, 0.9066213965415955, 0.9136955142021179, 0.9142614603042603, 0.918222963809967, 0.9122806787490845, 0.9213355779647827, 0.9235993027687073, 0.9187889099121094, 0.9066213965415955, 0.9255800843238831, 0.9281267523765564, 0.9298245906829834, 0.9329372048377991, 0.9326542019844055, 0.9329372048377991, 0.9391624331474304, 0.9400113224983215, 0.9357668161392212, 0.9394453763961792, 0.9402942657470703, 0.9360498189926147, 0.941426157951355, 0.9504810571670532, 0.9456706047058105, 0.9538766145706177, 0.9394453763961792, 0.9496321678161621, 0.9552914500236511, 0.9589700102806091, 0.9567062854766846, 0.9501980543136597], 'val_loss': [1.1779810190200806, 1.1736953258514404, 1.1692405939102173, 1.1640033721923828, 1.1596767902374268, 1.1558665037155151, 1.1487669944763184, 1.142443299293518, 1.1361968517303467, 1.1318109035491943, 1.1247649192810059, 1.120391845703125, 1.1097825765609741, 1.1061793565750122, 1.0965895652770996, 1.0868909358978271, 1.0847055912017822, 1.0715569257736206, 1.0672236680984497, 1.057931661605835, 1.053874135017395, 1.0510964393615723, 1.0448483228683472, 1.0434980392456055, 1.0432894229888916, 1.0419135093688965, 1.0496994256973267, 1.0477945804595947, 1.0477278232574463, 1.045559287071228, 1.0641725063323975, 1.0577975511550903, 1.0543246269226074, 1.0483653545379639, 1.047559380531311, 1.047410488128662, 1.0594877004623413, 1.0490765571594238, 1.0508261919021606, 1.0514585971832275, 1.0526336431503296, 1.0576322078704834, 1.057727336883545, 1.0687161684036255, 1.058392882347107, 1.056732416152954, 1.063521146774292, 1.0588146448135376, 1.0611732006072998, 1.0659259557724, 1.0988978147506714, 1.11716890335083, 1.0729821920394897, 1.0685471296310425, 1.0722801685333252, 1.0703256130218506, 1.074285864830017, 1.0746744871139526, 1.0760270357131958, 1.0856257677078247, 1.0799758434295654, 1.0834993124008179, 1.084094524383545, 1.0852771997451782, 1.0923781394958496, 1.088461995124817, 1.1173547506332397, 1.1117408275604248, 1.1321815252304077, 1.1010817289352417, 1.1011290550231934, 1.1066380739212036, 1.1080878973007202, 1.130772352218628, 1.1108559370040894, 1.1145838499069214, 1.177757978439331, 1.121603012084961, 1.12313973903656, 1.1326078176498413, 1.1295130252838135, 1.1301649808883667, 1.130497694015503, 1.1304351091384888, 1.1473034620285034, 1.1451541185379028, 1.147458791732788, 1.1495476961135864, 1.182090401649475, 1.1533677577972412, 1.1531178951263428, 1.1660377979278564, 1.1614651679992676, 1.2023060321807861, 1.1780545711517334, 1.1729159355163574, 1.1741288900375366, 1.1824977397918701, 1.219191312789917, 1.1847327947616577], 'val_accuracy': [0.5441176295280457, 0.5452488660812378, 0.5486425161361694, 0.5712669491767883, 0.5633484125137329, 0.557692289352417, 0.5859728455543518, 0.6300904750823975, 0.6481900215148926, 0.6210407018661499, 0.6459276080131531, 0.6029411554336548, 0.6753393411636353, 0.627828061580658, 0.6504524946212769, 0.6730769276618958, 0.6436651349067688, 0.6809954643249512, 0.6730769276618958, 0.6764705777168274, 0.6753393411636353, 0.6809954643249512, 0.6742081642150879, 0.6821267008781433, 0.6764705777168274, 0.6719456911087036, 0.6719456911087036, 0.6764705777168274, 0.6764705777168274, 0.6776018142700195, 0.662895917892456, 0.6708144545555115, 0.6753393411636353, 0.679864227771759, 0.6776018142700195, 0.6809954643249512, 0.6742081642150879, 0.6708144545555115, 0.6809954643249512, 0.6753393411636353, 0.6696832776069641, 0.6719456911087036, 0.6776018142700195, 0.6674208045005798, 0.668552041053772, 0.6753393411636353, 0.6742081642150879, 0.668552041053772, 0.6719456911087036, 0.6776018142700195, 0.6527149081230164, 0.6357465982437134, 0.6617646813392639, 0.6640271544456482, 0.6662895679473877, 0.6651583909988403, 0.6674208045005798, 0.668552041053772, 0.6662895679473877, 0.6583710312843323, 0.668552041053772, 0.6606335043907166, 0.6696832776069641, 0.6662895679473877, 0.6708144545555115, 0.6708144545555115, 0.6402714848518372, 0.6538461446762085, 0.6414027214050293, 0.6595022678375244, 0.6753393411636353, 0.6606335043907166, 0.662895917892456, 0.6425339579582214, 0.6640271544456482, 0.6617646813392639, 0.6300904750823975, 0.662895917892456, 0.668552041053772, 0.6493212580680847, 0.6538461446762085, 0.6708144545555115, 0.668552041053772, 0.6708144545555115, 0.6696832776069641, 0.6640271544456482, 0.6595022678375244, 0.6651583909988403, 0.6300904750823975, 0.6719456911087036, 0.668552041053772, 0.6549773812294006, 0.6617646813392639, 0.6402714848518372, 0.6696832776069641, 0.6730769276618958, 0.6595022678375244, 0.6595022678375244, 0.6414027214050293, 0.6719456911087036]}\n","45/45 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 30ms/step - loss: 1.0340 - accuracy: 0.7284 - val_loss: 1.1783 - val_accuracy: 0.5475\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 1.0212 - accuracy: 0.7344"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 19ms/step - loss: 1.0171 - accuracy: 0.7424 - val_loss: 1.1739 - val_accuracy: 0.5496\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0071 - accuracy: 0.7486 - val_loss: 1.1692 - val_accuracy: 0.5702\n","Epoch 4/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0015 - accuracy: 0.7468 - val_loss: 1.1645 - val_accuracy: 0.5868\n","Epoch 5/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9927 - accuracy: 0.7537 - val_loss: 1.1600 - val_accuracy: 0.5692\n","Epoch 6/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9825 - accuracy: 0.7610 - val_loss: 1.1552 - val_accuracy: 0.5909\n","Epoch 7/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9701 - accuracy: 0.7705 - val_loss: 1.1505 - val_accuracy: 0.5909\n","Epoch 8/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9637 - accuracy: 0.7778 - val_loss: 1.1453 - val_accuracy: 0.5961\n","Epoch 9/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9589 - accuracy: 0.7669 - val_loss: 1.1407 - val_accuracy: 0.5878\n","Epoch 10/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9502 - accuracy: 0.7824 - val_loss: 1.1346 - val_accuracy: 0.6012\n","Epoch 11/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9425 - accuracy: 0.7884 - val_loss: 1.1315 - val_accuracy: 0.5981\n","Epoch 12/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.9373 - accuracy: 0.7873 - val_loss: 1.1244 - val_accuracy: 0.6085\n","Epoch 13/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9313 - accuracy: 0.7855 - val_loss: 1.1187 - val_accuracy: 0.6147\n","Epoch 14/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9319 - accuracy: 0.7817 - val_loss: 1.1156 - val_accuracy: 0.6012\n","Epoch 15/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9223 - accuracy: 0.7876 - val_loss: 1.1092 - val_accuracy: 0.6178\n","Epoch 16/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9212 - accuracy: 0.7788 - val_loss: 1.1057 - val_accuracy: 0.6054\n","Epoch 17/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9060 - accuracy: 0.7987 - val_loss: 1.1030 - val_accuracy: 0.6209\n","Epoch 18/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8994 - accuracy: 0.8057 - val_loss: 1.1014 - val_accuracy: 0.6043\n","Epoch 19/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8967 - accuracy: 0.7925 - val_loss: 1.1045 - val_accuracy: 0.6043\n","Epoch 20/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8909 - accuracy: 0.8075 - val_loss: 1.1011 - val_accuracy: 0.6219\n","Epoch 21/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8839 - accuracy: 0.8093 - val_loss: 1.1148 - val_accuracy: 0.5857\n","Epoch 22/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8787 - accuracy: 0.8096 - val_loss: 1.1077 - val_accuracy: 0.6229\n","Epoch 23/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8690 - accuracy: 0.8214 - val_loss: 1.1122 - val_accuracy: 0.6198\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8688 - accuracy: 0.8111 - val_loss: 1.1174 - val_accuracy: 0.6116\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8618 - accuracy: 0.8176 - val_loss: 1.1188 - val_accuracy: 0.6136\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8541 - accuracy: 0.8160 - val_loss: 1.1289 - val_accuracy: 0.6074\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8496 - accuracy: 0.8196 - val_loss: 1.1572 - val_accuracy: 0.5733\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8484 - accuracy: 0.8194 - val_loss: 1.1452 - val_accuracy: 0.6023\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8526 - accuracy: 0.8150 - val_loss: 1.1391 - val_accuracy: 0.6126\n","Epoch 30/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8383 - accuracy: 0.8240 - val_loss: 1.1394 - val_accuracy: 0.6023\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8238 - accuracy: 0.8349 - val_loss: 1.1443 - val_accuracy: 0.5992\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8190 - accuracy: 0.8429 - val_loss: 1.1507 - val_accuracy: 0.5992\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8142 - accuracy: 0.8455 - val_loss: 1.1728 - val_accuracy: 0.5847\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8104 - accuracy: 0.8401 - val_loss: 1.1765 - val_accuracy: 0.5816\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8041 - accuracy: 0.8434 - val_loss: 1.1836 - val_accuracy: 0.5775\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8126 - accuracy: 0.8305 - val_loss: 1.1692 - val_accuracy: 0.5950\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7947 - accuracy: 0.8501 - val_loss: 1.1578 - val_accuracy: 0.5992\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7918 - accuracy: 0.8463 - val_loss: 1.1754 - val_accuracy: 0.5961\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7923 - accuracy: 0.8408 - val_loss: 1.1842 - val_accuracy: 0.5806\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7881 - accuracy: 0.8421 - val_loss: 1.1668 - val_accuracy: 0.5981\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7759 - accuracy: 0.8473 - val_loss: 1.2070 - val_accuracy: 0.5764\n","Epoch 42/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7865 - accuracy: 0.8315 - val_loss: 1.2118 - val_accuracy: 0.5713\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7720 - accuracy: 0.8478 - val_loss: 1.1733 - val_accuracy: 0.5950\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7617 - accuracy: 0.8641 - val_loss: 1.1779 - val_accuracy: 0.5919\n","Epoch 45/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7572 - accuracy: 0.8646 - val_loss: 1.1739 - val_accuracy: 0.6043\n","Epoch 46/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7473 - accuracy: 0.8716 - val_loss: 1.1760 - val_accuracy: 0.6116\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7515 - accuracy: 0.8630 - val_loss: 1.1764 - val_accuracy: 0.6095\n","Epoch 48/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7521 - accuracy: 0.8535 - val_loss: 1.1787 - val_accuracy: 0.6085\n","Epoch 49/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7367 - accuracy: 0.8739 - val_loss: 1.1799 - val_accuracy: 0.6116\n","Epoch 50/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7325 - accuracy: 0.8703 - val_loss: 1.1920 - val_accuracy: 0.5971\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7266 - accuracy: 0.8752 - val_loss: 1.2165 - val_accuracy: 0.5930\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7307 - accuracy: 0.8649 - val_loss: 1.1902 - val_accuracy: 0.6054\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7150 - accuracy: 0.8835 - val_loss: 1.2011 - val_accuracy: 0.5950\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7153 - accuracy: 0.8786 - val_loss: 1.2017 - val_accuracy: 0.6023\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7130 - accuracy: 0.8783 - val_loss: 1.1959 - val_accuracy: 0.6033\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7034 - accuracy: 0.8860 - val_loss: 1.1979 - val_accuracy: 0.6012\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6969 - accuracy: 0.8912 - val_loss: 1.2074 - val_accuracy: 0.6012\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6916 - accuracy: 0.8873 - val_loss: 1.2091 - val_accuracy: 0.6043\n","Epoch 59/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6882 - accuracy: 0.8920 - val_loss: 1.2134 - val_accuracy: 0.6043\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6829 - accuracy: 0.8992 - val_loss: 1.2276 - val_accuracy: 0.5919\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6805 - accuracy: 0.8953 - val_loss: 1.2210 - val_accuracy: 0.5950\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6783 - accuracy: 0.8987 - val_loss: 1.2599 - val_accuracy: 0.5930\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6768 - accuracy: 0.8948 - val_loss: 1.2501 - val_accuracy: 0.5981\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6712 - accuracy: 0.8964 - val_loss: 1.2478 - val_accuracy: 0.5919\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6713 - accuracy: 0.8897 - val_loss: 1.2392 - val_accuracy: 0.6023\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6591 - accuracy: 0.9023 - val_loss: 1.2319 - val_accuracy: 0.6043\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6543 - accuracy: 0.9062 - val_loss: 1.2519 - val_accuracy: 0.5940\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6486 - accuracy: 0.9085 - val_loss: 1.2796 - val_accuracy: 0.5919\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6447 - accuracy: 0.9101 - val_loss: 1.2624 - val_accuracy: 0.5930\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6394 - accuracy: 0.9147 - val_loss: 1.2519 - val_accuracy: 0.5992\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6452 - accuracy: 0.9013 - val_loss: 1.2681 - val_accuracy: 0.5888\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6489 - accuracy: 0.8966 - val_loss: 1.2651 - val_accuracy: 0.6002\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6268 - accuracy: 0.9140 - val_loss: 1.2697 - val_accuracy: 0.5981\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6226 - accuracy: 0.9194 - val_loss: 1.2684 - val_accuracy: 0.6023\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6196 - accuracy: 0.9183 - val_loss: 1.3033 - val_accuracy: 0.5899\n","Epoch 76/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6200 - accuracy: 0.9168 - val_loss: 1.2749 - val_accuracy: 0.6012\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6091 - accuracy: 0.9235 - val_loss: 1.2851 - val_accuracy: 0.5992\n","Epoch 78/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6173 - accuracy: 0.9158 - val_loss: 1.2879 - val_accuracy: 0.6064\n","Epoch 79/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6149 - accuracy: 0.9150 - val_loss: 1.3323 - val_accuracy: 0.5919\n","Epoch 80/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6179 - accuracy: 0.9088 - val_loss: 1.3597 - val_accuracy: 0.5899\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6177 - accuracy: 0.9047 - val_loss: 1.2944 - val_accuracy: 0.6012\n","Epoch 82/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5958 - accuracy: 0.9240 - val_loss: 1.2966 - val_accuracy: 0.5992\n","Epoch 83/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5867 - accuracy: 0.9331 - val_loss: 1.3609 - val_accuracy: 0.5971\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5877 - accuracy: 0.9253 - val_loss: 1.3115 - val_accuracy: 0.5950\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6046 - accuracy: 0.9065 - val_loss: 1.3165 - val_accuracy: 0.6054\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5872 - accuracy: 0.9297 - val_loss: 1.3144 - val_accuracy: 0.6023\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5771 - accuracy: 0.9339 - val_loss: 1.3334 - val_accuracy: 0.5919\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5765 - accuracy: 0.9323 - val_loss: 1.3343 - val_accuracy: 0.5981\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5673 - accuracy: 0.9388 - val_loss: 1.3373 - val_accuracy: 0.5981\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5991 - accuracy: 0.9059 - val_loss: 1.3381 - val_accuracy: 0.5930\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5654 - accuracy: 0.9357 - val_loss: 1.3388 - val_accuracy: 0.6023\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5567 - accuracy: 0.9413 - val_loss: 1.3401 - val_accuracy: 0.5961\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5546 - accuracy: 0.9442 - val_loss: 1.3551 - val_accuracy: 0.5971\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5503 - accuracy: 0.9444 - val_loss: 1.3548 - val_accuracy: 0.5930\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5478 - accuracy: 0.9444 - val_loss: 1.3604 - val_accuracy: 0.5919\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5436 - accuracy: 0.9481 - val_loss: 1.3625 - val_accuracy: 0.5961\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5427 - accuracy: 0.9491 - val_loss: 1.3847 - val_accuracy: 0.5888\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5361 - accuracy: 0.9522 - val_loss: 1.3693 - val_accuracy: 0.6043\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5405 - accuracy: 0.9437 - val_loss: 1.3853 - val_accuracy: 0.5950\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5308 - accuracy: 0.9517 - val_loss: 1.3907 - val_accuracy: 0.5992\n","{'loss': [1.0339947938919067, 1.0170936584472656, 1.007068157196045, 1.0015007257461548, 0.9926664233207703, 0.982471227645874, 0.9701489806175232, 0.9636980891227722, 0.9588615894317627, 0.9502497315406799, 0.9424562454223633, 0.9373332858085632, 0.931328535079956, 0.9318744540214539, 0.9223271608352661, 0.9211630821228027, 0.9059596657752991, 0.8993701338768005, 0.8967247009277344, 0.8908712267875671, 0.8838503360748291, 0.8787437677383423, 0.869032621383667, 0.8688220381736755, 0.8617514371871948, 0.8540688157081604, 0.8496147990226746, 0.8483814597129822, 0.8526321649551392, 0.8383175134658813, 0.8238151669502258, 0.8190168738365173, 0.8142368197441101, 0.8103721141815186, 0.8041228652000427, 0.8126177787780762, 0.7946751117706299, 0.7918472290039062, 0.792304277420044, 0.7880843877792358, 0.7759296298027039, 0.7865201830863953, 0.7719837427139282, 0.7617082595825195, 0.7572087049484253, 0.7472723126411438, 0.7514569759368896, 0.7521349191665649, 0.7366999983787537, 0.7325282096862793, 0.7266415953636169, 0.7307444214820862, 0.715013325214386, 0.7152842879295349, 0.7130176424980164, 0.7034229040145874, 0.696933925151825, 0.6915870308876038, 0.6882199048995972, 0.6828805804252625, 0.6804553270339966, 0.6782719492912292, 0.6767884492874146, 0.6712192296981812, 0.6713144779205322, 0.6590918302536011, 0.6542796492576599, 0.6486395001411438, 0.6447115540504456, 0.6393680572509766, 0.6452156901359558, 0.6489456295967102, 0.6268016695976257, 0.6225531697273254, 0.6195739507675171, 0.620029091835022, 0.6090933680534363, 0.6173462271690369, 0.6148845553398132, 0.617905855178833, 0.6176707148551941, 0.5958245992660522, 0.5867146253585815, 0.5877480506896973, 0.6045584678649902, 0.5871565341949463, 0.5770675539970398, 0.576545238494873, 0.5672653317451477, 0.5990797281265259, 0.565427839756012, 0.5566543936729431, 0.5545522570610046, 0.5503063797950745, 0.547832190990448, 0.5435848236083984, 0.5427247881889343, 0.5360545516014099, 0.5404794216156006, 0.5308058857917786], 'accuracy': [0.7284237742424011, 0.7423772811889648, 0.7485787868499756, 0.7467700242996216, 0.753746747970581, 0.7609819173812866, 0.7705426216125488, 0.7777777910232544, 0.766925036907196, 0.7824289202690125, 0.7883720993995667, 0.7873384952545166, 0.7855297327041626, 0.7816537618637085, 0.7875968813896179, 0.7788113951683044, 0.7987080216407776, 0.8056847453117371, 0.7925064563751221, 0.8074935674667358, 0.8093023300170898, 0.8095607161521912, 0.8214470148086548, 0.8111110925674438, 0.8175710439682007, 0.816020667552948, 0.8196382522583008, 0.8193798661231995, 0.814987063407898, 0.8240309953689575, 0.8348837494850159, 0.8428940773010254, 0.8454780578613281, 0.8400516510009766, 0.843410849571228, 0.8304909467697144, 0.8501291871070862, 0.8462532162666321, 0.8408268690109253, 0.8421188592910767, 0.8472868204116821, 0.8315245509147644, 0.8478035926818848, 0.8640826940536499, 0.8645994663238525, 0.8715762495994568, 0.8630490899085999, 0.8534883856773376, 0.8739017844200134, 0.8702842593193054, 0.8751937747001648, 0.8648578524589539, 0.8834625482559204, 0.8785529732704163, 0.8782945871353149, 0.8860465288162231, 0.8912144899368286, 0.8873385190963745, 0.8919896483421326, 0.8992248177528381, 0.895348846912384, 0.8987079858779907, 0.8948320150375366, 0.8963824510574341, 0.8896640539169312, 0.9023255705833435, 0.9062015414237976, 0.908527135848999, 0.9100775122642517, 0.9147287011146545, 0.9012919664382935, 0.8966408371925354, 0.9139534831047058, 0.9193798303604126, 0.9183462262153625, 0.9167958498001099, 0.923514187335968, 0.9157622456550598, 0.9149870872497559, 0.9087855219841003, 0.9046511650085449, 0.9240310192108154, 0.933074951171875, 0.9253230094909668, 0.9064599275588989, 0.9297157526016235, 0.933850109577179, 0.9322997331619263, 0.9387596845626831, 0.9059431552886963, 0.9356589317321777, 0.9413436651229858, 0.9441860318183899, 0.9444444179534912, 0.9444444179534912, 0.948062002658844, 0.949095606803894, 0.9521963596343994, 0.9436692595481873, 0.9516795873641968], 'val_loss': [1.178344964981079, 1.1738985776901245, 1.1691657304763794, 1.1644949913024902, 1.1600358486175537, 1.155160665512085, 1.1505372524261475, 1.1453050374984741, 1.1406649351119995, 1.134639024734497, 1.1315175294876099, 1.124356746673584, 1.1186612844467163, 1.1156105995178223, 1.1092480421066284, 1.1057127714157104, 1.1030429601669312, 1.1013644933700562, 1.1045137643814087, 1.101056456565857, 1.1148245334625244, 1.1076775789260864, 1.1121612787246704, 1.11739182472229, 1.118821144104004, 1.1288584470748901, 1.1571931838989258, 1.1452137231826782, 1.1390525102615356, 1.13944673538208, 1.1442769765853882, 1.1507441997528076, 1.1727696657180786, 1.176467776298523, 1.1835747957229614, 1.1691553592681885, 1.1578338146209717, 1.175417184829712, 1.1842129230499268, 1.1668133735656738, 1.2069755792617798, 1.2117606401443481, 1.1733384132385254, 1.1779178380966187, 1.1739182472229004, 1.1760162115097046, 1.1763994693756104, 1.1786847114562988, 1.1798888444900513, 1.192041039466858, 1.216483473777771, 1.19020676612854, 1.201145887374878, 1.2016735076904297, 1.1959166526794434, 1.1978766918182373, 1.2073514461517334, 1.2090760469436646, 1.2134122848510742, 1.227596402168274, 1.2210315465927124, 1.2598708868026733, 1.2500975131988525, 1.2478151321411133, 1.2391538619995117, 1.2319155931472778, 1.251943588256836, 1.279588222503662, 1.262414813041687, 1.2519131898880005, 1.2680693864822388, 1.2651249170303345, 1.2696824073791504, 1.2683651447296143, 1.3033274412155151, 1.274895429611206, 1.2850757837295532, 1.2879360914230347, 1.3323090076446533, 1.35965895652771, 1.2943602800369263, 1.2965549230575562, 1.3609294891357422, 1.3115155696868896, 1.3164881467819214, 1.3144248723983765, 1.3334134817123413, 1.334331750869751, 1.3373122215270996, 1.3380796909332275, 1.338775873184204, 1.3401015996932983, 1.3551011085510254, 1.3548051118850708, 1.360421895980835, 1.362509846687317, 1.3846980333328247, 1.3692749738693237, 1.385316252708435, 1.3907084465026855], 'val_accuracy': [0.547520637512207, 0.5495867729187012, 0.5702479481697083, 0.586776852607727, 0.5692148804664612, 0.5909090638160706, 0.5909090638160706, 0.5960744023323059, 0.5878099203109741, 0.6012396812438965, 0.5981404781341553, 0.6084710955619812, 0.6146694421768188, 0.6012396812438965, 0.6177685856819153, 0.60537189245224, 0.6208677887916565, 0.6043388247489929, 0.6043388247489929, 0.6219007968902588, 0.58574378490448, 0.6229338645935059, 0.6198347210884094, 0.6115702390670776, 0.6136363744735718, 0.6074380278587341, 0.5733470916748047, 0.6022727489471436, 0.6126033067703247, 0.6022727489471436, 0.5991735458374023, 0.5991735458374023, 0.5847107172012329, 0.5816115736961365, 0.577479362487793, 0.5950413346290588, 0.5991735458374023, 0.5960744023323059, 0.5805785059928894, 0.5981404781341553, 0.5764462947845459, 0.5712810158729553, 0.5950413346290588, 0.5919421315193176, 0.6043388247489929, 0.6115702390670776, 0.6095041036605835, 0.6084710955619812, 0.6115702390670776, 0.5971074104309082, 0.5929751992225647, 0.60537189245224, 0.5950413346290588, 0.6022727489471436, 0.6033057570457458, 0.6012396812438965, 0.6012396812438965, 0.6043388247489929, 0.6043388247489929, 0.5919421315193176, 0.5950413346290588, 0.5929751992225647, 0.5981404781341553, 0.5919421315193176, 0.6022727489471436, 0.6043388247489929, 0.5940082669258118, 0.5919421315193176, 0.5929751992225647, 0.5991735458374023, 0.5888429880142212, 0.6002066135406494, 0.5981404781341553, 0.6022727489471436, 0.5898760557174683, 0.6012396812438965, 0.5991735458374023, 0.6064049601554871, 0.5919421315193176, 0.5898760557174683, 0.6012396812438965, 0.5991735458374023, 0.5971074104309082, 0.5950413346290588, 0.60537189245224, 0.6022727489471436, 0.5919421315193176, 0.5981404781341553, 0.5981404781341553, 0.5929751992225647, 0.6022727489471436, 0.5960744023323059, 0.5971074104309082, 0.5929751992225647, 0.5919421315193176, 0.5960744023323059, 0.5888429880142212, 0.6043388247489929, 0.5950413346290588, 0.5991735458374023]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 5s 37ms/step - loss: 0.6537 - accuracy: 0.8777 - val_loss: 1.0367 - val_accuracy: 0.6024\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.6070 - accuracy: 0.8906"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 1s 18ms/step - loss: 0.6305 - accuracy: 0.8955 - val_loss: 1.0330 - val_accuracy: 0.6078\n","Epoch 3/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6241 - accuracy: 0.9014 - val_loss: 1.0276 - val_accuracy: 0.6228\n","Epoch 4/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6189 - accuracy: 0.9011 - val_loss: 1.0218 - val_accuracy: 0.6476\n","Epoch 5/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6115 - accuracy: 0.9071 - val_loss: 1.0161 - val_accuracy: 0.6606\n","Epoch 6/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6022 - accuracy: 0.9114 - val_loss: 1.0094 - val_accuracy: 0.6821\n","Epoch 7/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5972 - accuracy: 0.9157 - val_loss: 1.0016 - val_accuracy: 0.6950\n","Epoch 8/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5959 - accuracy: 0.9157 - val_loss: 0.9945 - val_accuracy: 0.6821\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5836 - accuracy: 0.9235 - val_loss: 0.9854 - val_accuracy: 0.6972\n","Epoch 10/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5761 - accuracy: 0.9243 - val_loss: 0.9777 - val_accuracy: 0.6800\n","Epoch 11/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5732 - accuracy: 0.9289 - val_loss: 0.9633 - val_accuracy: 0.7252\n","Epoch 12/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5690 - accuracy: 0.9305 - val_loss: 0.9588 - val_accuracy: 0.6961\n","Epoch 13/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5760 - accuracy: 0.9203 - val_loss: 0.9427 - val_accuracy: 0.7188\n","Epoch 14/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5683 - accuracy: 0.9235 - val_loss: 0.9312 - val_accuracy: 0.7284\n","Epoch 15/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5580 - accuracy: 0.9370 - val_loss: 0.9214 - val_accuracy: 0.7263\n","Epoch 16/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5503 - accuracy: 0.9394 - val_loss: 0.9116 - val_accuracy: 0.7328\n","Epoch 17/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5506 - accuracy: 0.9370 - val_loss: 0.9031 - val_accuracy: 0.7392\n","Epoch 18/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5432 - accuracy: 0.9415 - val_loss: 0.8978 - val_accuracy: 0.7338\n","Epoch 19/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5403 - accuracy: 0.9448 - val_loss: 0.8992 - val_accuracy: 0.7284\n","Epoch 20/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5350 - accuracy: 0.9502 - val_loss: 0.8902 - val_accuracy: 0.7414\n","Epoch 21/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5298 - accuracy: 0.9531 - val_loss: 0.9011 - val_accuracy: 0.7338\n","Epoch 22/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5285 - accuracy: 0.9507 - val_loss: 0.8968 - val_accuracy: 0.7425\n","Epoch 23/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5274 - accuracy: 0.9472 - val_loss: 0.9043 - val_accuracy: 0.7435\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5295 - accuracy: 0.9464 - val_loss: 0.9065 - val_accuracy: 0.7435\n","Epoch 25/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5211 - accuracy: 0.9480 - val_loss: 0.9317 - val_accuracy: 0.7295\n","Epoch 26/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5131 - accuracy: 0.9569 - val_loss: 0.9277 - val_accuracy: 0.7425\n","Epoch 27/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5073 - accuracy: 0.9591 - val_loss: 0.9703 - val_accuracy: 0.7177\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5128 - accuracy: 0.9545 - val_loss: 0.9521 - val_accuracy: 0.7295\n","Epoch 29/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5133 - accuracy: 0.9477 - val_loss: 0.9505 - val_accuracy: 0.7360\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5041 - accuracy: 0.9574 - val_loss: 0.9574 - val_accuracy: 0.7425\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5014 - accuracy: 0.9609 - val_loss: 0.9657 - val_accuracy: 0.7392\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4996 - accuracy: 0.9599 - val_loss: 1.0340 - val_accuracy: 0.7134\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4941 - accuracy: 0.9663 - val_loss: 0.9808 - val_accuracy: 0.7381\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4916 - accuracy: 0.9609 - val_loss: 0.9973 - val_accuracy: 0.7295\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4900 - accuracy: 0.9631 - val_loss: 0.9823 - val_accuracy: 0.7381\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4804 - accuracy: 0.9693 - val_loss: 1.0031 - val_accuracy: 0.7263\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4776 - accuracy: 0.9739 - val_loss: 0.9859 - val_accuracy: 0.7371\n","Epoch 38/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4745 - accuracy: 0.9717 - val_loss: 0.9954 - val_accuracy: 0.7338\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4711 - accuracy: 0.9733 - val_loss: 1.0033 - val_accuracy: 0.7220\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4746 - accuracy: 0.9690 - val_loss: 0.9984 - val_accuracy: 0.7381\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4646 - accuracy: 0.9776 - val_loss: 0.9981 - val_accuracy: 0.7360\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4614 - accuracy: 0.9784 - val_loss: 1.0057 - val_accuracy: 0.7338\n","Epoch 43/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4593 - accuracy: 0.9787 - val_loss: 1.0126 - val_accuracy: 0.7317\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4559 - accuracy: 0.9774 - val_loss: 1.0162 - val_accuracy: 0.7209\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4581 - accuracy: 0.9733 - val_loss: 1.0166 - val_accuracy: 0.7306\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4584 - accuracy: 0.9755 - val_loss: 1.0136 - val_accuracy: 0.7338\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4472 - accuracy: 0.9811 - val_loss: 1.0193 - val_accuracy: 0.7328\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4492 - accuracy: 0.9790 - val_loss: 1.0223 - val_accuracy: 0.7338\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4484 - accuracy: 0.9760 - val_loss: 1.0597 - val_accuracy: 0.7252\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4440 - accuracy: 0.9828 - val_loss: 1.0275 - val_accuracy: 0.7349\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4410 - accuracy: 0.9814 - val_loss: 1.0329 - val_accuracy: 0.7274\n","Epoch 52/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4417 - accuracy: 0.9801 - val_loss: 1.0377 - val_accuracy: 0.7274\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4399 - accuracy: 0.9798 - val_loss: 1.0741 - val_accuracy: 0.7198\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4352 - accuracy: 0.9817 - val_loss: 1.0455 - val_accuracy: 0.7306\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4301 - accuracy: 0.9865 - val_loss: 1.0452 - val_accuracy: 0.7231\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4312 - accuracy: 0.9852 - val_loss: 1.0437 - val_accuracy: 0.7284\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4246 - accuracy: 0.9876 - val_loss: 1.0708 - val_accuracy: 0.7274\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4233 - accuracy: 0.9865 - val_loss: 1.0690 - val_accuracy: 0.7306\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4216 - accuracy: 0.9852 - val_loss: 1.0580 - val_accuracy: 0.7241\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4181 - accuracy: 0.9906 - val_loss: 1.0977 - val_accuracy: 0.7177\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4164 - accuracy: 0.9906 - val_loss: 1.0624 - val_accuracy: 0.7284\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4144 - accuracy: 0.9879 - val_loss: 1.1073 - val_accuracy: 0.7123\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4137 - accuracy: 0.9890 - val_loss: 1.0658 - val_accuracy: 0.7220\n","Epoch 64/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4099 - accuracy: 0.9900 - val_loss: 1.0703 - val_accuracy: 0.7284\n","Epoch 65/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4121 - accuracy: 0.9906 - val_loss: 1.1067 - val_accuracy: 0.7123\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4068 - accuracy: 0.9922 - val_loss: 1.0853 - val_accuracy: 0.7295\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4047 - accuracy: 0.9911 - val_loss: 1.0794 - val_accuracy: 0.7263\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4070 - accuracy: 0.9903 - val_loss: 1.0856 - val_accuracy: 0.7295\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4007 - accuracy: 0.9935 - val_loss: 1.1019 - val_accuracy: 0.7241\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4030 - accuracy: 0.9919 - val_loss: 1.0960 - val_accuracy: 0.7209\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4040 - accuracy: 0.9898 - val_loss: 1.1239 - val_accuracy: 0.7188\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3996 - accuracy: 0.9916 - val_loss: 1.1203 - val_accuracy: 0.7188\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4000 - accuracy: 0.9908 - val_loss: 1.0956 - val_accuracy: 0.7220\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3974 - accuracy: 0.9914 - val_loss: 1.1031 - val_accuracy: 0.7252\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3932 - accuracy: 0.9949 - val_loss: 1.1163 - val_accuracy: 0.7166\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3878 - accuracy: 0.9938 - val_loss: 1.1385 - val_accuracy: 0.7188\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3866 - accuracy: 0.9965 - val_loss: 1.1172 - val_accuracy: 0.7198\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3838 - accuracy: 0.9960 - val_loss: 1.1203 - val_accuracy: 0.7198\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3865 - accuracy: 0.9952 - val_loss: 1.1196 - val_accuracy: 0.7220\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3866 - accuracy: 0.9941 - val_loss: 1.1292 - val_accuracy: 0.7155\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3832 - accuracy: 0.9952 - val_loss: 1.1445 - val_accuracy: 0.7209\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3828 - accuracy: 0.9949 - val_loss: 1.1415 - val_accuracy: 0.7241\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3800 - accuracy: 0.9962 - val_loss: 1.1376 - val_accuracy: 0.7166\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3765 - accuracy: 0.9965 - val_loss: 1.1430 - val_accuracy: 0.7209\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3741 - accuracy: 0.9978 - val_loss: 1.1664 - val_accuracy: 0.7177\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3742 - accuracy: 0.9981 - val_loss: 1.1418 - val_accuracy: 0.7209\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3723 - accuracy: 0.9984 - val_loss: 1.1729 - val_accuracy: 0.7069\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3731 - accuracy: 0.9981 - val_loss: 1.1566 - val_accuracy: 0.7134\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3698 - accuracy: 0.9981 - val_loss: 1.1576 - val_accuracy: 0.7220\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3695 - accuracy: 0.9981 - val_loss: 1.1969 - val_accuracy: 0.7101\n","Epoch 91/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3690 - accuracy: 0.9970 - val_loss: 1.1634 - val_accuracy: 0.7134\n","Epoch 92/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3670 - accuracy: 0.9976 - val_loss: 1.1617 - val_accuracy: 0.7241\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3658 - accuracy: 0.9973 - val_loss: 1.1900 - val_accuracy: 0.7123\n","Epoch 94/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3633 - accuracy: 0.9992 - val_loss: 1.1662 - val_accuracy: 0.7177\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3633 - accuracy: 0.9989 - val_loss: 1.1768 - val_accuracy: 0.7198\n","Epoch 96/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3624 - accuracy: 0.9984 - val_loss: 1.1805 - val_accuracy: 0.7220\n","Epoch 97/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3593 - accuracy: 0.9987 - val_loss: 1.1949 - val_accuracy: 0.7144\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3609 - accuracy: 0.9984 - val_loss: 1.1874 - val_accuracy: 0.7263\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3582 - accuracy: 0.9995 - val_loss: 1.1936 - val_accuracy: 0.7198\n","Epoch 100/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3581 - accuracy: 0.9989 - val_loss: 1.1971 - val_accuracy: 0.7188\n","{'loss': [0.6537120938301086, 0.6304609179496765, 0.6240571141242981, 0.6188585758209229, 0.6114596128463745, 0.6021578311920166, 0.5971711277961731, 0.5958816409111023, 0.583574116230011, 0.5760683417320251, 0.5731889009475708, 0.5689600706100464, 0.575977087020874, 0.5683040022850037, 0.5580037832260132, 0.5502635836601257, 0.5505713820457458, 0.5432426929473877, 0.5403341054916382, 0.5350394248962402, 0.5298110842704773, 0.5285378694534302, 0.5274428725242615, 0.5294756293296814, 0.5210688710212708, 0.5131143927574158, 0.5073260068893433, 0.5127501487731934, 0.5132907629013062, 0.5040522217750549, 0.5014382004737854, 0.4996114671230316, 0.4940585196018219, 0.4916365444660187, 0.4900420010089874, 0.4804227650165558, 0.4776288866996765, 0.47450581192970276, 0.4710503816604614, 0.47463443875312805, 0.4646081030368805, 0.4613843858242035, 0.4592558741569519, 0.455908864736557, 0.45805877447128296, 0.4584048092365265, 0.44720354676246643, 0.4491855800151825, 0.4484485387802124, 0.44397708773612976, 0.44101011753082275, 0.44169488549232483, 0.4399200975894928, 0.435163676738739, 0.43007493019104004, 0.43120047450065613, 0.42460697889328003, 0.42334726452827454, 0.42163941264152527, 0.4180767238140106, 0.4164365231990814, 0.41435706615448, 0.4136982858181, 0.409868061542511, 0.41212198138237, 0.40675580501556396, 0.40468236804008484, 0.4070238769054413, 0.40073421597480774, 0.40303587913513184, 0.4039667248725891, 0.39963245391845703, 0.3999972939491272, 0.3973786532878876, 0.3931832015514374, 0.387808233499527, 0.3866156339645386, 0.3837794065475464, 0.3864929676055908, 0.3865657150745392, 0.383226215839386, 0.3828491270542145, 0.3800433576107025, 0.3764841556549072, 0.37410151958465576, 0.3741767406463623, 0.37225058674812317, 0.37313735485076904, 0.3697814345359802, 0.36954763531684875, 0.36898180842399597, 0.36695894598960876, 0.3658366799354553, 0.36325228214263916, 0.36332663893699646, 0.36241474747657776, 0.3592996895313263, 0.36085087060928345, 0.3582266867160797, 0.3580549955368042], 'accuracy': [0.8776939511299133, 0.8954741358757019, 0.9014008641242981, 0.9011314511299133, 0.9070581793785095, 0.9113685488700867, 0.915678858757019, 0.915678858757019, 0.923491358757019, 0.9242995977401733, 0.9288793206214905, 0.9304956793785095, 0.920258641242981, 0.923491358757019, 0.9369612336158752, 0.9393857717514038, 0.9369612336158752, 0.9415409564971924, 0.9447737336158752, 0.9501616358757019, 0.953125, 0.9507004022598267, 0.9471982717514038, 0.9463900923728943, 0.9480064511299133, 0.9568965435028076, 0.9590517282485962, 0.954472005367279, 0.9477370977401733, 0.9574353694915771, 0.9609375, 0.9598599076271057, 0.9663254022598267, 0.9609375, 0.9630926847457886, 0.9692887663841248, 0.9738685488700867, 0.9717133641242981, 0.9733297228813171, 0.9690194129943848, 0.9776400923728943, 0.9784482717514038, 0.9787176847457886, 0.9773706793785095, 0.9733297228813171, 0.9754849076271057, 0.9811422228813171, 0.9789870977401733, 0.9760237336158752, 0.982758641242981, 0.9814116358757019, 0.9800646305084229, 0.9797952771186829, 0.9816810488700867, 0.9865301847457886, 0.9851831793785095, 0.9876077771186829, 0.9865301847457886, 0.9851831793785095, 0.990571141242981, 0.990571141242981, 0.9878771305084229, 0.9889547228813171, 0.9900323152542114, 0.990571141242981, 0.9921875, 0.9911099076271057, 0.9903017282485962, 0.993534505367279, 0.9919180870056152, 0.9897629022598267, 0.9916487336158752, 0.990840494632721, 0.9913793206214905, 0.9948814511299133, 0.993803858757019, 0.9964978694915771, 0.9959590435028076, 0.9951508641242981, 0.9940732717514038, 0.9951508641242981, 0.9948814511299133, 0.9962284564971924, 0.9964978694915771, 0.9978448152542114, 0.9981142282485962, 0.998383641242981, 0.9981142282485962, 0.9981142282485962, 0.9981142282485962, 0.9970366358757019, 0.9975754022598267, 0.9973060488700867, 0.9991918206214905, 0.9989224076271057, 0.998383641242981, 0.998652994632721, 0.998383641242981, 0.9994612336158752, 0.9989224076271057], 'val_loss': [1.0366525650024414, 1.0330382585525513, 1.0276466608047485, 1.0217926502227783, 1.0161266326904297, 1.0093551874160767, 1.0015506744384766, 0.9944592118263245, 0.9854025840759277, 0.9776995182037354, 0.9632776975631714, 0.9588205218315125, 0.9426988959312439, 0.9312084317207336, 0.9213798642158508, 0.9116027355194092, 0.9031438231468201, 0.8978050947189331, 0.8991751074790955, 0.8902359008789062, 0.901103138923645, 0.8967543244361877, 0.9043304324150085, 0.9064704775810242, 0.9316856265068054, 0.9276719093322754, 0.970288872718811, 0.9521034955978394, 0.9504512548446655, 0.9574267864227295, 0.9656752347946167, 1.0339503288269043, 0.9808199405670166, 0.9973139762878418, 0.9823448061943054, 1.0030556917190552, 0.985885739326477, 0.9953933358192444, 1.003258228302002, 0.9983572363853455, 0.9980579018592834, 1.0057059526443481, 1.0126124620437622, 1.0162433385849, 1.0165770053863525, 1.0136052370071411, 1.0193068981170654, 1.0223499536514282, 1.059700846672058, 1.0274672508239746, 1.0329012870788574, 1.037732720375061, 1.074116587638855, 1.0454635620117188, 1.0451632738113403, 1.04367196559906, 1.0708121061325073, 1.0690467357635498, 1.0579578876495361, 1.097653865814209, 1.0623631477355957, 1.1072903871536255, 1.0658292770385742, 1.0703139305114746, 1.1067463159561157, 1.085281252861023, 1.0794177055358887, 1.0856287479400635, 1.1018530130386353, 1.096004605293274, 1.1239441633224487, 1.1203255653381348, 1.095595359802246, 1.103062629699707, 1.116333246231079, 1.1384800672531128, 1.1171667575836182, 1.120331883430481, 1.1195831298828125, 1.129238247871399, 1.1445246934890747, 1.1415293216705322, 1.1376357078552246, 1.1429537534713745, 1.166386365890503, 1.1418087482452393, 1.1728557348251343, 1.1565911769866943, 1.1576024293899536, 1.1968843936920166, 1.16343355178833, 1.161721110343933, 1.1899809837341309, 1.1662431955337524, 1.1767524480819702, 1.1805399656295776, 1.1948546171188354, 1.1873871088027954, 1.1935597658157349, 1.1971033811569214], 'val_accuracy': [0.6023706793785095, 0.607758641242981, 0.6228448152542114, 0.6476293206214905, 0.6605603694915771, 0.6821120977401733, 0.6950430870056152, 0.6821120977401733, 0.6971982717514038, 0.6799569129943848, 0.725215494632721, 0.6961206793785095, 0.71875, 0.7284482717514038, 0.7262930870056152, 0.732758641242981, 0.7392241358757019, 0.7338362336158752, 0.7284482717514038, 0.7413793206214905, 0.7338362336158752, 0.7424569129943848, 0.743534505367279, 0.743534505367279, 0.7295258641242981, 0.7424569129943848, 0.7176724076271057, 0.7295258641242981, 0.735991358757019, 0.7424569129943848, 0.7392241358757019, 0.7133620977401733, 0.7381465435028076, 0.7295258641242981, 0.7381465435028076, 0.7262930870056152, 0.7370689511299133, 0.7338362336158752, 0.7219827771186829, 0.7381465435028076, 0.735991358757019, 0.7338362336158752, 0.7316810488700867, 0.7209051847457886, 0.7306034564971924, 0.7338362336158752, 0.732758641242981, 0.7338362336158752, 0.725215494632721, 0.7349137663841248, 0.7273706793785095, 0.7273706793785095, 0.7198275923728943, 0.7306034564971924, 0.7230603694915771, 0.7284482717514038, 0.7273706793785095, 0.7306034564971924, 0.7241379022598267, 0.7176724076271057, 0.7284482717514038, 0.712284505367279, 0.7219827771186829, 0.7284482717514038, 0.712284505367279, 0.7295258641242981, 0.7262930870056152, 0.7295258641242981, 0.7241379022598267, 0.7209051847457886, 0.71875, 0.71875, 0.7219827771186829, 0.725215494632721, 0.7165948152542114, 0.71875, 0.7198275923728943, 0.7198275923728943, 0.7219827771186829, 0.7155172228813171, 0.7209051847457886, 0.7241379022598267, 0.7165948152542114, 0.7209051847457886, 0.7176724076271057, 0.7209051847457886, 0.7068965435028076, 0.7133620977401733, 0.7219827771186829, 0.7101293206214905, 0.7133620977401733, 0.7241379022598267, 0.712284505367279, 0.7176724076271057, 0.7198275923728943, 0.7219827771186829, 0.7144396305084229, 0.7262930870056152, 0.7198275923728943, 0.71875]}\n","38/38 [==============================] - 0s 6ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 34ms/step - loss: 0.6654 - accuracy: 0.8729 - val_loss: 1.0355 - val_accuracy: 0.5973\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.6068 - accuracy: 0.8906"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 1s 21ms/step - loss: 0.6337 - accuracy: 0.8947 - val_loss: 1.0316 - val_accuracy: 0.5995\n","Epoch 3/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6295 - accuracy: 0.8896 - val_loss: 1.0257 - val_accuracy: 0.6493\n","Epoch 4/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6202 - accuracy: 0.8984 - val_loss: 1.0204 - val_accuracy: 0.6652\n","Epoch 5/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6120 - accuracy: 0.9075 - val_loss: 1.0134 - val_accuracy: 0.6878\n","Epoch 6/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6055 - accuracy: 0.9080 - val_loss: 1.0068 - val_accuracy: 0.6821\n","Epoch 7/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.5988 - accuracy: 0.9160 - val_loss: 0.9988 - val_accuracy: 0.7161\n","Epoch 8/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6043 - accuracy: 0.9154 - val_loss: 0.9924 - val_accuracy: 0.6731\n","Epoch 9/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5905 - accuracy: 0.9205 - val_loss: 0.9834 - val_accuracy: 0.6787\n","Epoch 10/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5881 - accuracy: 0.9219 - val_loss: 0.9732 - val_accuracy: 0.7025\n","Epoch 11/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5813 - accuracy: 0.9244 - val_loss: 0.9610 - val_accuracy: 0.7149\n","Epoch 12/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5778 - accuracy: 0.9250 - val_loss: 0.9500 - val_accuracy: 0.7251\n","Epoch 13/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5675 - accuracy: 0.9358 - val_loss: 0.9381 - val_accuracy: 0.7330\n","Epoch 14/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5670 - accuracy: 0.9324 - val_loss: 0.9268 - val_accuracy: 0.7308\n","Epoch 15/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5658 - accuracy: 0.9332 - val_loss: 0.9170 - val_accuracy: 0.7330\n","Epoch 16/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5574 - accuracy: 0.9375 - val_loss: 0.9072 - val_accuracy: 0.7353\n","Epoch 17/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5552 - accuracy: 0.9375 - val_loss: 0.8966 - val_accuracy: 0.7421\n","Epoch 18/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5530 - accuracy: 0.9360 - val_loss: 0.8935 - val_accuracy: 0.7466\n","Epoch 19/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5461 - accuracy: 0.9482 - val_loss: 0.8832 - val_accuracy: 0.7364\n","Epoch 20/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5417 - accuracy: 0.9440 - val_loss: 0.8845 - val_accuracy: 0.7455\n","Epoch 21/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5409 - accuracy: 0.9420 - val_loss: 0.8792 - val_accuracy: 0.7545\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5339 - accuracy: 0.9502 - val_loss: 0.8802 - val_accuracy: 0.7398\n","Epoch 23/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5287 - accuracy: 0.9522 - val_loss: 0.8921 - val_accuracy: 0.7455\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5315 - accuracy: 0.9488 - val_loss: 0.8924 - val_accuracy: 0.7500\n","Epoch 25/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5248 - accuracy: 0.9527 - val_loss: 0.9037 - val_accuracy: 0.7534\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5224 - accuracy: 0.9536 - val_loss: 0.9167 - val_accuracy: 0.7262\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5201 - accuracy: 0.9513 - val_loss: 0.9167 - val_accuracy: 0.7489\n","Epoch 28/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5104 - accuracy: 0.9578 - val_loss: 0.9296 - val_accuracy: 0.7613\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5070 - accuracy: 0.9626 - val_loss: 0.9519 - val_accuracy: 0.7489\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5145 - accuracy: 0.9522 - val_loss: 0.9535 - val_accuracy: 0.7489\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5016 - accuracy: 0.9641 - val_loss: 0.9489 - val_accuracy: 0.7353\n","Epoch 32/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4959 - accuracy: 0.9655 - val_loss: 0.9535 - val_accuracy: 0.7398\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4995 - accuracy: 0.9632 - val_loss: 0.9836 - val_accuracy: 0.7240\n","Epoch 34/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4937 - accuracy: 0.9649 - val_loss: 0.9677 - val_accuracy: 0.7466\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4885 - accuracy: 0.9700 - val_loss: 0.9787 - val_accuracy: 0.7330\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4862 - accuracy: 0.9689 - val_loss: 0.9757 - val_accuracy: 0.7387\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4796 - accuracy: 0.9751 - val_loss: 0.9802 - val_accuracy: 0.7319\n","Epoch 38/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4807 - accuracy: 0.9717 - val_loss: 0.9862 - val_accuracy: 0.7364\n","Epoch 39/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4749 - accuracy: 0.9748 - val_loss: 0.9956 - val_accuracy: 0.7319\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4808 - accuracy: 0.9669 - val_loss: 1.0257 - val_accuracy: 0.7410\n","Epoch 41/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4702 - accuracy: 0.9726 - val_loss: 0.9922 - val_accuracy: 0.7511\n","Epoch 42/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4663 - accuracy: 0.9765 - val_loss: 1.0122 - val_accuracy: 0.7319\n","Epoch 43/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4727 - accuracy: 0.9714 - val_loss: 1.0095 - val_accuracy: 0.7410\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4680 - accuracy: 0.9709 - val_loss: 1.0033 - val_accuracy: 0.7296\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4589 - accuracy: 0.9765 - val_loss: 1.0332 - val_accuracy: 0.7511\n","Epoch 46/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4569 - accuracy: 0.9782 - val_loss: 1.0114 - val_accuracy: 0.7319\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4545 - accuracy: 0.9782 - val_loss: 1.0175 - val_accuracy: 0.7443\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4546 - accuracy: 0.9768 - val_loss: 1.0254 - val_accuracy: 0.7342\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4492 - accuracy: 0.9776 - val_loss: 1.0361 - val_accuracy: 0.7240\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4462 - accuracy: 0.9810 - val_loss: 1.0313 - val_accuracy: 0.7296\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4438 - accuracy: 0.9819 - val_loss: 1.0235 - val_accuracy: 0.7319\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4417 - accuracy: 0.9839 - val_loss: 1.0385 - val_accuracy: 0.7387\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4384 - accuracy: 0.9816 - val_loss: 1.0278 - val_accuracy: 0.7364\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4391 - accuracy: 0.9825 - val_loss: 1.0504 - val_accuracy: 0.7274\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4380 - accuracy: 0.9802 - val_loss: 1.0457 - val_accuracy: 0.7308\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4319 - accuracy: 0.9856 - val_loss: 1.0593 - val_accuracy: 0.7251\n","Epoch 57/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4297 - accuracy: 0.9844 - val_loss: 1.0493 - val_accuracy: 0.7376\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4298 - accuracy: 0.9859 - val_loss: 1.0508 - val_accuracy: 0.7398\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4231 - accuracy: 0.9873 - val_loss: 1.0543 - val_accuracy: 0.7319\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4194 - accuracy: 0.9890 - val_loss: 1.0605 - val_accuracy: 0.7262\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4209 - accuracy: 0.9907 - val_loss: 1.0874 - val_accuracy: 0.7251\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4182 - accuracy: 0.9881 - val_loss: 1.0619 - val_accuracy: 0.7330\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4163 - accuracy: 0.9895 - val_loss: 1.0687 - val_accuracy: 0.7296\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4214 - accuracy: 0.9853 - val_loss: 1.0680 - val_accuracy: 0.7342\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4093 - accuracy: 0.9909 - val_loss: 1.0719 - val_accuracy: 0.7319\n","Epoch 66/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4082 - accuracy: 0.9929 - val_loss: 1.1077 - val_accuracy: 0.7251\n","Epoch 67/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4108 - accuracy: 0.9898 - val_loss: 1.0748 - val_accuracy: 0.7376\n","Epoch 68/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4045 - accuracy: 0.9935 - val_loss: 1.0893 - val_accuracy: 0.7364\n","Epoch 69/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4039 - accuracy: 0.9924 - val_loss: 1.0856 - val_accuracy: 0.7251\n","Epoch 70/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4184 - accuracy: 0.9836 - val_loss: 1.1201 - val_accuracy: 0.7387\n","Epoch 71/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4068 - accuracy: 0.9875 - val_loss: 1.0952 - val_accuracy: 0.7319\n","Epoch 72/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4012 - accuracy: 0.9921 - val_loss: 1.1345 - val_accuracy: 0.7172\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4090 - accuracy: 0.9890 - val_loss: 1.1028 - val_accuracy: 0.7285\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3972 - accuracy: 0.9935 - val_loss: 1.1055 - val_accuracy: 0.7319\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3917 - accuracy: 0.9958 - val_loss: 1.1087 - val_accuracy: 0.7240\n","Epoch 76/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3908 - accuracy: 0.9958 - val_loss: 1.1223 - val_accuracy: 0.7229\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3937 - accuracy: 0.9949 - val_loss: 1.1165 - val_accuracy: 0.7262\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3863 - accuracy: 0.9963 - val_loss: 1.1137 - val_accuracy: 0.7319\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3900 - accuracy: 0.9949 - val_loss: 1.1338 - val_accuracy: 0.7262\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3871 - accuracy: 0.9963 - val_loss: 1.1425 - val_accuracy: 0.7296\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3906 - accuracy: 0.9938 - val_loss: 1.1426 - val_accuracy: 0.7330\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3814 - accuracy: 0.9975 - val_loss: 1.1395 - val_accuracy: 0.7251\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3813 - accuracy: 0.9958 - val_loss: 1.1647 - val_accuracy: 0.7251\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3795 - accuracy: 0.9972 - val_loss: 1.1394 - val_accuracy: 0.7285\n","Epoch 85/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3813 - accuracy: 0.9946 - val_loss: 1.1515 - val_accuracy: 0.7330\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3798 - accuracy: 0.9975 - val_loss: 1.1452 - val_accuracy: 0.7274\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3754 - accuracy: 0.9986 - val_loss: 1.1616 - val_accuracy: 0.7330\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3764 - accuracy: 0.9963 - val_loss: 1.2265 - val_accuracy: 0.7081\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3796 - accuracy: 0.9952 - val_loss: 1.1578 - val_accuracy: 0.7296\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3761 - accuracy: 0.9966 - val_loss: 1.1714 - val_accuracy: 0.7296\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3718 - accuracy: 0.9983 - val_loss: 1.1634 - val_accuracy: 0.7240\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3724 - accuracy: 0.9975 - val_loss: 1.1729 - val_accuracy: 0.7296\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3682 - accuracy: 0.9977 - val_loss: 1.1832 - val_accuracy: 0.7319\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3678 - accuracy: 0.9972 - val_loss: 1.1803 - val_accuracy: 0.7308\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3654 - accuracy: 0.9986 - val_loss: 1.1812 - val_accuracy: 0.7251\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3677 - accuracy: 0.9966 - val_loss: 1.1839 - val_accuracy: 0.7274\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3639 - accuracy: 0.9977 - val_loss: 1.1835 - val_accuracy: 0.7353\n","Epoch 98/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3677 - accuracy: 0.9969 - val_loss: 1.1923 - val_accuracy: 0.7296\n","Epoch 99/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3612 - accuracy: 0.9994 - val_loss: 1.1911 - val_accuracy: 0.7285\n","Epoch 100/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3626 - accuracy: 0.9975 - val_loss: 1.2006 - val_accuracy: 0.7296\n","{'loss': [0.6653652787208557, 0.6336686015129089, 0.6294528245925903, 0.6201667189598083, 0.6119599342346191, 0.6055077314376831, 0.5987523198127747, 0.6043370366096497, 0.5904553532600403, 0.5880517363548279, 0.5813232064247131, 0.5778469443321228, 0.5675458312034607, 0.5670422315597534, 0.565797746181488, 0.5574202537536621, 0.5552447438240051, 0.5529741644859314, 0.5461201071739197, 0.5417351126670837, 0.5408678650856018, 0.5339159369468689, 0.5286685824394226, 0.5315061211585999, 0.5248374938964844, 0.5223569273948669, 0.5200707912445068, 0.51043301820755, 0.5069570541381836, 0.51453697681427, 0.5016417503356934, 0.49586984515190125, 0.49948927760124207, 0.49371573328971863, 0.48853880167007446, 0.48624756932258606, 0.4795859456062317, 0.48066452145576477, 0.47488293051719666, 0.48076170682907104, 0.4701782763004303, 0.4663323163986206, 0.4727451205253601, 0.4679509401321411, 0.45890459418296814, 0.45685967803001404, 0.45451417565345764, 0.45459914207458496, 0.44923242926597595, 0.4462330639362335, 0.44375139474868774, 0.44165048003196716, 0.43838056921958923, 0.43905001878738403, 0.4379882514476776, 0.43188852071762085, 0.42974328994750977, 0.42978963255882263, 0.42311564087867737, 0.4193752408027649, 0.4208739399909973, 0.4182263910770416, 0.4162624478340149, 0.4214327931404114, 0.4092584550380707, 0.4081517159938812, 0.4107685685157776, 0.40453410148620605, 0.4038979113101959, 0.41836637258529663, 0.4068427085876465, 0.4011736214160919, 0.40901345014572144, 0.3971639573574066, 0.3917160928249359, 0.3908206820487976, 0.3937378525733948, 0.3862743675708771, 0.39001035690307617, 0.3871154487133026, 0.3905784785747528, 0.3814336061477661, 0.3812514543533325, 0.379472941160202, 0.3813067674636841, 0.37981635332107544, 0.37538832426071167, 0.3763575553894043, 0.3796107769012451, 0.3761245012283325, 0.3718283772468567, 0.3724209666252136, 0.36823636293411255, 0.3677557408809662, 0.36544522643089294, 0.36769556999206543, 0.36386165022850037, 0.36769041419029236, 0.3612467050552368, 0.3625718951225281], 'accuracy': [0.8729485273361206, 0.8947368264198303, 0.8896434903144836, 0.8984153866767883, 0.9074702858924866, 0.9080362319946289, 0.9159592390060425, 0.9153932929039001, 0.9204866886138916, 0.921901524066925, 0.9244481921195984, 0.9250141382217407, 0.9357668161392212, 0.9323712587356567, 0.9332201480865479, 0.9374646544456482, 0.9374646544456482, 0.9360498189926147, 0.9482173323631287, 0.9439728260040283, 0.9419921040534973, 0.9501980543136597, 0.9521788358688354, 0.9487832188606262, 0.9527447819709778, 0.9535936713218689, 0.9513299465179443, 0.9578381180763245, 0.9626485705375671, 0.9521788358688354, 0.9640634059906006, 0.965478241443634, 0.9632145166397095, 0.9649122953414917, 0.9700056314468384, 0.9688737988471985, 0.9750990271568298, 0.9717034697532654, 0.974816083908081, 0.9668930172920227, 0.9725523591041565, 0.9765138626098633, 0.9714204668998718, 0.9708545804023743, 0.9765138626098633, 0.9782116413116455, 0.9782116413116455, 0.9767968058586121, 0.977645754814148, 0.9810413122177124, 0.9818902015686035, 0.9838709831237793, 0.9816072583198547, 0.9824561476707458, 0.9801924228668213, 0.9855687618255615, 0.9844368696212769, 0.9858517050743103, 0.9872665405273438, 0.988964319229126, 0.990662157535553, 0.9881154298782349, 0.9895302653312683, 0.9852858185768127, 0.9909451007843018, 0.9929258823394775, 0.9898132681846619, 0.9934917688369751, 0.9923599362373352, 0.9835879802703857, 0.9875495433807373, 0.9920769929885864, 0.988964319229126, 0.9934917688369751, 0.9957554936408997, 0.9957554936408997, 0.9949066042900085, 0.996321439743042, 0.9949066042900085, 0.996321439743042, 0.9937747716903687, 0.9974533319473267, 0.9957554936408997, 0.9971703290939331, 0.9946236610412598, 0.9974533319473267, 0.9985851645469666, 0.996321439743042, 0.9951896071434021, 0.9966044425964355, 0.9983022212982178, 0.9974533319473267, 0.9977362751960754, 0.9971703290939331, 0.9985851645469666, 0.9966044425964355, 0.9977362751960754, 0.9968873858451843, 0.9994340538978577, 0.9974533319473267], 'val_loss': [1.0354524850845337, 1.0315628051757812, 1.0257285833358765, 1.02040696144104, 1.0134135484695435, 1.0068299770355225, 0.9988363981246948, 0.9923853874206543, 0.9834223389625549, 0.9732286334037781, 0.9609779119491577, 0.9500052332878113, 0.9380779266357422, 0.9267982244491577, 0.9170379638671875, 0.9072096943855286, 0.8965572118759155, 0.8935434818267822, 0.8831672668457031, 0.8845466375350952, 0.8791671395301819, 0.8802321553230286, 0.8921394944190979, 0.8924487829208374, 0.9037278294563293, 0.9166812896728516, 0.9167183041572571, 0.9296282529830933, 0.9519373774528503, 0.9535048604011536, 0.948865532875061, 0.9535137414932251, 0.9835949540138245, 0.9677162766456604, 0.9787333011627197, 0.9756641387939453, 0.9801841378211975, 0.9862164258956909, 0.9955781698226929, 1.0256847143173218, 0.9921948313713074, 1.0122054815292358, 1.00949227809906, 1.003250241279602, 1.0332244634628296, 1.0114216804504395, 1.0174719095230103, 1.0254281759262085, 1.036073088645935, 1.031293272972107, 1.0235366821289062, 1.0384691953659058, 1.0278027057647705, 1.0504094362258911, 1.0457494258880615, 1.059329867362976, 1.0493488311767578, 1.0508042573928833, 1.0542840957641602, 1.0604777336120605, 1.087386131286621, 1.0619151592254639, 1.068735957145691, 1.0679785013198853, 1.0718750953674316, 1.1077446937561035, 1.0747864246368408, 1.0893124341964722, 1.0856447219848633, 1.1201258897781372, 1.095157504081726, 1.1344926357269287, 1.1027837991714478, 1.1055456399917603, 1.1086677312850952, 1.1223325729370117, 1.1165040731430054, 1.113690733909607, 1.1337952613830566, 1.1424986124038696, 1.142642617225647, 1.1395342350006104, 1.1647021770477295, 1.139396071434021, 1.1514867544174194, 1.1452138423919678, 1.161612629890442, 1.2264858484268188, 1.1578035354614258, 1.1713818311691284, 1.1634085178375244, 1.172898769378662, 1.1832200288772583, 1.1803126335144043, 1.1812142133712769, 1.1838735342025757, 1.1834665536880493, 1.1923121213912964, 1.1911455392837524, 1.2005765438079834], 'val_accuracy': [0.5972850918769836, 0.5995475053787231, 0.6493212580680847, 0.6651583909988403, 0.6877828240394592, 0.6821267008781433, 0.7160633206367493, 0.6730769276618958, 0.6787330508232117, 0.7024886608123779, 0.7149321436882019, 0.7251130938529968, 0.733031690120697, 0.7307692170143127, 0.733031690120697, 0.7352941036224365, 0.7420814633369446, 0.7466063499450684, 0.7364253401756287, 0.7454751133918762, 0.7545248866081238, 0.7398189902305603, 0.7454751133918762, 0.75, 0.7533936500549316, 0.726244330406189, 0.7488687634468079, 0.7613122463226318, 0.7488687634468079, 0.7488687634468079, 0.7352941036224365, 0.7398189902305603, 0.7239819169044495, 0.7466063499450684, 0.733031690120697, 0.7386877536773682, 0.7319004535675049, 0.7364253401756287, 0.7319004535675049, 0.7409502267837524, 0.7511312365531921, 0.7319004535675049, 0.7409502267837524, 0.7296379804611206, 0.7511312365531921, 0.7319004535675049, 0.7443438768386841, 0.7341628670692444, 0.7239819169044495, 0.7296379804611206, 0.7319004535675049, 0.7386877536773682, 0.7364253401756287, 0.7273755669593811, 0.7307692170143127, 0.7251130938529968, 0.7375565767288208, 0.7398189902305603, 0.7319004535675049, 0.726244330406189, 0.7251130938529968, 0.733031690120697, 0.7296379804611206, 0.7341628670692444, 0.7319004535675049, 0.7251130938529968, 0.7375565767288208, 0.7364253401756287, 0.7251130938529968, 0.7386877536773682, 0.7319004535675049, 0.7171945571899414, 0.7285068035125732, 0.7319004535675049, 0.7239819169044495, 0.7228506803512573, 0.726244330406189, 0.7319004535675049, 0.726244330406189, 0.7296379804611206, 0.733031690120697, 0.7251130938529968, 0.7251130938529968, 0.7285068035125732, 0.733031690120697, 0.7273755669593811, 0.733031690120697, 0.7081447839736938, 0.7296379804611206, 0.7296379804611206, 0.7239819169044495, 0.7296379804611206, 0.7319004535675049, 0.7307692170143127, 0.7251130938529968, 0.7273755669593811, 0.7352941036224365, 0.7296379804611206, 0.7285068035125732, 0.7296379804611206]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 4s 33ms/step - loss: 0.6801 - accuracy: 0.8656 - val_loss: 1.0429 - val_accuracy: 0.5527\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.6767 - accuracy: 0.8750"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 21ms/step - loss: 0.6603 - accuracy: 0.8752 - val_loss: 1.0382 - val_accuracy: 0.5754\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6371 - accuracy: 0.8912 - val_loss: 1.0335 - val_accuracy: 0.5950\n","Epoch 4/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6296 - accuracy: 0.8956 - val_loss: 1.0279 - val_accuracy: 0.6147\n","Epoch 5/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6230 - accuracy: 0.8990 - val_loss: 1.0234 - val_accuracy: 0.6147\n","Epoch 6/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6234 - accuracy: 0.8979 - val_loss: 1.0184 - val_accuracy: 0.6095\n","Epoch 7/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6047 - accuracy: 0.9145 - val_loss: 1.0126 - val_accuracy: 0.6126\n","Epoch 8/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5996 - accuracy: 0.9147 - val_loss: 1.0049 - val_accuracy: 0.6426\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5932 - accuracy: 0.9176 - val_loss: 0.9973 - val_accuracy: 0.6529\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5965 - accuracy: 0.9165 - val_loss: 0.9933 - val_accuracy: 0.6415\n","Epoch 11/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5880 - accuracy: 0.9178 - val_loss: 0.9818 - val_accuracy: 0.6777\n","Epoch 12/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5805 - accuracy: 0.9264 - val_loss: 0.9739 - val_accuracy: 0.6756\n","Epoch 13/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5785 - accuracy: 0.9243 - val_loss: 0.9688 - val_accuracy: 0.6818\n","Epoch 14/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5739 - accuracy: 0.9264 - val_loss: 0.9625 - val_accuracy: 0.6756\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5713 - accuracy: 0.9276 - val_loss: 0.9648 - val_accuracy: 0.6705\n","Epoch 16/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5657 - accuracy: 0.9359 - val_loss: 0.9602 - val_accuracy: 0.6870\n","Epoch 17/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5634 - accuracy: 0.9320 - val_loss: 0.9662 - val_accuracy: 0.6767\n","Epoch 18/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5613 - accuracy: 0.9326 - val_loss: 0.9647 - val_accuracy: 0.6952\n","Epoch 19/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5628 - accuracy: 0.9274 - val_loss: 0.9850 - val_accuracy: 0.6777\n","Epoch 20/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5676 - accuracy: 0.9204 - val_loss: 1.0203 - val_accuracy: 0.6498\n","Epoch 21/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5556 - accuracy: 0.9362 - val_loss: 0.9962 - val_accuracy: 0.7014\n","Epoch 22/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5432 - accuracy: 0.9408 - val_loss: 1.0165 - val_accuracy: 0.6890\n","Epoch 23/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5407 - accuracy: 0.9439 - val_loss: 1.0552 - val_accuracy: 0.6705\n","Epoch 24/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5431 - accuracy: 0.9380 - val_loss: 1.0520 - val_accuracy: 0.6787\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5308 - accuracy: 0.9488 - val_loss: 1.0724 - val_accuracy: 0.6818\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5312 - accuracy: 0.9460 - val_loss: 1.0755 - val_accuracy: 0.6860\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5298 - accuracy: 0.9439 - val_loss: 1.1057 - val_accuracy: 0.6787\n","Epoch 28/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5266 - accuracy: 0.9473 - val_loss: 1.1084 - val_accuracy: 0.6901\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5327 - accuracy: 0.9413 - val_loss: 1.1121 - val_accuracy: 0.6880\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5233 - accuracy: 0.9426 - val_loss: 1.1500 - val_accuracy: 0.6684\n","Epoch 31/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5134 - accuracy: 0.9537 - val_loss: 1.1228 - val_accuracy: 0.6942\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5070 - accuracy: 0.9574 - val_loss: 1.1357 - val_accuracy: 0.6860\n","Epoch 33/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5086 - accuracy: 0.9509 - val_loss: 1.1623 - val_accuracy: 0.6829\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5092 - accuracy: 0.9525 - val_loss: 1.1791 - val_accuracy: 0.6705\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5009 - accuracy: 0.9602 - val_loss: 1.1490 - val_accuracy: 0.6870\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5022 - accuracy: 0.9563 - val_loss: 1.1672 - val_accuracy: 0.6839\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4995 - accuracy: 0.9576 - val_loss: 1.2077 - val_accuracy: 0.6746\n","Epoch 38/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4924 - accuracy: 0.9594 - val_loss: 1.1600 - val_accuracy: 0.6880\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4866 - accuracy: 0.9618 - val_loss: 1.1782 - val_accuracy: 0.6777\n","Epoch 40/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4870 - accuracy: 0.9633 - val_loss: 1.1950 - val_accuracy: 0.6767\n","Epoch 41/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4806 - accuracy: 0.9672 - val_loss: 1.1757 - val_accuracy: 0.6901\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4810 - accuracy: 0.9641 - val_loss: 1.1744 - val_accuracy: 0.6808\n","Epoch 43/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4759 - accuracy: 0.9690 - val_loss: 1.2182 - val_accuracy: 0.6663\n","Epoch 44/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4748 - accuracy: 0.9682 - val_loss: 1.1898 - val_accuracy: 0.6839\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4739 - accuracy: 0.9682 - val_loss: 1.2146 - val_accuracy: 0.6787\n","Epoch 46/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4675 - accuracy: 0.9698 - val_loss: 1.2066 - val_accuracy: 0.6777\n","Epoch 47/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4692 - accuracy: 0.9687 - val_loss: 1.2044 - val_accuracy: 0.6890\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4638 - accuracy: 0.9703 - val_loss: 1.2548 - val_accuracy: 0.6767\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4659 - accuracy: 0.9695 - val_loss: 1.2266 - val_accuracy: 0.6746\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4552 - accuracy: 0.9780 - val_loss: 1.2403 - val_accuracy: 0.6808\n","Epoch 51/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4620 - accuracy: 0.9695 - val_loss: 1.2427 - val_accuracy: 0.6715\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4509 - accuracy: 0.9788 - val_loss: 1.2330 - val_accuracy: 0.6736\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4507 - accuracy: 0.9796 - val_loss: 1.2749 - val_accuracy: 0.6674\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4494 - accuracy: 0.9791 - val_loss: 1.2478 - val_accuracy: 0.6715\n","Epoch 55/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4439 - accuracy: 0.9811 - val_loss: 1.2493 - val_accuracy: 0.6736\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4446 - accuracy: 0.9796 - val_loss: 1.2481 - val_accuracy: 0.6860\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4493 - accuracy: 0.9765 - val_loss: 1.2512 - val_accuracy: 0.6756\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4395 - accuracy: 0.9814 - val_loss: 1.2564 - val_accuracy: 0.6767\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4356 - accuracy: 0.9837 - val_loss: 1.3009 - val_accuracy: 0.6663\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4339 - accuracy: 0.9837 - val_loss: 1.2652 - val_accuracy: 0.6746\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4306 - accuracy: 0.9842 - val_loss: 1.2677 - val_accuracy: 0.6808\n","Epoch 62/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4379 - accuracy: 0.9778 - val_loss: 1.4465 - val_accuracy: 0.6415\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4524 - accuracy: 0.9667 - val_loss: 1.3403 - val_accuracy: 0.6581\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4307 - accuracy: 0.9832 - val_loss: 1.3037 - val_accuracy: 0.6684\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4260 - accuracy: 0.9845 - val_loss: 1.3082 - val_accuracy: 0.6736\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4341 - accuracy: 0.9765 - val_loss: 1.2873 - val_accuracy: 0.6798\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4207 - accuracy: 0.9855 - val_loss: 1.2873 - val_accuracy: 0.6818\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4193 - accuracy: 0.9845 - val_loss: 1.2924 - val_accuracy: 0.6818\n","Epoch 69/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4159 - accuracy: 0.9897 - val_loss: 1.3020 - val_accuracy: 0.6860\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4126 - accuracy: 0.9879 - val_loss: 1.3385 - val_accuracy: 0.6705\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4143 - accuracy: 0.9860 - val_loss: 1.3175 - val_accuracy: 0.6736\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4100 - accuracy: 0.9904 - val_loss: 1.3232 - val_accuracy: 0.6643\n","Epoch 73/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4067 - accuracy: 0.9928 - val_loss: 1.3225 - val_accuracy: 0.6705\n","Epoch 74/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4050 - accuracy: 0.9925 - val_loss: 1.3661 - val_accuracy: 0.6684\n","Epoch 75/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4046 - accuracy: 0.9920 - val_loss: 1.3720 - val_accuracy: 0.6674\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4019 - accuracy: 0.9915 - val_loss: 1.3430 - val_accuracy: 0.6839\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4148 - accuracy: 0.9832 - val_loss: 1.3386 - val_accuracy: 0.6746\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3986 - accuracy: 0.9917 - val_loss: 1.3696 - val_accuracy: 0.6653\n","Epoch 79/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3975 - accuracy: 0.9917 - val_loss: 1.3564 - val_accuracy: 0.6715\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3936 - accuracy: 0.9948 - val_loss: 1.3606 - val_accuracy: 0.6684\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3943 - accuracy: 0.9935 - val_loss: 1.3704 - val_accuracy: 0.6653\n","Epoch 82/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3933 - accuracy: 0.9930 - val_loss: 1.3697 - val_accuracy: 0.6674\n","Epoch 83/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3918 - accuracy: 0.9922 - val_loss: 1.3917 - val_accuracy: 0.6643\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3893 - accuracy: 0.9951 - val_loss: 1.3763 - val_accuracy: 0.6705\n","Epoch 85/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3867 - accuracy: 0.9959 - val_loss: 1.3757 - val_accuracy: 0.6746\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3856 - accuracy: 0.9946 - val_loss: 1.3977 - val_accuracy: 0.6632\n","Epoch 87/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3854 - accuracy: 0.9943 - val_loss: 1.4061 - val_accuracy: 0.6643\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3829 - accuracy: 0.9948 - val_loss: 1.4094 - val_accuracy: 0.6653\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3810 - accuracy: 0.9946 - val_loss: 1.3991 - val_accuracy: 0.6705\n","Epoch 90/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3807 - accuracy: 0.9956 - val_loss: 1.4149 - val_accuracy: 0.6622\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3772 - accuracy: 0.9969 - val_loss: 1.4125 - val_accuracy: 0.6787\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3805 - accuracy: 0.9943 - val_loss: 1.4082 - val_accuracy: 0.6684\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3763 - accuracy: 0.9948 - val_loss: 1.4268 - val_accuracy: 0.6663\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3758 - accuracy: 0.9951 - val_loss: 1.4231 - val_accuracy: 0.6725\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3729 - accuracy: 0.9961 - val_loss: 1.4330 - val_accuracy: 0.6684\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3750 - accuracy: 0.9946 - val_loss: 1.4667 - val_accuracy: 0.6684\n","Epoch 97/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3730 - accuracy: 0.9956 - val_loss: 1.4398 - val_accuracy: 0.6767\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3703 - accuracy: 0.9951 - val_loss: 1.4729 - val_accuracy: 0.6705\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3696 - accuracy: 0.9956 - val_loss: 1.4831 - val_accuracy: 0.6653\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3683 - accuracy: 0.9959 - val_loss: 1.4471 - val_accuracy: 0.6725\n","{'loss': [0.6801390647888184, 0.6602946519851685, 0.6371248364448547, 0.6296059489250183, 0.6229779124259949, 0.6233792304992676, 0.6046744585037231, 0.599576473236084, 0.5931535363197327, 0.5964536070823669, 0.5879625678062439, 0.5805309414863586, 0.5785492658615112, 0.5739485025405884, 0.5713021159172058, 0.565706729888916, 0.5633531808853149, 0.5612683296203613, 0.5628151893615723, 0.567603349685669, 0.5556107759475708, 0.5431665778160095, 0.5407499670982361, 0.5430843830108643, 0.5308398604393005, 0.5311756134033203, 0.5298058986663818, 0.5266188383102417, 0.532726526260376, 0.5233345627784729, 0.5133784413337708, 0.5070048570632935, 0.508585512638092, 0.5092013478279114, 0.5008647441864014, 0.5022444725036621, 0.4994826316833496, 0.49237382411956787, 0.48663878440856934, 0.4869769513607025, 0.48064476251602173, 0.4809640944004059, 0.4758923351764679, 0.47476401925086975, 0.47390636801719666, 0.4674987494945526, 0.4692365229129791, 0.46381837129592896, 0.4659367799758911, 0.45523738861083984, 0.46201497316360474, 0.4508782625198364, 0.4506944417953491, 0.44936275482177734, 0.4439327120780945, 0.4446285367012024, 0.4493406414985657, 0.4395160675048828, 0.43564775586128235, 0.4339383840560913, 0.43062201142311096, 0.43788570165634155, 0.45243731141090393, 0.43066543340682983, 0.42599934339523315, 0.4340611398220062, 0.42070022225379944, 0.41926562786102295, 0.4158537983894348, 0.41264960169792175, 0.41427111625671387, 0.4099988341331482, 0.40666958689689636, 0.4050392210483551, 0.4045710563659668, 0.40191957354545593, 0.4147549867630005, 0.39863458275794983, 0.39749616384506226, 0.39362064003944397, 0.3943459093570709, 0.3933008313179016, 0.39182016253471375, 0.3893091380596161, 0.3867432177066803, 0.3855583071708679, 0.3853529393672943, 0.38293424248695374, 0.3810138404369354, 0.38067471981048584, 0.3772468864917755, 0.38054999709129333, 0.3762611448764801, 0.3757548928260803, 0.3729257881641388, 0.37496417760849, 0.3729545772075653, 0.3703303039073944, 0.36962130665779114, 0.36826053261756897], 'accuracy': [0.8656330704689026, 0.8751937747001648, 0.8912144899368286, 0.8956072330474854, 0.8989664316177368, 0.8979328274726868, 0.9144702553749084, 0.9147287011146545, 0.9175710678100586, 0.9165374636650085, 0.9178294539451599, 0.9263566136360168, 0.9242894053459167, 0.9263566136360168, 0.9276486039161682, 0.935917317867279, 0.932041347026825, 0.9325581192970276, 0.9273901581764221, 0.9204134345054626, 0.9361757040023804, 0.9408268928527832, 0.9439276456832886, 0.9379844665527344, 0.9488372206687927, 0.9459948539733887, 0.9439276456832886, 0.94728684425354, 0.9413436651229858, 0.9426356554031372, 0.9537467956542969, 0.9573643207550049, 0.950904369354248, 0.9524548053741455, 0.9602067470550537, 0.9563307762145996, 0.957622766494751, 0.959431529045105, 0.9617571234703064, 0.9633074998855591, 0.9671834707260132, 0.964082658290863, 0.9689922332763672, 0.9682170748710632, 0.9682170748710632, 0.9697674512863159, 0.9687338471412659, 0.9702842235565186, 0.9695090651512146, 0.9780361652374268, 0.9695090651512146, 0.9788113832473755, 0.9795865416526794, 0.9790697693824768, 0.9811369776725769, 0.9795865416526794, 0.9764857888221741, 0.9813953638076782, 0.9837209582328796, 0.9837209582328796, 0.9842377305030823, 0.9777777791023254, 0.9666666388511658, 0.9832041263580322, 0.9844961166381836, 0.9764857888221741, 0.9855297207832336, 0.9844961166381836, 0.9896640777587891, 0.9878553152084351, 0.9860464930534363, 0.9904392957687378, 0.9927648305892944, 0.9925064444541931, 0.9919896721839905, 0.9914728403091431, 0.9832041263580322, 0.9917312860488892, 0.9917312860488892, 0.9948320388793945, 0.9935400485992432, 0.9930232763290405, 0.9922480583190918, 0.9950904250144958, 0.9958656430244446, 0.9945736527442932, 0.9943152666091919, 0.9948320388793945, 0.9945736527442932, 0.9956072568893433, 0.9968992471694946, 0.9943152666091919, 0.9948320388793945, 0.9950904250144958, 0.9961240291595459, 0.9945736527442932, 0.9956072568893433, 0.9950904250144958, 0.9956072568893433, 0.9958656430244446], 'val_loss': [1.0428725481033325, 1.038221836090088, 1.0334511995315552, 1.0278565883636475, 1.0234347581863403, 1.0183697938919067, 1.0126149654388428, 1.0049431324005127, 0.9972726702690125, 0.9932667016983032, 0.9818090796470642, 0.9738693833351135, 0.9688394069671631, 0.962532639503479, 0.9648491740226746, 0.9601582884788513, 0.9662489295005798, 0.9646793007850647, 0.9849953055381775, 1.0203149318695068, 0.9962331056594849, 1.016475796699524, 1.0551865100860596, 1.0520392656326294, 1.0724400281906128, 1.075461506843567, 1.1056982278823853, 1.108392357826233, 1.1121383905410767, 1.1500269174575806, 1.1228448152542114, 1.1357176303863525, 1.1622520685195923, 1.179125428199768, 1.1490366458892822, 1.167194128036499, 1.2077127695083618, 1.1599870920181274, 1.178154706954956, 1.1949599981307983, 1.1757041215896606, 1.1743969917297363, 1.2181599140167236, 1.1898391246795654, 1.2146447896957397, 1.2066022157669067, 1.2044460773468018, 1.2548320293426514, 1.2266231775283813, 1.2403355836868286, 1.24266517162323, 1.2330032587051392, 1.2749369144439697, 1.247776746749878, 1.2493454217910767, 1.248143196105957, 1.251249074935913, 1.2563998699188232, 1.3008519411087036, 1.2652243375778198, 1.2676551342010498, 1.4465322494506836, 1.3403385877609253, 1.3036733865737915, 1.3081884384155273, 1.2872769832611084, 1.2873116731643677, 1.292364478111267, 1.301975965499878, 1.3385117053985596, 1.3175019025802612, 1.323175072669983, 1.3224949836730957, 1.3660677671432495, 1.3719688653945923, 1.3430168628692627, 1.3386036157608032, 1.3696049451828003, 1.356438159942627, 1.3606371879577637, 1.3703773021697998, 1.3696873188018799, 1.391719102859497, 1.3762999773025513, 1.3756858110427856, 1.3977367877960205, 1.4060852527618408, 1.4094265699386597, 1.3990870714187622, 1.4149271249771118, 1.4125012159347534, 1.408159613609314, 1.4267809391021729, 1.4230775833129883, 1.4330288171768188, 1.4667431116104126, 1.4398491382598877, 1.4728974103927612, 1.483148217201233, 1.4470829963684082], 'val_accuracy': [0.5526859760284424, 0.5754132270812988, 0.5950413346290588, 0.6146694421768188, 0.6146694421768188, 0.6095041036605835, 0.6126033067703247, 0.6425619721412659, 0.6528925895690918, 0.6415289044380188, 0.6776859760284424, 0.6756198406219482, 0.6818181872367859, 0.6756198406219482, 0.6704545617103577, 0.6869834661483765, 0.6766529083251953, 0.6952479481697083, 0.6776859760284424, 0.6497933864593506, 0.7014462947845459, 0.6890496015548706, 0.6704545617103577, 0.6787189841270447, 0.6818181872367859, 0.6859503984451294, 0.6787189841270447, 0.6900826692581177, 0.6880165338516235, 0.6683884263038635, 0.6942148804664612, 0.6859503984451294, 0.682851254940033, 0.6704545617103577, 0.6869834661483765, 0.68388432264328, 0.6745867729187012, 0.6880165338516235, 0.6776859760284424, 0.6766529083251953, 0.6900826692581177, 0.6807851195335388, 0.6663222908973694, 0.68388432264328, 0.6787189841270447, 0.6776859760284424, 0.6890496015548706, 0.6766529083251953, 0.6745867729187012, 0.6807851195335388, 0.6714876294136047, 0.6735537052154541, 0.6673553586006165, 0.6714876294136047, 0.6735537052154541, 0.6859503984451294, 0.6756198406219482, 0.6766529083251953, 0.6663222908973694, 0.6745867729187012, 0.6807851195335388, 0.6415289044380188, 0.6580578684806824, 0.6683884263038635, 0.6735537052154541, 0.6797520518302917, 0.6818181872367859, 0.6818181872367859, 0.6859503984451294, 0.6704545617103577, 0.6735537052154541, 0.66425621509552, 0.6704545617103577, 0.6683884263038635, 0.6673553586006165, 0.68388432264328, 0.6745867729187012, 0.6652892827987671, 0.6714876294136047, 0.6683884263038635, 0.6652892827987671, 0.6673553586006165, 0.66425621509552, 0.6704545617103577, 0.6745867729187012, 0.663223147392273, 0.66425621509552, 0.6652892827987671, 0.6704545617103577, 0.6621900796890259, 0.6787189841270447, 0.6683884263038635, 0.6663222908973694, 0.672520637512207, 0.6683884263038635, 0.6683884263038635, 0.6766529083251953, 0.6704545617103577, 0.6652892827987671, 0.672520637512207]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.4927 - accuracy: 0.9332"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 4s 40ms/step - loss: 0.4927 - accuracy: 0.9332 - val_loss: 1.0071 - val_accuracy: 0.5151\n","Epoch 2/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4469 - accuracy: 0.9585 - val_loss: 1.0004 - val_accuracy: 0.5442\n","Epoch 3/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4285 - accuracy: 0.9714 - val_loss: 0.9928 - val_accuracy: 0.5560\n","Epoch 4/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4214 - accuracy: 0.9731 - val_loss: 0.9824 - val_accuracy: 0.5797\n","Epoch 5/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4135 - accuracy: 0.9779 - val_loss: 0.9773 - val_accuracy: 0.5851\n","Epoch 6/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4104 - accuracy: 0.9798 - val_loss: 0.9608 - val_accuracy: 0.6325\n","Epoch 7/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4099 - accuracy: 0.9763 - val_loss: 0.9602 - val_accuracy: 0.6164\n","Epoch 8/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4049 - accuracy: 0.9809 - val_loss: 0.9437 - val_accuracy: 0.6476\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3968 - accuracy: 0.9841 - val_loss: 0.9242 - val_accuracy: 0.6767\n","Epoch 10/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3957 - accuracy: 0.9844 - val_loss: 0.9029 - val_accuracy: 0.7091\n","Epoch 11/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3954 - accuracy: 0.9841 - val_loss: 0.8830 - val_accuracy: 0.7317\n","Epoch 12/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3895 - accuracy: 0.9876 - val_loss: 0.8731 - val_accuracy: 0.7295\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3843 - accuracy: 0.9916 - val_loss: 0.8559 - val_accuracy: 0.7457\n","Epoch 14/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3894 - accuracy: 0.9868 - val_loss: 0.8335 - val_accuracy: 0.7716\n","Epoch 15/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3830 - accuracy: 0.9900 - val_loss: 0.8232 - val_accuracy: 0.7791\n","Epoch 16/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3793 - accuracy: 0.9914 - val_loss: 0.8096 - val_accuracy: 0.7888\n","Epoch 17/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3796 - accuracy: 0.9938 - val_loss: 0.8017 - val_accuracy: 0.7856\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3776 - accuracy: 0.9927 - val_loss: 0.7952 - val_accuracy: 0.7942\n","Epoch 19/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3775 - accuracy: 0.9941 - val_loss: 0.8140 - val_accuracy: 0.7812\n","Epoch 20/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3726 - accuracy: 0.9935 - val_loss: 0.8063 - val_accuracy: 0.7996\n","Epoch 21/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3734 - accuracy: 0.9943 - val_loss: 0.8101 - val_accuracy: 0.8006\n","Epoch 22/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3683 - accuracy: 0.9965 - val_loss: 0.8204 - val_accuracy: 0.7899\n","Epoch 23/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3657 - accuracy: 0.9976 - val_loss: 0.8311 - val_accuracy: 0.7953\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3652 - accuracy: 0.9957 - val_loss: 0.8614 - val_accuracy: 0.7974\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3641 - accuracy: 0.9970 - val_loss: 0.8729 - val_accuracy: 0.7942\n","Epoch 26/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3659 - accuracy: 0.9952 - val_loss: 0.8909 - val_accuracy: 0.7963\n","Epoch 27/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3622 - accuracy: 0.9970 - val_loss: 0.8980 - val_accuracy: 0.7931\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3644 - accuracy: 0.9952 - val_loss: 0.9163 - val_accuracy: 0.7953\n","Epoch 29/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3580 - accuracy: 0.9978 - val_loss: 0.9248 - val_accuracy: 0.7974\n","Epoch 30/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3656 - accuracy: 0.9938 - val_loss: 0.9268 - val_accuracy: 0.7953\n","Epoch 31/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3563 - accuracy: 0.9978 - val_loss: 0.9439 - val_accuracy: 0.7953\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3545 - accuracy: 0.9973 - val_loss: 0.9603 - val_accuracy: 0.7888\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3529 - accuracy: 0.9989 - val_loss: 0.9594 - val_accuracy: 0.7963\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3510 - accuracy: 0.9992 - val_loss: 0.9557 - val_accuracy: 0.7909\n","Epoch 35/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3504 - accuracy: 0.9984 - val_loss: 0.9690 - val_accuracy: 0.7963\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3503 - accuracy: 0.9992 - val_loss: 0.9781 - val_accuracy: 0.7963\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3524 - accuracy: 0.9970 - val_loss: 0.9742 - val_accuracy: 0.7942\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3541 - accuracy: 0.9965 - val_loss: 0.9784 - val_accuracy: 0.7920\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3467 - accuracy: 0.9987 - val_loss: 0.9754 - val_accuracy: 0.7899\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3451 - accuracy: 0.9997 - val_loss: 0.9885 - val_accuracy: 0.7953\n","Epoch 41/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3457 - accuracy: 0.9989 - val_loss: 0.9958 - val_accuracy: 0.7866\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3476 - accuracy: 0.9984 - val_loss: 1.0200 - val_accuracy: 0.7812\n","Epoch 43/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3497 - accuracy: 0.9952 - val_loss: 0.9995 - val_accuracy: 0.7920\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3494 - accuracy: 0.9968 - val_loss: 1.0238 - val_accuracy: 0.7769\n","Epoch 45/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3471 - accuracy: 0.9970 - val_loss: 1.0447 - val_accuracy: 0.7726\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3417 - accuracy: 0.9978 - val_loss: 1.0001 - val_accuracy: 0.7866\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3407 - accuracy: 0.9995 - val_loss: 1.0182 - val_accuracy: 0.7899\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3374 - accuracy: 1.0000 - val_loss: 1.0053 - val_accuracy: 0.7888\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3368 - accuracy: 0.9995 - val_loss: 1.0145 - val_accuracy: 0.7866\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3397 - accuracy: 0.9995 - val_loss: 1.0569 - val_accuracy: 0.7716\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3369 - accuracy: 0.9992 - val_loss: 1.0191 - val_accuracy: 0.7888\n","Epoch 52/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3349 - accuracy: 0.9995 - val_loss: 1.0179 - val_accuracy: 0.7909\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3338 - accuracy: 0.9997 - val_loss: 1.0233 - val_accuracy: 0.7856\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3326 - accuracy: 1.0000 - val_loss: 1.0168 - val_accuracy: 0.7888\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3312 - accuracy: 0.9997 - val_loss: 1.0285 - val_accuracy: 0.7834\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3309 - accuracy: 0.9997 - val_loss: 1.0204 - val_accuracy: 0.7888\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3311 - accuracy: 0.9997 - val_loss: 1.0318 - val_accuracy: 0.7823\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3306 - accuracy: 1.0000 - val_loss: 1.0379 - val_accuracy: 0.7877\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3288 - accuracy: 1.0000 - val_loss: 1.0240 - val_accuracy: 0.7888\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3273 - accuracy: 1.0000 - val_loss: 1.0361 - val_accuracy: 0.7866\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3317 - accuracy: 0.9995 - val_loss: 1.0553 - val_accuracy: 0.7769\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3313 - accuracy: 0.9997 - val_loss: 1.0372 - val_accuracy: 0.7845\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3263 - accuracy: 0.9995 - val_loss: 1.0284 - val_accuracy: 0.7899\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3247 - accuracy: 1.0000 - val_loss: 1.0490 - val_accuracy: 0.7845\n","Epoch 65/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3257 - accuracy: 0.9995 - val_loss: 1.0415 - val_accuracy: 0.7834\n","Epoch 66/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3230 - accuracy: 1.0000 - val_loss: 1.0517 - val_accuracy: 0.7780\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3234 - accuracy: 0.9997 - val_loss: 1.0608 - val_accuracy: 0.7759\n","Epoch 68/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3217 - accuracy: 1.0000 - val_loss: 1.0497 - val_accuracy: 0.7812\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3217 - accuracy: 1.0000 - val_loss: 1.0454 - val_accuracy: 0.7888\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3211 - accuracy: 1.0000 - val_loss: 1.0608 - val_accuracy: 0.7780\n","Epoch 71/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3197 - accuracy: 1.0000 - val_loss: 1.0558 - val_accuracy: 0.7845\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3259 - accuracy: 0.9992 - val_loss: 1.1717 - val_accuracy: 0.7522\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3217 - accuracy: 0.9989 - val_loss: 1.0553 - val_accuracy: 0.7823\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3181 - accuracy: 1.0000 - val_loss: 1.0546 - val_accuracy: 0.7823\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3171 - accuracy: 1.0000 - val_loss: 1.0774 - val_accuracy: 0.7802\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3161 - accuracy: 0.9997 - val_loss: 1.0573 - val_accuracy: 0.7845\n","Epoch 77/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3163 - accuracy: 1.0000 - val_loss: 1.0666 - val_accuracy: 0.7791\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3153 - accuracy: 0.9997 - val_loss: 1.0719 - val_accuracy: 0.7802\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3172 - accuracy: 1.0000 - val_loss: 1.0740 - val_accuracy: 0.7791\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3165 - accuracy: 0.9989 - val_loss: 1.0724 - val_accuracy: 0.7802\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3163 - accuracy: 0.9995 - val_loss: 1.0787 - val_accuracy: 0.7812\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3139 - accuracy: 1.0000 - val_loss: 1.0684 - val_accuracy: 0.7845\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3121 - accuracy: 1.0000 - val_loss: 1.0897 - val_accuracy: 0.7769\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3110 - accuracy: 0.9997 - val_loss: 1.0854 - val_accuracy: 0.7737\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3111 - accuracy: 1.0000 - val_loss: 1.0728 - val_accuracy: 0.7834\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3103 - accuracy: 1.0000 - val_loss: 1.0806 - val_accuracy: 0.7823\n","Epoch 87/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3091 - accuracy: 1.0000 - val_loss: 1.1033 - val_accuracy: 0.7726\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3083 - accuracy: 1.0000 - val_loss: 1.0790 - val_accuracy: 0.7823\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3088 - accuracy: 1.0000 - val_loss: 1.0810 - val_accuracy: 0.7888\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3067 - accuracy: 1.0000 - val_loss: 1.0880 - val_accuracy: 0.7791\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3062 - accuracy: 1.0000 - val_loss: 1.0819 - val_accuracy: 0.7823\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3057 - accuracy: 1.0000 - val_loss: 1.0915 - val_accuracy: 0.7802\n","Epoch 93/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3064 - accuracy: 0.9997 - val_loss: 1.0965 - val_accuracy: 0.7791\n","Epoch 94/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3046 - accuracy: 1.0000 - val_loss: 1.0971 - val_accuracy: 0.7759\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3032 - accuracy: 1.0000 - val_loss: 1.0915 - val_accuracy: 0.7802\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3024 - accuracy: 1.0000 - val_loss: 1.0917 - val_accuracy: 0.7802\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3026 - accuracy: 1.0000 - val_loss: 1.0919 - val_accuracy: 0.7823\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3021 - accuracy: 1.0000 - val_loss: 1.0916 - val_accuracy: 0.7823\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3013 - accuracy: 1.0000 - val_loss: 1.1254 - val_accuracy: 0.7651\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3014 - accuracy: 1.0000 - val_loss: 1.1019 - val_accuracy: 0.7802\n","{'loss': [0.4926874339580536, 0.44691526889801025, 0.42847561836242676, 0.42136916518211365, 0.4135042130947113, 0.41044390201568604, 0.4099261164665222, 0.40491336584091187, 0.39679473638534546, 0.39569756388664246, 0.3953865170478821, 0.38954970240592957, 0.3843023180961609, 0.38944098353385925, 0.3829650282859802, 0.37932777404785156, 0.3795720338821411, 0.3776249289512634, 0.37753015756607056, 0.37261730432510376, 0.37337708473205566, 0.3682776689529419, 0.3657299876213074, 0.3652419149875641, 0.36414214968681335, 0.3659268617630005, 0.36218053102493286, 0.3644108474254608, 0.3580454885959625, 0.36564624309539795, 0.3563240170478821, 0.35452473163604736, 0.35293206572532654, 0.35099321603775024, 0.350350946187973, 0.35031378269195557, 0.35236823558807373, 0.35411855578422546, 0.3467108905315399, 0.3450929820537567, 0.34571507573127747, 0.3476465344429016, 0.3497159481048584, 0.3493610620498657, 0.3471095860004425, 0.34170272946357727, 0.3407072126865387, 0.33738330006599426, 0.3368324935436249, 0.33974096179008484, 0.3368645906448364, 0.3348928987979889, 0.33376890420913696, 0.33262282609939575, 0.33117058873176575, 0.33090919256210327, 0.331130713224411, 0.3305705189704895, 0.3288242220878601, 0.3273497521877289, 0.33173754811286926, 0.3313487470149994, 0.3262917697429657, 0.324700266122818, 0.3257337212562561, 0.3229691684246063, 0.3234069049358368, 0.3216923475265503, 0.3216858208179474, 0.32112839818000793, 0.3196772634983063, 0.32588547468185425, 0.3217484951019287, 0.3180837035179138, 0.3171307444572449, 0.3160674571990967, 0.3162611722946167, 0.3152891993522644, 0.3172248899936676, 0.31654125452041626, 0.3163035213947296, 0.3138917088508606, 0.31205520033836365, 0.31101828813552856, 0.3111298978328705, 0.3103395700454712, 0.3090531826019287, 0.30834171175956726, 0.30881720781326294, 0.3067058026790619, 0.30617374181747437, 0.3056723177433014, 0.3063910901546478, 0.30459871888160706, 0.3032437562942505, 0.30239614844322205, 0.30256807804107666, 0.3020867109298706, 0.3013036549091339, 0.30136847496032715], 'accuracy': [0.9331896305084229, 0.9585129022598267, 0.9714439511299133, 0.9730603694915771, 0.977909505367279, 0.9797952771186829, 0.9762930870056152, 0.9808728694915771, 0.9841055870056152, 0.984375, 0.9841055870056152, 0.9876077771186829, 0.9916487336158752, 0.9867995977401733, 0.9900323152542114, 0.9913793206214905, 0.993803858757019, 0.9927262663841248, 0.9940732717514038, 0.993534505367279, 0.9943426847457886, 0.9964978694915771, 0.9975754022598267, 0.9956896305084229, 0.9970366358757019, 0.9951508641242981, 0.9970366358757019, 0.9951508641242981, 0.9978448152542114, 0.993803858757019, 0.9978448152542114, 0.9973060488700867, 0.9989224076271057, 0.9991918206214905, 0.998383641242981, 0.9991918206214905, 0.9970366358757019, 0.9964978694915771, 0.998652994632721, 0.9997305870056152, 0.9989224076271057, 0.998383641242981, 0.9951508641242981, 0.9967672228813171, 0.9970366358757019, 0.9978448152542114, 0.9994612336158752, 1.0, 0.9994612336158752, 0.9994612336158752, 0.9991918206214905, 0.9994612336158752, 0.9997305870056152, 1.0, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152, 1.0, 1.0, 1.0, 0.9994612336158752, 0.9997305870056152, 0.9994612336158752, 1.0, 0.9994612336158752, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 0.9991918206214905, 0.9989224076271057, 1.0, 1.0, 0.9997305870056152, 1.0, 0.9997305870056152, 1.0, 0.9989224076271057, 0.9994612336158752, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [1.0070693492889404, 1.0003995895385742, 0.9927776455879211, 0.9824066162109375, 0.977275013923645, 0.9608492851257324, 0.9602007865905762, 0.9436845183372498, 0.9242067933082581, 0.9028953313827515, 0.8830417394638062, 0.8730534315109253, 0.8558738231658936, 0.8335040807723999, 0.8231912851333618, 0.8096193671226501, 0.8016781210899353, 0.7951881885528564, 0.8139966130256653, 0.8062527179718018, 0.8100795149803162, 0.8204274773597717, 0.8310973644256592, 0.8614163994789124, 0.872866690158844, 0.8908509016036987, 0.8979849219322205, 0.9163298606872559, 0.9248071312904358, 0.926827073097229, 0.943890392780304, 0.9603291153907776, 0.959382951259613, 0.955682098865509, 0.9690303206443787, 0.9780532121658325, 0.9742178320884705, 0.9784069061279297, 0.975385308265686, 0.988525927066803, 0.995834469795227, 1.0200129747390747, 0.9994540214538574, 1.0237629413604736, 1.044738531112671, 1.0000933408737183, 1.0182468891143799, 1.0053132772445679, 1.0145008563995361, 1.0569472312927246, 1.019083023071289, 1.017902135848999, 1.023279070854187, 1.0168386697769165, 1.028533935546875, 1.0204466581344604, 1.0318244695663452, 1.0378942489624023, 1.0239733457565308, 1.0361435413360596, 1.0552693605422974, 1.0371941328048706, 1.0283968448638916, 1.048967957496643, 1.041453242301941, 1.0516773462295532, 1.0608022212982178, 1.0497021675109863, 1.045365810394287, 1.06083083152771, 1.0558043718338013, 1.1717419624328613, 1.0552903413772583, 1.0545697212219238, 1.07735013961792, 1.057307243347168, 1.0666015148162842, 1.0718852281570435, 1.0740259885787964, 1.072365641593933, 1.078709363937378, 1.0683737993240356, 1.0897483825683594, 1.0854237079620361, 1.072837233543396, 1.080573558807373, 1.1032500267028809, 1.0789633989334106, 1.0810116529464722, 1.0880138874053955, 1.0818763971328735, 1.091503620147705, 1.0964820384979248, 1.0971195697784424, 1.0914978981018066, 1.091688871383667, 1.0919439792633057, 1.0916022062301636, 1.125362753868103, 1.1019395589828491], 'val_accuracy': [0.5150862336158752, 0.5441810488700867, 0.556034505367279, 0.579741358757019, 0.5851293206214905, 0.6325430870056152, 0.6163793206214905, 0.6476293206214905, 0.6767241358757019, 0.7090517282485962, 0.7316810488700867, 0.7295258641242981, 0.7456896305084229, 0.7715517282485962, 0.7790948152542114, 0.7887930870056152, 0.7855603694915771, 0.7941810488700867, 0.78125, 0.7995689511299133, 0.8006465435028076, 0.7898706793785095, 0.795258641242981, 0.7974137663841248, 0.7941810488700867, 0.7963362336158752, 0.7931034564971924, 0.795258641242981, 0.7974137663841248, 0.795258641242981, 0.795258641242981, 0.7887930870056152, 0.7963362336158752, 0.7909482717514038, 0.7963362336158752, 0.7963362336158752, 0.7941810488700867, 0.7920258641242981, 0.7898706793785095, 0.795258641242981, 0.7866379022598267, 0.78125, 0.7920258641242981, 0.7769396305084229, 0.7726293206214905, 0.7866379022598267, 0.7898706793785095, 0.7887930870056152, 0.7866379022598267, 0.7715517282485962, 0.7887930870056152, 0.7909482717514038, 0.7855603694915771, 0.7887930870056152, 0.7834051847457886, 0.7887930870056152, 0.7823275923728943, 0.787715494632721, 0.7887930870056152, 0.7866379022598267, 0.7769396305084229, 0.7844827771186829, 0.7898706793785095, 0.7844827771186829, 0.7834051847457886, 0.7780172228813171, 0.7758620977401733, 0.78125, 0.7887930870056152, 0.7780172228813171, 0.7844827771186829, 0.7521551847457886, 0.7823275923728943, 0.7823275923728943, 0.7801724076271057, 0.7844827771186829, 0.7790948152542114, 0.7801724076271057, 0.7790948152542114, 0.7801724076271057, 0.78125, 0.7844827771186829, 0.7769396305084229, 0.7737069129943848, 0.7834051847457886, 0.7823275923728943, 0.7726293206214905, 0.7823275923728943, 0.7887930870056152, 0.7790948152542114, 0.7823275923728943, 0.7801724076271057, 0.7790948152542114, 0.7758620977401733, 0.7801724076271057, 0.7801724076271057, 0.7823275923728943, 0.7823275923728943, 0.7650862336158752, 0.7801724076271057]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 32ms/step - loss: 0.4598 - accuracy: 0.9533 - val_loss: 0.9975 - val_accuracy: 0.5577\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.4515 - accuracy: 0.9375"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 1s 21ms/step - loss: 0.4369 - accuracy: 0.9652 - val_loss: 0.9953 - val_accuracy: 0.5622\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4255 - accuracy: 0.9717 - val_loss: 0.9904 - val_accuracy: 0.5701\n","Epoch 4/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4135 - accuracy: 0.9791 - val_loss: 0.9779 - val_accuracy: 0.5939\n","Epoch 5/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4181 - accuracy: 0.9731 - val_loss: 0.9769 - val_accuracy: 0.5894\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4133 - accuracy: 0.9737 - val_loss: 0.9699 - val_accuracy: 0.5973\n","Epoch 7/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4052 - accuracy: 0.9813 - val_loss: 0.9514 - val_accuracy: 0.6324\n","Epoch 8/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3981 - accuracy: 0.9873 - val_loss: 0.9590 - val_accuracy: 0.6086\n","Epoch 9/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3994 - accuracy: 0.9853 - val_loss: 0.9326 - val_accuracy: 0.6538\n","Epoch 10/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4009 - accuracy: 0.9813 - val_loss: 0.9053 - val_accuracy: 0.6900\n","Epoch 11/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.3897 - accuracy: 0.9912 - val_loss: 0.8851 - val_accuracy: 0.7081\n","Epoch 12/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3854 - accuracy: 0.9924 - val_loss: 0.8692 - val_accuracy: 0.7206\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3866 - accuracy: 0.9901 - val_loss: 0.8701 - val_accuracy: 0.7161\n","Epoch 14/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3843 - accuracy: 0.9901 - val_loss: 0.8401 - val_accuracy: 0.7466\n","Epoch 15/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3792 - accuracy: 0.9949 - val_loss: 0.8145 - val_accuracy: 0.7749\n","Epoch 16/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3776 - accuracy: 0.9943 - val_loss: 0.8059 - val_accuracy: 0.7749\n","Epoch 17/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3754 - accuracy: 0.9958 - val_loss: 0.7927 - val_accuracy: 0.7862\n","Epoch 18/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3741 - accuracy: 0.9949 - val_loss: 0.7867 - val_accuracy: 0.7885\n","Epoch 19/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3824 - accuracy: 0.9895 - val_loss: 0.7800 - val_accuracy: 0.7998\n","Epoch 20/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3745 - accuracy: 0.9946 - val_loss: 0.7844 - val_accuracy: 0.7964\n","Epoch 21/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3679 - accuracy: 0.9969 - val_loss: 0.7888 - val_accuracy: 0.7986\n","Epoch 22/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3699 - accuracy: 0.9958 - val_loss: 0.8022 - val_accuracy: 0.7964\n","Epoch 23/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3670 - accuracy: 0.9963 - val_loss: 0.8077 - val_accuracy: 0.8077\n","Epoch 24/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3697 - accuracy: 0.9958 - val_loss: 0.8199 - val_accuracy: 0.8054\n","Epoch 25/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3618 - accuracy: 0.9972 - val_loss: 0.8326 - val_accuracy: 0.8032\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3597 - accuracy: 0.9992 - val_loss: 0.8475 - val_accuracy: 0.8054\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3603 - accuracy: 0.9989 - val_loss: 0.8666 - val_accuracy: 0.8066\n","Epoch 28/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3594 - accuracy: 0.9989 - val_loss: 0.8749 - val_accuracy: 0.8111\n","Epoch 29/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3575 - accuracy: 0.9980 - val_loss: 0.9012 - val_accuracy: 0.7930\n","Epoch 30/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3564 - accuracy: 0.9986 - val_loss: 0.9003 - val_accuracy: 0.7975\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3528 - accuracy: 0.9997 - val_loss: 0.9233 - val_accuracy: 0.7998\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3524 - accuracy: 0.9997 - val_loss: 0.9324 - val_accuracy: 0.7930\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3531 - accuracy: 0.9986 - val_loss: 0.9228 - val_accuracy: 0.7998\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3509 - accuracy: 0.9992 - val_loss: 0.9331 - val_accuracy: 0.8020\n","Epoch 35/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3509 - accuracy: 0.9989 - val_loss: 0.9731 - val_accuracy: 0.7941\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3502 - accuracy: 0.9992 - val_loss: 0.9441 - val_accuracy: 0.7930\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3479 - accuracy: 0.9992 - val_loss: 0.9568 - val_accuracy: 0.8088\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3459 - accuracy: 0.9994 - val_loss: 0.9494 - val_accuracy: 0.7986\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3444 - accuracy: 0.9997 - val_loss: 0.9545 - val_accuracy: 0.7975\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3444 - accuracy: 0.9994 - val_loss: 0.9722 - val_accuracy: 0.7907\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3454 - accuracy: 0.9997 - val_loss: 0.9618 - val_accuracy: 0.7885\n","Epoch 42/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3429 - accuracy: 0.9994 - val_loss: 0.9700 - val_accuracy: 0.8054\n","Epoch 43/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3438 - accuracy: 0.9992 - val_loss: 0.9711 - val_accuracy: 0.7885\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3443 - accuracy: 0.9994 - val_loss: 0.9777 - val_accuracy: 0.7930\n","Epoch 45/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3397 - accuracy: 0.9997 - val_loss: 0.9825 - val_accuracy: 0.7896\n","Epoch 46/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3382 - accuracy: 1.0000 - val_loss: 0.9763 - val_accuracy: 0.7851\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3371 - accuracy: 0.9994 - val_loss: 0.9836 - val_accuracy: 0.7919\n","Epoch 48/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3402 - accuracy: 0.9986 - val_loss: 1.0579 - val_accuracy: 0.7738\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3438 - accuracy: 0.9986 - val_loss: 1.0043 - val_accuracy: 0.7805\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3377 - accuracy: 0.9986 - val_loss: 0.9962 - val_accuracy: 0.7873\n","Epoch 51/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3344 - accuracy: 1.0000 - val_loss: 1.0009 - val_accuracy: 0.7941\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3338 - accuracy: 0.9994 - val_loss: 1.0033 - val_accuracy: 0.7851\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3315 - accuracy: 1.0000 - val_loss: 0.9986 - val_accuracy: 0.7919\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3300 - accuracy: 1.0000 - val_loss: 1.0093 - val_accuracy: 0.7930\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3299 - accuracy: 0.9997 - val_loss: 1.0056 - val_accuracy: 0.7873\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3289 - accuracy: 1.0000 - val_loss: 1.0037 - val_accuracy: 0.7919\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3297 - accuracy: 0.9997 - val_loss: 1.0098 - val_accuracy: 0.7873\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3279 - accuracy: 1.0000 - val_loss: 1.0367 - val_accuracy: 0.7828\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3286 - accuracy: 0.9997 - val_loss: 1.0309 - val_accuracy: 0.7805\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3293 - accuracy: 0.9997 - val_loss: 1.0135 - val_accuracy: 0.7930\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3268 - accuracy: 1.0000 - val_loss: 1.0182 - val_accuracy: 0.7794\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3250 - accuracy: 1.0000 - val_loss: 1.0218 - val_accuracy: 0.7817\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3237 - accuracy: 1.0000 - val_loss: 1.0312 - val_accuracy: 0.7885\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3271 - accuracy: 0.9994 - val_loss: 1.0650 - val_accuracy: 0.7873\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3238 - accuracy: 0.9997 - val_loss: 1.0380 - val_accuracy: 0.7851\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3227 - accuracy: 1.0000 - val_loss: 1.0331 - val_accuracy: 0.7839\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3246 - accuracy: 0.9997 - val_loss: 1.0696 - val_accuracy: 0.7783\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3219 - accuracy: 1.0000 - val_loss: 1.0446 - val_accuracy: 0.7839\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3195 - accuracy: 1.0000 - val_loss: 1.0446 - val_accuracy: 0.7885\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3197 - accuracy: 1.0000 - val_loss: 1.0471 - val_accuracy: 0.7704\n","Epoch 71/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3199 - accuracy: 1.0000 - val_loss: 1.0477 - val_accuracy: 0.7726\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3172 - accuracy: 1.0000 - val_loss: 1.0444 - val_accuracy: 0.7817\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3168 - accuracy: 1.0000 - val_loss: 1.0456 - val_accuracy: 0.7749\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3160 - accuracy: 1.0000 - val_loss: 1.0503 - val_accuracy: 0.7817\n","Epoch 75/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3154 - accuracy: 1.0000 - val_loss: 1.0504 - val_accuracy: 0.7873\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3160 - accuracy: 1.0000 - val_loss: 1.0545 - val_accuracy: 0.7828\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3146 - accuracy: 1.0000 - val_loss: 1.0597 - val_accuracy: 0.7828\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3135 - accuracy: 1.0000 - val_loss: 1.0633 - val_accuracy: 0.7817\n","Epoch 79/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3129 - accuracy: 1.0000 - val_loss: 1.0589 - val_accuracy: 0.7749\n","Epoch 80/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3118 - accuracy: 1.0000 - val_loss: 1.0632 - val_accuracy: 0.7896\n","Epoch 81/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3118 - accuracy: 1.0000 - val_loss: 1.0605 - val_accuracy: 0.7726\n","Epoch 82/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3105 - accuracy: 1.0000 - val_loss: 1.0665 - val_accuracy: 0.7817\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3096 - accuracy: 1.0000 - val_loss: 1.0628 - val_accuracy: 0.7873\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3089 - accuracy: 1.0000 - val_loss: 1.0797 - val_accuracy: 0.7771\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3099 - accuracy: 1.0000 - val_loss: 1.0736 - val_accuracy: 0.7839\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3083 - accuracy: 1.0000 - val_loss: 1.0702 - val_accuracy: 0.7749\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3075 - accuracy: 1.0000 - val_loss: 1.0736 - val_accuracy: 0.7805\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3062 - accuracy: 1.0000 - val_loss: 1.0891 - val_accuracy: 0.7805\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3064 - accuracy: 1.0000 - val_loss: 1.0748 - val_accuracy: 0.7771\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3056 - accuracy: 1.0000 - val_loss: 1.0746 - val_accuracy: 0.7794\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3044 - accuracy: 1.0000 - val_loss: 1.0810 - val_accuracy: 0.7851\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3039 - accuracy: 1.0000 - val_loss: 1.0782 - val_accuracy: 0.7783\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3027 - accuracy: 1.0000 - val_loss: 1.0840 - val_accuracy: 0.7828\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3021 - accuracy: 1.0000 - val_loss: 1.0880 - val_accuracy: 0.7794\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3030 - accuracy: 1.0000 - val_loss: 1.1098 - val_accuracy: 0.7760\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3015 - accuracy: 1.0000 - val_loss: 1.1025 - val_accuracy: 0.7771\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3010 - accuracy: 1.0000 - val_loss: 1.0907 - val_accuracy: 0.7771\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2995 - accuracy: 1.0000 - val_loss: 1.0915 - val_accuracy: 0.7771\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2991 - accuracy: 1.0000 - val_loss: 1.1230 - val_accuracy: 0.7715\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3002 - accuracy: 1.0000 - val_loss: 1.0902 - val_accuracy: 0.7794\n","{'loss': [0.4597519338130951, 0.4368852972984314, 0.4254910349845886, 0.41348403692245483, 0.4181371033191681, 0.413286417722702, 0.4051707088947296, 0.3980703353881836, 0.3994239866733551, 0.40088123083114624, 0.38971105217933655, 0.3853534460067749, 0.3866184651851654, 0.38429298996925354, 0.37922802567481995, 0.37763649225234985, 0.375367671251297, 0.3740551173686981, 0.38244298100471497, 0.3744688630104065, 0.3679440915584564, 0.36992424726486206, 0.3670334815979004, 0.3696552515029907, 0.3617613613605499, 0.3597170114517212, 0.36030706763267517, 0.35941022634506226, 0.3575078248977661, 0.3564440906047821, 0.3527767062187195, 0.3523963987827301, 0.3531041443347931, 0.3509071171283722, 0.35090765357017517, 0.3502403199672699, 0.3479210436344147, 0.34589919447898865, 0.34444162249565125, 0.3443854749202728, 0.3454102575778961, 0.3428952693939209, 0.3438494801521301, 0.34425926208496094, 0.339714378118515, 0.33820000290870667, 0.3371340036392212, 0.34020236134529114, 0.3437706232070923, 0.3377416729927063, 0.33438271284103394, 0.33380261063575745, 0.3314749598503113, 0.3300243020057678, 0.3298642635345459, 0.3289392590522766, 0.32974010705947876, 0.3279230296611786, 0.3285757899284363, 0.3292786180973053, 0.32680028676986694, 0.32497966289520264, 0.32374605536460876, 0.32706910371780396, 0.3238314390182495, 0.3226874768733978, 0.32463234663009644, 0.3218722939491272, 0.3195169270038605, 0.3196556866168976, 0.31987395882606506, 0.31719204783439636, 0.31679004430770874, 0.31603893637657166, 0.31538522243499756, 0.3159637451171875, 0.3145557940006256, 0.31354621052742004, 0.31291452050209045, 0.3117569386959076, 0.31177496910095215, 0.31046369671821594, 0.30961742997169495, 0.3088664710521698, 0.3099413812160492, 0.30826589465141296, 0.3075234293937683, 0.30624404549598694, 0.3063904941082001, 0.30556538701057434, 0.30436182022094727, 0.3039018511772156, 0.30274608731269836, 0.3021223545074463, 0.30304044485092163, 0.30147236585617065, 0.30097708106040955, 0.2995232045650482, 0.2991321384906769, 0.3001735210418701], 'accuracy': [0.9533106684684753, 0.9651952385902405, 0.9717034697532654, 0.9790605306625366, 0.9731183052062988, 0.9736841917037964, 0.9813242554664612, 0.9872665405273438, 0.9852858185768127, 0.9813242554664612, 0.9912280440330505, 0.9923599362373352, 0.9900962114334106, 0.9900962114334106, 0.9949066042900085, 0.994340717792511, 0.9957554936408997, 0.9949066042900085, 0.9895302653312683, 0.9946236610412598, 0.9968873858451843, 0.9957554936408997, 0.996321439743042, 0.9957554936408997, 0.9971703290939331, 0.9991511106491089, 0.9988681674003601, 0.9988681674003601, 0.9980192184448242, 0.9985851645469666, 0.9997170567512512, 0.9997170567512512, 0.9985851645469666, 0.9991511106491089, 0.9988681674003601, 0.9991511106491089, 0.9991511106491089, 0.9994340538978577, 0.9997170567512512, 0.9994340538978577, 0.9997170567512512, 0.9994340538978577, 0.9991511106491089, 0.9994340538978577, 0.9997170567512512, 1.0, 0.9994340538978577, 0.9985851645469666, 0.9985851645469666, 0.9985851645469666, 1.0, 0.9994340538978577, 1.0, 1.0, 0.9997170567512512, 1.0, 0.9997170567512512, 1.0, 0.9997170567512512, 0.9997170567512512, 1.0, 1.0, 1.0, 0.9994340538978577, 0.9997170567512512, 1.0, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.9974924325942993, 0.9952908158302307, 0.9904414415359497, 0.9779388904571533, 0.9768894910812378, 0.9699379801750183, 0.9514201879501343, 0.9589645862579346, 0.9325705766677856, 0.9052549600601196, 0.8851497173309326, 0.8691712617874146, 0.8701484203338623, 0.8401150703430176, 0.8144928216934204, 0.8058888912200928, 0.7926913499832153, 0.7866894602775574, 0.7800000309944153, 0.7844340205192566, 0.7887625098228455, 0.8022011518478394, 0.8077402114868164, 0.8198833465576172, 0.8326258659362793, 0.8474512100219727, 0.8665609955787659, 0.8749101758003235, 0.9012016654014587, 0.900310754776001, 0.9233220219612122, 0.9323794841766357, 0.92279052734375, 0.9330710768699646, 0.9730738401412964, 0.9441291689872742, 0.9567957520484924, 0.9494035840034485, 0.9545110464096069, 0.9722259044647217, 0.9617982506752014, 0.9699951410293579, 0.9711368083953857, 0.9777109622955322, 0.9824836254119873, 0.9763326048851013, 0.9836348295211792, 1.0578523874282837, 1.004341959953308, 0.9961995482444763, 1.000944972038269, 1.0032849311828613, 0.9985673427581787, 1.0093203783035278, 1.0055896043777466, 1.003713846206665, 1.0098388195037842, 1.0366888046264648, 1.0308787822723389, 1.0134785175323486, 1.0181883573532104, 1.0217883586883545, 1.0311683416366577, 1.0649738311767578, 1.0380430221557617, 1.03314208984375, 1.0696460008621216, 1.0446209907531738, 1.0446462631225586, 1.047075867652893, 1.0477023124694824, 1.0443822145462036, 1.0455502271652222, 1.050326943397522, 1.050355076789856, 1.0545434951782227, 1.059692144393921, 1.06333589553833, 1.0588842630386353, 1.0632081031799316, 1.0605264902114868, 1.0665079355239868, 1.0628471374511719, 1.0796562433242798, 1.0736093521118164, 1.0701875686645508, 1.0736174583435059, 1.0890991687774658, 1.0747992992401123, 1.0746318101882935, 1.0809794664382935, 1.0781898498535156, 1.084012508392334, 1.0880309343338013, 1.1098464727401733, 1.1025338172912598, 1.090685486793518, 1.0914617776870728, 1.1229974031448364, 1.0902094841003418], 'val_accuracy': [0.557692289352417, 0.5622171759605408, 0.570135772228241, 0.5938913822174072, 0.5893664956092834, 0.5972850918769836, 0.6323529481887817, 0.6085972785949707, 0.6538461446762085, 0.6900452375411987, 0.7081447839736938, 0.720588207244873, 0.7160633206367493, 0.7466063499450684, 0.7748869061470032, 0.7748869061470032, 0.7861990928649902, 0.7884615659713745, 0.7997737526893616, 0.7963801026344299, 0.7986425161361694, 0.7963801026344299, 0.807692289352417, 0.8054298758506775, 0.8031674027442932, 0.8054298758506775, 0.8065611124038696, 0.8110859990119934, 0.7929864525794983, 0.7975113391876221, 0.7997737526893616, 0.7929864525794983, 0.7997737526893616, 0.8020362257957458, 0.7941176295280457, 0.7929864525794983, 0.8088235259056091, 0.7986425161361694, 0.7975113391876221, 0.790723979473114, 0.7884615659713745, 0.8054298758506775, 0.7884615659713745, 0.7929864525794983, 0.7895927429199219, 0.7850678563117981, 0.7918552160263062, 0.773755669593811, 0.7805429697036743, 0.7873303294181824, 0.7941176295280457, 0.7850678563117981, 0.7918552160263062, 0.7929864525794983, 0.7873303294181824, 0.7918552160263062, 0.7873303294181824, 0.7828054428100586, 0.7805429697036743, 0.7929864525794983, 0.779411792755127, 0.7816742062568665, 0.7884615659713745, 0.7873303294181824, 0.7850678563117981, 0.7839366793632507, 0.7782805562019348, 0.7839366793632507, 0.7884615659713745, 0.7703620195388794, 0.7726244330406189, 0.7816742062568665, 0.7748869061470032, 0.7816742062568665, 0.7873303294181824, 0.7828054428100586, 0.7828054428100586, 0.7816742062568665, 0.7748869061470032, 0.7895927429199219, 0.7726244330406189, 0.7816742062568665, 0.7873303294181824, 0.7771493196487427, 0.7839366793632507, 0.7748869061470032, 0.7805429697036743, 0.7805429697036743, 0.7771493196487427, 0.779411792755127, 0.7850678563117981, 0.7782805562019348, 0.7828054428100586, 0.779411792755127, 0.7760180830955505, 0.7771493196487427, 0.7771493196487427, 0.7771493196487427, 0.7714931964874268, 0.779411792755127]}\n","45/45 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 5s 32ms/step - loss: 0.4941 - accuracy: 0.9367 - val_loss: 1.0157 - val_accuracy: 0.5227\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.4931 - accuracy: 0.9219"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 21ms/step - loss: 0.4564 - accuracy: 0.9550 - val_loss: 1.0049 - val_accuracy: 0.5506\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4404 - accuracy: 0.9623 - val_loss: 1.0010 - val_accuracy: 0.5630\n","Epoch 4/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4325 - accuracy: 0.9690 - val_loss: 1.0033 - val_accuracy: 0.5579\n","Epoch 5/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4249 - accuracy: 0.9724 - val_loss: 0.9872 - val_accuracy: 0.5878\n","Epoch 6/100\n","31/31 [==============================] - 1s 35ms/step - loss: 0.4181 - accuracy: 0.9744 - val_loss: 0.9740 - val_accuracy: 0.6085\n","Epoch 7/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4176 - accuracy: 0.9765 - val_loss: 0.9759 - val_accuracy: 0.5930\n","Epoch 8/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4149 - accuracy: 0.9739 - val_loss: 0.9661 - val_accuracy: 0.6033\n","Epoch 9/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4040 - accuracy: 0.9837 - val_loss: 0.9467 - val_accuracy: 0.6343\n","Epoch 10/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4035 - accuracy: 0.9822 - val_loss: 0.9314 - val_accuracy: 0.6612\n","Epoch 11/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3982 - accuracy: 0.9863 - val_loss: 0.9158 - val_accuracy: 0.6932\n","Epoch 12/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3974 - accuracy: 0.9860 - val_loss: 0.8985 - val_accuracy: 0.7087\n","Epoch 13/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3989 - accuracy: 0.9853 - val_loss: 0.8899 - val_accuracy: 0.7211\n","Epoch 14/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3908 - accuracy: 0.9879 - val_loss: 0.9102 - val_accuracy: 0.6994\n","Epoch 15/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3908 - accuracy: 0.9881 - val_loss: 0.8851 - val_accuracy: 0.7304\n","Epoch 16/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3889 - accuracy: 0.9894 - val_loss: 0.9305 - val_accuracy: 0.6973\n","Epoch 17/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3915 - accuracy: 0.9884 - val_loss: 0.8981 - val_accuracy: 0.7397\n","Epoch 18/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3843 - accuracy: 0.9907 - val_loss: 0.9077 - val_accuracy: 0.7438\n","Epoch 19/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3849 - accuracy: 0.9891 - val_loss: 0.9229 - val_accuracy: 0.7459\n","Epoch 20/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3808 - accuracy: 0.9935 - val_loss: 0.9419 - val_accuracy: 0.7500\n","Epoch 21/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3773 - accuracy: 0.9938 - val_loss: 0.9736 - val_accuracy: 0.7500\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3835 - accuracy: 0.9897 - val_loss: 1.0469 - val_accuracy: 0.7273\n","Epoch 23/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3774 - accuracy: 0.9925 - val_loss: 1.1079 - val_accuracy: 0.7138\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3793 - accuracy: 0.9910 - val_loss: 1.0700 - val_accuracy: 0.7459\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3715 - accuracy: 0.9935 - val_loss: 1.0907 - val_accuracy: 0.7469\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3695 - accuracy: 0.9956 - val_loss: 1.1291 - val_accuracy: 0.7335\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3757 - accuracy: 0.9910 - val_loss: 1.1283 - val_accuracy: 0.7500\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3672 - accuracy: 0.9938 - val_loss: 1.1805 - val_accuracy: 0.7283\n","Epoch 29/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3650 - accuracy: 0.9948 - val_loss: 1.1725 - val_accuracy: 0.7407\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3637 - accuracy: 0.9972 - val_loss: 1.1708 - val_accuracy: 0.7438\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3624 - accuracy: 0.9969 - val_loss: 1.1903 - val_accuracy: 0.7355\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3620 - accuracy: 0.9961 - val_loss: 1.1953 - val_accuracy: 0.7448\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3621 - accuracy: 0.9961 - val_loss: 1.2296 - val_accuracy: 0.7397\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3676 - accuracy: 0.9928 - val_loss: 1.2370 - val_accuracy: 0.7262\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3839 - accuracy: 0.9817 - val_loss: 1.2754 - val_accuracy: 0.7180\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3591 - accuracy: 0.9951 - val_loss: 1.2242 - val_accuracy: 0.7324\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3541 - accuracy: 0.9972 - val_loss: 1.2099 - val_accuracy: 0.7386\n","Epoch 38/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3550 - accuracy: 0.9964 - val_loss: 1.2243 - val_accuracy: 0.7366\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3508 - accuracy: 0.9974 - val_loss: 1.2619 - val_accuracy: 0.7293\n","Epoch 40/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3536 - accuracy: 0.9964 - val_loss: 1.3734 - val_accuracy: 0.7035\n","Epoch 41/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3694 - accuracy: 0.9904 - val_loss: 1.2453 - val_accuracy: 0.7335\n","Epoch 42/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3502 - accuracy: 0.9974 - val_loss: 1.2481 - val_accuracy: 0.7366\n","Epoch 43/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3512 - accuracy: 0.9964 - val_loss: 1.2392 - val_accuracy: 0.7417\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3478 - accuracy: 0.9982 - val_loss: 1.2399 - val_accuracy: 0.7407\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3502 - accuracy: 0.9959 - val_loss: 1.2436 - val_accuracy: 0.7366\n","Epoch 46/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3464 - accuracy: 0.9987 - val_loss: 1.2618 - val_accuracy: 0.7314\n","Epoch 47/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3438 - accuracy: 0.9979 - val_loss: 1.2587 - val_accuracy: 0.7283\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3438 - accuracy: 0.9987 - val_loss: 1.2535 - val_accuracy: 0.7386\n","Epoch 49/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3472 - accuracy: 0.9979 - val_loss: 1.2478 - val_accuracy: 0.7376\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3411 - accuracy: 0.9995 - val_loss: 1.2577 - val_accuracy: 0.7397\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3409 - accuracy: 0.9992 - val_loss: 1.2631 - val_accuracy: 0.7417\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3391 - accuracy: 0.9997 - val_loss: 1.2585 - val_accuracy: 0.7366\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3383 - accuracy: 0.9984 - val_loss: 1.2847 - val_accuracy: 0.7283\n","Epoch 54/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3374 - accuracy: 0.9990 - val_loss: 1.2657 - val_accuracy: 0.7304\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3368 - accuracy: 0.9990 - val_loss: 1.3190 - val_accuracy: 0.7304\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3383 - accuracy: 0.9984 - val_loss: 1.3855 - val_accuracy: 0.7097\n","Epoch 57/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3374 - accuracy: 0.9982 - val_loss: 1.2720 - val_accuracy: 0.7376\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3339 - accuracy: 0.9990 - val_loss: 1.2948 - val_accuracy: 0.7407\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3436 - accuracy: 0.9964 - val_loss: 1.3256 - val_accuracy: 0.7314\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3374 - accuracy: 0.9974 - val_loss: 1.2920 - val_accuracy: 0.7366\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3326 - accuracy: 0.9990 - val_loss: 1.2892 - val_accuracy: 0.7417\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3336 - accuracy: 0.9982 - val_loss: 1.2830 - val_accuracy: 0.7417\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3367 - accuracy: 0.9974 - val_loss: 1.2915 - val_accuracy: 0.7293\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3298 - accuracy: 0.9992 - val_loss: 1.3250 - val_accuracy: 0.7273\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3307 - accuracy: 0.9987 - val_loss: 1.3095 - val_accuracy: 0.7314\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3291 - accuracy: 0.9990 - val_loss: 1.3079 - val_accuracy: 0.7366\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3274 - accuracy: 0.9997 - val_loss: 1.3363 - val_accuracy: 0.7242\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3263 - accuracy: 0.9997 - val_loss: 1.3179 - val_accuracy: 0.7366\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3261 - accuracy: 0.9992 - val_loss: 1.3123 - val_accuracy: 0.7366\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3253 - accuracy: 0.9995 - val_loss: 1.3128 - val_accuracy: 0.7335\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3250 - accuracy: 0.9990 - val_loss: 1.3592 - val_accuracy: 0.7314\n","Epoch 72/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3246 - accuracy: 0.9995 - val_loss: 1.3405 - val_accuracy: 0.7273\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3237 - accuracy: 0.9995 - val_loss: 1.3243 - val_accuracy: 0.7397\n","Epoch 74/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3217 - accuracy: 0.9997 - val_loss: 1.3287 - val_accuracy: 0.7283\n","Epoch 75/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3209 - accuracy: 1.0000 - val_loss: 1.3386 - val_accuracy: 0.7345\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3201 - accuracy: 1.0000 - val_loss: 1.3309 - val_accuracy: 0.7407\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3217 - accuracy: 0.9995 - val_loss: 1.3750 - val_accuracy: 0.7200\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3201 - accuracy: 1.0000 - val_loss: 1.3417 - val_accuracy: 0.7386\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3200 - accuracy: 0.9995 - val_loss: 1.3418 - val_accuracy: 0.7335\n","Epoch 80/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3189 - accuracy: 0.9992 - val_loss: 1.3466 - val_accuracy: 0.7262\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3190 - accuracy: 0.9992 - val_loss: 1.3490 - val_accuracy: 0.7366\n","Epoch 82/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3198 - accuracy: 0.9992 - val_loss: 1.3529 - val_accuracy: 0.7376\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3179 - accuracy: 0.9997 - val_loss: 1.4014 - val_accuracy: 0.7200\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3200 - accuracy: 0.9974 - val_loss: 1.3960 - val_accuracy: 0.7221\n","Epoch 85/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3170 - accuracy: 0.9992 - val_loss: 1.4426 - val_accuracy: 0.7118\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3198 - accuracy: 0.9992 - val_loss: 1.3820 - val_accuracy: 0.7283\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3167 - accuracy: 1.0000 - val_loss: 1.4035 - val_accuracy: 0.7211\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3125 - accuracy: 1.0000 - val_loss: 1.3818 - val_accuracy: 0.7273\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3113 - accuracy: 1.0000 - val_loss: 1.3715 - val_accuracy: 0.7283\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3106 - accuracy: 1.0000 - val_loss: 1.3683 - val_accuracy: 0.7324\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3098 - accuracy: 1.0000 - val_loss: 1.4003 - val_accuracy: 0.7221\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3101 - accuracy: 1.0000 - val_loss: 1.4258 - val_accuracy: 0.7221\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3098 - accuracy: 1.0000 - val_loss: 1.3828 - val_accuracy: 0.7366\n","Epoch 94/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3112 - accuracy: 1.0000 - val_loss: 1.4004 - val_accuracy: 0.7335\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3111 - accuracy: 0.9992 - val_loss: 1.3944 - val_accuracy: 0.7242\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3074 - accuracy: 1.0000 - val_loss: 1.3840 - val_accuracy: 0.7304\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3066 - accuracy: 1.0000 - val_loss: 1.4016 - val_accuracy: 0.7314\n","Epoch 98/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3058 - accuracy: 1.0000 - val_loss: 1.4126 - val_accuracy: 0.7252\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3074 - accuracy: 0.9997 - val_loss: 1.4559 - val_accuracy: 0.7200\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3055 - accuracy: 1.0000 - val_loss: 1.3900 - val_accuracy: 0.7335\n","{'loss': [0.4941316843032837, 0.45638740062713623, 0.4403524100780487, 0.43253961205482483, 0.4248960316181183, 0.4181217849254608, 0.41762781143188477, 0.41487258672714233, 0.4040166139602661, 0.403548926115036, 0.3982418179512024, 0.3974103331565857, 0.3988732099533081, 0.3908033072948456, 0.39082878828048706, 0.38890692591667175, 0.3915039598941803, 0.3843124806880951, 0.3848752975463867, 0.38084495067596436, 0.37728801369667053, 0.3834742307662964, 0.37738317251205444, 0.37925398349761963, 0.3714985251426697, 0.36952894926071167, 0.37571337819099426, 0.36717742681503296, 0.36499086022377014, 0.36369556188583374, 0.36241284012794495, 0.3620254695415497, 0.36214134097099304, 0.36759185791015625, 0.3838956952095032, 0.35910001397132874, 0.35405316948890686, 0.3549535870552063, 0.35079917311668396, 0.35359448194503784, 0.36939409375190735, 0.3502136766910553, 0.351205974817276, 0.3478483557701111, 0.3502400517463684, 0.3463665246963501, 0.3438134491443634, 0.3437905013561249, 0.3472018837928772, 0.3411291241645813, 0.3408926725387573, 0.3390730619430542, 0.33833643794059753, 0.33735132217407227, 0.33678004145622253, 0.3382921516895294, 0.33735164999961853, 0.33389681577682495, 0.34359753131866455, 0.3373793363571167, 0.33255666494369507, 0.3336094617843628, 0.33674511313438416, 0.3297598659992218, 0.3306678235530853, 0.3291259706020355, 0.32742369174957275, 0.3263190984725952, 0.32609593868255615, 0.32529330253601074, 0.32500699162483215, 0.32459694147109985, 0.3236546814441681, 0.32165634632110596, 0.32090696692466736, 0.3201405107975006, 0.32170212268829346, 0.32006001472473145, 0.3199591636657715, 0.3188874125480652, 0.31904008984565735, 0.31976065039634705, 0.3179265558719635, 0.3199847638607025, 0.3169540762901306, 0.3197513818740845, 0.3167143762111664, 0.31253939867019653, 0.31126439571380615, 0.31061264872550964, 0.30975696444511414, 0.310075968503952, 0.30983269214630127, 0.3112412691116333, 0.3111189305782318, 0.30736613273620605, 0.30657312273979187, 0.30578306317329407, 0.3074434697628021, 0.30551737546920776], 'accuracy': [0.9366925358772278, 0.9550387859344482, 0.962273895740509, 0.9689922332763672, 0.9723514318466187, 0.974418580532074, 0.9764857888221741, 0.9739018082618713, 0.9837209582328796, 0.9821705222129822, 0.9863049387931824, 0.9860464930534363, 0.9852713346481323, 0.9878553152084351, 0.9881137013435364, 0.9894056916236877, 0.9883720874786377, 0.9906976819038391, 0.9891473054885864, 0.9935400485992432, 0.9937984347343445, 0.9896640777587891, 0.9925064444541931, 0.9909560680389404, 0.9935400485992432, 0.9956072568893433, 0.9909560680389404, 0.9937984347343445, 0.9948320388793945, 0.997157633304596, 0.9968992471694946, 0.9961240291595459, 0.9961240291595459, 0.9927648305892944, 0.9816537499427795, 0.9950904250144958, 0.997157633304596, 0.9963824152946472, 0.9974160194396973, 0.9963824152946472, 0.9904392957687378, 0.9974160194396973, 0.9963824152946472, 0.998191237449646, 0.9958656430244446, 0.9987080097198486, 0.9979327917098999, 0.9987080097198486, 0.9979327917098999, 0.9994832277297974, 0.9992247819900513, 0.9997416138648987, 0.9984496235847473, 0.99896639585495, 0.99896639585495, 0.9984496235847473, 0.998191237449646, 0.99896639585495, 0.9963824152946472, 0.9974160194396973, 0.99896639585495, 0.998191237449646, 0.9974160194396973, 0.9992247819900513, 0.9987080097198486, 0.99896639585495, 0.9997416138648987, 0.9997416138648987, 0.9992247819900513, 0.9994832277297974, 0.99896639585495, 0.9994832277297974, 0.9994832277297974, 0.9997416138648987, 1.0, 1.0, 0.9994832277297974, 1.0, 0.9994832277297974, 0.9992247819900513, 0.9992247819900513, 0.9992247819900513, 0.9997416138648987, 0.9974160194396973, 0.9992247819900513, 0.9992247819900513, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9992247819900513, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0], 'val_loss': [1.015702247619629, 1.0049165487289429, 1.0009799003601074, 1.003335952758789, 0.9872334599494934, 0.9739589095115662, 0.9759196043014526, 0.96611487865448, 0.9467385411262512, 0.9313729405403137, 0.9158036708831787, 0.8984562158584595, 0.8898607492446899, 0.910166323184967, 0.8850993514060974, 0.9305066466331482, 0.8980703949928284, 0.9077205657958984, 0.9228700995445251, 0.9418962001800537, 0.9735643267631531, 1.0468690395355225, 1.1078649759292603, 1.0699734687805176, 1.0906881093978882, 1.1290719509124756, 1.1283252239227295, 1.1805472373962402, 1.1725411415100098, 1.170822262763977, 1.1903473138809204, 1.1953331232070923, 1.229647159576416, 1.237046241760254, 1.275442361831665, 1.2242200374603271, 1.209925651550293, 1.2242692708969116, 1.2618739604949951, 1.3733962774276733, 1.2453291416168213, 1.2481075525283813, 1.2392449378967285, 1.2399293184280396, 1.2435702085494995, 1.2618329524993896, 1.2587016820907593, 1.2535327672958374, 1.2477896213531494, 1.2577122449874878, 1.263132095336914, 1.258528470993042, 1.284687876701355, 1.2657420635223389, 1.3189775943756104, 1.3855286836624146, 1.2720376253128052, 1.2947872877120972, 1.3256086111068726, 1.2920125722885132, 1.2892193794250488, 1.2829632759094238, 1.2914997339248657, 1.3249989748001099, 1.3095346689224243, 1.30794095993042, 1.3362599611282349, 1.3178949356079102, 1.3122979402542114, 1.3128092288970947, 1.359182596206665, 1.340450406074524, 1.3242720365524292, 1.328726053237915, 1.3386427164077759, 1.3308671712875366, 1.3750007152557373, 1.341732144355774, 1.3417888879776, 1.3465663194656372, 1.3490231037139893, 1.3529359102249146, 1.4013572931289673, 1.3960448503494263, 1.4425956010818481, 1.3819611072540283, 1.403487205505371, 1.381750464439392, 1.371492862701416, 1.368294596672058, 1.4002701044082642, 1.4257681369781494, 1.3827823400497437, 1.4003887176513672, 1.3944392204284668, 1.3839542865753174, 1.4016133546829224, 1.4126124382019043, 1.4558707475662231, 1.390032172203064], 'val_accuracy': [0.5227272510528564, 0.5506198406219482, 0.5630165338516235, 0.557851254940033, 0.5878099203109741, 0.6084710955619812, 0.5929751992225647, 0.6033057570457458, 0.6342975497245789, 0.6611570119857788, 0.6931818127632141, 0.7086777091026306, 0.7210744023323059, 0.6993801593780518, 0.73037189245224, 0.6973140239715576, 0.7396694421768188, 0.7438016533851624, 0.7458677887916565, 0.75, 0.75, 0.7272727489471436, 0.7138429880142212, 0.7458677887916565, 0.7469007968902588, 0.7334710955619812, 0.75, 0.7283057570457458, 0.7407024502754211, 0.7438016533851624, 0.7355371713638306, 0.7448347210884094, 0.7396694421768188, 0.7262396812438965, 0.7179751992225647, 0.7324380278587341, 0.7386363744735718, 0.7365702390670776, 0.7293388247489929, 0.7035123705863953, 0.7334710955619812, 0.7365702390670776, 0.7417355179786682, 0.7407024502754211, 0.7365702390670776, 0.7314049601554871, 0.7283057570457458, 0.7386363744735718, 0.7376033067703247, 0.7396694421768188, 0.7417355179786682, 0.7365702390670776, 0.7283057570457458, 0.73037189245224, 0.73037189245224, 0.7097107172012329, 0.7376033067703247, 0.7407024502754211, 0.7314049601554871, 0.7365702390670776, 0.7417355179786682, 0.7417355179786682, 0.7293388247489929, 0.7272727489471436, 0.7314049601554871, 0.7365702390670776, 0.7241735458374023, 0.7365702390670776, 0.7365702390670776, 0.7334710955619812, 0.7314049601554871, 0.7272727489471436, 0.7396694421768188, 0.7283057570457458, 0.7345041036605835, 0.7407024502754211, 0.7200413346290588, 0.7386363744735718, 0.7334710955619812, 0.7262396812438965, 0.7365702390670776, 0.7376033067703247, 0.7200413346290588, 0.7221074104309082, 0.711776852607727, 0.7283057570457458, 0.7210744023323059, 0.7272727489471436, 0.7283057570457458, 0.7324380278587341, 0.7221074104309082, 0.7221074104309082, 0.7365702390670776, 0.7334710955619812, 0.7241735458374023, 0.73037189245224, 0.7314049601554871, 0.7252066135406494, 0.7200413346290588, 0.7334710955619812]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.3869 - accuracy: 0.9696"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 4s 35ms/step - loss: 0.3865 - accuracy: 0.9690 - val_loss: 0.9788 - val_accuracy: 0.5226\n","Epoch 2/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3541 - accuracy: 0.9814 - val_loss: 0.9715 - val_accuracy: 0.5388\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3397 - accuracy: 0.9881 - val_loss: 0.9679 - val_accuracy: 0.5442\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3280 - accuracy: 0.9938 - val_loss: 0.9608 - val_accuracy: 0.5614\n","Epoch 5/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3233 - accuracy: 0.9954 - val_loss: 0.9445 - val_accuracy: 0.5894\n","Epoch 6/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3199 - accuracy: 0.9965 - val_loss: 0.9427 - val_accuracy: 0.5905\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3212 - accuracy: 0.9965 - val_loss: 0.9110 - val_accuracy: 0.6390\n","Epoch 8/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3174 - accuracy: 0.9976 - val_loss: 0.9033 - val_accuracy: 0.6466\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3133 - accuracy: 0.9995 - val_loss: 0.8956 - val_accuracy: 0.6584\n","Epoch 10/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3135 - accuracy: 0.9981 - val_loss: 0.8636 - val_accuracy: 0.6961\n","Epoch 11/100\n","29/29 [==============================] - 3s 89ms/step - loss: 0.3119 - accuracy: 0.9992 - val_loss: 0.8292 - val_accuracy: 0.7295\n","Epoch 12/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3112 - accuracy: 0.9995 - val_loss: 0.8152 - val_accuracy: 0.7392\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3087 - accuracy: 1.0000 - val_loss: 0.7841 - val_accuracy: 0.7780\n","Epoch 14/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3098 - accuracy: 0.9992 - val_loss: 0.7646 - val_accuracy: 0.7931\n","Epoch 15/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3083 - accuracy: 0.9995 - val_loss: 0.7860 - val_accuracy: 0.7662\n","Epoch 16/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3123 - accuracy: 0.9987 - val_loss: 0.7355 - val_accuracy: 0.8071\n","Epoch 17/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3097 - accuracy: 0.9987 - val_loss: 0.7300 - val_accuracy: 0.8103\n","Epoch 18/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3072 - accuracy: 0.9989 - val_loss: 0.7694 - val_accuracy: 0.8028\n","Epoch 19/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3046 - accuracy: 0.9997 - val_loss: 0.7527 - val_accuracy: 0.8050\n","Epoch 20/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3070 - accuracy: 0.9992 - val_loss: 0.7916 - val_accuracy: 0.8093\n","Epoch 21/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3056 - accuracy: 1.0000 - val_loss: 0.7505 - val_accuracy: 0.8190\n","Epoch 22/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3019 - accuracy: 1.0000 - val_loss: 0.7612 - val_accuracy: 0.8233\n","Epoch 23/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3008 - accuracy: 1.0000 - val_loss: 0.7782 - val_accuracy: 0.8265\n","Epoch 24/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3009 - accuracy: 0.9995 - val_loss: 0.7905 - val_accuracy: 0.8244\n","Epoch 25/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3005 - accuracy: 1.0000 - val_loss: 0.8233 - val_accuracy: 0.8287\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3030 - accuracy: 0.9995 - val_loss: 0.8808 - val_accuracy: 0.8082\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3023 - accuracy: 0.9997 - val_loss: 0.8524 - val_accuracy: 0.8222\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2985 - accuracy: 1.0000 - val_loss: 0.8545 - val_accuracy: 0.8244\n","Epoch 29/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2974 - accuracy: 1.0000 - val_loss: 0.8737 - val_accuracy: 0.8244\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2962 - accuracy: 1.0000 - val_loss: 0.8753 - val_accuracy: 0.8276\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2958 - accuracy: 1.0000 - val_loss: 0.8846 - val_accuracy: 0.8254\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2948 - accuracy: 1.0000 - val_loss: 0.8884 - val_accuracy: 0.8276\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2946 - accuracy: 1.0000 - val_loss: 0.9020 - val_accuracy: 0.8200\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2944 - accuracy: 0.9997 - val_loss: 0.9105 - val_accuracy: 0.8233\n","Epoch 35/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2940 - accuracy: 1.0000 - val_loss: 0.9300 - val_accuracy: 0.8244\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2949 - accuracy: 1.0000 - val_loss: 0.9494 - val_accuracy: 0.8244\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2940 - accuracy: 1.0000 - val_loss: 0.9171 - val_accuracy: 0.8254\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2917 - accuracy: 1.0000 - val_loss: 0.9237 - val_accuracy: 0.8222\n","Epoch 39/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2910 - accuracy: 1.0000 - val_loss: 0.9251 - val_accuracy: 0.8179\n","Epoch 40/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2903 - accuracy: 1.0000 - val_loss: 0.9185 - val_accuracy: 0.8200\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2914 - accuracy: 1.0000 - val_loss: 0.9251 - val_accuracy: 0.8179\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2892 - accuracy: 1.0000 - val_loss: 0.9416 - val_accuracy: 0.8190\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2882 - accuracy: 1.0000 - val_loss: 0.9325 - val_accuracy: 0.8244\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2879 - accuracy: 1.0000 - val_loss: 0.9348 - val_accuracy: 0.8147\n","Epoch 45/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2872 - accuracy: 1.0000 - val_loss: 0.9337 - val_accuracy: 0.8136\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2867 - accuracy: 1.0000 - val_loss: 0.9347 - val_accuracy: 0.8168\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2859 - accuracy: 1.0000 - val_loss: 0.9322 - val_accuracy: 0.8222\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2849 - accuracy: 1.0000 - val_loss: 0.9366 - val_accuracy: 0.8179\n","Epoch 49/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2846 - accuracy: 1.0000 - val_loss: 0.9576 - val_accuracy: 0.8168\n","Epoch 50/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2838 - accuracy: 1.0000 - val_loss: 0.9410 - val_accuracy: 0.8190\n","Epoch 51/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2839 - accuracy: 1.0000 - val_loss: 0.9451 - val_accuracy: 0.8147\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2827 - accuracy: 1.0000 - val_loss: 0.9422 - val_accuracy: 0.8147\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2822 - accuracy: 1.0000 - val_loss: 0.9430 - val_accuracy: 0.8125\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2831 - accuracy: 1.0000 - val_loss: 0.9570 - val_accuracy: 0.8147\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2866 - accuracy: 0.9995 - val_loss: 1.0174 - val_accuracy: 0.7974\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2835 - accuracy: 0.9997 - val_loss: 0.9479 - val_accuracy: 0.8147\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2800 - accuracy: 1.0000 - val_loss: 0.9468 - val_accuracy: 0.8125\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2792 - accuracy: 1.0000 - val_loss: 0.9604 - val_accuracy: 0.8114\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2788 - accuracy: 1.0000 - val_loss: 0.9477 - val_accuracy: 0.8136\n","Epoch 60/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2787 - accuracy: 1.0000 - val_loss: 0.9418 - val_accuracy: 0.8157\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2783 - accuracy: 1.0000 - val_loss: 0.9487 - val_accuracy: 0.8114\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2769 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.8179\n","Epoch 63/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2763 - accuracy: 1.0000 - val_loss: 0.9526 - val_accuracy: 0.8136\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2763 - accuracy: 1.0000 - val_loss: 0.9646 - val_accuracy: 0.8179\n","Epoch 65/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2748 - accuracy: 1.0000 - val_loss: 0.9567 - val_accuracy: 0.8103\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2740 - accuracy: 1.0000 - val_loss: 0.9690 - val_accuracy: 0.8157\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2738 - accuracy: 1.0000 - val_loss: 0.9546 - val_accuracy: 0.8136\n","Epoch 68/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2733 - accuracy: 1.0000 - val_loss: 0.9579 - val_accuracy: 0.8136\n","Epoch 69/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2726 - accuracy: 1.0000 - val_loss: 0.9615 - val_accuracy: 0.8082\n","Epoch 70/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2714 - accuracy: 1.0000 - val_loss: 0.9537 - val_accuracy: 0.8136\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2710 - accuracy: 1.0000 - val_loss: 0.9637 - val_accuracy: 0.8147\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2707 - accuracy: 1.0000 - val_loss: 0.9638 - val_accuracy: 0.8071\n","Epoch 73/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2705 - accuracy: 1.0000 - val_loss: 0.9740 - val_accuracy: 0.8093\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2695 - accuracy: 1.0000 - val_loss: 0.9597 - val_accuracy: 0.8136\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2685 - accuracy: 1.0000 - val_loss: 0.9554 - val_accuracy: 0.8114\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2677 - accuracy: 1.0000 - val_loss: 0.9897 - val_accuracy: 0.8125\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2673 - accuracy: 1.0000 - val_loss: 0.9594 - val_accuracy: 0.8103\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2668 - accuracy: 1.0000 - val_loss: 0.9708 - val_accuracy: 0.8179\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2656 - accuracy: 1.0000 - val_loss: 0.9593 - val_accuracy: 0.8082\n","Epoch 80/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2649 - accuracy: 1.0000 - val_loss: 0.9707 - val_accuracy: 0.8103\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2645 - accuracy: 1.0000 - val_loss: 0.9988 - val_accuracy: 0.8125\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2643 - accuracy: 1.0000 - val_loss: 0.9664 - val_accuracy: 0.8071\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2631 - accuracy: 1.0000 - val_loss: 0.9706 - val_accuracy: 0.8071\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2622 - accuracy: 1.0000 - val_loss: 0.9652 - val_accuracy: 0.8071\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2616 - accuracy: 1.0000 - val_loss: 0.9829 - val_accuracy: 0.8125\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2609 - accuracy: 1.0000 - val_loss: 0.9837 - val_accuracy: 0.8103\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2602 - accuracy: 1.0000 - val_loss: 0.9679 - val_accuracy: 0.8039\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2595 - accuracy: 1.0000 - val_loss: 0.9700 - val_accuracy: 0.8071\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2593 - accuracy: 1.0000 - val_loss: 0.9742 - val_accuracy: 0.8093\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2590 - accuracy: 1.0000 - val_loss: 0.9661 - val_accuracy: 0.8093\n","Epoch 91/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2577 - accuracy: 1.0000 - val_loss: 0.9862 - val_accuracy: 0.8060\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2571 - accuracy: 1.0000 - val_loss: 0.9670 - val_accuracy: 0.8093\n","Epoch 93/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2561 - accuracy: 1.0000 - val_loss: 0.9695 - val_accuracy: 0.8060\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2564 - accuracy: 1.0000 - val_loss: 0.9658 - val_accuracy: 0.8071\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2547 - accuracy: 1.0000 - val_loss: 0.9796 - val_accuracy: 0.8093\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2543 - accuracy: 1.0000 - val_loss: 0.9920 - val_accuracy: 0.8071\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2544 - accuracy: 1.0000 - val_loss: 0.9825 - val_accuracy: 0.8039\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2539 - accuracy: 1.0000 - val_loss: 1.0072 - val_accuracy: 0.8060\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2531 - accuracy: 1.0000 - val_loss: 0.9933 - val_accuracy: 0.8082\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2526 - accuracy: 1.0000 - val_loss: 0.9760 - val_accuracy: 0.8039\n","{'loss': [0.3865187466144562, 0.3540513813495636, 0.3397347331047058, 0.3279520571231842, 0.32334649562835693, 0.3199456036090851, 0.3212146759033203, 0.3174033761024475, 0.3132970333099365, 0.3134947419166565, 0.3118772506713867, 0.31120550632476807, 0.3087001144886017, 0.3098274767398834, 0.3083014190196991, 0.3122703731060028, 0.309679239988327, 0.30722934007644653, 0.3046276271343231, 0.3070145845413208, 0.30562859773635864, 0.30187705159187317, 0.30083951354026794, 0.30086857080459595, 0.30054089426994324, 0.3029523491859436, 0.30231547355651855, 0.29853206872940063, 0.29744720458984375, 0.2961997091770172, 0.2958316504955292, 0.29480013251304626, 0.294554203748703, 0.29439955949783325, 0.2940019369125366, 0.29487279057502747, 0.2940010130405426, 0.29173970222473145, 0.2910354733467102, 0.29032379388809204, 0.29135969281196594, 0.2892182469367981, 0.2881629467010498, 0.28790122270584106, 0.28720176219940186, 0.2866608798503876, 0.28594401478767395, 0.2849091589450836, 0.2846451997756958, 0.28380653262138367, 0.2838839888572693, 0.28273749351501465, 0.282166451215744, 0.28312456607818604, 0.2865620255470276, 0.28348976373672485, 0.2799912691116333, 0.2792062759399414, 0.2788175046443939, 0.27874505519866943, 0.278274267911911, 0.2768884301185608, 0.2763138711452484, 0.2763063907623291, 0.27482420206069946, 0.27403903007507324, 0.2738465368747711, 0.2732789218425751, 0.2725537419319153, 0.27138766646385193, 0.27101990580558777, 0.27065563201904297, 0.2704829275608063, 0.2695421278476715, 0.2684883773326874, 0.267678439617157, 0.26732179522514343, 0.2667960524559021, 0.2656150162220001, 0.26485228538513184, 0.2645258605480194, 0.2642928957939148, 0.263064980506897, 0.262187123298645, 0.26164281368255615, 0.2609480321407318, 0.2601774036884308, 0.25954514741897583, 0.2593309283256531, 0.25897282361984253, 0.25769832730293274, 0.2570541799068451, 0.25607830286026, 0.25642457604408264, 0.25468578934669495, 0.2543165385723114, 0.2544345557689667, 0.25392085313796997, 0.2530710697174072, 0.2525683343410492], 'accuracy': [0.9690194129943848, 0.9814116358757019, 0.9881465435028076, 0.993803858757019, 0.9954202771186829, 0.9964978694915771, 0.9964978694915771, 0.9975754022598267, 0.9994612336158752, 0.9981142282485962, 0.9991918206214905, 0.9994612336158752, 1.0, 0.9991918206214905, 0.9994612336158752, 0.998652994632721, 0.998652994632721, 0.9989224076271057, 0.9997305870056152, 0.9991918206214905, 1.0, 1.0, 1.0, 0.9994612336158752, 1.0, 0.9994612336158752, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9994612336158752, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.9787750840187073, 0.9714565277099609, 0.9678547978401184, 0.960818350315094, 0.9445222616195679, 0.9427332282066345, 0.9109943509101868, 0.9032636284828186, 0.8955729007720947, 0.8635900616645813, 0.8292165994644165, 0.8151700496673584, 0.7841081023216248, 0.7645750641822815, 0.7860375046730042, 0.7355102896690369, 0.7299840450286865, 0.7693546414375305, 0.7526940703392029, 0.7915982007980347, 0.7504704594612122, 0.7612223029136658, 0.778176486492157, 0.7904917597770691, 0.8233177661895752, 0.8808373808860779, 0.8524103760719299, 0.8545267581939697, 0.8737396001815796, 0.8752884864807129, 0.8846435546875, 0.8884443640708923, 0.9020206332206726, 0.9104833006858826, 0.93003249168396, 0.9493721723556519, 0.9170629382133484, 0.9237456917762756, 0.9251276254653931, 0.9184714555740356, 0.9251214861869812, 0.9415565729141235, 0.9325477480888367, 0.9347788691520691, 0.9337404370307922, 0.9347482919692993, 0.9321783781051636, 0.9365817308425903, 0.9575793743133545, 0.9410349130630493, 0.9450535774230957, 0.9421800374984741, 0.9429752230644226, 0.9569676518440247, 1.0173945426940918, 0.9479156732559204, 0.9468187093734741, 0.960369348526001, 0.9477187395095825, 0.9418341517448425, 0.9486934542655945, 0.9553259015083313, 0.9526358842849731, 0.9645971655845642, 0.9567068815231323, 0.9690414071083069, 0.9546262621879578, 0.9578572511672974, 0.9614624381065369, 0.953686535358429, 0.9637213349342346, 0.9637847542762756, 0.9739962220191956, 0.9596943855285645, 0.9553955793380737, 0.9896759390830994, 0.9594020247459412, 0.9708123803138733, 0.9592615962028503, 0.9707134962081909, 0.9988335967063904, 0.9664354920387268, 0.9705553650856018, 0.9652056097984314, 0.9828764200210571, 0.9837036728858948, 0.9679140448570251, 0.9700478315353394, 0.9742066860198975, 0.9660890698432922, 0.9861640334129333, 0.9669632911682129, 0.9694819450378418, 0.9657953381538391, 0.9795966148376465, 0.9920419454574585, 0.9824644923210144, 1.007218360900879, 0.9933194518089294, 0.9759862422943115], 'val_accuracy': [0.5226293206214905, 0.5387930870056152, 0.5441810488700867, 0.5614224076271057, 0.5894396305084229, 0.5905172228813171, 0.639008641242981, 0.6465517282485962, 0.6584051847457886, 0.6961206793785095, 0.7295258641242981, 0.7392241358757019, 0.7780172228813171, 0.7931034564971924, 0.7661637663841248, 0.8071120977401733, 0.8103448152542114, 0.8028017282485962, 0.8049569129943848, 0.8092672228813171, 0.818965494632721, 0.8232758641242981, 0.826508641242981, 0.8243534564971924, 0.8286637663841248, 0.8081896305084229, 0.8221982717514038, 0.8243534564971924, 0.8243534564971924, 0.8275862336158752, 0.8254310488700867, 0.8275862336158752, 0.8200430870056152, 0.8232758641242981, 0.8243534564971924, 0.8243534564971924, 0.8254310488700867, 0.8221982717514038, 0.8178879022598267, 0.8200430870056152, 0.8178879022598267, 0.818965494632721, 0.8243534564971924, 0.8146551847457886, 0.8135775923728943, 0.8168103694915771, 0.8221982717514038, 0.8178879022598267, 0.8168103694915771, 0.818965494632721, 0.8146551847457886, 0.8146551847457886, 0.8125, 0.8146551847457886, 0.7974137663841248, 0.8146551847457886, 0.8125, 0.8114224076271057, 0.8135775923728943, 0.8157327771186829, 0.8114224076271057, 0.8178879022598267, 0.8135775923728943, 0.8178879022598267, 0.8103448152542114, 0.8157327771186829, 0.8135775923728943, 0.8135775923728943, 0.8081896305084229, 0.8135775923728943, 0.8146551847457886, 0.8071120977401733, 0.8092672228813171, 0.8135775923728943, 0.8114224076271057, 0.8125, 0.8103448152542114, 0.8178879022598267, 0.8081896305084229, 0.8103448152542114, 0.8125, 0.8071120977401733, 0.8071120977401733, 0.8071120977401733, 0.8125, 0.8103448152542114, 0.8038793206214905, 0.8071120977401733, 0.8092672228813171, 0.8092672228813171, 0.806034505367279, 0.8092672228813171, 0.806034505367279, 0.8071120977401733, 0.8092672228813171, 0.8071120977401733, 0.8038793206214905, 0.806034505367279, 0.8081896305084229, 0.8038793206214905]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 5s 41ms/step - loss: 0.4355 - accuracy: 0.9457 - val_loss: 0.9583 - val_accuracy: 0.5633\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3542 - accuracy: 0.9822 - val_loss: 0.9624 - val_accuracy: 0.5554\n","Epoch 3/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3374 - accuracy: 0.9895 - val_loss: 0.9650 - val_accuracy: 0.5554\n","Epoch 4/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3294 - accuracy: 0.9924 - val_loss: 0.9501 - val_accuracy: 0.5781\n","Epoch 5/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3254 - accuracy: 0.9943 - val_loss: 0.9522 - val_accuracy: 0.5724\n","Epoch 6/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3226 - accuracy: 0.9960 - val_loss: 0.9333 - val_accuracy: 0.6029\n","Epoch 7/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3205 - accuracy: 0.9963 - val_loss: 0.9261 - val_accuracy: 0.6120\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3179 - accuracy: 0.9972 - val_loss: 0.9033 - val_accuracy: 0.6471\n","Epoch 9/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3179 - accuracy: 0.9969 - val_loss: 0.8873 - val_accuracy: 0.6674\n","Epoch 10/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3143 - accuracy: 0.9989 - val_loss: 0.8647 - val_accuracy: 0.6878\n","Epoch 11/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3161 - accuracy: 0.9992 - val_loss: 0.8453 - val_accuracy: 0.7014\n","Epoch 12/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.3174 - accuracy: 0.9972 - val_loss: 0.8291 - val_accuracy: 0.7206\n","Epoch 13/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3119 - accuracy: 1.0000 - val_loss: 0.8024 - val_accuracy: 0.7432\n","Epoch 14/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3112 - accuracy: 0.9997 - val_loss: 0.7756 - val_accuracy: 0.7658\n","Epoch 15/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3098 - accuracy: 1.0000 - val_loss: 0.7563 - val_accuracy: 0.7794\n","Epoch 16/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3084 - accuracy: 1.0000 - val_loss: 0.7317 - val_accuracy: 0.7998\n","Epoch 17/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3082 - accuracy: 1.0000 - val_loss: 0.7181 - val_accuracy: 0.8145\n","Epoch 18/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3074 - accuracy: 1.0000 - val_loss: 0.7099 - val_accuracy: 0.8190\n","Epoch 19/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3069 - accuracy: 1.0000 - val_loss: 0.7024 - val_accuracy: 0.8281\n","Epoch 20/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3074 - accuracy: 0.9997 - val_loss: 0.6963 - val_accuracy: 0.8507\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3056 - accuracy: 1.0000 - val_loss: 0.6993 - val_accuracy: 0.8405\n","Epoch 22/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3043 - accuracy: 1.0000 - val_loss: 0.7052 - val_accuracy: 0.8484\n","Epoch 23/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3040 - accuracy: 1.0000 - val_loss: 0.7228 - val_accuracy: 0.8462\n","Epoch 24/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3033 - accuracy: 1.0000 - val_loss: 0.7367 - val_accuracy: 0.8473\n","Epoch 25/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3040 - accuracy: 1.0000 - val_loss: 0.7420 - val_accuracy: 0.8473\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3046 - accuracy: 0.9997 - val_loss: 0.7578 - val_accuracy: 0.8484\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3019 - accuracy: 1.0000 - val_loss: 0.7827 - val_accuracy: 0.8450\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3012 - accuracy: 1.0000 - val_loss: 0.7835 - val_accuracy: 0.8495\n","Epoch 29/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3004 - accuracy: 1.0000 - val_loss: 0.7921 - val_accuracy: 0.8529\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2998 - accuracy: 1.0000 - val_loss: 0.8066 - val_accuracy: 0.8484\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2995 - accuracy: 1.0000 - val_loss: 0.8195 - val_accuracy: 0.8450\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2983 - accuracy: 1.0000 - val_loss: 0.8218 - val_accuracy: 0.8473\n","Epoch 33/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2980 - accuracy: 1.0000 - val_loss: 0.8365 - val_accuracy: 0.8507\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2995 - accuracy: 1.0000 - val_loss: 0.8522 - val_accuracy: 0.8371\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2977 - accuracy: 1.0000 - val_loss: 0.8504 - val_accuracy: 0.8473\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2974 - accuracy: 1.0000 - val_loss: 0.8441 - val_accuracy: 0.8473\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2966 - accuracy: 1.0000 - val_loss: 0.8720 - val_accuracy: 0.8439\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2971 - accuracy: 1.0000 - val_loss: 0.8462 - val_accuracy: 0.8450\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2949 - accuracy: 1.0000 - val_loss: 0.8466 - val_accuracy: 0.8416\n","Epoch 40/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2951 - accuracy: 1.0000 - val_loss: 0.8555 - val_accuracy: 0.8450\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2936 - accuracy: 1.0000 - val_loss: 0.8651 - val_accuracy: 0.8360\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2936 - accuracy: 1.0000 - val_loss: 0.8671 - val_accuracy: 0.8416\n","Epoch 43/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2924 - accuracy: 1.0000 - val_loss: 0.8646 - val_accuracy: 0.8416\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2921 - accuracy: 1.0000 - val_loss: 0.8643 - val_accuracy: 0.8416\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2919 - accuracy: 1.0000 - val_loss: 0.8777 - val_accuracy: 0.8428\n","Epoch 46/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2916 - accuracy: 1.0000 - val_loss: 0.8707 - val_accuracy: 0.8462\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2918 - accuracy: 1.0000 - val_loss: 0.8973 - val_accuracy: 0.8394\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2908 - accuracy: 1.0000 - val_loss: 0.8741 - val_accuracy: 0.8360\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2894 - accuracy: 1.0000 - val_loss: 0.8861 - val_accuracy: 0.8405\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2897 - accuracy: 1.0000 - val_loss: 0.8708 - val_accuracy: 0.8405\n","Epoch 51/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2880 - accuracy: 1.0000 - val_loss: 0.8814 - val_accuracy: 0.8337\n","Epoch 52/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2873 - accuracy: 1.0000 - val_loss: 0.8804 - val_accuracy: 0.8382\n","Epoch 53/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2865 - accuracy: 1.0000 - val_loss: 0.8801 - val_accuracy: 0.8382\n","Epoch 54/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2866 - accuracy: 1.0000 - val_loss: 0.8804 - val_accuracy: 0.8348\n","Epoch 55/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2856 - accuracy: 1.0000 - val_loss: 0.8771 - val_accuracy: 0.8371\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2861 - accuracy: 1.0000 - val_loss: 0.8809 - val_accuracy: 0.8326\n","Epoch 57/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2855 - accuracy: 1.0000 - val_loss: 0.8919 - val_accuracy: 0.8382\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2836 - accuracy: 1.0000 - val_loss: 0.8879 - val_accuracy: 0.8360\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2838 - accuracy: 1.0000 - val_loss: 0.8896 - val_accuracy: 0.8337\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2829 - accuracy: 1.0000 - val_loss: 0.8969 - val_accuracy: 0.8292\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2821 - accuracy: 1.0000 - val_loss: 0.9140 - val_accuracy: 0.8247\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2825 - accuracy: 1.0000 - val_loss: 0.8976 - val_accuracy: 0.8348\n","Epoch 63/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2815 - accuracy: 1.0000 - val_loss: 0.8910 - val_accuracy: 0.8326\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2805 - accuracy: 1.0000 - val_loss: 0.8960 - val_accuracy: 0.8360\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2801 - accuracy: 1.0000 - val_loss: 0.8885 - val_accuracy: 0.8314\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2798 - accuracy: 1.0000 - val_loss: 0.8971 - val_accuracy: 0.8326\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2787 - accuracy: 1.0000 - val_loss: 0.8942 - val_accuracy: 0.8314\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2783 - accuracy: 1.0000 - val_loss: 0.9048 - val_accuracy: 0.8258\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2784 - accuracy: 1.0000 - val_loss: 0.8993 - val_accuracy: 0.8337\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2781 - accuracy: 1.0000 - val_loss: 0.9230 - val_accuracy: 0.8258\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2769 - accuracy: 1.0000 - val_loss: 0.9157 - val_accuracy: 0.8224\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2763 - accuracy: 1.0000 - val_loss: 0.9047 - val_accuracy: 0.8337\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2753 - accuracy: 1.0000 - val_loss: 0.9006 - val_accuracy: 0.8303\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2750 - accuracy: 1.0000 - val_loss: 0.9095 - val_accuracy: 0.8292\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2745 - accuracy: 1.0000 - val_loss: 0.9087 - val_accuracy: 0.8360\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2738 - accuracy: 1.0000 - val_loss: 0.9059 - val_accuracy: 0.8247\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2730 - accuracy: 1.0000 - val_loss: 0.9110 - val_accuracy: 0.8247\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2725 - accuracy: 1.0000 - val_loss: 0.9062 - val_accuracy: 0.8303\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2721 - accuracy: 1.0000 - val_loss: 0.9187 - val_accuracy: 0.8224\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2716 - accuracy: 1.0000 - val_loss: 0.9137 - val_accuracy: 0.8269\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2708 - accuracy: 1.0000 - val_loss: 0.9141 - val_accuracy: 0.8281\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2700 - accuracy: 1.0000 - val_loss: 0.9159 - val_accuracy: 0.8247\n","Epoch 83/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2690 - accuracy: 1.0000 - val_loss: 0.9085 - val_accuracy: 0.8258\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2687 - accuracy: 1.0000 - val_loss: 0.9337 - val_accuracy: 0.8167\n","Epoch 85/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2695 - accuracy: 1.0000 - val_loss: 0.9262 - val_accuracy: 0.8167\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2683 - accuracy: 1.0000 - val_loss: 0.9179 - val_accuracy: 0.8258\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2672 - accuracy: 1.0000 - val_loss: 0.9207 - val_accuracy: 0.8224\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2670 - accuracy: 1.0000 - val_loss: 0.9405 - val_accuracy: 0.8122\n","Epoch 89/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2656 - accuracy: 1.0000 - val_loss: 0.9167 - val_accuracy: 0.8213\n","Epoch 90/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2650 - accuracy: 1.0000 - val_loss: 0.9223 - val_accuracy: 0.8247\n","Epoch 91/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2640 - accuracy: 1.0000 - val_loss: 0.9319 - val_accuracy: 0.8201\n","Epoch 92/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2636 - accuracy: 1.0000 - val_loss: 0.9226 - val_accuracy: 0.8247\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2630 - accuracy: 1.0000 - val_loss: 0.9304 - val_accuracy: 0.8269\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2626 - accuracy: 1.0000 - val_loss: 0.9236 - val_accuracy: 0.8235\n","Epoch 95/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2615 - accuracy: 1.0000 - val_loss: 0.9543 - val_accuracy: 0.8066\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2620 - accuracy: 1.0000 - val_loss: 0.9547 - val_accuracy: 0.8156\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2616 - accuracy: 1.0000 - val_loss: 0.9404 - val_accuracy: 0.8122\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2599 - accuracy: 1.0000 - val_loss: 0.9434 - val_accuracy: 0.8088\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2590 - accuracy: 1.0000 - val_loss: 0.9374 - val_accuracy: 0.8111\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2586 - accuracy: 1.0000 - val_loss: 0.9226 - val_accuracy: 0.8156\n","{'loss': [0.4355204999446869, 0.3541983962059021, 0.3373691439628601, 0.32937175035476685, 0.3254278898239136, 0.3225814402103424, 0.3205360770225525, 0.31794583797454834, 0.3179149329662323, 0.3143230676651001, 0.3160807490348816, 0.3174281716346741, 0.3118865489959717, 0.31119486689567566, 0.3098062574863434, 0.3083893358707428, 0.30817821621894836, 0.30742019414901733, 0.30687156319618225, 0.307438462972641, 0.3056058883666992, 0.30431967973709106, 0.3040119409561157, 0.3032810389995575, 0.3039757311344147, 0.30461055040359497, 0.30194637179374695, 0.3011762797832489, 0.3003763258457184, 0.29981333017349243, 0.2995130121707916, 0.29827722907066345, 0.29795920848846436, 0.2995433509349823, 0.2976832389831543, 0.2973850667476654, 0.29662686586380005, 0.29709509015083313, 0.29486778378486633, 0.29512885212898254, 0.29357579350471497, 0.29362332820892334, 0.2924194931983948, 0.2920541763305664, 0.29194241762161255, 0.2916157841682434, 0.29180780053138733, 0.2908346652984619, 0.2893778383731842, 0.28972509503364563, 0.28800398111343384, 0.2872823476791382, 0.2865091562271118, 0.28658461570739746, 0.28558769822120667, 0.2861050069332123, 0.28545406460762024, 0.2836472690105438, 0.2837629020214081, 0.28288379311561584, 0.28214502334594727, 0.28248295187950134, 0.2814543843269348, 0.28046318888664246, 0.28014132380485535, 0.27980974316596985, 0.27871090173721313, 0.2783418595790863, 0.2784076929092407, 0.2781105935573578, 0.27688005566596985, 0.2763006389141083, 0.2752941846847534, 0.2750184237957001, 0.2745124399662018, 0.27375730872154236, 0.2729993760585785, 0.27253562211990356, 0.2720702588558197, 0.2716085612773895, 0.2708280682563782, 0.27000510692596436, 0.2689969837665558, 0.26869481801986694, 0.26953771710395813, 0.2682778835296631, 0.2671908438205719, 0.26701289415359497, 0.2656048834323883, 0.26503393054008484, 0.2639934718608856, 0.26357361674308777, 0.26296451687812805, 0.2626037299633026, 0.26152876019477844, 0.26201850175857544, 0.2615940272808075, 0.25988852977752686, 0.2590315639972687, 0.25855088233947754], 'accuracy': [0.9456706047058105, 0.9821732044219971, 0.9895302653312683, 0.9923599362373352, 0.994340717792511, 0.9960384964942932, 0.996321439743042, 0.9971703290939331, 0.9968873858451843, 0.9988681674003601, 0.9991511106491089, 0.9971703290939331, 1.0, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.9583015441894531, 0.962375283241272, 0.9649975895881653, 0.9501107335090637, 0.9521661400794983, 0.9333182573318481, 0.9261002540588379, 0.9032598733901978, 0.8873151540756226, 0.864662766456604, 0.8453018665313721, 0.8291004300117493, 0.8024321794509888, 0.7755786180496216, 0.7562652826309204, 0.7317196726799011, 0.7181317806243896, 0.7099155187606812, 0.7024359107017517, 0.6962832808494568, 0.6992799043655396, 0.7051824331283569, 0.7228140234947205, 0.7367127537727356, 0.7419766187667847, 0.7577933073043823, 0.7826586365699768, 0.783460795879364, 0.7921097874641418, 0.8066324591636658, 0.8195313215255737, 0.8218005895614624, 0.836464524269104, 0.8522272706031799, 0.8504263162612915, 0.844072163105011, 0.8720415234565735, 0.8462210893630981, 0.846570611000061, 0.8554962873458862, 0.8651149272918701, 0.8670680522918701, 0.864581823348999, 0.8643158078193665, 0.8777317404747009, 0.8707384467124939, 0.8972502946853638, 0.8741055130958557, 0.8860688209533691, 0.8708146810531616, 0.8814420104026794, 0.880368173122406, 0.8801032304763794, 0.8803942799568176, 0.877083957195282, 0.8809416890144348, 0.8918634653091431, 0.8879252076148987, 0.8895798921585083, 0.8969108462333679, 0.914044201374054, 0.8976184725761414, 0.8910236358642578, 0.8960317373275757, 0.8885179758071899, 0.8971148729324341, 0.894169807434082, 0.9047567248344421, 0.8993268013000488, 0.9229809045791626, 0.9156890511512756, 0.9046886563301086, 0.900560200214386, 0.9094517827033997, 0.9087336659431458, 0.9058955907821655, 0.9109904170036316, 0.9062312245368958, 0.9187053442001343, 0.9137210249900818, 0.9140730500221252, 0.9159095883369446, 0.9085330367088318, 0.9337489604949951, 0.9262159466743469, 0.9179267287254333, 0.9207000732421875, 0.9404861927032471, 0.9166970252990723, 0.9223235845565796, 0.9318894147872925, 0.9225974678993225, 0.9303775429725647, 0.9236027002334595, 0.9542838931083679, 0.9546754360198975, 0.9403634071350098, 0.9434479475021362, 0.9373886585235596, 0.9226135611534119], 'val_accuracy': [0.5633484125137329, 0.5554298758506775, 0.5554298758506775, 0.5780543088912964, 0.5723981857299805, 0.6029411554336548, 0.6119909286499023, 0.6470588445663452, 0.6674208045005798, 0.6877828240394592, 0.7013574838638306, 0.720588207244873, 0.7432126402854919, 0.7658371329307556, 0.779411792755127, 0.7997737526893616, 0.814479649066925, 0.8190045356750488, 0.8280543088912964, 0.8506787419319153, 0.8404977321624756, 0.848416268825531, 0.8461538553237915, 0.8472850918769836, 0.8472850918769836, 0.848416268825531, 0.8450226187705994, 0.8495475053787231, 0.8529411554336548, 0.848416268825531, 0.8450226187705994, 0.8472850918769836, 0.8506787419319153, 0.837104082107544, 0.8472850918769836, 0.8472850918769836, 0.8438913822174072, 0.8450226187705994, 0.8416289687156677, 0.8450226187705994, 0.8359728455543518, 0.8416289687156677, 0.8416289687156677, 0.8416289687156677, 0.8427602052688599, 0.8461538553237915, 0.8393664956092834, 0.8359728455543518, 0.8404977321624756, 0.8404977321624756, 0.8337104320526123, 0.8382353186607361, 0.8382353186607361, 0.8348416090011597, 0.837104082107544, 0.8325791954994202, 0.8382353186607361, 0.8359728455543518, 0.8337104320526123, 0.8291855454444885, 0.8246606588363647, 0.8348416090011597, 0.8325791954994202, 0.8359728455543518, 0.831447958946228, 0.8325791954994202, 0.831447958946228, 0.8257918357849121, 0.8337104320526123, 0.8257918357849121, 0.8223981857299805, 0.8337104320526123, 0.8303167223930359, 0.8291855454444885, 0.8359728455543518, 0.8246606588363647, 0.8246606588363647, 0.8303167223930359, 0.8223981857299805, 0.8269230723381042, 0.8280543088912964, 0.8246606588363647, 0.8257918357849121, 0.8167420625686646, 0.8167420625686646, 0.8257918357849121, 0.8223981857299805, 0.8122171759605408, 0.8212669491767883, 0.8246606588363647, 0.820135772228241, 0.8246606588363647, 0.8269230723381042, 0.8235294222831726, 0.8065611124038696, 0.8156108856201172, 0.8122171759605408, 0.8088235259056091, 0.8110859990119934, 0.8156108856201172]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.4135 - accuracy: 0.9576"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 5s 45ms/step - loss: 0.4132 - accuracy: 0.9576 - val_loss: 0.9818 - val_accuracy: 0.5351\n","Epoch 2/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3553 - accuracy: 0.9811 - val_loss: 0.9784 - val_accuracy: 0.5496\n","Epoch 3/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3426 - accuracy: 0.9884 - val_loss: 0.9827 - val_accuracy: 0.5413\n","Epoch 4/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3358 - accuracy: 0.9910 - val_loss: 0.9716 - val_accuracy: 0.5589\n","Epoch 5/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3313 - accuracy: 0.9935 - val_loss: 0.9523 - val_accuracy: 0.5981\n","Epoch 6/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3344 - accuracy: 0.9930 - val_loss: 0.9600 - val_accuracy: 0.5816\n","Epoch 7/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3281 - accuracy: 0.9941 - val_loss: 0.9354 - val_accuracy: 0.6188\n","Epoch 8/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3286 - accuracy: 0.9946 - val_loss: 0.9398 - val_accuracy: 0.6095\n","Epoch 9/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3256 - accuracy: 0.9951 - val_loss: 0.9013 - val_accuracy: 0.6581\n","Epoch 10/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3189 - accuracy: 0.9982 - val_loss: 0.8860 - val_accuracy: 0.6767\n","Epoch 11/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3192 - accuracy: 0.9972 - val_loss: 0.8813 - val_accuracy: 0.6798\n","Epoch 12/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3193 - accuracy: 0.9964 - val_loss: 0.8716 - val_accuracy: 0.7004\n","Epoch 13/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3153 - accuracy: 0.9987 - val_loss: 0.8484 - val_accuracy: 0.7283\n","Epoch 14/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3149 - accuracy: 0.9987 - val_loss: 0.8336 - val_accuracy: 0.7583\n","Epoch 15/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3151 - accuracy: 0.9992 - val_loss: 0.8564 - val_accuracy: 0.7459\n","Epoch 16/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3207 - accuracy: 0.9969 - val_loss: 0.8255 - val_accuracy: 0.7676\n","Epoch 17/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3114 - accuracy: 0.9990 - val_loss: 0.8675 - val_accuracy: 0.7645\n","Epoch 18/100\n","31/31 [==============================] - 2s 71ms/step - loss: 0.3119 - accuracy: 0.9984 - val_loss: 0.8755 - val_accuracy: 0.7800\n","Epoch 19/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.3109 - accuracy: 0.9995 - val_loss: 0.8970 - val_accuracy: 0.7810\n","Epoch 20/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3085 - accuracy: 0.9992 - val_loss: 0.8966 - val_accuracy: 0.7810\n","Epoch 21/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3072 - accuracy: 0.9997 - val_loss: 0.9363 - val_accuracy: 0.7779\n","Epoch 22/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3080 - accuracy: 0.9987 - val_loss: 0.9656 - val_accuracy: 0.7851\n","Epoch 23/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3062 - accuracy: 0.9997 - val_loss: 1.0027 - val_accuracy: 0.7831\n","Epoch 24/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3059 - accuracy: 0.9995 - val_loss: 1.0351 - val_accuracy: 0.7800\n","Epoch 25/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3065 - accuracy: 0.9995 - val_loss: 1.0557 - val_accuracy: 0.7882\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3045 - accuracy: 0.9992 - val_loss: 1.0720 - val_accuracy: 0.7882\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3041 - accuracy: 0.9997 - val_loss: 1.1024 - val_accuracy: 0.7882\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3027 - accuracy: 0.9990 - val_loss: 1.1146 - val_accuracy: 0.7841\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3050 - accuracy: 0.9982 - val_loss: 1.1612 - val_accuracy: 0.7831\n","Epoch 30/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3075 - accuracy: 0.9987 - val_loss: 1.1959 - val_accuracy: 0.7800\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3041 - accuracy: 0.9995 - val_loss: 1.1517 - val_accuracy: 0.7872\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3010 - accuracy: 1.0000 - val_loss: 1.1700 - val_accuracy: 0.7862\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3008 - accuracy: 0.9995 - val_loss: 1.1788 - val_accuracy: 0.7851\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2984 - accuracy: 0.9997 - val_loss: 1.1702 - val_accuracy: 0.7841\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2984 - accuracy: 0.9997 - val_loss: 1.1790 - val_accuracy: 0.7851\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2970 - accuracy: 1.0000 - val_loss: 1.2077 - val_accuracy: 0.7800\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2981 - accuracy: 1.0000 - val_loss: 1.1971 - val_accuracy: 0.7851\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2977 - accuracy: 0.9995 - val_loss: 1.2126 - val_accuracy: 0.7841\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2958 - accuracy: 1.0000 - val_loss: 1.2023 - val_accuracy: 0.7831\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2950 - accuracy: 1.0000 - val_loss: 1.2090 - val_accuracy: 0.7882\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2951 - accuracy: 1.0000 - val_loss: 1.2031 - val_accuracy: 0.7831\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2935 - accuracy: 1.0000 - val_loss: 1.1963 - val_accuracy: 0.7872\n","Epoch 43/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2946 - accuracy: 1.0000 - val_loss: 1.2078 - val_accuracy: 0.7831\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2920 - accuracy: 1.0000 - val_loss: 1.2278 - val_accuracy: 0.7769\n","Epoch 45/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2920 - accuracy: 1.0000 - val_loss: 1.2457 - val_accuracy: 0.7769\n","Epoch 46/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2923 - accuracy: 1.0000 - val_loss: 1.2703 - val_accuracy: 0.7738\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2926 - accuracy: 1.0000 - val_loss: 1.2158 - val_accuracy: 0.7841\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2894 - accuracy: 1.0000 - val_loss: 1.2242 - val_accuracy: 0.7810\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2895 - accuracy: 1.0000 - val_loss: 1.2391 - val_accuracy: 0.7800\n","Epoch 50/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2895 - accuracy: 1.0000 - val_loss: 1.2435 - val_accuracy: 0.7748\n","Epoch 51/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2907 - accuracy: 0.9995 - val_loss: 1.2396 - val_accuracy: 0.7758\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2888 - accuracy: 0.9997 - val_loss: 1.2623 - val_accuracy: 0.7738\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2887 - accuracy: 0.9997 - val_loss: 1.2569 - val_accuracy: 0.7738\n","Epoch 54/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2990 - accuracy: 0.9974 - val_loss: 1.2538 - val_accuracy: 0.7748\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2881 - accuracy: 0.9997 - val_loss: 1.2396 - val_accuracy: 0.7727\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2857 - accuracy: 1.0000 - val_loss: 1.2385 - val_accuracy: 0.7800\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2850 - accuracy: 1.0000 - val_loss: 1.2359 - val_accuracy: 0.7748\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2862 - accuracy: 0.9997 - val_loss: 1.2414 - val_accuracy: 0.7758\n","Epoch 59/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2831 - accuracy: 1.0000 - val_loss: 1.2594 - val_accuracy: 0.7707\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2835 - accuracy: 1.0000 - val_loss: 1.2400 - val_accuracy: 0.7769\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2823 - accuracy: 1.0000 - val_loss: 1.2382 - val_accuracy: 0.7820\n","Epoch 62/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2813 - accuracy: 1.0000 - val_loss: 1.2505 - val_accuracy: 0.7831\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2824 - accuracy: 1.0000 - val_loss: 1.2507 - val_accuracy: 0.7820\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2819 - accuracy: 1.0000 - val_loss: 1.2582 - val_accuracy: 0.7738\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2803 - accuracy: 1.0000 - val_loss: 1.2503 - val_accuracy: 0.7758\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2797 - accuracy: 1.0000 - val_loss: 1.2553 - val_accuracy: 0.7758\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2782 - accuracy: 1.0000 - val_loss: 1.2578 - val_accuracy: 0.7738\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2776 - accuracy: 1.0000 - val_loss: 1.2658 - val_accuracy: 0.7727\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2774 - accuracy: 1.0000 - val_loss: 1.2490 - val_accuracy: 0.7789\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2768 - accuracy: 1.0000 - val_loss: 1.2522 - val_accuracy: 0.7789\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2764 - accuracy: 1.0000 - val_loss: 1.2543 - val_accuracy: 0.7779\n","Epoch 72/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2763 - accuracy: 1.0000 - val_loss: 1.2605 - val_accuracy: 0.7789\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2753 - accuracy: 1.0000 - val_loss: 1.2467 - val_accuracy: 0.7810\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2743 - accuracy: 1.0000 - val_loss: 1.2538 - val_accuracy: 0.7738\n","Epoch 75/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2746 - accuracy: 1.0000 - val_loss: 1.2658 - val_accuracy: 0.7748\n","Epoch 76/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2732 - accuracy: 1.0000 - val_loss: 1.2565 - val_accuracy: 0.7810\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2726 - accuracy: 1.0000 - val_loss: 1.2566 - val_accuracy: 0.7748\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2722 - accuracy: 1.0000 - val_loss: 1.2911 - val_accuracy: 0.7624\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2735 - accuracy: 1.0000 - val_loss: 1.2534 - val_accuracy: 0.7727\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2719 - accuracy: 1.0000 - val_loss: 1.2732 - val_accuracy: 0.7769\n","Epoch 81/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2705 - accuracy: 1.0000 - val_loss: 1.2639 - val_accuracy: 0.7748\n","Epoch 82/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2703 - accuracy: 1.0000 - val_loss: 1.2639 - val_accuracy: 0.7810\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2689 - accuracy: 1.0000 - val_loss: 1.2656 - val_accuracy: 0.7789\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2682 - accuracy: 1.0000 - val_loss: 1.2631 - val_accuracy: 0.7789\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2675 - accuracy: 1.0000 - val_loss: 1.2715 - val_accuracy: 0.7738\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2672 - accuracy: 1.0000 - val_loss: 1.2630 - val_accuracy: 0.7707\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2663 - accuracy: 1.0000 - val_loss: 1.2850 - val_accuracy: 0.7717\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2655 - accuracy: 1.0000 - val_loss: 1.2667 - val_accuracy: 0.7748\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2658 - accuracy: 1.0000 - val_loss: 1.2657 - val_accuracy: 0.7769\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2655 - accuracy: 1.0000 - val_loss: 1.2701 - val_accuracy: 0.7769\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2645 - accuracy: 1.0000 - val_loss: 1.2865 - val_accuracy: 0.7738\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2653 - accuracy: 1.0000 - val_loss: 1.3995 - val_accuracy: 0.7469\n","Epoch 93/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2727 - accuracy: 0.9995 - val_loss: 1.2837 - val_accuracy: 0.7686\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2746 - accuracy: 0.9982 - val_loss: 1.2929 - val_accuracy: 0.7696\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3731 - accuracy: 0.9607 - val_loss: 1.9236 - val_accuracy: 0.6632\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3149 - accuracy: 0.9801 - val_loss: 1.4339 - val_accuracy: 0.7345\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2761 - accuracy: 0.9964 - val_loss: 1.3201 - val_accuracy: 0.7593\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2682 - accuracy: 0.9984 - val_loss: 1.2688 - val_accuracy: 0.7686\n","Epoch 99/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2631 - accuracy: 1.0000 - val_loss: 1.2497 - val_accuracy: 0.7758\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2613 - accuracy: 1.0000 - val_loss: 1.2599 - val_accuracy: 0.7696\n","{'loss': [0.41321611404418945, 0.3553461730480194, 0.3425532579421997, 0.33575329184532166, 0.33129867911338806, 0.33435899019241333, 0.3280870020389557, 0.3285900354385376, 0.3256015181541443, 0.31886595487594604, 0.31921321153640747, 0.31931033730506897, 0.3153165876865387, 0.31494244933128357, 0.3150692582130432, 0.3206803798675537, 0.3114384412765503, 0.3118680417537689, 0.31085509061813354, 0.3084677457809448, 0.30718544125556946, 0.3080430328845978, 0.306172639131546, 0.30589818954467773, 0.3064761757850647, 0.3045424520969391, 0.30406302213668823, 0.30268779397010803, 0.30497705936431885, 0.3074810802936554, 0.304066926240921, 0.3010382056236267, 0.30079278349876404, 0.2984294891357422, 0.29835206270217896, 0.2970188558101654, 0.2981458902359009, 0.29771506786346436, 0.2957535982131958, 0.29496657848358154, 0.29505282640457153, 0.2935224175453186, 0.2945830225944519, 0.2920026183128357, 0.29197046160697937, 0.29229527711868286, 0.292635977268219, 0.289404034614563, 0.28951990604400635, 0.2894503176212311, 0.2907368540763855, 0.2887991666793823, 0.2887270450592041, 0.2990357279777527, 0.2881394624710083, 0.28568586707115173, 0.28498703241348267, 0.28621116280555725, 0.2831134796142578, 0.28354930877685547, 0.2823149263858795, 0.2813105285167694, 0.28238898515701294, 0.28190362453460693, 0.2802501618862152, 0.2796977758407593, 0.27823030948638916, 0.27762916684150696, 0.27744966745376587, 0.27676236629486084, 0.276432603597641, 0.2763471305370331, 0.2753376364707947, 0.27430102229118347, 0.27456575632095337, 0.2732197344303131, 0.27256321907043457, 0.2721611261367798, 0.2735084593296051, 0.2719429135322571, 0.27052041888237, 0.27027997374534607, 0.26889482140541077, 0.2682393789291382, 0.26752105355262756, 0.26723554730415344, 0.26631081104278564, 0.2655353248119354, 0.26578181982040405, 0.26550358533859253, 0.264507919549942, 0.2652815878391266, 0.2726513743400574, 0.2746095061302185, 0.37309277057647705, 0.31489259004592896, 0.27608799934387207, 0.2681654989719391, 0.26313793659210205, 0.2612587809562683], 'accuracy': [0.957622766494751, 0.9811369776725769, 0.9883720874786377, 0.9909560680389404, 0.9935400485992432, 0.9930232763290405, 0.9940568208694458, 0.9945736527442932, 0.9950904250144958, 0.998191237449646, 0.997157633304596, 0.9963824152946472, 0.9987080097198486, 0.9987080097198486, 0.9992247819900513, 0.9968992471694946, 0.99896639585495, 0.9984496235847473, 0.9994832277297974, 0.9992247819900513, 0.9997416138648987, 0.9987080097198486, 0.9997416138648987, 0.9994832277297974, 0.9994832277297974, 0.9992247819900513, 0.9997416138648987, 0.99896639585495, 0.998191237449646, 0.9987080097198486, 0.9994832277297974, 1.0, 0.9994832277297974, 0.9997416138648987, 0.9997416138648987, 1.0, 1.0, 0.9994832277297974, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9994832277297974, 0.9997416138648987, 0.9997416138648987, 0.9974160194396973, 0.9997416138648987, 1.0, 1.0, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9994832277297974, 0.998191237449646, 0.9607235193252563, 0.9801033735275269, 0.9963824152946472, 0.9984496235847473, 1.0, 1.0], 'val_loss': [0.9818322062492371, 0.9784368872642517, 0.9826517701148987, 0.9716271758079529, 0.9523210525512695, 0.9599926471710205, 0.935373842716217, 0.9398284554481506, 0.9012821912765503, 0.885973334312439, 0.8812698125839233, 0.8715763688087463, 0.8484082221984863, 0.8336129188537598, 0.85643470287323, 0.8254842758178711, 0.8674651980400085, 0.8755052089691162, 0.8969669342041016, 0.8966416120529175, 0.9363157153129578, 0.9655749797821045, 1.0027412176132202, 1.0350791215896606, 1.055675745010376, 1.0719921588897705, 1.1023991107940674, 1.1146259307861328, 1.1611692905426025, 1.1958627700805664, 1.1516733169555664, 1.1700453758239746, 1.178802490234375, 1.1701958179473877, 1.1789846420288086, 1.2076836824417114, 1.1971099376678467, 1.212602138519287, 1.202268123626709, 1.2089968919754028, 1.2030855417251587, 1.1963108777999878, 1.2077782154083252, 1.2277663946151733, 1.2456681728363037, 1.2703391313552856, 1.2158286571502686, 1.2242178916931152, 1.2391116619110107, 1.2434810400009155, 1.2395977973937988, 1.262304663658142, 1.2569258213043213, 1.253848671913147, 1.2395579814910889, 1.2384899854660034, 1.2359124422073364, 1.2413926124572754, 1.2594470977783203, 1.2400003671646118, 1.2382121086120605, 1.2504898309707642, 1.2506786584854126, 1.2581554651260376, 1.2503474950790405, 1.25529146194458, 1.2577645778656006, 1.2658429145812988, 1.2490352392196655, 1.2521655559539795, 1.2542815208435059, 1.2605350017547607, 1.2466837167739868, 1.2537510395050049, 1.26582932472229, 1.2565248012542725, 1.256585955619812, 1.291072130203247, 1.2533891201019287, 1.273245930671692, 1.263898491859436, 1.263880729675293, 1.265577793121338, 1.2631229162216187, 1.2715257406234741, 1.2629621028900146, 1.2849675416946411, 1.2667279243469238, 1.265653133392334, 1.270065426826477, 1.286510705947876, 1.3994773626327515, 1.2837148904800415, 1.2928749322891235, 1.9235754013061523, 1.4339423179626465, 1.3200774192810059, 1.2687913179397583, 1.24972403049469, 1.259878158569336], 'val_accuracy': [0.5351239442825317, 0.5495867729187012, 0.5413222908973694, 0.55888432264328, 0.5981404781341553, 0.5816115736961365, 0.6188016533851624, 0.6095041036605835, 0.6580578684806824, 0.6766529083251953, 0.6797520518302917, 0.7004132270812988, 0.7283057570457458, 0.7582644820213318, 0.7458677887916565, 0.7675619721412659, 0.7644628286361694, 0.7799586653709412, 0.7809917330741882, 0.7809917330741882, 0.7778925895690918, 0.7851239442825317, 0.7830578684806824, 0.7799586653709412, 0.788223147392273, 0.788223147392273, 0.788223147392273, 0.7840909361839294, 0.7830578684806824, 0.7799586653709412, 0.7871900796890259, 0.7861570119857788, 0.7851239442825317, 0.7840909361839294, 0.7851239442825317, 0.7799586653709412, 0.7851239442825317, 0.7840909361839294, 0.7830578684806824, 0.788223147392273, 0.7830578684806824, 0.7871900796890259, 0.7830578684806824, 0.7768595218658447, 0.7768595218658447, 0.7737603187561035, 0.7840909361839294, 0.7809917330741882, 0.7799586653709412, 0.7747933864593506, 0.7758264541625977, 0.7737603187561035, 0.7737603187561035, 0.7747933864593506, 0.7727272510528564, 0.7799586653709412, 0.7747933864593506, 0.7758264541625977, 0.7706611752510071, 0.7768595218658447, 0.7820248007774353, 0.7830578684806824, 0.7820248007774353, 0.7737603187561035, 0.7758264541625977, 0.7758264541625977, 0.7737603187561035, 0.7727272510528564, 0.7789255976676941, 0.7789255976676941, 0.7778925895690918, 0.7789255976676941, 0.7809917330741882, 0.7737603187561035, 0.7747933864593506, 0.7809917330741882, 0.7747933864593506, 0.7623966932296753, 0.7727272510528564, 0.7768595218658447, 0.7747933864593506, 0.7809917330741882, 0.7789255976676941, 0.7789255976676941, 0.7737603187561035, 0.7706611752510071, 0.7716942429542542, 0.7747933864593506, 0.7768595218658447, 0.7768595218658447, 0.7737603187561035, 0.7469007968902588, 0.7685950398445129, 0.76962810754776, 0.663223147392273, 0.7345041036605835, 0.7592975497245789, 0.7685950398445129, 0.7758264541625977, 0.76962810754776]}\n","32/32 [==============================] - 0s 3ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_CNN.round(3)"],"metadata":{"id":"y3RXIk-qZ7ts","colab":{"base_uri":"https://localhost:8080/","height":519},"executionInfo":{"status":"ok","timestamp":1717503869746,"user_tz":-360,"elapsed":28,"user":{"displayName":"Raihan Khan","userId":"09495118940322292713"}},"outputId":"0957712a-9237-4fe7-9d81-61e16c4cf14b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.537      0.540   0.494  0.516        0.494        0.580   \n","1        1     0.543      0.533   0.691  0.602        0.691        0.395   \n","2        2     0.570      0.572   0.558  0.565        0.558        0.582   \n","3        0     0.613      0.626   0.563  0.593        0.563        0.663   \n","4        1     0.622      0.602   0.723  0.657        0.723        0.521   \n","5        2     0.662      0.683   0.602  0.640        0.602        0.721   \n","6        0     0.693      0.692   0.697  0.694        0.697        0.690   \n","7        1     0.707      0.710   0.701  0.705        0.701        0.713   \n","8        2     0.740      0.747   0.725  0.736        0.725        0.755   \n","9        0     0.763      0.750   0.789  0.769        0.789        0.737   \n","10       1     0.771      0.762   0.788  0.775        0.788        0.754   \n","11       2     0.793      0.800   0.781  0.791        0.781        0.805   \n","12       0     0.805      0.773   0.863  0.816        0.863        0.747   \n","13       1     0.810      0.810   0.811  0.810        0.811        0.809   \n","14       2     0.820      0.815   0.829  0.822        0.829        0.811   \n","\n","    Kappa  \n","0   0.074  \n","1   0.086  \n","2   0.141  \n","3   0.226  \n","4   0.244  \n","5   0.323  \n","6   0.387  \n","7   0.414  \n","8   0.480  \n","9   0.526  \n","10  0.542  \n","11  0.586  \n","12  0.610  \n","13  0.620  \n","14  0.641  "],"text/html":["\n","  <div id=\"df-ce48db39-dd5a-4560-802f-b1345d7b3b84\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.537</td>\n","      <td>0.540</td>\n","      <td>0.494</td>\n","      <td>0.516</td>\n","      <td>0.494</td>\n","      <td>0.580</td>\n","      <td>0.074</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.543</td>\n","      <td>0.533</td>\n","      <td>0.691</td>\n","      <td>0.602</td>\n","      <td>0.691</td>\n","      <td>0.395</td>\n","      <td>0.086</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.570</td>\n","      <td>0.572</td>\n","      <td>0.558</td>\n","      <td>0.565</td>\n","      <td>0.558</td>\n","      <td>0.582</td>\n","      <td>0.141</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.613</td>\n","      <td>0.626</td>\n","      <td>0.563</td>\n","      <td>0.593</td>\n","      <td>0.563</td>\n","      <td>0.663</td>\n","      <td>0.226</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.622</td>\n","      <td>0.602</td>\n","      <td>0.723</td>\n","      <td>0.657</td>\n","      <td>0.723</td>\n","      <td>0.521</td>\n","      <td>0.244</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.662</td>\n","      <td>0.683</td>\n","      <td>0.602</td>\n","      <td>0.640</td>\n","      <td>0.602</td>\n","      <td>0.721</td>\n","      <td>0.323</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.693</td>\n","      <td>0.692</td>\n","      <td>0.697</td>\n","      <td>0.694</td>\n","      <td>0.697</td>\n","      <td>0.690</td>\n","      <td>0.387</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.707</td>\n","      <td>0.710</td>\n","      <td>0.701</td>\n","      <td>0.705</td>\n","      <td>0.701</td>\n","      <td>0.713</td>\n","      <td>0.414</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.740</td>\n","      <td>0.747</td>\n","      <td>0.725</td>\n","      <td>0.736</td>\n","      <td>0.725</td>\n","      <td>0.755</td>\n","      <td>0.480</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.763</td>\n","      <td>0.750</td>\n","      <td>0.789</td>\n","      <td>0.769</td>\n","      <td>0.789</td>\n","      <td>0.737</td>\n","      <td>0.526</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.771</td>\n","      <td>0.762</td>\n","      <td>0.788</td>\n","      <td>0.775</td>\n","      <td>0.788</td>\n","      <td>0.754</td>\n","      <td>0.542</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.793</td>\n","      <td>0.800</td>\n","      <td>0.781</td>\n","      <td>0.791</td>\n","      <td>0.781</td>\n","      <td>0.805</td>\n","      <td>0.586</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.805</td>\n","      <td>0.773</td>\n","      <td>0.863</td>\n","      <td>0.816</td>\n","      <td>0.863</td>\n","      <td>0.747</td>\n","      <td>0.610</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.810</td>\n","      <td>0.810</td>\n","      <td>0.811</td>\n","      <td>0.810</td>\n","      <td>0.811</td>\n","      <td>0.809</td>\n","      <td>0.620</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.820</td>\n","      <td>0.815</td>\n","      <td>0.829</td>\n","      <td>0.822</td>\n","      <td>0.829</td>\n","      <td>0.811</td>\n","      <td>0.641</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce48db39-dd5a-4560-802f-b1345d7b3b84')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ce48db39-dd5a-4560-802f-b1345d7b3b84 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ce48db39-dd5a-4560-802f-b1345d7b3b84');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-df5fee99-7f63-4179-91de-21afeb4e5e46\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df5fee99-7f63-4179-91de-21afeb4e5e46')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-df5fee99-7f63-4179-91de-21afeb4e5e46 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df_CNN\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0999727105621472,\n        \"min\": 0.537,\n        \"max\": 0.82,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.763,\n          0.793,\n          0.537\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0978816097324187,\n        \"min\": 0.533,\n        \"max\": 0.815,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.75,\n          0.8,\n          0.54\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10990038779774729,\n        \"min\": 0.494,\n        \"max\": 0.863,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.789,\n          0.781,\n          0.494\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09965712647444165,\n        \"min\": 0.516,\n        \"max\": 0.822,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.769,\n          0.791,\n          0.516\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10990038779774729,\n        \"min\": 0.494,\n        \"max\": 0.863,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.789,\n          0.781,\n          0.494\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11864585157197069,\n        \"min\": 0.395,\n        \"max\": 0.811,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.737,\n          0.805,\n          0.58\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19996594948235796,\n        \"min\": 0.074,\n        \"max\": 0.641,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.526,\n          0.586,\n          0.074\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["metrics_df_CNN.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/TF Domain/CNN/Alpha_TF_CNN.csv', index = False)"],"metadata":{"id":"_iOLsKpkfzdG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# GRU\n"],"metadata":{"id":"Ssm9VqaJH_e4"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model_gru(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(GRU(256, return_sequences=True))\n","    model.add(GRU(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning_gru(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model_gru(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model_gru(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time+Frequency/Alpha/CNN_GRU/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time+Frequency/Alpha/CNN_GRU/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n","\n"],"metadata":{"id":"ieXSN-9PI4Dx","executionInfo":{"status":"ok","timestamp":1717589290148,"user_tz":-360,"elapsed":602,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ba522630-f978-47a7-cd81-c5bc3458e091"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["global_model_gru, metrics_df_gru = federated_learning_gru(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"lD5S-Pvy5B-r","executionInfo":{"status":"ok","timestamp":1717590591205,"user_tz":-360,"elapsed":1301062,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}},"outputId":"60d84d5f-620a-422d-802c-8b3d2f5efa79"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 37, 29), Test shape: (1194, 37, 29)\n","Train shape: (4418, 37, 29), Test shape: (1416, 37, 29)\n","Train shape: (4838, 37, 29), Test shape: (996, 37, 29)\n","Train shape: (4640, 37, 29), Test shape: (1194, 37, 29)\n","Train shape: (4418, 37, 29), Test shape: (1416, 37, 29)\n","Train shape: (4838, 37, 29), Test shape: (996, 37, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 1.7053 - accuracy: 0.4949"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 33s 235ms/step - loss: 1.7053 - accuracy: 0.4949 - val_loss: 1.7002 - val_accuracy: 0.4871\n","Epoch 2/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.6955 - accuracy: 0.5003 - val_loss: 1.6905 - val_accuracy: 0.4978\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.6859 - accuracy: 0.5046 - val_loss: 1.6810 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.6764 - accuracy: 0.5032 - val_loss: 1.6715 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.6669 - accuracy: 0.5046 - val_loss: 1.6621 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.6573 - accuracy: 0.5078 - val_loss: 1.6528 - val_accuracy: 0.5075\n","Epoch 7/100\n","29/29 [==============================] - 1s 34ms/step - loss: 1.6480 - accuracy: 0.5127 - val_loss: 1.6435 - val_accuracy: 0.5119\n","Epoch 8/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.6389 - accuracy: 0.5046 - val_loss: 1.6344 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.6297 - accuracy: 0.5048 - val_loss: 1.6254 - val_accuracy: 0.4849\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.6206 - accuracy: 0.5073 - val_loss: 1.6164 - val_accuracy: 0.4849\n","Epoch 11/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.6116 - accuracy: 0.5100 - val_loss: 1.6075 - val_accuracy: 0.4849\n","Epoch 12/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.6027 - accuracy: 0.5110 - val_loss: 1.5987 - val_accuracy: 0.4860\n","Epoch 13/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.5938 - accuracy: 0.5089 - val_loss: 1.5900 - val_accuracy: 0.4849\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5850 - accuracy: 0.5116 - val_loss: 1.5813 - val_accuracy: 0.4925\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5764 - accuracy: 0.5407 - val_loss: 1.5727 - val_accuracy: 0.4935\n","Epoch 16/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.5678 - accuracy: 0.5259 - val_loss: 1.5642 - val_accuracy: 0.4871\n","Epoch 17/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5592 - accuracy: 0.5302 - val_loss: 1.5559 - val_accuracy: 0.4838\n","Epoch 18/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5508 - accuracy: 0.5127 - val_loss: 1.5475 - val_accuracy: 0.4968\n","Epoch 19/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.5424 - accuracy: 0.5401 - val_loss: 1.5392 - val_accuracy: 0.4925\n","Epoch 20/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.5342 - accuracy: 0.5216 - val_loss: 1.5309 - val_accuracy: 0.5323\n","Epoch 21/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.5258 - accuracy: 0.5337 - val_loss: 1.5229 - val_accuracy: 0.5129\n","Epoch 22/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5174 - accuracy: 0.5490 - val_loss: 1.5151 - val_accuracy: 0.4935\n","Epoch 23/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.5095 - accuracy: 0.5272 - val_loss: 1.5065 - val_accuracy: 0.5636\n","Epoch 24/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5015 - accuracy: 0.5595 - val_loss: 1.4998 - val_accuracy: 0.4871\n","Epoch 25/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4930 - accuracy: 0.5216 - val_loss: 1.4906 - val_accuracy: 0.5399\n","Epoch 26/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4854 - accuracy: 0.5372 - val_loss: 1.4830 - val_accuracy: 0.5539\n","Epoch 27/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4767 - accuracy: 0.5695 - val_loss: 1.4759 - val_accuracy: 0.5097\n","Epoch 28/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.4688 - accuracy: 0.5633 - val_loss: 1.4675 - val_accuracy: 0.5506\n","Epoch 29/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.4613 - accuracy: 0.5625 - val_loss: 1.4612 - val_accuracy: 0.4978\n","Epoch 30/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.4544 - accuracy: 0.5477 - val_loss: 1.4519 - val_accuracy: 0.5399\n","Epoch 31/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.4453 - accuracy: 0.5652 - val_loss: 1.4448 - val_accuracy: 0.5528\n","Epoch 32/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.4374 - accuracy: 0.5703 - val_loss: 1.4378 - val_accuracy: 0.5431\n","Epoch 33/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.4286 - accuracy: 0.5765 - val_loss: 1.4296 - val_accuracy: 0.5603\n","Epoch 34/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.4202 - accuracy: 0.5819 - val_loss: 1.4253 - val_accuracy: 0.5172\n","Epoch 35/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4137 - accuracy: 0.5679 - val_loss: 1.4169 - val_accuracy: 0.5399\n","Epoch 36/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.4059 - accuracy: 0.5676 - val_loss: 1.4079 - val_accuracy: 0.5668\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3982 - accuracy: 0.5849 - val_loss: 1.4015 - val_accuracy: 0.5625\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3896 - accuracy: 0.5851 - val_loss: 1.3969 - val_accuracy: 0.5409\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3819 - accuracy: 0.5709 - val_loss: 1.3903 - val_accuracy: 0.5485\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3734 - accuracy: 0.5832 - val_loss: 1.3816 - val_accuracy: 0.5614\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3651 - accuracy: 0.5897 - val_loss: 1.3765 - val_accuracy: 0.5550\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3585 - accuracy: 0.5878 - val_loss: 1.3809 - val_accuracy: 0.5226\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3491 - accuracy: 0.5929 - val_loss: 1.3663 - val_accuracy: 0.5442\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3398 - accuracy: 0.6026 - val_loss: 1.3544 - val_accuracy: 0.5668\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3312 - accuracy: 0.6078 - val_loss: 1.3603 - val_accuracy: 0.5399\n","Epoch 46/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3271 - accuracy: 0.5978 - val_loss: 1.3437 - val_accuracy: 0.5571\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3158 - accuracy: 0.6180 - val_loss: 1.3407 - val_accuracy: 0.5625\n","Epoch 48/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.3062 - accuracy: 0.6237 - val_loss: 1.3366 - val_accuracy: 0.5463\n","Epoch 49/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.2981 - accuracy: 0.6185 - val_loss: 1.3260 - val_accuracy: 0.5765\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2906 - accuracy: 0.6285 - val_loss: 1.3231 - val_accuracy: 0.5668\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2794 - accuracy: 0.6328 - val_loss: 1.3149 - val_accuracy: 0.5765\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2728 - accuracy: 0.6371 - val_loss: 1.3142 - val_accuracy: 0.5690\n","Epoch 53/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.2662 - accuracy: 0.6385 - val_loss: 1.3072 - val_accuracy: 0.5787\n","Epoch 54/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.2561 - accuracy: 0.6476 - val_loss: 1.3030 - val_accuracy: 0.5851\n","Epoch 55/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.2447 - accuracy: 0.6525 - val_loss: 1.2984 - val_accuracy: 0.5776\n","Epoch 56/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2420 - accuracy: 0.6371 - val_loss: 1.2934 - val_accuracy: 0.5776\n","Epoch 57/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.2300 - accuracy: 0.6487 - val_loss: 1.2881 - val_accuracy: 0.5819\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2267 - accuracy: 0.6557 - val_loss: 1.3064 - val_accuracy: 0.5539\n","Epoch 59/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2289 - accuracy: 0.6377 - val_loss: 1.2877 - val_accuracy: 0.5668\n","Epoch 60/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2081 - accuracy: 0.6651 - val_loss: 1.2765 - val_accuracy: 0.5808\n","Epoch 61/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2006 - accuracy: 0.6700 - val_loss: 1.2733 - val_accuracy: 0.5797\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1890 - accuracy: 0.6748 - val_loss: 1.2762 - val_accuracy: 0.5711\n","Epoch 63/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.1796 - accuracy: 0.6835 - val_loss: 1.2698 - val_accuracy: 0.5938\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1753 - accuracy: 0.6797 - val_loss: 1.2637 - val_accuracy: 0.5841\n","Epoch 65/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1672 - accuracy: 0.6786 - val_loss: 1.2690 - val_accuracy: 0.5722\n","Epoch 66/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1575 - accuracy: 0.6832 - val_loss: 1.2662 - val_accuracy: 0.5722\n","Epoch 67/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1483 - accuracy: 0.6950 - val_loss: 1.2551 - val_accuracy: 0.5830\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1442 - accuracy: 0.6959 - val_loss: 1.2957 - val_accuracy: 0.5550\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1387 - accuracy: 0.6862 - val_loss: 1.2481 - val_accuracy: 0.5938\n","Epoch 70/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1260 - accuracy: 0.7012 - val_loss: 1.2459 - val_accuracy: 0.5873\n","Epoch 71/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.1304 - accuracy: 0.6832 - val_loss: 1.2415 - val_accuracy: 0.5959\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1171 - accuracy: 0.6985 - val_loss: 1.2750 - val_accuracy: 0.5582\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1116 - accuracy: 0.7018 - val_loss: 1.2484 - val_accuracy: 0.5711\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0992 - accuracy: 0.7012 - val_loss: 1.2347 - val_accuracy: 0.5894\n","Epoch 75/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0903 - accuracy: 0.7171 - val_loss: 1.2422 - val_accuracy: 0.5711\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0869 - accuracy: 0.7150 - val_loss: 1.2313 - val_accuracy: 0.5894\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0788 - accuracy: 0.7115 - val_loss: 1.2600 - val_accuracy: 0.5550\n","Epoch 78/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0767 - accuracy: 0.7179 - val_loss: 1.2263 - val_accuracy: 0.5938\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0657 - accuracy: 0.7241 - val_loss: 1.2262 - val_accuracy: 0.5905\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0539 - accuracy: 0.7260 - val_loss: 1.2536 - val_accuracy: 0.5528\n","Epoch 81/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0522 - accuracy: 0.7263 - val_loss: 1.2458 - val_accuracy: 0.5636\n","Epoch 82/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0528 - accuracy: 0.7174 - val_loss: 1.2204 - val_accuracy: 0.5938\n","Epoch 83/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.0480 - accuracy: 0.7295 - val_loss: 1.2384 - val_accuracy: 0.5647\n","Epoch 84/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.0342 - accuracy: 0.7282 - val_loss: 1.2161 - val_accuracy: 0.5894\n","Epoch 85/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.0252 - accuracy: 0.7346 - val_loss: 1.2170 - val_accuracy: 0.5884\n","Epoch 86/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.0153 - accuracy: 0.7478 - val_loss: 1.2186 - val_accuracy: 0.5830\n","Epoch 87/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.0112 - accuracy: 0.7379 - val_loss: 1.2177 - val_accuracy: 0.5819\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0057 - accuracy: 0.7433 - val_loss: 1.2223 - val_accuracy: 0.5797\n","Epoch 89/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9991 - accuracy: 0.7462 - val_loss: 1.2153 - val_accuracy: 0.5819\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9925 - accuracy: 0.7538 - val_loss: 1.2130 - val_accuracy: 0.5894\n","Epoch 91/100\n","29/29 [==============================] - 1s 38ms/step - loss: 0.9832 - accuracy: 0.7581 - val_loss: 1.2120 - val_accuracy: 0.5970\n","Epoch 92/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9832 - accuracy: 0.7546 - val_loss: 1.2067 - val_accuracy: 0.5970\n","Epoch 93/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.9683 - accuracy: 0.7654 - val_loss: 1.2138 - val_accuracy: 0.5991\n","Epoch 94/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9684 - accuracy: 0.7667 - val_loss: 1.2051 - val_accuracy: 0.5916\n","Epoch 95/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9565 - accuracy: 0.7664 - val_loss: 1.2076 - val_accuracy: 0.5948\n","Epoch 96/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9669 - accuracy: 0.7540 - val_loss: 1.2071 - val_accuracy: 0.6024\n","Epoch 97/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9463 - accuracy: 0.7710 - val_loss: 1.2380 - val_accuracy: 0.5722\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9291 - accuracy: 0.7839 - val_loss: 1.2141 - val_accuracy: 0.5905\n","Epoch 99/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.9329 - accuracy: 0.7769 - val_loss: 1.2065 - val_accuracy: 0.5948\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9268 - accuracy: 0.7734 - val_loss: 1.2625 - val_accuracy: 0.5560\n","{'loss': [1.7052993774414062, 1.69550359249115, 1.6858550310134888, 1.676355004310608, 1.6669269800186157, 1.657301664352417, 1.6480432748794556, 1.638946533203125, 1.6297341585159302, 1.6206153631210327, 1.6116175651550293, 1.6027082204818726, 1.5938431024551392, 1.5849614143371582, 1.5764151811599731, 1.5678191184997559, 1.5591922998428345, 1.5508222579956055, 1.5423892736434937, 1.5342129468917847, 1.5257853269577026, 1.517432451248169, 1.5095160007476807, 1.5014623403549194, 1.493008017539978, 1.4854180812835693, 1.476731538772583, 1.4687752723693848, 1.4613112211227417, 1.4543875455856323, 1.4452921152114868, 1.4374239444732666, 1.428605079650879, 1.4202051162719727, 1.4137004613876343, 1.4059494733810425, 1.3981910943984985, 1.389555811882019, 1.3818634748458862, 1.373402714729309, 1.3650553226470947, 1.3585302829742432, 1.3490824699401855, 1.3398226499557495, 1.33119535446167, 1.3270721435546875, 1.3157707452774048, 1.3062031269073486, 1.2981007099151611, 1.2906018495559692, 1.2794312238693237, 1.272839903831482, 1.2661877870559692, 1.2560689449310303, 1.2446917295455933, 1.2420051097869873, 1.2300007343292236, 1.2267065048217773, 1.2288788557052612, 1.2081294059753418, 1.2006170749664307, 1.189018726348877, 1.179572582244873, 1.1752862930297852, 1.167212963104248, 1.157474160194397, 1.1483254432678223, 1.1441863775253296, 1.1386613845825195, 1.1260254383087158, 1.1303731203079224, 1.117146611213684, 1.111575961112976, 1.0992237329483032, 1.0903229713439941, 1.086887001991272, 1.078816294670105, 1.0766758918762207, 1.0657340288162231, 1.0538684129714966, 1.0522382259368896, 1.0527889728546143, 1.0479680299758911, 1.0342392921447754, 1.0251957178115845, 1.0153435468673706, 1.0112390518188477, 1.0057222843170166, 0.9990609288215637, 0.9924710392951965, 0.9831908941268921, 0.983167290687561, 0.9682633876800537, 0.9683728218078613, 0.9565371870994568, 0.9668731689453125, 0.9463057518005371, 0.9291292428970337, 0.9328698515892029, 0.9267696738243103], 'accuracy': [0.49488145112991333, 0.5002694129943848, 0.5045797228813171, 0.5032327771186829, 0.5045797228813171, 0.5078125, 0.5126616358757019, 0.5045797228813171, 0.5048491358757019, 0.5072737336158752, 0.5099676847457886, 0.5110452771186829, 0.5088900923728943, 0.5115840435028076, 0.540678858757019, 0.5258620977401733, 0.5301724076271057, 0.5126616358757019, 0.5401400923728943, 0.5215517282485962, 0.5336745977401733, 0.5490301847457886, 0.5272090435028076, 0.5595366358757019, 0.5215517282485962, 0.5371767282485962, 0.5695043206214905, 0.5633081793785095, 0.5625, 0.5476831793785095, 0.5651939511299133, 0.5703125, 0.576508641242981, 0.5818965435028076, 0.5678879022598267, 0.5676185488700867, 0.5848599076271057, 0.5851293206214905, 0.5708512663841248, 0.5832435488700867, 0.5897090435028076, 0.5878232717514038, 0.5929418206214905, 0.6026400923728943, 0.607758641242981, 0.5977909564971924, 0.6179956793785095, 0.623652994632721, 0.618534505367279, 0.6285021305084229, 0.6328125, 0.6371228694915771, 0.6384698152542114, 0.6476293206214905, 0.6524784564971924, 0.6371228694915771, 0.6487069129943848, 0.6557112336158752, 0.6376616358757019, 0.6651400923728943, 0.6699892282485962, 0.6748383641242981, 0.6834590435028076, 0.6796875, 0.6786099076271057, 0.6831896305084229, 0.6950430870056152, 0.6958512663841248, 0.686152994632721, 0.7012392282485962, 0.6831896305084229, 0.6985452771186829, 0.701777994632721, 0.7012392282485962, 0.717133641242981, 0.7149784564971924, 0.7114762663841248, 0.7179418206214905, 0.7241379022598267, 0.7260237336158752, 0.7262930870056152, 0.717402994632721, 0.7295258641242981, 0.728178858757019, 0.7346444129943848, 0.7478448152542114, 0.7378771305084229, 0.7432650923728943, 0.7462284564971924, 0.7537715435028076, 0.7580819129943848, 0.7545797228813171, 0.7653555870056152, 0.7667025923728943, 0.7664331793785095, 0.7540409564971924, 0.7710129022598267, 0.7839439511299133, 0.7769396305084229, 0.7734375], 'val_loss': [1.7001620531082153, 1.6905125379562378, 1.6809717416763306, 1.671492099761963, 1.6621208190917969, 1.652777910232544, 1.6435465812683105, 1.6344444751739502, 1.6253838539123535, 1.616391658782959, 1.6075252294540405, 1.598669171333313, 1.5899571180343628, 1.5812897682189941, 1.5727131366729736, 1.5642482042312622, 1.5559183359146118, 1.5474750995635986, 1.539227843284607, 1.5309300422668457, 1.5228934288024902, 1.5150847434997559, 1.5065066814422607, 1.4997855424880981, 1.4905868768692017, 1.4829779863357544, 1.4759495258331299, 1.4675073623657227, 1.461234211921692, 1.4519401788711548, 1.44478440284729, 1.4377936124801636, 1.429630160331726, 1.425263524055481, 1.4169195890426636, 1.4079147577285767, 1.4014843702316284, 1.3968522548675537, 1.3902738094329834, 1.3815929889678955, 1.3764548301696777, 1.3808729648590088, 1.3662726879119873, 1.3543610572814941, 1.360348105430603, 1.3436853885650635, 1.3407204151153564, 1.336556315422058, 1.3259789943695068, 1.3230615854263306, 1.314893126487732, 1.3141618967056274, 1.3072383403778076, 1.3030458688735962, 1.298372745513916, 1.2933883666992188, 1.2880663871765137, 1.3063548803329468, 1.2877246141433716, 1.276479959487915, 1.2733228206634521, 1.276208519935608, 1.2698309421539307, 1.263685941696167, 1.2690064907073975, 1.2661700248718262, 1.2550671100616455, 1.2957497835159302, 1.2481037378311157, 1.2459211349487305, 1.241473913192749, 1.2749873399734497, 1.2484322786331177, 1.2346657514572144, 1.2422468662261963, 1.231306552886963, 1.2599893808364868, 1.2263458967208862, 1.2262370586395264, 1.253603219985962, 1.2457786798477173, 1.220352053642273, 1.238368034362793, 1.2160513401031494, 1.217010259628296, 1.218634009361267, 1.217679500579834, 1.222325086593628, 1.2153304815292358, 1.2130154371261597, 1.2119842767715454, 1.2067320346832275, 1.213812232017517, 1.2051081657409668, 1.2075552940368652, 1.2070748805999756, 1.2379571199417114, 1.2141362428665161, 1.2065417766571045, 1.2624722719192505], 'val_accuracy': [0.48706895112991333, 0.4978448152542114, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.5075430870056152, 0.5118534564971924, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.48491379618644714, 0.4924568831920624, 0.49353447556495667, 0.48706895112991333, 0.48383620381355286, 0.4967672526836395, 0.4924568831920624, 0.5323275923728943, 0.5129310488700867, 0.49353447556495667, 0.5635775923728943, 0.48706895112991333, 0.5398706793785095, 0.5538793206214905, 0.5096982717514038, 0.5506465435028076, 0.4978448152542114, 0.5398706793785095, 0.5528017282485962, 0.5431034564971924, 0.5603448152542114, 0.517241358757019, 0.5398706793785095, 0.5668103694915771, 0.5625, 0.5409482717514038, 0.548491358757019, 0.5614224076271057, 0.5549569129943848, 0.5226293206214905, 0.5441810488700867, 0.5668103694915771, 0.5398706793785095, 0.5571120977401733, 0.5625, 0.5463362336158752, 0.576508641242981, 0.5668103694915771, 0.576508641242981, 0.568965494632721, 0.5786637663841248, 0.5851293206214905, 0.5775862336158752, 0.5775862336158752, 0.5818965435028076, 0.5538793206214905, 0.5668103694915771, 0.5808189511299133, 0.579741358757019, 0.5711206793785095, 0.59375, 0.5840517282485962, 0.5721982717514038, 0.5721982717514038, 0.5829741358757019, 0.5549569129943848, 0.59375, 0.587284505367279, 0.5959051847457886, 0.5581896305084229, 0.5711206793785095, 0.5894396305084229, 0.5711206793785095, 0.5894396305084229, 0.5549569129943848, 0.59375, 0.5905172228813171, 0.5528017282485962, 0.5635775923728943, 0.59375, 0.5646551847457886, 0.5894396305084229, 0.5883620977401733, 0.5829741358757019, 0.5818965435028076, 0.579741358757019, 0.5818965435028076, 0.5894396305084229, 0.5969827771186829, 0.5969827771186829, 0.5991379022598267, 0.5915948152542114, 0.5948275923728943, 0.6023706793785095, 0.5721982717514038, 0.5905172228813171, 0.5948275923728943, 0.556034505367279]}\n","38/38 [==============================] - 1s 10ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 1.7054 - accuracy: 0.5028"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 13s 210ms/step - loss: 1.7054 - accuracy: 0.5028 - val_loss: 1.7005 - val_accuracy: 0.4943\n","Epoch 2/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.6959 - accuracy: 0.5031 - val_loss: 1.6912 - val_accuracy: 0.4943\n","Epoch 3/100\n","28/28 [==============================] - 1s 32ms/step - loss: 1.6866 - accuracy: 0.5175 - val_loss: 1.6819 - val_accuracy: 0.4966\n","Epoch 4/100\n","28/28 [==============================] - 1s 33ms/step - loss: 1.6774 - accuracy: 0.5113 - val_loss: 1.6728 - val_accuracy: 0.4989\n","Epoch 5/100\n","28/28 [==============================] - 1s 33ms/step - loss: 1.6682 - accuracy: 0.5232 - val_loss: 1.6638 - val_accuracy: 0.5011\n","Epoch 6/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.6592 - accuracy: 0.5136 - val_loss: 1.6548 - val_accuracy: 0.4966\n","Epoch 7/100\n","28/28 [==============================] - 1s 42ms/step - loss: 1.6500 - accuracy: 0.5272 - val_loss: 1.6459 - val_accuracy: 0.5023\n","Epoch 8/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.6412 - accuracy: 0.5354 - val_loss: 1.6371 - val_accuracy: 0.5011\n","Epoch 9/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.6326 - accuracy: 0.5181 - val_loss: 1.6284 - val_accuracy: 0.5000\n","Epoch 10/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.6239 - accuracy: 0.5065 - val_loss: 1.6198 - val_accuracy: 0.5000\n","Epoch 11/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.6151 - accuracy: 0.5190 - val_loss: 1.6112 - val_accuracy: 0.5045\n","Epoch 12/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.6064 - accuracy: 0.5331 - val_loss: 1.6028 - val_accuracy: 0.4966\n","Epoch 13/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.5979 - accuracy: 0.5388 - val_loss: 1.5945 - val_accuracy: 0.4966\n","Epoch 14/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.5894 - accuracy: 0.5308 - val_loss: 1.5862 - val_accuracy: 0.4966\n","Epoch 15/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.5814 - accuracy: 0.5198 - val_loss: 1.5780 - val_accuracy: 0.5068\n","Epoch 16/100\n","28/28 [==============================] - 1s 45ms/step - loss: 1.5730 - accuracy: 0.5289 - val_loss: 1.5698 - val_accuracy: 0.5260\n","Epoch 17/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5648 - accuracy: 0.5184 - val_loss: 1.5618 - val_accuracy: 0.5102\n","Epoch 18/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.5563 - accuracy: 0.5490 - val_loss: 1.5538 - val_accuracy: 0.5181\n","Epoch 19/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.5481 - accuracy: 0.5614 - val_loss: 1.5459 - val_accuracy: 0.5204\n","Epoch 20/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.5403 - accuracy: 0.5467 - val_loss: 1.5380 - val_accuracy: 0.5192\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.5323 - accuracy: 0.5470 - val_loss: 1.5302 - val_accuracy: 0.5136\n","Epoch 22/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.5242 - accuracy: 0.5727 - val_loss: 1.5225 - val_accuracy: 0.5249\n","Epoch 23/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.5164 - accuracy: 0.5424 - val_loss: 1.5148 - val_accuracy: 0.5271\n","Epoch 24/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.5085 - accuracy: 0.5504 - val_loss: 1.5074 - val_accuracy: 0.5192\n","Epoch 25/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.5007 - accuracy: 0.5504 - val_loss: 1.5006 - val_accuracy: 0.5011\n","Epoch 26/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.4933 - accuracy: 0.5509 - val_loss: 1.4929 - val_accuracy: 0.5045\n","Epoch 27/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.4850 - accuracy: 0.5637 - val_loss: 1.4856 - val_accuracy: 0.5102\n","Epoch 28/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.4777 - accuracy: 0.5523 - val_loss: 1.4784 - val_accuracy: 0.5113\n","Epoch 29/100\n","28/28 [==============================] - 1s 33ms/step - loss: 1.4698 - accuracy: 0.5631 - val_loss: 1.4705 - val_accuracy: 0.5294\n","Epoch 30/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.4616 - accuracy: 0.5623 - val_loss: 1.4631 - val_accuracy: 0.5430\n","Epoch 31/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4543 - accuracy: 0.5696 - val_loss: 1.4564 - val_accuracy: 0.5339\n","Epoch 32/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4462 - accuracy: 0.5716 - val_loss: 1.4490 - val_accuracy: 0.5305\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4400 - accuracy: 0.5543 - val_loss: 1.4422 - val_accuracy: 0.5396\n","Epoch 34/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.4323 - accuracy: 0.5702 - val_loss: 1.4365 - val_accuracy: 0.5283\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4238 - accuracy: 0.5849 - val_loss: 1.4290 - val_accuracy: 0.5407\n","Epoch 36/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.4149 - accuracy: 0.5894 - val_loss: 1.4222 - val_accuracy: 0.5464\n","Epoch 37/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.4075 - accuracy: 0.5852 - val_loss: 1.4157 - val_accuracy: 0.5475\n","Epoch 38/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4005 - accuracy: 0.5818 - val_loss: 1.4093 - val_accuracy: 0.5464\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3921 - accuracy: 0.5832 - val_loss: 1.4035 - val_accuracy: 0.5339\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3849 - accuracy: 0.5937 - val_loss: 1.3973 - val_accuracy: 0.5430\n","Epoch 41/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.3774 - accuracy: 0.5883 - val_loss: 1.3910 - val_accuracy: 0.5498\n","Epoch 42/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3702 - accuracy: 0.5951 - val_loss: 1.3854 - val_accuracy: 0.5452\n","Epoch 43/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.3626 - accuracy: 0.5959 - val_loss: 1.3790 - val_accuracy: 0.5543\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3531 - accuracy: 0.6022 - val_loss: 1.3737 - val_accuracy: 0.5475\n","Epoch 45/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3480 - accuracy: 0.5945 - val_loss: 1.3674 - val_accuracy: 0.5475\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3388 - accuracy: 0.6089 - val_loss: 1.3677 - val_accuracy: 0.5362\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3373 - accuracy: 0.5971 - val_loss: 1.3643 - val_accuracy: 0.5407\n","Epoch 48/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.3286 - accuracy: 0.6078 - val_loss: 1.3534 - val_accuracy: 0.5430\n","Epoch 49/100\n","28/28 [==============================] - 1s 33ms/step - loss: 1.3172 - accuracy: 0.6248 - val_loss: 1.3497 - val_accuracy: 0.5554\n","Epoch 50/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.3154 - accuracy: 0.6010 - val_loss: 1.3399 - val_accuracy: 0.5532\n","Epoch 51/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.3028 - accuracy: 0.6231 - val_loss: 1.3405 - val_accuracy: 0.5407\n","Epoch 52/100\n","28/28 [==============================] - 1s 33ms/step - loss: 1.2983 - accuracy: 0.6180 - val_loss: 1.3298 - val_accuracy: 0.5645\n","Epoch 53/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.2881 - accuracy: 0.6242 - val_loss: 1.3261 - val_accuracy: 0.5543\n","Epoch 54/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2824 - accuracy: 0.6217 - val_loss: 1.3199 - val_accuracy: 0.5622\n","Epoch 55/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2707 - accuracy: 0.6338 - val_loss: 1.3165 - val_accuracy: 0.5543\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2747 - accuracy: 0.6186 - val_loss: 1.3259 - val_accuracy: 0.5430\n","Epoch 57/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.2558 - accuracy: 0.6446 - val_loss: 1.3090 - val_accuracy: 0.5656\n","Epoch 58/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.2497 - accuracy: 0.6443 - val_loss: 1.3041 - val_accuracy: 0.5667\n","Epoch 59/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2429 - accuracy: 0.6553 - val_loss: 1.2978 - val_accuracy: 0.5645\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2418 - accuracy: 0.6466 - val_loss: 1.3103 - val_accuracy: 0.5452\n","Epoch 61/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.2296 - accuracy: 0.6630 - val_loss: 1.2888 - val_accuracy: 0.5679\n","Epoch 62/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2199 - accuracy: 0.6636 - val_loss: 1.2909 - val_accuracy: 0.5645\n","Epoch 63/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.2218 - accuracy: 0.6460 - val_loss: 1.2804 - val_accuracy: 0.5735\n","Epoch 64/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2092 - accuracy: 0.6647 - val_loss: 1.2873 - val_accuracy: 0.5588\n","Epoch 65/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.2033 - accuracy: 0.6661 - val_loss: 1.2733 - val_accuracy: 0.5758\n","Epoch 66/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1929 - accuracy: 0.6678 - val_loss: 1.2751 - val_accuracy: 0.5701\n","Epoch 67/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.1836 - accuracy: 0.6737 - val_loss: 1.2742 - val_accuracy: 0.5656\n","Epoch 68/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.1739 - accuracy: 0.6839 - val_loss: 1.2646 - val_accuracy: 0.5826\n","Epoch 69/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1675 - accuracy: 0.6825 - val_loss: 1.2613 - val_accuracy: 0.5769\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1668 - accuracy: 0.6774 - val_loss: 1.2767 - val_accuracy: 0.5611\n","Epoch 71/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1618 - accuracy: 0.6735 - val_loss: 1.2576 - val_accuracy: 0.5826\n","Epoch 72/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.1500 - accuracy: 0.6896 - val_loss: 1.2662 - val_accuracy: 0.5611\n","Epoch 73/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.1459 - accuracy: 0.6828 - val_loss: 1.2471 - val_accuracy: 0.5792\n","Epoch 74/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.1371 - accuracy: 0.6969 - val_loss: 1.2449 - val_accuracy: 0.5814\n","Epoch 75/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.1396 - accuracy: 0.6842 - val_loss: 1.2721 - val_accuracy: 0.5498\n","Epoch 76/100\n","28/28 [==============================] - 1s 33ms/step - loss: 1.1304 - accuracy: 0.6952 - val_loss: 1.2458 - val_accuracy: 0.5837\n","Epoch 77/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1158 - accuracy: 0.6964 - val_loss: 1.2526 - val_accuracy: 0.5701\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1124 - accuracy: 0.7009 - val_loss: 1.2463 - val_accuracy: 0.5758\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1053 - accuracy: 0.7060 - val_loss: 1.2440 - val_accuracy: 0.5792\n","Epoch 80/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.0954 - accuracy: 0.7088 - val_loss: 1.2316 - val_accuracy: 0.5860\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0896 - accuracy: 0.7066 - val_loss: 1.2294 - val_accuracy: 0.5848\n","Epoch 82/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.0800 - accuracy: 0.7173 - val_loss: 1.2262 - val_accuracy: 0.5871\n","Epoch 83/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0731 - accuracy: 0.7131 - val_loss: 1.2267 - val_accuracy: 0.5814\n","Epoch 84/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0634 - accuracy: 0.7272 - val_loss: 1.2393 - val_accuracy: 0.5758\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0643 - accuracy: 0.7179 - val_loss: 1.2354 - val_accuracy: 0.5701\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0507 - accuracy: 0.7334 - val_loss: 1.2271 - val_accuracy: 0.5860\n","Epoch 87/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.0441 - accuracy: 0.7377 - val_loss: 1.2178 - val_accuracy: 0.5905\n","Epoch 88/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0373 - accuracy: 0.7329 - val_loss: 1.2179 - val_accuracy: 0.5781\n","Epoch 89/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0339 - accuracy: 0.7377 - val_loss: 1.2168 - val_accuracy: 0.5860\n","Epoch 90/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.0260 - accuracy: 0.7380 - val_loss: 1.2165 - val_accuracy: 0.5928\n","Epoch 91/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0238 - accuracy: 0.7380 - val_loss: 1.2232 - val_accuracy: 0.5826\n","Epoch 92/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0144 - accuracy: 0.7487 - val_loss: 1.2219 - val_accuracy: 0.5848\n","Epoch 93/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.0189 - accuracy: 0.7388 - val_loss: 1.2256 - val_accuracy: 0.5758\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0219 - accuracy: 0.7298 - val_loss: 1.2105 - val_accuracy: 0.5928\n","Epoch 95/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0011 - accuracy: 0.7411 - val_loss: 1.2301 - val_accuracy: 0.5724\n","Epoch 96/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9986 - accuracy: 0.7518 - val_loss: 1.2191 - val_accuracy: 0.5758\n","Epoch 97/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9856 - accuracy: 0.7566 - val_loss: 1.2055 - val_accuracy: 0.5860\n","Epoch 98/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9791 - accuracy: 0.7583 - val_loss: 1.2041 - val_accuracy: 0.5894\n","Epoch 99/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9751 - accuracy: 0.7561 - val_loss: 1.2209 - val_accuracy: 0.5882\n","Epoch 100/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.9900 - accuracy: 0.7400 - val_loss: 1.2164 - val_accuracy: 0.5735\n","{'loss': [1.7053604125976562, 1.6958980560302734, 1.6865984201431274, 1.6774214506149292, 1.6682064533233643, 1.659159541130066, 1.6500401496887207, 1.6412461996078491, 1.632567286491394, 1.623913288116455, 1.6150882244110107, 1.6064339876174927, 1.597857117652893, 1.589442491531372, 1.581393837928772, 1.5730408430099487, 1.5648118257522583, 1.556348204612732, 1.5480707883834839, 1.5403494834899902, 1.5322924852371216, 1.5241934061050415, 1.5164036750793457, 1.5084569454193115, 1.500702977180481, 1.4933297634124756, 1.4849522113800049, 1.4777098894119263, 1.4698474407196045, 1.4615662097930908, 1.4543415307998657, 1.4461658000946045, 1.440049648284912, 1.4322878122329712, 1.423780918121338, 1.414925217628479, 1.4075450897216797, 1.400499939918518, 1.39208984375, 1.3848813772201538, 1.3773659467697144, 1.3702337741851807, 1.3625999689102173, 1.353096604347229, 1.3479771614074707, 1.3388116359710693, 1.3373137712478638, 1.3286025524139404, 1.3171852827072144, 1.3154319524765015, 1.3028016090393066, 1.2983285188674927, 1.2880747318267822, 1.2824326753616333, 1.2707382440567017, 1.2747001647949219, 1.2557744979858398, 1.2496700286865234, 1.2429347038269043, 1.2418444156646729, 1.2295657396316528, 1.219853162765503, 1.221750259399414, 1.209194302558899, 1.2032510042190552, 1.1928900480270386, 1.1836097240447998, 1.1738718748092651, 1.1674745082855225, 1.1667706966400146, 1.1617927551269531, 1.14999520778656, 1.1459137201309204, 1.1370608806610107, 1.1395639181137085, 1.1303539276123047, 1.1158456802368164, 1.1124234199523926, 1.1052848100662231, 1.095402717590332, 1.089551329612732, 1.080013632774353, 1.0731163024902344, 1.063358187675476, 1.064346194267273, 1.0506815910339355, 1.0440831184387207, 1.0372633934020996, 1.033894419670105, 1.0260069370269775, 1.0238122940063477, 1.0144492387771606, 1.0189064741134644, 1.0218955278396606, 1.0010756254196167, 0.9986263513565063, 0.9855665564537048, 0.9790821075439453, 0.9751043319702148, 0.9900229573249817], 'accuracy': [0.5028296709060669, 0.5031126141548157, 0.5175438523292542, 0.5113186240196228, 0.5232031941413879, 0.5135823488235474, 0.5271646976470947, 0.5353707075119019, 0.5181097984313965, 0.5065082311630249, 0.5189586877822876, 0.5331069827079773, 0.5387662649154663, 0.5308432579040527, 0.5198075771331787, 0.528862476348877, 0.5183927416801453, 0.5489530563354492, 0.5614035129547119, 0.5466893315315247, 0.5469722747802734, 0.5727221369743347, 0.5424448251724243, 0.5503678321838379, 0.5503678321838379, 0.5509337782859802, 0.5636672377586365, 0.5523486137390137, 0.5631012916564941, 0.562252402305603, 0.569609522819519, 0.57159024477005, 0.5543293952941895, 0.5701754093170166, 0.5848896503448486, 0.5894170999526978, 0.5851725935935974, 0.581777036190033, 0.5831918716430664, 0.5936615467071533, 0.5882852077484131, 0.5950763821601868, 0.5959252715110779, 0.602150559425354, 0.5945104956626892, 0.6089417338371277, 0.5970571637153625, 0.607809841632843, 0.6247877478599548, 0.6010186672210693, 0.6230899691581726, 0.6179966330528259, 0.6242218613624573, 0.6216751337051392, 0.6338426470756531, 0.6185625195503235, 0.6445953845977783, 0.6443123817443848, 0.6553480625152588, 0.6465761065483093, 0.6629881262779236, 0.6635540723800659, 0.646010160446167, 0.6646859049797058, 0.6661007404327393, 0.6677985191345215, 0.673740804195404, 0.6839275360107422, 0.6825127601623535, 0.6774193644523621, 0.6734578609466553, 0.689586877822876, 0.6827957034111023, 0.696943998336792, 0.6842105388641357, 0.695246160030365, 0.6963780522346497, 0.7009055018424988, 0.7059988975524902, 0.7088285088539124, 0.7065647840499878, 0.7173174619674683, 0.7130730152130127, 0.7272212505340576, 0.7178834080696106, 0.7334465384483337, 0.7376909852027893, 0.7328805923461914, 0.7376909852027893, 0.7379739880561829, 0.7379739880561829, 0.7487266659736633, 0.738822877407074, 0.7297679781913757, 0.7410866022109985, 0.751839280128479, 0.7566496729850769, 0.7583475112915039, 0.7560837864875793, 0.7399547100067139], 'val_loss': [1.7004867792129517, 1.6911615133285522, 1.6819372177124023, 1.6728090047836304, 1.6637614965438843, 1.6548032760620117, 1.6459194421768188, 1.6371203660964966, 1.6284151077270508, 1.6198012828826904, 1.6112481355667114, 1.6028157472610474, 1.594457983970642, 1.5861833095550537, 1.5779790878295898, 1.569836974143982, 1.5618083477020264, 1.5537887811660767, 1.5458964109420776, 1.5380269289016724, 1.5302485227584839, 1.5224865674972534, 1.5147576332092285, 1.507364273071289, 1.5005857944488525, 1.4928555488586426, 1.4856210947036743, 1.4784258604049683, 1.4704827070236206, 1.463061809539795, 1.4564015865325928, 1.4490138292312622, 1.4421963691711426, 1.4365278482437134, 1.4289588928222656, 1.4221957921981812, 1.4157090187072754, 1.4093103408813477, 1.4034903049468994, 1.3972804546356201, 1.3909580707550049, 1.38542902469635, 1.379011869430542, 1.373686671257019, 1.367370367050171, 1.3677364587783813, 1.3643090724945068, 1.3533709049224854, 1.3497107028961182, 1.3399362564086914, 1.3404654264450073, 1.329793930053711, 1.3261312246322632, 1.3198819160461426, 1.3165385723114014, 1.3259291648864746, 1.308997631072998, 1.3041272163391113, 1.297837495803833, 1.3103220462799072, 1.2887519598007202, 1.290866494178772, 1.2803839445114136, 1.2873272895812988, 1.2732677459716797, 1.275100827217102, 1.2742164134979248, 1.2645888328552246, 1.2612767219543457, 1.2767343521118164, 1.2576192617416382, 1.266156792640686, 1.2471325397491455, 1.244855523109436, 1.2720729112625122, 1.2457947731018066, 1.252570629119873, 1.2462600469589233, 1.2439519166946411, 1.2316465377807617, 1.229421615600586, 1.2261805534362793, 1.2267004251480103, 1.2393285036087036, 1.2354483604431152, 1.2270898818969727, 1.2178231477737427, 1.2178977727890015, 1.2167744636535645, 1.2164995670318604, 1.2232455015182495, 1.2219387292861938, 1.2256215810775757, 1.2104657888412476, 1.2300807237625122, 1.2190513610839844, 1.2054877281188965, 1.204077124595642, 1.2208623886108398, 1.2163548469543457], 'val_accuracy': [0.4943438768386841, 0.4943438768386841, 0.49660632014274597, 0.49886876344680786, 0.5011312365531921, 0.49660632014274597, 0.5022624731063843, 0.5011312365531921, 0.5, 0.5, 0.5045248866081238, 0.49660632014274597, 0.49660632014274597, 0.49660632014274597, 0.5067873597145081, 0.5260180830955505, 0.5101810097694397, 0.5180995464324951, 0.5203620195388794, 0.5192307829856873, 0.5135746598243713, 0.5248869061470032, 0.5271493196487427, 0.5192307829856873, 0.5011312365531921, 0.5045248866081238, 0.5101810097694397, 0.5113122463226318, 0.529411792755127, 0.5429864525794983, 0.5339366793632507, 0.5305429697036743, 0.5395927429199219, 0.5282805562019348, 0.540723979473114, 0.5463801026344299, 0.5475113391876221, 0.5463801026344299, 0.5339366793632507, 0.5429864525794983, 0.5497737526893616, 0.5452488660812378, 0.5542986392974854, 0.5475113391876221, 0.5475113391876221, 0.5361990928649902, 0.540723979473114, 0.5429864525794983, 0.5554298758506775, 0.5531674027442932, 0.540723979473114, 0.564479649066925, 0.5542986392974854, 0.5622171759605408, 0.5542986392974854, 0.5429864525794983, 0.5656108856201172, 0.5667420625686646, 0.564479649066925, 0.5452488660812378, 0.5678732991218567, 0.564479649066925, 0.5735294222831726, 0.5588235259056091, 0.5757918357849121, 0.570135772228241, 0.5656108856201172, 0.5825791954994202, 0.5769230723381042, 0.5610859990119934, 0.5825791954994202, 0.5610859990119934, 0.5791855454444885, 0.581447958946228, 0.5497737526893616, 0.5837104320526123, 0.570135772228241, 0.5757918357849121, 0.5791855454444885, 0.5859728455543518, 0.5848416090011597, 0.587104082107544, 0.581447958946228, 0.5757918357849121, 0.570135772228241, 0.5859728455543518, 0.5904977321624756, 0.5780543088912964, 0.5859728455543518, 0.5927602052688599, 0.5825791954994202, 0.5848416090011597, 0.5757918357849121, 0.5927602052688599, 0.5723981857299805, 0.5757918357849121, 0.5859728455543518, 0.5893664956092834, 0.5882353186607361, 0.5735294222831726]}\n","45/45 [==============================] - 1s 8ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 1.7051 - accuracy: 0.5023"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 11s 176ms/step - loss: 1.7051 - accuracy: 0.5023 - val_loss: 1.6995 - val_accuracy: 0.4907\n","Epoch 2/100\n","31/31 [==============================] - 1s 29ms/step - loss: 1.6945 - accuracy: 0.5106 - val_loss: 1.6893 - val_accuracy: 0.4979\n","Epoch 3/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.6841 - accuracy: 0.5261 - val_loss: 1.6791 - val_accuracy: 0.4897\n","Epoch 4/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.6738 - accuracy: 0.5248 - val_loss: 1.6690 - val_accuracy: 0.4969\n","Epoch 5/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.6637 - accuracy: 0.5266 - val_loss: 1.6590 - val_accuracy: 0.4876\n","Epoch 6/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.6535 - accuracy: 0.5346 - val_loss: 1.6491 - val_accuracy: 0.4990\n","Epoch 7/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.6436 - accuracy: 0.5310 - val_loss: 1.6394 - val_accuracy: 0.4886\n","Epoch 8/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.6335 - accuracy: 0.5375 - val_loss: 1.6297 - val_accuracy: 0.4969\n","Epoch 9/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.6237 - accuracy: 0.5367 - val_loss: 1.6202 - val_accuracy: 0.4959\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.6137 - accuracy: 0.5357 - val_loss: 1.6108 - val_accuracy: 0.4979\n","Epoch 11/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.6040 - accuracy: 0.5455 - val_loss: 1.6016 - val_accuracy: 0.4959\n","Epoch 12/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.5950 - accuracy: 0.5359 - val_loss: 1.5922 - val_accuracy: 0.4990\n","Epoch 13/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.5852 - accuracy: 0.5504 - val_loss: 1.5832 - val_accuracy: 0.4979\n","Epoch 14/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.5758 - accuracy: 0.5351 - val_loss: 1.5744 - val_accuracy: 0.4959\n","Epoch 15/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.5660 - accuracy: 0.5488 - val_loss: 1.5653 - val_accuracy: 0.5145\n","Epoch 16/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.5573 - accuracy: 0.5475 - val_loss: 1.5567 - val_accuracy: 0.5124\n","Epoch 17/100\n","31/31 [==============================] - 1s 40ms/step - loss: 1.5478 - accuracy: 0.5522 - val_loss: 1.5479 - val_accuracy: 0.5103\n","Epoch 18/100\n","31/31 [==============================] - 1s 42ms/step - loss: 1.5385 - accuracy: 0.5525 - val_loss: 1.5399 - val_accuracy: 0.5072\n","Epoch 19/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.5296 - accuracy: 0.5525 - val_loss: 1.5322 - val_accuracy: 0.5052\n","Epoch 20/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.5208 - accuracy: 0.5530 - val_loss: 1.5236 - val_accuracy: 0.5114\n","Epoch 21/100\n","31/31 [==============================] - 1s 34ms/step - loss: 1.5125 - accuracy: 0.5509 - val_loss: 1.5152 - val_accuracy: 0.5186\n","Epoch 22/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.5047 - accuracy: 0.5460 - val_loss: 1.5085 - val_accuracy: 0.5145\n","Epoch 23/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.4961 - accuracy: 0.5566 - val_loss: 1.4990 - val_accuracy: 0.5186\n","Epoch 24/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.4866 - accuracy: 0.5550 - val_loss: 1.4951 - val_accuracy: 0.5052\n","Epoch 25/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.4799 - accuracy: 0.5525 - val_loss: 1.4845 - val_accuracy: 0.5351\n","Epoch 26/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4708 - accuracy: 0.5574 - val_loss: 1.4778 - val_accuracy: 0.5165\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.4625 - accuracy: 0.5651 - val_loss: 1.4698 - val_accuracy: 0.5227\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.4539 - accuracy: 0.5798 - val_loss: 1.4665 - val_accuracy: 0.5124\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.4472 - accuracy: 0.5649 - val_loss: 1.4559 - val_accuracy: 0.5176\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.4395 - accuracy: 0.5734 - val_loss: 1.4491 - val_accuracy: 0.5134\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4320 - accuracy: 0.5612 - val_loss: 1.4422 - val_accuracy: 0.5186\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.4234 - accuracy: 0.5760 - val_loss: 1.4374 - val_accuracy: 0.5217\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.4177 - accuracy: 0.5729 - val_loss: 1.4297 - val_accuracy: 0.5207\n","Epoch 34/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4073 - accuracy: 0.5824 - val_loss: 1.4226 - val_accuracy: 0.5310\n","Epoch 35/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.4010 - accuracy: 0.5749 - val_loss: 1.4162 - val_accuracy: 0.5238\n","Epoch 36/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3941 - accuracy: 0.5845 - val_loss: 1.4097 - val_accuracy: 0.5289\n","Epoch 37/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3864 - accuracy: 0.5868 - val_loss: 1.4034 - val_accuracy: 0.5351\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3783 - accuracy: 0.5855 - val_loss: 1.3983 - val_accuracy: 0.5331\n","Epoch 39/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.3718 - accuracy: 0.5879 - val_loss: 1.3911 - val_accuracy: 0.5393\n","Epoch 40/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3649 - accuracy: 0.5786 - val_loss: 1.3864 - val_accuracy: 0.5227\n","Epoch 41/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.3571 - accuracy: 0.5928 - val_loss: 1.3811 - val_accuracy: 0.5196\n","Epoch 42/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.3494 - accuracy: 0.5953 - val_loss: 1.3743 - val_accuracy: 0.5258\n","Epoch 43/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.3420 - accuracy: 0.6034 - val_loss: 1.3690 - val_accuracy: 0.5351\n","Epoch 44/100\n","31/31 [==============================] - 1s 30ms/step - loss: 1.3354 - accuracy: 0.6005 - val_loss: 1.3617 - val_accuracy: 0.5413\n","Epoch 45/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3275 - accuracy: 0.6021 - val_loss: 1.3576 - val_accuracy: 0.5289\n","Epoch 46/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.3197 - accuracy: 0.6028 - val_loss: 1.3541 - val_accuracy: 0.5372\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3131 - accuracy: 0.6049 - val_loss: 1.3509 - val_accuracy: 0.5320\n","Epoch 48/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.3067 - accuracy: 0.6140 - val_loss: 1.3400 - val_accuracy: 0.5372\n","Epoch 49/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.2968 - accuracy: 0.6147 - val_loss: 1.3353 - val_accuracy: 0.5434\n","Epoch 50/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2918 - accuracy: 0.6163 - val_loss: 1.3318 - val_accuracy: 0.5382\n","Epoch 51/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2813 - accuracy: 0.6225 - val_loss: 1.3262 - val_accuracy: 0.5372\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2742 - accuracy: 0.6292 - val_loss: 1.3234 - val_accuracy: 0.5403\n","Epoch 53/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2685 - accuracy: 0.6142 - val_loss: 1.3227 - val_accuracy: 0.5331\n","Epoch 54/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.2616 - accuracy: 0.6271 - val_loss: 1.3166 - val_accuracy: 0.5444\n","Epoch 55/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.2528 - accuracy: 0.6230 - val_loss: 1.3087 - val_accuracy: 0.5527\n","Epoch 56/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.2455 - accuracy: 0.6349 - val_loss: 1.3057 - val_accuracy: 0.5548\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2426 - accuracy: 0.6207 - val_loss: 1.3014 - val_accuracy: 0.5475\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2319 - accuracy: 0.6331 - val_loss: 1.2998 - val_accuracy: 0.5506\n","Epoch 59/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2224 - accuracy: 0.6468 - val_loss: 1.2955 - val_accuracy: 0.5537\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2155 - accuracy: 0.6465 - val_loss: 1.2985 - val_accuracy: 0.5393\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2111 - accuracy: 0.6382 - val_loss: 1.2896 - val_accuracy: 0.5455\n","Epoch 62/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2025 - accuracy: 0.6499 - val_loss: 1.2861 - val_accuracy: 0.5517\n","Epoch 63/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1917 - accuracy: 0.6605 - val_loss: 1.2836 - val_accuracy: 0.5527\n","Epoch 64/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1924 - accuracy: 0.6543 - val_loss: 1.2888 - val_accuracy: 0.5310\n","Epoch 65/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1824 - accuracy: 0.6517 - val_loss: 1.2763 - val_accuracy: 0.5506\n","Epoch 66/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.1790 - accuracy: 0.6561 - val_loss: 1.2738 - val_accuracy: 0.5527\n","Epoch 67/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1690 - accuracy: 0.6579 - val_loss: 1.2861 - val_accuracy: 0.5279\n","Epoch 68/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.1596 - accuracy: 0.6680 - val_loss: 1.2732 - val_accuracy: 0.5444\n","Epoch 69/100\n","31/31 [==============================] - 1s 42ms/step - loss: 1.1530 - accuracy: 0.6739 - val_loss: 1.2659 - val_accuracy: 0.5682\n","Epoch 70/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1456 - accuracy: 0.6755 - val_loss: 1.2691 - val_accuracy: 0.5413\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1444 - accuracy: 0.6636 - val_loss: 1.3070 - val_accuracy: 0.5134\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1361 - accuracy: 0.6757 - val_loss: 1.2630 - val_accuracy: 0.5568\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1263 - accuracy: 0.6804 - val_loss: 1.2601 - val_accuracy: 0.5444\n","Epoch 74/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1209 - accuracy: 0.6822 - val_loss: 1.2588 - val_accuracy: 0.5424\n","Epoch 75/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1106 - accuracy: 0.6966 - val_loss: 1.2529 - val_accuracy: 0.5610\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1045 - accuracy: 0.6894 - val_loss: 1.2852 - val_accuracy: 0.5300\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1076 - accuracy: 0.6780 - val_loss: 1.2595 - val_accuracy: 0.5455\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0964 - accuracy: 0.6902 - val_loss: 1.2658 - val_accuracy: 0.5382\n","Epoch 79/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0937 - accuracy: 0.6866 - val_loss: 1.2448 - val_accuracy: 0.5558\n","Epoch 80/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0795 - accuracy: 0.7039 - val_loss: 1.2460 - val_accuracy: 0.5702\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0679 - accuracy: 0.7072 - val_loss: 1.2447 - val_accuracy: 0.5599\n","Epoch 82/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0599 - accuracy: 0.7098 - val_loss: 1.2452 - val_accuracy: 0.5589\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0600 - accuracy: 0.7075 - val_loss: 1.2437 - val_accuracy: 0.5527\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0505 - accuracy: 0.7114 - val_loss: 1.2407 - val_accuracy: 0.5671\n","Epoch 85/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0469 - accuracy: 0.7124 - val_loss: 1.2402 - val_accuracy: 0.5651\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0429 - accuracy: 0.7189 - val_loss: 1.2446 - val_accuracy: 0.5465\n","Epoch 87/100\n","31/31 [==============================] - 1s 31ms/step - loss: 1.0314 - accuracy: 0.7189 - val_loss: 1.2426 - val_accuracy: 0.5744\n","Epoch 88/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0451 - accuracy: 0.7067 - val_loss: 1.2345 - val_accuracy: 0.5640\n","Epoch 89/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0356 - accuracy: 0.7070 - val_loss: 1.2301 - val_accuracy: 0.5744\n","Epoch 90/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.0232 - accuracy: 0.7274 - val_loss: 1.2704 - val_accuracy: 0.5320\n","Epoch 91/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.0235 - accuracy: 0.7090 - val_loss: 1.2376 - val_accuracy: 0.5558\n","Epoch 92/100\n","31/31 [==============================] - 1s 30ms/step - loss: 1.0216 - accuracy: 0.7155 - val_loss: 1.2298 - val_accuracy: 0.5857\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0033 - accuracy: 0.7295 - val_loss: 1.2381 - val_accuracy: 0.5517\n","Epoch 94/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9901 - accuracy: 0.7416 - val_loss: 1.2274 - val_accuracy: 0.5599\n","Epoch 95/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9874 - accuracy: 0.7398 - val_loss: 1.2260 - val_accuracy: 0.5702\n","Epoch 96/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9807 - accuracy: 0.7499 - val_loss: 1.2278 - val_accuracy: 0.5692\n","Epoch 97/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9793 - accuracy: 0.7388 - val_loss: 1.2439 - val_accuracy: 0.5589\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9737 - accuracy: 0.7398 - val_loss: 1.2288 - val_accuracy: 0.5558\n","Epoch 99/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9771 - accuracy: 0.7333 - val_loss: 1.2258 - val_accuracy: 0.5723\n","Epoch 100/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9662 - accuracy: 0.7318 - val_loss: 1.2260 - val_accuracy: 0.5579\n","{'loss': [1.7051377296447754, 1.6944506168365479, 1.6841357946395874, 1.6738303899765015, 1.6636945009231567, 1.653467059135437, 1.6435918807983398, 1.6334519386291504, 1.6237170696258545, 1.6137250661849976, 1.6040400266647339, 1.5949598550796509, 1.5851656198501587, 1.5758477449417114, 1.5659784078598022, 1.557315468788147, 1.5477710962295532, 1.5385167598724365, 1.529575228691101, 1.5208008289337158, 1.5124701261520386, 1.5047297477722168, 1.4961369037628174, 1.486624002456665, 1.479905128479004, 1.4707610607147217, 1.4625428915023804, 1.4538849592208862, 1.4471697807312012, 1.4395257234573364, 1.432035207748413, 1.4233577251434326, 1.4176534414291382, 1.4072935581207275, 1.4010313749313354, 1.3941489458084106, 1.386430025100708, 1.3782943487167358, 1.3718301057815552, 1.3648648262023926, 1.3571176528930664, 1.3493584394454956, 1.3420225381851196, 1.3353688716888428, 1.3274556398391724, 1.319711446762085, 1.313086748123169, 1.306725263595581, 1.2968002557754517, 1.2917711734771729, 1.2812992334365845, 1.2741823196411133, 1.2685225009918213, 1.2615759372711182, 1.2527920007705688, 1.2454975843429565, 1.2425565719604492, 1.231929063796997, 1.2223957777023315, 1.2154531478881836, 1.2111281156539917, 1.202504277229309, 1.1916875839233398, 1.1924461126327515, 1.1824016571044922, 1.1790330410003662, 1.1689913272857666, 1.1595613956451416, 1.152992844581604, 1.1456446647644043, 1.1443709135055542, 1.136111855506897, 1.126297116279602, 1.1208668947219849, 1.1105940341949463, 1.1044803857803345, 1.107576847076416, 1.0963561534881592, 1.0937323570251465, 1.0795170068740845, 1.067944049835205, 1.0598865747451782, 1.0599759817123413, 1.0505045652389526, 1.046948790550232, 1.0428539514541626, 1.0314009189605713, 1.045110821723938, 1.0355650186538696, 1.0231831073760986, 1.0235199928283691, 1.0215685367584229, 1.0033042430877686, 0.9901305437088013, 0.9874497056007385, 0.9806768894195557, 0.9792697429656982, 0.9736871123313904, 0.9770631194114685, 0.96623694896698], 'accuracy': [0.5023255944252014, 0.5105943083763123, 0.5260981917381287, 0.5248062014579773, 0.5266149640083313, 0.5346253514289856, 0.5310077667236328, 0.5374677181243896, 0.5366925001144409, 0.5356588959693909, 0.5454780459403992, 0.535917341709137, 0.5503876209259033, 0.5351421236991882, 0.5488371849060059, 0.5475451946258545, 0.5521963834762573, 0.5524547696113586, 0.5524547696113586, 0.552971601486206, 0.550904393196106, 0.5459948182106018, 0.5565891265869141, 0.5550387501716614, 0.5524547696113586, 0.5573643445968628, 0.565116286277771, 0.5798449516296387, 0.5648579001426697, 0.5733850002288818, 0.5612403154373169, 0.5759689807891846, 0.5728682279586792, 0.5824289321899414, 0.5749353766441345, 0.5844961404800415, 0.5868217349052429, 0.5855297446250916, 0.5878552794456482, 0.5785529613494873, 0.5927648544311523, 0.5953488349914551, 0.6033591628074646, 0.6005167961120605, 0.6020671725273132, 0.602842390537262, 0.6049095392227173, 0.6139534711837769, 0.6147286891937256, 0.6162790656089783, 0.6224806308746338, 0.6291989684104919, 0.6142118573188782, 0.6271317601203918, 0.6229974031448364, 0.6348837018013, 0.620671808719635, 0.633074939250946, 0.6467700004577637, 0.6465116143226624, 0.6382429003715515, 0.6498708128929138, 0.6604651212692261, 0.6542635560035706, 0.6516795754432678, 0.6560723781585693, 0.6578811407089233, 0.667958676815033, 0.6739017963409424, 0.6754521727561951, 0.6635658740997314, 0.6757106184959412, 0.6803617477416992, 0.682170569896698, 0.6966408491134644, 0.6894056797027588, 0.6780361533164978, 0.6901808977127075, 0.6865633130073547, 0.7038759589195251, 0.7072351574897766, 0.7098191380500793, 0.7074935436248779, 0.711369514465332, 0.7124031186103821, 0.7188630700111389, 0.7188630700111389, 0.7067183256149292, 0.7069767713546753, 0.7273901700973511, 0.7090439200401306, 0.7155038714408875, 0.7294573783874512, 0.7416020631790161, 0.7397933006286621, 0.749870777130127, 0.7387596964836121, 0.7397933006286621, 0.7333333492279053, 0.7317829728126526], 'val_loss': [1.6995350122451782, 1.6892573833465576, 1.6790759563446045, 1.6689844131469727, 1.6590229272842407, 1.649117350578308, 1.639402151107788, 1.6297297477722168, 1.6201963424682617, 1.6107821464538574, 1.6016089916229248, 1.5922191143035889, 1.5831892490386963, 1.574449062347412, 1.5653401613235474, 1.5566908121109009, 1.5479435920715332, 1.5399235486984253, 1.5322071313858032, 1.5235990285873413, 1.5151697397232056, 1.508482575416565, 1.4989584684371948, 1.4951149225234985, 1.4844695329666138, 1.477826476097107, 1.4697715044021606, 1.466469407081604, 1.455941915512085, 1.449105978012085, 1.4422082901000977, 1.4373632669448853, 1.4297468662261963, 1.4226391315460205, 1.416202187538147, 1.4097092151641846, 1.4034146070480347, 1.3983285427093506, 1.3911395072937012, 1.3863704204559326, 1.3811036348342896, 1.3742731809616089, 1.3689897060394287, 1.3616857528686523, 1.3575947284698486, 1.3540750741958618, 1.350873589515686, 1.3399937152862549, 1.3353219032287598, 1.3318052291870117, 1.3261706829071045, 1.323407530784607, 1.3227449655532837, 1.316569209098816, 1.308739423751831, 1.3057211637496948, 1.301373839378357, 1.2998093366622925, 1.2955242395401, 1.2985332012176514, 1.2895643711090088, 1.2860748767852783, 1.2836233377456665, 1.2888476848602295, 1.2762545347213745, 1.273803472518921, 1.286055088043213, 1.273231029510498, 1.2658613920211792, 1.2690954208374023, 1.3070322275161743, 1.2629899978637695, 1.2601467370986938, 1.2588062286376953, 1.2529081106185913, 1.2852489948272705, 1.2594889402389526, 1.265770673751831, 1.2447874546051025, 1.2459951639175415, 1.2446982860565186, 1.2451591491699219, 1.2436813116073608, 1.2406532764434814, 1.2401806116104126, 1.2446198463439941, 1.2425501346588135, 1.234456181526184, 1.2300868034362793, 1.2704380750656128, 1.2375744581222534, 1.229810118675232, 1.2380567789077759, 1.2274233102798462, 1.2260124683380127, 1.227791428565979, 1.2438980340957642, 1.2288107872009277, 1.2258234024047852, 1.2260453701019287], 'val_accuracy': [0.49070248007774353, 0.49793389439582825, 0.48966941237449646, 0.4969008266925812, 0.4876033067703247, 0.49896693229675293, 0.4886363744735718, 0.4969008266925812, 0.4958677589893341, 0.49793389439582825, 0.4958677589893341, 0.49896693229675293, 0.49793389439582825, 0.4958677589893341, 0.5144628286361694, 0.5123966932296753, 0.5103305578231812, 0.5072314143180847, 0.5051652789115906, 0.5113636255264282, 0.5185950398445129, 0.5144628286361694, 0.5185950398445129, 0.5051652789115906, 0.5351239442825317, 0.5165289044380188, 0.5227272510528564, 0.5123966932296753, 0.5175619721412659, 0.5134297609329224, 0.5185950398445129, 0.5216942429542542, 0.5206611752510071, 0.5309917330741882, 0.5237603187561035, 0.5289255976676941, 0.5351239442825317, 0.5330578684806824, 0.53925621509552, 0.5227272510528564, 0.51962810754776, 0.5258264541625977, 0.5351239442825317, 0.5413222908973694, 0.5289255976676941, 0.5371900796890259, 0.5320248007774353, 0.5371900796890259, 0.5433884263038635, 0.538223147392273, 0.5371900796890259, 0.5402892827987671, 0.5330578684806824, 0.5444214940071106, 0.5526859760284424, 0.5547520518302917, 0.547520637512207, 0.5506198406219482, 0.5537189841270447, 0.53925621509552, 0.5454545617103577, 0.5516529083251953, 0.5526859760284424, 0.5309917330741882, 0.5506198406219482, 0.5526859760284424, 0.5278925895690918, 0.5444214940071106, 0.5681818127632141, 0.5413222908973694, 0.5134297609329224, 0.5568181872367859, 0.5444214940071106, 0.5423553586006165, 0.5609503984451294, 0.5299586653709412, 0.5454545617103577, 0.538223147392273, 0.5557851195335388, 0.5702479481697083, 0.5599173307418823, 0.55888432264328, 0.5526859760284424, 0.567148745059967, 0.5650826692581177, 0.5464876294136047, 0.5743801593780518, 0.5640496015548706, 0.5743801593780518, 0.5320248007774353, 0.5557851195335388, 0.58574378490448, 0.5516529083251953, 0.5599173307418823, 0.5702479481697083, 0.5692148804664612, 0.55888432264328, 0.5557851195335388, 0.5723140239715576, 0.557851254940033]}\n","32/32 [==============================] - 1s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/29 [==========================>...] - ETA: 0s - loss: 1.0736 - accuracy: 0.6513"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 14s 263ms/step - loss: 1.0728 - accuracy: 0.6552 - val_loss: 1.1490 - val_accuracy: 0.5162\n","Epoch 2/100\n","29/29 [==============================] - 1s 34ms/step - loss: 1.0596 - accuracy: 0.6810 - val_loss: 1.1455 - val_accuracy: 0.5172\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0563 - accuracy: 0.6775 - val_loss: 1.1430 - val_accuracy: 0.5172\n","Epoch 4/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0413 - accuracy: 0.6942 - val_loss: 1.1404 - val_accuracy: 0.5162\n","Epoch 5/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.0346 - accuracy: 0.7012 - val_loss: 1.1369 - val_accuracy: 0.5183\n","Epoch 6/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.0235 - accuracy: 0.6985 - val_loss: 1.1319 - val_accuracy: 0.5205\n","Epoch 7/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0230 - accuracy: 0.6956 - val_loss: 1.1281 - val_accuracy: 0.5205\n","Epoch 8/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.0165 - accuracy: 0.7058 - val_loss: 1.1241 - val_accuracy: 0.5291\n","Epoch 9/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9984 - accuracy: 0.7155 - val_loss: 1.1213 - val_accuracy: 0.5259\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9965 - accuracy: 0.7161 - val_loss: 1.1179 - val_accuracy: 0.5291\n","Epoch 11/100\n","29/29 [==============================] - 1s 38ms/step - loss: 0.9930 - accuracy: 0.7077 - val_loss: 1.1124 - val_accuracy: 0.5323\n","Epoch 12/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9821 - accuracy: 0.7258 - val_loss: 1.1041 - val_accuracy: 0.5668\n","Epoch 13/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9786 - accuracy: 0.7204 - val_loss: 1.0980 - val_accuracy: 0.5700\n","Epoch 14/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9725 - accuracy: 0.7214 - val_loss: 1.0978 - val_accuracy: 0.5614\n","Epoch 15/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.9718 - accuracy: 0.7136 - val_loss: 1.0876 - val_accuracy: 0.5787\n","Epoch 16/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9599 - accuracy: 0.7344 - val_loss: 1.0799 - val_accuracy: 0.5938\n","Epoch 17/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.9569 - accuracy: 0.7306 - val_loss: 1.0680 - val_accuracy: 0.6369\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9591 - accuracy: 0.7177 - val_loss: 1.0645 - val_accuracy: 0.6239\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9692 - accuracy: 0.7069 - val_loss: 1.0648 - val_accuracy: 0.5970\n","Epoch 20/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.9477 - accuracy: 0.7252 - val_loss: 1.0471 - val_accuracy: 0.6509\n","Epoch 21/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9410 - accuracy: 0.7398 - val_loss: 1.0410 - val_accuracy: 0.6476\n","Epoch 22/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9331 - accuracy: 0.7328 - val_loss: 1.0363 - val_accuracy: 0.6466\n","Epoch 23/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9181 - accuracy: 0.7505 - val_loss: 1.0383 - val_accuracy: 0.6379\n","Epoch 24/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9145 - accuracy: 0.7508 - val_loss: 1.0289 - val_accuracy: 0.6498\n","Epoch 25/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9098 - accuracy: 0.7511 - val_loss: 1.0308 - val_accuracy: 0.6476\n","Epoch 26/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.9194 - accuracy: 0.7309 - val_loss: 1.0241 - val_accuracy: 0.6541\n","Epoch 27/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9011 - accuracy: 0.7554 - val_loss: 1.0238 - val_accuracy: 0.6541\n","Epoch 28/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8988 - accuracy: 0.7562 - val_loss: 1.0230 - val_accuracy: 0.6509\n","Epoch 29/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8878 - accuracy: 0.7565 - val_loss: 1.0461 - val_accuracy: 0.6261\n","Epoch 30/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.8874 - accuracy: 0.7559 - val_loss: 1.0228 - val_accuracy: 0.6562\n","Epoch 31/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8762 - accuracy: 0.7718 - val_loss: 1.0246 - val_accuracy: 0.6455\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8697 - accuracy: 0.7678 - val_loss: 1.0297 - val_accuracy: 0.6509\n","Epoch 33/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8626 - accuracy: 0.7680 - val_loss: 1.0251 - val_accuracy: 0.6476\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8787 - accuracy: 0.7524 - val_loss: 1.1415 - val_accuracy: 0.5884\n","Epoch 35/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8773 - accuracy: 0.7492 - val_loss: 1.0222 - val_accuracy: 0.6530\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8480 - accuracy: 0.7748 - val_loss: 1.0352 - val_accuracy: 0.6369\n","Epoch 37/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8482 - accuracy: 0.7772 - val_loss: 1.0280 - val_accuracy: 0.6519\n","Epoch 38/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8436 - accuracy: 0.7769 - val_loss: 1.0319 - val_accuracy: 0.6519\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8402 - accuracy: 0.7748 - val_loss: 1.0840 - val_accuracy: 0.6196\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8347 - accuracy: 0.7748 - val_loss: 1.0307 - val_accuracy: 0.6498\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8267 - accuracy: 0.7834 - val_loss: 1.0234 - val_accuracy: 0.6541\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8229 - accuracy: 0.7815 - val_loss: 1.0311 - val_accuracy: 0.6498\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8252 - accuracy: 0.7726 - val_loss: 1.0193 - val_accuracy: 0.6541\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8436 - accuracy: 0.7602 - val_loss: 1.0937 - val_accuracy: 0.6142\n","Epoch 45/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8178 - accuracy: 0.7883 - val_loss: 1.0249 - val_accuracy: 0.6487\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8076 - accuracy: 0.7912 - val_loss: 1.0201 - val_accuracy: 0.6487\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8039 - accuracy: 0.7928 - val_loss: 1.0179 - val_accuracy: 0.6541\n","Epoch 48/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7927 - accuracy: 0.7966 - val_loss: 1.0206 - val_accuracy: 0.6498\n","Epoch 49/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7831 - accuracy: 0.8060 - val_loss: 1.0218 - val_accuracy: 0.6498\n","Epoch 50/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7915 - accuracy: 0.7934 - val_loss: 1.0641 - val_accuracy: 0.6379\n","Epoch 51/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7906 - accuracy: 0.7909 - val_loss: 1.0467 - val_accuracy: 0.6476\n","Epoch 52/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7674 - accuracy: 0.8168 - val_loss: 1.0509 - val_accuracy: 0.6530\n","Epoch 53/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7757 - accuracy: 0.7993 - val_loss: 1.0488 - val_accuracy: 0.6498\n","Epoch 54/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7860 - accuracy: 0.7893 - val_loss: 1.0713 - val_accuracy: 0.6336\n","Epoch 55/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7669 - accuracy: 0.8077 - val_loss: 1.0315 - val_accuracy: 0.6519\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7715 - accuracy: 0.7988 - val_loss: 1.0404 - val_accuracy: 0.6530\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7487 - accuracy: 0.8230 - val_loss: 1.0231 - val_accuracy: 0.6455\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7372 - accuracy: 0.8214 - val_loss: 1.0318 - val_accuracy: 0.6498\n","Epoch 59/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7388 - accuracy: 0.8195 - val_loss: 1.0469 - val_accuracy: 0.6530\n","Epoch 60/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7367 - accuracy: 0.8209 - val_loss: 1.0305 - val_accuracy: 0.6455\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7448 - accuracy: 0.8117 - val_loss: 1.0342 - val_accuracy: 0.6487\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7265 - accuracy: 0.8292 - val_loss: 1.0356 - val_accuracy: 0.6412\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7245 - accuracy: 0.8284 - val_loss: 1.0563 - val_accuracy: 0.6530\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7266 - accuracy: 0.8292 - val_loss: 1.0468 - val_accuracy: 0.6498\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7356 - accuracy: 0.8106 - val_loss: 1.0332 - val_accuracy: 0.6466\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7213 - accuracy: 0.8190 - val_loss: 1.1287 - val_accuracy: 0.6175\n","Epoch 67/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7128 - accuracy: 0.8314 - val_loss: 1.0300 - val_accuracy: 0.6401\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7125 - accuracy: 0.8297 - val_loss: 1.0378 - val_accuracy: 0.6466\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6991 - accuracy: 0.8338 - val_loss: 1.0933 - val_accuracy: 0.6412\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6875 - accuracy: 0.8489 - val_loss: 1.0418 - val_accuracy: 0.6498\n","Epoch 71/100\n","29/29 [==============================] - 1s 44ms/step - loss: 0.6879 - accuracy: 0.8376 - val_loss: 1.0504 - val_accuracy: 0.6573\n","Epoch 72/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6907 - accuracy: 0.8394 - val_loss: 1.0562 - val_accuracy: 0.6498\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6867 - accuracy: 0.8397 - val_loss: 1.0391 - val_accuracy: 0.6390\n","Epoch 74/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6824 - accuracy: 0.8448 - val_loss: 1.1243 - val_accuracy: 0.6379\n","Epoch 75/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6760 - accuracy: 0.8421 - val_loss: 1.0418 - val_accuracy: 0.6401\n","Epoch 76/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6540 - accuracy: 0.8631 - val_loss: 1.0582 - val_accuracy: 0.6541\n","Epoch 77/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6570 - accuracy: 0.8578 - val_loss: 1.0632 - val_accuracy: 0.6487\n","Epoch 78/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6578 - accuracy: 0.8518 - val_loss: 1.1000 - val_accuracy: 0.6444\n","Epoch 79/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6508 - accuracy: 0.8610 - val_loss: 1.1204 - val_accuracy: 0.6455\n","Epoch 80/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6716 - accuracy: 0.8413 - val_loss: 1.0513 - val_accuracy: 0.6552\n","Epoch 81/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6391 - accuracy: 0.8685 - val_loss: 1.0836 - val_accuracy: 0.6552\n","Epoch 82/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.6361 - accuracy: 0.8626 - val_loss: 1.0593 - val_accuracy: 0.6325\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6311 - accuracy: 0.8688 - val_loss: 1.0771 - val_accuracy: 0.6530\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6305 - accuracy: 0.8726 - val_loss: 1.1048 - val_accuracy: 0.6552\n","Epoch 85/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6227 - accuracy: 0.8774 - val_loss: 1.0717 - val_accuracy: 0.6455\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6203 - accuracy: 0.8712 - val_loss: 1.0694 - val_accuracy: 0.6455\n","Epoch 87/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6225 - accuracy: 0.8726 - val_loss: 1.0824 - val_accuracy: 0.6519\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6260 - accuracy: 0.8677 - val_loss: 1.0952 - val_accuracy: 0.6476\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6286 - accuracy: 0.8656 - val_loss: 1.0765 - val_accuracy: 0.6412\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6147 - accuracy: 0.8645 - val_loss: 1.0752 - val_accuracy: 0.6433\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6059 - accuracy: 0.8712 - val_loss: 1.0859 - val_accuracy: 0.6476\n","Epoch 92/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5916 - accuracy: 0.8828 - val_loss: 1.0826 - val_accuracy: 0.6455\n","Epoch 93/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5992 - accuracy: 0.8817 - val_loss: 1.0844 - val_accuracy: 0.6401\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5998 - accuracy: 0.8747 - val_loss: 1.0811 - val_accuracy: 0.6390\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5762 - accuracy: 0.8944 - val_loss: 1.1080 - val_accuracy: 0.6498\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5944 - accuracy: 0.8734 - val_loss: 1.1314 - val_accuracy: 0.6401\n","Epoch 97/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5874 - accuracy: 0.8863 - val_loss: 1.0926 - val_accuracy: 0.6444\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5852 - accuracy: 0.8817 - val_loss: 1.1218 - val_accuracy: 0.6476\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5616 - accuracy: 0.8998 - val_loss: 1.1264 - val_accuracy: 0.6455\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5621 - accuracy: 0.8955 - val_loss: 1.1169 - val_accuracy: 0.6498\n","{'loss': [1.0727884769439697, 1.059607982635498, 1.0563300848007202, 1.0412538051605225, 1.0346184968948364, 1.0234589576721191, 1.023043155670166, 1.01651132106781, 0.998441755771637, 0.9964668154716492, 0.9930116534233093, 0.9821430444717407, 0.9785568714141846, 0.9725444912910461, 0.971828818321228, 0.9598645567893982, 0.9568661451339722, 0.9590510725975037, 0.9691511988639832, 0.9477224946022034, 0.9410449862480164, 0.9330798983573914, 0.9180839657783508, 0.914513111114502, 0.9098175764083862, 0.9194421172142029, 0.9010716080665588, 0.8988476395606995, 0.8878470063209534, 0.8874250650405884, 0.8762140870094299, 0.8697154521942139, 0.8626075983047485, 0.8787372708320618, 0.8773104548454285, 0.8479875922203064, 0.8481809496879578, 0.8435783386230469, 0.8402416706085205, 0.8347065448760986, 0.8266843557357788, 0.8228598833084106, 0.8251520395278931, 0.8436425924301147, 0.8178092837333679, 0.8076210618019104, 0.8038539290428162, 0.7927385568618774, 0.7830524444580078, 0.7915177345275879, 0.7906400561332703, 0.767371416091919, 0.775723397731781, 0.7859801650047302, 0.7669271230697632, 0.7714950442314148, 0.748702883720398, 0.7371616363525391, 0.7387845516204834, 0.7366851568222046, 0.7447808384895325, 0.7264910936355591, 0.7244846224784851, 0.7266483306884766, 0.7356039881706238, 0.7212771773338318, 0.7127570509910583, 0.7125144600868225, 0.699120283126831, 0.6874536871910095, 0.6879125833511353, 0.6907213926315308, 0.6867181658744812, 0.6823845505714417, 0.6760196089744568, 0.6539838910102844, 0.6569523215293884, 0.6578090190887451, 0.6508440375328064, 0.6715850830078125, 0.6390876770019531, 0.6360573768615723, 0.6311246752738953, 0.6305158734321594, 0.6226713061332703, 0.6203048825263977, 0.6224769353866577, 0.6259778738021851, 0.6285573840141296, 0.6147065758705139, 0.6059439182281494, 0.5915595293045044, 0.5991905927658081, 0.599837064743042, 0.5761579871177673, 0.5944455862045288, 0.5873904228210449, 0.5851773619651794, 0.5616406202316284, 0.5621166229248047], 'accuracy': [0.6551724076271057, 0.681034505367279, 0.6775323152542114, 0.6942349076271057, 0.7012392282485962, 0.6985452771186829, 0.6955819129943848, 0.7058189511299133, 0.7155172228813171, 0.7160560488700867, 0.7077047228813171, 0.7257543206214905, 0.720366358757019, 0.7214439511299133, 0.7136314511299133, 0.734375, 0.7306034564971924, 0.7176724076271057, 0.7068965435028076, 0.725215494632721, 0.7397629022598267, 0.732758641242981, 0.7505387663841248, 0.7508081793785095, 0.7510775923728943, 0.7308728694915771, 0.7553879022598267, 0.756196141242981, 0.756465494632721, 0.7559267282485962, 0.771821141242981, 0.7677801847457886, 0.7680495977401733, 0.7524245977401733, 0.7491918206214905, 0.774784505367279, 0.7772090435028076, 0.7769396305084229, 0.774784505367279, 0.774784505367279, 0.7834051847457886, 0.7815194129943848, 0.7726293206214905, 0.7602370977401733, 0.7882543206214905, 0.7912176847457886, 0.7928340435028076, 0.7966055870056152, 0.806034505367279, 0.7933728694915771, 0.7909482717514038, 0.8168103694915771, 0.7992995977401733, 0.7893319129943848, 0.8076508641242981, 0.7987607717514038, 0.8230064511299133, 0.8213900923728943, 0.8195043206214905, 0.8208512663841248, 0.8116918206214905, 0.8292025923728943, 0.8283944129943848, 0.8292025923728943, 0.8106142282485962, 0.818965494632721, 0.8313577771186829, 0.829741358757019, 0.8337823152542114, 0.8488685488700867, 0.837553858757019, 0.8394396305084229, 0.8397090435028076, 0.8448275923728943, 0.842133641242981, 0.8631465435028076, 0.857758641242981, 0.8518319129943848, 0.860991358757019, 0.8413254022598267, 0.868534505367279, 0.8626077771186829, 0.868803858757019, 0.8725754022598267, 0.8774245977401733, 0.8712284564971924, 0.8725754022598267, 0.8677262663841248, 0.865571141242981, 0.8644935488700867, 0.8712284564971924, 0.8828125, 0.8817349076271057, 0.8747305870056152, 0.8943965435028076, 0.873383641242981, 0.8863146305084229, 0.8817349076271057, 0.899784505367279, 0.8954741358757019], 'val_loss': [1.1489617824554443, 1.1455178260803223, 1.1429705619812012, 1.1403908729553223, 1.1368504762649536, 1.131925344467163, 1.1280786991119385, 1.1241319179534912, 1.1212823390960693, 1.1179200410842896, 1.112389326095581, 1.104116678237915, 1.097975492477417, 1.0977617502212524, 1.0876003503799438, 1.0799375772476196, 1.0679795742034912, 1.0645250082015991, 1.0648070573806763, 1.0471222400665283, 1.0409741401672363, 1.0362553596496582, 1.0383102893829346, 1.028933048248291, 1.0307872295379639, 1.0240627527236938, 1.0237681865692139, 1.0229660272598267, 1.0461302995681763, 1.0227729082107544, 1.024644136428833, 1.029689908027649, 1.0251268148422241, 1.1415188312530518, 1.022217869758606, 1.0351630449295044, 1.0279978513717651, 1.031935453414917, 1.0840283632278442, 1.0307217836380005, 1.0234479904174805, 1.0311083793640137, 1.019289493560791, 1.0937150716781616, 1.0248554944992065, 1.0201119184494019, 1.0179497003555298, 1.020591139793396, 1.021805763244629, 1.0640530586242676, 1.0466543436050415, 1.0508627891540527, 1.0488460063934326, 1.0712593793869019, 1.031542181968689, 1.0404266119003296, 1.0231142044067383, 1.0318262577056885, 1.0469104051589966, 1.0304898023605347, 1.0341918468475342, 1.0355738401412964, 1.0563273429870605, 1.0467798709869385, 1.0331753492355347, 1.1286585330963135, 1.030043363571167, 1.0378280878067017, 1.093266248703003, 1.0418459177017212, 1.0503937005996704, 1.0561697483062744, 1.039146065711975, 1.1242841482162476, 1.0417912006378174, 1.0581929683685303, 1.0632456541061401, 1.0999605655670166, 1.1203844547271729, 1.0513415336608887, 1.0835719108581543, 1.0593290328979492, 1.0771455764770508, 1.104782223701477, 1.0717185735702515, 1.069427728652954, 1.0823662281036377, 1.0951831340789795, 1.07650887966156, 1.0752092599868774, 1.0858838558197021, 1.0826497077941895, 1.0844069719314575, 1.0810526609420776, 1.107985019683838, 1.1314011812210083, 1.0925904512405396, 1.1218297481536865, 1.1263806819915771, 1.1169434785842896], 'val_accuracy': [0.5161637663841248, 0.517241358757019, 0.517241358757019, 0.5161637663841248, 0.5183189511299133, 0.5204741358757019, 0.5204741358757019, 0.5290948152542114, 0.5258620977401733, 0.5290948152542114, 0.5323275923728943, 0.5668103694915771, 0.5700430870056152, 0.5614224076271057, 0.5786637663841248, 0.59375, 0.6368534564971924, 0.6239224076271057, 0.5969827771186829, 0.6508620977401733, 0.6476293206214905, 0.6465517282485962, 0.6379310488700867, 0.649784505367279, 0.6476293206214905, 0.6540948152542114, 0.6540948152542114, 0.6508620977401733, 0.6260775923728943, 0.65625, 0.6454741358757019, 0.6508620977401733, 0.6476293206214905, 0.5883620977401733, 0.6530172228813171, 0.6368534564971924, 0.6519396305084229, 0.6519396305084229, 0.6196120977401733, 0.649784505367279, 0.6540948152542114, 0.649784505367279, 0.6540948152542114, 0.6142241358757019, 0.6487069129943848, 0.6487069129943848, 0.6540948152542114, 0.649784505367279, 0.649784505367279, 0.6379310488700867, 0.6476293206214905, 0.6530172228813171, 0.649784505367279, 0.6336206793785095, 0.6519396305084229, 0.6530172228813171, 0.6454741358757019, 0.649784505367279, 0.6530172228813171, 0.6454741358757019, 0.6487069129943848, 0.6411637663841248, 0.6530172228813171, 0.649784505367279, 0.6465517282485962, 0.6174569129943848, 0.6400862336158752, 0.6465517282485962, 0.6411637663841248, 0.649784505367279, 0.6573275923728943, 0.649784505367279, 0.639008641242981, 0.6379310488700867, 0.6400862336158752, 0.6540948152542114, 0.6487069129943848, 0.6443965435028076, 0.6454741358757019, 0.6551724076271057, 0.6551724076271057, 0.6325430870056152, 0.6530172228813171, 0.6551724076271057, 0.6454741358757019, 0.6454741358757019, 0.6519396305084229, 0.6476293206214905, 0.6411637663841248, 0.6433189511299133, 0.6476293206214905, 0.6454741358757019, 0.6400862336158752, 0.639008641242981, 0.649784505367279, 0.6400862336158752, 0.6443965435028076, 0.6476293206214905, 0.6454741358757019, 0.649784505367279]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 1.0731 - accuracy: 0.6652"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 11s 160ms/step - loss: 1.0743 - accuracy: 0.6627 - val_loss: 1.1492 - val_accuracy: 0.5045\n","Epoch 2/100\n","28/28 [==============================] - 1s 32ms/step - loss: 1.0621 - accuracy: 0.6718 - val_loss: 1.1460 - val_accuracy: 0.5068\n","Epoch 3/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0497 - accuracy: 0.6760 - val_loss: 1.1437 - val_accuracy: 0.5068\n","Epoch 4/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0440 - accuracy: 0.6910 - val_loss: 1.1407 - val_accuracy: 0.5068\n","Epoch 5/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0392 - accuracy: 0.6746 - val_loss: 1.1371 - val_accuracy: 0.5068\n","Epoch 6/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0249 - accuracy: 0.7015 - val_loss: 1.1346 - val_accuracy: 0.5068\n","Epoch 7/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0200 - accuracy: 0.6958 - val_loss: 1.1311 - val_accuracy: 0.5068\n","Epoch 8/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.0137 - accuracy: 0.6998 - val_loss: 1.1240 - val_accuracy: 0.5294\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0063 - accuracy: 0.7071 - val_loss: 1.1259 - val_accuracy: 0.5079\n","Epoch 10/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0123 - accuracy: 0.6904 - val_loss: 1.1171 - val_accuracy: 0.5294\n","Epoch 11/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.9975 - accuracy: 0.7018 - val_loss: 1.1129 - val_accuracy: 0.5351\n","Epoch 12/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.9907 - accuracy: 0.7179 - val_loss: 1.1053 - val_accuracy: 0.5611\n","Epoch 13/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.9856 - accuracy: 0.7111 - val_loss: 1.0999 - val_accuracy: 0.5758\n","Epoch 14/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.9736 - accuracy: 0.7216 - val_loss: 1.0946 - val_accuracy: 0.5860\n","Epoch 15/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.9692 - accuracy: 0.7224 - val_loss: 1.0842 - val_accuracy: 0.6290\n","Epoch 16/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9812 - accuracy: 0.6975 - val_loss: 1.0884 - val_accuracy: 0.5679\n","Epoch 17/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9629 - accuracy: 0.7216 - val_loss: 1.0786 - val_accuracy: 0.5995\n","Epoch 18/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.9489 - accuracy: 0.7357 - val_loss: 1.0636 - val_accuracy: 0.6505\n","Epoch 19/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9431 - accuracy: 0.7380 - val_loss: 1.0600 - val_accuracy: 0.6301\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9354 - accuracy: 0.7368 - val_loss: 1.0734 - val_accuracy: 0.5860\n","Epoch 21/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.9405 - accuracy: 0.7312 - val_loss: 1.0441 - val_accuracy: 0.6527\n","Epoch 22/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9314 - accuracy: 0.7349 - val_loss: 1.0365 - val_accuracy: 0.6493\n","Epoch 23/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9272 - accuracy: 0.7436 - val_loss: 1.0348 - val_accuracy: 0.6516\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9287 - accuracy: 0.7292 - val_loss: 1.0385 - val_accuracy: 0.6414\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9230 - accuracy: 0.7320 - val_loss: 1.0387 - val_accuracy: 0.6312\n","Epoch 26/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9145 - accuracy: 0.7419 - val_loss: 1.0239 - val_accuracy: 0.6369\n","Epoch 27/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9052 - accuracy: 0.7518 - val_loss: 1.0251 - val_accuracy: 0.6391\n","Epoch 28/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8965 - accuracy: 0.7465 - val_loss: 1.0315 - val_accuracy: 0.6369\n","Epoch 29/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8945 - accuracy: 0.7521 - val_loss: 1.0218 - val_accuracy: 0.6403\n","Epoch 30/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8868 - accuracy: 0.7566 - val_loss: 1.0217 - val_accuracy: 0.6482\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8745 - accuracy: 0.7677 - val_loss: 1.0327 - val_accuracy: 0.6346\n","Epoch 32/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8792 - accuracy: 0.7583 - val_loss: 1.0247 - val_accuracy: 0.6301\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8666 - accuracy: 0.7566 - val_loss: 1.0538 - val_accuracy: 0.6301\n","Epoch 34/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8775 - accuracy: 0.7589 - val_loss: 1.0260 - val_accuracy: 0.6425\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8703 - accuracy: 0.7541 - val_loss: 1.0255 - val_accuracy: 0.6324\n","Epoch 36/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.8658 - accuracy: 0.7550 - val_loss: 1.0334 - val_accuracy: 0.6618\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8495 - accuracy: 0.7790 - val_loss: 1.0665 - val_accuracy: 0.6199\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8462 - accuracy: 0.7702 - val_loss: 1.0284 - val_accuracy: 0.6391\n","Epoch 39/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8465 - accuracy: 0.7750 - val_loss: 1.0445 - val_accuracy: 0.6244\n","Epoch 40/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8300 - accuracy: 0.7866 - val_loss: 1.0695 - val_accuracy: 0.6131\n","Epoch 41/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8330 - accuracy: 0.7711 - val_loss: 1.1046 - val_accuracy: 0.6007\n","Epoch 42/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8333 - accuracy: 0.7759 - val_loss: 1.0259 - val_accuracy: 0.6324\n","Epoch 43/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8255 - accuracy: 0.7849 - val_loss: 1.0380 - val_accuracy: 0.6357\n","Epoch 44/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8121 - accuracy: 0.7934 - val_loss: 1.0357 - val_accuracy: 0.6335\n","Epoch 45/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8130 - accuracy: 0.7841 - val_loss: 1.0443 - val_accuracy: 0.6312\n","Epoch 46/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7971 - accuracy: 0.8008 - val_loss: 1.0290 - val_accuracy: 0.6357\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8171 - accuracy: 0.7807 - val_loss: 1.0304 - val_accuracy: 0.6346\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7963 - accuracy: 0.7954 - val_loss: 1.0533 - val_accuracy: 0.6290\n","Epoch 49/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8167 - accuracy: 0.7838 - val_loss: 1.0743 - val_accuracy: 0.6131\n","Epoch 50/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7970 - accuracy: 0.7940 - val_loss: 1.1147 - val_accuracy: 0.5984\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7861 - accuracy: 0.8005 - val_loss: 1.0441 - val_accuracy: 0.6267\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7781 - accuracy: 0.8056 - val_loss: 1.0306 - val_accuracy: 0.6335\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7695 - accuracy: 0.8107 - val_loss: 1.0576 - val_accuracy: 0.6256\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7713 - accuracy: 0.8096 - val_loss: 1.0353 - val_accuracy: 0.6335\n","Epoch 55/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7573 - accuracy: 0.8124 - val_loss: 1.0467 - val_accuracy: 0.6459\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7570 - accuracy: 0.8130 - val_loss: 1.0381 - val_accuracy: 0.6324\n","Epoch 57/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7535 - accuracy: 0.8172 - val_loss: 1.0459 - val_accuracy: 0.6154\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7533 - accuracy: 0.8096 - val_loss: 1.0399 - val_accuracy: 0.6346\n","Epoch 59/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7502 - accuracy: 0.8107 - val_loss: 1.0584 - val_accuracy: 0.6222\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7327 - accuracy: 0.8274 - val_loss: 1.0623 - val_accuracy: 0.6199\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7370 - accuracy: 0.8206 - val_loss: 1.0456 - val_accuracy: 0.6301\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7322 - accuracy: 0.8212 - val_loss: 1.1388 - val_accuracy: 0.6018\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7400 - accuracy: 0.8144 - val_loss: 1.0451 - val_accuracy: 0.6256\n","Epoch 64/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7363 - accuracy: 0.8240 - val_loss: 1.0712 - val_accuracy: 0.6391\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7286 - accuracy: 0.8172 - val_loss: 1.0475 - val_accuracy: 0.6425\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7091 - accuracy: 0.8367 - val_loss: 1.0729 - val_accuracy: 0.6256\n","Epoch 67/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7081 - accuracy: 0.8328 - val_loss: 1.0956 - val_accuracy: 0.6131\n","Epoch 68/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7036 - accuracy: 0.8373 - val_loss: 1.0889 - val_accuracy: 0.6176\n","Epoch 69/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6916 - accuracy: 0.8432 - val_loss: 1.0766 - val_accuracy: 0.6188\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6936 - accuracy: 0.8424 - val_loss: 1.0629 - val_accuracy: 0.6324\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6853 - accuracy: 0.8432 - val_loss: 1.0659 - val_accuracy: 0.6233\n","Epoch 72/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6839 - accuracy: 0.8461 - val_loss: 1.0780 - val_accuracy: 0.6131\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6743 - accuracy: 0.8523 - val_loss: 1.0752 - val_accuracy: 0.6188\n","Epoch 74/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6742 - accuracy: 0.8529 - val_loss: 1.0872 - val_accuracy: 0.6120\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6670 - accuracy: 0.8486 - val_loss: 1.1117 - val_accuracy: 0.6165\n","Epoch 76/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6717 - accuracy: 0.8495 - val_loss: 1.0759 - val_accuracy: 0.6380\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6722 - accuracy: 0.8384 - val_loss: 1.1594 - val_accuracy: 0.6097\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6499 - accuracy: 0.8594 - val_loss: 1.0924 - val_accuracy: 0.6233\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6520 - accuracy: 0.8580 - val_loss: 1.0915 - val_accuracy: 0.6222\n","Epoch 80/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6434 - accuracy: 0.8653 - val_loss: 1.1278 - val_accuracy: 0.6165\n","Epoch 81/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6428 - accuracy: 0.8639 - val_loss: 1.0886 - val_accuracy: 0.6357\n","Epoch 82/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6330 - accuracy: 0.8687 - val_loss: 1.0961 - val_accuracy: 0.6312\n","Epoch 83/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6402 - accuracy: 0.8625 - val_loss: 1.1827 - val_accuracy: 0.6097\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6385 - accuracy: 0.8591 - val_loss: 1.1134 - val_accuracy: 0.6222\n","Epoch 85/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6326 - accuracy: 0.8580 - val_loss: 1.1159 - val_accuracy: 0.6369\n","Epoch 86/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6309 - accuracy: 0.8687 - val_loss: 1.1088 - val_accuracy: 0.6233\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6222 - accuracy: 0.8715 - val_loss: 1.1339 - val_accuracy: 0.6188\n","Epoch 88/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6222 - accuracy: 0.8636 - val_loss: 1.1386 - val_accuracy: 0.6143\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6175 - accuracy: 0.8667 - val_loss: 1.1344 - val_accuracy: 0.6267\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6074 - accuracy: 0.8763 - val_loss: 1.1478 - val_accuracy: 0.6165\n","Epoch 91/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5982 - accuracy: 0.8834 - val_loss: 1.1245 - val_accuracy: 0.6210\n","Epoch 92/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5988 - accuracy: 0.8772 - val_loss: 1.1267 - val_accuracy: 0.6357\n","Epoch 93/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6091 - accuracy: 0.8701 - val_loss: 1.1442 - val_accuracy: 0.6199\n","Epoch 94/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5833 - accuracy: 0.8840 - val_loss: 1.1317 - val_accuracy: 0.6324\n","Epoch 95/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5809 - accuracy: 0.8851 - val_loss: 1.2688 - val_accuracy: 0.5962\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5791 - accuracy: 0.8871 - val_loss: 1.1654 - val_accuracy: 0.6165\n","Epoch 97/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5831 - accuracy: 0.8882 - val_loss: 1.1691 - val_accuracy: 0.6301\n","Epoch 98/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5953 - accuracy: 0.8749 - val_loss: 1.2975 - val_accuracy: 0.6041\n","Epoch 99/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5810 - accuracy: 0.8862 - val_loss: 1.1532 - val_accuracy: 0.6278\n","Epoch 100/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5619 - accuracy: 0.8967 - val_loss: 1.1697 - val_accuracy: 0.6188\n","{'loss': [1.074294924736023, 1.062070608139038, 1.049661636352539, 1.0439854860305786, 1.0392446517944336, 1.024936318397522, 1.0200291872024536, 1.013688325881958, 1.006332278251648, 1.0122689008712769, 0.9975078105926514, 0.9906671643257141, 0.9856255054473877, 0.9736486077308655, 0.9692230820655823, 0.9811865091323853, 0.9629221558570862, 0.9488817453384399, 0.9431341886520386, 0.9354158043861389, 0.9405052661895752, 0.9314488768577576, 0.9271557927131653, 0.9287422299385071, 0.9229611158370972, 0.9144673347473145, 0.9052435159683228, 0.8965421915054321, 0.8944521546363831, 0.8867757320404053, 0.874488353729248, 0.879204511642456, 0.866584062576294, 0.8774682283401489, 0.8702515363693237, 0.8657704591751099, 0.849487841129303, 0.8462151885032654, 0.8464722037315369, 0.8299764394760132, 0.8329815864562988, 0.8332841992378235, 0.8255410194396973, 0.8120537400245667, 0.8129702210426331, 0.797084391117096, 0.8170865774154663, 0.7963348627090454, 0.8166684508323669, 0.7969733476638794, 0.7861261963844299, 0.7781224846839905, 0.7694509029388428, 0.771344006061554, 0.7573498487472534, 0.7569978833198547, 0.7535025477409363, 0.7532666921615601, 0.7502297163009644, 0.7327489256858826, 0.7369794249534607, 0.7322487235069275, 0.7400093078613281, 0.7363173365592957, 0.7285630106925964, 0.7090612649917603, 0.7081074118614197, 0.7035642862319946, 0.6915704011917114, 0.6935914158821106, 0.6853089928627014, 0.6839330792427063, 0.6742813587188721, 0.6742206811904907, 0.6670107841491699, 0.6716557741165161, 0.6722300052642822, 0.6498550772666931, 0.6520049571990967, 0.6433551907539368, 0.6427823901176453, 0.6330116391181946, 0.6401843428611755, 0.6384954452514648, 0.6326321959495544, 0.6308807730674744, 0.6221592426300049, 0.6222159266471863, 0.617451548576355, 0.6074393391609192, 0.5982416868209839, 0.5988338589668274, 0.6091026067733765, 0.5833066701889038, 0.5809033513069153, 0.5790888667106628, 0.5830502510070801, 0.5953025817871094, 0.5810184478759766, 0.561871349811554], 'accuracy': [0.66270512342453, 0.6717600226402283, 0.6760045289993286, 0.6910017132759094, 0.6745896935462952, 0.7014714479446411, 0.6958121061325073, 0.6997736096382141, 0.7071307301521301, 0.6904357671737671, 0.7017543911933899, 0.7178834080696106, 0.7110922336578369, 0.7215619683265686, 0.7224108576774597, 0.6975098848342896, 0.7215619683265686, 0.7357102632522583, 0.7379739880561829, 0.7368420958518982, 0.7311828136444092, 0.7348613739013672, 0.7436332702636719, 0.7292020320892334, 0.7320317029953003, 0.7419354915618896, 0.751839280128479, 0.7464629411697388, 0.7521222233772278, 0.7566496729850769, 0.7676853537559509, 0.7583475112915039, 0.7566496729850769, 0.7589133977890015, 0.7541030049324036, 0.7549518942832947, 0.7790039777755737, 0.7702320218086243, 0.7750424742698669, 0.7866440415382385, 0.7710809111595154, 0.7758913636207581, 0.7849462628364563, 0.7934352159500122, 0.7840973138809204, 0.8007922768592834, 0.780701756477356, 0.7954159379005432, 0.7838143706321716, 0.7940011024475098, 0.8005093336105347, 0.8056027293205261, 0.8106960654258728, 0.8095642328262329, 0.8123939037322998, 0.8129597902297974, 0.8172042965888977, 0.8095642328262329, 0.8106960654258728, 0.8273910880088806, 0.8205999135971069, 0.8211658000946045, 0.8143746256828308, 0.8239954710006714, 0.8172042965888977, 0.8367289304733276, 0.8327674269676208, 0.83729487657547, 0.8432371020317078, 0.8423882126808167, 0.8432371020317078, 0.8460667729377747, 0.852292001247406, 0.8528579473495483, 0.848613440990448, 0.8494623899459839, 0.8384267091751099, 0.8593661785125732, 0.8579513430595398, 0.865308403968811, 0.8638936281204224, 0.8687040209770203, 0.8624787926673889, 0.8590831756591797, 0.8579513430595398, 0.8687040209770203, 0.8715336918830872, 0.8636106252670288, 0.8667232394218445, 0.8763440847396851, 0.8834182024002075, 0.8771929740905762, 0.8701188564300537, 0.8839841485023499, 0.8851160407066345, 0.8870967626571655, 0.8882286548614502, 0.8749292492866516, 0.8862478733062744, 0.8967176079750061], 'val_loss': [1.149234414100647, 1.1460232734680176, 1.1437253952026367, 1.140661597251892, 1.137098789215088, 1.13463294506073, 1.1311084032058716, 1.1240497827529907, 1.1259424686431885, 1.1170591115951538, 1.1128864288330078, 1.105293869972229, 1.099934697151184, 1.0945661067962646, 1.0841693878173828, 1.088374137878418, 1.078615665435791, 1.0636272430419922, 1.0600253343582153, 1.0733535289764404, 1.0440566539764404, 1.036545991897583, 1.034755825996399, 1.0385154485702515, 1.0386762619018555, 1.0238984823226929, 1.0250736474990845, 1.0314627885818481, 1.021837592124939, 1.0217218399047852, 1.0326781272888184, 1.024684190750122, 1.0538147687911987, 1.0259623527526855, 1.0255316495895386, 1.0333824157714844, 1.0665197372436523, 1.0284147262573242, 1.0445013046264648, 1.0695074796676636, 1.1046230792999268, 1.025854229927063, 1.0379713773727417, 1.035678744316101, 1.0442737340927124, 1.0289924144744873, 1.0303542613983154, 1.0533218383789062, 1.0743459463119507, 1.11466383934021, 1.0441462993621826, 1.0306264162063599, 1.057550072669983, 1.0353032350540161, 1.0467106103897095, 1.038134217262268, 1.0458711385726929, 1.0399010181427002, 1.0583574771881104, 1.0623418092727661, 1.0456005334854126, 1.1387500762939453, 1.045141339302063, 1.0711586475372314, 1.0474623441696167, 1.072859525680542, 1.0956248044967651, 1.088912844657898, 1.0765502452850342, 1.062945008277893, 1.0659343004226685, 1.0780164003372192, 1.0752272605895996, 1.0871500968933105, 1.1116694211959839, 1.0758956670761108, 1.1594340801239014, 1.092442274093628, 1.0915411710739136, 1.127827525138855, 1.0885941982269287, 1.0961298942565918, 1.1827163696289062, 1.1133887767791748, 1.1158753633499146, 1.1088329553604126, 1.13392174243927, 1.1386321783065796, 1.134380578994751, 1.1477668285369873, 1.1245311498641968, 1.1266947984695435, 1.1442002058029175, 1.1317037343978882, 1.268750786781311, 1.1653941869735718, 1.1690727472305298, 1.297529935836792, 1.153174877166748, 1.1696908473968506], 'val_accuracy': [0.5045248866081238, 0.5067873597145081, 0.5067873597145081, 0.5067873597145081, 0.5067873597145081, 0.5067873597145081, 0.5067873597145081, 0.529411792755127, 0.5079185366630554, 0.529411792755127, 0.5350678563117981, 0.5610859990119934, 0.5757918357849121, 0.5859728455543518, 0.6289592981338501, 0.5678732991218567, 0.5995475053787231, 0.6504524946212769, 0.6300904750823975, 0.5859728455543518, 0.6527149081230164, 0.6493212580680847, 0.651583731174469, 0.6414027214050293, 0.6312217116355896, 0.6368778347969055, 0.639140248298645, 0.6368778347969055, 0.6402714848518372, 0.6481900215148926, 0.6346153616905212, 0.6300904750823975, 0.6300904750823975, 0.6425339579582214, 0.6323529481887817, 0.6617646813392639, 0.6199095249176025, 0.639140248298645, 0.6244344115257263, 0.6131221652030945, 0.6006787419319153, 0.6323529481887817, 0.6357465982437134, 0.6334841847419739, 0.6312217116355896, 0.6357465982437134, 0.6346153616905212, 0.6289592981338501, 0.6131221652030945, 0.598416268825531, 0.6266968250274658, 0.6334841847419739, 0.6255655884742737, 0.6334841847419739, 0.6459276080131531, 0.6323529481887817, 0.6153846383094788, 0.6346153616905212, 0.622171938419342, 0.6199095249176025, 0.6300904750823975, 0.6018099784851074, 0.6255655884742737, 0.639140248298645, 0.6425339579582214, 0.6255655884742737, 0.6131221652030945, 0.6176470518112183, 0.6187782883644104, 0.6323529481887817, 0.6233031749725342, 0.6131221652030945, 0.6187782883644104, 0.6119909286499023, 0.6165158152580261, 0.6380090713500977, 0.6097285151481628, 0.6233031749725342, 0.622171938419342, 0.6165158152580261, 0.6357465982437134, 0.6312217116355896, 0.6097285151481628, 0.622171938419342, 0.6368778347969055, 0.6233031749725342, 0.6187782883644104, 0.6142534017562866, 0.6266968250274658, 0.6165158152580261, 0.6210407018661499, 0.6357465982437134, 0.6199095249176025, 0.6323529481887817, 0.5961538553237915, 0.6165158152580261, 0.6300904750823975, 0.6040723919868469, 0.627828061580658, 0.6187782883644104]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 1.0853 - accuracy: 0.6387"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 10s 137ms/step - loss: 1.0829 - accuracy: 0.6452 - val_loss: 1.1492 - val_accuracy: 0.5145\n","Epoch 2/100\n","31/31 [==============================] - 2s 55ms/step - loss: 1.0601 - accuracy: 0.6757 - val_loss: 1.1454 - val_accuracy: 0.5155\n","Epoch 3/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0528 - accuracy: 0.6757 - val_loss: 1.1427 - val_accuracy: 0.5145\n","Epoch 4/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0504 - accuracy: 0.6711 - val_loss: 1.1382 - val_accuracy: 0.5155\n","Epoch 5/100\n","31/31 [==============================] - 1s 33ms/step - loss: 1.0367 - accuracy: 0.6752 - val_loss: 1.1338 - val_accuracy: 0.5310\n","Epoch 6/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0295 - accuracy: 0.6930 - val_loss: 1.1302 - val_accuracy: 0.5248\n","Epoch 7/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0223 - accuracy: 0.6964 - val_loss: 1.1261 - val_accuracy: 0.5310\n","Epoch 8/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.0185 - accuracy: 0.6902 - val_loss: 1.1222 - val_accuracy: 0.5320\n","Epoch 9/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0205 - accuracy: 0.6868 - val_loss: 1.1186 - val_accuracy: 0.5300\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0015 - accuracy: 0.7049 - val_loss: 1.1150 - val_accuracy: 0.5289\n","Epoch 11/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0028 - accuracy: 0.6912 - val_loss: 1.1105 - val_accuracy: 0.5362\n","Epoch 12/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9932 - accuracy: 0.7049 - val_loss: 1.1043 - val_accuracy: 0.5733\n","Epoch 13/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9856 - accuracy: 0.7075 - val_loss: 1.1009 - val_accuracy: 0.5671\n","Epoch 14/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9775 - accuracy: 0.7140 - val_loss: 1.0965 - val_accuracy: 0.5671\n","Epoch 15/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9701 - accuracy: 0.7207 - val_loss: 1.0951 - val_accuracy: 0.5558\n","Epoch 16/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9764 - accuracy: 0.7129 - val_loss: 1.0832 - val_accuracy: 0.6281\n","Epoch 17/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9655 - accuracy: 0.7176 - val_loss: 1.0836 - val_accuracy: 0.5764\n","Epoch 18/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9636 - accuracy: 0.7165 - val_loss: 1.0740 - val_accuracy: 0.6291\n","Epoch 19/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9603 - accuracy: 0.7101 - val_loss: 1.0765 - val_accuracy: 0.6023\n","Epoch 20/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9483 - accuracy: 0.7264 - val_loss: 1.0765 - val_accuracy: 0.5878\n","Epoch 21/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9440 - accuracy: 0.7313 - val_loss: 1.0793 - val_accuracy: 0.5888\n","Epoch 22/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9458 - accuracy: 0.7119 - val_loss: 1.0699 - val_accuracy: 0.6105\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9359 - accuracy: 0.7258 - val_loss: 1.0650 - val_accuracy: 0.6229\n","Epoch 24/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9243 - accuracy: 0.7385 - val_loss: 1.0670 - val_accuracy: 0.6147\n","Epoch 25/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9194 - accuracy: 0.7426 - val_loss: 1.0738 - val_accuracy: 0.6095\n","Epoch 26/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9117 - accuracy: 0.7344 - val_loss: 1.0880 - val_accuracy: 0.5919\n","Epoch 27/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9108 - accuracy: 0.7393 - val_loss: 1.0737 - val_accuracy: 0.6178\n","Epoch 28/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9119 - accuracy: 0.7395 - val_loss: 1.0729 - val_accuracy: 0.6229\n","Epoch 29/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9063 - accuracy: 0.7390 - val_loss: 1.0761 - val_accuracy: 0.6188\n","Epoch 30/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8902 - accuracy: 0.7447 - val_loss: 1.0759 - val_accuracy: 0.6116\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8862 - accuracy: 0.7543 - val_loss: 1.0799 - val_accuracy: 0.6126\n","Epoch 32/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8840 - accuracy: 0.7468 - val_loss: 1.0825 - val_accuracy: 0.6147\n","Epoch 33/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8790 - accuracy: 0.7571 - val_loss: 1.0931 - val_accuracy: 0.6054\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8813 - accuracy: 0.7478 - val_loss: 1.0791 - val_accuracy: 0.6085\n","Epoch 35/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8714 - accuracy: 0.7638 - val_loss: 1.0785 - val_accuracy: 0.6198\n","Epoch 36/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8794 - accuracy: 0.7426 - val_loss: 1.0837 - val_accuracy: 0.6188\n","Epoch 37/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8714 - accuracy: 0.7556 - val_loss: 1.0812 - val_accuracy: 0.6188\n","Epoch 38/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8577 - accuracy: 0.7610 - val_loss: 1.0893 - val_accuracy: 0.6157\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8507 - accuracy: 0.7667 - val_loss: 1.0896 - val_accuracy: 0.5961\n","Epoch 40/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8310 - accuracy: 0.7832 - val_loss: 1.0755 - val_accuracy: 0.6229\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8342 - accuracy: 0.7811 - val_loss: 1.1091 - val_accuracy: 0.6064\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8236 - accuracy: 0.7765 - val_loss: 1.0930 - val_accuracy: 0.6229\n","Epoch 43/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8260 - accuracy: 0.7824 - val_loss: 1.0926 - val_accuracy: 0.6178\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8293 - accuracy: 0.7786 - val_loss: 1.0820 - val_accuracy: 0.6271\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8197 - accuracy: 0.7860 - val_loss: 1.0806 - val_accuracy: 0.6209\n","Epoch 46/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8229 - accuracy: 0.7736 - val_loss: 1.0903 - val_accuracy: 0.6116\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8062 - accuracy: 0.7930 - val_loss: 1.0804 - val_accuracy: 0.6178\n","Epoch 48/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7972 - accuracy: 0.7935 - val_loss: 1.0794 - val_accuracy: 0.6271\n","Epoch 49/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8029 - accuracy: 0.7824 - val_loss: 1.0820 - val_accuracy: 0.6240\n","Epoch 50/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7847 - accuracy: 0.8052 - val_loss: 1.1321 - val_accuracy: 0.5950\n","Epoch 51/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7823 - accuracy: 0.8034 - val_loss: 1.0861 - val_accuracy: 0.6198\n","Epoch 52/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7934 - accuracy: 0.7871 - val_loss: 1.0961 - val_accuracy: 0.6085\n","Epoch 53/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7806 - accuracy: 0.7995 - val_loss: 1.1034 - val_accuracy: 0.6167\n","Epoch 54/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7831 - accuracy: 0.7956 - val_loss: 1.0949 - val_accuracy: 0.6167\n","Epoch 55/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7644 - accuracy: 0.8049 - val_loss: 1.1023 - val_accuracy: 0.6178\n","Epoch 56/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7690 - accuracy: 0.8039 - val_loss: 1.1356 - val_accuracy: 0.5919\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7543 - accuracy: 0.8129 - val_loss: 1.1511 - val_accuracy: 0.5992\n","Epoch 58/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7596 - accuracy: 0.8072 - val_loss: 1.1028 - val_accuracy: 0.6219\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7507 - accuracy: 0.8181 - val_loss: 1.0989 - val_accuracy: 0.6229\n","Epoch 60/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7493 - accuracy: 0.8065 - val_loss: 1.0997 - val_accuracy: 0.6291\n","Epoch 61/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7315 - accuracy: 0.8194 - val_loss: 1.1041 - val_accuracy: 0.6281\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7276 - accuracy: 0.8204 - val_loss: 1.1071 - val_accuracy: 0.6157\n","Epoch 63/100\n","31/31 [==============================] - 1s 45ms/step - loss: 0.7374 - accuracy: 0.8214 - val_loss: 1.1102 - val_accuracy: 0.6302\n","Epoch 64/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7214 - accuracy: 0.8196 - val_loss: 1.1090 - val_accuracy: 0.6229\n","Epoch 65/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7307 - accuracy: 0.8199 - val_loss: 1.1181 - val_accuracy: 0.6219\n","Epoch 66/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7210 - accuracy: 0.8238 - val_loss: 1.1143 - val_accuracy: 0.6291\n","Epoch 67/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7109 - accuracy: 0.8320 - val_loss: 1.1147 - val_accuracy: 0.6167\n","Epoch 68/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7175 - accuracy: 0.8199 - val_loss: 1.1275 - val_accuracy: 0.6229\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7007 - accuracy: 0.8333 - val_loss: 1.1505 - val_accuracy: 0.6085\n","Epoch 70/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.7013 - accuracy: 0.8354 - val_loss: 1.1218 - val_accuracy: 0.6333\n","Epoch 71/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6930 - accuracy: 0.8372 - val_loss: 1.1772 - val_accuracy: 0.5961\n","Epoch 72/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6824 - accuracy: 0.8424 - val_loss: 1.1397 - val_accuracy: 0.6229\n","Epoch 73/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6803 - accuracy: 0.8437 - val_loss: 1.1399 - val_accuracy: 0.6271\n","Epoch 74/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6894 - accuracy: 0.8377 - val_loss: 1.1493 - val_accuracy: 0.6229\n","Epoch 75/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6764 - accuracy: 0.8421 - val_loss: 1.1385 - val_accuracy: 0.6291\n","Epoch 76/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6783 - accuracy: 0.8333 - val_loss: 1.1502 - val_accuracy: 0.6126\n","Epoch 77/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6518 - accuracy: 0.8548 - val_loss: 1.2251 - val_accuracy: 0.5940\n","Epoch 78/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6692 - accuracy: 0.8416 - val_loss: 1.1521 - val_accuracy: 0.6240\n","Epoch 79/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6633 - accuracy: 0.8437 - val_loss: 1.2009 - val_accuracy: 0.6085\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6613 - accuracy: 0.8509 - val_loss: 1.1554 - val_accuracy: 0.6302\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6403 - accuracy: 0.8561 - val_loss: 1.1814 - val_accuracy: 0.6136\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6388 - accuracy: 0.8597 - val_loss: 1.1822 - val_accuracy: 0.6188\n","Epoch 83/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6422 - accuracy: 0.8566 - val_loss: 1.1935 - val_accuracy: 0.6095\n","Epoch 84/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6466 - accuracy: 0.8571 - val_loss: 1.1858 - val_accuracy: 0.5940\n","Epoch 85/100\n","31/31 [==============================] - 1s 39ms/step - loss: 0.6380 - accuracy: 0.8625 - val_loss: 1.1682 - val_accuracy: 0.6353\n","Epoch 86/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6287 - accuracy: 0.8623 - val_loss: 1.2023 - val_accuracy: 0.6064\n","Epoch 87/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6202 - accuracy: 0.8742 - val_loss: 1.1750 - val_accuracy: 0.6260\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6240 - accuracy: 0.8654 - val_loss: 1.2026 - val_accuracy: 0.6147\n","Epoch 89/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6096 - accuracy: 0.8708 - val_loss: 1.1839 - val_accuracy: 0.6157\n","Epoch 90/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6073 - accuracy: 0.8747 - val_loss: 1.2112 - val_accuracy: 0.6209\n","Epoch 91/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6086 - accuracy: 0.8680 - val_loss: 1.2426 - val_accuracy: 0.6105\n","Epoch 92/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6368 - accuracy: 0.8465 - val_loss: 1.2406 - val_accuracy: 0.6116\n","Epoch 93/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6192 - accuracy: 0.8628 - val_loss: 1.2055 - val_accuracy: 0.6229\n","Epoch 94/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6008 - accuracy: 0.8786 - val_loss: 1.1865 - val_accuracy: 0.6291\n","Epoch 95/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5843 - accuracy: 0.8822 - val_loss: 1.2120 - val_accuracy: 0.6250\n","Epoch 96/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.5784 - accuracy: 0.8904 - val_loss: 1.2019 - val_accuracy: 0.6426\n","Epoch 97/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5759 - accuracy: 0.8868 - val_loss: 1.2070 - val_accuracy: 0.6405\n","Epoch 98/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5806 - accuracy: 0.8845 - val_loss: 1.2135 - val_accuracy: 0.6302\n","Epoch 99/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6027 - accuracy: 0.8667 - val_loss: 1.2145 - val_accuracy: 0.6281\n","Epoch 100/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5679 - accuracy: 0.8837 - val_loss: 1.2236 - val_accuracy: 0.6157\n","{'loss': [1.0828882455825806, 1.060133695602417, 1.0528159141540527, 1.0504063367843628, 1.036736011505127, 1.029512643814087, 1.022308111190796, 1.0184646844863892, 1.020543098449707, 1.0014959573745728, 1.002846360206604, 0.9931800365447998, 0.9855612516403198, 0.9774761199951172, 0.9700607061386108, 0.9764037728309631, 0.9654850363731384, 0.9635881781578064, 0.9602926969528198, 0.9483059644699097, 0.9440290927886963, 0.9458292722702026, 0.9359349608421326, 0.9243478178977966, 0.9193523526191711, 0.911724865436554, 0.9108356237411499, 0.911874532699585, 0.906254231929779, 0.8902263045310974, 0.8861532807350159, 0.8840367197990417, 0.8790342211723328, 0.8813080787658691, 0.8713960647583008, 0.8794342279434204, 0.8713899254798889, 0.8576745390892029, 0.8507407307624817, 0.8310164213180542, 0.834201991558075, 0.8235772848129272, 0.82602858543396, 0.8292659521102905, 0.8197033405303955, 0.8228604793548584, 0.8061954379081726, 0.7972310781478882, 0.8028564453125, 0.7846719026565552, 0.7822802662849426, 0.7934454679489136, 0.7806180119514465, 0.7830662131309509, 0.7643885016441345, 0.7690340876579285, 0.7542998790740967, 0.7596237063407898, 0.7507200837135315, 0.7492820024490356, 0.7314531803131104, 0.7275784611701965, 0.7374147176742554, 0.7213631868362427, 0.7307281494140625, 0.7209603190422058, 0.7108529806137085, 0.7174951434135437, 0.7007446885108948, 0.7012613415718079, 0.6930119395256042, 0.6823852062225342, 0.680276095867157, 0.6894411444664001, 0.6763991117477417, 0.6783090233802795, 0.6518146395683289, 0.6691898703575134, 0.6633114218711853, 0.6612794399261475, 0.6402988433837891, 0.6388328075408936, 0.6422061324119568, 0.6466432213783264, 0.637991726398468, 0.6286567449569702, 0.6202100515365601, 0.6239945888519287, 0.6096392273902893, 0.6072978973388672, 0.6085881590843201, 0.6367986798286438, 0.619174063205719, 0.6008238792419434, 0.5843326449394226, 0.5783681869506836, 0.5759440660476685, 0.5805954337120056, 0.6027452349662781, 0.5679330825805664], 'accuracy': [0.645219624042511, 0.6757106184959412, 0.6757106184959412, 0.6710594296455383, 0.6751937866210938, 0.6930232644081116, 0.6963824033737183, 0.6901808977127075, 0.686821699142456, 0.7049095630645752, 0.6912144422531128, 0.7049095630645752, 0.7074935436248779, 0.7139534950256348, 0.7206718325614929, 0.7129198908805847, 0.7175710797309875, 0.7165374755859375, 0.7100775241851807, 0.726356565952301, 0.7312661409378052, 0.7118862867355347, 0.7258397936820984, 0.7385013103485107, 0.7426356673240662, 0.7343669533729553, 0.7392764687538147, 0.739534854888916, 0.7390180826187134, 0.7447028160095215, 0.7542635798454285, 0.7467700242996216, 0.7571059465408325, 0.7478036284446716, 0.7638242840766907, 0.7426356673240662, 0.7555555701255798, 0.7609819173812866, 0.7666666507720947, 0.7832041382789612, 0.7811369299888611, 0.776485800743103, 0.7824289202690125, 0.7785529494285583, 0.7860465049743652, 0.773643434047699, 0.7930232286453247, 0.7935400605201721, 0.7824289202690125, 0.8051679730415344, 0.8033591508865356, 0.7870801091194153, 0.7994831800460815, 0.7956072092056274, 0.8049095869064331, 0.8038759827613831, 0.8129199147224426, 0.8072351217269897, 0.8180878758430481, 0.8064599633216858, 0.8193798661231995, 0.8204134106636047, 0.8214470148086548, 0.8196382522583008, 0.8198966383934021, 0.8237726092338562, 0.832041323184967, 0.8198966383934021, 0.8333333134651184, 0.8354005217552185, 0.8372092843055725, 0.842377245426178, 0.8436692357063293, 0.8377261161804199, 0.8421188592910767, 0.8333333134651184, 0.854780375957489, 0.841602087020874, 0.8436692357063293, 0.8509044051170349, 0.8560723662376404, 0.8596899509429932, 0.856589138507843, 0.8571059703826904, 0.8625323176383972, 0.8622739315032959, 0.8741602301597595, 0.8653746843338013, 0.8708010315895081, 0.8746770024299622, 0.867958664894104, 0.8465116024017334, 0.8627907037734985, 0.8785529732704163, 0.882170557975769, 0.8904392719268799, 0.8868216872215271, 0.8844961524009705, 0.8666666746139526, 0.8837209343910217], 'val_loss': [1.149198055267334, 1.145432472229004, 1.142696738243103, 1.1381785869598389, 1.1337708234786987, 1.1302176713943481, 1.126067876815796, 1.122236728668213, 1.1186467409133911, 1.1150096654891968, 1.1105324029922485, 1.1043423414230347, 1.1008981466293335, 1.0965373516082764, 1.0951151847839355, 1.0832303762435913, 1.0836117267608643, 1.0739765167236328, 1.0764867067337036, 1.0764920711517334, 1.0792642831802368, 1.069860816001892, 1.0649631023406982, 1.0670467615127563, 1.0737801790237427, 1.0879979133605957, 1.0736581087112427, 1.0728896856307983, 1.0760711431503296, 1.075875163078308, 1.0799109935760498, 1.0825469493865967, 1.0931107997894287, 1.079102873802185, 1.0785112380981445, 1.0836681127548218, 1.08122718334198, 1.089341402053833, 1.0896435976028442, 1.0754543542861938, 1.1091089248657227, 1.092970848083496, 1.0925676822662354, 1.082038402557373, 1.0806249380111694, 1.0903385877609253, 1.0804390907287598, 1.0794061422348022, 1.0819988250732422, 1.132051944732666, 1.0860884189605713, 1.0961427688598633, 1.1033707857131958, 1.0949162244796753, 1.102340579032898, 1.135644555091858, 1.1511340141296387, 1.1027772426605225, 1.098893642425537, 1.099684238433838, 1.1040750741958618, 1.1071115732192993, 1.110223412513733, 1.1090128421783447, 1.1181141138076782, 1.1143380403518677, 1.114744782447815, 1.1275330781936646, 1.1505253314971924, 1.1218191385269165, 1.1771758794784546, 1.139699101448059, 1.139932632446289, 1.1492643356323242, 1.1385023593902588, 1.150197982788086, 1.2250800132751465, 1.1521382331848145, 1.2009494304656982, 1.1554020643234253, 1.1813617944717407, 1.1822439432144165, 1.193476676940918, 1.185833215713501, 1.168152093887329, 1.2022713422775269, 1.1750363111495972, 1.2026067972183228, 1.1839150190353394, 1.2112048864364624, 1.242645025253296, 1.240572452545166, 1.2055200338363647, 1.1864594221115112, 1.2120150327682495, 1.2019158601760864, 1.207000494003296, 1.2135162353515625, 1.2145161628723145, 1.2236239910125732], 'val_accuracy': [0.5144628286361694, 0.5154958963394165, 0.5144628286361694, 0.5154958963394165, 0.5309917330741882, 0.5247933864593506, 0.5309917330741882, 0.5320248007774353, 0.5299586653709412, 0.5289255976676941, 0.5361570119857788, 0.5733470916748047, 0.567148745059967, 0.567148745059967, 0.5557851195335388, 0.6280992031097412, 0.5764462947845459, 0.6291322112083435, 0.6022727489471436, 0.5878099203109741, 0.5888429880142212, 0.6105371713638306, 0.6229338645935059, 0.6146694421768188, 0.6095041036605835, 0.5919421315193176, 0.6177685856819153, 0.6229338645935059, 0.6188016533851624, 0.6115702390670776, 0.6126033067703247, 0.6146694421768188, 0.60537189245224, 0.6084710955619812, 0.6198347210884094, 0.6188016533851624, 0.6188016533851624, 0.6157024502754211, 0.5960744023323059, 0.6229338645935059, 0.6064049601554871, 0.6229338645935059, 0.6177685856819153, 0.6270661354064941, 0.6208677887916565, 0.6115702390670776, 0.6177685856819153, 0.6270661354064941, 0.6239669322967529, 0.5950413346290588, 0.6198347210884094, 0.6084710955619812, 0.6167355179786682, 0.6167355179786682, 0.6177685856819153, 0.5919421315193176, 0.5991735458374023, 0.6219007968902588, 0.6229338645935059, 0.6291322112083435, 0.6280992031097412, 0.6157024502754211, 0.6301652789115906, 0.6229338645935059, 0.6219007968902588, 0.6291322112083435, 0.6167355179786682, 0.6229338645935059, 0.6084710955619812, 0.6332644820213318, 0.5960744023323059, 0.6229338645935059, 0.6270661354064941, 0.6229338645935059, 0.6291322112083435, 0.6126033067703247, 0.5940082669258118, 0.6239669322967529, 0.6084710955619812, 0.6301652789115906, 0.6136363744735718, 0.6188016533851624, 0.6095041036605835, 0.5940082669258118, 0.6353305578231812, 0.6064049601554871, 0.6260330677032471, 0.6146694421768188, 0.6157024502754211, 0.6208677887916565, 0.6105371713638306, 0.6115702390670776, 0.6229338645935059, 0.6291322112083435, 0.625, 0.6425619721412659, 0.6404958963394165, 0.6301652789115906, 0.6280992031097412, 0.6157024502754211]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.7286 - accuracy: 0.8082"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 13s 213ms/step - loss: 0.7286 - accuracy: 0.8082 - val_loss: 0.9940 - val_accuracy: 0.5194\n","Epoch 2/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.6673 - accuracy: 0.8341 - val_loss: 0.9911 - val_accuracy: 0.5205\n","Epoch 3/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6787 - accuracy: 0.8295 - val_loss: 0.9870 - val_accuracy: 0.5248\n","Epoch 4/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6570 - accuracy: 0.8367 - val_loss: 0.9835 - val_accuracy: 0.5323\n","Epoch 5/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6542 - accuracy: 0.8435 - val_loss: 0.9838 - val_accuracy: 0.5248\n","Epoch 6/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6421 - accuracy: 0.8559 - val_loss: 0.9799 - val_accuracy: 0.5291\n","Epoch 7/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.6402 - accuracy: 0.8502 - val_loss: 0.9712 - val_accuracy: 0.5463\n","Epoch 8/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.6444 - accuracy: 0.8438 - val_loss: 0.9564 - val_accuracy: 0.6002\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6461 - accuracy: 0.8454 - val_loss: 0.9564 - val_accuracy: 0.5819\n","Epoch 10/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6286 - accuracy: 0.8502 - val_loss: 0.9533 - val_accuracy: 0.5808\n","Epoch 11/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6158 - accuracy: 0.8545 - val_loss: 0.9429 - val_accuracy: 0.5970\n","Epoch 12/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6201 - accuracy: 0.8607 - val_loss: 0.9544 - val_accuracy: 0.5711\n","Epoch 13/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6290 - accuracy: 0.8494 - val_loss: 0.9259 - val_accuracy: 0.6153\n","Epoch 14/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5975 - accuracy: 0.8745 - val_loss: 0.9069 - val_accuracy: 0.6638\n","Epoch 15/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5979 - accuracy: 0.8753 - val_loss: 0.8962 - val_accuracy: 0.6756\n","Epoch 16/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6005 - accuracy: 0.8693 - val_loss: 0.8798 - val_accuracy: 0.6864\n","Epoch 17/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6084 - accuracy: 0.8610 - val_loss: 0.8682 - val_accuracy: 0.7047\n","Epoch 18/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6040 - accuracy: 0.8631 - val_loss: 0.8872 - val_accuracy: 0.6573\n","Epoch 19/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5850 - accuracy: 0.8782 - val_loss: 0.8596 - val_accuracy: 0.7015\n","Epoch 20/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5787 - accuracy: 0.8834 - val_loss: 0.8564 - val_accuracy: 0.6875\n","Epoch 21/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5974 - accuracy: 0.8618 - val_loss: 0.8371 - val_accuracy: 0.7112\n","Epoch 22/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5880 - accuracy: 0.8661 - val_loss: 0.8352 - val_accuracy: 0.7144\n","Epoch 23/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5594 - accuracy: 0.8882 - val_loss: 0.8349 - val_accuracy: 0.7198\n","Epoch 24/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5816 - accuracy: 0.8737 - val_loss: 0.8355 - val_accuracy: 0.7231\n","Epoch 25/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5609 - accuracy: 0.8858 - val_loss: 0.8583 - val_accuracy: 0.7101\n","Epoch 26/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5643 - accuracy: 0.8874 - val_loss: 0.8612 - val_accuracy: 0.7144\n","Epoch 27/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5622 - accuracy: 0.8863 - val_loss: 0.8538 - val_accuracy: 0.7177\n","Epoch 28/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5428 - accuracy: 0.8914 - val_loss: 0.8567 - val_accuracy: 0.7112\n","Epoch 29/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5482 - accuracy: 0.8874 - val_loss: 0.8621 - val_accuracy: 0.7231\n","Epoch 30/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5481 - accuracy: 0.8912 - val_loss: 0.8796 - val_accuracy: 0.7144\n","Epoch 31/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5423 - accuracy: 0.8957 - val_loss: 0.8768 - val_accuracy: 0.7134\n","Epoch 32/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5350 - accuracy: 0.8976 - val_loss: 0.8827 - val_accuracy: 0.7177\n","Epoch 33/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5395 - accuracy: 0.8939 - val_loss: 0.8952 - val_accuracy: 0.7209\n","Epoch 34/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5217 - accuracy: 0.9027 - val_loss: 0.8968 - val_accuracy: 0.7134\n","Epoch 35/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5353 - accuracy: 0.8957 - val_loss: 0.8886 - val_accuracy: 0.7166\n","Epoch 36/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5200 - accuracy: 0.8995 - val_loss: 0.9117 - val_accuracy: 0.7112\n","Epoch 37/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5200 - accuracy: 0.9006 - val_loss: 0.8981 - val_accuracy: 0.7188\n","Epoch 38/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5090 - accuracy: 0.9089 - val_loss: 0.9083 - val_accuracy: 0.7198\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5090 - accuracy: 0.9079 - val_loss: 0.9203 - val_accuracy: 0.7123\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5036 - accuracy: 0.9103 - val_loss: 0.9237 - val_accuracy: 0.7209\n","Epoch 41/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5045 - accuracy: 0.9154 - val_loss: 0.9408 - val_accuracy: 0.7188\n","Epoch 42/100\n","29/29 [==============================] - 1s 39ms/step - loss: 0.5049 - accuracy: 0.9089 - val_loss: 0.9246 - val_accuracy: 0.7263\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4973 - accuracy: 0.9154 - val_loss: 0.9235 - val_accuracy: 0.7069\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4988 - accuracy: 0.9130 - val_loss: 0.9527 - val_accuracy: 0.7198\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4840 - accuracy: 0.9208 - val_loss: 0.9465 - val_accuracy: 0.7101\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4979 - accuracy: 0.9133 - val_loss: 0.9779 - val_accuracy: 0.7101\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4930 - accuracy: 0.9116 - val_loss: 0.9264 - val_accuracy: 0.7123\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4743 - accuracy: 0.9267 - val_loss: 0.9490 - val_accuracy: 0.7231\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4644 - accuracy: 0.9300 - val_loss: 0.9656 - val_accuracy: 0.7166\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4739 - accuracy: 0.9238 - val_loss: 0.9822 - val_accuracy: 0.7101\n","Epoch 51/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4735 - accuracy: 0.9200 - val_loss: 0.9556 - val_accuracy: 0.7220\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4621 - accuracy: 0.9324 - val_loss: 0.9520 - val_accuracy: 0.7091\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4596 - accuracy: 0.9313 - val_loss: 0.9652 - val_accuracy: 0.7123\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4636 - accuracy: 0.9273 - val_loss: 0.9516 - val_accuracy: 0.7177\n","Epoch 55/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4556 - accuracy: 0.9324 - val_loss: 0.9783 - val_accuracy: 0.7004\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4492 - accuracy: 0.9332 - val_loss: 0.9613 - val_accuracy: 0.7134\n","Epoch 57/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4534 - accuracy: 0.9316 - val_loss: 0.9799 - val_accuracy: 0.7188\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4527 - accuracy: 0.9308 - val_loss: 0.9637 - val_accuracy: 0.7155\n","Epoch 59/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4517 - accuracy: 0.9337 - val_loss: 0.9666 - val_accuracy: 0.7188\n","Epoch 60/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4412 - accuracy: 0.9348 - val_loss: 0.9885 - val_accuracy: 0.7112\n","Epoch 61/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4376 - accuracy: 0.9367 - val_loss: 0.9804 - val_accuracy: 0.7209\n","Epoch 62/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.4423 - accuracy: 0.9294 - val_loss: 0.9724 - val_accuracy: 0.7091\n","Epoch 63/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4351 - accuracy: 0.9394 - val_loss: 1.0072 - val_accuracy: 0.7112\n","Epoch 64/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4373 - accuracy: 0.9310 - val_loss: 1.0634 - val_accuracy: 0.7026\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4437 - accuracy: 0.9321 - val_loss: 1.0885 - val_accuracy: 0.6961\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4228 - accuracy: 0.9410 - val_loss: 1.0071 - val_accuracy: 0.7080\n","Epoch 67/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4187 - accuracy: 0.9450 - val_loss: 1.0874 - val_accuracy: 0.6961\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4206 - accuracy: 0.9426 - val_loss: 1.0543 - val_accuracy: 0.7155\n","Epoch 69/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4271 - accuracy: 0.9367 - val_loss: 1.0003 - val_accuracy: 0.7091\n","Epoch 70/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4171 - accuracy: 0.9426 - val_loss: 1.0308 - val_accuracy: 0.7231\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4213 - accuracy: 0.9397 - val_loss: 1.2610 - val_accuracy: 0.6778\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4350 - accuracy: 0.9345 - val_loss: 1.1668 - val_accuracy: 0.6886\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4321 - accuracy: 0.9316 - val_loss: 1.0911 - val_accuracy: 0.7037\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4078 - accuracy: 0.9450 - val_loss: 1.0394 - val_accuracy: 0.7144\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4005 - accuracy: 0.9547 - val_loss: 1.0305 - val_accuracy: 0.7220\n","Epoch 76/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3982 - accuracy: 0.9534 - val_loss: 1.0452 - val_accuracy: 0.7112\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4098 - accuracy: 0.9445 - val_loss: 1.0305 - val_accuracy: 0.7166\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3973 - accuracy: 0.9494 - val_loss: 1.0659 - val_accuracy: 0.7058\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3992 - accuracy: 0.9491 - val_loss: 1.0523 - val_accuracy: 0.7177\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4009 - accuracy: 0.9488 - val_loss: 1.0508 - val_accuracy: 0.6972\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3883 - accuracy: 0.9564 - val_loss: 1.1483 - val_accuracy: 0.6950\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3955 - accuracy: 0.9485 - val_loss: 1.1742 - val_accuracy: 0.6940\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3911 - accuracy: 0.9526 - val_loss: 1.0420 - val_accuracy: 0.7134\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3821 - accuracy: 0.9569 - val_loss: 1.1151 - val_accuracy: 0.7058\n","Epoch 85/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3758 - accuracy: 0.9628 - val_loss: 1.1199 - val_accuracy: 0.7101\n","Epoch 86/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3983 - accuracy: 0.9518 - val_loss: 1.1041 - val_accuracy: 0.7188\n","Epoch 87/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3762 - accuracy: 0.9609 - val_loss: 1.0514 - val_accuracy: 0.7069\n","Epoch 88/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3728 - accuracy: 0.9615 - val_loss: 1.0955 - val_accuracy: 0.7166\n","Epoch 89/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3679 - accuracy: 0.9636 - val_loss: 1.1674 - val_accuracy: 0.7015\n","Epoch 90/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3832 - accuracy: 0.9566 - val_loss: 1.1646 - val_accuracy: 0.7026\n","Epoch 91/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3676 - accuracy: 0.9628 - val_loss: 1.0795 - val_accuracy: 0.7144\n","Epoch 92/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3730 - accuracy: 0.9601 - val_loss: 1.1894 - val_accuracy: 0.7069\n","Epoch 93/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3656 - accuracy: 0.9585 - val_loss: 1.1141 - val_accuracy: 0.7101\n","Epoch 94/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3688 - accuracy: 0.9623 - val_loss: 1.1045 - val_accuracy: 0.7144\n","Epoch 95/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3697 - accuracy: 0.9599 - val_loss: 1.3055 - val_accuracy: 0.6918\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3853 - accuracy: 0.9510 - val_loss: 1.1643 - val_accuracy: 0.7058\n","Epoch 97/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3625 - accuracy: 0.9617 - val_loss: 1.2691 - val_accuracy: 0.6897\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4142 - accuracy: 0.9305 - val_loss: 1.3376 - val_accuracy: 0.6886\n","Epoch 99/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3784 - accuracy: 0.9561 - val_loss: 1.2733 - val_accuracy: 0.6832\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3452 - accuracy: 0.9747 - val_loss: 1.0887 - val_accuracy: 0.7144\n","{'loss': [0.7285828590393066, 0.667323648929596, 0.6787299513816833, 0.6570354700088501, 0.6541792750358582, 0.6421457529067993, 0.6401968598365784, 0.6444347500801086, 0.6460961103439331, 0.6285775899887085, 0.6158244013786316, 0.6201383471488953, 0.6289923191070557, 0.5975095629692078, 0.5979026556015015, 0.6004758477210999, 0.6083858609199524, 0.6040197014808655, 0.5850167274475098, 0.5786728262901306, 0.5974061489105225, 0.5879525542259216, 0.5594497919082642, 0.581636369228363, 0.5609456896781921, 0.5643102526664734, 0.5622437000274658, 0.542834460735321, 0.5481913089752197, 0.5480973720550537, 0.5422835350036621, 0.5349778532981873, 0.53951495885849, 0.5217080116271973, 0.5353031754493713, 0.519952118396759, 0.5199933648109436, 0.5090366005897522, 0.5089820623397827, 0.5035627484321594, 0.5045254230499268, 0.5048682689666748, 0.49725431203842163, 0.49877434968948364, 0.48396822810173035, 0.49785634875297546, 0.4930385947227478, 0.47430095076560974, 0.4643791913986206, 0.4739362597465515, 0.473476380109787, 0.4620736241340637, 0.4596290588378906, 0.4636441469192505, 0.45564860105514526, 0.44915419816970825, 0.4534355700016022, 0.45272913575172424, 0.45171406865119934, 0.4411526918411255, 0.4376366138458252, 0.44226422905921936, 0.43512290716171265, 0.43734481930732727, 0.4436502456665039, 0.4228440225124359, 0.4187444746494293, 0.4206373691558838, 0.427068829536438, 0.41712304949760437, 0.4213271737098694, 0.43497851490974426, 0.432110995054245, 0.40775221586227417, 0.4005142152309418, 0.39816102385520935, 0.40977832674980164, 0.39734140038490295, 0.3991697132587433, 0.40086668729782104, 0.3882902264595032, 0.3955037593841553, 0.39113783836364746, 0.3820835053920746, 0.37579718232154846, 0.3982604146003723, 0.3761847913265228, 0.37282922863960266, 0.3678586483001709, 0.38319915533065796, 0.36757633090019226, 0.3729995787143707, 0.3655593991279602, 0.3688465356826782, 0.3697357177734375, 0.3853193521499634, 0.3624788522720337, 0.4141763746738434, 0.37839391827583313, 0.3452383279800415], 'accuracy': [0.8081896305084229, 0.8340517282485962, 0.829472005367279, 0.8367456793785095, 0.8434805870056152, 0.8558728694915771, 0.850215494632721, 0.84375, 0.845366358757019, 0.850215494632721, 0.8545258641242981, 0.860722005367279, 0.8494073152542114, 0.8744612336158752, 0.8752694129943848, 0.8693426847457886, 0.860991358757019, 0.8631465435028076, 0.8782327771186829, 0.8833512663841248, 0.8617995977401733, 0.8661099076271057, 0.8882004022598267, 0.873652994632721, 0.8857758641242981, 0.8873922228813171, 0.8863146305084229, 0.8914331793785095, 0.8873922228813171, 0.8911637663841248, 0.8957435488700867, 0.8976293206214905, 0.8938577771186829, 0.9027478694915771, 0.8957435488700867, 0.8995150923728943, 0.9005926847457886, 0.9089439511299133, 0.907866358757019, 0.9102909564971924, 0.915409505367279, 0.9089439511299133, 0.915409505367279, 0.9129849076271057, 0.9207974076271057, 0.9132543206214905, 0.9116379022598267, 0.9267241358757019, 0.9299569129943848, 0.9237607717514038, 0.9199892282485962, 0.9323814511299133, 0.931303858757019, 0.9272629022598267, 0.9323814511299133, 0.9331896305084229, 0.9315732717514038, 0.9307650923728943, 0.9337284564971924, 0.9348060488700867, 0.9366918206214905, 0.9294180870056152, 0.9393857717514038, 0.931034505367279, 0.9321120977401733, 0.9410021305084229, 0.9450430870056152, 0.9426185488700867, 0.9366918206214905, 0.9426185488700867, 0.9396551847457886, 0.9345366358757019, 0.9315732717514038, 0.9450430870056152, 0.954741358757019, 0.9533944129943848, 0.9445043206214905, 0.9493534564971924, 0.9490840435028076, 0.9488146305084229, 0.9563577771186829, 0.9485452771186829, 0.9525862336158752, 0.9568965435028076, 0.9628232717514038, 0.951777994632721, 0.9609375, 0.9614762663841248, 0.9636314511299133, 0.9566271305084229, 0.9628232717514038, 0.9601293206214905, 0.9585129022598267, 0.962284505367279, 0.9598599076271057, 0.9509698152542114, 0.9617456793785095, 0.9304956793785095, 0.9560883641242981, 0.9746767282485962], 'val_loss': [0.9939507842063904, 0.9910678863525391, 0.9870228171348572, 0.9834538102149963, 0.9838377237319946, 0.979945719242096, 0.9711912274360657, 0.956365704536438, 0.9563536047935486, 0.9532579183578491, 0.94288170337677, 0.9543957114219666, 0.9258561134338379, 0.9069002270698547, 0.8962146043777466, 0.8798282742500305, 0.8681610822677612, 0.8871766328811646, 0.8596383333206177, 0.8564343452453613, 0.8370895385742188, 0.8352230787277222, 0.8349143266677856, 0.8355029821395874, 0.8582803606987, 0.861152172088623, 0.8537904620170593, 0.8567042946815491, 0.8621203303337097, 0.8795828819274902, 0.8768295049667358, 0.8826778531074524, 0.8952457904815674, 0.8967548608779907, 0.8886175751686096, 0.9116645455360413, 0.898109495639801, 0.9082998633384705, 0.9202991127967834, 0.9237233996391296, 0.9408021569252014, 0.9246193170547485, 0.9234961271286011, 0.9526926279067993, 0.9464834332466125, 0.9778835773468018, 0.9263895153999329, 0.9489670991897583, 0.9655585885047913, 0.982168972492218, 0.9556158781051636, 0.9519748687744141, 0.9652373194694519, 0.9516252875328064, 0.9782940149307251, 0.961345911026001, 0.9799152612686157, 0.9636791348457336, 0.9666152000427246, 0.9884893894195557, 0.9804343581199646, 0.9724172949790955, 1.0072088241577148, 1.0634232759475708, 1.088538408279419, 1.0070521831512451, 1.0874215364456177, 1.0542880296707153, 1.0002583265304565, 1.0307648181915283, 1.2609608173370361, 1.1668003797531128, 1.0910595655441284, 1.0394078493118286, 1.0305328369140625, 1.045182228088379, 1.0305218696594238, 1.0659401416778564, 1.0523438453674316, 1.0508058071136475, 1.1482850313186646, 1.1741970777511597, 1.0420081615447998, 1.1150667667388916, 1.1199476718902588, 1.1040550470352173, 1.0513664484024048, 1.0955414772033691, 1.167403221130371, 1.1645987033843994, 1.0795108079910278, 1.189405083656311, 1.1141029596328735, 1.1045382022857666, 1.3054516315460205, 1.1642634868621826, 1.2690627574920654, 1.3376423120498657, 1.2733418941497803, 1.088729977607727], 'val_accuracy': [0.5193965435028076, 0.5204741358757019, 0.524784505367279, 0.5323275923728943, 0.524784505367279, 0.5290948152542114, 0.5463362336158752, 0.600215494632721, 0.5818965435028076, 0.5808189511299133, 0.5969827771186829, 0.5711206793785095, 0.6153017282485962, 0.6637930870056152, 0.6756465435028076, 0.6864224076271057, 0.704741358757019, 0.6573275923728943, 0.701508641242981, 0.6875, 0.7112069129943848, 0.7144396305084229, 0.7198275923728943, 0.7230603694915771, 0.7101293206214905, 0.7144396305084229, 0.7176724076271057, 0.7112069129943848, 0.7230603694915771, 0.7144396305084229, 0.7133620977401733, 0.7176724076271057, 0.7209051847457886, 0.7133620977401733, 0.7165948152542114, 0.7112069129943848, 0.71875, 0.7198275923728943, 0.712284505367279, 0.7209051847457886, 0.71875, 0.7262930870056152, 0.7068965435028076, 0.7198275923728943, 0.7101293206214905, 0.7101293206214905, 0.712284505367279, 0.7230603694915771, 0.7165948152542114, 0.7101293206214905, 0.7219827771186829, 0.7090517282485962, 0.712284505367279, 0.7176724076271057, 0.7004310488700867, 0.7133620977401733, 0.71875, 0.7155172228813171, 0.71875, 0.7112069129943848, 0.7209051847457886, 0.7090517282485962, 0.7112069129943848, 0.7025862336158752, 0.6961206793785095, 0.7079741358757019, 0.6961206793785095, 0.7155172228813171, 0.7090517282485962, 0.7230603694915771, 0.6778017282485962, 0.6885775923728943, 0.7036637663841248, 0.7144396305084229, 0.7219827771186829, 0.7112069129943848, 0.7165948152542114, 0.7058189511299133, 0.7176724076271057, 0.6971982717514038, 0.6950430870056152, 0.693965494632721, 0.7133620977401733, 0.7058189511299133, 0.7101293206214905, 0.71875, 0.7068965435028076, 0.7165948152542114, 0.701508641242981, 0.7025862336158752, 0.7144396305084229, 0.7068965435028076, 0.7101293206214905, 0.7144396305084229, 0.6918103694915771, 0.7058189511299133, 0.6896551847457886, 0.6885775923728943, 0.6831896305084229, 0.7144396305084229]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.7001 - accuracy: 0.8111"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 12s 177ms/step - loss: 0.7017 - accuracy: 0.8107 - val_loss: 0.9916 - val_accuracy: 0.5102\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6716 - accuracy: 0.8314 - val_loss: 0.9932 - val_accuracy: 0.5079\n","Epoch 3/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6596 - accuracy: 0.8367 - val_loss: 0.9905 - val_accuracy: 0.5113\n","Epoch 4/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6529 - accuracy: 0.8452 - val_loss: 0.9842 - val_accuracy: 0.5170\n","Epoch 5/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6743 - accuracy: 0.8305 - val_loss: 0.9850 - val_accuracy: 0.5136\n","Epoch 6/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6480 - accuracy: 0.8396 - val_loss: 0.9751 - val_accuracy: 0.5362\n","Epoch 7/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6373 - accuracy: 0.8529 - val_loss: 0.9685 - val_accuracy: 0.5600\n","Epoch 8/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6318 - accuracy: 0.8497 - val_loss: 0.9617 - val_accuracy: 0.5769\n","Epoch 9/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6307 - accuracy: 0.8503 - val_loss: 0.9566 - val_accuracy: 0.5860\n","Epoch 10/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.6203 - accuracy: 0.8574 - val_loss: 0.9513 - val_accuracy: 0.5871\n","Epoch 11/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.6159 - accuracy: 0.8664 - val_loss: 0.9444 - val_accuracy: 0.6052\n","Epoch 12/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.6095 - accuracy: 0.8687 - val_loss: 0.9241 - val_accuracy: 0.6674\n","Epoch 13/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6251 - accuracy: 0.8503 - val_loss: 0.9238 - val_accuracy: 0.6482\n","Epoch 14/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6065 - accuracy: 0.8616 - val_loss: 0.9028 - val_accuracy: 0.6900\n","Epoch 15/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5909 - accuracy: 0.8684 - val_loss: 0.8926 - val_accuracy: 0.6980\n","Epoch 16/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5858 - accuracy: 0.8746 - val_loss: 0.8772 - val_accuracy: 0.7161\n","Epoch 17/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5888 - accuracy: 0.8755 - val_loss: 0.8703 - val_accuracy: 0.7059\n","Epoch 18/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5918 - accuracy: 0.8704 - val_loss: 0.8812 - val_accuracy: 0.6821\n","Epoch 19/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5944 - accuracy: 0.8693 - val_loss: 0.8478 - val_accuracy: 0.7149\n","Epoch 20/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5761 - accuracy: 0.8814 - val_loss: 0.8480 - val_accuracy: 0.7104\n","Epoch 21/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5767 - accuracy: 0.8843 - val_loss: 0.8530 - val_accuracy: 0.7149\n","Epoch 22/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5761 - accuracy: 0.8718 - val_loss: 0.8604 - val_accuracy: 0.7104\n","Epoch 23/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5667 - accuracy: 0.8896 - val_loss: 0.8458 - val_accuracy: 0.7059\n","Epoch 24/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5689 - accuracy: 0.8817 - val_loss: 0.8427 - val_accuracy: 0.7104\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5604 - accuracy: 0.8823 - val_loss: 0.8672 - val_accuracy: 0.6934\n","Epoch 26/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5484 - accuracy: 0.8928 - val_loss: 0.8582 - val_accuracy: 0.7138\n","Epoch 27/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5498 - accuracy: 0.8894 - val_loss: 0.8648 - val_accuracy: 0.7093\n","Epoch 28/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5447 - accuracy: 0.8913 - val_loss: 0.8834 - val_accuracy: 0.7048\n","Epoch 29/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5348 - accuracy: 0.9001 - val_loss: 0.8872 - val_accuracy: 0.7059\n","Epoch 30/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5356 - accuracy: 0.8984 - val_loss: 0.9396 - val_accuracy: 0.6889\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5382 - accuracy: 0.8939 - val_loss: 0.9129 - val_accuracy: 0.7025\n","Epoch 32/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5278 - accuracy: 0.9052 - val_loss: 0.9163 - val_accuracy: 0.7070\n","Epoch 33/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5324 - accuracy: 0.9007 - val_loss: 0.9858 - val_accuracy: 0.6855\n","Epoch 34/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.5239 - accuracy: 0.9063 - val_loss: 0.9522 - val_accuracy: 0.6968\n","Epoch 35/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5171 - accuracy: 0.9061 - val_loss: 0.9818 - val_accuracy: 0.6912\n","Epoch 36/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5173 - accuracy: 0.8998 - val_loss: 0.9584 - val_accuracy: 0.7048\n","Epoch 37/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5271 - accuracy: 0.8925 - val_loss: 0.9945 - val_accuracy: 0.6946\n","Epoch 38/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5130 - accuracy: 0.9080 - val_loss: 0.9459 - val_accuracy: 0.7014\n","Epoch 39/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5079 - accuracy: 0.9089 - val_loss: 1.0702 - val_accuracy: 0.6753\n","Epoch 40/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4946 - accuracy: 0.9143 - val_loss: 0.9468 - val_accuracy: 0.7025\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4989 - accuracy: 0.9134 - val_loss: 0.9478 - val_accuracy: 0.7070\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4867 - accuracy: 0.9157 - val_loss: 1.0031 - val_accuracy: 0.6946\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4953 - accuracy: 0.9128 - val_loss: 0.9932 - val_accuracy: 0.7070\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4856 - accuracy: 0.9137 - val_loss: 0.9651 - val_accuracy: 0.7036\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4789 - accuracy: 0.9148 - val_loss: 0.9698 - val_accuracy: 0.6991\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4775 - accuracy: 0.9211 - val_loss: 0.9815 - val_accuracy: 0.7059\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5006 - accuracy: 0.9072 - val_loss: 1.0323 - val_accuracy: 0.6934\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4753 - accuracy: 0.9202 - val_loss: 0.9716 - val_accuracy: 0.7014\n","Epoch 49/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4724 - accuracy: 0.9236 - val_loss: 1.0086 - val_accuracy: 0.7048\n","Epoch 50/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4574 - accuracy: 0.9298 - val_loss: 0.9810 - val_accuracy: 0.7059\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4689 - accuracy: 0.9199 - val_loss: 1.0249 - val_accuracy: 0.7014\n","Epoch 52/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4626 - accuracy: 0.9253 - val_loss: 1.0273 - val_accuracy: 0.6991\n","Epoch 53/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4521 - accuracy: 0.9315 - val_loss: 1.0355 - val_accuracy: 0.7002\n","Epoch 54/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4566 - accuracy: 0.9290 - val_loss: 1.0294 - val_accuracy: 0.7036\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4476 - accuracy: 0.9321 - val_loss: 1.0421 - val_accuracy: 0.7036\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4486 - accuracy: 0.9344 - val_loss: 1.0062 - val_accuracy: 0.7002\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4500 - accuracy: 0.9295 - val_loss: 1.0538 - val_accuracy: 0.6991\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4420 - accuracy: 0.9332 - val_loss: 1.0248 - val_accuracy: 0.7059\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4398 - accuracy: 0.9383 - val_loss: 1.1396 - val_accuracy: 0.6833\n","Epoch 60/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4371 - accuracy: 0.9377 - val_loss: 1.1384 - val_accuracy: 0.6833\n","Epoch 61/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4373 - accuracy: 0.9369 - val_loss: 1.2716 - val_accuracy: 0.6697\n","Epoch 62/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4653 - accuracy: 0.9208 - val_loss: 1.0939 - val_accuracy: 0.7093\n","Epoch 63/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4263 - accuracy: 0.9457 - val_loss: 1.0410 - val_accuracy: 0.7025\n","Epoch 64/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4272 - accuracy: 0.9426 - val_loss: 1.1100 - val_accuracy: 0.6957\n","Epoch 65/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4153 - accuracy: 0.9477 - val_loss: 1.0434 - val_accuracy: 0.7014\n","Epoch 66/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4186 - accuracy: 0.9406 - val_loss: 1.0526 - val_accuracy: 0.6900\n","Epoch 67/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4105 - accuracy: 0.9519 - val_loss: 1.0536 - val_accuracy: 0.7014\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4261 - accuracy: 0.9346 - val_loss: 1.2622 - val_accuracy: 0.6742\n","Epoch 69/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4442 - accuracy: 0.9273 - val_loss: 1.1428 - val_accuracy: 0.6991\n","Epoch 70/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4109 - accuracy: 0.9493 - val_loss: 1.0769 - val_accuracy: 0.6957\n","Epoch 71/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4179 - accuracy: 0.9414 - val_loss: 1.0755 - val_accuracy: 0.7002\n","Epoch 72/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4126 - accuracy: 0.9437 - val_loss: 1.1092 - val_accuracy: 0.6878\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3956 - accuracy: 0.9536 - val_loss: 1.1293 - val_accuracy: 0.6946\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4014 - accuracy: 0.9527 - val_loss: 1.0777 - val_accuracy: 0.6934\n","Epoch 75/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3993 - accuracy: 0.9530 - val_loss: 1.0779 - val_accuracy: 0.7036\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3912 - accuracy: 0.9544 - val_loss: 1.1078 - val_accuracy: 0.6991\n","Epoch 77/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4001 - accuracy: 0.9468 - val_loss: 1.3047 - val_accuracy: 0.6708\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4063 - accuracy: 0.9477 - val_loss: 1.1130 - val_accuracy: 0.7048\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3918 - accuracy: 0.9530 - val_loss: 1.1331 - val_accuracy: 0.7025\n","Epoch 80/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3976 - accuracy: 0.9513 - val_loss: 1.1064 - val_accuracy: 0.7002\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3884 - accuracy: 0.9533 - val_loss: 1.2285 - val_accuracy: 0.6878\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3866 - accuracy: 0.9542 - val_loss: 1.1175 - val_accuracy: 0.7059\n","Epoch 83/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3846 - accuracy: 0.9573 - val_loss: 1.2166 - val_accuracy: 0.6923\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3820 - accuracy: 0.9530 - val_loss: 1.2659 - val_accuracy: 0.6821\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3862 - accuracy: 0.9550 - val_loss: 1.1441 - val_accuracy: 0.6878\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3754 - accuracy: 0.9595 - val_loss: 1.1808 - val_accuracy: 0.6957\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3708 - accuracy: 0.9624 - val_loss: 1.1303 - val_accuracy: 0.7014\n","Epoch 88/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3641 - accuracy: 0.9683 - val_loss: 1.2305 - val_accuracy: 0.6855\n","Epoch 89/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3775 - accuracy: 0.9578 - val_loss: 1.1605 - val_accuracy: 0.6934\n","Epoch 90/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3733 - accuracy: 0.9581 - val_loss: 1.1405 - val_accuracy: 0.7048\n","Epoch 91/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3599 - accuracy: 0.9652 - val_loss: 1.1500 - val_accuracy: 0.6980\n","Epoch 92/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3712 - accuracy: 0.9584 - val_loss: 1.1732 - val_accuracy: 0.7036\n","Epoch 93/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3625 - accuracy: 0.9646 - val_loss: 1.1866 - val_accuracy: 0.6991\n","Epoch 94/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3569 - accuracy: 0.9666 - val_loss: 1.2564 - val_accuracy: 0.6957\n","Epoch 95/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3534 - accuracy: 0.9694 - val_loss: 1.1564 - val_accuracy: 0.7138\n","Epoch 96/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3663 - accuracy: 0.9598 - val_loss: 1.1683 - val_accuracy: 0.7002\n","Epoch 97/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3584 - accuracy: 0.9646 - val_loss: 1.1702 - val_accuracy: 0.7025\n","Epoch 98/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3926 - accuracy: 0.9462 - val_loss: 1.2117 - val_accuracy: 0.7048\n","Epoch 99/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3830 - accuracy: 0.9477 - val_loss: 1.1749 - val_accuracy: 0.7002\n","Epoch 100/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3678 - accuracy: 0.9573 - val_loss: 1.1680 - val_accuracy: 0.7059\n","{'loss': [0.7016693353652954, 0.6715986728668213, 0.6595611572265625, 0.6529124975204468, 0.6742868423461914, 0.6480088829994202, 0.6373332738876343, 0.6317713856697083, 0.630670428276062, 0.6202961802482605, 0.6158525943756104, 0.6094691753387451, 0.6251299977302551, 0.6064801812171936, 0.590894341468811, 0.5857519507408142, 0.5888063311576843, 0.5917903780937195, 0.5943613648414612, 0.5760536789894104, 0.5766543745994568, 0.5760633945465088, 0.5666907429695129, 0.568945050239563, 0.5603903532028198, 0.5483918190002441, 0.5498236417770386, 0.5447304844856262, 0.5347610116004944, 0.5355520844459534, 0.5382400751113892, 0.5277846455574036, 0.5323757529258728, 0.5238576531410217, 0.5171046853065491, 0.5173048377037048, 0.5270938277244568, 0.5129807591438293, 0.5078608989715576, 0.4946250021457672, 0.49888962507247925, 0.4867427945137024, 0.49531230330467224, 0.48564907908439636, 0.4788966774940491, 0.47747716307640076, 0.5005690455436707, 0.4752640128135681, 0.47235527634620667, 0.4573533833026886, 0.46886375546455383, 0.46264493465423584, 0.4521448016166687, 0.456612229347229, 0.44761157035827637, 0.44858893752098083, 0.45000845193862915, 0.44202157855033875, 0.4397916793823242, 0.43706828355789185, 0.4372631907463074, 0.46531811356544495, 0.42631644010543823, 0.4272107779979706, 0.4152999818325043, 0.41859790682792664, 0.4104568362236023, 0.4261060357093811, 0.44421178102493286, 0.4108653664588928, 0.4178861677646637, 0.4126439690589905, 0.39563798904418945, 0.4014008641242981, 0.3993179202079773, 0.3911801874637604, 0.4001058042049408, 0.4062652289867401, 0.3917785882949829, 0.3975934684276581, 0.38840150833129883, 0.3866126835346222, 0.38455408811569214, 0.38201841711997986, 0.38617533445358276, 0.37539708614349365, 0.3707614243030548, 0.3640769124031067, 0.37754347920417786, 0.37333059310913086, 0.3598519265651703, 0.37123745679855347, 0.3624958395957947, 0.35689687728881836, 0.35344499349594116, 0.3663020730018616, 0.358402281999588, 0.3925914466381073, 0.383016973733902, 0.36782243847846985], 'accuracy': [0.8106960654258728, 0.8313525915145874, 0.8367289304733276, 0.8452178835868835, 0.8305037021636963, 0.8395586013793945, 0.8528579473495483, 0.8497453331947327, 0.850311279296875, 0.8573853969573975, 0.8664402961730957, 0.8687040209770203, 0.850311279296875, 0.8616299033164978, 0.8684210777282715, 0.8746463060379028, 0.875495195388794, 0.8704017996788025, 0.8692699670791626, 0.8814374804496765, 0.8842670917510986, 0.8718166351318359, 0.8896434903144836, 0.8817204236984253, 0.8822863698005676, 0.8927561044692993, 0.8893604874610901, 0.8913412690162659, 0.9001131653785706, 0.8984153866767883, 0.8938879370689392, 0.905206561088562, 0.9006791114807129, 0.9063384532928467, 0.9060554504394531, 0.8998302221298218, 0.8924731016159058, 0.9080362319946289, 0.90888512134552, 0.9142614603042603, 0.9134125709533691, 0.9156762957572937, 0.9128466248512268, 0.9136955142021179, 0.9148274064064026, 0.9210526347160339, 0.9071873426437378, 0.9202037453651428, 0.9235993027687073, 0.9298245906829834, 0.9199207425117493, 0.9252971410751343, 0.9315223693847656, 0.9289756417274475, 0.9320882558822632, 0.9343519806861877, 0.9295415878295898, 0.9332201480865479, 0.9383135437965393, 0.937747597694397, 0.9368987083435059, 0.9207696914672852, 0.9456706047058105, 0.9425579905509949, 0.9476513862609863, 0.9405772686004639, 0.9518958926200867, 0.9346349835395813, 0.9272778630256653, 0.9493491649627686, 0.941426157951355, 0.9436898827552795, 0.9535936713218689, 0.9527447819709778, 0.9530277252197266, 0.95444256067276, 0.9468024969100952, 0.9476513862609863, 0.9530277252197266, 0.9513299465179443, 0.9533106684684753, 0.9541596174240112, 0.9572722315788269, 0.9530277252197266, 0.9550085067749023, 0.9595359563827515, 0.9623655676841736, 0.9683078527450562, 0.9578381180763245, 0.958121120929718, 0.9651952385902405, 0.9584040641784668, 0.9646292924880981, 0.9666100740432739, 0.9694397449493408, 0.9598188996315002, 0.9646292924880981, 0.9462365508079529, 0.9476513862609863, 0.9572722315788269], 'val_loss': [0.9915515184402466, 0.9932246208190918, 0.9904705286026001, 0.9841551184654236, 0.985008716583252, 0.9750723838806152, 0.96845543384552, 0.9617155194282532, 0.9565689563751221, 0.9512995481491089, 0.9444003105163574, 0.9241154789924622, 0.9237870573997498, 0.9028002619743347, 0.8925943970680237, 0.8772043585777283, 0.8702797889709473, 0.8811762928962708, 0.8477926254272461, 0.8479583859443665, 0.852981686592102, 0.8604353666305542, 0.8458372354507446, 0.8427364826202393, 0.8672175407409668, 0.8582099676132202, 0.8648419976234436, 0.8834049701690674, 0.8871925473213196, 0.9396389722824097, 0.9129230380058289, 0.9163153171539307, 0.9858075380325317, 0.9522272944450378, 0.9818342924118042, 0.9584407210350037, 0.9945123791694641, 0.9459097981452942, 1.07023024559021, 0.9468376636505127, 0.9478490352630615, 1.0031253099441528, 0.9932282567024231, 0.9651497602462769, 0.9698293805122375, 0.98150634765625, 1.0323156118392944, 0.9715536832809448, 1.0086497068405151, 0.9810280203819275, 1.0248889923095703, 1.0273264646530151, 1.035537838935852, 1.0294121503829956, 1.042099952697754, 1.0061644315719604, 1.0537604093551636, 1.0248000621795654, 1.1396467685699463, 1.1384223699569702, 1.271621823310852, 1.093934178352356, 1.040963888168335, 1.1100386381149292, 1.043407917022705, 1.0526484251022339, 1.053602933883667, 1.2621814012527466, 1.1428205966949463, 1.0769013166427612, 1.0754801034927368, 1.1092051267623901, 1.1292515993118286, 1.0776870250701904, 1.0778872966766357, 1.1078153848648071, 1.304705262184143, 1.1129742860794067, 1.1331099271774292, 1.106440544128418, 1.228492259979248, 1.1174964904785156, 1.2165883779525757, 1.265855073928833, 1.1440951824188232, 1.1808207035064697, 1.130279302597046, 1.2304803133010864, 1.1604697704315186, 1.1405198574066162, 1.1500489711761475, 1.1731525659561157, 1.1865708827972412, 1.2564122676849365, 1.1564290523529053, 1.168328881263733, 1.1701853275299072, 1.2116518020629883, 1.1749211549758911, 1.1679695844650269], 'val_accuracy': [0.5101810097694397, 0.5079185366630554, 0.5113122463226318, 0.516968309879303, 0.5135746598243713, 0.5361990928649902, 0.5599547624588013, 0.5769230723381042, 0.5859728455543518, 0.587104082107544, 0.6052036285400391, 0.6674208045005798, 0.6481900215148926, 0.6900452375411987, 0.6979637742042542, 0.7160633206367493, 0.7058823704719543, 0.6821267008781433, 0.7149321436882019, 0.7104072570800781, 0.7149321436882019, 0.7104072570800781, 0.7058823704719543, 0.7104072570800781, 0.6934388875961304, 0.7138009071350098, 0.709276020526886, 0.7047511339187622, 0.7058823704719543, 0.6889140009880066, 0.7024886608123779, 0.7070135474205017, 0.685520350933075, 0.6968325972557068, 0.6911764740943909, 0.7047511339187622, 0.6945701241493225, 0.7013574838638306, 0.6753393411636353, 0.7024886608123779, 0.7070135474205017, 0.6945701241493225, 0.7070135474205017, 0.7036198973655701, 0.6990950107574463, 0.7058823704719543, 0.6934388875961304, 0.7013574838638306, 0.7047511339187622, 0.7058823704719543, 0.7013574838638306, 0.6990950107574463, 0.7002262473106384, 0.7036198973655701, 0.7036198973655701, 0.7002262473106384, 0.6990950107574463, 0.7058823704719543, 0.6832579374313354, 0.6832579374313354, 0.6696832776069641, 0.709276020526886, 0.7024886608123779, 0.6957013607025146, 0.7013574838638306, 0.6900452375411987, 0.7013574838638306, 0.6742081642150879, 0.6990950107574463, 0.6957013607025146, 0.7002262473106384, 0.6877828240394592, 0.6945701241493225, 0.6934388875961304, 0.7036198973655701, 0.6990950107574463, 0.6708144545555115, 0.7047511339187622, 0.7024886608123779, 0.7002262473106384, 0.6877828240394592, 0.7058823704719543, 0.692307710647583, 0.6821267008781433, 0.6877828240394592, 0.6957013607025146, 0.7013574838638306, 0.685520350933075, 0.6934388875961304, 0.7047511339187622, 0.6979637742042542, 0.7036198973655701, 0.6990950107574463, 0.6957013607025146, 0.7138009071350098, 0.7002262473106384, 0.7024886608123779, 0.7047511339187622, 0.7002262473106384, 0.7058823704719543]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.7231 - accuracy: 0.8086"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 12s 172ms/step - loss: 0.7222 - accuracy: 0.8085 - val_loss: 0.9936 - val_accuracy: 0.5176\n","Epoch 2/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6816 - accuracy: 0.8295 - val_loss: 0.9930 - val_accuracy: 0.5176\n","Epoch 3/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6805 - accuracy: 0.8279 - val_loss: 0.9855 - val_accuracy: 0.5227\n","Epoch 4/100\n","31/31 [==============================] - 1s 36ms/step - loss: 0.6999 - accuracy: 0.8173 - val_loss: 0.9823 - val_accuracy: 0.5289\n","Epoch 5/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6915 - accuracy: 0.8217 - val_loss: 0.9775 - val_accuracy: 0.5382\n","Epoch 6/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6824 - accuracy: 0.8245 - val_loss: 0.9733 - val_accuracy: 0.5506\n","Epoch 7/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6564 - accuracy: 0.8478 - val_loss: 0.9676 - val_accuracy: 0.5661\n","Epoch 8/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6507 - accuracy: 0.8494 - val_loss: 0.9672 - val_accuracy: 0.5579\n","Epoch 9/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6518 - accuracy: 0.8390 - val_loss: 0.9621 - val_accuracy: 0.5599\n","Epoch 10/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6406 - accuracy: 0.8426 - val_loss: 0.9502 - val_accuracy: 0.5826\n","Epoch 11/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6389 - accuracy: 0.8494 - val_loss: 0.9451 - val_accuracy: 0.5847\n","Epoch 12/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6329 - accuracy: 0.8514 - val_loss: 0.9354 - val_accuracy: 0.6167\n","Epoch 13/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6267 - accuracy: 0.8535 - val_loss: 0.9367 - val_accuracy: 0.5909\n","Epoch 14/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.6208 - accuracy: 0.8553 - val_loss: 0.9151 - val_accuracy: 0.6591\n","Epoch 15/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6261 - accuracy: 0.8574 - val_loss: 0.9103 - val_accuracy: 0.6570\n","Epoch 16/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6110 - accuracy: 0.8615 - val_loss: 0.8989 - val_accuracy: 0.6808\n","Epoch 17/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6205 - accuracy: 0.8504 - val_loss: 0.9104 - val_accuracy: 0.6529\n","Epoch 18/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6105 - accuracy: 0.8602 - val_loss: 0.8982 - val_accuracy: 0.6746\n","Epoch 19/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6035 - accuracy: 0.8695 - val_loss: 0.8924 - val_accuracy: 0.7035\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6046 - accuracy: 0.8610 - val_loss: 0.8975 - val_accuracy: 0.6932\n","Epoch 21/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5915 - accuracy: 0.8721 - val_loss: 0.9196 - val_accuracy: 0.6736\n","Epoch 22/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5955 - accuracy: 0.8713 - val_loss: 0.9207 - val_accuracy: 0.6808\n","Epoch 23/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5959 - accuracy: 0.8607 - val_loss: 0.9295 - val_accuracy: 0.6952\n","Epoch 24/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5918 - accuracy: 0.8630 - val_loss: 1.0462 - val_accuracy: 0.6353\n","Epoch 25/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6084 - accuracy: 0.8574 - val_loss: 0.9410 - val_accuracy: 0.7087\n","Epoch 26/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5781 - accuracy: 0.8731 - val_loss: 0.9664 - val_accuracy: 0.6860\n","Epoch 27/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5801 - accuracy: 0.8674 - val_loss: 0.9854 - val_accuracy: 0.6901\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5744 - accuracy: 0.8832 - val_loss: 0.9889 - val_accuracy: 0.6818\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5658 - accuracy: 0.8793 - val_loss: 0.9779 - val_accuracy: 0.7066\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5574 - accuracy: 0.8863 - val_loss: 0.9878 - val_accuracy: 0.7004\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5586 - accuracy: 0.8837 - val_loss: 1.0011 - val_accuracy: 0.6921\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5651 - accuracy: 0.8832 - val_loss: 1.0058 - val_accuracy: 0.6839\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5544 - accuracy: 0.8868 - val_loss: 1.0089 - val_accuracy: 0.6890\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5621 - accuracy: 0.8786 - val_loss: 1.0093 - val_accuracy: 0.6963\n","Epoch 35/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5390 - accuracy: 0.8951 - val_loss: 1.0331 - val_accuracy: 0.6787\n","Epoch 36/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5398 - accuracy: 0.8904 - val_loss: 1.0211 - val_accuracy: 0.6963\n","Epoch 37/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5351 - accuracy: 0.8941 - val_loss: 1.0426 - val_accuracy: 0.6808\n","Epoch 38/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5457 - accuracy: 0.8873 - val_loss: 1.0222 - val_accuracy: 0.7014\n","Epoch 39/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5277 - accuracy: 0.8964 - val_loss: 1.0299 - val_accuracy: 0.6849\n","Epoch 40/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5298 - accuracy: 0.8953 - val_loss: 1.0341 - val_accuracy: 0.6901\n","Epoch 41/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5515 - accuracy: 0.8788 - val_loss: 1.0301 - val_accuracy: 0.7025\n","Epoch 42/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5254 - accuracy: 0.8997 - val_loss: 1.0409 - val_accuracy: 0.6849\n","Epoch 43/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5175 - accuracy: 0.9067 - val_loss: 1.0304 - val_accuracy: 0.7014\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5181 - accuracy: 0.9010 - val_loss: 1.0507 - val_accuracy: 0.7014\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5038 - accuracy: 0.9070 - val_loss: 1.1284 - val_accuracy: 0.6653\n","Epoch 46/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5006 - accuracy: 0.9090 - val_loss: 1.0646 - val_accuracy: 0.6932\n","Epoch 47/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5056 - accuracy: 0.9052 - val_loss: 1.1330 - val_accuracy: 0.6632\n","Epoch 48/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5347 - accuracy: 0.8886 - val_loss: 1.0899 - val_accuracy: 0.6829\n","Epoch 49/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5175 - accuracy: 0.8953 - val_loss: 1.0529 - val_accuracy: 0.6890\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5131 - accuracy: 0.9039 - val_loss: 1.0524 - val_accuracy: 0.6849\n","Epoch 51/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5056 - accuracy: 0.9052 - val_loss: 1.0575 - val_accuracy: 0.6994\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4906 - accuracy: 0.9163 - val_loss: 1.0670 - val_accuracy: 0.6849\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4871 - accuracy: 0.9186 - val_loss: 1.0821 - val_accuracy: 0.6911\n","Epoch 54/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4932 - accuracy: 0.9031 - val_loss: 1.0747 - val_accuracy: 0.6963\n","Epoch 55/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4874 - accuracy: 0.9145 - val_loss: 1.2520 - val_accuracy: 0.6498\n","Epoch 56/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4965 - accuracy: 0.9093 - val_loss: 1.0777 - val_accuracy: 0.6829\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4701 - accuracy: 0.9204 - val_loss: 1.1674 - val_accuracy: 0.6601\n","Epoch 58/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4734 - accuracy: 0.9176 - val_loss: 1.0953 - val_accuracy: 0.6818\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4759 - accuracy: 0.9165 - val_loss: 1.1030 - val_accuracy: 0.6818\n","Epoch 60/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4739 - accuracy: 0.9160 - val_loss: 1.1130 - val_accuracy: 0.6921\n","Epoch 61/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4624 - accuracy: 0.9279 - val_loss: 1.1448 - val_accuracy: 0.6736\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4777 - accuracy: 0.9181 - val_loss: 1.0999 - val_accuracy: 0.6808\n","Epoch 63/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4556 - accuracy: 0.9253 - val_loss: 1.1022 - val_accuracy: 0.6870\n","Epoch 64/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4637 - accuracy: 0.9196 - val_loss: 1.1062 - val_accuracy: 0.6860\n","Epoch 65/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4860 - accuracy: 0.9083 - val_loss: 1.1811 - val_accuracy: 0.6798\n","Epoch 66/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4536 - accuracy: 0.9282 - val_loss: 1.1257 - val_accuracy: 0.6932\n","Epoch 67/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4489 - accuracy: 0.9313 - val_loss: 1.1123 - val_accuracy: 0.6870\n","Epoch 68/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4378 - accuracy: 0.9385 - val_loss: 1.1212 - val_accuracy: 0.6829\n","Epoch 69/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4418 - accuracy: 0.9341 - val_loss: 1.1468 - val_accuracy: 0.6880\n","Epoch 70/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4543 - accuracy: 0.9279 - val_loss: 1.1264 - val_accuracy: 0.6921\n","Epoch 71/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4413 - accuracy: 0.9336 - val_loss: 1.1451 - val_accuracy: 0.6808\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4433 - accuracy: 0.9300 - val_loss: 1.1346 - val_accuracy: 0.6808\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4247 - accuracy: 0.9432 - val_loss: 1.2412 - val_accuracy: 0.6705\n","Epoch 74/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4394 - accuracy: 0.9307 - val_loss: 1.1408 - val_accuracy: 0.6942\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4243 - accuracy: 0.9388 - val_loss: 1.1576 - val_accuracy: 0.6880\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4344 - accuracy: 0.9328 - val_loss: 1.1711 - val_accuracy: 0.6890\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4225 - accuracy: 0.9388 - val_loss: 1.1809 - val_accuracy: 0.6849\n","Epoch 78/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4374 - accuracy: 0.9289 - val_loss: 1.3409 - val_accuracy: 0.6570\n","Epoch 79/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4358 - accuracy: 0.9305 - val_loss: 1.1767 - val_accuracy: 0.6839\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4215 - accuracy: 0.9452 - val_loss: 1.1935 - val_accuracy: 0.6818\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4236 - accuracy: 0.9382 - val_loss: 1.2236 - val_accuracy: 0.6808\n","Epoch 82/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4237 - accuracy: 0.9385 - val_loss: 1.1855 - val_accuracy: 0.6818\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4049 - accuracy: 0.9460 - val_loss: 1.1756 - val_accuracy: 0.6880\n","Epoch 84/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4114 - accuracy: 0.9432 - val_loss: 1.2209 - val_accuracy: 0.6798\n","Epoch 85/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4028 - accuracy: 0.9486 - val_loss: 1.1937 - val_accuracy: 0.6870\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4002 - accuracy: 0.9481 - val_loss: 1.1934 - val_accuracy: 0.6839\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4017 - accuracy: 0.9488 - val_loss: 1.2146 - val_accuracy: 0.6839\n","Epoch 88/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3931 - accuracy: 0.9527 - val_loss: 1.2170 - val_accuracy: 0.6921\n","Epoch 89/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3959 - accuracy: 0.9501 - val_loss: 1.2688 - val_accuracy: 0.6798\n","Epoch 90/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3875 - accuracy: 0.9514 - val_loss: 1.2243 - val_accuracy: 0.6860\n","Epoch 91/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3964 - accuracy: 0.9496 - val_loss: 1.2312 - val_accuracy: 0.6839\n","Epoch 92/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4118 - accuracy: 0.9388 - val_loss: 1.2410 - val_accuracy: 0.6890\n","Epoch 93/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3824 - accuracy: 0.9592 - val_loss: 1.2910 - val_accuracy: 0.6746\n","Epoch 94/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3913 - accuracy: 0.9517 - val_loss: 1.5013 - val_accuracy: 0.6488\n","Epoch 95/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4025 - accuracy: 0.9408 - val_loss: 1.2302 - val_accuracy: 0.6870\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3792 - accuracy: 0.9589 - val_loss: 1.2439 - val_accuracy: 0.6839\n","Epoch 97/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3845 - accuracy: 0.9514 - val_loss: 1.2360 - val_accuracy: 0.6870\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3712 - accuracy: 0.9602 - val_loss: 1.2468 - val_accuracy: 0.6860\n","Epoch 99/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3794 - accuracy: 0.9543 - val_loss: 1.2507 - val_accuracy: 0.6839\n","Epoch 100/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3640 - accuracy: 0.9677 - val_loss: 1.2594 - val_accuracy: 0.6767\n","{'loss': [0.7222341895103455, 0.6815765500068665, 0.6805392503738403, 0.6998981833457947, 0.6915171146392822, 0.6823832392692566, 0.6564197540283203, 0.650672197341919, 0.6517703533172607, 0.6405799388885498, 0.6389375925064087, 0.6328631043434143, 0.6266964673995972, 0.6207568645477295, 0.6261205077171326, 0.6110278964042664, 0.6204503774642944, 0.6105359196662903, 0.60349440574646, 0.6046386361122131, 0.591529905796051, 0.5954781174659729, 0.5959006547927856, 0.591804027557373, 0.6083858013153076, 0.5781190991401672, 0.5800879597663879, 0.5744384527206421, 0.5658056139945984, 0.5574430227279663, 0.5585550665855408, 0.5650674700737, 0.5544047951698303, 0.5620821714401245, 0.5390188097953796, 0.5397607684135437, 0.5350939631462097, 0.5457092523574829, 0.5277473330497742, 0.5297830104827881, 0.5514546036720276, 0.5253940224647522, 0.5175415873527527, 0.5180778503417969, 0.5037866234779358, 0.5006093382835388, 0.5055776834487915, 0.5346741676330566, 0.5175270438194275, 0.5130727291107178, 0.5056270360946655, 0.4905914068222046, 0.4870762526988983, 0.49315503239631653, 0.4873588979244232, 0.49650144577026367, 0.4701129198074341, 0.4734225869178772, 0.4759291708469391, 0.4739195704460144, 0.46237966418266296, 0.4776613712310791, 0.45563116669654846, 0.46373528242111206, 0.48604851961135864, 0.45361557602882385, 0.44890516996383667, 0.4378160536289215, 0.44183284044265747, 0.4542604982852936, 0.4413051903247833, 0.4432559013366699, 0.42474955320358276, 0.4393725097179413, 0.4243243634700775, 0.43437495827674866, 0.42250505089759827, 0.4374077320098877, 0.43582460284233093, 0.4214935302734375, 0.423642098903656, 0.4236835837364197, 0.4048708379268646, 0.4114203453063965, 0.40282773971557617, 0.40019693970680237, 0.4017356038093567, 0.3931339681148529, 0.3958604335784912, 0.38754430413246155, 0.39636966586112976, 0.4117797613143921, 0.3824467957019806, 0.3913114666938782, 0.4024866819381714, 0.37921929359436035, 0.3845193088054657, 0.37120482325553894, 0.37941327691078186, 0.3640017509460449], 'accuracy': [0.8085271120071411, 0.8294573426246643, 0.8279069662094116, 0.8173126578330994, 0.8217054009437561, 0.8245478272438049, 0.8478035926818848, 0.8493540287017822, 0.8390181064605713, 0.8426356315612793, 0.8493540287017822, 0.8514211773872375, 0.8534883856773376, 0.8552971482276917, 0.8573643565177917, 0.8614987134933472, 0.8503875732421875, 0.8602067232131958, 0.8695090413093567, 0.8609819412231445, 0.8720930218696594, 0.8713178038597107, 0.8607234954833984, 0.8630490899085999, 0.8573643565177917, 0.8731266260147095, 0.8674418330192566, 0.8832041621208191, 0.879328191280365, 0.8863049149513245, 0.8837209343910217, 0.8832041621208191, 0.8868216872215271, 0.8785529732704163, 0.8950904607772827, 0.8904392719268799, 0.8940568566322327, 0.8873385190963745, 0.8963824510574341, 0.895348846912384, 0.8788113594055176, 0.8997415900230408, 0.906718373298645, 0.9010335803031921, 0.9069767594337463, 0.9090439081192017, 0.9051679372787476, 0.8886305093765259, 0.895348846912384, 0.9038759469985962, 0.9051679372787476, 0.9162790775299072, 0.9186046719551086, 0.9031007885932922, 0.9144702553749084, 0.9093023538589478, 0.9204134345054626, 0.9175710678100586, 0.9165374636650085, 0.9160206913948059, 0.9279069900512695, 0.9180878400802612, 0.9253230094909668, 0.9196382164955139, 0.9082687497138977, 0.9281653761863708, 0.9312661290168762, 0.9385012984275818, 0.934108555316925, 0.9279069900512695, 0.9335917234420776, 0.9299741387367249, 0.9431524276733398, 0.9307493567466736, 0.9387596845626831, 0.9328165650367737, 0.9387596845626831, 0.9289405941963196, 0.9304909706115723, 0.9452196359634399, 0.9382429122924805, 0.9385012984275818, 0.9459948539733887, 0.9431524276733398, 0.9485788345336914, 0.948062002658844, 0.9488372206687927, 0.9527131915092468, 0.9501292109489441, 0.9514212012290955, 0.9496123790740967, 0.9387596845626831, 0.9591731429100037, 0.9516795873641968, 0.9408268928527832, 0.9589147567749023, 0.9514212012290955, 0.9602067470550537, 0.9542635679244995, 0.9677002429962158], 'val_loss': [0.993566632270813, 0.9929569363594055, 0.9855083227157593, 0.9823072552680969, 0.9774854779243469, 0.9733073711395264, 0.9676160216331482, 0.9672432541847229, 0.9620917439460754, 0.9501896500587463, 0.945148766040802, 0.9353591203689575, 0.9366857409477234, 0.9151445627212524, 0.91032874584198, 0.8988722562789917, 0.9103843569755554, 0.8982431888580322, 0.8924152851104736, 0.8974815011024475, 0.9196340441703796, 0.920717179775238, 0.92951500415802, 1.0461616516113281, 0.940956711769104, 0.9664098024368286, 0.9854497909545898, 0.9889349937438965, 0.9779266715049744, 0.9877597689628601, 1.001111388206482, 1.0057941675186157, 1.0088841915130615, 1.0092674493789673, 1.0331369638442993, 1.0210851430892944, 1.0425816774368286, 1.0222089290618896, 1.0298904180526733, 1.034070372581482, 1.0301319360733032, 1.0408961772918701, 1.0304232835769653, 1.0506823062896729, 1.1284446716308594, 1.0646055936813354, 1.132973313331604, 1.0899335145950317, 1.0529160499572754, 1.0524380207061768, 1.0574548244476318, 1.0669511556625366, 1.0820757150650024, 1.0746910572052002, 1.2520052194595337, 1.0777058601379395, 1.1673712730407715, 1.0952644348144531, 1.1029551029205322, 1.1130181550979614, 1.1447757482528687, 1.0999082326889038, 1.1021627187728882, 1.1062405109405518, 1.1810827255249023, 1.1256946325302124, 1.1122591495513916, 1.1211718320846558, 1.1468191146850586, 1.126386046409607, 1.1451153755187988, 1.1345906257629395, 1.2412002086639404, 1.140814185142517, 1.1575827598571777, 1.1710606813430786, 1.180915355682373, 1.340895414352417, 1.176662802696228, 1.1935375928878784, 1.2235671281814575, 1.1854593753814697, 1.1755728721618652, 1.2208669185638428, 1.1937129497528076, 1.1933937072753906, 1.2145801782608032, 1.2169690132141113, 1.2688324451446533, 1.2243114709854126, 1.231201171875, 1.2410340309143066, 1.2909616231918335, 1.5012680292129517, 1.2302004098892212, 1.243910312652588, 1.2360304594039917, 1.2467799186706543, 1.2507045269012451, 1.2594479322433472], 'val_accuracy': [0.5175619721412659, 0.5175619721412659, 0.5227272510528564, 0.5289255976676941, 0.538223147392273, 0.5506198406219482, 0.56611567735672, 0.557851254940033, 0.5599173307418823, 0.5826446413993835, 0.5847107172012329, 0.6167355179786682, 0.5909090638160706, 0.6590909361839294, 0.6570248007774353, 0.6807851195335388, 0.6528925895690918, 0.6745867729187012, 0.7035123705863953, 0.6931818127632141, 0.6735537052154541, 0.6807851195335388, 0.6952479481697083, 0.6353305578231812, 0.7086777091026306, 0.6859503984451294, 0.6900826692581177, 0.6818181872367859, 0.7066115736961365, 0.7004132270812988, 0.692148745059967, 0.68388432264328, 0.6890496015548706, 0.6962810158729553, 0.6787189841270447, 0.6962810158729553, 0.6807851195335388, 0.7014462947845459, 0.6849173307418823, 0.6900826692581177, 0.702479362487793, 0.6849173307418823, 0.7014462947845459, 0.7014462947845459, 0.6652892827987671, 0.6931818127632141, 0.663223147392273, 0.682851254940033, 0.6890496015548706, 0.6849173307418823, 0.6993801593780518, 0.6849173307418823, 0.69111567735672, 0.6962810158729553, 0.6497933864593506, 0.682851254940033, 0.6601239442825317, 0.6818181872367859, 0.6818181872367859, 0.692148745059967, 0.6735537052154541, 0.6807851195335388, 0.6869834661483765, 0.6859503984451294, 0.6797520518302917, 0.6931818127632141, 0.6869834661483765, 0.682851254940033, 0.6880165338516235, 0.692148745059967, 0.6807851195335388, 0.6807851195335388, 0.6704545617103577, 0.6942148804664612, 0.6880165338516235, 0.6890496015548706, 0.6849173307418823, 0.6570248007774353, 0.68388432264328, 0.6818181872367859, 0.6807851195335388, 0.6818181872367859, 0.6880165338516235, 0.6797520518302917, 0.6869834661483765, 0.68388432264328, 0.68388432264328, 0.692148745059967, 0.6797520518302917, 0.6859503984451294, 0.68388432264328, 0.6890496015548706, 0.6745867729187012, 0.6487603187561035, 0.6869834661483765, 0.68388432264328, 0.6869834661483765, 0.6859503984451294, 0.68388432264328, 0.6766529083251953]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.4844 - accuracy: 0.9099"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 13s 218ms/step - loss: 0.4897 - accuracy: 0.9087 - val_loss: 0.9482 - val_accuracy: 0.5205\n","Epoch 2/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4645 - accuracy: 0.9154 - val_loss: 0.9466 - val_accuracy: 0.5205\n","Epoch 3/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4470 - accuracy: 0.9195 - val_loss: 0.9372 - val_accuracy: 0.5323\n","Epoch 4/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.4425 - accuracy: 0.9211 - val_loss: 0.9302 - val_accuracy: 0.5431\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4407 - accuracy: 0.9265 - val_loss: 0.9322 - val_accuracy: 0.5388\n","Epoch 6/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.4422 - accuracy: 0.9270 - val_loss: 0.9285 - val_accuracy: 0.5485\n","Epoch 7/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.4341 - accuracy: 0.9240 - val_loss: 0.9091 - val_accuracy: 0.5819\n","Epoch 8/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.4206 - accuracy: 0.9380 - val_loss: 0.8976 - val_accuracy: 0.6002\n","Epoch 9/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4160 - accuracy: 0.9370 - val_loss: 0.8969 - val_accuracy: 0.5862\n","Epoch 10/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4126 - accuracy: 0.9402 - val_loss: 0.8743 - val_accuracy: 0.6325\n","Epoch 11/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4106 - accuracy: 0.9380 - val_loss: 0.8701 - val_accuracy: 0.6218\n","Epoch 12/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4069 - accuracy: 0.9386 - val_loss: 0.8679 - val_accuracy: 0.6196\n","Epoch 13/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4064 - accuracy: 0.9426 - val_loss: 0.8270 - val_accuracy: 0.7037\n","Epoch 14/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3966 - accuracy: 0.9483 - val_loss: 0.8168 - val_accuracy: 0.6983\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3875 - accuracy: 0.9494 - val_loss: 0.8152 - val_accuracy: 0.6907\n","Epoch 16/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3990 - accuracy: 0.9399 - val_loss: 0.7675 - val_accuracy: 0.7522\n","Epoch 17/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3925 - accuracy: 0.9475 - val_loss: 0.7516 - val_accuracy: 0.7575\n","Epoch 18/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3927 - accuracy: 0.9475 - val_loss: 0.7706 - val_accuracy: 0.7328\n","Epoch 19/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3966 - accuracy: 0.9450 - val_loss: 0.7532 - val_accuracy: 0.7522\n","Epoch 20/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3766 - accuracy: 0.9591 - val_loss: 0.7661 - val_accuracy: 0.7468\n","Epoch 21/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3774 - accuracy: 0.9572 - val_loss: 0.7676 - val_accuracy: 0.7468\n","Epoch 22/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3847 - accuracy: 0.9469 - val_loss: 0.8354 - val_accuracy: 0.7263\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4117 - accuracy: 0.9332 - val_loss: 0.8300 - val_accuracy: 0.7317\n","Epoch 24/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3854 - accuracy: 0.9485 - val_loss: 0.7552 - val_accuracy: 0.7802\n","Epoch 25/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3749 - accuracy: 0.9523 - val_loss: 0.7808 - val_accuracy: 0.7791\n","Epoch 26/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3768 - accuracy: 0.9550 - val_loss: 0.7734 - val_accuracy: 0.7748\n","Epoch 27/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3697 - accuracy: 0.9580 - val_loss: 0.8312 - val_accuracy: 0.7629\n","Epoch 28/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3596 - accuracy: 0.9671 - val_loss: 0.8160 - val_accuracy: 0.7640\n","Epoch 29/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3600 - accuracy: 0.9623 - val_loss: 0.8277 - val_accuracy: 0.7748\n","Epoch 30/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3786 - accuracy: 0.9456 - val_loss: 0.9420 - val_accuracy: 0.7446\n","Epoch 31/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3679 - accuracy: 0.9555 - val_loss: 0.8378 - val_accuracy: 0.7705\n","Epoch 32/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3510 - accuracy: 0.9663 - val_loss: 0.8315 - val_accuracy: 0.7769\n","Epoch 33/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3561 - accuracy: 0.9636 - val_loss: 0.8404 - val_accuracy: 0.7672\n","Epoch 34/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3542 - accuracy: 0.9639 - val_loss: 0.8604 - val_accuracy: 0.7694\n","Epoch 35/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3584 - accuracy: 0.9585 - val_loss: 0.9028 - val_accuracy: 0.7726\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3505 - accuracy: 0.9642 - val_loss: 0.8703 - val_accuracy: 0.7726\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3417 - accuracy: 0.9698 - val_loss: 0.8697 - val_accuracy: 0.7705\n","Epoch 38/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3462 - accuracy: 0.9642 - val_loss: 0.9267 - val_accuracy: 0.7629\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3554 - accuracy: 0.9577 - val_loss: 0.9799 - val_accuracy: 0.7414\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3626 - accuracy: 0.9561 - val_loss: 0.8779 - val_accuracy: 0.7726\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3391 - accuracy: 0.9669 - val_loss: 0.9033 - val_accuracy: 0.7716\n","Epoch 42/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3273 - accuracy: 0.9741 - val_loss: 0.9373 - val_accuracy: 0.7672\n","Epoch 43/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3336 - accuracy: 0.9690 - val_loss: 0.9105 - val_accuracy: 0.7683\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3275 - accuracy: 0.9741 - val_loss: 0.9078 - val_accuracy: 0.7716\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3329 - accuracy: 0.9712 - val_loss: 0.9726 - val_accuracy: 0.7586\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3526 - accuracy: 0.9577 - val_loss: 0.9177 - val_accuracy: 0.7662\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3366 - accuracy: 0.9698 - val_loss: 0.9000 - val_accuracy: 0.7640\n","Epoch 48/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3262 - accuracy: 0.9747 - val_loss: 0.9031 - val_accuracy: 0.7716\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3309 - accuracy: 0.9701 - val_loss: 0.9555 - val_accuracy: 0.7662\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3347 - accuracy: 0.9647 - val_loss: 0.9534 - val_accuracy: 0.7575\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3447 - accuracy: 0.9623 - val_loss: 0.9023 - val_accuracy: 0.7705\n","Epoch 52/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3332 - accuracy: 0.9690 - val_loss: 0.9119 - val_accuracy: 0.7619\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3179 - accuracy: 0.9749 - val_loss: 0.9473 - val_accuracy: 0.7662\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3218 - accuracy: 0.9720 - val_loss: 1.0583 - val_accuracy: 0.7511\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3232 - accuracy: 0.9731 - val_loss: 0.9563 - val_accuracy: 0.7672\n","Epoch 56/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3173 - accuracy: 0.9725 - val_loss: 0.9167 - val_accuracy: 0.7629\n","Epoch 57/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3201 - accuracy: 0.9731 - val_loss: 0.9286 - val_accuracy: 0.7597\n","Epoch 58/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3233 - accuracy: 0.9706 - val_loss: 0.9577 - val_accuracy: 0.7554\n","Epoch 59/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3260 - accuracy: 0.9749 - val_loss: 0.9554 - val_accuracy: 0.7662\n","Epoch 60/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3164 - accuracy: 0.9736 - val_loss: 0.9273 - val_accuracy: 0.7619\n","Epoch 61/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3111 - accuracy: 0.9776 - val_loss: 0.9446 - val_accuracy: 0.7640\n","Epoch 62/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3110 - accuracy: 0.9787 - val_loss: 1.0292 - val_accuracy: 0.7619\n","Epoch 63/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3390 - accuracy: 0.9623 - val_loss: 1.0010 - val_accuracy: 0.7522\n","Epoch 64/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3181 - accuracy: 0.9736 - val_loss: 1.1565 - val_accuracy: 0.7371\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3688 - accuracy: 0.9496 - val_loss: 1.0793 - val_accuracy: 0.7500\n","Epoch 66/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3436 - accuracy: 0.9601 - val_loss: 0.9567 - val_accuracy: 0.7640\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3040 - accuracy: 0.9793 - val_loss: 0.9454 - val_accuracy: 0.7705\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3056 - accuracy: 0.9806 - val_loss: 1.0969 - val_accuracy: 0.7522\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3045 - accuracy: 0.9784 - val_loss: 0.9459 - val_accuracy: 0.7672\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3027 - accuracy: 0.9814 - val_loss: 0.9860 - val_accuracy: 0.7619\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3015 - accuracy: 0.9809 - val_loss: 0.9987 - val_accuracy: 0.7586\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3051 - accuracy: 0.9795 - val_loss: 1.0541 - val_accuracy: 0.7554\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3098 - accuracy: 0.9774 - val_loss: 0.9701 - val_accuracy: 0.7640\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2966 - accuracy: 0.9830 - val_loss: 0.9706 - val_accuracy: 0.7716\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3030 - accuracy: 0.9782 - val_loss: 0.9909 - val_accuracy: 0.7683\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2986 - accuracy: 0.9795 - val_loss: 1.0626 - val_accuracy: 0.7565\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2971 - accuracy: 0.9836 - val_loss: 1.0594 - val_accuracy: 0.7597\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3142 - accuracy: 0.9712 - val_loss: 0.9953 - val_accuracy: 0.7608\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3188 - accuracy: 0.9690 - val_loss: 1.0856 - val_accuracy: 0.7468\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2951 - accuracy: 0.9833 - val_loss: 0.9796 - val_accuracy: 0.7759\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2922 - accuracy: 0.9822 - val_loss: 1.0019 - val_accuracy: 0.7554\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2913 - accuracy: 0.9825 - val_loss: 0.9784 - val_accuracy: 0.7608\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2891 - accuracy: 0.9846 - val_loss: 0.9969 - val_accuracy: 0.7500\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2904 - accuracy: 0.9820 - val_loss: 1.0602 - val_accuracy: 0.7543\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2828 - accuracy: 0.9865 - val_loss: 1.0078 - val_accuracy: 0.7619\n","Epoch 86/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2958 - accuracy: 0.9801 - val_loss: 1.0020 - val_accuracy: 0.7683\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2859 - accuracy: 0.9838 - val_loss: 1.0133 - val_accuracy: 0.7565\n","Epoch 88/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2887 - accuracy: 0.9838 - val_loss: 1.0083 - val_accuracy: 0.7629\n","Epoch 89/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2852 - accuracy: 0.9852 - val_loss: 0.9959 - val_accuracy: 0.7694\n","Epoch 90/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2835 - accuracy: 0.9863 - val_loss: 1.0357 - val_accuracy: 0.7651\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2983 - accuracy: 0.9768 - val_loss: 1.0426 - val_accuracy: 0.7640\n","Epoch 92/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2925 - accuracy: 0.9814 - val_loss: 1.0260 - val_accuracy: 0.7554\n","Epoch 93/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3053 - accuracy: 0.9760 - val_loss: 1.0285 - val_accuracy: 0.7511\n","Epoch 94/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2807 - accuracy: 0.9860 - val_loss: 1.0115 - val_accuracy: 0.7586\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2807 - accuracy: 0.9855 - val_loss: 1.0151 - val_accuracy: 0.7640\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2797 - accuracy: 0.9852 - val_loss: 1.0451 - val_accuracy: 0.7575\n","Epoch 97/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2729 - accuracy: 0.9908 - val_loss: 1.0328 - val_accuracy: 0.7640\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2728 - accuracy: 0.9914 - val_loss: 1.0667 - val_accuracy: 0.7629\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2783 - accuracy: 0.9860 - val_loss: 1.0863 - val_accuracy: 0.7619\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2724 - accuracy: 0.9890 - val_loss: 1.0330 - val_accuracy: 0.7511\n","{'loss': [0.48965102434158325, 0.464470773935318, 0.4469843804836273, 0.4424956142902374, 0.4406958818435669, 0.44215095043182373, 0.4340934157371521, 0.4205561578273773, 0.41596195101737976, 0.4126320481300354, 0.4105740189552307, 0.4068915843963623, 0.40637823939323425, 0.3966420888900757, 0.387469083070755, 0.3989769220352173, 0.3924620449542999, 0.39268749952316284, 0.39663296937942505, 0.37661173939704895, 0.37737032771110535, 0.3846866488456726, 0.411687970161438, 0.38539788126945496, 0.3748546540737152, 0.37678584456443787, 0.3696964383125305, 0.35960569977760315, 0.36004993319511414, 0.37861761450767517, 0.3678904175758362, 0.3510488271713257, 0.3560895025730133, 0.35420939326286316, 0.3584398925304413, 0.3504641354084015, 0.3417249321937561, 0.3462458848953247, 0.355360209941864, 0.3626432418823242, 0.33906078338623047, 0.32726991176605225, 0.33355483412742615, 0.327507346868515, 0.3328959345817566, 0.3525543808937073, 0.33658698201179504, 0.32621482014656067, 0.3308824300765991, 0.33472558856010437, 0.34472471475601196, 0.33317363262176514, 0.31793785095214844, 0.3217829763889313, 0.32323405146598816, 0.31732696294784546, 0.32010266184806824, 0.32327213883399963, 0.32604411244392395, 0.3163560628890991, 0.31108638644218445, 0.3109726011753082, 0.33900025486946106, 0.31812751293182373, 0.36883723735809326, 0.343575656414032, 0.3039968013763428, 0.30560269951820374, 0.3044532537460327, 0.3027273714542389, 0.30152127146720886, 0.30506110191345215, 0.3097505271434784, 0.2966325879096985, 0.3030332922935486, 0.2985817790031433, 0.297112375497818, 0.3141828179359436, 0.3187829256057739, 0.29513809084892273, 0.2922387421131134, 0.29127970337867737, 0.28913238644599915, 0.2904074788093567, 0.2828296720981598, 0.29583218693733215, 0.2858516573905945, 0.28871193528175354, 0.28523191809654236, 0.2834734618663788, 0.29831209778785706, 0.2925388514995575, 0.30528613924980164, 0.280707448720932, 0.28068381547927856, 0.27970847487449646, 0.27291253209114075, 0.2727576792240143, 0.278253972530365, 0.2724316716194153], 'accuracy': [0.9086745977401733, 0.915409505367279, 0.9194504022598267, 0.9210668206214905, 0.9264547228813171, 0.9269935488700867, 0.9240301847457886, 0.9380387663841248, 0.9369612336158752, 0.9401939511299133, 0.9380387663841248, 0.9385775923728943, 0.9426185488700867, 0.9482758641242981, 0.9493534564971924, 0.9399245977401733, 0.9474676847457886, 0.9474676847457886, 0.9450430870056152, 0.9590517282485962, 0.9571659564971924, 0.946928858757019, 0.9331896305084229, 0.9485452771186829, 0.9523168206214905, 0.9550107717514038, 0.9579741358757019, 0.967133641242981, 0.962284505367279, 0.9455819129943848, 0.9555495977401733, 0.9663254022598267, 0.9636314511299133, 0.9639008641242981, 0.9585129022598267, 0.9641702771186829, 0.9698275923728943, 0.9641702771186829, 0.9577047228813171, 0.9560883641242981, 0.9668642282485962, 0.9741379022598267, 0.9690194129943848, 0.9741379022598267, 0.9711745977401733, 0.9577047228813171, 0.9698275923728943, 0.9746767282485962, 0.970097005367279, 0.9647090435028076, 0.962284505367279, 0.9690194129943848, 0.974946141242981, 0.9719827771186829, 0.9730603694915771, 0.9725215435028076, 0.9730603694915771, 0.9706357717514038, 0.974946141242981, 0.9735991358757019, 0.9776400923728943, 0.9787176847457886, 0.962284505367279, 0.9735991358757019, 0.9496228694915771, 0.9601293206214905, 0.9792564511299133, 0.9806034564971924, 0.9784482717514038, 0.9814116358757019, 0.9808728694915771, 0.9795258641242981, 0.9773706793785095, 0.983027994632721, 0.978178858757019, 0.9795258641242981, 0.9835668206214905, 0.9711745977401733, 0.9690194129943848, 0.9832974076271057, 0.9822198152542114, 0.9824892282485962, 0.9846444129943848, 0.9819504022598267, 0.9865301847457886, 0.9800646305084229, 0.9838362336158752, 0.9838362336158752, 0.9851831793785095, 0.9862607717514038, 0.9768319129943848, 0.9814116358757019, 0.9760237336158752, 0.985991358757019, 0.9854525923728943, 0.9851831793785095, 0.990840494632721, 0.9913793206214905, 0.985991358757019, 0.9889547228813171], 'val_loss': [0.9482091069221497, 0.9466323852539062, 0.937196671962738, 0.9301641583442688, 0.93223637342453, 0.9284533262252808, 0.9090765714645386, 0.8975862860679626, 0.8969128131866455, 0.8743402361869812, 0.8701244592666626, 0.8678612112998962, 0.8270140886306763, 0.8167576789855957, 0.8151973485946655, 0.7674946188926697, 0.751572847366333, 0.7706393599510193, 0.753169596195221, 0.7660650014877319, 0.7676132321357727, 0.8353706002235413, 0.8300111889839172, 0.755234956741333, 0.7808376550674438, 0.7734019756317139, 0.8311762809753418, 0.8160267472267151, 0.8276534080505371, 0.9420450925827026, 0.8378068804740906, 0.8315072655677795, 0.8403555154800415, 0.8603852987289429, 0.9027791023254395, 0.8703242540359497, 0.8696538209915161, 0.926663339138031, 0.9798680543899536, 0.8779104948043823, 0.903325617313385, 0.9372648596763611, 0.910535991191864, 0.9078320264816284, 0.9725573062896729, 0.917667806148529, 0.8999728560447693, 0.9031307101249695, 0.9554678797721863, 0.9534124135971069, 0.9022716879844666, 0.911881148815155, 0.9473393559455872, 1.0582655668258667, 0.9563228487968445, 0.9166733026504517, 0.9285908937454224, 0.9576687812805176, 0.9553981423377991, 0.9272986650466919, 0.9446014761924744, 1.0292376279830933, 1.001034140586853, 1.156491756439209, 1.0793269872665405, 0.9566740989685059, 0.9454325437545776, 1.096887230873108, 0.9459049701690674, 0.9859517812728882, 0.9987343549728394, 1.0541385412216187, 0.9700560569763184, 0.9705750942230225, 0.9908589124679565, 1.0626428127288818, 1.0593969821929932, 0.9952933192253113, 1.085623025894165, 0.9795750975608826, 1.0019348859786987, 0.9783803224563599, 0.9968821406364441, 1.0602271556854248, 1.0078073740005493, 1.002043604850769, 1.0132611989974976, 1.0083377361297607, 0.9958637952804565, 1.0356996059417725, 1.0425602197647095, 1.0259701013565063, 1.0284512042999268, 1.0115479230880737, 1.0150837898254395, 1.0451273918151855, 1.032763957977295, 1.0666759014129639, 1.086320161819458, 1.032984733581543], 'val_accuracy': [0.5204741358757019, 0.5204741358757019, 0.5323275923728943, 0.5431034564971924, 0.5387930870056152, 0.548491358757019, 0.5818965435028076, 0.600215494632721, 0.5862069129943848, 0.6325430870056152, 0.6217672228813171, 0.6196120977401733, 0.7036637663841248, 0.6982758641242981, 0.6907327771186829, 0.7521551847457886, 0.7575430870056152, 0.732758641242981, 0.7521551847457886, 0.7467672228813171, 0.7467672228813171, 0.7262930870056152, 0.7316810488700867, 0.7801724076271057, 0.7790948152542114, 0.774784505367279, 0.7629310488700867, 0.764008641242981, 0.774784505367279, 0.7446120977401733, 0.7704741358757019, 0.7769396305084229, 0.767241358757019, 0.7693965435028076, 0.7726293206214905, 0.7726293206214905, 0.7704741358757019, 0.7629310488700867, 0.7413793206214905, 0.7726293206214905, 0.7715517282485962, 0.767241358757019, 0.7683189511299133, 0.7715517282485962, 0.7586206793785095, 0.7661637663841248, 0.764008641242981, 0.7715517282485962, 0.7661637663841248, 0.7575430870056152, 0.7704741358757019, 0.7618534564971924, 0.7661637663841248, 0.7510775923728943, 0.767241358757019, 0.7629310488700867, 0.7596982717514038, 0.7553879022598267, 0.7661637663841248, 0.7618534564971924, 0.764008641242981, 0.7618534564971924, 0.7521551847457886, 0.7370689511299133, 0.75, 0.764008641242981, 0.7704741358757019, 0.7521551847457886, 0.767241358757019, 0.7618534564971924, 0.7586206793785095, 0.7553879022598267, 0.764008641242981, 0.7715517282485962, 0.7683189511299133, 0.756465494632721, 0.7596982717514038, 0.7607758641242981, 0.7467672228813171, 0.7758620977401733, 0.7553879022598267, 0.7607758641242981, 0.75, 0.7543103694915771, 0.7618534564971924, 0.7683189511299133, 0.756465494632721, 0.7629310488700867, 0.7693965435028076, 0.7650862336158752, 0.764008641242981, 0.7553879022598267, 0.7510775923728943, 0.7586206793785095, 0.764008641242981, 0.7575430870056152, 0.764008641242981, 0.7629310488700867, 0.7618534564971924, 0.7510775923728943]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.4925 - accuracy: 0.8978"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 12s 223ms/step - loss: 0.4904 - accuracy: 0.8984 - val_loss: 0.9522 - val_accuracy: 0.5068\n","Epoch 2/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4639 - accuracy: 0.9154 - val_loss: 0.9538 - val_accuracy: 0.5068\n","Epoch 3/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4386 - accuracy: 0.9261 - val_loss: 0.9497 - val_accuracy: 0.5102\n","Epoch 4/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4320 - accuracy: 0.9315 - val_loss: 0.9439 - val_accuracy: 0.5124\n","Epoch 5/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4296 - accuracy: 0.9301 - val_loss: 0.9370 - val_accuracy: 0.5170\n","Epoch 6/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4213 - accuracy: 0.9377 - val_loss: 0.9322 - val_accuracy: 0.5271\n","Epoch 7/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4169 - accuracy: 0.9335 - val_loss: 0.9242 - val_accuracy: 0.5498\n","Epoch 8/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4203 - accuracy: 0.9324 - val_loss: 0.9135 - val_accuracy: 0.5724\n","Epoch 9/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4200 - accuracy: 0.9349 - val_loss: 0.9140 - val_accuracy: 0.5622\n","Epoch 10/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4101 - accuracy: 0.9383 - val_loss: 0.8714 - val_accuracy: 0.6550\n","Epoch 11/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4159 - accuracy: 0.9358 - val_loss: 0.8660 - val_accuracy: 0.6471\n","Epoch 12/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3929 - accuracy: 0.9460 - val_loss: 0.8468 - val_accuracy: 0.6855\n","Epoch 13/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3955 - accuracy: 0.9485 - val_loss: 0.8772 - val_accuracy: 0.6131\n","Epoch 14/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.3992 - accuracy: 0.9417 - val_loss: 0.8348 - val_accuracy: 0.6867\n","Epoch 15/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.4232 - accuracy: 0.9293 - val_loss: 0.7759 - val_accuracy: 0.7760\n","Epoch 16/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4145 - accuracy: 0.9324 - val_loss: 0.7765 - val_accuracy: 0.7534\n","Epoch 17/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3864 - accuracy: 0.9539 - val_loss: 0.7777 - val_accuracy: 0.7443\n","Epoch 18/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3899 - accuracy: 0.9493 - val_loss: 0.7682 - val_accuracy: 0.7489\n","Epoch 19/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3853 - accuracy: 0.9491 - val_loss: 0.7283 - val_accuracy: 0.7851\n","Epoch 20/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3914 - accuracy: 0.9485 - val_loss: 0.7468 - val_accuracy: 0.7579\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3818 - accuracy: 0.9496 - val_loss: 0.7674 - val_accuracy: 0.7489\n","Epoch 22/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3751 - accuracy: 0.9533 - val_loss: 0.7334 - val_accuracy: 0.7715\n","Epoch 23/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3681 - accuracy: 0.9615 - val_loss: 0.7846 - val_accuracy: 0.7511\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3685 - accuracy: 0.9570 - val_loss: 0.7596 - val_accuracy: 0.7715\n","Epoch 25/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3658 - accuracy: 0.9564 - val_loss: 0.7647 - val_accuracy: 0.7726\n","Epoch 26/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3654 - accuracy: 0.9581 - val_loss: 0.7903 - val_accuracy: 0.7749\n","Epoch 27/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3536 - accuracy: 0.9610 - val_loss: 0.7998 - val_accuracy: 0.7851\n","Epoch 28/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3592 - accuracy: 0.9590 - val_loss: 0.8221 - val_accuracy: 0.7794\n","Epoch 29/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3619 - accuracy: 0.9567 - val_loss: 0.8399 - val_accuracy: 0.7647\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3525 - accuracy: 0.9646 - val_loss: 0.8555 - val_accuracy: 0.7726\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3521 - accuracy: 0.9652 - val_loss: 0.8492 - val_accuracy: 0.7805\n","Epoch 32/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3537 - accuracy: 0.9632 - val_loss: 0.8847 - val_accuracy: 0.7715\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3479 - accuracy: 0.9666 - val_loss: 0.8916 - val_accuracy: 0.7738\n","Epoch 34/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3510 - accuracy: 0.9649 - val_loss: 0.9457 - val_accuracy: 0.7489\n","Epoch 35/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3862 - accuracy: 0.9454 - val_loss: 0.8947 - val_accuracy: 0.7749\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3453 - accuracy: 0.9649 - val_loss: 0.9499 - val_accuracy: 0.7590\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3300 - accuracy: 0.9768 - val_loss: 0.9395 - val_accuracy: 0.7613\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3442 - accuracy: 0.9638 - val_loss: 0.9782 - val_accuracy: 0.7455\n","Epoch 39/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3354 - accuracy: 0.9694 - val_loss: 0.9320 - val_accuracy: 0.7636\n","Epoch 40/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3370 - accuracy: 0.9686 - val_loss: 0.9236 - val_accuracy: 0.7681\n","Epoch 41/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3312 - accuracy: 0.9731 - val_loss: 0.9500 - val_accuracy: 0.7658\n","Epoch 42/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3320 - accuracy: 0.9726 - val_loss: 0.9987 - val_accuracy: 0.7523\n","Epoch 43/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3412 - accuracy: 0.9641 - val_loss: 0.9788 - val_accuracy: 0.7590\n","Epoch 44/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3411 - accuracy: 0.9646 - val_loss: 1.0104 - val_accuracy: 0.7455\n","Epoch 45/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3360 - accuracy: 0.9658 - val_loss: 1.0342 - val_accuracy: 0.7398\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3291 - accuracy: 0.9694 - val_loss: 0.9782 - val_accuracy: 0.7636\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3351 - accuracy: 0.9680 - val_loss: 1.0983 - val_accuracy: 0.7342\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3578 - accuracy: 0.9559 - val_loss: 1.1228 - val_accuracy: 0.7308\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3170 - accuracy: 0.9791 - val_loss: 0.9527 - val_accuracy: 0.7715\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3240 - accuracy: 0.9737 - val_loss: 1.0215 - val_accuracy: 0.7500\n","Epoch 51/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3345 - accuracy: 0.9675 - val_loss: 0.9625 - val_accuracy: 0.7681\n","Epoch 52/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3289 - accuracy: 0.9660 - val_loss: 1.1963 - val_accuracy: 0.7229\n","Epoch 53/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3219 - accuracy: 0.9743 - val_loss: 0.9625 - val_accuracy: 0.7692\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3151 - accuracy: 0.9757 - val_loss: 1.0104 - val_accuracy: 0.7636\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3136 - accuracy: 0.9768 - val_loss: 0.9872 - val_accuracy: 0.7647\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3130 - accuracy: 0.9779 - val_loss: 0.9933 - val_accuracy: 0.7624\n","Epoch 57/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3238 - accuracy: 0.9697 - val_loss: 1.0414 - val_accuracy: 0.7511\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3070 - accuracy: 0.9799 - val_loss: 0.9760 - val_accuracy: 0.7624\n","Epoch 59/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3091 - accuracy: 0.9788 - val_loss: 0.9814 - val_accuracy: 0.7726\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3069 - accuracy: 0.9793 - val_loss: 1.0058 - val_accuracy: 0.7636\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3085 - accuracy: 0.9796 - val_loss: 1.1380 - val_accuracy: 0.7364\n","Epoch 62/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3034 - accuracy: 0.9825 - val_loss: 1.0768 - val_accuracy: 0.7455\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3085 - accuracy: 0.9805 - val_loss: 1.0377 - val_accuracy: 0.7602\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3014 - accuracy: 0.9813 - val_loss: 1.0998 - val_accuracy: 0.7466\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2913 - accuracy: 0.9861 - val_loss: 1.0421 - val_accuracy: 0.7670\n","Epoch 66/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3106 - accuracy: 0.9759 - val_loss: 1.0372 - val_accuracy: 0.7613\n","Epoch 67/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3130 - accuracy: 0.9743 - val_loss: 1.0925 - val_accuracy: 0.7500\n","Epoch 68/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2967 - accuracy: 0.9856 - val_loss: 1.0332 - val_accuracy: 0.7670\n","Epoch 69/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2972 - accuracy: 0.9819 - val_loss: 1.0391 - val_accuracy: 0.7658\n","Epoch 70/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2903 - accuracy: 0.9887 - val_loss: 1.0495 - val_accuracy: 0.7636\n","Epoch 71/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2959 - accuracy: 0.9827 - val_loss: 1.0239 - val_accuracy: 0.7760\n","Epoch 72/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3067 - accuracy: 0.9745 - val_loss: 1.0784 - val_accuracy: 0.7613\n","Epoch 73/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2967 - accuracy: 0.9816 - val_loss: 1.0851 - val_accuracy: 0.7523\n","Epoch 74/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2947 - accuracy: 0.9847 - val_loss: 1.0670 - val_accuracy: 0.7602\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2843 - accuracy: 0.9890 - val_loss: 1.0892 - val_accuracy: 0.7523\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2924 - accuracy: 0.9844 - val_loss: 1.0570 - val_accuracy: 0.7636\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3039 - accuracy: 0.9771 - val_loss: 1.0798 - val_accuracy: 0.7523\n","Epoch 78/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3050 - accuracy: 0.9779 - val_loss: 1.0784 - val_accuracy: 0.7568\n","Epoch 79/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2949 - accuracy: 0.9822 - val_loss: 1.0586 - val_accuracy: 0.7658\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2929 - accuracy: 0.9796 - val_loss: 1.0625 - val_accuracy: 0.7590\n","Epoch 81/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2865 - accuracy: 0.9875 - val_loss: 1.0613 - val_accuracy: 0.7704\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2920 - accuracy: 0.9836 - val_loss: 1.0776 - val_accuracy: 0.7590\n","Epoch 83/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2838 - accuracy: 0.9887 - val_loss: 1.1065 - val_accuracy: 0.7557\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2760 - accuracy: 0.9898 - val_loss: 1.2291 - val_accuracy: 0.7308\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3027 - accuracy: 0.9776 - val_loss: 1.1052 - val_accuracy: 0.7557\n","Epoch 86/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2841 - accuracy: 0.9856 - val_loss: 1.1003 - val_accuracy: 0.7602\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3034 - accuracy: 0.9768 - val_loss: 1.0953 - val_accuracy: 0.7715\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2838 - accuracy: 0.9870 - val_loss: 1.0934 - val_accuracy: 0.7557\n","Epoch 89/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2732 - accuracy: 0.9892 - val_loss: 1.1372 - val_accuracy: 0.7670\n","Epoch 90/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2925 - accuracy: 0.9813 - val_loss: 1.1239 - val_accuracy: 0.7545\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2882 - accuracy: 0.9830 - val_loss: 1.1219 - val_accuracy: 0.7579\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2895 - accuracy: 0.9785 - val_loss: 1.1603 - val_accuracy: 0.7410\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2831 - accuracy: 0.9833 - val_loss: 1.0917 - val_accuracy: 0.7760\n","Epoch 94/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3060 - accuracy: 0.9731 - val_loss: 1.2005 - val_accuracy: 0.7353\n","Epoch 95/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2975 - accuracy: 0.9796 - val_loss: 1.1393 - val_accuracy: 0.7466\n","Epoch 96/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2855 - accuracy: 0.9833 - val_loss: 1.1231 - val_accuracy: 0.7647\n","Epoch 97/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2715 - accuracy: 0.9870 - val_loss: 1.1025 - val_accuracy: 0.7726\n","Epoch 98/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2753 - accuracy: 0.9873 - val_loss: 1.1898 - val_accuracy: 0.7466\n","Epoch 99/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2859 - accuracy: 0.9833 - val_loss: 1.1783 - val_accuracy: 0.7421\n","Epoch 100/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2682 - accuracy: 0.9901 - val_loss: 1.1020 - val_accuracy: 0.7636\n","{'loss': [0.4903944730758667, 0.4639158844947815, 0.4385565519332886, 0.431977778673172, 0.4295732080936432, 0.4213162660598755, 0.4169233739376068, 0.4203339219093323, 0.4200136661529541, 0.4100847840309143, 0.41591471433639526, 0.392897367477417, 0.3954906165599823, 0.3991994857788086, 0.42322036623954773, 0.41451695561408997, 0.38642358779907227, 0.3898508846759796, 0.38525429368019104, 0.3914458751678467, 0.38182294368743896, 0.3750528395175934, 0.3680714964866638, 0.36845844984054565, 0.36575672030448914, 0.3654305338859558, 0.35363417863845825, 0.35917386412620544, 0.36189064383506775, 0.3524699807167053, 0.35214316844940186, 0.3536606729030609, 0.34786438941955566, 0.3510347306728363, 0.38618242740631104, 0.34533828496932983, 0.3299875855445862, 0.34417247772216797, 0.33542871475219727, 0.33703216910362244, 0.3311555087566376, 0.33196544647216797, 0.34119778871536255, 0.3411025106906891, 0.3360482156276703, 0.32906782627105713, 0.3351379930973053, 0.35779452323913574, 0.31695467233657837, 0.3240494132041931, 0.334536075592041, 0.3289497494697571, 0.3218880295753479, 0.3150850534439087, 0.31361886858940125, 0.3129826486110687, 0.3237703740596771, 0.30703434348106384, 0.30911463499069214, 0.30692747235298157, 0.3084987998008728, 0.3033705949783325, 0.3085193336009979, 0.30137982964515686, 0.2912854254245758, 0.3105778992176056, 0.31299522519111633, 0.29670605063438416, 0.29719415307044983, 0.2903437316417694, 0.29589754343032837, 0.3066929578781128, 0.29671213030815125, 0.2946794033050537, 0.2843354344367981, 0.2924482822418213, 0.3039325773715973, 0.3049618601799011, 0.2948648929595947, 0.29289788007736206, 0.2865430414676666, 0.29201066493988037, 0.28380683064460754, 0.27601152658462524, 0.3026658296585083, 0.2841491103172302, 0.3033902049064636, 0.28375664353370667, 0.2732163369655609, 0.2924744784832001, 0.2881840467453003, 0.2894671857357025, 0.2831496000289917, 0.30597949028015137, 0.2974737584590912, 0.28548678755760193, 0.27154991030693054, 0.2752821743488312, 0.2858666479587555, 0.268175333738327], 'accuracy': [0.8984153866767883, 0.9153932929039001, 0.9261460304260254, 0.9315223693847656, 0.9301075339317322, 0.937747597694397, 0.9335030913352966, 0.9323712587356567, 0.9349179267883301, 0.9383135437965393, 0.9357668161392212, 0.9459536075592041, 0.9485002756118774, 0.9417091012001038, 0.9292586445808411, 0.9323712587356567, 0.9538766145706177, 0.9493491649627686, 0.9490662217140198, 0.9485002756118774, 0.9496321678161621, 0.9533106684684753, 0.9615166783332825, 0.9569892287254333, 0.9564233422279358, 0.958121120929718, 0.9609507918357849, 0.9589700102806091, 0.9567062854766846, 0.9646292924880981, 0.9651952385902405, 0.9632145166397095, 0.9666100740432739, 0.9649122953414917, 0.9453876614570618, 0.9649122953414917, 0.9767968058586121, 0.963780403137207, 0.9694397449493408, 0.9685908555984497, 0.9731183052062988, 0.9725523591041565, 0.9640634059906006, 0.9646292924880981, 0.9657611846923828, 0.9694397449493408, 0.9680249094963074, 0.9558573961257935, 0.9790605306625366, 0.9736841917037964, 0.967458963394165, 0.9660441279411316, 0.9742501378059387, 0.9756649732589722, 0.9767968058586121, 0.9779286980628967, 0.9697226881980896, 0.9799094796180725, 0.9787775874137878, 0.9793435335159302, 0.979626476764679, 0.9824561476707458, 0.9804753661155701, 0.9813242554664612, 0.9861347079277039, 0.975947916507721, 0.9742501378059387, 0.9855687618255615, 0.9818902015686035, 0.9886813759803772, 0.9827390909194946, 0.9745330810546875, 0.9816072583198547, 0.9847198724746704, 0.988964319229126, 0.9844368696212769, 0.9770798087120056, 0.9779286980628967, 0.9821732044219971, 0.979626476764679, 0.9875495433807373, 0.9835879802703857, 0.9886813759803772, 0.9898132681846619, 0.977645754814148, 0.9855687618255615, 0.9767968058586121, 0.986983597278595, 0.9892473220825195, 0.9813242554664612, 0.9830220937728882, 0.9784946441650391, 0.983305037021637, 0.9731183052062988, 0.979626476764679, 0.983305037021637, 0.986983597278595, 0.9872665405273438, 0.983305037021637, 0.9900962114334106], 'val_loss': [0.9521982669830322, 0.9538173079490662, 0.9496588110923767, 0.9439382553100586, 0.9370012283325195, 0.9322307705879211, 0.9242001175880432, 0.913452684879303, 0.9140385985374451, 0.8714072108268738, 0.8659625053405762, 0.8468432426452637, 0.8771690726280212, 0.8348214030265808, 0.7758778929710388, 0.7765249013900757, 0.7777034640312195, 0.7681607007980347, 0.7283487319946289, 0.7468191385269165, 0.767394483089447, 0.7334200739860535, 0.7845741510391235, 0.759590744972229, 0.7647151350975037, 0.790256679058075, 0.7998366951942444, 0.8221099972724915, 0.8398703336715698, 0.8555024862289429, 0.8491852283477783, 0.8846503496170044, 0.8915572166442871, 0.9456564784049988, 0.8947405815124512, 0.9499328136444092, 0.9395061731338501, 0.9781891703605652, 0.9319973587989807, 0.9235547780990601, 0.9499748945236206, 0.9987034797668457, 0.9788460731506348, 1.0103908777236938, 1.0342140197753906, 0.9782143235206604, 1.0982859134674072, 1.1227632761001587, 0.9527335166931152, 1.0215259790420532, 0.9625104069709778, 1.196336030960083, 0.9625406861305237, 1.0103988647460938, 0.9872264862060547, 0.993257462978363, 1.0414292812347412, 0.9759646654129028, 0.9813956618309021, 1.0058265924453735, 1.1379841566085815, 1.0768260955810547, 1.037739634513855, 1.0997889041900635, 1.0420966148376465, 1.037168264389038, 1.092526912689209, 1.0331560373306274, 1.0391085147857666, 1.049499273300171, 1.0238910913467407, 1.0783518552780151, 1.0850967168807983, 1.067044734954834, 1.0892049074172974, 1.0569710731506348, 1.0797744989395142, 1.0783864259719849, 1.0586496591567993, 1.0624552965164185, 1.0612679719924927, 1.0776056051254272, 1.1065434217453003, 1.2291204929351807, 1.1052124500274658, 1.1002702713012695, 1.0953313112258911, 1.0934113264083862, 1.137211561203003, 1.1239359378814697, 1.1219249963760376, 1.1602922677993774, 1.0916860103607178, 1.2005438804626465, 1.1393147706985474, 1.1230580806732178, 1.1025495529174805, 1.1898194551467896, 1.1783487796783447, 1.101983904838562], 'val_accuracy': [0.5067873597145081, 0.5067873597145081, 0.5101810097694397, 0.5124434232711792, 0.516968309879303, 0.5271493196487427, 0.5497737526893616, 0.5723981857299805, 0.5622171759605408, 0.6549773812294006, 0.6470588445663452, 0.685520350933075, 0.6131221652030945, 0.6866515874862671, 0.7760180830955505, 0.7533936500549316, 0.7443438768386841, 0.7488687634468079, 0.7850678563117981, 0.7579185366630554, 0.7488687634468079, 0.7714931964874268, 0.7511312365531921, 0.7714931964874268, 0.7726244330406189, 0.7748869061470032, 0.7850678563117981, 0.779411792755127, 0.7647058963775635, 0.7726244330406189, 0.7805429697036743, 0.7714931964874268, 0.773755669593811, 0.7488687634468079, 0.7748869061470032, 0.7590497732162476, 0.7613122463226318, 0.7454751133918762, 0.7635746598243713, 0.7680995464324951, 0.7658371329307556, 0.7522624731063843, 0.7590497732162476, 0.7454751133918762, 0.7398189902305603, 0.7635746598243713, 0.7341628670692444, 0.7307692170143127, 0.7714931964874268, 0.75, 0.7680995464324951, 0.7228506803512573, 0.7692307829856873, 0.7635746598243713, 0.7647058963775635, 0.7624434232711792, 0.7511312365531921, 0.7624434232711792, 0.7726244330406189, 0.7635746598243713, 0.7364253401756287, 0.7454751133918762, 0.7601810097694397, 0.7466063499450684, 0.766968309879303, 0.7613122463226318, 0.75, 0.766968309879303, 0.7658371329307556, 0.7635746598243713, 0.7760180830955505, 0.7613122463226318, 0.7522624731063843, 0.7601810097694397, 0.7522624731063843, 0.7635746598243713, 0.7522624731063843, 0.7567873597145081, 0.7658371329307556, 0.7590497732162476, 0.7703620195388794, 0.7590497732162476, 0.7556561231613159, 0.7307692170143127, 0.7556561231613159, 0.7601810097694397, 0.7714931964874268, 0.7556561231613159, 0.766968309879303, 0.7545248866081238, 0.7579185366630554, 0.7409502267837524, 0.7760180830955505, 0.7352941036224365, 0.7466063499450684, 0.7647058963775635, 0.7726244330406189, 0.7466063499450684, 0.7420814633369446, 0.7635746598243713]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.5270 - accuracy: 0.8898"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 13s 219ms/step - loss: 0.5244 - accuracy: 0.8930 - val_loss: 0.9515 - val_accuracy: 0.5145\n","Epoch 2/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5234 - accuracy: 0.8915 - val_loss: 0.9406 - val_accuracy: 0.5258\n","Epoch 3/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4888 - accuracy: 0.9049 - val_loss: 0.9396 - val_accuracy: 0.5248\n","Epoch 4/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4810 - accuracy: 0.9070 - val_loss: 0.9328 - val_accuracy: 0.5341\n","Epoch 5/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4925 - accuracy: 0.8987 - val_loss: 0.9392 - val_accuracy: 0.5227\n","Epoch 6/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4705 - accuracy: 0.9103 - val_loss: 0.9202 - val_accuracy: 0.5589\n","Epoch 7/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4603 - accuracy: 0.9168 - val_loss: 0.9131 - val_accuracy: 0.5744\n","Epoch 8/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4463 - accuracy: 0.9264 - val_loss: 0.9113 - val_accuracy: 0.5682\n","Epoch 9/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4381 - accuracy: 0.9331 - val_loss: 0.8918 - val_accuracy: 0.6188\n","Epoch 10/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4389 - accuracy: 0.9305 - val_loss: 0.8798 - val_accuracy: 0.6302\n","Epoch 11/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.4248 - accuracy: 0.9320 - val_loss: 0.8733 - val_accuracy: 0.6353\n","Epoch 12/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.4372 - accuracy: 0.9300 - val_loss: 0.8482 - val_accuracy: 0.6921\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4348 - accuracy: 0.9266 - val_loss: 0.8646 - val_accuracy: 0.6467\n","Epoch 14/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.4236 - accuracy: 0.9305 - val_loss: 0.8182 - val_accuracy: 0.7283\n","Epoch 15/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4271 - accuracy: 0.9323 - val_loss: 0.8374 - val_accuracy: 0.6829\n","Epoch 16/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4182 - accuracy: 0.9349 - val_loss: 0.8161 - val_accuracy: 0.7231\n","Epoch 17/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4299 - accuracy: 0.9289 - val_loss: 0.9084 - val_accuracy: 0.6415\n","Epoch 18/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4431 - accuracy: 0.9178 - val_loss: 0.9794 - val_accuracy: 0.6167\n","Epoch 19/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4400 - accuracy: 0.9233 - val_loss: 0.7980 - val_accuracy: 0.7593\n","Epoch 20/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4081 - accuracy: 0.9388 - val_loss: 0.8055 - val_accuracy: 0.7645\n","Epoch 21/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4478 - accuracy: 0.9158 - val_loss: 0.8220 - val_accuracy: 0.7665\n","Epoch 22/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4113 - accuracy: 0.9403 - val_loss: 0.8521 - val_accuracy: 0.7521\n","Epoch 23/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4135 - accuracy: 0.9346 - val_loss: 0.8522 - val_accuracy: 0.7583\n","Epoch 24/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4156 - accuracy: 0.9362 - val_loss: 0.8794 - val_accuracy: 0.7614\n","Epoch 25/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4004 - accuracy: 0.9442 - val_loss: 0.8944 - val_accuracy: 0.7707\n","Epoch 26/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3975 - accuracy: 0.9473 - val_loss: 0.9230 - val_accuracy: 0.7583\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4124 - accuracy: 0.9364 - val_loss: 0.9280 - val_accuracy: 0.7634\n","Epoch 28/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3904 - accuracy: 0.9483 - val_loss: 0.9464 - val_accuracy: 0.7583\n","Epoch 29/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4001 - accuracy: 0.9408 - val_loss: 0.9716 - val_accuracy: 0.7469\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3889 - accuracy: 0.9483 - val_loss: 0.9981 - val_accuracy: 0.7459\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4595 - accuracy: 0.9127 - val_loss: 1.1115 - val_accuracy: 0.7107\n","Epoch 32/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4167 - accuracy: 0.9279 - val_loss: 0.9702 - val_accuracy: 0.7614\n","Epoch 33/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3854 - accuracy: 0.9486 - val_loss: 0.9847 - val_accuracy: 0.7634\n","Epoch 34/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3760 - accuracy: 0.9517 - val_loss: 0.9863 - val_accuracy: 0.7572\n","Epoch 35/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3741 - accuracy: 0.9545 - val_loss: 0.9940 - val_accuracy: 0.7531\n","Epoch 36/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3751 - accuracy: 0.9568 - val_loss: 1.0389 - val_accuracy: 0.7552\n","Epoch 37/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3624 - accuracy: 0.9599 - val_loss: 1.0010 - val_accuracy: 0.7614\n","Epoch 38/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3789 - accuracy: 0.9522 - val_loss: 1.0716 - val_accuracy: 0.7366\n","Epoch 39/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3918 - accuracy: 0.9411 - val_loss: 1.0762 - val_accuracy: 0.7335\n","Epoch 40/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3869 - accuracy: 0.9450 - val_loss: 1.0270 - val_accuracy: 0.7603\n","Epoch 41/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3758 - accuracy: 0.9527 - val_loss: 1.0666 - val_accuracy: 0.7376\n","Epoch 42/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3652 - accuracy: 0.9553 - val_loss: 1.0269 - val_accuracy: 0.7562\n","Epoch 43/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3714 - accuracy: 0.9535 - val_loss: 1.0208 - val_accuracy: 0.7562\n","Epoch 44/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3628 - accuracy: 0.9584 - val_loss: 1.0384 - val_accuracy: 0.7510\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3503 - accuracy: 0.9656 - val_loss: 1.0532 - val_accuracy: 0.7438\n","Epoch 46/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3674 - accuracy: 0.9548 - val_loss: 1.1211 - val_accuracy: 0.7335\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3770 - accuracy: 0.9504 - val_loss: 1.0455 - val_accuracy: 0.7531\n","Epoch 48/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3432 - accuracy: 0.9685 - val_loss: 1.0660 - val_accuracy: 0.7459\n","Epoch 49/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3604 - accuracy: 0.9553 - val_loss: 1.0531 - val_accuracy: 0.7490\n","Epoch 50/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3548 - accuracy: 0.9599 - val_loss: 1.1703 - val_accuracy: 0.7293\n","Epoch 51/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3510 - accuracy: 0.9641 - val_loss: 1.1067 - val_accuracy: 0.7417\n","Epoch 52/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3494 - accuracy: 0.9654 - val_loss: 1.0660 - val_accuracy: 0.7521\n","Epoch 53/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3401 - accuracy: 0.9693 - val_loss: 1.0840 - val_accuracy: 0.7490\n","Epoch 54/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3626 - accuracy: 0.9548 - val_loss: 1.0629 - val_accuracy: 0.7552\n","Epoch 55/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3346 - accuracy: 0.9724 - val_loss: 1.0954 - val_accuracy: 0.7376\n","Epoch 56/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3535 - accuracy: 0.9592 - val_loss: 1.0775 - val_accuracy: 0.7510\n","Epoch 57/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3597 - accuracy: 0.9548 - val_loss: 1.1303 - val_accuracy: 0.7345\n","Epoch 58/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3508 - accuracy: 0.9625 - val_loss: 1.0970 - val_accuracy: 0.7428\n","Epoch 59/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3394 - accuracy: 0.9698 - val_loss: 1.1107 - val_accuracy: 0.7479\n","Epoch 60/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3306 - accuracy: 0.9718 - val_loss: 1.0974 - val_accuracy: 0.7479\n","Epoch 61/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3373 - accuracy: 0.9659 - val_loss: 1.1325 - val_accuracy: 0.7417\n","Epoch 62/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3368 - accuracy: 0.9661 - val_loss: 1.2221 - val_accuracy: 0.7231\n","Epoch 63/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3374 - accuracy: 0.9661 - val_loss: 1.1164 - val_accuracy: 0.7417\n","Epoch 64/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3270 - accuracy: 0.9718 - val_loss: 1.1169 - val_accuracy: 0.7417\n","Epoch 65/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3337 - accuracy: 0.9718 - val_loss: 1.1123 - val_accuracy: 0.7459\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3238 - accuracy: 0.9747 - val_loss: 1.1367 - val_accuracy: 0.7376\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3243 - accuracy: 0.9747 - val_loss: 1.1596 - val_accuracy: 0.7407\n","Epoch 68/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3244 - accuracy: 0.9726 - val_loss: 1.1723 - val_accuracy: 0.7397\n","Epoch 69/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3303 - accuracy: 0.9708 - val_loss: 1.1945 - val_accuracy: 0.7324\n","Epoch 70/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3178 - accuracy: 0.9786 - val_loss: 1.1421 - val_accuracy: 0.7448\n","Epoch 71/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3211 - accuracy: 0.9749 - val_loss: 1.1734 - val_accuracy: 0.7355\n","Epoch 72/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3286 - accuracy: 0.9693 - val_loss: 1.1827 - val_accuracy: 0.7386\n","Epoch 73/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3194 - accuracy: 0.9739 - val_loss: 1.1501 - val_accuracy: 0.7386\n","Epoch 74/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3119 - accuracy: 0.9765 - val_loss: 1.1563 - val_accuracy: 0.7438\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3105 - accuracy: 0.9804 - val_loss: 1.2559 - val_accuracy: 0.7293\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3072 - accuracy: 0.9783 - val_loss: 1.2344 - val_accuracy: 0.7397\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3218 - accuracy: 0.9708 - val_loss: 1.1597 - val_accuracy: 0.7448\n","Epoch 78/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3211 - accuracy: 0.9693 - val_loss: 1.2454 - val_accuracy: 0.7283\n","Epoch 79/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3428 - accuracy: 0.9620 - val_loss: 1.2057 - val_accuracy: 0.7304\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3128 - accuracy: 0.9729 - val_loss: 1.1635 - val_accuracy: 0.7407\n","Epoch 81/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3132 - accuracy: 0.9770 - val_loss: 1.1682 - val_accuracy: 0.7417\n","Epoch 82/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3048 - accuracy: 0.9809 - val_loss: 1.1940 - val_accuracy: 0.7355\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3068 - accuracy: 0.9773 - val_loss: 1.2891 - val_accuracy: 0.7221\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3039 - accuracy: 0.9798 - val_loss: 1.2016 - val_accuracy: 0.7479\n","Epoch 85/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3067 - accuracy: 0.9780 - val_loss: 1.2468 - val_accuracy: 0.7262\n","Epoch 86/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3060 - accuracy: 0.9752 - val_loss: 1.2438 - val_accuracy: 0.7386\n","Epoch 87/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3049 - accuracy: 0.9773 - val_loss: 1.2133 - val_accuracy: 0.7376\n","Epoch 88/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3009 - accuracy: 0.9798 - val_loss: 1.2267 - val_accuracy: 0.7376\n","Epoch 89/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3293 - accuracy: 0.9594 - val_loss: 1.5403 - val_accuracy: 0.6849\n","Epoch 90/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3535 - accuracy: 0.9537 - val_loss: 1.3763 - val_accuracy: 0.7066\n","Epoch 91/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3295 - accuracy: 0.9661 - val_loss: 1.2218 - val_accuracy: 0.7335\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3088 - accuracy: 0.9739 - val_loss: 1.3559 - val_accuracy: 0.7076\n","Epoch 93/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3075 - accuracy: 0.9778 - val_loss: 1.3132 - val_accuracy: 0.7221\n","Epoch 94/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3037 - accuracy: 0.9773 - val_loss: 1.2318 - val_accuracy: 0.7366\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2919 - accuracy: 0.9817 - val_loss: 1.2201 - val_accuracy: 0.7407\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3046 - accuracy: 0.9760 - val_loss: 1.2252 - val_accuracy: 0.7366\n","Epoch 97/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2897 - accuracy: 0.9832 - val_loss: 1.2363 - val_accuracy: 0.7386\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3208 - accuracy: 0.9718 - val_loss: 1.2538 - val_accuracy: 0.7397\n","Epoch 99/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2894 - accuracy: 0.9837 - val_loss: 1.2883 - val_accuracy: 0.7273\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2894 - accuracy: 0.9814 - val_loss: 1.2480 - val_accuracy: 0.7386\n","{'loss': [0.5244473814964294, 0.5233944058418274, 0.4888482391834259, 0.4809630215167999, 0.4925009310245514, 0.4704814553260803, 0.46033963561058044, 0.4462527930736542, 0.43808749318122864, 0.4389320909976959, 0.4248453676700592, 0.43718084692955017, 0.4348326623439789, 0.42360740900039673, 0.42705756425857544, 0.418170690536499, 0.42991992831230164, 0.4430575370788574, 0.43997541069984436, 0.4080953896045685, 0.44781702756881714, 0.41130462288856506, 0.41354289650917053, 0.41559937596321106, 0.40039342641830444, 0.39752843976020813, 0.4123915731906891, 0.3904110789299011, 0.4001058340072632, 0.38894835114479065, 0.4594708979129791, 0.41673704981803894, 0.38543233275413513, 0.37604227662086487, 0.3740619122982025, 0.37505200505256653, 0.3624091148376465, 0.3789454400539398, 0.39178791642189026, 0.38690274953842163, 0.37575748562812805, 0.3652106821537018, 0.37137553095817566, 0.36284109950065613, 0.35026851296424866, 0.3674139976501465, 0.3770465552806854, 0.3432299792766571, 0.3604114055633545, 0.35481318831443787, 0.35097935795783997, 0.3494458496570587, 0.34005746245384216, 0.3626343905925751, 0.3346136510372162, 0.353481650352478, 0.3597477972507477, 0.35077396035194397, 0.3393944799900055, 0.33056914806365967, 0.33728909492492676, 0.33683648705482483, 0.33739984035491943, 0.3269534409046173, 0.33365190029144287, 0.32379329204559326, 0.32433250546455383, 0.3244279623031616, 0.3302907645702362, 0.31783774495124817, 0.32109516859054565, 0.32856106758117676, 0.3193647265434265, 0.3118501603603363, 0.31045812368392944, 0.30723026394844055, 0.32182377576828003, 0.3211224675178528, 0.34278225898742676, 0.3128233253955841, 0.3131905794143677, 0.3048137128353119, 0.30677857995033264, 0.3039252758026123, 0.30665987730026245, 0.3060205280780792, 0.30488041043281555, 0.3009187877178192, 0.3292900621891022, 0.3534640669822693, 0.32947465777397156, 0.308768093585968, 0.30752816796302795, 0.30369138717651367, 0.2918742001056671, 0.3046199679374695, 0.28972792625427246, 0.32082846760749817, 0.28943514823913574, 0.28937214612960815], 'accuracy': [0.8930232524871826, 0.8914728760719299, 0.9049095511436462, 0.9069767594337463, 0.8987079858779907, 0.910335898399353, 0.9167958498001099, 0.9263566136360168, 0.933074951171875, 0.9304909706115723, 0.932041347026825, 0.9299741387367249, 0.9266149997711182, 0.9304909706115723, 0.9322997331619263, 0.934883713722229, 0.9289405941963196, 0.9178294539451599, 0.9232558012008667, 0.9387596845626831, 0.9157622456550598, 0.9403100609779358, 0.9346253275871277, 0.9361757040023804, 0.9441860318183899, 0.94728684425354, 0.9364340901374817, 0.9483203887939453, 0.9408268928527832, 0.9483203887939453, 0.9126614928245544, 0.9279069900512695, 0.9485788345336914, 0.9516795873641968, 0.9545219540596008, 0.9568475484848022, 0.9599483013153076, 0.9521963596343994, 0.9410852789878845, 0.9449612498283386, 0.9527131915092468, 0.9552971720695496, 0.9534883499145508, 0.9583979249000549, 0.9656330943107605, 0.9547803401947021, 0.9503875970840454, 0.9684754610061646, 0.9552971720695496, 0.9599483013153076, 0.964082658290863, 0.9653746485710144, 0.9692506194114685, 0.9547803401947021, 0.9723514318466187, 0.9591731429100037, 0.9547803401947021, 0.9625322818756104, 0.9697674512863159, 0.9718345999717712, 0.9658914804458618, 0.9661498665809631, 0.9661498665809631, 0.9718345999717712, 0.9718345999717712, 0.9746770262718201, 0.9746770262718201, 0.97260981798172, 0.970801055431366, 0.9785529971122742, 0.9749354124069214, 0.9692506194114685, 0.9739018082618713, 0.9764857888221741, 0.9803617596626282, 0.9782945513725281, 0.970801055431366, 0.9692506194114685, 0.9620155096054077, 0.9728682041168213, 0.9770025610923767, 0.9808785319328308, 0.9772610068321228, 0.9798449873924255, 0.9780361652374268, 0.9751937985420227, 0.9772610068321228, 0.9798449873924255, 0.959431529045105, 0.9537467956542969, 0.9661498665809631, 0.9739018082618713, 0.9777777791023254, 0.9772610068321228, 0.9816537499427795, 0.9759690165519714, 0.9832041263580322, 0.9718345999717712, 0.9837209582328796, 0.9813953638076782], 'val_loss': [0.9515020251274109, 0.9405823945999146, 0.9396212100982666, 0.9327645897865295, 0.9392415881156921, 0.9202354550361633, 0.9131025671958923, 0.9112563729286194, 0.8917988538742065, 0.8797773122787476, 0.8733488917350769, 0.8482294082641602, 0.8645585179328918, 0.8181683421134949, 0.8374339938163757, 0.8160539865493774, 0.9084246158599854, 0.9793567061424255, 0.7979793548583984, 0.8054765462875366, 0.8219802975654602, 0.8520750403404236, 0.8521531224250793, 0.8793913125991821, 0.8943983316421509, 0.9229751229286194, 0.9279841184616089, 0.9464025497436523, 0.9716246128082275, 0.9981123208999634, 1.1114561557769775, 0.9701727032661438, 0.9846793413162231, 0.9862729907035828, 0.993960440158844, 1.038936972618103, 1.0009644031524658, 1.0716121196746826, 1.0762443542480469, 1.0270326137542725, 1.0666252374649048, 1.026923418045044, 1.0208121538162231, 1.038355827331543, 1.0532352924346924, 1.121122121810913, 1.045514702796936, 1.0660178661346436, 1.053114891052246, 1.1702708005905151, 1.1066595315933228, 1.0660477876663208, 1.0839967727661133, 1.0629299879074097, 1.0954303741455078, 1.0774846076965332, 1.1302515268325806, 1.0970451831817627, 1.110691785812378, 1.097446322441101, 1.132496953010559, 1.2221201658248901, 1.1164089441299438, 1.1168938875198364, 1.112268090248108, 1.1366801261901855, 1.159556269645691, 1.172256350517273, 1.1944643259048462, 1.1421400308609009, 1.17337167263031, 1.1826865673065186, 1.1501199007034302, 1.156346321105957, 1.2558653354644775, 1.2344143390655518, 1.1596583127975464, 1.245402216911316, 1.205721139907837, 1.1634917259216309, 1.1682465076446533, 1.1940457820892334, 1.289099931716919, 1.2015526294708252, 1.246799111366272, 1.2437963485717773, 1.2132551670074463, 1.2266628742218018, 1.5403467416763306, 1.3763374090194702, 1.2218478918075562, 1.355869174003601, 1.3131667375564575, 1.2318230867385864, 1.2200902700424194, 1.2251991033554077, 1.2363053560256958, 1.2538121938705444, 1.288347601890564, 1.2479655742645264], 'val_accuracy': [0.5144628286361694, 0.5258264541625977, 0.5247933864593506, 0.5340909361839294, 0.5227272510528564, 0.55888432264328, 0.5743801593780518, 0.5681818127632141, 0.6188016533851624, 0.6301652789115906, 0.6353305578231812, 0.692148745059967, 0.6466942429542542, 0.7283057570457458, 0.682851254940033, 0.7231404781341553, 0.6415289044380188, 0.6167355179786682, 0.7592975497245789, 0.7644628286361694, 0.7665289044380188, 0.7520661354064941, 0.7582644820213318, 0.7613636255264282, 0.7706611752510071, 0.7582644820213318, 0.7634297609329224, 0.7582644820213318, 0.7469007968902588, 0.7458677887916565, 0.71074378490448, 0.7613636255264282, 0.7634297609329224, 0.7572314143180847, 0.7530992031097412, 0.7551652789115906, 0.7613636255264282, 0.7365702390670776, 0.7334710955619812, 0.7603305578231812, 0.7376033067703247, 0.7561983466148376, 0.7561983466148376, 0.7510330677032471, 0.7438016533851624, 0.7334710955619812, 0.7530992031097412, 0.7458677887916565, 0.7489669322967529, 0.7293388247489929, 0.7417355179786682, 0.7520661354064941, 0.7489669322967529, 0.7551652789115906, 0.7376033067703247, 0.7510330677032471, 0.7345041036605835, 0.7427685856819153, 0.7479338645935059, 0.7479338645935059, 0.7417355179786682, 0.7231404781341553, 0.7417355179786682, 0.7417355179786682, 0.7458677887916565, 0.7376033067703247, 0.7407024502754211, 0.7396694421768188, 0.7324380278587341, 0.7448347210884094, 0.7355371713638306, 0.7386363744735718, 0.7386363744735718, 0.7438016533851624, 0.7293388247489929, 0.7396694421768188, 0.7448347210884094, 0.7283057570457458, 0.73037189245224, 0.7407024502754211, 0.7417355179786682, 0.7355371713638306, 0.7221074104309082, 0.7479338645935059, 0.7262396812438965, 0.7386363744735718, 0.7376033067703247, 0.7376033067703247, 0.6849173307418823, 0.7066115736961365, 0.7334710955619812, 0.7076446413993835, 0.7221074104309082, 0.7365702390670776, 0.7407024502754211, 0.7365702390670776, 0.7386363744735718, 0.7396694421768188, 0.7272727489471436, 0.7386363744735718]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.5031 - accuracy: 0.9057"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 13s 232ms/step - loss: 0.5031 - accuracy: 0.9057 - val_loss: 0.9361 - val_accuracy: 0.5172\n","Epoch 2/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.3680 - accuracy: 0.9534 - val_loss: 0.9305 - val_accuracy: 0.5216\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3441 - accuracy: 0.9612 - val_loss: 0.9311 - val_accuracy: 0.5205\n","Epoch 4/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.3384 - accuracy: 0.9609 - val_loss: 0.9278 - val_accuracy: 0.5259\n","Epoch 5/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.3398 - accuracy: 0.9604 - val_loss: 0.9101 - val_accuracy: 0.5485\n","Epoch 6/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.3325 - accuracy: 0.9626 - val_loss: 0.9048 - val_accuracy: 0.5528\n","Epoch 7/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.3242 - accuracy: 0.9661 - val_loss: 0.8991 - val_accuracy: 0.5603\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3350 - accuracy: 0.9634 - val_loss: 0.8966 - val_accuracy: 0.5603\n","Epoch 9/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3167 - accuracy: 0.9709 - val_loss: 0.8744 - val_accuracy: 0.5862\n","Epoch 10/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3145 - accuracy: 0.9704 - val_loss: 0.8708 - val_accuracy: 0.5927\n","Epoch 11/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3106 - accuracy: 0.9723 - val_loss: 0.8442 - val_accuracy: 0.6250\n","Epoch 12/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3126 - accuracy: 0.9720 - val_loss: 0.8233 - val_accuracy: 0.6455\n","Epoch 13/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3108 - accuracy: 0.9701 - val_loss: 0.7997 - val_accuracy: 0.6692\n","Epoch 14/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3021 - accuracy: 0.9758 - val_loss: 0.7755 - val_accuracy: 0.7037\n","Epoch 15/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3046 - accuracy: 0.9784 - val_loss: 0.7649 - val_accuracy: 0.7134\n","Epoch 16/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3060 - accuracy: 0.9776 - val_loss: 0.7225 - val_accuracy: 0.7478\n","Epoch 17/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.2975 - accuracy: 0.9774 - val_loss: 0.6881 - val_accuracy: 0.7802\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2983 - accuracy: 0.9760 - val_loss: 0.7489 - val_accuracy: 0.7306\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3049 - accuracy: 0.9739 - val_loss: 0.7341 - val_accuracy: 0.7500\n","Epoch 20/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2961 - accuracy: 0.9790 - val_loss: 0.6778 - val_accuracy: 0.7996\n","Epoch 21/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.2973 - accuracy: 0.9798 - val_loss: 0.6718 - val_accuracy: 0.8233\n","Epoch 22/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.3267 - accuracy: 0.9626 - val_loss: 0.6692 - val_accuracy: 0.8319\n","Epoch 23/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3210 - accuracy: 0.9674 - val_loss: 0.6926 - val_accuracy: 0.8157\n","Epoch 24/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2942 - accuracy: 0.9779 - val_loss: 0.7306 - val_accuracy: 0.7985\n","Epoch 25/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2892 - accuracy: 0.9795 - val_loss: 0.7029 - val_accuracy: 0.8222\n","Epoch 26/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2971 - accuracy: 0.9784 - val_loss: 0.7704 - val_accuracy: 0.7963\n","Epoch 27/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2941 - accuracy: 0.9776 - val_loss: 0.7359 - val_accuracy: 0.8200\n","Epoch 28/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2864 - accuracy: 0.9814 - val_loss: 0.7646 - val_accuracy: 0.8136\n","Epoch 29/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2977 - accuracy: 0.9771 - val_loss: 0.7746 - val_accuracy: 0.8168\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2830 - accuracy: 0.9825 - val_loss: 0.7839 - val_accuracy: 0.8190\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2847 - accuracy: 0.9811 - val_loss: 0.7828 - val_accuracy: 0.8147\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2823 - accuracy: 0.9820 - val_loss: 0.7989 - val_accuracy: 0.8168\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2787 - accuracy: 0.9841 - val_loss: 0.7988 - val_accuracy: 0.8244\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2794 - accuracy: 0.9830 - val_loss: 0.7978 - val_accuracy: 0.8200\n","Epoch 35/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2792 - accuracy: 0.9855 - val_loss: 0.8406 - val_accuracy: 0.8093\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2781 - accuracy: 0.9844 - val_loss: 0.8149 - val_accuracy: 0.8222\n","Epoch 37/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2804 - accuracy: 0.9814 - val_loss: 0.9534 - val_accuracy: 0.7812\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2756 - accuracy: 0.9846 - val_loss: 0.9633 - val_accuracy: 0.7996\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2853 - accuracy: 0.9809 - val_loss: 0.9050 - val_accuracy: 0.8006\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2783 - accuracy: 0.9830 - val_loss: 0.8508 - val_accuracy: 0.8147\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2872 - accuracy: 0.9820 - val_loss: 0.8630 - val_accuracy: 0.8147\n","Epoch 42/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2819 - accuracy: 0.9798 - val_loss: 0.8561 - val_accuracy: 0.8136\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2757 - accuracy: 0.9857 - val_loss: 0.9583 - val_accuracy: 0.7974\n","Epoch 44/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2726 - accuracy: 0.9855 - val_loss: 0.9382 - val_accuracy: 0.8039\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2856 - accuracy: 0.9776 - val_loss: 1.0169 - val_accuracy: 0.7909\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2776 - accuracy: 0.9846 - val_loss: 0.8808 - val_accuracy: 0.8050\n","Epoch 47/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2682 - accuracy: 0.9873 - val_loss: 0.8652 - val_accuracy: 0.8082\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2694 - accuracy: 0.9868 - val_loss: 0.8533 - val_accuracy: 0.8157\n","Epoch 49/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2648 - accuracy: 0.9876 - val_loss: 0.8728 - val_accuracy: 0.8136\n","Epoch 50/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2711 - accuracy: 0.9873 - val_loss: 0.9014 - val_accuracy: 0.8082\n","Epoch 51/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2633 - accuracy: 0.9895 - val_loss: 0.8663 - val_accuracy: 0.8017\n","Epoch 52/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2673 - accuracy: 0.9879 - val_loss: 0.9252 - val_accuracy: 0.7877\n","Epoch 53/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2695 - accuracy: 0.9836 - val_loss: 0.9074 - val_accuracy: 0.7942\n","Epoch 54/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2691 - accuracy: 0.9849 - val_loss: 0.8721 - val_accuracy: 0.8179\n","Epoch 55/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2651 - accuracy: 0.9879 - val_loss: 0.8738 - val_accuracy: 0.8093\n","Epoch 56/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2596 - accuracy: 0.9900 - val_loss: 0.8814 - val_accuracy: 0.8136\n","Epoch 57/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2597 - accuracy: 0.9890 - val_loss: 0.8905 - val_accuracy: 0.8103\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2640 - accuracy: 0.9881 - val_loss: 1.0992 - val_accuracy: 0.7597\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2729 - accuracy: 0.9833 - val_loss: 0.8928 - val_accuracy: 0.8028\n","Epoch 60/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2677 - accuracy: 0.9849 - val_loss: 0.9070 - val_accuracy: 0.8082\n","Epoch 61/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2606 - accuracy: 0.9898 - val_loss: 0.8937 - val_accuracy: 0.8125\n","Epoch 62/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2587 - accuracy: 0.9895 - val_loss: 0.9377 - val_accuracy: 0.7953\n","Epoch 63/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2569 - accuracy: 0.9916 - val_loss: 0.9697 - val_accuracy: 0.7974\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2565 - accuracy: 0.9908 - val_loss: 0.9317 - val_accuracy: 0.7996\n","Epoch 65/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2569 - accuracy: 0.9890 - val_loss: 0.9075 - val_accuracy: 0.8125\n","Epoch 66/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2552 - accuracy: 0.9900 - val_loss: 0.9155 - val_accuracy: 0.8028\n","Epoch 67/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2673 - accuracy: 0.9833 - val_loss: 0.9122 - val_accuracy: 0.8071\n","Epoch 68/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2573 - accuracy: 0.9881 - val_loss: 0.9927 - val_accuracy: 0.8006\n","Epoch 69/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2591 - accuracy: 0.9895 - val_loss: 1.0657 - val_accuracy: 0.7942\n","Epoch 70/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2724 - accuracy: 0.9817 - val_loss: 1.0052 - val_accuracy: 0.7748\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2795 - accuracy: 0.9766 - val_loss: 1.0902 - val_accuracy: 0.7629\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2874 - accuracy: 0.9717 - val_loss: 0.9130 - val_accuracy: 0.8017\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2489 - accuracy: 0.9949 - val_loss: 0.9425 - val_accuracy: 0.8071\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2510 - accuracy: 0.9919 - val_loss: 0.9720 - val_accuracy: 0.7909\n","Epoch 75/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2509 - accuracy: 0.9925 - val_loss: 0.9182 - val_accuracy: 0.8028\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2608 - accuracy: 0.9844 - val_loss: 0.9314 - val_accuracy: 0.8039\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2509 - accuracy: 0.9916 - val_loss: 0.9131 - val_accuracy: 0.8093\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2493 - accuracy: 0.9927 - val_loss: 0.9378 - val_accuracy: 0.7963\n","Epoch 79/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2446 - accuracy: 0.9938 - val_loss: 0.9331 - val_accuracy: 0.8082\n","Epoch 80/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2512 - accuracy: 0.9906 - val_loss: 0.9472 - val_accuracy: 0.7909\n","Epoch 81/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2475 - accuracy: 0.9919 - val_loss: 0.9160 - val_accuracy: 0.8039\n","Epoch 82/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2404 - accuracy: 0.9960 - val_loss: 0.9286 - val_accuracy: 0.8039\n","Epoch 83/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2458 - accuracy: 0.9911 - val_loss: 0.9815 - val_accuracy: 0.7899\n","Epoch 84/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2379 - accuracy: 0.9960 - val_loss: 0.9379 - val_accuracy: 0.8082\n","Epoch 85/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2480 - accuracy: 0.9914 - val_loss: 0.9382 - val_accuracy: 0.8017\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2420 - accuracy: 0.9949 - val_loss: 0.9349 - val_accuracy: 0.8071\n","Epoch 87/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2468 - accuracy: 0.9914 - val_loss: 1.0460 - val_accuracy: 0.7909\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2426 - accuracy: 0.9935 - val_loss: 1.1525 - val_accuracy: 0.7780\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2546 - accuracy: 0.9855 - val_loss: 1.3387 - val_accuracy: 0.7489\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2860 - accuracy: 0.9758 - val_loss: 0.9601 - val_accuracy: 0.8039\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2446 - accuracy: 0.9927 - val_loss: 0.9293 - val_accuracy: 0.7985\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2416 - accuracy: 0.9941 - val_loss: 1.0270 - val_accuracy: 0.7877\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2375 - accuracy: 0.9952 - val_loss: 0.9334 - val_accuracy: 0.8103\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2484 - accuracy: 0.9900 - val_loss: 0.9477 - val_accuracy: 0.8071\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2556 - accuracy: 0.9857 - val_loss: 0.9449 - val_accuracy: 0.7974\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2382 - accuracy: 0.9943 - val_loss: 0.9853 - val_accuracy: 0.7931\n","Epoch 97/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2519 - accuracy: 0.9863 - val_loss: 0.9559 - val_accuracy: 0.8060\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2367 - accuracy: 0.9943 - val_loss: 0.9535 - val_accuracy: 0.8060\n","Epoch 99/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2342 - accuracy: 0.9962 - val_loss: 0.9982 - val_accuracy: 0.7985\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2416 - accuracy: 0.9914 - val_loss: 1.0134 - val_accuracy: 0.7866\n","{'loss': [0.5031070709228516, 0.36804065108299255, 0.3440629243850708, 0.3384398818016052, 0.3398183286190033, 0.33249756693840027, 0.3241698443889618, 0.3350219130516052, 0.3167038559913635, 0.3144923150539398, 0.3105715811252594, 0.31256648898124695, 0.31081172823905945, 0.3021157681941986, 0.3045674264431, 0.306039422750473, 0.2975068986415863, 0.2983449697494507, 0.3049452006816864, 0.2961162328720093, 0.2972501814365387, 0.3266684114933014, 0.32102328538894653, 0.2941725254058838, 0.28917282819747925, 0.29709839820861816, 0.2940880358219147, 0.28641241788864136, 0.2977278232574463, 0.2830040454864502, 0.28471237421035767, 0.2822663486003876, 0.2786934971809387, 0.2794298231601715, 0.2792361080646515, 0.27811363339424133, 0.2803518772125244, 0.27557939291000366, 0.28531786799430847, 0.27829715609550476, 0.2871742248535156, 0.28194618225097656, 0.27566465735435486, 0.2725728452205658, 0.2855963408946991, 0.2775542438030243, 0.2681688964366913, 0.2694035768508911, 0.2648434042930603, 0.2710754871368408, 0.26325902342796326, 0.2672806680202484, 0.2694724500179291, 0.2691035866737366, 0.265098512172699, 0.25958704948425293, 0.2596556842327118, 0.2639687657356262, 0.27289503812789917, 0.2676526606082916, 0.26060035824775696, 0.25871601700782776, 0.25688624382019043, 0.2564530372619629, 0.25694358348846436, 0.2551998198032379, 0.2672588527202606, 0.25727853178977966, 0.25912123918533325, 0.27235648036003113, 0.27945542335510254, 0.28740254044532776, 0.24890123307704926, 0.2509543001651764, 0.250934898853302, 0.2608042359352112, 0.2508973777294159, 0.24925130605697632, 0.24462980031967163, 0.25116729736328125, 0.24747543036937714, 0.24035663902759552, 0.24583078920841217, 0.2379494309425354, 0.24800369143486023, 0.2420155256986618, 0.24679915606975555, 0.242630735039711, 0.2546371817588806, 0.2859681248664856, 0.2445967048406601, 0.24159687757492065, 0.2375103384256363, 0.24839580059051514, 0.25560927391052246, 0.23818492889404297, 0.2519218921661377, 0.23674598336219788, 0.23416216671466827, 0.24161455035209656], 'accuracy': [0.9057112336158752, 0.9533944129943848, 0.9612069129943848, 0.9609375, 0.9603987336158752, 0.962553858757019, 0.9660560488700867, 0.9633620977401733, 0.9709051847457886, 0.970366358757019, 0.9722521305084229, 0.9719827771186829, 0.970097005367279, 0.9757543206214905, 0.9784482717514038, 0.9776400923728943, 0.9773706793785095, 0.9760237336158752, 0.9738685488700867, 0.9789870977401733, 0.9797952771186829, 0.962553858757019, 0.967402994632721, 0.977909505367279, 0.9795258641242981, 0.9784482717514038, 0.9776400923728943, 0.9814116358757019, 0.9771012663841248, 0.9824892282485962, 0.9811422228813171, 0.9819504022598267, 0.9841055870056152, 0.983027994632721, 0.9854525923728943, 0.984375, 0.9814116358757019, 0.9846444129943848, 0.9808728694915771, 0.983027994632721, 0.9819504022598267, 0.9797952771186829, 0.985722005367279, 0.9854525923728943, 0.9776400923728943, 0.9846444129943848, 0.9873383641242981, 0.9867995977401733, 0.9876077771186829, 0.9873383641242981, 0.9894935488700867, 0.9878771305084229, 0.9835668206214905, 0.9849137663841248, 0.9878771305084229, 0.9900323152542114, 0.9889547228813171, 0.9881465435028076, 0.9832974076271057, 0.9849137663841248, 0.9897629022598267, 0.9894935488700867, 0.9916487336158752, 0.990840494632721, 0.9889547228813171, 0.9900323152542114, 0.9832974076271057, 0.9881465435028076, 0.9894935488700867, 0.9816810488700867, 0.9765625, 0.9717133641242981, 0.9948814511299133, 0.9919180870056152, 0.9924569129943848, 0.984375, 0.9916487336158752, 0.9927262663841248, 0.993803858757019, 0.990571141242981, 0.9919180870056152, 0.9959590435028076, 0.9911099076271057, 0.9959590435028076, 0.9913793206214905, 0.9948814511299133, 0.9913793206214905, 0.993534505367279, 0.9854525923728943, 0.9757543206214905, 0.9927262663841248, 0.9940732717514038, 0.9951508641242981, 0.9900323152542114, 0.985722005367279, 0.9943426847457886, 0.9862607717514038, 0.9943426847457886, 0.9962284564971924, 0.9913793206214905], 'val_loss': [0.9361134767532349, 0.9305221438407898, 0.9310618042945862, 0.9277706146240234, 0.9101108908653259, 0.9048128724098206, 0.8990525007247925, 0.8965896368026733, 0.8743805885314941, 0.8708423376083374, 0.844214916229248, 0.8232746124267578, 0.7996950745582581, 0.7754902839660645, 0.7648787498474121, 0.7224900722503662, 0.6880760788917542, 0.7488574981689453, 0.7340875267982483, 0.6777600049972534, 0.6717633605003357, 0.6692331433296204, 0.692589521408081, 0.7305989265441895, 0.7029260993003845, 0.7703640460968018, 0.7359370589256287, 0.7645975947380066, 0.7746403813362122, 0.7838839888572693, 0.7827842235565186, 0.7989446520805359, 0.7988372445106506, 0.7977850437164307, 0.8406177759170532, 0.8149355053901672, 0.9534329175949097, 0.9633437991142273, 0.9049848318099976, 0.8508109450340271, 0.863027811050415, 0.8560525178909302, 0.9583497643470764, 0.938222348690033, 1.0168896913528442, 0.8807968497276306, 0.8652442693710327, 0.8532728552818298, 0.8728185892105103, 0.9013569355010986, 0.8663437366485596, 0.9251765012741089, 0.9073803424835205, 0.8721144199371338, 0.8737744092941284, 0.8814132213592529, 0.8904540538787842, 1.0992387533187866, 0.8927631974220276, 0.9070340394973755, 0.8936558365821838, 0.9376854300498962, 0.9697195291519165, 0.9317378401756287, 0.9074909687042236, 0.9155160784721375, 0.9121969938278198, 0.9927124977111816, 1.065682291984558, 1.005155086517334, 1.0902336835861206, 0.9129989147186279, 0.9424639940261841, 0.9719521999359131, 0.9182083606719971, 0.9313886165618896, 0.9130880236625671, 0.9378431439399719, 0.9330570697784424, 0.9472190141677856, 0.9159851670265198, 0.9286266565322876, 0.9815303683280945, 0.937908411026001, 0.9382456541061401, 0.9348799586296082, 1.0459530353546143, 1.1525003910064697, 1.3387378454208374, 0.9600724577903748, 0.929338812828064, 1.0270473957061768, 0.9334445595741272, 0.947666585445404, 0.9448590278625488, 0.9852882623672485, 0.9559381008148193, 0.9534704089164734, 0.9981837868690491, 1.0134221315383911], 'val_accuracy': [0.517241358757019, 0.5215517282485962, 0.5204741358757019, 0.5258620977401733, 0.548491358757019, 0.5528017282485962, 0.5603448152542114, 0.5603448152542114, 0.5862069129943848, 0.5926724076271057, 0.625, 0.6454741358757019, 0.6691810488700867, 0.7036637663841248, 0.7133620977401733, 0.7478448152542114, 0.7801724076271057, 0.7306034564971924, 0.75, 0.7995689511299133, 0.8232758641242981, 0.8318965435028076, 0.8157327771186829, 0.798491358757019, 0.8221982717514038, 0.7963362336158752, 0.8200430870056152, 0.8135775923728943, 0.8168103694915771, 0.818965494632721, 0.8146551847457886, 0.8168103694915771, 0.8243534564971924, 0.8200430870056152, 0.8092672228813171, 0.8221982717514038, 0.78125, 0.7995689511299133, 0.8006465435028076, 0.8146551847457886, 0.8146551847457886, 0.8135775923728943, 0.7974137663841248, 0.8038793206214905, 0.7909482717514038, 0.8049569129943848, 0.8081896305084229, 0.8157327771186829, 0.8135775923728943, 0.8081896305084229, 0.8017241358757019, 0.787715494632721, 0.7941810488700867, 0.8178879022598267, 0.8092672228813171, 0.8135775923728943, 0.8103448152542114, 0.7596982717514038, 0.8028017282485962, 0.8081896305084229, 0.8125, 0.795258641242981, 0.7974137663841248, 0.7995689511299133, 0.8125, 0.8028017282485962, 0.8071120977401733, 0.8006465435028076, 0.7941810488700867, 0.774784505367279, 0.7629310488700867, 0.8017241358757019, 0.8071120977401733, 0.7909482717514038, 0.8028017282485962, 0.8038793206214905, 0.8092672228813171, 0.7963362336158752, 0.8081896305084229, 0.7909482717514038, 0.8038793206214905, 0.8038793206214905, 0.7898706793785095, 0.8081896305084229, 0.8017241358757019, 0.8071120977401733, 0.7909482717514038, 0.7780172228813171, 0.7489224076271057, 0.8038793206214905, 0.798491358757019, 0.787715494632721, 0.8103448152542114, 0.8071120977401733, 0.7974137663841248, 0.7931034564971924, 0.806034505367279, 0.806034505367279, 0.798491358757019, 0.7866379022598267]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.4263 - accuracy: 0.9327"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 12s 213ms/step - loss: 0.4226 - accuracy: 0.9335 - val_loss: 0.9380 - val_accuracy: 0.5068\n","Epoch 2/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.3545 - accuracy: 0.9539 - val_loss: 0.9319 - val_accuracy: 0.5113\n","Epoch 3/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3396 - accuracy: 0.9612 - val_loss: 0.9321 - val_accuracy: 0.5136\n","Epoch 4/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3296 - accuracy: 0.9626 - val_loss: 0.9364 - val_accuracy: 0.5102\n","Epoch 5/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3283 - accuracy: 0.9643 - val_loss: 0.9233 - val_accuracy: 0.5158\n","Epoch 6/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3213 - accuracy: 0.9700 - val_loss: 0.9150 - val_accuracy: 0.5238\n","Epoch 7/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3090 - accuracy: 0.9734 - val_loss: 0.8964 - val_accuracy: 0.5645\n","Epoch 8/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3492 - accuracy: 0.9510 - val_loss: 0.9128 - val_accuracy: 0.5351\n","Epoch 9/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3217 - accuracy: 0.9658 - val_loss: 0.8668 - val_accuracy: 0.6109\n","Epoch 10/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3171 - accuracy: 0.9666 - val_loss: 0.8398 - val_accuracy: 0.6471\n","Epoch 11/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3346 - accuracy: 0.9612 - val_loss: 0.8559 - val_accuracy: 0.6199\n","Epoch 12/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.3145 - accuracy: 0.9686 - val_loss: 0.8171 - val_accuracy: 0.6652\n","Epoch 13/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.2991 - accuracy: 0.9785 - val_loss: 0.7904 - val_accuracy: 0.6968\n","Epoch 14/100\n","28/28 [==============================] - 1s 46ms/step - loss: 0.3040 - accuracy: 0.9743 - val_loss: 0.7268 - val_accuracy: 0.7986\n","Epoch 15/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3079 - accuracy: 0.9740 - val_loss: 0.7444 - val_accuracy: 0.7455\n","Epoch 16/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3343 - accuracy: 0.9595 - val_loss: 0.8028 - val_accuracy: 0.6844\n","Epoch 17/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3253 - accuracy: 0.9604 - val_loss: 0.7167 - val_accuracy: 0.7602\n","Epoch 18/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2910 - accuracy: 0.9813 - val_loss: 0.6996 - val_accuracy: 0.7760\n","Epoch 19/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.2940 - accuracy: 0.9791 - val_loss: 0.6434 - val_accuracy: 0.8292\n","Epoch 20/100\n","28/28 [==============================] - 1s 17ms/step - loss: 0.2969 - accuracy: 0.9782 - val_loss: 0.6546 - val_accuracy: 0.8247\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2979 - accuracy: 0.9793 - val_loss: 0.6881 - val_accuracy: 0.8088\n","Epoch 22/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.2924 - accuracy: 0.9782 - val_loss: 0.6565 - val_accuracy: 0.8303\n","Epoch 23/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2970 - accuracy: 0.9745 - val_loss: 0.6600 - val_accuracy: 0.8235\n","Epoch 24/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2838 - accuracy: 0.9825 - val_loss: 0.6982 - val_accuracy: 0.8269\n","Epoch 25/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2796 - accuracy: 0.9853 - val_loss: 0.6852 - val_accuracy: 0.8303\n","Epoch 26/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.2910 - accuracy: 0.9816 - val_loss: 0.7144 - val_accuracy: 0.8314\n","Epoch 27/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2874 - accuracy: 0.9813 - val_loss: 0.7186 - val_accuracy: 0.8292\n","Epoch 28/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3191 - accuracy: 0.9652 - val_loss: 0.7651 - val_accuracy: 0.8167\n","Epoch 29/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2892 - accuracy: 0.9774 - val_loss: 0.9566 - val_accuracy: 0.7704\n","Epoch 30/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3063 - accuracy: 0.9714 - val_loss: 0.7967 - val_accuracy: 0.8156\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2887 - accuracy: 0.9774 - val_loss: 0.8535 - val_accuracy: 0.8066\n","Epoch 32/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2796 - accuracy: 0.9861 - val_loss: 0.8157 - val_accuracy: 0.8122\n","Epoch 33/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.2837 - accuracy: 0.9836 - val_loss: 0.8064 - val_accuracy: 0.8371\n","Epoch 34/100\n","28/28 [==============================] - 1s 17ms/step - loss: 0.2810 - accuracy: 0.9850 - val_loss: 0.8984 - val_accuracy: 0.7986\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2779 - accuracy: 0.9830 - val_loss: 0.8057 - val_accuracy: 0.8269\n","Epoch 36/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2763 - accuracy: 0.9861 - val_loss: 0.8155 - val_accuracy: 0.8213\n","Epoch 37/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2901 - accuracy: 0.9737 - val_loss: 0.9182 - val_accuracy: 0.7964\n","Epoch 38/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2740 - accuracy: 0.9875 - val_loss: 0.8723 - val_accuracy: 0.8020\n","Epoch 39/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2743 - accuracy: 0.9878 - val_loss: 0.8489 - val_accuracy: 0.8213\n","Epoch 40/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2691 - accuracy: 0.9884 - val_loss: 0.8975 - val_accuracy: 0.8043\n","Epoch 41/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2744 - accuracy: 0.9842 - val_loss: 0.8793 - val_accuracy: 0.8100\n","Epoch 42/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2840 - accuracy: 0.9825 - val_loss: 0.8562 - val_accuracy: 0.8179\n","Epoch 43/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2718 - accuracy: 0.9861 - val_loss: 0.8895 - val_accuracy: 0.8077\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3137 - accuracy: 0.9649 - val_loss: 0.8646 - val_accuracy: 0.8133\n","Epoch 45/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2852 - accuracy: 0.9796 - val_loss: 0.8925 - val_accuracy: 0.8167\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2739 - accuracy: 0.9839 - val_loss: 0.8391 - val_accuracy: 0.8190\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2654 - accuracy: 0.9892 - val_loss: 0.8699 - val_accuracy: 0.8167\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2647 - accuracy: 0.9895 - val_loss: 0.8804 - val_accuracy: 0.8111\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2632 - accuracy: 0.9890 - val_loss: 0.9162 - val_accuracy: 0.8100\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2651 - accuracy: 0.9878 - val_loss: 0.8862 - val_accuracy: 0.8066\n","Epoch 51/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2621 - accuracy: 0.9915 - val_loss: 0.8790 - val_accuracy: 0.8100\n","Epoch 52/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2584 - accuracy: 0.9918 - val_loss: 0.8595 - val_accuracy: 0.8122\n","Epoch 53/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2619 - accuracy: 0.9907 - val_loss: 1.0166 - val_accuracy: 0.7851\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2734 - accuracy: 0.9844 - val_loss: 0.9993 - val_accuracy: 0.7907\n","Epoch 55/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2609 - accuracy: 0.9915 - val_loss: 0.8709 - val_accuracy: 0.8201\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2607 - accuracy: 0.9898 - val_loss: 0.9485 - val_accuracy: 0.7885\n","Epoch 57/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2760 - accuracy: 0.9805 - val_loss: 0.9466 - val_accuracy: 0.7930\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2548 - accuracy: 0.9924 - val_loss: 0.9310 - val_accuracy: 0.7986\n","Epoch 59/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2585 - accuracy: 0.9912 - val_loss: 0.9259 - val_accuracy: 0.8032\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2615 - accuracy: 0.9898 - val_loss: 0.8948 - val_accuracy: 0.8111\n","Epoch 61/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2591 - accuracy: 0.9895 - val_loss: 0.9018 - val_accuracy: 0.8066\n","Epoch 62/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2534 - accuracy: 0.9938 - val_loss: 0.8864 - val_accuracy: 0.8100\n","Epoch 63/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2515 - accuracy: 0.9932 - val_loss: 0.9527 - val_accuracy: 0.7998\n","Epoch 64/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2547 - accuracy: 0.9926 - val_loss: 0.9317 - val_accuracy: 0.8043\n","Epoch 65/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2546 - accuracy: 0.9924 - val_loss: 1.0305 - val_accuracy: 0.7873\n","Epoch 66/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2618 - accuracy: 0.9878 - val_loss: 1.0479 - val_accuracy: 0.7805\n","Epoch 67/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2492 - accuracy: 0.9949 - val_loss: 0.9172 - val_accuracy: 0.8122\n","Epoch 68/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2514 - accuracy: 0.9929 - val_loss: 0.9746 - val_accuracy: 0.8054\n","Epoch 69/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2514 - accuracy: 0.9924 - val_loss: 0.9140 - val_accuracy: 0.8156\n","Epoch 70/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2491 - accuracy: 0.9932 - val_loss: 0.9117 - val_accuracy: 0.8179\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2492 - accuracy: 0.9924 - val_loss: 1.4238 - val_accuracy: 0.7353\n","Epoch 72/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2647 - accuracy: 0.9836 - val_loss: 0.9071 - val_accuracy: 0.8145\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2556 - accuracy: 0.9890 - val_loss: 0.9862 - val_accuracy: 0.8020\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2566 - accuracy: 0.9887 - val_loss: 1.0470 - val_accuracy: 0.7862\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2489 - accuracy: 0.9929 - val_loss: 0.9233 - val_accuracy: 0.8145\n","Epoch 76/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2480 - accuracy: 0.9918 - val_loss: 0.9152 - val_accuracy: 0.8247\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2645 - accuracy: 0.9844 - val_loss: 0.9454 - val_accuracy: 0.8032\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2515 - accuracy: 0.9912 - val_loss: 1.0350 - val_accuracy: 0.7817\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2518 - accuracy: 0.9918 - val_loss: 0.9296 - val_accuracy: 0.8111\n","Epoch 80/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2540 - accuracy: 0.9895 - val_loss: 0.9635 - val_accuracy: 0.8066\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2624 - accuracy: 0.9856 - val_loss: 1.1465 - val_accuracy: 0.7647\n","Epoch 82/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2560 - accuracy: 0.9881 - val_loss: 0.9278 - val_accuracy: 0.8100\n","Epoch 83/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2641 - accuracy: 0.9842 - val_loss: 0.9471 - val_accuracy: 0.8111\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2575 - accuracy: 0.9887 - val_loss: 1.0542 - val_accuracy: 0.7941\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2537 - accuracy: 0.9875 - val_loss: 1.0540 - val_accuracy: 0.7839\n","Epoch 86/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2555 - accuracy: 0.9892 - val_loss: 0.9993 - val_accuracy: 0.8020\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2556 - accuracy: 0.9895 - val_loss: 0.9242 - val_accuracy: 0.8235\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2471 - accuracy: 0.9926 - val_loss: 0.9370 - val_accuracy: 0.8122\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2364 - accuracy: 0.9975 - val_loss: 0.9397 - val_accuracy: 0.8122\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2383 - accuracy: 0.9955 - val_loss: 0.9791 - val_accuracy: 0.8032\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2413 - accuracy: 0.9943 - val_loss: 0.9269 - val_accuracy: 0.8122\n","Epoch 92/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2419 - accuracy: 0.9946 - val_loss: 1.0172 - val_accuracy: 0.7975\n","Epoch 93/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2433 - accuracy: 0.9918 - val_loss: 0.9529 - val_accuracy: 0.8077\n","Epoch 94/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2443 - accuracy: 0.9921 - val_loss: 1.1345 - val_accuracy: 0.7817\n","Epoch 95/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2411 - accuracy: 0.9946 - val_loss: 0.9803 - val_accuracy: 0.8100\n","Epoch 96/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2364 - accuracy: 0.9960 - val_loss: 0.9653 - val_accuracy: 0.8009\n","Epoch 97/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2464 - accuracy: 0.9907 - val_loss: 1.1198 - val_accuracy: 0.7783\n","Epoch 98/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2465 - accuracy: 0.9887 - val_loss: 1.0044 - val_accuracy: 0.7986\n","Epoch 99/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2462 - accuracy: 0.9924 - val_loss: 0.9720 - val_accuracy: 0.8077\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2366 - accuracy: 0.9949 - val_loss: 1.2889 - val_accuracy: 0.7534\n","{'loss': [0.42258360981941223, 0.3544611930847168, 0.33958369493484497, 0.32957205176353455, 0.3283074200153351, 0.32126957178115845, 0.30900028347969055, 0.34916186332702637, 0.3216785788536072, 0.31714171171188354, 0.3345978558063507, 0.3144571781158447, 0.29905685782432556, 0.30404868721961975, 0.30789828300476074, 0.3342616558074951, 0.32528457045555115, 0.2909582853317261, 0.294018030166626, 0.29689809679985046, 0.2978953719139099, 0.2923828065395355, 0.29696962237358093, 0.2838071882724762, 0.279608815908432, 0.2909609377384186, 0.28736868500709534, 0.31909671425819397, 0.28917738795280457, 0.30634933710098267, 0.2887117564678192, 0.27963823080062866, 0.28370752930641174, 0.28104448318481445, 0.27790024876594543, 0.27626362442970276, 0.2901271879673004, 0.2740107476711273, 0.2743346393108368, 0.26911360025405884, 0.27440640330314636, 0.28397491574287415, 0.27178123593330383, 0.3137221336364746, 0.28516605496406555, 0.2738848030567169, 0.2654288411140442, 0.2646696865558624, 0.263198584318161, 0.26513105630874634, 0.2620658874511719, 0.25843608379364014, 0.26193541288375854, 0.2733553647994995, 0.26093369722366333, 0.2607100307941437, 0.27598607540130615, 0.25475409626960754, 0.25847914814949036, 0.2614670395851135, 0.25913652777671814, 0.2533794641494751, 0.25145232677459717, 0.2547041177749634, 0.2546031177043915, 0.2617708742618561, 0.24919335544109344, 0.25136616826057434, 0.25137507915496826, 0.2490718960762024, 0.24915063381195068, 0.26469266414642334, 0.25556129217147827, 0.25661933422088623, 0.24893897771835327, 0.24797409772872925, 0.2644769251346588, 0.2515178322792053, 0.2517614960670471, 0.2539767622947693, 0.26237356662750244, 0.25603535771369934, 0.26414597034454346, 0.25753140449523926, 0.2537250220775604, 0.2554803788661957, 0.25559690594673157, 0.2471078783273697, 0.23636439442634583, 0.23834441602230072, 0.24131378531455994, 0.24194903671741486, 0.2433023899793625, 0.2443154901266098, 0.24112311005592346, 0.2363990843296051, 0.24637413024902344, 0.24652895331382751, 0.24619516730308533, 0.2366241067647934], 'accuracy': [0.9335030913352966, 0.9538766145706177, 0.9612337350845337, 0.9626485705375671, 0.9643463492393494, 0.9700056314468384, 0.9734012484550476, 0.9510469436645508, 0.9657611846923828, 0.9666100740432739, 0.9612337350845337, 0.9685908555984497, 0.9784946441650391, 0.9742501378059387, 0.9739671945571899, 0.9595359563827515, 0.9603848457336426, 0.9813242554664612, 0.9790605306625366, 0.9782116413116455, 0.9793435335159302, 0.9782116413116455, 0.9745330810546875, 0.9824561476707458, 0.9852858185768127, 0.9816072583198547, 0.9813242554664612, 0.9651952385902405, 0.9773627519607544, 0.9714204668998718, 0.9773627519607544, 0.9861347079277039, 0.9835879802703857, 0.9850028157234192, 0.9830220937728882, 0.9861347079277039, 0.9736841917037964, 0.9875495433807373, 0.9878324866294861, 0.9883984327316284, 0.9841539263725281, 0.9824561476707458, 0.9861347079277039, 0.9649122953414917, 0.979626476764679, 0.9838709831237793, 0.9892473220825195, 0.9895302653312683, 0.988964319229126, 0.9878324866294861, 0.9915110468864441, 0.9917939901351929, 0.990662157535553, 0.9844368696212769, 0.9915110468864441, 0.9898132681846619, 0.9804753661155701, 0.9923599362373352, 0.9912280440330505, 0.9898132681846619, 0.9895302653312683, 0.9937747716903687, 0.9932088255882263, 0.992642879486084, 0.9923599362373352, 0.9878324866294861, 0.9949066042900085, 0.9929258823394775, 0.9923599362373352, 0.9932088255882263, 0.9923599362373352, 0.9835879802703857, 0.988964319229126, 0.9886813759803772, 0.9929258823394775, 0.9917939901351929, 0.9844368696212769, 0.9912280440330505, 0.9917939901351929, 0.9895302653312683, 0.9855687618255615, 0.9881154298782349, 0.9841539263725281, 0.9886813759803772, 0.9875495433807373, 0.9892473220825195, 0.9895302653312683, 0.992642879486084, 0.9974533319473267, 0.9954725503921509, 0.994340717792511, 0.9946236610412598, 0.9917939901351929, 0.9920769929885864, 0.9946236610412598, 0.9960384964942932, 0.990662157535553, 0.9886813759803772, 0.9923599362373352, 0.9949066042900085], 'val_loss': [0.9379907250404358, 0.9318856000900269, 0.9321290254592896, 0.9363591074943542, 0.9233059287071228, 0.9150295257568359, 0.8963810801506042, 0.9127748012542725, 0.866790235042572, 0.8398356437683105, 0.8558675050735474, 0.8171416521072388, 0.790386438369751, 0.7267799973487854, 0.7444021701812744, 0.8027637600898743, 0.7166861891746521, 0.6996214389801025, 0.6434473395347595, 0.6545875072479248, 0.688093364238739, 0.6564511060714722, 0.6599777936935425, 0.6982277631759644, 0.6852139830589294, 0.7144489288330078, 0.7186219096183777, 0.7650970220565796, 0.9565693140029907, 0.7967244982719421, 0.8535196185112, 0.8157044053077698, 0.8064308762550354, 0.8984350562095642, 0.8057459592819214, 0.8154627084732056, 0.9181748628616333, 0.8723318576812744, 0.8489049077033997, 0.897540807723999, 0.8793461918830872, 0.8561784625053406, 0.8895115852355957, 0.8645861744880676, 0.8925102949142456, 0.8390508890151978, 0.8699397444725037, 0.8804090023040771, 0.9162165522575378, 0.886208176612854, 0.8789933919906616, 0.8595267534255981, 1.0166497230529785, 0.9993385672569275, 0.8709120154380798, 0.9485119581222534, 0.9466044306755066, 0.9309974908828735, 0.9258630871772766, 0.8948094844818115, 0.9018246531486511, 0.8864285349845886, 0.9527291655540466, 0.9316626787185669, 1.0304797887802124, 1.0479049682617188, 0.9171699285507202, 0.9745811223983765, 0.9140323996543884, 0.9117158651351929, 1.4237548112869263, 0.9071335792541504, 0.9861533641815186, 1.0469727516174316, 0.9233385920524597, 0.9152048826217651, 0.9454122185707092, 1.0349817276000977, 0.9296087622642517, 0.9634923934936523, 1.1465232372283936, 0.9278321266174316, 0.947115957736969, 1.0541743040084839, 1.0540201663970947, 0.9993309378623962, 0.9242473840713501, 0.9369907975196838, 0.9397107362747192, 0.9790820479393005, 0.9269318580627441, 1.017210841178894, 0.9529292583465576, 1.134534478187561, 0.9803354144096375, 0.9652805924415588, 1.119835376739502, 1.00437331199646, 0.9720277190208435, 1.2889031171798706], 'val_accuracy': [0.5067873597145081, 0.5113122463226318, 0.5135746598243713, 0.5101810097694397, 0.5158371329307556, 0.523755669593811, 0.564479649066925, 0.5350678563117981, 0.610859751701355, 0.6470588445663452, 0.6199095249176025, 0.6651583909988403, 0.6968325972557068, 0.7986425161361694, 0.7454751133918762, 0.6843891143798828, 0.7601810097694397, 0.7760180830955505, 0.8291855454444885, 0.8246606588363647, 0.8088235259056091, 0.8303167223930359, 0.8235294222831726, 0.8269230723381042, 0.8303167223930359, 0.831447958946228, 0.8291855454444885, 0.8167420625686646, 0.7703620195388794, 0.8156108856201172, 0.8065611124038696, 0.8122171759605408, 0.837104082107544, 0.7986425161361694, 0.8269230723381042, 0.8212669491767883, 0.7963801026344299, 0.8020362257957458, 0.8212669491767883, 0.8042986392974854, 0.8099547624588013, 0.8178732991218567, 0.807692289352417, 0.8133484125137329, 0.8167420625686646, 0.8190045356750488, 0.8167420625686646, 0.8110859990119934, 0.8099547624588013, 0.8065611124038696, 0.8099547624588013, 0.8122171759605408, 0.7850678563117981, 0.790723979473114, 0.820135772228241, 0.7884615659713745, 0.7929864525794983, 0.7986425161361694, 0.8031674027442932, 0.8110859990119934, 0.8065611124038696, 0.8099547624588013, 0.7997737526893616, 0.8042986392974854, 0.7873303294181824, 0.7805429697036743, 0.8122171759605408, 0.8054298758506775, 0.8156108856201172, 0.8178732991218567, 0.7352941036224365, 0.814479649066925, 0.8020362257957458, 0.7861990928649902, 0.814479649066925, 0.8246606588363647, 0.8031674027442932, 0.7816742062568665, 0.8110859990119934, 0.8065611124038696, 0.7647058963775635, 0.8099547624588013, 0.8110859990119934, 0.7941176295280457, 0.7839366793632507, 0.8020362257957458, 0.8235294222831726, 0.8122171759605408, 0.8122171759605408, 0.8031674027442932, 0.8122171759605408, 0.7975113391876221, 0.807692289352417, 0.7816742062568665, 0.8099547624588013, 0.8009049892425537, 0.7782805562019348, 0.7986425161361694, 0.807692289352417, 0.7533936500549316]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.4837 - accuracy: 0.9117"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 13s 239ms/step - loss: 0.4841 - accuracy: 0.9116 - val_loss: 0.9313 - val_accuracy: 0.5186\n","Epoch 2/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4098 - accuracy: 0.9328 - val_loss: 0.9276 - val_accuracy: 0.5227\n","Epoch 3/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3921 - accuracy: 0.9424 - val_loss: 0.9303 - val_accuracy: 0.5227\n","Epoch 4/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3561 - accuracy: 0.9530 - val_loss: 0.9213 - val_accuracy: 0.5279\n","Epoch 5/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3690 - accuracy: 0.9473 - val_loss: 0.9313 - val_accuracy: 0.5196\n","Epoch 6/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3509 - accuracy: 0.9579 - val_loss: 0.9130 - val_accuracy: 0.5424\n","Epoch 7/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3562 - accuracy: 0.9571 - val_loss: 0.9141 - val_accuracy: 0.5444\n","Epoch 8/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3510 - accuracy: 0.9558 - val_loss: 0.9030 - val_accuracy: 0.5548\n","Epoch 9/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3378 - accuracy: 0.9615 - val_loss: 0.9191 - val_accuracy: 0.5465\n","Epoch 10/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.3590 - accuracy: 0.9530 - val_loss: 0.8673 - val_accuracy: 0.6064\n","Epoch 11/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3377 - accuracy: 0.9612 - val_loss: 0.9021 - val_accuracy: 0.5754\n","Epoch 12/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.3321 - accuracy: 0.9623 - val_loss: 0.8507 - val_accuracy: 0.6312\n","Epoch 13/100\n","31/31 [==============================] - 1s 35ms/step - loss: 0.3211 - accuracy: 0.9682 - val_loss: 0.7964 - val_accuracy: 0.7097\n","Epoch 14/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3360 - accuracy: 0.9625 - val_loss: 0.8808 - val_accuracy: 0.6188\n","Epoch 15/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3430 - accuracy: 0.9589 - val_loss: 0.8337 - val_accuracy: 0.6787\n","Epoch 16/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3224 - accuracy: 0.9700 - val_loss: 0.8095 - val_accuracy: 0.7076\n","Epoch 17/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3431 - accuracy: 0.9610 - val_loss: 0.7267 - val_accuracy: 0.8151\n","Epoch 18/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3373 - accuracy: 0.9605 - val_loss: 0.7344 - val_accuracy: 0.7996\n","Epoch 19/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3412 - accuracy: 0.9592 - val_loss: 0.8370 - val_accuracy: 0.7345\n","Epoch 20/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3128 - accuracy: 0.9721 - val_loss: 0.7825 - val_accuracy: 0.7872\n","Epoch 21/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3128 - accuracy: 0.9708 - val_loss: 0.7872 - val_accuracy: 0.7986\n","Epoch 22/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3012 - accuracy: 0.9780 - val_loss: 0.8093 - val_accuracy: 0.8079\n","Epoch 23/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3202 - accuracy: 0.9690 - val_loss: 0.8361 - val_accuracy: 0.7955\n","Epoch 24/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3101 - accuracy: 0.9721 - val_loss: 0.8761 - val_accuracy: 0.7924\n","Epoch 25/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3123 - accuracy: 0.9726 - val_loss: 0.9004 - val_accuracy: 0.8089\n","Epoch 26/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3574 - accuracy: 0.9496 - val_loss: 0.9667 - val_accuracy: 0.7975\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3644 - accuracy: 0.9398 - val_loss: 0.9070 - val_accuracy: 0.7986\n","Epoch 28/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3057 - accuracy: 0.9752 - val_loss: 0.9434 - val_accuracy: 0.7882\n","Epoch 29/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3265 - accuracy: 0.9633 - val_loss: 0.9472 - val_accuracy: 0.7913\n","Epoch 30/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3019 - accuracy: 0.9752 - val_loss: 0.9464 - val_accuracy: 0.7955\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3007 - accuracy: 0.9760 - val_loss: 0.9640 - val_accuracy: 0.8006\n","Epoch 32/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2947 - accuracy: 0.9798 - val_loss: 1.0170 - val_accuracy: 0.7820\n","Epoch 33/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2998 - accuracy: 0.9755 - val_loss: 0.9877 - val_accuracy: 0.8017\n","Epoch 34/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2977 - accuracy: 0.9793 - val_loss: 0.9966 - val_accuracy: 0.7934\n","Epoch 35/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3039 - accuracy: 0.9734 - val_loss: 0.9966 - val_accuracy: 0.7965\n","Epoch 36/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2982 - accuracy: 0.9773 - val_loss: 0.9933 - val_accuracy: 0.8017\n","Epoch 37/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2947 - accuracy: 0.9793 - val_loss: 1.1124 - val_accuracy: 0.7882\n","Epoch 38/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2914 - accuracy: 0.9793 - val_loss: 1.0754 - val_accuracy: 0.7934\n","Epoch 39/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2966 - accuracy: 0.9804 - val_loss: 0.9891 - val_accuracy: 0.7924\n","Epoch 40/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2844 - accuracy: 0.9829 - val_loss: 1.0121 - val_accuracy: 0.7924\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2986 - accuracy: 0.9757 - val_loss: 1.1071 - val_accuracy: 0.7645\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3058 - accuracy: 0.9711 - val_loss: 1.0543 - val_accuracy: 0.7913\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2815 - accuracy: 0.9837 - val_loss: 1.0291 - val_accuracy: 0.7996\n","Epoch 44/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2824 - accuracy: 0.9809 - val_loss: 1.0495 - val_accuracy: 0.7882\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2868 - accuracy: 0.9837 - val_loss: 1.0439 - val_accuracy: 0.7903\n","Epoch 46/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2904 - accuracy: 0.9780 - val_loss: 1.2029 - val_accuracy: 0.7479\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3136 - accuracy: 0.9651 - val_loss: 1.0120 - val_accuracy: 0.7965\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2822 - accuracy: 0.9809 - val_loss: 1.0322 - val_accuracy: 0.7924\n","Epoch 49/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2802 - accuracy: 0.9837 - val_loss: 1.0485 - val_accuracy: 0.7851\n","Epoch 50/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2831 - accuracy: 0.9801 - val_loss: 1.1925 - val_accuracy: 0.7510\n","Epoch 51/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3104 - accuracy: 0.9685 - val_loss: 1.0616 - val_accuracy: 0.7789\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2828 - accuracy: 0.9811 - val_loss: 1.0530 - val_accuracy: 0.7924\n","Epoch 53/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2726 - accuracy: 0.9850 - val_loss: 1.0667 - val_accuracy: 0.7965\n","Epoch 54/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2725 - accuracy: 0.9850 - val_loss: 1.0657 - val_accuracy: 0.7872\n","Epoch 55/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2880 - accuracy: 0.9793 - val_loss: 1.0550 - val_accuracy: 0.7903\n","Epoch 56/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2760 - accuracy: 0.9837 - val_loss: 1.0349 - val_accuracy: 0.7934\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2771 - accuracy: 0.9837 - val_loss: 1.0594 - val_accuracy: 0.7882\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2718 - accuracy: 0.9863 - val_loss: 1.0530 - val_accuracy: 0.7862\n","Epoch 59/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2722 - accuracy: 0.9853 - val_loss: 1.1238 - val_accuracy: 0.7738\n","Epoch 60/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2795 - accuracy: 0.9806 - val_loss: 1.1203 - val_accuracy: 0.7862\n","Epoch 61/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2689 - accuracy: 0.9858 - val_loss: 1.0927 - val_accuracy: 0.7779\n","Epoch 62/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2821 - accuracy: 0.9791 - val_loss: 1.0954 - val_accuracy: 0.7748\n","Epoch 63/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2848 - accuracy: 0.9775 - val_loss: 1.1219 - val_accuracy: 0.7810\n","Epoch 64/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2685 - accuracy: 0.9876 - val_loss: 1.1047 - val_accuracy: 0.7831\n","Epoch 65/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2712 - accuracy: 0.9855 - val_loss: 1.1347 - val_accuracy: 0.7882\n","Epoch 66/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2782 - accuracy: 0.9817 - val_loss: 1.0906 - val_accuracy: 0.7862\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2643 - accuracy: 0.9881 - val_loss: 1.1168 - val_accuracy: 0.7862\n","Epoch 68/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2638 - accuracy: 0.9866 - val_loss: 1.4354 - val_accuracy: 0.7324\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2743 - accuracy: 0.9822 - val_loss: 1.2218 - val_accuracy: 0.7758\n","Epoch 70/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2664 - accuracy: 0.9860 - val_loss: 1.1114 - val_accuracy: 0.7831\n","Epoch 71/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2731 - accuracy: 0.9835 - val_loss: 1.1081 - val_accuracy: 0.7882\n","Epoch 72/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2783 - accuracy: 0.9806 - val_loss: 1.1227 - val_accuracy: 0.7903\n","Epoch 73/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2626 - accuracy: 0.9871 - val_loss: 1.1199 - val_accuracy: 0.7862\n","Epoch 74/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2787 - accuracy: 0.9817 - val_loss: 1.1394 - val_accuracy: 0.7831\n","Epoch 75/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2587 - accuracy: 0.9894 - val_loss: 1.1286 - val_accuracy: 0.7831\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2639 - accuracy: 0.9894 - val_loss: 1.1348 - val_accuracy: 0.7779\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2656 - accuracy: 0.9855 - val_loss: 1.1655 - val_accuracy: 0.7810\n","Epoch 78/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2612 - accuracy: 0.9879 - val_loss: 1.2039 - val_accuracy: 0.7758\n","Epoch 79/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2601 - accuracy: 0.9891 - val_loss: 1.2619 - val_accuracy: 0.7583\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2663 - accuracy: 0.9845 - val_loss: 1.1439 - val_accuracy: 0.7810\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2560 - accuracy: 0.9917 - val_loss: 1.1537 - val_accuracy: 0.7882\n","Epoch 82/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2619 - accuracy: 0.9850 - val_loss: 1.1778 - val_accuracy: 0.7738\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2575 - accuracy: 0.9884 - val_loss: 1.1647 - val_accuracy: 0.7789\n","Epoch 84/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2531 - accuracy: 0.9899 - val_loss: 1.1797 - val_accuracy: 0.7851\n","Epoch 85/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2491 - accuracy: 0.9928 - val_loss: 1.2151 - val_accuracy: 0.7810\n","Epoch 86/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2520 - accuracy: 0.9910 - val_loss: 1.2479 - val_accuracy: 0.7769\n","Epoch 87/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2831 - accuracy: 0.9729 - val_loss: 1.7143 - val_accuracy: 0.6818\n","Epoch 88/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2973 - accuracy: 0.9677 - val_loss: 1.1957 - val_accuracy: 0.7748\n","Epoch 89/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2562 - accuracy: 0.9891 - val_loss: 1.1510 - val_accuracy: 0.7748\n","Epoch 90/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2557 - accuracy: 0.9881 - val_loss: 1.2350 - val_accuracy: 0.7748\n","Epoch 91/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2507 - accuracy: 0.9917 - val_loss: 1.2004 - val_accuracy: 0.7800\n","Epoch 92/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2887 - accuracy: 0.9716 - val_loss: 1.1869 - val_accuracy: 0.7645\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2570 - accuracy: 0.9876 - val_loss: 1.3509 - val_accuracy: 0.7583\n","Epoch 94/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2561 - accuracy: 0.9866 - val_loss: 1.2242 - val_accuracy: 0.7707\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2714 - accuracy: 0.9822 - val_loss: 1.2063 - val_accuracy: 0.7748\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2522 - accuracy: 0.9902 - val_loss: 1.2075 - val_accuracy: 0.7810\n","Epoch 97/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2463 - accuracy: 0.9928 - val_loss: 1.1789 - val_accuracy: 0.7779\n","Epoch 98/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2472 - accuracy: 0.9922 - val_loss: 1.4483 - val_accuracy: 0.7200\n","Epoch 99/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2782 - accuracy: 0.9760 - val_loss: 1.3798 - val_accuracy: 0.7335\n","Epoch 100/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2558 - accuracy: 0.9899 - val_loss: 1.2121 - val_accuracy: 0.7810\n","{'loss': [0.48413175344467163, 0.40984660387039185, 0.39209073781967163, 0.3561481237411499, 0.36896511912345886, 0.35092228651046753, 0.3561512529850006, 0.35099005699157715, 0.3378487825393677, 0.35903775691986084, 0.3376823365688324, 0.33206334710121155, 0.32108670473098755, 0.33598265051841736, 0.3430369198322296, 0.3223504424095154, 0.34313899278640747, 0.3372965157032013, 0.34123489260673523, 0.31277039647102356, 0.31278592348098755, 0.3012411892414093, 0.32016798853874207, 0.3101477026939392, 0.31227466464042664, 0.3574293255805969, 0.36442357301712036, 0.3057328164577484, 0.3264864385128021, 0.3019067347049713, 0.3007223308086395, 0.29472747445106506, 0.29976731538772583, 0.2977369427680969, 0.3039311170578003, 0.2982316315174103, 0.2947385609149933, 0.29138296842575073, 0.2965680956840515, 0.2843879759311676, 0.29864534735679626, 0.3058047890663147, 0.28151991963386536, 0.2824268341064453, 0.2867622375488281, 0.2904263138771057, 0.3136288523674011, 0.28219786286354065, 0.2802436947822571, 0.2831333577632904, 0.31044572591781616, 0.28281858563423157, 0.27261123061180115, 0.2725462317466736, 0.2879672348499298, 0.2759622037410736, 0.27713677287101746, 0.27182015776634216, 0.27221307158470154, 0.27949509024620056, 0.2688766121864319, 0.2821482717990875, 0.2848132252693176, 0.2684527039527893, 0.27123987674713135, 0.2781841456890106, 0.26430413126945496, 0.263759970664978, 0.2743118405342102, 0.2663543224334717, 0.27310845255851746, 0.27829083800315857, 0.26263633370399475, 0.2787225842475891, 0.2586970627307892, 0.2638729512691498, 0.2655581533908844, 0.26121440529823303, 0.26007792353630066, 0.2662942707538605, 0.2559959888458252, 0.26185518503189087, 0.2575187683105469, 0.25313600897789, 0.24908629059791565, 0.252046138048172, 0.28305327892303467, 0.2973422408103943, 0.256173312664032, 0.2556537091732025, 0.25072747468948364, 0.2887057960033417, 0.2569579780101776, 0.2561042606830597, 0.271359920501709, 0.2521651089191437, 0.24627242982387543, 0.24717342853546143, 0.2781681716442108, 0.2557651400566101], 'accuracy': [0.9116278886795044, 0.9328165650367737, 0.9423772692680359, 0.9529715776443481, 0.94728684425354, 0.9578811526298523, 0.9571059346199036, 0.9558139443397522, 0.9614987373352051, 0.9529715776443481, 0.961240291595459, 0.962273895740509, 0.9682170748710632, 0.9625322818756104, 0.9589147567749023, 0.9700258374214172, 0.9609819054603577, 0.960465133190155, 0.9591731429100037, 0.9720930457115173, 0.970801055431366, 0.9780361652374268, 0.9689922332763672, 0.9720930457115173, 0.97260981798172, 0.9496123790740967, 0.9397932887077332, 0.9751937985420227, 0.9633074998855591, 0.9751937985420227, 0.9759690165519714, 0.9798449873924255, 0.975452184677124, 0.9793281555175781, 0.9733850359916687, 0.9772610068321228, 0.9793281555175781, 0.9793281555175781, 0.9803617596626282, 0.9829457402229309, 0.9757105708122253, 0.9710594415664673, 0.9837209582328796, 0.9808785319328308, 0.9837209582328796, 0.9780361652374268, 0.9651162624359131, 0.9808785319328308, 0.9837209582328796, 0.9801033735275269, 0.9684754610061646, 0.9811369776725769, 0.985012948513031, 0.985012948513031, 0.9793281555175781, 0.9837209582328796, 0.9837209582328796, 0.9863049387931824, 0.9852713346481323, 0.9806201457977295, 0.985788106918335, 0.9790697693824768, 0.9775193929672241, 0.987596869468689, 0.9855297207832336, 0.9816537499427795, 0.9881137013435364, 0.9865633249282837, 0.9821705222129822, 0.9860464930534363, 0.9834625124931335, 0.9806201457977295, 0.9870800971984863, 0.9816537499427795, 0.9894056916236877, 0.9894056916236877, 0.9855297207832336, 0.9878553152084351, 0.9891473054885864, 0.9844961166381836, 0.9917312860488892, 0.985012948513031, 0.9883720874786377, 0.9899224638938904, 0.9927648305892944, 0.9909560680389404, 0.9728682041168213, 0.9677002429962158, 0.9891473054885864, 0.9881137013435364, 0.9917312860488892, 0.9715762138366699, 0.987596869468689, 0.9865633249282837, 0.9821705222129822, 0.9901808500289917, 0.9927648305892944, 0.9922480583190918, 0.9759690165519714, 0.9899224638938904], 'val_loss': [0.9312600493431091, 0.9276125431060791, 0.9303051829338074, 0.9213361740112305, 0.9313134551048279, 0.9129988551139832, 0.9141497015953064, 0.9029649496078491, 0.9191393256187439, 0.8673064112663269, 0.9020723700523376, 0.8507051467895508, 0.7964107394218445, 0.8808497786521912, 0.8337172865867615, 0.8095464110374451, 0.7266510725021362, 0.7344186305999756, 0.8369757533073425, 0.7824550271034241, 0.7871897220611572, 0.809310793876648, 0.836126446723938, 0.8760569095611572, 0.9003793001174927, 0.966720700263977, 0.9070445895195007, 0.9433916211128235, 0.9472458362579346, 0.9464317560195923, 0.9640077352523804, 1.0169932842254639, 0.9877219200134277, 0.9965823888778687, 0.9965879321098328, 0.9932850003242493, 1.1124428510665894, 1.0754190683364868, 0.9891051054000854, 1.0121341943740845, 1.1071399450302124, 1.054256558418274, 1.0290513038635254, 1.049457311630249, 1.0438817739486694, 1.2029370069503784, 1.0120415687561035, 1.0321686267852783, 1.0485409498214722, 1.1924935579299927, 1.0616484880447388, 1.05304753780365, 1.066739797592163, 1.0657439231872559, 1.0550144910812378, 1.0348738431930542, 1.0593825578689575, 1.0530073642730713, 1.123773455619812, 1.1202819347381592, 1.092704176902771, 1.0953893661499023, 1.12186598777771, 1.1047230958938599, 1.134748101234436, 1.090572714805603, 1.1168204545974731, 1.4353574514389038, 1.2217930555343628, 1.1114206314086914, 1.1081197261810303, 1.1227424144744873, 1.1198867559432983, 1.1394306421279907, 1.1285744905471802, 1.134779691696167, 1.165507197380066, 1.2039319276809692, 1.2618858814239502, 1.143929123878479, 1.153686761856079, 1.1778210401535034, 1.1647169589996338, 1.1797401905059814, 1.2151050567626953, 1.247859239578247, 1.7143070697784424, 1.1957318782806396, 1.150981068611145, 1.2350339889526367, 1.2004438638687134, 1.1868940591812134, 1.3509188890457153, 1.2241871356964111, 1.2062872648239136, 1.2074991464614868, 1.178900957107544, 1.4483076333999634, 1.3797608613967896, 1.2120633125305176], 'val_accuracy': [0.5185950398445129, 0.5227272510528564, 0.5227272510528564, 0.5278925895690918, 0.51962810754776, 0.5423553586006165, 0.5444214940071106, 0.5547520518302917, 0.5464876294136047, 0.6064049601554871, 0.5754132270812988, 0.6311983466148376, 0.7097107172012329, 0.6188016533851624, 0.6787189841270447, 0.7076446413993835, 0.8150826692581177, 0.7995867729187012, 0.7345041036605835, 0.7871900796890259, 0.7985537052154541, 0.807851254940033, 0.7954545617103577, 0.7923553586006165, 0.80888432264328, 0.797520637512207, 0.7985537052154541, 0.788223147392273, 0.7913222908973694, 0.7954545617103577, 0.8006198406219482, 0.7820248007774353, 0.8016529083251953, 0.7933884263038635, 0.7964876294136047, 0.8016529083251953, 0.788223147392273, 0.7933884263038635, 0.7923553586006165, 0.7923553586006165, 0.7644628286361694, 0.7913222908973694, 0.7995867729187012, 0.788223147392273, 0.7902892827987671, 0.7479338645935059, 0.7964876294136047, 0.7923553586006165, 0.7851239442825317, 0.7510330677032471, 0.7789255976676941, 0.7923553586006165, 0.7964876294136047, 0.7871900796890259, 0.7902892827987671, 0.7933884263038635, 0.788223147392273, 0.7861570119857788, 0.7737603187561035, 0.7861570119857788, 0.7778925895690918, 0.7747933864593506, 0.7809917330741882, 0.7830578684806824, 0.788223147392273, 0.7861570119857788, 0.7861570119857788, 0.7324380278587341, 0.7758264541625977, 0.7830578684806824, 0.788223147392273, 0.7902892827987671, 0.7861570119857788, 0.7830578684806824, 0.7830578684806824, 0.7778925895690918, 0.7809917330741882, 0.7758264541625977, 0.7582644820213318, 0.7809917330741882, 0.788223147392273, 0.7737603187561035, 0.7789255976676941, 0.7851239442825317, 0.7809917330741882, 0.7768595218658447, 0.6818181872367859, 0.7747933864593506, 0.7747933864593506, 0.7747933864593506, 0.7799586653709412, 0.7644628286361694, 0.7582644820213318, 0.7706611752510071, 0.7747933864593506, 0.7809917330741882, 0.7778925895690918, 0.7200413346290588, 0.7334710955619812, 0.7809917330741882]}\n","32/32 [==============================] - 1s 4ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_gru"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":519},"collapsed":true,"id":"kleLoWSV5B7Y","executionInfo":{"status":"ok","timestamp":1717590591212,"user_tz":-360,"elapsed":65,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}},"outputId":"1ed3c8bd-424a-4752-eecc-f10f471f8372"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision    Recall        F1  Sensitivity  Specificity  \\\n","0        0  0.533501   0.541841  0.433836  0.481860     0.433836     0.633166   \n","1        1  0.558616   0.550920  0.634181  0.589626     0.634181     0.483051   \n","2        2  0.590361   0.629310  0.439759  0.517730     0.439759     0.740964   \n","3        0  0.601340   0.586305  0.688442  0.633282     0.688442     0.514238   \n","4        1  0.612288   0.650284  0.485876  0.556184     0.485876     0.738701   \n","5        2  0.656627   0.669565  0.618474  0.643006     0.618474     0.694779   \n","6        0  0.690117   0.671192  0.745394  0.706349     0.745394     0.634841   \n","7        1  0.691384   0.727731  0.611582  0.664620     0.611582     0.771186   \n","8        2  0.735944   0.753780  0.700803  0.726327     0.700803     0.771084   \n","9        0  0.732831   0.768340  0.666667  0.713901     0.666667     0.798995   \n","10       1  0.755650   0.767751  0.733051  0.750000     0.733051     0.778249   \n","11       2  0.790161   0.778420  0.811245  0.794494     0.811245     0.769076   \n","12       0  0.784757   0.760736  0.830821  0.794235     0.830821     0.738693   \n","13       1  0.789548   0.839404  0.716102  0.772866     0.716102     0.862994   \n","14       2  0.814257   0.803883  0.831325  0.817374     0.831325     0.797189   \n","\n","       Kappa  \n","0   0.067002  \n","1   0.117232  \n","2   0.180723  \n","3   0.202680  \n","4   0.224576  \n","5   0.313253  \n","6   0.380235  \n","7   0.382768  \n","8   0.471888  \n","9   0.465662  \n","10  0.511299  \n","11  0.580321  \n","12  0.569514  \n","13  0.579096  \n","14  0.628514  "],"text/html":["\n","  <div id=\"df-08869e79-106d-4e36-bfd5-be361c609c33\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.533501</td>\n","      <td>0.541841</td>\n","      <td>0.433836</td>\n","      <td>0.481860</td>\n","      <td>0.433836</td>\n","      <td>0.633166</td>\n","      <td>0.067002</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.558616</td>\n","      <td>0.550920</td>\n","      <td>0.634181</td>\n","      <td>0.589626</td>\n","      <td>0.634181</td>\n","      <td>0.483051</td>\n","      <td>0.117232</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.590361</td>\n","      <td>0.629310</td>\n","      <td>0.439759</td>\n","      <td>0.517730</td>\n","      <td>0.439759</td>\n","      <td>0.740964</td>\n","      <td>0.180723</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.601340</td>\n","      <td>0.586305</td>\n","      <td>0.688442</td>\n","      <td>0.633282</td>\n","      <td>0.688442</td>\n","      <td>0.514238</td>\n","      <td>0.202680</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.612288</td>\n","      <td>0.650284</td>\n","      <td>0.485876</td>\n","      <td>0.556184</td>\n","      <td>0.485876</td>\n","      <td>0.738701</td>\n","      <td>0.224576</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.656627</td>\n","      <td>0.669565</td>\n","      <td>0.618474</td>\n","      <td>0.643006</td>\n","      <td>0.618474</td>\n","      <td>0.694779</td>\n","      <td>0.313253</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.690117</td>\n","      <td>0.671192</td>\n","      <td>0.745394</td>\n","      <td>0.706349</td>\n","      <td>0.745394</td>\n","      <td>0.634841</td>\n","      <td>0.380235</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.691384</td>\n","      <td>0.727731</td>\n","      <td>0.611582</td>\n","      <td>0.664620</td>\n","      <td>0.611582</td>\n","      <td>0.771186</td>\n","      <td>0.382768</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.735944</td>\n","      <td>0.753780</td>\n","      <td>0.700803</td>\n","      <td>0.726327</td>\n","      <td>0.700803</td>\n","      <td>0.771084</td>\n","      <td>0.471888</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.732831</td>\n","      <td>0.768340</td>\n","      <td>0.666667</td>\n","      <td>0.713901</td>\n","      <td>0.666667</td>\n","      <td>0.798995</td>\n","      <td>0.465662</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.755650</td>\n","      <td>0.767751</td>\n","      <td>0.733051</td>\n","      <td>0.750000</td>\n","      <td>0.733051</td>\n","      <td>0.778249</td>\n","      <td>0.511299</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.790161</td>\n","      <td>0.778420</td>\n","      <td>0.811245</td>\n","      <td>0.794494</td>\n","      <td>0.811245</td>\n","      <td>0.769076</td>\n","      <td>0.580321</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.784757</td>\n","      <td>0.760736</td>\n","      <td>0.830821</td>\n","      <td>0.794235</td>\n","      <td>0.830821</td>\n","      <td>0.738693</td>\n","      <td>0.569514</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.789548</td>\n","      <td>0.839404</td>\n","      <td>0.716102</td>\n","      <td>0.772866</td>\n","      <td>0.716102</td>\n","      <td>0.862994</td>\n","      <td>0.579096</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.814257</td>\n","      <td>0.803883</td>\n","      <td>0.831325</td>\n","      <td>0.817374</td>\n","      <td>0.831325</td>\n","      <td>0.797189</td>\n","      <td>0.628514</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08869e79-106d-4e36-bfd5-be361c609c33')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-08869e79-106d-4e36-bfd5-be361c609c33 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-08869e79-106d-4e36-bfd5-be361c609c33');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f819acef-6651-49ef-967b-5e0b41c541d3\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f819acef-6651-49ef-967b-5e0b41c541d3')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f819acef-6651-49ef-967b-5e0b41c541d3 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"metrics_df_gru","summary":"{\n  \"name\": \"metrics_df_gru\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09231248913200958,\n        \"min\": 0.533500837520938,\n        \"max\": 0.8142570281124498,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7328308207705193,\n          0.7901606425702812,\n          0.533500837520938\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0934941401154955,\n        \"min\": 0.5418410041841004,\n        \"max\": 0.8394039735099338,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7683397683397684,\n          0.7784200385356455,\n          0.5418410041841004\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12935596090455637,\n        \"min\": 0.4338358458961474,\n        \"max\": 0.8313253012048193,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6666666666666666,\n          0.8112449799196787,\n          0.4338358458961474\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10533047629682142,\n        \"min\": 0.4818604651162791,\n        \"max\": 0.8173741362290227,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7139013452914797,\n          0.7944936086529008,\n          0.4818604651162791\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12935596090455637,\n        \"min\": 0.4338358458961474,\n        \"max\": 0.8313253012048193,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6666666666666666,\n          0.8112449799196787,\n          0.4338358458961474\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10635970589917244,\n        \"min\": 0.4830508474576271,\n        \"max\": 0.8629943502824858,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7989949748743719,\n          0.7690763052208835,\n          0.6331658291457286\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18462497826401916,\n        \"min\": 0.06700167504187604,\n        \"max\": 0.6285140562248996,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.4656616415410385,\n          0.5803212851405622,\n          0.06700167504187604\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["metrics_df_gru.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/TF Domain/GRU/Alpha_tf_GRU.csv', index = False)"],"metadata":{"id":"QWSx6aHR5Bwr","executionInfo":{"status":"ok","timestamp":1717590591876,"user_tz":-360,"elapsed":717,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AyNWl5MFJXoT"},"execution_count":null,"outputs":[]}]}