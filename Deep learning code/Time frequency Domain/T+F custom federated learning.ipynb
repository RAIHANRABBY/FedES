{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1683,"status":"ok","timestamp":1717402806393,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"Mbfw8uvdftFM"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sb"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":876,"status":"ok","timestamp":1717402807266,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"INiFJfLjgOkx"},"outputs":[],"source":["\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5943,"status":"ok","timestamp":1717402813205,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"lYo2Uq77gQSH"},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score, cross_val_predict"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6137,"status":"ok","timestamp":1717402819326,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"g66575_xgVzz"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPool1D, Flatten, Dropout,LSTM"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23696,"status":"ok","timestamp":1717402843007,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"MOCNWlamfr3v","outputId":"f547417b-215b-4ab3-8e9f-1ab1384e514a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1717402843008,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"iNy9eOGMf2qO"},"outputs":[],"source":["# Raw_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/only data/raw_data.npz'\n","\n","Theta_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/time frequency domain/RAW/Total_merged_features.npz'\n","\n","\n","# RAW = np.load(Raw_data, allow_pickle=True)  # Allow loading pickled object arrays\n","# X = RAW['X'].astype('float64')\n","# Y = RAW['Y'].astype('float64')\n","# group = RAW['Group'].astype('float64')"]},{"cell_type":"markdown","metadata":{"id":"PzeABzSyHgKg"},"source":["This is a good performing model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Os2jd5SO1jf"},"outputs":[],"source":["# %%capture\n","# !pip install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tbr8rHq9PnM4"},"outputs":[],"source":["# import wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iwbCosHcPohF"},"outputs":[],"source":["# !wandb login"]},{"cell_type":"markdown","metadata":{"id":"6DhAYwXUSE9z"},"source":["# CNN-LSTM"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":12349,"status":"ok","timestamp":1717402855348,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"hbtbzyEJHP52"},"outputs":[],"source":["%%capture\n","!pip install tensorflow_addons"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1717402855348,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"VvjC2xCQNHLP"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dense(32, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_callback = ModelCheckpoint(\n","                f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time+Frequency/Total/CNN_LSTM/best_model_{run_name}.h5',\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time+Frequency/Total/CNN_LSTM/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Evaluate client model\n","            y_pred = (client_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1462446,"status":"ok","timestamp":1717404317787,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"ZVURUnmYNNNg","outputId":"6fd2ef6e-70ac-4737-f028-c3f99fc7b448"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 37, 29), Test shape: (1194, 37, 29)\n","Train shape: (4418, 37, 29), Test shape: (1416, 37, 29)\n","Train shape: (4838, 37, 29), Test shape: (996, 37, 29)\n","Train shape: (4640, 37, 29), Test shape: (1194, 37, 29)\n","Train shape: (4418, 37, 29), Test shape: (1416, 37, 29)\n","Train shape: (4838, 37, 29), Test shape: (996, 37, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.6919 - accuracy: 0.5119"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 34s 377ms/step - loss: 0.6919 - accuracy: 0.5119 - val_loss: 0.6931 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.6892 - accuracy: 0.5046 - val_loss: 0.6928 - val_accuracy: 0.7188\n","Epoch 3/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6826 - accuracy: 0.5442 - val_loss: 0.6922 - val_accuracy: 0.6401\n","Epoch 4/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6679 - accuracy: 0.6460 - val_loss: 0.6908 - val_accuracy: 0.6250\n","Epoch 5/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6399 - accuracy: 0.7018 - val_loss: 0.6882 - val_accuracy: 0.6315\n","Epoch 6/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5955 - accuracy: 0.7328 - val_loss: 0.6827 - val_accuracy: 0.6519\n","Epoch 7/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5473 - accuracy: 0.7470 - val_loss: 0.6729 - val_accuracy: 0.6983\n","Epoch 8/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5155 - accuracy: 0.7513 - val_loss: 0.6631 - val_accuracy: 0.7209\n","Epoch 9/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5023 - accuracy: 0.7570 - val_loss: 0.6500 - val_accuracy: 0.7489\n","Epoch 10/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4991 - accuracy: 0.7629 - val_loss: 0.6434 - val_accuracy: 0.7511\n","Epoch 11/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.4888 - accuracy: 0.7672 - val_loss: 0.6316 - val_accuracy: 0.7575\n","Epoch 12/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.4826 - accuracy: 0.7707 - val_loss: 0.6200 - val_accuracy: 0.7683\n","Epoch 13/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.4774 - accuracy: 0.7740 - val_loss: 0.6052 - val_accuracy: 0.7716\n","Epoch 14/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4782 - accuracy: 0.7702 - val_loss: 0.5969 - val_accuracy: 0.7640\n","Epoch 15/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.4764 - accuracy: 0.7753 - val_loss: 0.5767 - val_accuracy: 0.7802\n","Epoch 16/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4751 - accuracy: 0.7769 - val_loss: 0.5626 - val_accuracy: 0.7802\n","Epoch 17/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4716 - accuracy: 0.7783 - val_loss: 0.5465 - val_accuracy: 0.7845\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4718 - accuracy: 0.7821 - val_loss: 0.5317 - val_accuracy: 0.7802\n","Epoch 19/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4674 - accuracy: 0.7839 - val_loss: 0.5144 - val_accuracy: 0.7888\n","Epoch 20/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4641 - accuracy: 0.7874 - val_loss: 0.4997 - val_accuracy: 0.7888\n","Epoch 21/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4630 - accuracy: 0.7872 - val_loss: 0.4976 - val_accuracy: 0.7812\n","Epoch 22/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4661 - accuracy: 0.7804 - val_loss: 0.4780 - val_accuracy: 0.7942\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4614 - accuracy: 0.7883 - val_loss: 0.4707 - val_accuracy: 0.7888\n","Epoch 24/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4547 - accuracy: 0.7931 - val_loss: 0.4711 - val_accuracy: 0.7877\n","Epoch 25/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4530 - accuracy: 0.7920 - val_loss: 0.4573 - val_accuracy: 0.7931\n","Epoch 26/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4612 - accuracy: 0.7880 - val_loss: 0.4574 - val_accuracy: 0.7953\n","Epoch 27/100\n","29/29 [==============================] - 1s 43ms/step - loss: 0.4512 - accuracy: 0.7918 - val_loss: 0.4504 - val_accuracy: 0.8017\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4522 - accuracy: 0.7963 - val_loss: 0.4493 - val_accuracy: 0.7953\n","Epoch 29/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4527 - accuracy: 0.7912 - val_loss: 0.4468 - val_accuracy: 0.8039\n","Epoch 30/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4463 - accuracy: 0.7958 - val_loss: 0.4491 - val_accuracy: 0.7942\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4476 - accuracy: 0.7966 - val_loss: 0.4461 - val_accuracy: 0.8028\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4430 - accuracy: 0.7950 - val_loss: 0.4443 - val_accuracy: 0.7974\n","Epoch 33/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4410 - accuracy: 0.7961 - val_loss: 0.4396 - val_accuracy: 0.8060\n","Epoch 34/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4405 - accuracy: 0.7998 - val_loss: 0.4424 - val_accuracy: 0.8017\n","Epoch 35/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.4354 - accuracy: 0.8031 - val_loss: 0.4354 - val_accuracy: 0.8071\n","Epoch 36/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4361 - accuracy: 0.8001 - val_loss: 0.4451 - val_accuracy: 0.7974\n","Epoch 37/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4386 - accuracy: 0.7966 - val_loss: 0.4352 - val_accuracy: 0.8071\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4307 - accuracy: 0.8071 - val_loss: 0.4375 - val_accuracy: 0.8060\n","Epoch 39/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.4294 - accuracy: 0.8041 - val_loss: 0.4280 - val_accuracy: 0.8157\n","Epoch 40/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4248 - accuracy: 0.8095 - val_loss: 0.4258 - val_accuracy: 0.8147\n","Epoch 41/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4202 - accuracy: 0.8093 - val_loss: 0.4242 - val_accuracy: 0.8147\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4202 - accuracy: 0.8087 - val_loss: 0.4234 - val_accuracy: 0.8114\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4176 - accuracy: 0.8066 - val_loss: 0.4303 - val_accuracy: 0.8103\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4148 - accuracy: 0.8128 - val_loss: 0.4191 - val_accuracy: 0.8157\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4133 - accuracy: 0.8114 - val_loss: 0.4234 - val_accuracy: 0.8082\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4009 - accuracy: 0.8206 - val_loss: 0.4289 - val_accuracy: 0.8093\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4123 - accuracy: 0.8109 - val_loss: 0.4214 - val_accuracy: 0.8147\n","Epoch 48/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4070 - accuracy: 0.8195 - val_loss: 0.4136 - val_accuracy: 0.8222\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3962 - accuracy: 0.8246 - val_loss: 0.4101 - val_accuracy: 0.8157\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3998 - accuracy: 0.8262 - val_loss: 0.4182 - val_accuracy: 0.8190\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3974 - accuracy: 0.8246 - val_loss: 0.4089 - val_accuracy: 0.8200\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4013 - accuracy: 0.8200 - val_loss: 0.4050 - val_accuracy: 0.8114\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3900 - accuracy: 0.8284 - val_loss: 0.4223 - val_accuracy: 0.8211\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3919 - accuracy: 0.8260 - val_loss: 0.4112 - val_accuracy: 0.8222\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3830 - accuracy: 0.8319 - val_loss: 0.4011 - val_accuracy: 0.8125\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3823 - accuracy: 0.8265 - val_loss: 0.4145 - val_accuracy: 0.8168\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3820 - accuracy: 0.8281 - val_loss: 0.3989 - val_accuracy: 0.8168\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3720 - accuracy: 0.8367 - val_loss: 0.3993 - val_accuracy: 0.8190\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3733 - accuracy: 0.8397 - val_loss: 0.4007 - val_accuracy: 0.8190\n","Epoch 60/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3691 - accuracy: 0.8378 - val_loss: 0.4091 - val_accuracy: 0.8244\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3762 - accuracy: 0.8359 - val_loss: 0.3953 - val_accuracy: 0.8222\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3631 - accuracy: 0.8411 - val_loss: 0.4019 - val_accuracy: 0.8157\n","Epoch 63/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.3619 - accuracy: 0.8405 - val_loss: 0.3940 - val_accuracy: 0.8276\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3576 - accuracy: 0.8443 - val_loss: 0.4003 - val_accuracy: 0.8190\n","Epoch 65/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3604 - accuracy: 0.8429 - val_loss: 0.3968 - val_accuracy: 0.8265\n","Epoch 66/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3551 - accuracy: 0.8464 - val_loss: 0.3997 - val_accuracy: 0.8190\n","Epoch 67/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3572 - accuracy: 0.8483 - val_loss: 0.3969 - val_accuracy: 0.8254\n","Epoch 68/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.3486 - accuracy: 0.8561 - val_loss: 0.3941 - val_accuracy: 0.8308\n","Epoch 69/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3477 - accuracy: 0.8521 - val_loss: 0.3945 - val_accuracy: 0.8287\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3434 - accuracy: 0.8607 - val_loss: 0.4017 - val_accuracy: 0.8308\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3388 - accuracy: 0.8602 - val_loss: 0.4066 - val_accuracy: 0.8233\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3424 - accuracy: 0.8467 - val_loss: 0.4031 - val_accuracy: 0.8200\n","Epoch 73/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.3373 - accuracy: 0.8578 - val_loss: 0.3942 - val_accuracy: 0.8330\n","Epoch 74/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3315 - accuracy: 0.8599 - val_loss: 0.3928 - val_accuracy: 0.8373\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3325 - accuracy: 0.8599 - val_loss: 0.3911 - val_accuracy: 0.8341\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3357 - accuracy: 0.8572 - val_loss: 0.4177 - val_accuracy: 0.8114\n","Epoch 77/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3295 - accuracy: 0.8605 - val_loss: 0.3926 - val_accuracy: 0.8416\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3242 - accuracy: 0.8610 - val_loss: 0.4019 - val_accuracy: 0.8319\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3232 - accuracy: 0.8623 - val_loss: 0.3933 - val_accuracy: 0.8373\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3180 - accuracy: 0.8623 - val_loss: 0.3937 - val_accuracy: 0.8384\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3189 - accuracy: 0.8618 - val_loss: 0.4024 - val_accuracy: 0.8265\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3374 - accuracy: 0.8524 - val_loss: 0.4083 - val_accuracy: 0.8276\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3241 - accuracy: 0.8615 - val_loss: 0.4030 - val_accuracy: 0.8265\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3114 - accuracy: 0.8737 - val_loss: 0.3924 - val_accuracy: 0.8351\n","Epoch 85/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3044 - accuracy: 0.8731 - val_loss: 0.3965 - val_accuracy: 0.8341\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3072 - accuracy: 0.8677 - val_loss: 0.3989 - val_accuracy: 0.8330\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3025 - accuracy: 0.8769 - val_loss: 0.3962 - val_accuracy: 0.8362\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2958 - accuracy: 0.8761 - val_loss: 0.4008 - val_accuracy: 0.8341\n","Epoch 89/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3010 - accuracy: 0.8774 - val_loss: 0.4007 - val_accuracy: 0.8319\n","Epoch 90/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3001 - accuracy: 0.8774 - val_loss: 0.4082 - val_accuracy: 0.8351\n","Epoch 91/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2924 - accuracy: 0.8801 - val_loss: 0.4015 - val_accuracy: 0.8351\n","Epoch 92/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2865 - accuracy: 0.8834 - val_loss: 0.4015 - val_accuracy: 0.8373\n","Epoch 93/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2858 - accuracy: 0.8828 - val_loss: 0.4009 - val_accuracy: 0.8351\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3070 - accuracy: 0.8728 - val_loss: 0.4017 - val_accuracy: 0.8373\n","Epoch 95/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3045 - accuracy: 0.8715 - val_loss: 0.4063 - val_accuracy: 0.8297\n","Epoch 96/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2803 - accuracy: 0.8847 - val_loss: 0.4066 - val_accuracy: 0.8287\n","Epoch 97/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2891 - accuracy: 0.8823 - val_loss: 0.4063 - val_accuracy: 0.8319\n","Epoch 98/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2900 - accuracy: 0.8801 - val_loss: 0.4008 - val_accuracy: 0.8362\n","Epoch 99/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2863 - accuracy: 0.8844 - val_loss: 0.4227 - val_accuracy: 0.8200\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2843 - accuracy: 0.8879 - val_loss: 0.4041 - val_accuracy: 0.8373\n","{'loss': [0.6919020414352417, 0.6891512274742126, 0.6825953125953674, 0.6678944230079651, 0.6398676037788391, 0.5954574346542358, 0.5473220348358154, 0.5154906511306763, 0.5022642016410828, 0.499077707529068, 0.48877912759780884, 0.4825540781021118, 0.4773836135864258, 0.47815874218940735, 0.47642070055007935, 0.4751327633857727, 0.47159725427627563, 0.471792608499527, 0.4673670828342438, 0.4640898108482361, 0.46303245425224304, 0.46605223417282104, 0.4614473879337311, 0.4546738564968109, 0.45295044779777527, 0.46124401688575745, 0.45122572779655457, 0.4522055387496948, 0.45267847180366516, 0.4463047385215759, 0.4475953280925751, 0.44303345680236816, 0.44096839427948, 0.4405035078525543, 0.4354308247566223, 0.4360821843147278, 0.438579797744751, 0.430718332529068, 0.4293767213821411, 0.424845427274704, 0.42022502422332764, 0.4202210605144501, 0.417609304189682, 0.4148316979408264, 0.41331055760383606, 0.40093353390693665, 0.41231563687324524, 0.40702736377716064, 0.3962363302707672, 0.3998051583766937, 0.3974350094795227, 0.4013203978538513, 0.39002206921577454, 0.39187803864479065, 0.38303884863853455, 0.38226518034935, 0.3819938898086548, 0.371971070766449, 0.3733009099960327, 0.36912307143211365, 0.376243531703949, 0.3630515933036804, 0.3619215488433838, 0.35762766003608704, 0.36041051149368286, 0.35507363080978394, 0.35723677277565, 0.3486185073852539, 0.3477005660533905, 0.3433668911457062, 0.3387739360332489, 0.34236952662467957, 0.33732086420059204, 0.33146098256111145, 0.33254918456077576, 0.3356584906578064, 0.32949525117874146, 0.3241730332374573, 0.32321539521217346, 0.3180394470691681, 0.3189302384853363, 0.3374049961566925, 0.3241456151008606, 0.31141197681427, 0.3043910264968872, 0.3072147071361542, 0.3025146424770355, 0.29575416445732117, 0.3009519875049591, 0.30009695887565613, 0.29237809777259827, 0.28645917773246765, 0.2857743501663208, 0.3070375323295593, 0.30454227328300476, 0.28028273582458496, 0.28912919759750366, 0.29002878069877625, 0.2862721085548401, 0.28428104519844055], 'accuracy': [0.5118534564971924, 0.5045797228813171, 0.5441810488700867, 0.6460129022598267, 0.701777994632721, 0.732758641242981, 0.7470366358757019, 0.751347005367279, 0.7570043206214905, 0.7629310488700867, 0.767241358757019, 0.7707435488700867, 0.7739762663841248, 0.7702047228813171, 0.7753232717514038, 0.7769396305084229, 0.7782866358757019, 0.7820581793785095, 0.7839439511299133, 0.787446141242981, 0.7871767282485962, 0.7804418206214905, 0.7882543206214905, 0.7931034564971924, 0.7920258641242981, 0.7879849076271057, 0.7917564511299133, 0.7963362336158752, 0.7912176847457886, 0.7957974076271057, 0.7966055870056152, 0.7949892282485962, 0.7960668206214905, 0.7998383641242981, 0.803071141242981, 0.8001077771186829, 0.7966055870056152, 0.8071120977401733, 0.8041487336158752, 0.8095366358757019, 0.8092672228813171, 0.8087284564971924, 0.8065732717514038, 0.8127694129943848, 0.8114224076271057, 0.8205819129943848, 0.810883641242981, 0.8195043206214905, 0.8246228694915771, 0.8262392282485962, 0.8246228694915771, 0.8200430870056152, 0.8283944129943848, 0.8259698152542114, 0.8318965435028076, 0.826508641242981, 0.828125, 0.8367456793785095, 0.8397090435028076, 0.8378232717514038, 0.8359375, 0.8410560488700867, 0.8405172228813171, 0.8442887663841248, 0.8429418206214905, 0.8464439511299133, 0.8483297228813171, 0.8561422228813171, 0.8521012663841248, 0.860722005367279, 0.8601831793785095, 0.8467133641242981, 0.857758641242981, 0.8599137663841248, 0.8599137663841248, 0.8572198152542114, 0.8604525923728943, 0.860991358757019, 0.8623383641242981, 0.8623383641242981, 0.8617995977401733, 0.8523706793785095, 0.8615301847457886, 0.873652994632721, 0.8731142282485962, 0.8677262663841248, 0.8768857717514038, 0.8760775923728943, 0.8774245977401733, 0.8774245977401733, 0.8801185488700867, 0.8833512663841248, 0.8828125, 0.8728448152542114, 0.8714978694915771, 0.8846982717514038, 0.8822737336158752, 0.8801185488700867, 0.884428858757019, 0.8879310488700867], 'val_loss': [0.6930518746376038, 0.6927802562713623, 0.6922102570533752, 0.6907811760902405, 0.6881551146507263, 0.6827295422554016, 0.6728574633598328, 0.6630513668060303, 0.650021493434906, 0.6433965563774109, 0.6315993070602417, 0.6199547052383423, 0.6052040457725525, 0.5968788266181946, 0.5767144560813904, 0.5625889301300049, 0.5464687943458557, 0.5317391753196716, 0.5143811106681824, 0.499683141708374, 0.4975757896900177, 0.47795677185058594, 0.4707159698009491, 0.4710801839828491, 0.4573395550251007, 0.4574498236179352, 0.4504423439502716, 0.4493076503276825, 0.44676682353019714, 0.44912564754486084, 0.44610127806663513, 0.4442666172981262, 0.4396132826805115, 0.44242343306541443, 0.4354254901409149, 0.4451303482055664, 0.43518301844596863, 0.43750259280204773, 0.42796602845191956, 0.4257505536079407, 0.42420902848243713, 0.4233856499195099, 0.4303465187549591, 0.4191177189350128, 0.42340967059135437, 0.42885705828666687, 0.42136669158935547, 0.41361087560653687, 0.41014283895492554, 0.41824930906295776, 0.40885287523269653, 0.40500354766845703, 0.42226481437683105, 0.41117116808891296, 0.4010533094406128, 0.4144943356513977, 0.3989303410053253, 0.39930135011672974, 0.4007404148578644, 0.409145325422287, 0.3953443765640259, 0.4019387364387512, 0.39403602480888367, 0.4003083407878876, 0.3967764973640442, 0.39966943860054016, 0.39687976241111755, 0.39411288499832153, 0.3944699764251709, 0.40168312191963196, 0.40663209557533264, 0.40310046076774597, 0.39416253566741943, 0.3928091526031494, 0.3910835087299347, 0.4176575839519501, 0.39262938499450684, 0.4018707871437073, 0.3932781219482422, 0.3936803340911865, 0.4023533761501312, 0.408255010843277, 0.4030328094959259, 0.39240211248397827, 0.39650338888168335, 0.39894261956214905, 0.39620110392570496, 0.40084272623062134, 0.4006503224372864, 0.40817126631736755, 0.4015297591686249, 0.401511013507843, 0.4008899927139282, 0.4017113745212555, 0.40633291006088257, 0.4065544903278351, 0.4063049256801605, 0.4007816016674042, 0.422674298286438, 0.4040555953979492], 'val_accuracy': [0.48491379618644714, 0.71875, 0.6400862336158752, 0.625, 0.631465494632721, 0.6519396305084229, 0.6982758641242981, 0.7209051847457886, 0.7489224076271057, 0.7510775923728943, 0.7575430870056152, 0.7683189511299133, 0.7715517282485962, 0.764008641242981, 0.7801724076271057, 0.7801724076271057, 0.7844827771186829, 0.7801724076271057, 0.7887930870056152, 0.7887930870056152, 0.78125, 0.7941810488700867, 0.7887930870056152, 0.787715494632721, 0.7931034564971924, 0.795258641242981, 0.8017241358757019, 0.795258641242981, 0.8038793206214905, 0.7941810488700867, 0.8028017282485962, 0.7974137663841248, 0.806034505367279, 0.8017241358757019, 0.8071120977401733, 0.7974137663841248, 0.8071120977401733, 0.806034505367279, 0.8157327771186829, 0.8146551847457886, 0.8146551847457886, 0.8114224076271057, 0.8103448152542114, 0.8157327771186829, 0.8081896305084229, 0.8092672228813171, 0.8146551847457886, 0.8221982717514038, 0.8157327771186829, 0.818965494632721, 0.8200430870056152, 0.8114224076271057, 0.8211206793785095, 0.8221982717514038, 0.8125, 0.8168103694915771, 0.8168103694915771, 0.818965494632721, 0.818965494632721, 0.8243534564971924, 0.8221982717514038, 0.8157327771186829, 0.8275862336158752, 0.818965494632721, 0.826508641242981, 0.818965494632721, 0.8254310488700867, 0.8308189511299133, 0.8286637663841248, 0.8308189511299133, 0.8232758641242981, 0.8200430870056152, 0.8329741358757019, 0.837284505367279, 0.8340517282485962, 0.8114224076271057, 0.8415948152542114, 0.8318965435028076, 0.837284505367279, 0.8383620977401733, 0.826508641242981, 0.8275862336158752, 0.826508641242981, 0.8351293206214905, 0.8340517282485962, 0.8329741358757019, 0.8362069129943848, 0.8340517282485962, 0.8318965435028076, 0.8351293206214905, 0.8351293206214905, 0.837284505367279, 0.8351293206214905, 0.837284505367279, 0.829741358757019, 0.8286637663841248, 0.8318965435028076, 0.8362069129943848, 0.8200430870056152, 0.837284505367279]}\n","38/38 [==============================] - 1s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.5085"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 14s 217ms/step - loss: 0.6921 - accuracy: 0.5085 - val_loss: 0.6931 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6901 - accuracy: 0.5023 - val_loss: 0.6929 - val_accuracy: 0.6844\n","Epoch 3/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6857 - accuracy: 0.5458 - val_loss: 0.6925 - val_accuracy: 0.6663\n","Epoch 4/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6761 - accuracy: 0.5954 - val_loss: 0.6918 - val_accuracy: 0.5667\n","Epoch 5/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6587 - accuracy: 0.6718 - val_loss: 0.6896 - val_accuracy: 0.6561\n","Epoch 6/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.6308 - accuracy: 0.6967 - val_loss: 0.6876 - val_accuracy: 0.6086\n","Epoch 7/100\n","28/28 [==============================] - 1s 40ms/step - loss: 0.5926 - accuracy: 0.7142 - val_loss: 0.6818 - val_accuracy: 0.6527\n","Epoch 8/100\n","28/28 [==============================] - 1s 45ms/step - loss: 0.5596 - accuracy: 0.7230 - val_loss: 0.6746 - val_accuracy: 0.6708\n","Epoch 9/100\n","28/28 [==============================] - 2s 61ms/step - loss: 0.5398 - accuracy: 0.7295 - val_loss: 0.6639 - val_accuracy: 0.7048\n","Epoch 10/100\n","28/28 [==============================] - 1s 41ms/step - loss: 0.5339 - accuracy: 0.7380 - val_loss: 0.6577 - val_accuracy: 0.7081\n","Epoch 11/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.5310 - accuracy: 0.7419 - val_loss: 0.6493 - val_accuracy: 0.7229\n","Epoch 12/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5203 - accuracy: 0.7473 - val_loss: 0.6428 - val_accuracy: 0.7149\n","Epoch 13/100\n","28/28 [==============================] - 1s 47ms/step - loss: 0.5212 - accuracy: 0.7408 - val_loss: 0.6272 - val_accuracy: 0.7432\n","Epoch 14/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5216 - accuracy: 0.7467 - val_loss: 0.6231 - val_accuracy: 0.7330\n","Epoch 15/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5122 - accuracy: 0.7473 - val_loss: 0.6089 - val_accuracy: 0.7421\n","Epoch 16/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5135 - accuracy: 0.7518 - val_loss: 0.5986 - val_accuracy: 0.7398\n","Epoch 17/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5041 - accuracy: 0.7578 - val_loss: 0.5819 - val_accuracy: 0.7410\n","Epoch 18/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.5035 - accuracy: 0.7544 - val_loss: 0.5698 - val_accuracy: 0.7489\n","Epoch 19/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.5029 - accuracy: 0.7575 - val_loss: 0.5588 - val_accuracy: 0.7557\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4985 - accuracy: 0.7598 - val_loss: 0.5472 - val_accuracy: 0.7545\n","Epoch 21/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4969 - accuracy: 0.7609 - val_loss: 0.5352 - val_accuracy: 0.7500\n","Epoch 22/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4929 - accuracy: 0.7651 - val_loss: 0.5229 - val_accuracy: 0.7523\n","Epoch 23/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4929 - accuracy: 0.7634 - val_loss: 0.5164 - val_accuracy: 0.7534\n","Epoch 24/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.4877 - accuracy: 0.7680 - val_loss: 0.5075 - val_accuracy: 0.7568\n","Epoch 25/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4882 - accuracy: 0.7674 - val_loss: 0.5009 - val_accuracy: 0.7568\n","Epoch 26/100\n","28/28 [==============================] - 1s 53ms/step - loss: 0.4878 - accuracy: 0.7660 - val_loss: 0.5011 - val_accuracy: 0.7613\n","Epoch 27/100\n","28/28 [==============================] - 2s 55ms/step - loss: 0.4813 - accuracy: 0.7680 - val_loss: 0.4950 - val_accuracy: 0.7636\n","Epoch 28/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4759 - accuracy: 0.7688 - val_loss: 0.4904 - val_accuracy: 0.7602\n","Epoch 29/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.4732 - accuracy: 0.7790 - val_loss: 0.4975 - val_accuracy: 0.7658\n","Epoch 30/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4753 - accuracy: 0.7787 - val_loss: 0.4876 - val_accuracy: 0.7613\n","Epoch 31/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.4658 - accuracy: 0.7835 - val_loss: 0.4835 - val_accuracy: 0.7704\n","Epoch 32/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.4680 - accuracy: 0.7821 - val_loss: 0.4827 - val_accuracy: 0.7726\n","Epoch 33/100\n","28/28 [==============================] - 1s 46ms/step - loss: 0.4645 - accuracy: 0.7793 - val_loss: 0.4800 - val_accuracy: 0.7738\n","Epoch 34/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4902 - val_accuracy: 0.7783\n","Epoch 35/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4596 - accuracy: 0.7824 - val_loss: 0.4768 - val_accuracy: 0.7794\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4495 - accuracy: 0.7878 - val_loss: 0.4744 - val_accuracy: 0.7783\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4500 - accuracy: 0.7892 - val_loss: 0.4735 - val_accuracy: 0.7771\n","Epoch 38/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.4427 - accuracy: 0.7929 - val_loss: 0.4770 - val_accuracy: 0.7828\n","Epoch 39/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4405 - accuracy: 0.7991 - val_loss: 0.4796 - val_accuracy: 0.7692\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4418 - accuracy: 0.7968 - val_loss: 0.4745 - val_accuracy: 0.7760\n","Epoch 41/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4363 - accuracy: 0.7977 - val_loss: 0.4720 - val_accuracy: 0.7771\n","Epoch 42/100\n","28/28 [==============================] - 2s 61ms/step - loss: 0.4370 - accuracy: 0.7954 - val_loss: 0.4680 - val_accuracy: 0.7839\n","Epoch 43/100\n","28/28 [==============================] - 1s 51ms/step - loss: 0.4319 - accuracy: 0.8042 - val_loss: 0.4720 - val_accuracy: 0.7771\n","Epoch 44/100\n","28/28 [==============================] - 2s 90ms/step - loss: 0.4266 - accuracy: 0.8053 - val_loss: 0.4627 - val_accuracy: 0.7862\n","Epoch 45/100\n","28/28 [==============================] - 1s 39ms/step - loss: 0.4316 - accuracy: 0.7994 - val_loss: 0.4664 - val_accuracy: 0.7828\n","Epoch 46/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4248 - accuracy: 0.8087 - val_loss: 0.4673 - val_accuracy: 0.7862\n","Epoch 47/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.4154 - accuracy: 0.8161 - val_loss: 0.4620 - val_accuracy: 0.7896\n","Epoch 48/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4099 - accuracy: 0.8166 - val_loss: 0.4626 - val_accuracy: 0.7862\n","Epoch 49/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4109 - accuracy: 0.8186 - val_loss: 0.4608 - val_accuracy: 0.7862\n","Epoch 50/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4137 - accuracy: 0.8118 - val_loss: 0.4597 - val_accuracy: 0.7851\n","Epoch 51/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4090 - accuracy: 0.8132 - val_loss: 0.4577 - val_accuracy: 0.7896\n","Epoch 52/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4024 - accuracy: 0.8206 - val_loss: 0.4583 - val_accuracy: 0.7873\n","Epoch 53/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4052 - accuracy: 0.8113 - val_loss: 0.4596 - val_accuracy: 0.7851\n","Epoch 54/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3922 - accuracy: 0.8268 - val_loss: 0.4701 - val_accuracy: 0.7873\n","Epoch 55/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3945 - accuracy: 0.8260 - val_loss: 0.4582 - val_accuracy: 0.7805\n","Epoch 56/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3884 - accuracy: 0.8263 - val_loss: 0.4565 - val_accuracy: 0.7885\n","Epoch 57/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3980 - accuracy: 0.8229 - val_loss: 0.4550 - val_accuracy: 0.7862\n","Epoch 58/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3864 - accuracy: 0.8214 - val_loss: 0.4746 - val_accuracy: 0.7839\n","Epoch 59/100\n","28/28 [==============================] - 2s 56ms/step - loss: 0.3885 - accuracy: 0.8237 - val_loss: 0.4605 - val_accuracy: 0.7907\n","Epoch 60/100\n","28/28 [==============================] - 1s 51ms/step - loss: 0.3885 - accuracy: 0.8223 - val_loss: 0.4538 - val_accuracy: 0.7828\n","Epoch 61/100\n","28/28 [==============================] - 1s 53ms/step - loss: 0.3772 - accuracy: 0.8319 - val_loss: 0.4567 - val_accuracy: 0.7907\n","Epoch 62/100\n","28/28 [==============================] - 2s 77ms/step - loss: 0.3852 - accuracy: 0.8248 - val_loss: 0.4619 - val_accuracy: 0.7919\n","Epoch 63/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3698 - accuracy: 0.8379 - val_loss: 0.4752 - val_accuracy: 0.7873\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3783 - accuracy: 0.8280 - val_loss: 0.4547 - val_accuracy: 0.7862\n","Epoch 65/100\n","28/28 [==============================] - 1s 48ms/step - loss: 0.3758 - accuracy: 0.8359 - val_loss: 0.4553 - val_accuracy: 0.7998\n","Epoch 66/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.3692 - accuracy: 0.8350 - val_loss: 0.4592 - val_accuracy: 0.7941\n","Epoch 67/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3633 - accuracy: 0.8415 - val_loss: 0.4540 - val_accuracy: 0.7896\n","Epoch 68/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3635 - accuracy: 0.8367 - val_loss: 0.4548 - val_accuracy: 0.7998\n","Epoch 69/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3622 - accuracy: 0.8424 - val_loss: 0.4581 - val_accuracy: 0.7975\n","Epoch 70/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3572 - accuracy: 0.8444 - val_loss: 0.4824 - val_accuracy: 0.7919\n","Epoch 71/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3647 - accuracy: 0.8393 - val_loss: 0.4641 - val_accuracy: 0.7941\n","Epoch 72/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3553 - accuracy: 0.8475 - val_loss: 0.4560 - val_accuracy: 0.7952\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3544 - accuracy: 0.8435 - val_loss: 0.4567 - val_accuracy: 0.7907\n","Epoch 74/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3490 - accuracy: 0.8472 - val_loss: 0.4557 - val_accuracy: 0.7930\n","Epoch 75/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.3413 - accuracy: 0.8514 - val_loss: 0.4558 - val_accuracy: 0.7975\n","Epoch 76/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3444 - accuracy: 0.8537 - val_loss: 0.4757 - val_accuracy: 0.7964\n","Epoch 77/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.3508 - accuracy: 0.8492 - val_loss: 0.4813 - val_accuracy: 0.8009\n","Epoch 78/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3456 - accuracy: 0.8497 - val_loss: 0.4746 - val_accuracy: 0.7998\n","Epoch 79/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3414 - accuracy: 0.8557 - val_loss: 0.4964 - val_accuracy: 0.7907\n","Epoch 80/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3416 - accuracy: 0.8514 - val_loss: 0.4605 - val_accuracy: 0.7975\n","Epoch 81/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3279 - accuracy: 0.8616 - val_loss: 0.4607 - val_accuracy: 0.7998\n","Epoch 82/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3323 - accuracy: 0.8568 - val_loss: 0.4599 - val_accuracy: 0.7986\n","Epoch 83/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.3317 - accuracy: 0.8619 - val_loss: 0.4665 - val_accuracy: 0.8043\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3290 - accuracy: 0.8619 - val_loss: 0.4591 - val_accuracy: 0.7986\n","Epoch 85/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3299 - accuracy: 0.8596 - val_loss: 0.4883 - val_accuracy: 0.7975\n","Epoch 86/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3360 - accuracy: 0.8580 - val_loss: 0.4585 - val_accuracy: 0.7998\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3339 - accuracy: 0.8568 - val_loss: 0.5020 - val_accuracy: 0.7930\n","Epoch 88/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3200 - accuracy: 0.8639 - val_loss: 0.4659 - val_accuracy: 0.7964\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3116 - accuracy: 0.8729 - val_loss: 0.4627 - val_accuracy: 0.8020\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3086 - accuracy: 0.8721 - val_loss: 0.4941 - val_accuracy: 0.7941\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3240 - accuracy: 0.8596 - val_loss: 0.4757 - val_accuracy: 0.8020\n","Epoch 92/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3178 - accuracy: 0.8628 - val_loss: 0.4605 - val_accuracy: 0.7998\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3040 - accuracy: 0.8704 - val_loss: 0.5542 - val_accuracy: 0.7760\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3241 - accuracy: 0.8619 - val_loss: 0.4817 - val_accuracy: 0.8020\n","Epoch 95/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3072 - accuracy: 0.8701 - val_loss: 0.4592 - val_accuracy: 0.8077\n","Epoch 96/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3008 - accuracy: 0.8738 - val_loss: 0.4611 - val_accuracy: 0.8043\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3084 - accuracy: 0.8744 - val_loss: 0.4617 - val_accuracy: 0.7998\n","Epoch 98/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3050 - accuracy: 0.8735 - val_loss: 0.4601 - val_accuracy: 0.8077\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2936 - accuracy: 0.8783 - val_loss: 0.4644 - val_accuracy: 0.8043\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2924 - accuracy: 0.8809 - val_loss: 0.4921 - val_accuracy: 0.7998\n","{'loss': [0.6920925378799438, 0.6901342868804932, 0.68565434217453, 0.676118791103363, 0.6586765050888062, 0.6307681202888489, 0.5925787687301636, 0.5596301555633545, 0.5398234128952026, 0.5338833332061768, 0.5309668183326721, 0.5203332901000977, 0.5212150812149048, 0.5216082334518433, 0.5121632218360901, 0.5134509801864624, 0.5040503740310669, 0.5035356283187866, 0.5029355883598328, 0.4985139071941376, 0.49685296416282654, 0.4929272532463074, 0.4929174780845642, 0.4877464771270752, 0.4881655275821686, 0.487751841545105, 0.4812983274459839, 0.4759279787540436, 0.4731936454772949, 0.4753060042858124, 0.4658094048500061, 0.46796149015426636, 0.4644773602485657, 0.46055832505226135, 0.45963141322135925, 0.44950070977211, 0.44995370507240295, 0.44274893403053284, 0.44051796197891235, 0.44178488850593567, 0.4362969696521759, 0.43704521656036377, 0.43189775943756104, 0.42656952142715454, 0.4316449463367462, 0.42484474182128906, 0.41544631123542786, 0.4099366366863251, 0.4109315872192383, 0.41372916102409363, 0.4090021848678589, 0.402395635843277, 0.4051579236984253, 0.3922167420387268, 0.3945430517196655, 0.38836219906806946, 0.3979848623275757, 0.3864484131336212, 0.3885135352611542, 0.38852331042289734, 0.3772493600845337, 0.38524195551872253, 0.36981120705604553, 0.37827616930007935, 0.37583377957344055, 0.36920005083084106, 0.36330097913742065, 0.3635490834712982, 0.36218321323394775, 0.357222318649292, 0.36469215154647827, 0.3553295433521271, 0.3543804883956909, 0.34898895025253296, 0.34129634499549866, 0.34441590309143066, 0.3507656157016754, 0.3456161618232727, 0.3414139747619629, 0.3415946662425995, 0.32789599895477295, 0.33226829767227173, 0.33170899748802185, 0.3289850950241089, 0.3298874497413635, 0.3359827399253845, 0.3339483439922333, 0.32002270221710205, 0.31159743666648865, 0.30859264731407166, 0.3240406811237335, 0.3178350329399109, 0.3039534091949463, 0.32405662536621094, 0.3071916997432709, 0.3007934093475342, 0.30835846066474915, 0.3050245940685272, 0.2935514450073242, 0.2923746705055237], 'accuracy': [0.5084889531135559, 0.5022637248039246, 0.5458403825759888, 0.5953593850135803, 0.6717600226402283, 0.6966609954833984, 0.7142048478126526, 0.722976803779602, 0.7294849753379822, 0.7379739880561829, 0.7419354915618896, 0.7473118305206299, 0.740803599357605, 0.7467458844184875, 0.7473118305206299, 0.751839280128479, 0.7577815651893616, 0.7543859481811523, 0.757498562335968, 0.7597622871398926, 0.7608941793441772, 0.7651386260986328, 0.7634408473968506, 0.7679682970046997, 0.7674023509025574, 0.7659875750541687, 0.7679682970046997, 0.7688171863555908, 0.7790039777755737, 0.7787209749221802, 0.7835314273834229, 0.7821165919303894, 0.7792869210243225, 0.7829654812812805, 0.7823995351791382, 0.7877758741378784, 0.7891907095909119, 0.7928692698478699, 0.7990944981575012, 0.7968307733535767, 0.7976796627044678, 0.7954159379005432, 0.8041878938674927, 0.8053197264671326, 0.7993775010108948, 0.8087153434753418, 0.8160724639892578, 0.8166383504867554, 0.8186191320419312, 0.8118279576301575, 0.8132427930831909, 0.8205999135971069, 0.8112620115280151, 0.8268251419067383, 0.8259762525558472, 0.826259195804596, 0.8228636384010315, 0.821448802947998, 0.8237125277519226, 0.8222976922988892, 0.831918478012085, 0.8248443603515625, 0.8378607630729675, 0.8279569745063782, 0.8358800411224365, 0.8350311517715454, 0.8415393233299255, 0.8367289304733276, 0.8423882126808167, 0.8443689942359924, 0.839275598526001, 0.8474816083908081, 0.8435201048851013, 0.8471986651420593, 0.8514431118965149, 0.8537068367004395, 0.8491793870925903, 0.8497453331947327, 0.8556876182556152, 0.8514431118965149, 0.8616299033164978, 0.8568194508552551, 0.8619128465652466, 0.8619128465652466, 0.859649121761322, 0.8579513430595398, 0.8568194508552551, 0.8638936281204224, 0.8729485273361206, 0.8720995783805847, 0.859649121761322, 0.8627617359161377, 0.8704017996788025, 0.8619128465652466, 0.8701188564300537, 0.8737974166870117, 0.8743633031845093, 0.8735144138336182, 0.8783248662948608, 0.8808715343475342], 'val_loss': [0.6930589079856873, 0.6928929090499878, 0.6924713850021362, 0.6918214559555054, 0.6896452903747559, 0.6875867247581482, 0.6818477511405945, 0.6746428608894348, 0.6639089584350586, 0.6576637029647827, 0.6493302583694458, 0.6428157091140747, 0.6271885633468628, 0.6230692863464355, 0.6088663935661316, 0.5985547304153442, 0.581923246383667, 0.5697624087333679, 0.5588240623474121, 0.5471652150154114, 0.5351763963699341, 0.5229402184486389, 0.5164178013801575, 0.5074866414070129, 0.500861644744873, 0.501051664352417, 0.4950384199619293, 0.4904063045978546, 0.4974942207336426, 0.48762568831443787, 0.4834626019001007, 0.48268401622772217, 0.4800480902194977, 0.49024805426597595, 0.476793110370636, 0.4743778109550476, 0.47349488735198975, 0.47695186734199524, 0.47958850860595703, 0.4745185077190399, 0.47200244665145874, 0.4680023789405823, 0.47198206186294556, 0.46270620822906494, 0.46638116240501404, 0.4673292636871338, 0.4619845449924469, 0.4625866115093231, 0.4607648253440857, 0.4597390294075012, 0.4577082693576813, 0.45833179354667664, 0.4596368372440338, 0.47008806467056274, 0.4582121968269348, 0.45648854970932007, 0.4549832344055176, 0.47455573081970215, 0.4604658782482147, 0.4537649154663086, 0.45672550797462463, 0.46185386180877686, 0.4752374291419983, 0.45467162132263184, 0.4553232192993164, 0.4592202603816986, 0.4539882242679596, 0.45483773946762085, 0.45811140537261963, 0.4823676645755768, 0.46411409974098206, 0.4559749364852905, 0.45673036575317383, 0.45570436120033264, 0.4558163583278656, 0.4757128655910492, 0.48127034306526184, 0.4745526611804962, 0.4963679909706116, 0.4605005383491516, 0.4606620967388153, 0.45985063910484314, 0.46654635667800903, 0.4591412842273712, 0.4883345663547516, 0.4584796130657196, 0.5020297169685364, 0.4658806025981903, 0.4627489149570465, 0.49407944083213806, 0.47565415501594543, 0.46047070622444153, 0.5541720986366272, 0.48166847229003906, 0.4592033922672272, 0.4611048996448517, 0.46169131994247437, 0.46012505888938904, 0.464399516582489, 0.49206438660621643], 'val_accuracy': [0.4954751133918762, 0.6843891143798828, 0.6662895679473877, 0.5667420625686646, 0.6561086177825928, 0.6085972785949707, 0.6527149081230164, 0.6708144545555115, 0.7047511339187622, 0.7081447839736938, 0.7228506803512573, 0.7149321436882019, 0.7432126402854919, 0.733031690120697, 0.7420814633369446, 0.7398189902305603, 0.7409502267837524, 0.7488687634468079, 0.7556561231613159, 0.7545248866081238, 0.75, 0.7522624731063843, 0.7533936500549316, 0.7567873597145081, 0.7567873597145081, 0.7613122463226318, 0.7635746598243713, 0.7601810097694397, 0.7658371329307556, 0.7613122463226318, 0.7703620195388794, 0.7726244330406189, 0.773755669593811, 0.7782805562019348, 0.779411792755127, 0.7782805562019348, 0.7771493196487427, 0.7828054428100586, 0.7692307829856873, 0.7760180830955505, 0.7771493196487427, 0.7839366793632507, 0.7771493196487427, 0.7861990928649902, 0.7828054428100586, 0.7861990928649902, 0.7895927429199219, 0.7861990928649902, 0.7861990928649902, 0.7850678563117981, 0.7895927429199219, 0.7873303294181824, 0.7850678563117981, 0.7873303294181824, 0.7805429697036743, 0.7884615659713745, 0.7861990928649902, 0.7839366793632507, 0.790723979473114, 0.7828054428100586, 0.790723979473114, 0.7918552160263062, 0.7873303294181824, 0.7861990928649902, 0.7997737526893616, 0.7941176295280457, 0.7895927429199219, 0.7997737526893616, 0.7975113391876221, 0.7918552160263062, 0.7941176295280457, 0.7952488660812378, 0.790723979473114, 0.7929864525794983, 0.7975113391876221, 0.7963801026344299, 0.8009049892425537, 0.7997737526893616, 0.790723979473114, 0.7975113391876221, 0.7997737526893616, 0.7986425161361694, 0.8042986392974854, 0.7986425161361694, 0.7975113391876221, 0.7997737526893616, 0.7929864525794983, 0.7963801026344299, 0.8020362257957458, 0.7941176295280457, 0.8020362257957458, 0.7997737526893616, 0.7760180830955505, 0.8020362257957458, 0.807692289352417, 0.8042986392974854, 0.7997737526893616, 0.807692289352417, 0.8042986392974854, 0.7997737526893616]}\n","45/45 [==============================] - 1s 7ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.6920 - accuracy: 0.5155"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 13s 200ms/step - loss: 0.6920 - accuracy: 0.5155 - val_loss: 0.6931 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 3s 83ms/step - loss: 0.6891 - accuracy: 0.5036 - val_loss: 0.6928 - val_accuracy: 0.6519\n","Epoch 3/100\n","31/31 [==============================] - 2s 65ms/step - loss: 0.6827 - accuracy: 0.5328 - val_loss: 0.6922 - val_accuracy: 0.6560\n","Epoch 4/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6682 - accuracy: 0.6307 - val_loss: 0.6909 - val_accuracy: 0.5992\n","Epoch 5/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6394 - accuracy: 0.6866 - val_loss: 0.6877 - val_accuracy: 0.6178\n","Epoch 6/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5967 - accuracy: 0.7111 - val_loss: 0.6838 - val_accuracy: 0.5971\n","Epoch 7/100\n","31/31 [==============================] - 1s 35ms/step - loss: 0.5593 - accuracy: 0.7310 - val_loss: 0.6730 - val_accuracy: 0.6890\n","Epoch 8/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5394 - accuracy: 0.7377 - val_loss: 0.6682 - val_accuracy: 0.6519\n","Epoch 9/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.5284 - accuracy: 0.7393 - val_loss: 0.6562 - val_accuracy: 0.7293\n","Epoch 10/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.5208 - accuracy: 0.7426 - val_loss: 0.6479 - val_accuracy: 0.7500\n","Epoch 11/100\n","31/31 [==============================] - 1s 37ms/step - loss: 0.5128 - accuracy: 0.7517 - val_loss: 0.6367 - val_accuracy: 0.7665\n","Epoch 12/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.5045 - accuracy: 0.7563 - val_loss: 0.6255 - val_accuracy: 0.7676\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5005 - accuracy: 0.7576 - val_loss: 0.6125 - val_accuracy: 0.7634\n","Epoch 14/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4976 - accuracy: 0.7512 - val_loss: 0.5978 - val_accuracy: 0.7634\n","Epoch 15/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4934 - accuracy: 0.7651 - val_loss: 0.5829 - val_accuracy: 0.7717\n","Epoch 16/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4895 - accuracy: 0.7656 - val_loss: 0.5686 - val_accuracy: 0.7686\n","Epoch 17/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4837 - accuracy: 0.7693 - val_loss: 0.5513 - val_accuracy: 0.7603\n","Epoch 18/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4869 - accuracy: 0.7680 - val_loss: 0.5370 - val_accuracy: 0.7707\n","Epoch 19/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4838 - accuracy: 0.7674 - val_loss: 0.5281 - val_accuracy: 0.7583\n","Epoch 20/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4736 - accuracy: 0.7739 - val_loss: 0.5109 - val_accuracy: 0.7665\n","Epoch 21/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4732 - accuracy: 0.7752 - val_loss: 0.5146 - val_accuracy: 0.7510\n","Epoch 22/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4724 - accuracy: 0.7778 - val_loss: 0.5033 - val_accuracy: 0.7614\n","Epoch 23/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4676 - accuracy: 0.7778 - val_loss: 0.4949 - val_accuracy: 0.7624\n","Epoch 24/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4648 - accuracy: 0.7824 - val_loss: 0.4931 - val_accuracy: 0.7603\n","Epoch 25/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4590 - accuracy: 0.7848 - val_loss: 0.4955 - val_accuracy: 0.7614\n","Epoch 26/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4576 - accuracy: 0.7848 - val_loss: 0.4849 - val_accuracy: 0.7707\n","Epoch 27/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4508 - accuracy: 0.7925 - val_loss: 0.4730 - val_accuracy: 0.7717\n","Epoch 28/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4470 - accuracy: 0.7904 - val_loss: 0.4754 - val_accuracy: 0.7748\n","Epoch 29/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4445 - accuracy: 0.7966 - val_loss: 0.4673 - val_accuracy: 0.7779\n","Epoch 30/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4409 - accuracy: 0.7959 - val_loss: 0.4644 - val_accuracy: 0.7800\n","Epoch 31/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4401 - accuracy: 0.7990 - val_loss: 0.4680 - val_accuracy: 0.7789\n","Epoch 32/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4332 - accuracy: 0.8034 - val_loss: 0.4615 - val_accuracy: 0.7810\n","Epoch 33/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4263 - accuracy: 0.8093 - val_loss: 0.4609 - val_accuracy: 0.7820\n","Epoch 34/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4261 - accuracy: 0.8067 - val_loss: 0.4588 - val_accuracy: 0.7851\n","Epoch 35/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4244 - accuracy: 0.8111 - val_loss: 0.4609 - val_accuracy: 0.7831\n","Epoch 36/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4171 - accuracy: 0.8199 - val_loss: 0.4544 - val_accuracy: 0.7882\n","Epoch 37/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4216 - accuracy: 0.8171 - val_loss: 0.4521 - val_accuracy: 0.7882\n","Epoch 38/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4167 - accuracy: 0.8150 - val_loss: 0.4590 - val_accuracy: 0.7820\n","Epoch 39/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4122 - accuracy: 0.8168 - val_loss: 0.4488 - val_accuracy: 0.7924\n","Epoch 40/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4051 - accuracy: 0.8269 - val_loss: 0.4510 - val_accuracy: 0.7862\n","Epoch 41/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.4026 - accuracy: 0.8189 - val_loss: 0.4442 - val_accuracy: 0.7975\n","Epoch 42/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4059 - accuracy: 0.8178 - val_loss: 0.4745 - val_accuracy: 0.7789\n","Epoch 43/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3965 - accuracy: 0.8235 - val_loss: 0.4442 - val_accuracy: 0.7924\n","Epoch 44/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3980 - accuracy: 0.8202 - val_loss: 0.4422 - val_accuracy: 0.7934\n","Epoch 45/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3940 - accuracy: 0.8307 - val_loss: 0.4393 - val_accuracy: 0.7955\n","Epoch 46/100\n","31/31 [==============================] - 1s 37ms/step - loss: 0.3893 - accuracy: 0.8282 - val_loss: 0.4400 - val_accuracy: 0.7996\n","Epoch 47/100\n","31/31 [==============================] - 1s 35ms/step - loss: 0.3822 - accuracy: 0.8315 - val_loss: 0.4363 - val_accuracy: 0.8017\n","Epoch 48/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3856 - accuracy: 0.8297 - val_loss: 0.4365 - val_accuracy: 0.8017\n","Epoch 49/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3765 - accuracy: 0.8364 - val_loss: 0.4444 - val_accuracy: 0.7975\n","Epoch 50/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3790 - accuracy: 0.8370 - val_loss: 0.4514 - val_accuracy: 0.7893\n","Epoch 51/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3787 - accuracy: 0.8307 - val_loss: 0.4389 - val_accuracy: 0.7986\n","Epoch 52/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.3718 - accuracy: 0.8367 - val_loss: 0.4320 - val_accuracy: 0.8037\n","Epoch 53/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3664 - accuracy: 0.8370 - val_loss: 0.4504 - val_accuracy: 0.7893\n","Epoch 54/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3653 - accuracy: 0.8408 - val_loss: 0.4576 - val_accuracy: 0.7944\n","Epoch 55/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.3655 - accuracy: 0.8437 - val_loss: 0.4301 - val_accuracy: 0.8068\n","Epoch 56/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3597 - accuracy: 0.8439 - val_loss: 0.4337 - val_accuracy: 0.8048\n","Epoch 57/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3554 - accuracy: 0.8491 - val_loss: 0.4320 - val_accuracy: 0.8037\n","Epoch 58/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3602 - accuracy: 0.8444 - val_loss: 0.4402 - val_accuracy: 0.8037\n","Epoch 59/100\n","31/31 [==============================] - 1s 46ms/step - loss: 0.3584 - accuracy: 0.8452 - val_loss: 0.4273 - val_accuracy: 0.8130\n","Epoch 60/100\n","31/31 [==============================] - 2s 60ms/step - loss: 0.3513 - accuracy: 0.8468 - val_loss: 0.4272 - val_accuracy: 0.8089\n","Epoch 61/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3512 - accuracy: 0.8491 - val_loss: 0.4673 - val_accuracy: 0.7810\n","Epoch 62/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.3570 - accuracy: 0.8478 - val_loss: 0.4320 - val_accuracy: 0.8017\n","Epoch 63/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3430 - accuracy: 0.8517 - val_loss: 0.4398 - val_accuracy: 0.7986\n","Epoch 64/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.3443 - accuracy: 0.8512 - val_loss: 0.4256 - val_accuracy: 0.8140\n","Epoch 65/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.3389 - accuracy: 0.8519 - val_loss: 0.4606 - val_accuracy: 0.7851\n","Epoch 66/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3411 - accuracy: 0.8558 - val_loss: 0.4360 - val_accuracy: 0.8006\n","Epoch 67/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3392 - accuracy: 0.8563 - val_loss: 0.4292 - val_accuracy: 0.8058\n","Epoch 68/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3439 - accuracy: 0.8519 - val_loss: 0.4260 - val_accuracy: 0.8099\n","Epoch 69/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3309 - accuracy: 0.8592 - val_loss: 0.4245 - val_accuracy: 0.8120\n","Epoch 70/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3334 - accuracy: 0.8605 - val_loss: 0.4354 - val_accuracy: 0.8027\n","Epoch 71/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3222 - accuracy: 0.8615 - val_loss: 0.4246 - val_accuracy: 0.8099\n","Epoch 72/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3302 - accuracy: 0.8618 - val_loss: 0.4611 - val_accuracy: 0.7913\n","Epoch 73/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3183 - accuracy: 0.8625 - val_loss: 0.4255 - val_accuracy: 0.8079\n","Epoch 74/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3202 - accuracy: 0.8674 - val_loss: 0.4249 - val_accuracy: 0.8079\n","Epoch 75/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3166 - accuracy: 0.8674 - val_loss: 0.4253 - val_accuracy: 0.8058\n","Epoch 76/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3193 - accuracy: 0.8674 - val_loss: 0.4415 - val_accuracy: 0.8027\n","Epoch 77/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3138 - accuracy: 0.8680 - val_loss: 0.4440 - val_accuracy: 0.8027\n","Epoch 78/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3116 - accuracy: 0.8711 - val_loss: 0.4335 - val_accuracy: 0.8068\n","Epoch 79/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.3105 - accuracy: 0.8672 - val_loss: 0.4277 - val_accuracy: 0.8110\n","Epoch 80/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.3104 - accuracy: 0.8698 - val_loss: 0.4422 - val_accuracy: 0.8058\n","Epoch 81/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3078 - accuracy: 0.8664 - val_loss: 0.4317 - val_accuracy: 0.8089\n","Epoch 82/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3112 - accuracy: 0.8690 - val_loss: 0.4274 - val_accuracy: 0.8120\n","Epoch 83/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2988 - accuracy: 0.8765 - val_loss: 0.4427 - val_accuracy: 0.8068\n","Epoch 84/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3050 - accuracy: 0.8718 - val_loss: 0.4347 - val_accuracy: 0.8110\n","Epoch 85/100\n","31/31 [==============================] - 2s 74ms/step - loss: 0.2940 - accuracy: 0.8798 - val_loss: 0.4291 - val_accuracy: 0.8151\n","Epoch 86/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2924 - accuracy: 0.8811 - val_loss: 0.4670 - val_accuracy: 0.8027\n","Epoch 87/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2960 - accuracy: 0.8762 - val_loss: 0.4280 - val_accuracy: 0.8079\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2820 - accuracy: 0.8796 - val_loss: 0.4311 - val_accuracy: 0.8110\n","Epoch 89/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2862 - accuracy: 0.8819 - val_loss: 0.4337 - val_accuracy: 0.8130\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2884 - accuracy: 0.8863 - val_loss: 0.4672 - val_accuracy: 0.7996\n","Epoch 91/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2931 - accuracy: 0.8739 - val_loss: 0.4323 - val_accuracy: 0.8110\n","Epoch 92/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2784 - accuracy: 0.8866 - val_loss: 0.4314 - val_accuracy: 0.8120\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2895 - accuracy: 0.8760 - val_loss: 0.4385 - val_accuracy: 0.8110\n","Epoch 94/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2795 - accuracy: 0.8855 - val_loss: 0.4307 - val_accuracy: 0.8120\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2759 - accuracy: 0.8866 - val_loss: 0.4322 - val_accuracy: 0.8130\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2701 - accuracy: 0.8897 - val_loss: 0.4328 - val_accuracy: 0.8140\n","Epoch 97/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2729 - accuracy: 0.8863 - val_loss: 0.4344 - val_accuracy: 0.8161\n","Epoch 98/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2744 - accuracy: 0.8889 - val_loss: 0.4535 - val_accuracy: 0.8079\n","Epoch 99/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2724 - accuracy: 0.8884 - val_loss: 0.4616 - val_accuracy: 0.8068\n","Epoch 100/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2853 - accuracy: 0.8822 - val_loss: 0.4304 - val_accuracy: 0.8140\n","{'loss': [0.6919817924499512, 0.6891336441040039, 0.6827007532119751, 0.6682233214378357, 0.6393635272979736, 0.5967239737510681, 0.559310793876648, 0.5394214391708374, 0.5283702611923218, 0.5208389163017273, 0.5127776265144348, 0.5044719576835632, 0.5005462169647217, 0.49758481979370117, 0.49339917302131653, 0.489516019821167, 0.4837075471878052, 0.4869447946548462, 0.4837661385536194, 0.47356900572776794, 0.47323188185691833, 0.4723770022392273, 0.4676375687122345, 0.4648118317127228, 0.4589977562427521, 0.45761075615882874, 0.4508160650730133, 0.4469761252403259, 0.4444541037082672, 0.4408639669418335, 0.4401027262210846, 0.4332306981086731, 0.42628559470176697, 0.42614641785621643, 0.4244266152381897, 0.4170955717563629, 0.4216459393501282, 0.4166508615016937, 0.4121626317501068, 0.40513181686401367, 0.4025520086288452, 0.4058545231819153, 0.3964897394180298, 0.3980488181114197, 0.3940139710903168, 0.389332115650177, 0.382229208946228, 0.38557565212249756, 0.37653160095214844, 0.3790258467197418, 0.37867969274520874, 0.3717776834964752, 0.36636883020401, 0.3653169870376587, 0.3654608130455017, 0.3596780598163605, 0.3553640842437744, 0.3602483570575714, 0.3583954870700836, 0.3513403832912445, 0.35117560625076294, 0.35703960061073303, 0.3429761230945587, 0.3442569375038147, 0.3388718068599701, 0.3411351442337036, 0.33922603726387024, 0.34389105439186096, 0.33086663484573364, 0.3333684802055359, 0.3222409188747406, 0.3301525115966797, 0.3182714283466339, 0.32016658782958984, 0.31657615303993225, 0.3193301260471344, 0.31377869844436646, 0.31158173084259033, 0.3105364739894867, 0.310374915599823, 0.3078456223011017, 0.31120532751083374, 0.29884716868400574, 0.3049606680870056, 0.29399430751800537, 0.29236793518066406, 0.2960350811481476, 0.2819981276988983, 0.2861768901348114, 0.28840160369873047, 0.2931317389011383, 0.2783993184566498, 0.28948724269866943, 0.27951881289482117, 0.27587202191352844, 0.2701244056224823, 0.27289822697639465, 0.27443066239356995, 0.27244889736175537, 0.28530725836753845], 'accuracy': [0.5155038833618164, 0.5036175847053528, 0.5328165292739868, 0.6307493448257446, 0.6865633130073547, 0.7111111283302307, 0.7310077548027039, 0.737726092338562, 0.7392764687538147, 0.7426356673240662, 0.7516795992851257, 0.7563307285308838, 0.7576227188110352, 0.7511627674102783, 0.765116274356842, 0.7656330466270447, 0.7692506313323975, 0.7679586410522461, 0.7674418687820435, 0.7739018201828003, 0.7751938104629517, 0.7777777910232544, 0.7777777910232544, 0.7824289202690125, 0.7847545146942139, 0.7847545146942139, 0.7925064563751221, 0.790439248085022, 0.7966408133506775, 0.7958656549453735, 0.7989664077758789, 0.8033591508865356, 0.8093023300170898, 0.8067183494567871, 0.8111110925674438, 0.8198966383934021, 0.817054271697998, 0.814987063407898, 0.8167958855628967, 0.8268733620643616, 0.818863034248352, 0.817829430103302, 0.8235142230987549, 0.8201550245285034, 0.8307493329048157, 0.8281653523445129, 0.8315245509147644, 0.8297157883644104, 0.8364341259002686, 0.8369508981704712, 0.8307493329048157, 0.8366925120353699, 0.8369508981704712, 0.8408268690109253, 0.8436692357063293, 0.8439276218414307, 0.8490955829620361, 0.8444444537162781, 0.845219612121582, 0.8467700481414795, 0.8490955829620361, 0.8478035926818848, 0.8516795635223389, 0.8511627912521362, 0.851938009262085, 0.8558139801025391, 0.8563307523727417, 0.851938009262085, 0.8591731190681458, 0.8604651093482971, 0.8614987134933472, 0.8617570996284485, 0.8625323176383972, 0.8674418330192566, 0.8674418330192566, 0.8674418330192566, 0.867958664894104, 0.8710594177246094, 0.8671834468841553, 0.869767427444458, 0.8664082884788513, 0.868992269039154, 0.8764857649803162, 0.8718346357345581, 0.8798449635505676, 0.881136953830719, 0.8762273788452148, 0.8795865774154663, 0.8819121718406677, 0.8863049149513245, 0.8739017844200134, 0.8865633010864258, 0.8759689927101135, 0.8855296969413757, 0.8865633010864258, 0.8896640539169312, 0.8863049149513245, 0.8888888955116272, 0.8883720636367798, 0.882170557975769], 'val_loss': [0.6930627822875977, 0.6928281784057617, 0.6921930909156799, 0.6909397840499878, 0.6877190470695496, 0.6838325262069702, 0.6729531288146973, 0.6681880950927734, 0.656226634979248, 0.6479226350784302, 0.636668860912323, 0.6254744529724121, 0.6125405430793762, 0.5978225469589233, 0.5829230546951294, 0.5686297416687012, 0.5513105392456055, 0.5370087623596191, 0.528128445148468, 0.5109278559684753, 0.5146368145942688, 0.5033497214317322, 0.4949394762516022, 0.4931238293647766, 0.4954938590526581, 0.48487502336502075, 0.47297775745391846, 0.4753933250904083, 0.46730053424835205, 0.46436989307403564, 0.46803492307662964, 0.46147871017456055, 0.4609094560146332, 0.4588082432746887, 0.4608931243419647, 0.45436039566993713, 0.4520719349384308, 0.4589802026748657, 0.4488157033920288, 0.4510224163532257, 0.44420579075813293, 0.47445258498191833, 0.4441928565502167, 0.4422152042388916, 0.43926283717155457, 0.4400119185447693, 0.4362682104110718, 0.43649399280548096, 0.44438454508781433, 0.45139768719673157, 0.4389265775680542, 0.43196651339530945, 0.4504249691963196, 0.45760786533355713, 0.43006908893585205, 0.4336957633495331, 0.43199700117111206, 0.44018176198005676, 0.42731302976608276, 0.4271811842918396, 0.4672803282737732, 0.43202513456344604, 0.43978312611579895, 0.42561718821525574, 0.46062490344047546, 0.4360446035861969, 0.42915380001068115, 0.4259725511074066, 0.42449668049812317, 0.4353853464126587, 0.4245851933956146, 0.461071640253067, 0.4254525303840637, 0.4249137043952942, 0.4252575635910034, 0.4414699375629425, 0.4440007507801056, 0.4335083067417145, 0.42769762873649597, 0.442195862531662, 0.43168753385543823, 0.42736655473709106, 0.4427037537097931, 0.43472403287887573, 0.4291307032108307, 0.46696144342422485, 0.42802894115448, 0.431140273809433, 0.43367913365364075, 0.4672217071056366, 0.4322590231895447, 0.4314243197441101, 0.43849724531173706, 0.430708110332489, 0.4322405457496643, 0.4328117072582245, 0.4343709349632263, 0.45347875356674194, 0.461570680141449, 0.43037426471710205], 'val_accuracy': [0.48553720116615295, 0.6518595218658447, 0.6559917330741882, 0.5991735458374023, 0.6177685856819153, 0.5971074104309082, 0.6890496015548706, 0.6518595218658447, 0.7293388247489929, 0.75, 0.7665289044380188, 0.7675619721412659, 0.7634297609329224, 0.7634297609329224, 0.7716942429542542, 0.7685950398445129, 0.7603305578231812, 0.7706611752510071, 0.7582644820213318, 0.7665289044380188, 0.7510330677032471, 0.7613636255264282, 0.7623966932296753, 0.7603305578231812, 0.7613636255264282, 0.7706611752510071, 0.7716942429542542, 0.7747933864593506, 0.7778925895690918, 0.7799586653709412, 0.7789255976676941, 0.7809917330741882, 0.7820248007774353, 0.7851239442825317, 0.7830578684806824, 0.788223147392273, 0.788223147392273, 0.7820248007774353, 0.7923553586006165, 0.7861570119857788, 0.797520637512207, 0.7789255976676941, 0.7923553586006165, 0.7933884263038635, 0.7954545617103577, 0.7995867729187012, 0.8016529083251953, 0.8016529083251953, 0.797520637512207, 0.78925621509552, 0.7985537052154541, 0.8037189841270447, 0.78925621509552, 0.7944214940071106, 0.8068181872367859, 0.8047520518302917, 0.8037189841270447, 0.8037189841270447, 0.8130165338516235, 0.80888432264328, 0.7809917330741882, 0.8016529083251953, 0.7985537052154541, 0.8140496015548706, 0.7851239442825317, 0.8006198406219482, 0.8057851195335388, 0.8099173307418823, 0.8119834661483765, 0.8026859760284424, 0.8099173307418823, 0.7913222908973694, 0.807851254940033, 0.807851254940033, 0.8057851195335388, 0.8026859760284424, 0.8026859760284424, 0.8068181872367859, 0.8109503984451294, 0.8057851195335388, 0.80888432264328, 0.8119834661483765, 0.8068181872367859, 0.8109503984451294, 0.8150826692581177, 0.8026859760284424, 0.807851254940033, 0.8109503984451294, 0.8130165338516235, 0.7995867729187012, 0.8109503984451294, 0.8119834661483765, 0.8109503984451294, 0.8119834661483765, 0.8130165338516235, 0.8140496015548706, 0.81611567735672, 0.807851254940033, 0.8068181872367859, 0.8140496015548706]}\n","32/32 [==============================] - 1s 10ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.3594 - accuracy: 0.8499"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 20s 413ms/step - loss: 0.3571 - accuracy: 0.8516 - val_loss: 0.6963 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3501 - accuracy: 0.8518 - val_loss: 0.6957 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3422 - accuracy: 0.8518 - val_loss: 0.6949 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3379 - accuracy: 0.8513 - val_loss: 0.6925 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3371 - accuracy: 0.8605 - val_loss: 0.6882 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3304 - accuracy: 0.8605 - val_loss: 0.6851 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3346 - accuracy: 0.8602 - val_loss: 0.6778 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 2s 58ms/step - loss: 0.3224 - accuracy: 0.8650 - val_loss: 0.6617 - val_accuracy: 0.4871\n","Epoch 9/100\n","29/29 [==============================] - 1s 39ms/step - loss: 0.3159 - accuracy: 0.8677 - val_loss: 0.6569 - val_accuracy: 0.4881\n","Epoch 10/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.3142 - accuracy: 0.8710 - val_loss: 0.6372 - val_accuracy: 0.5065\n","Epoch 11/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3162 - accuracy: 0.8677 - val_loss: 0.6302 - val_accuracy: 0.5065\n","Epoch 12/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3163 - accuracy: 0.8605 - val_loss: 0.6117 - val_accuracy: 0.5442\n","Epoch 13/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3128 - accuracy: 0.8696 - val_loss: 0.5999 - val_accuracy: 0.5668\n","Epoch 14/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3159 - accuracy: 0.8602 - val_loss: 0.5649 - val_accuracy: 0.7597\n","Epoch 15/100\n","29/29 [==============================] - 3s 97ms/step - loss: 0.3058 - accuracy: 0.8737 - val_loss: 0.5481 - val_accuracy: 0.7619\n","Epoch 16/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.2986 - accuracy: 0.8766 - val_loss: 0.5249 - val_accuracy: 0.7856\n","Epoch 17/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.2941 - accuracy: 0.8739 - val_loss: 0.5037 - val_accuracy: 0.7931\n","Epoch 18/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3015 - accuracy: 0.8750 - val_loss: 0.4611 - val_accuracy: 0.8459\n","Epoch 19/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2872 - accuracy: 0.8780 - val_loss: 0.4912 - val_accuracy: 0.7662\n","Epoch 20/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3047 - accuracy: 0.8707 - val_loss: 0.4104 - val_accuracy: 0.8556\n","Epoch 21/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.2869 - accuracy: 0.8828 - val_loss: 0.3958 - val_accuracy: 0.8567\n","Epoch 22/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.2833 - accuracy: 0.8858 - val_loss: 0.3810 - val_accuracy: 0.8578\n","Epoch 23/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2871 - accuracy: 0.8782 - val_loss: 0.3764 - val_accuracy: 0.8470\n","Epoch 24/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2835 - accuracy: 0.8793 - val_loss: 0.3458 - val_accuracy: 0.8567\n","Epoch 25/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.2797 - accuracy: 0.8879 - val_loss: 0.3450 - val_accuracy: 0.8599\n","Epoch 26/100\n","29/29 [==============================] - 1s 35ms/step - loss: 0.2806 - accuracy: 0.8844 - val_loss: 0.3438 - val_accuracy: 0.8610\n","Epoch 27/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2723 - accuracy: 0.8914 - val_loss: 0.3410 - val_accuracy: 0.8578\n","Epoch 28/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2734 - accuracy: 0.8898 - val_loss: 0.4119 - val_accuracy: 0.8244\n","Epoch 29/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2875 - accuracy: 0.8828 - val_loss: 0.3540 - val_accuracy: 0.8481\n","Epoch 30/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2850 - accuracy: 0.8809 - val_loss: 0.3518 - val_accuracy: 0.8545\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2717 - accuracy: 0.8922 - val_loss: 0.3541 - val_accuracy: 0.8567\n","Epoch 32/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2697 - accuracy: 0.8901 - val_loss: 0.3726 - val_accuracy: 0.8416\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2611 - accuracy: 0.8920 - val_loss: 0.3385 - val_accuracy: 0.8599\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2572 - accuracy: 0.8939 - val_loss: 0.3410 - val_accuracy: 0.8578\n","Epoch 35/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2516 - accuracy: 0.8995 - val_loss: 0.3419 - val_accuracy: 0.8599\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2518 - accuracy: 0.9014 - val_loss: 0.3500 - val_accuracy: 0.8588\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2573 - accuracy: 0.8960 - val_loss: 0.3464 - val_accuracy: 0.8599\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2522 - accuracy: 0.9025 - val_loss: 0.3498 - val_accuracy: 0.8556\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2570 - accuracy: 0.8976 - val_loss: 0.3650 - val_accuracy: 0.8534\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2456 - accuracy: 0.9022 - val_loss: 0.3463 - val_accuracy: 0.8599\n","Epoch 41/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2411 - accuracy: 0.9071 - val_loss: 0.3496 - val_accuracy: 0.8588\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2444 - accuracy: 0.9049 - val_loss: 0.3525 - val_accuracy: 0.8567\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2332 - accuracy: 0.9095 - val_loss: 0.3622 - val_accuracy: 0.8567\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2307 - accuracy: 0.9081 - val_loss: 0.3511 - val_accuracy: 0.8599\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2325 - accuracy: 0.9089 - val_loss: 0.3602 - val_accuracy: 0.8534\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2305 - accuracy: 0.9122 - val_loss: 0.3506 - val_accuracy: 0.8610\n","Epoch 47/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2332 - accuracy: 0.9052 - val_loss: 0.3807 - val_accuracy: 0.8491\n","Epoch 48/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2277 - accuracy: 0.9162 - val_loss: 0.3669 - val_accuracy: 0.8534\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2243 - accuracy: 0.9106 - val_loss: 0.3657 - val_accuracy: 0.8567\n","Epoch 50/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2210 - accuracy: 0.9108 - val_loss: 0.3564 - val_accuracy: 0.8578\n","Epoch 51/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2190 - accuracy: 0.9135 - val_loss: 0.3737 - val_accuracy: 0.8481\n","Epoch 52/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2389 - accuracy: 0.9014 - val_loss: 0.4574 - val_accuracy: 0.8254\n","Epoch 53/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2220 - accuracy: 0.9151 - val_loss: 0.3585 - val_accuracy: 0.8599\n","Epoch 54/100\n","29/29 [==============================] - 2s 70ms/step - loss: 0.2067 - accuracy: 0.9224 - val_loss: 0.3591 - val_accuracy: 0.8621\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2034 - accuracy: 0.9262 - val_loss: 0.3580 - val_accuracy: 0.8599\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2046 - accuracy: 0.9181 - val_loss: 0.3650 - val_accuracy: 0.8567\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2063 - accuracy: 0.9211 - val_loss: 0.3615 - val_accuracy: 0.8610\n","Epoch 58/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.2037 - accuracy: 0.9197 - val_loss: 0.3595 - val_accuracy: 0.8642\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2084 - accuracy: 0.9192 - val_loss: 0.3716 - val_accuracy: 0.8567\n","Epoch 60/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1912 - accuracy: 0.9278 - val_loss: 0.3652 - val_accuracy: 0.8578\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1915 - accuracy: 0.9267 - val_loss: 0.3959 - val_accuracy: 0.8438\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1889 - accuracy: 0.9340 - val_loss: 0.3852 - val_accuracy: 0.8524\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2002 - accuracy: 0.9246 - val_loss: 0.4362 - val_accuracy: 0.8319\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1925 - accuracy: 0.9267 - val_loss: 0.3850 - val_accuracy: 0.8524\n","Epoch 65/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1905 - accuracy: 0.9265 - val_loss: 0.3658 - val_accuracy: 0.8610\n","Epoch 66/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1840 - accuracy: 0.9310 - val_loss: 0.3689 - val_accuracy: 0.8567\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1812 - accuracy: 0.9329 - val_loss: 0.4430 - val_accuracy: 0.8297\n","Epoch 68/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1921 - accuracy: 0.9205 - val_loss: 0.3786 - val_accuracy: 0.8556\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1844 - accuracy: 0.9267 - val_loss: 0.3943 - val_accuracy: 0.8502\n","Epoch 70/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1786 - accuracy: 0.9348 - val_loss: 0.3804 - val_accuracy: 0.8578\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1966 - accuracy: 0.9273 - val_loss: 0.4563 - val_accuracy: 0.8308\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1942 - accuracy: 0.9248 - val_loss: 0.3858 - val_accuracy: 0.8545\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1663 - accuracy: 0.9437 - val_loss: 0.3898 - val_accuracy: 0.8502\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1620 - accuracy: 0.9432 - val_loss: 0.3852 - val_accuracy: 0.8578\n","Epoch 75/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1611 - accuracy: 0.9421 - val_loss: 0.3802 - val_accuracy: 0.8556\n","Epoch 76/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1648 - accuracy: 0.9407 - val_loss: 0.3849 - val_accuracy: 0.8556\n","Epoch 77/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1693 - accuracy: 0.9372 - val_loss: 0.4737 - val_accuracy: 0.8276\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1880 - accuracy: 0.9270 - val_loss: 0.4046 - val_accuracy: 0.8556\n","Epoch 79/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1592 - accuracy: 0.9450 - val_loss: 0.4007 - val_accuracy: 0.8545\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1521 - accuracy: 0.9432 - val_loss: 0.4049 - val_accuracy: 0.8524\n","Epoch 81/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1855 - accuracy: 0.9286 - val_loss: 0.4428 - val_accuracy: 0.8362\n","Epoch 82/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1785 - accuracy: 0.9305 - val_loss: 0.4986 - val_accuracy: 0.8297\n","Epoch 83/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.1709 - accuracy: 0.9359 - val_loss: 0.4157 - val_accuracy: 0.8481\n","Epoch 84/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1559 - accuracy: 0.9434 - val_loss: 0.4358 - val_accuracy: 0.8438\n","Epoch 85/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1567 - accuracy: 0.9415 - val_loss: 0.3988 - val_accuracy: 0.8567\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1415 - accuracy: 0.9488 - val_loss: 0.4068 - val_accuracy: 0.8524\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1482 - accuracy: 0.9440 - val_loss: 0.4676 - val_accuracy: 0.8394\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1581 - accuracy: 0.9429 - val_loss: 0.3942 - val_accuracy: 0.8610\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1404 - accuracy: 0.9496 - val_loss: 0.4013 - val_accuracy: 0.8556\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1516 - accuracy: 0.9410 - val_loss: 0.4475 - val_accuracy: 0.8427\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1412 - accuracy: 0.9480 - val_loss: 0.4765 - val_accuracy: 0.8287\n","Epoch 92/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1433 - accuracy: 0.9483 - val_loss: 0.4056 - val_accuracy: 0.8556\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1376 - accuracy: 0.9496 - val_loss: 0.4281 - val_accuracy: 0.8524\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1353 - accuracy: 0.9534 - val_loss: 0.4091 - val_accuracy: 0.8534\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1391 - accuracy: 0.9499 - val_loss: 0.4494 - val_accuracy: 0.8427\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1358 - accuracy: 0.9504 - val_loss: 0.4879 - val_accuracy: 0.8341\n","Epoch 97/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1336 - accuracy: 0.9504 - val_loss: 0.4135 - val_accuracy: 0.8588\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1234 - accuracy: 0.9569 - val_loss: 0.4246 - val_accuracy: 0.8524\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1274 - accuracy: 0.9561 - val_loss: 0.4648 - val_accuracy: 0.8351\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1211 - accuracy: 0.9591 - val_loss: 0.4241 - val_accuracy: 0.8621\n","{'loss': [0.3571048080921173, 0.3501301109790802, 0.3421500623226166, 0.3378530740737915, 0.3370574116706848, 0.3304194211959839, 0.3345755934715271, 0.32244619727134705, 0.31587502360343933, 0.3141760528087616, 0.3161774277687073, 0.31628552079200745, 0.31283697485923767, 0.31593748927116394, 0.3057524859905243, 0.2986109256744385, 0.2940901815891266, 0.3015485107898712, 0.28724998235702515, 0.30467477440834045, 0.28687259554862976, 0.28325656056404114, 0.28711268305778503, 0.2835169732570648, 0.27968522906303406, 0.28064659237861633, 0.27231982350349426, 0.27336055040359497, 0.2875310778617859, 0.2849913537502289, 0.2716690003871918, 0.26968643069267273, 0.26110121607780457, 0.25722864270210266, 0.2516280710697174, 0.2518168091773987, 0.25729900598526, 0.25219103693962097, 0.2570132911205292, 0.2455698698759079, 0.24112652242183685, 0.2443995475769043, 0.23319731652736664, 0.23073065280914307, 0.2324724793434143, 0.23048372566699982, 0.23318952322006226, 0.22773844003677368, 0.22426849603652954, 0.22095811367034912, 0.21895775198936462, 0.23886968195438385, 0.2220352739095688, 0.20671221613883972, 0.2034335732460022, 0.2045726776123047, 0.20625248551368713, 0.2037176638841629, 0.20838995277881622, 0.19124402105808258, 0.19145262241363525, 0.18888607621192932, 0.20020373165607452, 0.19245661795139313, 0.19053474068641663, 0.1840030550956726, 0.18117554485797882, 0.1921084225177765, 0.1844392716884613, 0.1785828322172165, 0.19656985998153687, 0.19422703981399536, 0.1663248986005783, 0.16199849545955658, 0.1610514223575592, 0.16476619243621826, 0.16934703290462494, 0.1880243718624115, 0.1592060923576355, 0.1521381288766861, 0.1855120062828064, 0.17851266264915466, 0.17086996138095856, 0.15586164593696594, 0.15668855607509613, 0.14150801301002502, 0.14819194376468658, 0.15808963775634766, 0.14043954014778137, 0.15161839127540588, 0.14121440052986145, 0.14328815042972565, 0.13764600455760956, 0.13525496423244476, 0.13906803727149963, 0.13576920330524445, 0.13362187147140503, 0.12338235974311829, 0.127386212348938, 0.12113720923662186], 'accuracy': [0.8515625, 0.8518319129943848, 0.8518319129943848, 0.8512930870056152, 0.8604525923728943, 0.8604525923728943, 0.8601831793785095, 0.8650323152542114, 0.8677262663841248, 0.8709590435028076, 0.8677262663841248, 0.8604525923728943, 0.8696120977401733, 0.8601831793785095, 0.873652994632721, 0.876616358757019, 0.8739224076271057, 0.875, 0.8779633641242981, 0.8706896305084229, 0.8828125, 0.8857758641242981, 0.8782327771186829, 0.8793103694915771, 0.8879310488700867, 0.884428858757019, 0.8914331793785095, 0.8898168206214905, 0.8828125, 0.8809267282485962, 0.892241358757019, 0.8900862336158752, 0.891972005367279, 0.8938577771186829, 0.8995150923728943, 0.9014008641242981, 0.8960129022598267, 0.9024784564971924, 0.8976293206214905, 0.9022090435028076, 0.9070581793785095, 0.904902994632721, 0.9094827771186829, 0.9081357717514038, 0.9089439511299133, 0.9121767282485962, 0.9051724076271057, 0.9162176847457886, 0.9105603694915771, 0.9108297228813171, 0.9135237336158752, 0.9014008641242981, 0.9151400923728943, 0.9224137663841248, 0.9261853694915771, 0.9181034564971924, 0.9210668206214905, 0.9197198152542114, 0.9191810488700867, 0.9278017282485962, 0.9267241358757019, 0.9339978694915771, 0.9245689511299133, 0.9267241358757019, 0.9264547228813171, 0.931034505367279, 0.9329202771186829, 0.920527994632721, 0.9267241358757019, 0.9348060488700867, 0.9272629022598267, 0.9248383641242981, 0.943696141242981, 0.9431573152542114, 0.9420797228813171, 0.9407327771186829, 0.9372305870056152, 0.9269935488700867, 0.9450430870056152, 0.9431573152542114, 0.9286099076271057, 0.9304956793785095, 0.935883641242981, 0.9434267282485962, 0.9415409564971924, 0.9488146305084229, 0.943965494632721, 0.9428879022598267, 0.9496228694915771, 0.9410021305084229, 0.9480064511299133, 0.9482758641242981, 0.9496228694915771, 0.9533944129943848, 0.9498922228813171, 0.9504310488700867, 0.9504310488700867, 0.9568965435028076, 0.9560883641242981, 0.9590517282485962], 'val_loss': [0.6962693929672241, 0.6956623196601868, 0.6948612928390503, 0.6924922466278076, 0.6882025599479675, 0.6851209998130798, 0.6778379082679749, 0.6617022752761841, 0.6568892002105713, 0.6371934413909912, 0.6302295923233032, 0.6117460131645203, 0.5998790860176086, 0.564911961555481, 0.5481455326080322, 0.5249494910240173, 0.5037006139755249, 0.4611057937145233, 0.4911564886569977, 0.4104166030883789, 0.39575517177581787, 0.38100922107696533, 0.37637415528297424, 0.3457726538181305, 0.34496667981147766, 0.34377482533454895, 0.3410150706768036, 0.41187962889671326, 0.35396137833595276, 0.3517560660839081, 0.3540871739387512, 0.37255915999412537, 0.3385404944419861, 0.34095820784568787, 0.34185972809791565, 0.35002169013023376, 0.3463760018348694, 0.34981831908226013, 0.3649897873401642, 0.3463452458381653, 0.3496313989162445, 0.35249388217926025, 0.3622443675994873, 0.3511117100715637, 0.36021551489830017, 0.3506292998790741, 0.380664199590683, 0.36686909198760986, 0.36573153734207153, 0.3564472496509552, 0.373687744140625, 0.45739978551864624, 0.3585384488105774, 0.3591022789478302, 0.3579613268375397, 0.3650228679180145, 0.3615454435348511, 0.3595304787158966, 0.3716432750225067, 0.36520248651504517, 0.39593613147735596, 0.38524600863456726, 0.43616172671318054, 0.38504335284233093, 0.36578768491744995, 0.3689156770706177, 0.44304075837135315, 0.37862974405288696, 0.394331693649292, 0.3803754448890686, 0.45628589391708374, 0.3858043849468231, 0.3897782266139984, 0.38520824909210205, 0.3801901936531067, 0.3848615288734436, 0.47370728850364685, 0.4046361446380615, 0.40066882967948914, 0.4049396812915802, 0.44277065992355347, 0.498639851808548, 0.4157339334487915, 0.4357779026031494, 0.3988235592842102, 0.4067559838294983, 0.46761468052864075, 0.3941704332828522, 0.4013124108314514, 0.4475240409374237, 0.4765385687351227, 0.40564611554145813, 0.42812907695770264, 0.40914610028266907, 0.4494065046310425, 0.4879031479358673, 0.4134651720523834, 0.4245690405368805, 0.4647883474826813, 0.42411521077156067], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48706895112991333, 0.4881465435028076, 0.506465494632721, 0.506465494632721, 0.5441810488700867, 0.5668103694915771, 0.7596982717514038, 0.7618534564971924, 0.7855603694915771, 0.7931034564971924, 0.8459051847457886, 0.7661637663841248, 0.8556034564971924, 0.8566810488700867, 0.857758641242981, 0.8469827771186829, 0.8566810488700867, 0.8599137663841248, 0.860991358757019, 0.857758641242981, 0.8243534564971924, 0.8480603694915771, 0.8545258641242981, 0.8566810488700867, 0.8415948152542114, 0.8599137663841248, 0.857758641242981, 0.8599137663841248, 0.8588362336158752, 0.8599137663841248, 0.8556034564971924, 0.8534482717514038, 0.8599137663841248, 0.8588362336158752, 0.8566810488700867, 0.8566810488700867, 0.8599137663841248, 0.8534482717514038, 0.860991358757019, 0.8491379022598267, 0.8534482717514038, 0.8566810488700867, 0.857758641242981, 0.8480603694915771, 0.8254310488700867, 0.8599137663841248, 0.8620689511299133, 0.8599137663841248, 0.8566810488700867, 0.860991358757019, 0.8642241358757019, 0.8566810488700867, 0.857758641242981, 0.84375, 0.8523706793785095, 0.8318965435028076, 0.8523706793785095, 0.860991358757019, 0.8566810488700867, 0.829741358757019, 0.8556034564971924, 0.850215494632721, 0.857758641242981, 0.8308189511299133, 0.8545258641242981, 0.850215494632721, 0.857758641242981, 0.8556034564971924, 0.8556034564971924, 0.8275862336158752, 0.8556034564971924, 0.8545258641242981, 0.8523706793785095, 0.8362069129943848, 0.829741358757019, 0.8480603694915771, 0.84375, 0.8566810488700867, 0.8523706793785095, 0.8394396305084229, 0.860991358757019, 0.8556034564971924, 0.8426724076271057, 0.8286637663841248, 0.8556034564971924, 0.8523706793785095, 0.8534482717514038, 0.8426724076271057, 0.8340517282485962, 0.8588362336158752, 0.8523706793785095, 0.8351293206214905, 0.8620689511299133]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.3756 - accuracy: 0.8370"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 13s 207ms/step - loss: 0.3756 - accuracy: 0.8370 - val_loss: 0.6947 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3693 - accuracy: 0.8336 - val_loss: 0.6944 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3673 - accuracy: 0.8342 - val_loss: 0.6932 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3554 - accuracy: 0.8418 - val_loss: 0.6923 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3448 - accuracy: 0.8497 - val_loss: 0.6899 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3476 - accuracy: 0.8500 - val_loss: 0.6846 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3362 - accuracy: 0.8591 - val_loss: 0.6733 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3464 - accuracy: 0.8486 - val_loss: 0.6702 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.3373 - accuracy: 0.8548 - val_loss: 0.6561 - val_accuracy: 0.4977\n","Epoch 10/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.3361 - accuracy: 0.8531 - val_loss: 0.6461 - val_accuracy: 0.5102\n","Epoch 11/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.3336 - accuracy: 0.8548 - val_loss: 0.6320 - val_accuracy: 0.5452\n","Epoch 12/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3293 - accuracy: 0.8540 - val_loss: 0.6254 - val_accuracy: 0.5305\n","Epoch 13/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3210 - accuracy: 0.8647 - val_loss: 0.6092 - val_accuracy: 0.5837\n","Epoch 14/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3244 - accuracy: 0.8585 - val_loss: 0.5815 - val_accuracy: 0.7364\n","Epoch 15/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3157 - accuracy: 0.8639 - val_loss: 0.5681 - val_accuracy: 0.7229\n","Epoch 16/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3212 - accuracy: 0.8613 - val_loss: 0.5569 - val_accuracy: 0.7081\n","Epoch 17/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3197 - accuracy: 0.8630 - val_loss: 0.5142 - val_accuracy: 0.8156\n","Epoch 18/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3177 - accuracy: 0.8645 - val_loss: 0.5369 - val_accuracy: 0.7036\n","Epoch 19/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3213 - accuracy: 0.8630 - val_loss: 0.4712 - val_accuracy: 0.8201\n","Epoch 20/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3153 - accuracy: 0.8690 - val_loss: 0.4682 - val_accuracy: 0.8054\n","Epoch 21/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3101 - accuracy: 0.8741 - val_loss: 0.4429 - val_accuracy: 0.8156\n","Epoch 22/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3032 - accuracy: 0.8741 - val_loss: 0.4293 - val_accuracy: 0.8133\n","Epoch 23/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3015 - accuracy: 0.8715 - val_loss: 0.4206 - val_accuracy: 0.8156\n","Epoch 24/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3092 - accuracy: 0.8664 - val_loss: 0.4078 - val_accuracy: 0.8190\n","Epoch 25/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2948 - accuracy: 0.8780 - val_loss: 0.3968 - val_accuracy: 0.8247\n","Epoch 26/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3023 - accuracy: 0.8673 - val_loss: 0.4011 - val_accuracy: 0.8190\n","Epoch 27/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2904 - accuracy: 0.8758 - val_loss: 0.3990 - val_accuracy: 0.8224\n","Epoch 28/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2895 - accuracy: 0.8778 - val_loss: 0.3868 - val_accuracy: 0.8269\n","Epoch 29/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.2849 - accuracy: 0.8797 - val_loss: 0.3930 - val_accuracy: 0.8326\n","Epoch 30/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2881 - accuracy: 0.8772 - val_loss: 0.4068 - val_accuracy: 0.8258\n","Epoch 31/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.2827 - accuracy: 0.8817 - val_loss: 0.4000 - val_accuracy: 0.8382\n","Epoch 32/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2843 - accuracy: 0.8817 - val_loss: 0.4076 - val_accuracy: 0.8258\n","Epoch 33/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2735 - accuracy: 0.8862 - val_loss: 0.3943 - val_accuracy: 0.8235\n","Epoch 34/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2735 - accuracy: 0.8882 - val_loss: 0.4086 - val_accuracy: 0.8314\n","Epoch 35/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2747 - accuracy: 0.8908 - val_loss: 0.3985 - val_accuracy: 0.8247\n","Epoch 36/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2737 - accuracy: 0.8899 - val_loss: 0.4036 - val_accuracy: 0.8281\n","Epoch 37/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2685 - accuracy: 0.8877 - val_loss: 0.3976 - val_accuracy: 0.8292\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2852 - accuracy: 0.8769 - val_loss: 0.3979 - val_accuracy: 0.8269\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2583 - accuracy: 0.8922 - val_loss: 0.4039 - val_accuracy: 0.8303\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2686 - accuracy: 0.8834 - val_loss: 0.4024 - val_accuracy: 0.8281\n","Epoch 41/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2576 - accuracy: 0.8987 - val_loss: 0.4054 - val_accuracy: 0.8292\n","Epoch 42/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2635 - accuracy: 0.8902 - val_loss: 0.4081 - val_accuracy: 0.8292\n","Epoch 43/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2681 - accuracy: 0.8891 - val_loss: 0.4045 - val_accuracy: 0.8292\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2605 - accuracy: 0.8871 - val_loss: 0.4075 - val_accuracy: 0.8303\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2495 - accuracy: 0.9001 - val_loss: 0.4085 - val_accuracy: 0.8303\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2492 - accuracy: 0.8990 - val_loss: 0.4099 - val_accuracy: 0.8292\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2410 - accuracy: 0.9052 - val_loss: 0.4064 - val_accuracy: 0.8326\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2457 - accuracy: 0.8998 - val_loss: 0.4082 - val_accuracy: 0.8314\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2465 - accuracy: 0.8930 - val_loss: 0.4097 - val_accuracy: 0.8292\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2342 - accuracy: 0.9061 - val_loss: 0.4096 - val_accuracy: 0.8326\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2334 - accuracy: 0.9055 - val_loss: 0.4218 - val_accuracy: 0.8337\n","Epoch 52/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2520 - accuracy: 0.8967 - val_loss: 0.4229 - val_accuracy: 0.8326\n","Epoch 53/100\n","28/28 [==============================] - 2s 72ms/step - loss: 0.2465 - accuracy: 0.8987 - val_loss: 0.4074 - val_accuracy: 0.8405\n","Epoch 54/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2380 - accuracy: 0.9069 - val_loss: 0.4067 - val_accuracy: 0.8348\n","Epoch 55/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2358 - accuracy: 0.9004 - val_loss: 0.4483 - val_accuracy: 0.8281\n","Epoch 56/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2285 - accuracy: 0.9097 - val_loss: 0.4109 - val_accuracy: 0.8314\n","Epoch 57/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2262 - accuracy: 0.9134 - val_loss: 0.4196 - val_accuracy: 0.8348\n","Epoch 58/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2238 - accuracy: 0.9126 - val_loss: 0.4113 - val_accuracy: 0.8394\n","Epoch 59/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2243 - accuracy: 0.9160 - val_loss: 0.4113 - val_accuracy: 0.8371\n","Epoch 60/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2237 - accuracy: 0.9095 - val_loss: 0.4259 - val_accuracy: 0.8348\n","Epoch 61/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2251 - accuracy: 0.9061 - val_loss: 0.4237 - val_accuracy: 0.8337\n","Epoch 62/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2158 - accuracy: 0.9154 - val_loss: 0.4326 - val_accuracy: 0.8326\n","Epoch 63/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2356 - accuracy: 0.9063 - val_loss: 0.4363 - val_accuracy: 0.8326\n","Epoch 64/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2077 - accuracy: 0.9194 - val_loss: 0.4833 - val_accuracy: 0.8247\n","Epoch 65/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2167 - accuracy: 0.9145 - val_loss: 0.4157 - val_accuracy: 0.8348\n","Epoch 66/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2166 - accuracy: 0.9137 - val_loss: 0.4212 - val_accuracy: 0.8394\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2052 - accuracy: 0.9196 - val_loss: 0.4285 - val_accuracy: 0.8337\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1992 - accuracy: 0.9259 - val_loss: 0.4425 - val_accuracy: 0.8348\n","Epoch 69/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1981 - accuracy: 0.9236 - val_loss: 0.4201 - val_accuracy: 0.8382\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1947 - accuracy: 0.9230 - val_loss: 0.4300 - val_accuracy: 0.8405\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2024 - accuracy: 0.9165 - val_loss: 0.4477 - val_accuracy: 0.8314\n","Epoch 72/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1952 - accuracy: 0.9301 - val_loss: 0.4230 - val_accuracy: 0.8394\n","Epoch 73/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1896 - accuracy: 0.9315 - val_loss: 0.4305 - val_accuracy: 0.8360\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1933 - accuracy: 0.9256 - val_loss: 0.4317 - val_accuracy: 0.8348\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1941 - accuracy: 0.9242 - val_loss: 0.4272 - val_accuracy: 0.8382\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1990 - accuracy: 0.9202 - val_loss: 0.4531 - val_accuracy: 0.8337\n","Epoch 77/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1707 - accuracy: 0.9372 - val_loss: 0.4266 - val_accuracy: 0.8405\n","Epoch 78/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1803 - accuracy: 0.9358 - val_loss: 0.4330 - val_accuracy: 0.8382\n","Epoch 79/100\n","28/28 [==============================] - 2s 67ms/step - loss: 0.1828 - accuracy: 0.9287 - val_loss: 0.4340 - val_accuracy: 0.8439\n","Epoch 80/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1766 - accuracy: 0.9360 - val_loss: 0.4458 - val_accuracy: 0.8292\n","Epoch 81/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2268 - accuracy: 0.9058 - val_loss: 0.4367 - val_accuracy: 0.8326\n","Epoch 82/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1961 - accuracy: 0.9267 - val_loss: 0.4920 - val_accuracy: 0.8224\n","Epoch 83/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1811 - accuracy: 0.9315 - val_loss: 0.4231 - val_accuracy: 0.8371\n","Epoch 84/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1625 - accuracy: 0.9380 - val_loss: 0.4443 - val_accuracy: 0.8258\n","Epoch 85/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1717 - accuracy: 0.9338 - val_loss: 0.4315 - val_accuracy: 0.8382\n","Epoch 86/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1739 - accuracy: 0.9341 - val_loss: 0.4329 - val_accuracy: 0.8439\n","Epoch 87/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1628 - accuracy: 0.9377 - val_loss: 0.4421 - val_accuracy: 0.8247\n","Epoch 88/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1627 - accuracy: 0.9403 - val_loss: 0.4473 - val_accuracy: 0.8269\n","Epoch 89/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1648 - accuracy: 0.9369 - val_loss: 0.4568 - val_accuracy: 0.8428\n","Epoch 90/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1485 - accuracy: 0.9477 - val_loss: 0.4456 - val_accuracy: 0.8382\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1607 - accuracy: 0.9403 - val_loss: 0.4642 - val_accuracy: 0.8405\n","Epoch 92/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1468 - accuracy: 0.9426 - val_loss: 0.4734 - val_accuracy: 0.8292\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1533 - accuracy: 0.9392 - val_loss: 0.4687 - val_accuracy: 0.8269\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1507 - accuracy: 0.9428 - val_loss: 0.4603 - val_accuracy: 0.8371\n","Epoch 95/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1510 - accuracy: 0.9420 - val_loss: 0.4567 - val_accuracy: 0.8405\n","Epoch 96/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1638 - accuracy: 0.9338 - val_loss: 0.5135 - val_accuracy: 0.8224\n","Epoch 97/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1701 - accuracy: 0.9338 - val_loss: 0.5308 - val_accuracy: 0.8167\n","Epoch 98/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1576 - accuracy: 0.9383 - val_loss: 0.4509 - val_accuracy: 0.8269\n","Epoch 99/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1379 - accuracy: 0.9525 - val_loss: 0.4634 - val_accuracy: 0.8405\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1412 - accuracy: 0.9468 - val_loss: 0.5088 - val_accuracy: 0.8224\n","{'loss': [0.3755795657634735, 0.36931106448173523, 0.367340624332428, 0.3553878962993622, 0.34477588534355164, 0.3476347327232361, 0.33616843819618225, 0.3464204668998718, 0.3373410701751709, 0.3360554277896881, 0.33359360694885254, 0.3293420970439911, 0.32104501128196716, 0.32437077164649963, 0.3157128691673279, 0.3211822807788849, 0.3196521997451782, 0.3177488148212433, 0.3212660551071167, 0.31534403562545776, 0.31008806824684143, 0.30315449833869934, 0.3014957308769226, 0.3092440068721771, 0.2948020100593567, 0.30227670073509216, 0.290412575006485, 0.28946608304977417, 0.28490373492240906, 0.28808513283729553, 0.2827118933200836, 0.2842603325843811, 0.27354270219802856, 0.2735278010368347, 0.2747153043746948, 0.27374503016471863, 0.2684684693813324, 0.2851690351963043, 0.25833556056022644, 0.2686416208744049, 0.2575705051422119, 0.26345813274383545, 0.26814866065979004, 0.2604983448982239, 0.24954849481582642, 0.24920393526554108, 0.2409747987985611, 0.2456754744052887, 0.24653510749340057, 0.23420974612236023, 0.2334483116865158, 0.2520078420639038, 0.24654044210910797, 0.23804080486297607, 0.23581945896148682, 0.2285417914390564, 0.2261958122253418, 0.2237791121006012, 0.2243489772081375, 0.22368331253528595, 0.22509659826755524, 0.21577860414981842, 0.23555465042591095, 0.20767351984977722, 0.2166849672794342, 0.21658676862716675, 0.20520490407943726, 0.199224591255188, 0.19812941551208496, 0.1947251409292221, 0.2023574858903885, 0.19519951939582825, 0.18961092829704285, 0.19327175617218018, 0.19414784014225006, 0.19902905821800232, 0.17072561383247375, 0.18033434450626373, 0.18276289105415344, 0.1766413152217865, 0.22681139409542084, 0.19614724814891815, 0.1810716688632965, 0.16247841715812683, 0.17172633111476898, 0.1738785058259964, 0.1627662181854248, 0.16273559629917145, 0.16478072106838226, 0.1485266387462616, 0.16068558394908905, 0.14682753384113312, 0.15325380861759186, 0.15071628987789154, 0.1509651094675064, 0.16379530727863312, 0.1701398640871048, 0.1576223224401474, 0.13788600265979767, 0.141218900680542], 'accuracy': [0.8370118737220764, 0.833616316318512, 0.8341822028160095, 0.8418223261833191, 0.8497453331947327, 0.8500282764434814, 0.8590831756591797, 0.848613440990448, 0.8548387289047241, 0.8531408905982971, 0.8548387289047241, 0.853989839553833, 0.8647425174713135, 0.8585172891616821, 0.8638936281204224, 0.8613469004631042, 0.8630446791648865, 0.8644595146179199, 0.8630446791648865, 0.868986964225769, 0.8740803599357605, 0.8740803599357605, 0.8715336918830872, 0.8664402961730957, 0.8780418634414673, 0.8672891855239868, 0.8757781386375427, 0.8777589201927185, 0.8797396421432495, 0.8771929740905762, 0.8817204236984253, 0.8817204236984253, 0.8862478733062744, 0.8882286548614502, 0.8907753229141235, 0.8899264335632324, 0.8876627087593079, 0.8769100308418274, 0.892190158367157, 0.8834182024002075, 0.8986983299255371, 0.8902093768119812, 0.8890775442123413, 0.8870967626571655, 0.9001131653785706, 0.8989813327789307, 0.905206561088562, 0.8998302221298218, 0.8930390477180481, 0.9060554504394531, 0.9054895043373108, 0.8967176079750061, 0.8986983299255371, 0.9069043397903442, 0.9003961682319641, 0.9097340106964111, 0.9134125709533691, 0.912563681602478, 0.9159592390060425, 0.9094510674476624, 0.9060554504394531, 0.9153932929039001, 0.9063384532928467, 0.9193548560142517, 0.914544403553009, 0.9136955142021179, 0.9196377992630005, 0.9258630275726318, 0.9235993027687073, 0.9230334162712097, 0.9165251851081848, 0.9301075339317322, 0.9315223693847656, 0.9255800843238831, 0.9241652488708496, 0.9202037453651428, 0.9371816515922546, 0.9357668161392212, 0.9286926984786987, 0.9360498189926147, 0.9057725071907043, 0.926711916923523, 0.9315223693847656, 0.9380305409431458, 0.9337860941886902, 0.934069037437439, 0.937747597694397, 0.9402942657470703, 0.9368987083435059, 0.9476513862609863, 0.9402942657470703, 0.9425579905509949, 0.9391624331474304, 0.9428409934043884, 0.9419921040534973, 0.9337860941886902, 0.9337860941886902, 0.9383135437965393, 0.9524617791175842, 0.9468024969100952], 'val_loss': [0.6946557760238647, 0.694385290145874, 0.6931905746459961, 0.6922897696495056, 0.6899374723434448, 0.6845671534538269, 0.6732786297798157, 0.6702446341514587, 0.6561362147331238, 0.6460874676704407, 0.631982147693634, 0.6254474520683289, 0.6092438101768494, 0.5814838409423828, 0.568126916885376, 0.5569145083427429, 0.5141805410385132, 0.5369088649749756, 0.4711748957633972, 0.4682314693927765, 0.4429314136505127, 0.4292600154876709, 0.4206342101097107, 0.40784892439842224, 0.39684754610061646, 0.4010535478591919, 0.3989793360233307, 0.38675206899642944, 0.3929995596408844, 0.4067881405353546, 0.4000406265258789, 0.4075668752193451, 0.39431560039520264, 0.40864667296409607, 0.3985486328601837, 0.40357550978660583, 0.39763402938842773, 0.3978772461414337, 0.4039204716682434, 0.4023500680923462, 0.40536999702453613, 0.408066064119339, 0.4044854938983917, 0.4074878692626953, 0.40848034620285034, 0.40987518429756165, 0.40642499923706055, 0.4082471430301666, 0.40970346331596375, 0.409633606672287, 0.42178669571876526, 0.42293891310691833, 0.40737804770469666, 0.4066798985004425, 0.4483157992362976, 0.41093793511390686, 0.4196326732635498, 0.4112847149372101, 0.41132140159606934, 0.42590004205703735, 0.42365509271621704, 0.4326189458370209, 0.4363478720188141, 0.48327162861824036, 0.4156950116157532, 0.42118918895721436, 0.42850449681282043, 0.4425427317619324, 0.4200707972049713, 0.4299595355987549, 0.44766664505004883, 0.4230285882949829, 0.43046835064888, 0.4316924512386322, 0.427190363407135, 0.45308440923690796, 0.4266202449798584, 0.4329533576965332, 0.43400508165359497, 0.4458410143852234, 0.4366758465766907, 0.49196621775627136, 0.42306816577911377, 0.4442698657512665, 0.4315498173236847, 0.4329301416873932, 0.44208356738090515, 0.44728589057922363, 0.45681601762771606, 0.4455762803554535, 0.4641869366168976, 0.473388671875, 0.46874764561653137, 0.4602539539337158, 0.45666778087615967, 0.5135390162467957, 0.5307595133781433, 0.45085206627845764, 0.463401198387146, 0.5087764859199524], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4977375566959381, 0.5101810097694397, 0.5452488660812378, 0.5305429697036743, 0.5837104320526123, 0.7364253401756287, 0.7228506803512573, 0.7081447839736938, 0.8156108856201172, 0.7036198973655701, 0.820135772228241, 0.8054298758506775, 0.8156108856201172, 0.8133484125137329, 0.8156108856201172, 0.8190045356750488, 0.8246606588363647, 0.8190045356750488, 0.8223981857299805, 0.8269230723381042, 0.8325791954994202, 0.8257918357849121, 0.8382353186607361, 0.8257918357849121, 0.8235294222831726, 0.831447958946228, 0.8246606588363647, 0.8280543088912964, 0.8291855454444885, 0.8269230723381042, 0.8303167223930359, 0.8280543088912964, 0.8291855454444885, 0.8291855454444885, 0.8291855454444885, 0.8303167223930359, 0.8303167223930359, 0.8291855454444885, 0.8325791954994202, 0.831447958946228, 0.8291855454444885, 0.8325791954994202, 0.8337104320526123, 0.8325791954994202, 0.8404977321624756, 0.8348416090011597, 0.8280543088912964, 0.831447958946228, 0.8348416090011597, 0.8393664956092834, 0.837104082107544, 0.8348416090011597, 0.8337104320526123, 0.8325791954994202, 0.8325791954994202, 0.8246606588363647, 0.8348416090011597, 0.8393664956092834, 0.8337104320526123, 0.8348416090011597, 0.8382353186607361, 0.8404977321624756, 0.831447958946228, 0.8393664956092834, 0.8359728455543518, 0.8348416090011597, 0.8382353186607361, 0.8337104320526123, 0.8404977321624756, 0.8382353186607361, 0.8438913822174072, 0.8291855454444885, 0.8325791954994202, 0.8223981857299805, 0.837104082107544, 0.8257918357849121, 0.8382353186607361, 0.8438913822174072, 0.8246606588363647, 0.8269230723381042, 0.8427602052688599, 0.8382353186607361, 0.8404977321624756, 0.8291855454444885, 0.8269230723381042, 0.837104082107544, 0.8404977321624756, 0.8223981857299805, 0.8167420625686646, 0.8269230723381042, 0.8404977321624756, 0.8223981857299805]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.3617 - accuracy: 0.8430"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 20s 420ms/step - loss: 0.3613 - accuracy: 0.8432 - val_loss: 0.6965 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3449 - accuracy: 0.8506 - val_loss: 0.6963 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3391 - accuracy: 0.8610 - val_loss: 0.6952 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3368 - accuracy: 0.8537 - val_loss: 0.6943 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3244 - accuracy: 0.8638 - val_loss: 0.6885 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3269 - accuracy: 0.8594 - val_loss: 0.6779 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3213 - accuracy: 0.8625 - val_loss: 0.6753 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3147 - accuracy: 0.8698 - val_loss: 0.6549 - val_accuracy: 0.4866\n","Epoch 9/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3239 - accuracy: 0.8610 - val_loss: 0.6512 - val_accuracy: 0.4866\n","Epoch 10/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3052 - accuracy: 0.8742 - val_loss: 0.6335 - val_accuracy: 0.5062\n","Epoch 11/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3035 - accuracy: 0.8716 - val_loss: 0.6171 - val_accuracy: 0.5620\n","Epoch 12/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3092 - accuracy: 0.8695 - val_loss: 0.5933 - val_accuracy: 0.7087\n","Epoch 13/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3059 - accuracy: 0.8672 - val_loss: 0.5832 - val_accuracy: 0.6601\n","Epoch 14/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2989 - accuracy: 0.8742 - val_loss: 0.5523 - val_accuracy: 0.7758\n","Epoch 15/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2903 - accuracy: 0.8786 - val_loss: 0.5490 - val_accuracy: 0.6983\n","Epoch 16/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2967 - accuracy: 0.8770 - val_loss: 0.5149 - val_accuracy: 0.7686\n","Epoch 17/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.3026 - accuracy: 0.8659 - val_loss: 0.4691 - val_accuracy: 0.8337\n","Epoch 18/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2903 - accuracy: 0.8770 - val_loss: 0.4664 - val_accuracy: 0.8006\n","Epoch 19/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2864 - accuracy: 0.8814 - val_loss: 0.4428 - val_accuracy: 0.8058\n","Epoch 20/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2861 - accuracy: 0.8814 - val_loss: 0.4194 - val_accuracy: 0.8171\n","Epoch 21/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.2794 - accuracy: 0.8881 - val_loss: 0.3883 - val_accuracy: 0.8378\n","Epoch 22/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2826 - accuracy: 0.8848 - val_loss: 0.4040 - val_accuracy: 0.8202\n","Epoch 23/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2741 - accuracy: 0.8860 - val_loss: 0.4094 - val_accuracy: 0.8130\n","Epoch 24/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2844 - accuracy: 0.8788 - val_loss: 0.3692 - val_accuracy: 0.8285\n","Epoch 25/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2805 - accuracy: 0.8832 - val_loss: 0.3688 - val_accuracy: 0.8306\n","Epoch 26/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2694 - accuracy: 0.8881 - val_loss: 0.3783 - val_accuracy: 0.8275\n","Epoch 27/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2726 - accuracy: 0.8858 - val_loss: 0.3737 - val_accuracy: 0.8347\n","Epoch 28/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.2657 - accuracy: 0.8866 - val_loss: 0.3755 - val_accuracy: 0.8388\n","Epoch 29/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2597 - accuracy: 0.8912 - val_loss: 0.3763 - val_accuracy: 0.8285\n","Epoch 30/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2667 - accuracy: 0.8884 - val_loss: 0.3817 - val_accuracy: 0.8295\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2811 - accuracy: 0.8793 - val_loss: 0.4293 - val_accuracy: 0.8130\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2692 - accuracy: 0.8889 - val_loss: 0.3797 - val_accuracy: 0.8326\n","Epoch 33/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2541 - accuracy: 0.8964 - val_loss: 0.3843 - val_accuracy: 0.8264\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2477 - accuracy: 0.9021 - val_loss: 0.3864 - val_accuracy: 0.8357\n","Epoch 35/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2472 - accuracy: 0.8982 - val_loss: 0.3872 - val_accuracy: 0.8337\n","Epoch 36/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2482 - accuracy: 0.8974 - val_loss: 0.3878 - val_accuracy: 0.8378\n","Epoch 37/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2446 - accuracy: 0.9003 - val_loss: 0.3978 - val_accuracy: 0.8368\n","Epoch 38/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2427 - accuracy: 0.9000 - val_loss: 0.3966 - val_accuracy: 0.8357\n","Epoch 39/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2441 - accuracy: 0.9028 - val_loss: 0.4042 - val_accuracy: 0.8254\n","Epoch 40/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2506 - accuracy: 0.8915 - val_loss: 0.4017 - val_accuracy: 0.8254\n","Epoch 41/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2433 - accuracy: 0.8987 - val_loss: 0.4034 - val_accuracy: 0.8347\n","Epoch 42/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2403 - accuracy: 0.9039 - val_loss: 0.4712 - val_accuracy: 0.8161\n","Epoch 43/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2342 - accuracy: 0.9059 - val_loss: 0.3930 - val_accuracy: 0.8357\n","Epoch 44/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2296 - accuracy: 0.9013 - val_loss: 0.4054 - val_accuracy: 0.8337\n","Epoch 45/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2385 - accuracy: 0.9016 - val_loss: 0.3941 - val_accuracy: 0.8337\n","Epoch 46/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2541 - accuracy: 0.8930 - val_loss: 0.3954 - val_accuracy: 0.8337\n","Epoch 47/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2251 - accuracy: 0.9103 - val_loss: 0.3998 - val_accuracy: 0.8326\n","Epoch 48/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2184 - accuracy: 0.9127 - val_loss: 0.4070 - val_accuracy: 0.8295\n","Epoch 49/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2123 - accuracy: 0.9129 - val_loss: 0.4056 - val_accuracy: 0.8378\n","Epoch 50/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2207 - accuracy: 0.9101 - val_loss: 0.4002 - val_accuracy: 0.8347\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2164 - accuracy: 0.9101 - val_loss: 0.4012 - val_accuracy: 0.8347\n","Epoch 52/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2195 - accuracy: 0.9083 - val_loss: 0.4150 - val_accuracy: 0.8295\n","Epoch 53/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2111 - accuracy: 0.9163 - val_loss: 0.4339 - val_accuracy: 0.8326\n","Epoch 54/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2112 - accuracy: 0.9165 - val_loss: 0.4058 - val_accuracy: 0.8295\n","Epoch 55/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2164 - accuracy: 0.9124 - val_loss: 0.4100 - val_accuracy: 0.8378\n","Epoch 56/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2027 - accuracy: 0.9196 - val_loss: 0.4272 - val_accuracy: 0.8306\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2046 - accuracy: 0.9109 - val_loss: 0.4263 - val_accuracy: 0.8347\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2060 - accuracy: 0.9137 - val_loss: 0.4292 - val_accuracy: 0.8337\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2011 - accuracy: 0.9235 - val_loss: 0.4087 - val_accuracy: 0.8337\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1950 - accuracy: 0.9243 - val_loss: 0.4128 - val_accuracy: 0.8337\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2089 - accuracy: 0.9150 - val_loss: 0.4128 - val_accuracy: 0.8337\n","Epoch 62/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1919 - accuracy: 0.9256 - val_loss: 0.4166 - val_accuracy: 0.8357\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1904 - accuracy: 0.9243 - val_loss: 0.4434 - val_accuracy: 0.8254\n","Epoch 64/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1961 - accuracy: 0.9217 - val_loss: 0.4428 - val_accuracy: 0.8306\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1983 - accuracy: 0.9248 - val_loss: 0.4161 - val_accuracy: 0.8347\n","Epoch 66/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1955 - accuracy: 0.9165 - val_loss: 0.4203 - val_accuracy: 0.8295\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1779 - accuracy: 0.9359 - val_loss: 0.4399 - val_accuracy: 0.8285\n","Epoch 68/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1872 - accuracy: 0.9276 - val_loss: 0.4577 - val_accuracy: 0.8264\n","Epoch 69/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1883 - accuracy: 0.9222 - val_loss: 0.4513 - val_accuracy: 0.8254\n","Epoch 70/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1808 - accuracy: 0.9313 - val_loss: 0.4515 - val_accuracy: 0.8306\n","Epoch 71/100\n","31/31 [==============================] - 2s 82ms/step - loss: 0.1858 - accuracy: 0.9271 - val_loss: 0.4227 - val_accuracy: 0.8409\n","Epoch 72/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1695 - accuracy: 0.9357 - val_loss: 0.4341 - val_accuracy: 0.8347\n","Epoch 73/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1709 - accuracy: 0.9372 - val_loss: 0.4952 - val_accuracy: 0.8130\n","Epoch 74/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1753 - accuracy: 0.9302 - val_loss: 0.4383 - val_accuracy: 0.8347\n","Epoch 75/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1659 - accuracy: 0.9349 - val_loss: 0.4643 - val_accuracy: 0.8337\n","Epoch 76/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1949 - accuracy: 0.9194 - val_loss: 0.4417 - val_accuracy: 0.8388\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1748 - accuracy: 0.9310 - val_loss: 0.4329 - val_accuracy: 0.8399\n","Epoch 78/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.1639 - accuracy: 0.9382 - val_loss: 0.4342 - val_accuracy: 0.8419\n","Epoch 79/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1589 - accuracy: 0.9385 - val_loss: 0.4390 - val_accuracy: 0.8368\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1683 - accuracy: 0.9346 - val_loss: 0.4520 - val_accuracy: 0.8295\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1865 - accuracy: 0.9240 - val_loss: 0.6854 - val_accuracy: 0.7686\n","Epoch 82/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1865 - accuracy: 0.9233 - val_loss: 0.4368 - val_accuracy: 0.8399\n","Epoch 83/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.1534 - accuracy: 0.9450 - val_loss: 0.4341 - val_accuracy: 0.8430\n","Epoch 84/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1508 - accuracy: 0.9411 - val_loss: 0.4450 - val_accuracy: 0.8337\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1521 - accuracy: 0.9452 - val_loss: 0.4807 - val_accuracy: 0.8223\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1551 - accuracy: 0.9390 - val_loss: 0.4852 - val_accuracy: 0.8213\n","Epoch 87/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1531 - accuracy: 0.9393 - val_loss: 0.4658 - val_accuracy: 0.8409\n","Epoch 88/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1704 - accuracy: 0.9310 - val_loss: 0.5280 - val_accuracy: 0.8171\n","Epoch 89/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1602 - accuracy: 0.9351 - val_loss: 0.5167 - val_accuracy: 0.8202\n","Epoch 90/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1511 - accuracy: 0.9419 - val_loss: 0.4467 - val_accuracy: 0.8347\n","Epoch 91/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1562 - accuracy: 0.9401 - val_loss: 0.4687 - val_accuracy: 0.8337\n","Epoch 92/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1417 - accuracy: 0.9475 - val_loss: 0.4577 - val_accuracy: 0.8295\n","Epoch 93/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1370 - accuracy: 0.9494 - val_loss: 0.4570 - val_accuracy: 0.8368\n","Epoch 94/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1332 - accuracy: 0.9532 - val_loss: 0.4593 - val_accuracy: 0.8419\n","Epoch 95/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1480 - accuracy: 0.9442 - val_loss: 0.4787 - val_accuracy: 0.8306\n","Epoch 96/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1398 - accuracy: 0.9478 - val_loss: 0.5325 - val_accuracy: 0.8110\n","Epoch 97/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1512 - accuracy: 0.9426 - val_loss: 0.5050 - val_accuracy: 0.8213\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1461 - accuracy: 0.9434 - val_loss: 0.4619 - val_accuracy: 0.8347\n","Epoch 99/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1323 - accuracy: 0.9530 - val_loss: 0.5094 - val_accuracy: 0.8223\n","Epoch 100/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1426 - accuracy: 0.9434 - val_loss: 0.6522 - val_accuracy: 0.7841\n","{'loss': [0.3613279461860657, 0.3448781967163086, 0.33913636207580566, 0.33678627014160156, 0.3244488537311554, 0.32688993215560913, 0.3213452398777008, 0.3147490322589874, 0.32391804456710815, 0.30518674850463867, 0.30349230766296387, 0.30920326709747314, 0.30586156249046326, 0.29885032773017883, 0.2903076112270355, 0.29667139053344727, 0.3026057779788971, 0.2902754545211792, 0.2864338755607605, 0.28614601492881775, 0.27939990162849426, 0.28264591097831726, 0.27412545680999756, 0.2843746542930603, 0.2805435061454773, 0.26943010091781616, 0.2725878059864044, 0.26574966311454773, 0.25974035263061523, 0.26667657494544983, 0.2811224162578583, 0.2691758871078491, 0.2541169226169586, 0.2477272003889084, 0.24717767536640167, 0.24824464321136475, 0.24460241198539734, 0.24268841743469238, 0.24407146871089935, 0.2506469488143921, 0.24334101378917694, 0.2402975708246231, 0.23415561020374298, 0.22956378757953644, 0.23846741020679474, 0.25413447618484497, 0.22508816421031952, 0.21839892864227295, 0.21227328479290009, 0.22067460417747498, 0.21637238562107086, 0.21946850419044495, 0.2110869586467743, 0.21119089424610138, 0.21643035113811493, 0.20266950130462646, 0.20462758839130402, 0.2059754729270935, 0.20107807219028473, 0.1950104832649231, 0.20889009535312653, 0.191919207572937, 0.19039568305015564, 0.19610945880413055, 0.1983473300933838, 0.19547012448310852, 0.17786088585853577, 0.18720653653144836, 0.1883496195077896, 0.18080547451972961, 0.1858213245868683, 0.169487863779068, 0.17091745138168335, 0.17532800137996674, 0.16586878895759583, 0.19492363929748535, 0.17482180893421173, 0.16394354403018951, 0.15891854465007782, 0.16828535497188568, 0.18647514283657074, 0.18651564419269562, 0.15344293415546417, 0.1508239358663559, 0.15207287669181824, 0.15506836771965027, 0.15310746431350708, 0.1703801304101944, 0.16024696826934814, 0.15108469128608704, 0.15622445940971375, 0.14168308675289154, 0.13703572750091553, 0.13318893313407898, 0.1479715257883072, 0.1397915631532669, 0.15116621553897858, 0.14613480865955353, 0.13227836787700653, 0.14261354506015778], 'accuracy': [0.8431524634361267, 0.8506460189819336, 0.8609819412231445, 0.853746771812439, 0.8638243079185486, 0.8594315052032471, 0.8625323176383972, 0.869767427444458, 0.8609819412231445, 0.8741602301597595, 0.8715762495994568, 0.8695090413093567, 0.8671834468841553, 0.8741602301597595, 0.8785529732704163, 0.8770025968551636, 0.8658914566040039, 0.8770025968551636, 0.8813953399658203, 0.8813953399658203, 0.8881136775016785, 0.8847545385360718, 0.8860465288162231, 0.8788113594055176, 0.8832041621208191, 0.8881136775016785, 0.8857881426811218, 0.8865633010864258, 0.8912144899368286, 0.8883720636367798, 0.879328191280365, 0.8888888955116272, 0.8963824510574341, 0.9020671844482422, 0.8981912136077881, 0.8974159955978394, 0.9002584218978882, 0.8999999761581421, 0.9028424024581909, 0.8914728760719299, 0.8987079858779907, 0.9038759469985962, 0.9059431552886963, 0.9012919664382935, 0.9015504121780396, 0.8930232524871826, 0.910335898399353, 0.9126614928245544, 0.9129198789596558, 0.9100775122642517, 0.9100775122642517, 0.9082687497138977, 0.9162790775299072, 0.9165374636650085, 0.9124031066894531, 0.9196382164955139, 0.9108527302742004, 0.9136950969696045, 0.923514187335968, 0.9242894053459167, 0.9149870872497559, 0.9255813956260681, 0.9242894053459167, 0.921705424785614, 0.9248061776161194, 0.9165374636650085, 0.935917317867279, 0.9276486039161682, 0.9222221970558167, 0.9312661290168762, 0.9271317720413208, 0.9356589317321777, 0.9372093081474304, 0.930232584476471, 0.934883713722229, 0.9193798303604126, 0.9310077428817749, 0.9382429122924805, 0.9385012984275818, 0.9346253275871277, 0.9240310192108154, 0.9232558012008667, 0.9449612498283386, 0.9410852789878845, 0.9452196359634399, 0.9390180706977844, 0.9392764568328857, 0.9310077428817749, 0.9351420998573303, 0.9418604373931885, 0.9400516748428345, 0.9475452303886414, 0.9493539929389954, 0.9532299637794495, 0.9441860318183899, 0.9478036165237427, 0.9426356554031372, 0.9434108734130859, 0.9529715776443481, 0.9434108734130859], 'val_loss': [0.696468710899353, 0.6963357329368591, 0.695239245891571, 0.6942682862281799, 0.6885159015655518, 0.6778706908226013, 0.6752833127975464, 0.6549381017684937, 0.6512234210968018, 0.6335313320159912, 0.6171481609344482, 0.5932793021202087, 0.5831519961357117, 0.5523446202278137, 0.5489700436592102, 0.5148539543151855, 0.469137042760849, 0.4664471745491028, 0.44277772307395935, 0.41941434144973755, 0.3882605731487274, 0.4040474593639374, 0.40942659974098206, 0.3691996932029724, 0.3688470125198364, 0.37834805250167847, 0.37367212772369385, 0.3755340278148651, 0.3762829303741455, 0.3816737234592438, 0.4292980134487152, 0.3797474801540375, 0.3843131959438324, 0.3864060342311859, 0.38717129826545715, 0.3877970278263092, 0.3978261947631836, 0.3965911567211151, 0.4041743874549866, 0.4016810357570648, 0.40338951349258423, 0.4712370038032532, 0.3930167853832245, 0.4053677022457123, 0.3940722942352295, 0.39535436034202576, 0.39984819293022156, 0.40700864791870117, 0.4055996537208557, 0.40024641156196594, 0.4012090265750885, 0.41495048999786377, 0.4338679611682892, 0.4057784080505371, 0.4099683463573456, 0.4272441565990448, 0.4262722134590149, 0.42917323112487793, 0.4086717367172241, 0.4127940237522125, 0.41275501251220703, 0.4166072905063629, 0.44336628913879395, 0.44278305768966675, 0.4161449670791626, 0.42026740312576294, 0.43990227580070496, 0.45770716667175293, 0.45130178332328796, 0.45148801803588867, 0.422709196805954, 0.43412062525749207, 0.495236337184906, 0.4383275806903839, 0.464313805103302, 0.4417406916618347, 0.4329433739185333, 0.4342183470726013, 0.4389614760875702, 0.45196759700775146, 0.6854137778282166, 0.43677452206611633, 0.434051513671875, 0.44497233629226685, 0.4807493984699249, 0.48515641689300537, 0.4657856523990631, 0.5279800295829773, 0.5166586637496948, 0.44665583968162537, 0.4686659574508667, 0.4576908349990845, 0.45704081654548645, 0.4592905640602112, 0.4787479639053345, 0.5324659943580627, 0.5050440430641174, 0.4618805944919586, 0.5093913078308105, 0.6521952152252197], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.48657023906707764, 0.5061983466148376, 0.5619834661483765, 0.7086777091026306, 0.6601239442825317, 0.7758264541625977, 0.6983470916748047, 0.7685950398445129, 0.8336777091026306, 0.8006198406219482, 0.8057851195335388, 0.817148745059967, 0.8378099203109741, 0.8202479481697083, 0.8130165338516235, 0.8285123705863953, 0.8305785059928894, 0.827479362487793, 0.8347107172012329, 0.8388429880142212, 0.8285123705863953, 0.8295454382896423, 0.8130165338516235, 0.8326446413993835, 0.8264462947845459, 0.83574378490448, 0.8336777091026306, 0.8378099203109741, 0.836776852607727, 0.83574378490448, 0.8254132270812988, 0.8254132270812988, 0.8347107172012329, 0.81611567735672, 0.83574378490448, 0.8336777091026306, 0.8336777091026306, 0.8336777091026306, 0.8326446413993835, 0.8295454382896423, 0.8378099203109741, 0.8347107172012329, 0.8347107172012329, 0.8295454382896423, 0.8326446413993835, 0.8295454382896423, 0.8378099203109741, 0.8305785059928894, 0.8347107172012329, 0.8336777091026306, 0.8336777091026306, 0.8336777091026306, 0.8336777091026306, 0.83574378490448, 0.8254132270812988, 0.8305785059928894, 0.8347107172012329, 0.8295454382896423, 0.8285123705863953, 0.8264462947845459, 0.8254132270812988, 0.8305785059928894, 0.8409090638160706, 0.8347107172012329, 0.8130165338516235, 0.8347107172012329, 0.8336777091026306, 0.8388429880142212, 0.8398760557174683, 0.8419421315193176, 0.836776852607727, 0.8295454382896423, 0.7685950398445129, 0.8398760557174683, 0.8429751992225647, 0.8336777091026306, 0.8223140239715576, 0.8212810158729553, 0.8409090638160706, 0.817148745059967, 0.8202479481697083, 0.8347107172012329, 0.8336777091026306, 0.8295454382896423, 0.836776852607727, 0.8419421315193176, 0.8305785059928894, 0.8109503984451294, 0.8212810158729553, 0.8347107172012329, 0.8223140239715576, 0.7840909361839294]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.2218 - accuracy: 0.9090"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 12s 212ms/step - loss: 0.2203 - accuracy: 0.9095 - val_loss: 0.7071 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1891 - accuracy: 0.9256 - val_loss: 0.7061 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1926 - accuracy: 0.9254 - val_loss: 0.7048 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1814 - accuracy: 0.9300 - val_loss: 0.7035 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1836 - accuracy: 0.9305 - val_loss: 0.7027 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.1764 - accuracy: 0.9313 - val_loss: 0.7000 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1846 - accuracy: 0.9308 - val_loss: 0.6969 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1750 - accuracy: 0.9364 - val_loss: 0.6791 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.1709 - accuracy: 0.9364 - val_loss: 0.6746 - val_accuracy: 0.4871\n","Epoch 10/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.1650 - accuracy: 0.9372 - val_loss: 0.6500 - val_accuracy: 0.4957\n","Epoch 11/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.1568 - accuracy: 0.9429 - val_loss: 0.6236 - val_accuracy: 0.5151\n","Epoch 12/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.1564 - accuracy: 0.9413 - val_loss: 0.5964 - val_accuracy: 0.5582\n","Epoch 13/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1573 - accuracy: 0.9423 - val_loss: 0.5925 - val_accuracy: 0.5539\n","Epoch 14/100\n","29/29 [==============================] - 1s 38ms/step - loss: 0.1585 - accuracy: 0.9410 - val_loss: 0.5341 - val_accuracy: 0.6832\n","Epoch 15/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.1565 - accuracy: 0.9413 - val_loss: 0.4896 - val_accuracy: 0.7726\n","Epoch 16/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1456 - accuracy: 0.9475 - val_loss: 0.4763 - val_accuracy: 0.7554\n","Epoch 17/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.1574 - accuracy: 0.9388 - val_loss: 0.4188 - val_accuracy: 0.8448\n","Epoch 18/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1442 - accuracy: 0.9480 - val_loss: 0.4448 - val_accuracy: 0.7694\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1299 - accuracy: 0.9555 - val_loss: 0.3797 - val_accuracy: 0.8394\n","Epoch 20/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.1324 - accuracy: 0.9545 - val_loss: 0.3355 - val_accuracy: 0.8664\n","Epoch 21/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1362 - accuracy: 0.9483 - val_loss: 0.3559 - val_accuracy: 0.8491\n","Epoch 22/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.1370 - accuracy: 0.9496 - val_loss: 0.2834 - val_accuracy: 0.8890\n","Epoch 23/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1539 - accuracy: 0.9402 - val_loss: 0.2928 - val_accuracy: 0.8815\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1356 - accuracy: 0.9480 - val_loss: 0.3231 - val_accuracy: 0.8664\n","Epoch 25/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1371 - accuracy: 0.9483 - val_loss: 0.2840 - val_accuracy: 0.8879\n","Epoch 26/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1239 - accuracy: 0.9558 - val_loss: 0.3167 - val_accuracy: 0.8728\n","Epoch 27/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.1397 - accuracy: 0.9494 - val_loss: 0.2703 - val_accuracy: 0.8976\n","Epoch 28/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1249 - accuracy: 0.9580 - val_loss: 0.2780 - val_accuracy: 0.8976\n","Epoch 29/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1154 - accuracy: 0.9588 - val_loss: 0.2860 - val_accuracy: 0.8933\n","Epoch 30/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1269 - accuracy: 0.9534 - val_loss: 0.3118 - val_accuracy: 0.8869\n","Epoch 31/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.1301 - accuracy: 0.9531 - val_loss: 0.2978 - val_accuracy: 0.9030\n","Epoch 32/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1128 - accuracy: 0.9612 - val_loss: 0.2971 - val_accuracy: 0.9030\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1170 - accuracy: 0.9623 - val_loss: 0.3350 - val_accuracy: 0.8815\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1210 - accuracy: 0.9564 - val_loss: 0.3770 - val_accuracy: 0.8664\n","Epoch 35/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1074 - accuracy: 0.9628 - val_loss: 0.3222 - val_accuracy: 0.8804\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1043 - accuracy: 0.9626 - val_loss: 0.3176 - val_accuracy: 0.8912\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1124 - accuracy: 0.9588 - val_loss: 0.3801 - val_accuracy: 0.8664\n","Epoch 38/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1119 - accuracy: 0.9577 - val_loss: 0.3392 - val_accuracy: 0.8879\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1058 - accuracy: 0.9620 - val_loss: 0.3523 - val_accuracy: 0.8804\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0962 - accuracy: 0.9655 - val_loss: 0.3326 - val_accuracy: 0.8869\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0984 - accuracy: 0.9679 - val_loss: 0.3633 - val_accuracy: 0.8761\n","Epoch 42/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1039 - accuracy: 0.9647 - val_loss: 0.3267 - val_accuracy: 0.8912\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1156 - accuracy: 0.9585 - val_loss: 0.3619 - val_accuracy: 0.8825\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1185 - accuracy: 0.9550 - val_loss: 0.3602 - val_accuracy: 0.8847\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1066 - accuracy: 0.9644 - val_loss: 0.3233 - val_accuracy: 0.8922\n","Epoch 46/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1006 - accuracy: 0.9647 - val_loss: 0.3613 - val_accuracy: 0.8772\n","Epoch 47/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0914 - accuracy: 0.9717 - val_loss: 0.3464 - val_accuracy: 0.8836\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0964 - accuracy: 0.9685 - val_loss: 0.3428 - val_accuracy: 0.8772\n","Epoch 49/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0962 - accuracy: 0.9671 - val_loss: 0.3456 - val_accuracy: 0.8761\n","Epoch 50/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0825 - accuracy: 0.9725 - val_loss: 0.3392 - val_accuracy: 0.8901\n","Epoch 51/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0801 - accuracy: 0.9714 - val_loss: 0.3664 - val_accuracy: 0.8772\n","Epoch 52/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0953 - accuracy: 0.9647 - val_loss: 0.3480 - val_accuracy: 0.8944\n","Epoch 53/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.1024 - accuracy: 0.9617 - val_loss: 0.3489 - val_accuracy: 0.8782\n","Epoch 54/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0843 - accuracy: 0.9720 - val_loss: 0.3488 - val_accuracy: 0.8858\n","Epoch 55/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0855 - accuracy: 0.9682 - val_loss: 0.3498 - val_accuracy: 0.8890\n","Epoch 56/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0748 - accuracy: 0.9758 - val_loss: 0.3540 - val_accuracy: 0.8825\n","Epoch 57/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0700 - accuracy: 0.9774 - val_loss: 0.3681 - val_accuracy: 0.8782\n","Epoch 58/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0776 - accuracy: 0.9741 - val_loss: 0.3660 - val_accuracy: 0.8869\n","Epoch 59/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0791 - accuracy: 0.9720 - val_loss: 0.4259 - val_accuracy: 0.8664\n","Epoch 60/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0772 - accuracy: 0.9758 - val_loss: 0.4762 - val_accuracy: 0.8534\n","Epoch 61/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0742 - accuracy: 0.9752 - val_loss: 0.3629 - val_accuracy: 0.8836\n","Epoch 62/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0668 - accuracy: 0.9790 - val_loss: 0.3730 - val_accuracy: 0.8901\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0633 - accuracy: 0.9803 - val_loss: 0.3663 - val_accuracy: 0.8933\n","Epoch 64/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0711 - accuracy: 0.9725 - val_loss: 0.3778 - val_accuracy: 0.8869\n","Epoch 65/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0704 - accuracy: 0.9768 - val_loss: 0.3980 - val_accuracy: 0.8761\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0674 - accuracy: 0.9766 - val_loss: 0.3749 - val_accuracy: 0.8804\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0683 - accuracy: 0.9779 - val_loss: 0.3896 - val_accuracy: 0.8772\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0645 - accuracy: 0.9784 - val_loss: 0.3943 - val_accuracy: 0.8804\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0667 - accuracy: 0.9747 - val_loss: 0.4085 - val_accuracy: 0.8772\n","Epoch 70/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0813 - accuracy: 0.9720 - val_loss: 0.3851 - val_accuracy: 0.8815\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0614 - accuracy: 0.9779 - val_loss: 0.3855 - val_accuracy: 0.8782\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0660 - accuracy: 0.9763 - val_loss: 0.3992 - val_accuracy: 0.8836\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0800 - accuracy: 0.9698 - val_loss: 0.4125 - val_accuracy: 0.8707\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0652 - accuracy: 0.9811 - val_loss: 0.3969 - val_accuracy: 0.8782\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0576 - accuracy: 0.9806 - val_loss: 0.3932 - val_accuracy: 0.8761\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0546 - accuracy: 0.9841 - val_loss: 0.4214 - val_accuracy: 0.8728\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0536 - accuracy: 0.9825 - val_loss: 0.3970 - val_accuracy: 0.8750\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0569 - accuracy: 0.9806 - val_loss: 0.4018 - val_accuracy: 0.8825\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0521 - accuracy: 0.9825 - val_loss: 0.4129 - val_accuracy: 0.8825\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0542 - accuracy: 0.9811 - val_loss: 0.4271 - val_accuracy: 0.8728\n","Epoch 81/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0601 - accuracy: 0.9801 - val_loss: 0.4489 - val_accuracy: 0.8782\n","Epoch 82/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1288 - accuracy: 0.9483 - val_loss: 0.4121 - val_accuracy: 0.8847\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0765 - accuracy: 0.9739 - val_loss: 0.4823 - val_accuracy: 0.8621\n","Epoch 84/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0798 - accuracy: 0.9690 - val_loss: 0.4048 - val_accuracy: 0.8815\n","Epoch 85/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0593 - accuracy: 0.9784 - val_loss: 0.4230 - val_accuracy: 0.8739\n","Epoch 86/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0590 - accuracy: 0.9795 - val_loss: 0.3944 - val_accuracy: 0.8825\n","Epoch 87/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0508 - accuracy: 0.9844 - val_loss: 0.4067 - val_accuracy: 0.8804\n","Epoch 88/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0601 - accuracy: 0.9779 - val_loss: 0.4047 - val_accuracy: 0.8815\n","Epoch 89/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0441 - accuracy: 0.9865 - val_loss: 0.4258 - val_accuracy: 0.8815\n","Epoch 90/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0595 - accuracy: 0.9790 - val_loss: 0.4320 - val_accuracy: 0.8772\n","Epoch 91/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0501 - accuracy: 0.9820 - val_loss: 0.4203 - val_accuracy: 0.8782\n","Epoch 92/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0529 - accuracy: 0.9836 - val_loss: 0.4216 - val_accuracy: 0.8761\n","Epoch 93/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0503 - accuracy: 0.9825 - val_loss: 0.4260 - val_accuracy: 0.8815\n","Epoch 94/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0476 - accuracy: 0.9833 - val_loss: 0.4863 - val_accuracy: 0.8664\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0448 - accuracy: 0.9849 - val_loss: 0.4667 - val_accuracy: 0.8707\n","Epoch 96/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0429 - accuracy: 0.9846 - val_loss: 0.4572 - val_accuracy: 0.8728\n","Epoch 97/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0379 - accuracy: 0.9871 - val_loss: 0.4411 - val_accuracy: 0.8739\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0415 - accuracy: 0.9863 - val_loss: 0.4777 - val_accuracy: 0.8739\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0413 - accuracy: 0.9881 - val_loss: 0.4852 - val_accuracy: 0.8782\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0392 - accuracy: 0.9879 - val_loss: 0.4872 - val_accuracy: 0.8728\n","{'loss': [0.22025932371616364, 0.18912503123283386, 0.19259101152420044, 0.18139854073524475, 0.183648481965065, 0.17640724778175354, 0.1845908761024475, 0.17496377229690552, 0.17089878022670746, 0.16495615243911743, 0.15678364038467407, 0.15638896822929382, 0.15734581649303436, 0.15847855806350708, 0.15652206540107727, 0.14560925960540771, 0.15743863582611084, 0.14418894052505493, 0.12993194162845612, 0.13238997757434845, 0.13615158200263977, 0.13701659440994263, 0.15393956005573273, 0.13558433949947357, 0.13709361851215363, 0.12387204170227051, 0.1396930068731308, 0.1248917430639267, 0.11540094017982483, 0.12691181898117065, 0.13012266159057617, 0.11275544762611389, 0.1169959083199501, 0.12096226960420609, 0.10743945837020874, 0.10430537909269333, 0.11236164718866348, 0.1119275614619255, 0.10577426105737686, 0.09615587443113327, 0.09841123223304749, 0.10390228778123856, 0.11563616991043091, 0.1185322105884552, 0.10660667717456818, 0.10062439739704132, 0.09139384329319, 0.09637007117271423, 0.09619873762130737, 0.08250211924314499, 0.08005456626415253, 0.09529804438352585, 0.10238588601350784, 0.08433127403259277, 0.08549538254737854, 0.07481970638036728, 0.06998150050640106, 0.07758673280477524, 0.07906044274568558, 0.07720920443534851, 0.07423730194568634, 0.06679783761501312, 0.06328605860471725, 0.07105626910924911, 0.07042040675878525, 0.06741730123758316, 0.06825912743806839, 0.06445813924074173, 0.06668820232152939, 0.08130485564470291, 0.061417367309331894, 0.06603045761585236, 0.08001138269901276, 0.06522364169359207, 0.05757628753781319, 0.0545637272298336, 0.053615979850292206, 0.056869976222515106, 0.0521293506026268, 0.0542457140982151, 0.06009270250797272, 0.12879419326782227, 0.07647773623466492, 0.07980126142501831, 0.05928623676300049, 0.05898613855242729, 0.05078733339905739, 0.060146816074848175, 0.04413766413927078, 0.059495966881513596, 0.050122711807489395, 0.052894677966833115, 0.05034414678812027, 0.04763096943497658, 0.044811856001615524, 0.04288942366838455, 0.03785506263375282, 0.04145391657948494, 0.041321590542793274, 0.03921328857541084], 'accuracy': [0.9094827771186829, 0.9256465435028076, 0.9253771305084229, 0.9299569129943848, 0.9304956793785095, 0.931303858757019, 0.9307650923728943, 0.9364224076271057, 0.9364224076271057, 0.9372305870056152, 0.9428879022598267, 0.9412715435028076, 0.9423491358757019, 0.9410021305084229, 0.9412715435028076, 0.9474676847457886, 0.938847005367279, 0.9480064511299133, 0.9555495977401733, 0.954472005367279, 0.9482758641242981, 0.9496228694915771, 0.9401939511299133, 0.9480064511299133, 0.9482758641242981, 0.9558189511299133, 0.9493534564971924, 0.9579741358757019, 0.9587823152542114, 0.9533944129943848, 0.953125, 0.9612069129943848, 0.962284505367279, 0.9563577771186829, 0.9628232717514038, 0.962553858757019, 0.9587823152542114, 0.9577047228813171, 0.9620150923728943, 0.9655172228813171, 0.9679418206214905, 0.9647090435028076, 0.9585129022598267, 0.9550107717514038, 0.9644396305084229, 0.9647090435028076, 0.9717133641242981, 0.9684805870056152, 0.967133641242981, 0.9725215435028076, 0.9714439511299133, 0.9647090435028076, 0.9617456793785095, 0.9719827771186829, 0.9682112336158752, 0.9757543206214905, 0.9773706793785095, 0.9741379022598267, 0.9719827771186829, 0.9757543206214905, 0.975215494632721, 0.9789870977401733, 0.9803340435028076, 0.9725215435028076, 0.9768319129943848, 0.9765625, 0.977909505367279, 0.9784482717514038, 0.9746767282485962, 0.9719827771186829, 0.977909505367279, 0.9762930870056152, 0.9698275923728943, 0.9811422228813171, 0.9806034564971924, 0.9841055870056152, 0.9824892282485962, 0.9806034564971924, 0.9824892282485962, 0.9811422228813171, 0.9800646305084229, 0.9482758641242981, 0.9738685488700867, 0.9690194129943848, 0.9784482717514038, 0.9795258641242981, 0.984375, 0.977909505367279, 0.9865301847457886, 0.9789870977401733, 0.9819504022598267, 0.9835668206214905, 0.9824892282485962, 0.9832974076271057, 0.9849137663841248, 0.9846444129943848, 0.9870689511299133, 0.9862607717514038, 0.9881465435028076, 0.9878771305084229], 'val_loss': [0.7070789933204651, 0.7061448693275452, 0.7048431038856506, 0.7035338282585144, 0.702663242816925, 0.70000159740448, 0.6969033479690552, 0.6791385412216187, 0.6745712161064148, 0.6499883532524109, 0.6236345171928406, 0.5963954925537109, 0.5924842953681946, 0.5341147184371948, 0.4895806908607483, 0.4762659966945648, 0.4188387095928192, 0.44476988911628723, 0.3797370195388794, 0.3354787826538086, 0.355856716632843, 0.28341367840766907, 0.29275956749916077, 0.3230791985988617, 0.28399625420570374, 0.31671419739723206, 0.270343542098999, 0.2779863476753235, 0.28596198558807373, 0.3118136525154114, 0.29777079820632935, 0.2970843017101288, 0.33504176139831543, 0.377017080783844, 0.3222379982471466, 0.3176499009132385, 0.3801319897174835, 0.3392229676246643, 0.3523300290107727, 0.3326249420642853, 0.3632971942424774, 0.32666459679603577, 0.3618699312210083, 0.3602311611175537, 0.32331985235214233, 0.3612937927246094, 0.34644728899002075, 0.3428429961204529, 0.34559983015060425, 0.3392083942890167, 0.3664094805717468, 0.34804704785346985, 0.34885019063949585, 0.3488193154335022, 0.3497774302959442, 0.3540003299713135, 0.36812424659729004, 0.3660183250904083, 0.4258762001991272, 0.4761773943901062, 0.36289742588996887, 0.3729798495769501, 0.366328626871109, 0.3778132200241089, 0.39803189039230347, 0.37491175532341003, 0.38957443833351135, 0.39432260394096375, 0.4085063338279724, 0.38505321741104126, 0.38553646206855774, 0.3991563320159912, 0.4125008285045624, 0.39686915278434753, 0.39322730898857117, 0.42139288783073425, 0.3969636857509613, 0.4017617404460907, 0.41290411353111267, 0.42709487676620483, 0.44893309473991394, 0.41206109523773193, 0.4823211133480072, 0.4048241376876831, 0.42302802205085754, 0.3944207429885864, 0.40673792362213135, 0.4046572744846344, 0.4257841408252716, 0.43198415637016296, 0.4203374683856964, 0.42156660556793213, 0.4260406196117401, 0.48632222414016724, 0.46667346358299255, 0.45721322298049927, 0.44113701581954956, 0.4777213931083679, 0.48522403836250305, 0.4871717095375061], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48706895112991333, 0.49568966031074524, 0.5150862336158752, 0.5581896305084229, 0.5538793206214905, 0.6831896305084229, 0.7726293206214905, 0.7553879022598267, 0.8448275923728943, 0.7693965435028076, 0.8394396305084229, 0.8663793206214905, 0.8491379022598267, 0.889008641242981, 0.881465494632721, 0.8663793206214905, 0.8879310488700867, 0.8728448152542114, 0.8976293206214905, 0.8976293206214905, 0.8933189511299133, 0.8868534564971924, 0.9030172228813171, 0.9030172228813171, 0.881465494632721, 0.8663793206214905, 0.8803879022598267, 0.8911637663841248, 0.8663793206214905, 0.8879310488700867, 0.8803879022598267, 0.8868534564971924, 0.8760775923728943, 0.8911637663841248, 0.8825430870056152, 0.8846982717514038, 0.892241358757019, 0.8771551847457886, 0.8836206793785095, 0.8771551847457886, 0.8760775923728943, 0.8900862336158752, 0.8771551847457886, 0.8943965435028076, 0.8782327771186829, 0.8857758641242981, 0.889008641242981, 0.8825430870056152, 0.8782327771186829, 0.8868534564971924, 0.8663793206214905, 0.8534482717514038, 0.8836206793785095, 0.8900862336158752, 0.8933189511299133, 0.8868534564971924, 0.8760775923728943, 0.8803879022598267, 0.8771551847457886, 0.8803879022598267, 0.8771551847457886, 0.881465494632721, 0.8782327771186829, 0.8836206793785095, 0.8706896305084229, 0.8782327771186829, 0.8760775923728943, 0.8728448152542114, 0.875, 0.8825430870056152, 0.8825430870056152, 0.8728448152542114, 0.8782327771186829, 0.8846982717514038, 0.8620689511299133, 0.881465494632721, 0.8739224076271057, 0.8825430870056152, 0.8803879022598267, 0.881465494632721, 0.881465494632721, 0.8771551847457886, 0.8782327771186829, 0.8760775923728943, 0.881465494632721, 0.8663793206214905, 0.8706896305084229, 0.8728448152542114, 0.8739224076271057, 0.8739224076271057, 0.8782327771186829, 0.8728448152542114]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.2237 - accuracy: 0.9137"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 11s 198ms/step - loss: 0.2242 - accuracy: 0.9134 - val_loss: 0.7042 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2032 - accuracy: 0.9225 - val_loss: 0.7031 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2007 - accuracy: 0.9208 - val_loss: 0.7026 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2081 - accuracy: 0.9174 - val_loss: 0.7012 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1926 - accuracy: 0.9284 - val_loss: 0.6982 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1879 - accuracy: 0.9281 - val_loss: 0.6983 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1878 - accuracy: 0.9256 - val_loss: 0.6930 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1805 - accuracy: 0.9315 - val_loss: 0.6898 - val_accuracy: 0.4955\n","Epoch 9/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.1862 - accuracy: 0.9281 - val_loss: 0.6789 - val_accuracy: 0.4966\n","Epoch 10/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.1815 - accuracy: 0.9284 - val_loss: 0.6494 - val_accuracy: 0.5057\n","Epoch 11/100\n","28/28 [==============================] - 1s 39ms/step - loss: 0.1669 - accuracy: 0.9380 - val_loss: 0.6404 - val_accuracy: 0.5102\n","Epoch 12/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.1728 - accuracy: 0.9329 - val_loss: 0.6139 - val_accuracy: 0.5373\n","Epoch 13/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.1667 - accuracy: 0.9386 - val_loss: 0.5918 - val_accuracy: 0.5701\n","Epoch 14/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.1731 - accuracy: 0.9324 - val_loss: 0.5714 - val_accuracy: 0.6018\n","Epoch 15/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.1593 - accuracy: 0.9369 - val_loss: 0.5301 - val_accuracy: 0.7036\n","Epoch 16/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.1704 - accuracy: 0.9329 - val_loss: 0.5028 - val_accuracy: 0.7330\n","Epoch 17/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.1716 - accuracy: 0.9312 - val_loss: 0.4856 - val_accuracy: 0.7455\n","Epoch 18/100\n","28/28 [==============================] - 3s 97ms/step - loss: 0.1556 - accuracy: 0.9431 - val_loss: 0.4199 - val_accuracy: 0.8382\n","Epoch 19/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.1615 - accuracy: 0.9335 - val_loss: 0.4038 - val_accuracy: 0.8269\n","Epoch 20/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1508 - accuracy: 0.9417 - val_loss: 0.4054 - val_accuracy: 0.8111\n","Epoch 21/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1621 - accuracy: 0.9383 - val_loss: 0.3923 - val_accuracy: 0.8133\n","Epoch 22/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.1570 - accuracy: 0.9386 - val_loss: 0.3443 - val_accuracy: 0.8529\n","Epoch 23/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.1590 - accuracy: 0.9352 - val_loss: 0.3119 - val_accuracy: 0.8710\n","Epoch 24/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1625 - accuracy: 0.9344 - val_loss: 0.3234 - val_accuracy: 0.8665\n","Epoch 25/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.1432 - accuracy: 0.9462 - val_loss: 0.2980 - val_accuracy: 0.8733\n","Epoch 26/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.1335 - accuracy: 0.9522 - val_loss: 0.2927 - val_accuracy: 0.8756\n","Epoch 27/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.1359 - accuracy: 0.9533 - val_loss: 0.2905 - val_accuracy: 0.8846\n","Epoch 28/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1339 - accuracy: 0.9533 - val_loss: 0.2996 - val_accuracy: 0.8767\n","Epoch 29/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1392 - accuracy: 0.9505 - val_loss: 0.3042 - val_accuracy: 0.8733\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1419 - accuracy: 0.9462 - val_loss: 0.3219 - val_accuracy: 0.8643\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1254 - accuracy: 0.9530 - val_loss: 0.3349 - val_accuracy: 0.8699\n","Epoch 32/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1303 - accuracy: 0.9547 - val_loss: 0.3116 - val_accuracy: 0.8801\n","Epoch 33/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.1336 - accuracy: 0.9485 - val_loss: 0.3176 - val_accuracy: 0.8857\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1233 - accuracy: 0.9550 - val_loss: 0.3223 - val_accuracy: 0.8824\n","Epoch 35/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1222 - accuracy: 0.9561 - val_loss: 0.3180 - val_accuracy: 0.8824\n","Epoch 36/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1207 - accuracy: 0.9564 - val_loss: 0.3229 - val_accuracy: 0.8812\n","Epoch 37/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1200 - accuracy: 0.9578 - val_loss: 0.3363 - val_accuracy: 0.8767\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1451 - accuracy: 0.9454 - val_loss: 0.3855 - val_accuracy: 0.8643\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1332 - accuracy: 0.9513 - val_loss: 0.3369 - val_accuracy: 0.8824\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1216 - accuracy: 0.9542 - val_loss: 0.3301 - val_accuracy: 0.8857\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1190 - accuracy: 0.9542 - val_loss: 0.3381 - val_accuracy: 0.8846\n","Epoch 42/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.1057 - accuracy: 0.9624 - val_loss: 0.3637 - val_accuracy: 0.8699\n","Epoch 43/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1122 - accuracy: 0.9604 - val_loss: 0.3342 - val_accuracy: 0.8835\n","Epoch 44/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1082 - accuracy: 0.9629 - val_loss: 0.3348 - val_accuracy: 0.8778\n","Epoch 45/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1136 - accuracy: 0.9576 - val_loss: 0.3407 - val_accuracy: 0.8846\n","Epoch 46/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.1070 - accuracy: 0.9632 - val_loss: 0.4173 - val_accuracy: 0.8507\n","Epoch 47/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.1171 - accuracy: 0.9556 - val_loss: 0.3436 - val_accuracy: 0.8846\n","Epoch 48/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.1078 - accuracy: 0.9615 - val_loss: 0.3434 - val_accuracy: 0.8857\n","Epoch 49/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.1171 - accuracy: 0.9590 - val_loss: 0.3521 - val_accuracy: 0.8903\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1013 - accuracy: 0.9663 - val_loss: 0.3493 - val_accuracy: 0.8756\n","Epoch 51/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1005 - accuracy: 0.9646 - val_loss: 0.3588 - val_accuracy: 0.8857\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0917 - accuracy: 0.9706 - val_loss: 0.3569 - val_accuracy: 0.8801\n","Epoch 53/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1010 - accuracy: 0.9646 - val_loss: 0.3524 - val_accuracy: 0.8835\n","Epoch 54/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0892 - accuracy: 0.9677 - val_loss: 0.3649 - val_accuracy: 0.8710\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1092 - accuracy: 0.9590 - val_loss: 0.4167 - val_accuracy: 0.8722\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0965 - accuracy: 0.9649 - val_loss: 0.3502 - val_accuracy: 0.8835\n","Epoch 57/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0887 - accuracy: 0.9711 - val_loss: 0.3609 - val_accuracy: 0.8744\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0940 - accuracy: 0.9666 - val_loss: 0.3729 - val_accuracy: 0.8767\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0884 - accuracy: 0.9669 - val_loss: 0.3649 - val_accuracy: 0.8790\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0850 - accuracy: 0.9748 - val_loss: 0.3649 - val_accuracy: 0.8778\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0844 - accuracy: 0.9723 - val_loss: 0.4114 - val_accuracy: 0.8654\n","Epoch 62/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0991 - accuracy: 0.9593 - val_loss: 0.3711 - val_accuracy: 0.8824\n","Epoch 63/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0801 - accuracy: 0.9743 - val_loss: 0.3844 - val_accuracy: 0.8790\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0742 - accuracy: 0.9785 - val_loss: 0.3832 - val_accuracy: 0.8767\n","Epoch 65/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0761 - accuracy: 0.9720 - val_loss: 0.4220 - val_accuracy: 0.8722\n","Epoch 66/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0796 - accuracy: 0.9728 - val_loss: 0.4826 - val_accuracy: 0.8586\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0972 - accuracy: 0.9635 - val_loss: 0.4061 - val_accuracy: 0.8756\n","Epoch 68/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0780 - accuracy: 0.9745 - val_loss: 0.4351 - val_accuracy: 0.8654\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0788 - accuracy: 0.9726 - val_loss: 0.4039 - val_accuracy: 0.8790\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1049 - accuracy: 0.9618 - val_loss: 0.5828 - val_accuracy: 0.8428\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0809 - accuracy: 0.9751 - val_loss: 0.3866 - val_accuracy: 0.8835\n","Epoch 72/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0739 - accuracy: 0.9765 - val_loss: 0.3843 - val_accuracy: 0.8824\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0655 - accuracy: 0.9819 - val_loss: 0.4247 - val_accuracy: 0.8665\n","Epoch 74/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0765 - accuracy: 0.9731 - val_loss: 0.3958 - val_accuracy: 0.8756\n","Epoch 75/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0706 - accuracy: 0.9757 - val_loss: 0.3944 - val_accuracy: 0.8846\n","Epoch 76/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0710 - accuracy: 0.9751 - val_loss: 0.4049 - val_accuracy: 0.8733\n","Epoch 77/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0664 - accuracy: 0.9771 - val_loss: 0.4129 - val_accuracy: 0.8733\n","Epoch 78/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0636 - accuracy: 0.9793 - val_loss: 0.4021 - val_accuracy: 0.8835\n","Epoch 79/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0674 - accuracy: 0.9782 - val_loss: 0.4073 - val_accuracy: 0.8824\n","Epoch 80/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0598 - accuracy: 0.9825 - val_loss: 0.4082 - val_accuracy: 0.8801\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0604 - accuracy: 0.9813 - val_loss: 0.4045 - val_accuracy: 0.8778\n","Epoch 82/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0570 - accuracy: 0.9827 - val_loss: 0.4450 - val_accuracy: 0.8631\n","Epoch 83/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0947 - accuracy: 0.9641 - val_loss: 0.4204 - val_accuracy: 0.8790\n","Epoch 84/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0716 - accuracy: 0.9757 - val_loss: 0.4158 - val_accuracy: 0.8676\n","Epoch 85/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0626 - accuracy: 0.9788 - val_loss: 0.4074 - val_accuracy: 0.8767\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0553 - accuracy: 0.9810 - val_loss: 0.4563 - val_accuracy: 0.8620\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0613 - accuracy: 0.9793 - val_loss: 0.4089 - val_accuracy: 0.8767\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0623 - accuracy: 0.9793 - val_loss: 0.5125 - val_accuracy: 0.8654\n","Epoch 89/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0662 - accuracy: 0.9768 - val_loss: 0.4499 - val_accuracy: 0.8744\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0506 - accuracy: 0.9853 - val_loss: 0.4223 - val_accuracy: 0.8744\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0525 - accuracy: 0.9830 - val_loss: 0.4238 - val_accuracy: 0.8790\n","Epoch 92/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0530 - accuracy: 0.9827 - val_loss: 0.4197 - val_accuracy: 0.8756\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0514 - accuracy: 0.9853 - val_loss: 0.4750 - val_accuracy: 0.8643\n","Epoch 94/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0559 - accuracy: 0.9810 - val_loss: 0.4371 - val_accuracy: 0.8744\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0542 - accuracy: 0.9816 - val_loss: 0.4265 - val_accuracy: 0.8835\n","Epoch 96/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0495 - accuracy: 0.9856 - val_loss: 0.4498 - val_accuracy: 0.8688\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0651 - accuracy: 0.9757 - val_loss: 0.4390 - val_accuracy: 0.8846\n","Epoch 98/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0491 - accuracy: 0.9867 - val_loss: 0.4335 - val_accuracy: 0.8846\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0453 - accuracy: 0.9867 - val_loss: 0.4317 - val_accuracy: 0.8756\n","Epoch 100/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0501 - accuracy: 0.9844 - val_loss: 0.4424 - val_accuracy: 0.8801\n","{'loss': [0.22422583401203156, 0.20324715971946716, 0.200667604804039, 0.20809786021709442, 0.19256550073623657, 0.18793614208698273, 0.18776258826255798, 0.180548295378685, 0.18624478578567505, 0.18147939443588257, 0.16688421368598938, 0.1728103905916214, 0.16665323078632355, 0.1731155812740326, 0.15925367176532745, 0.17037475109100342, 0.17159155011177063, 0.155607208609581, 0.1614939421415329, 0.15083876252174377, 0.1620536595582962, 0.156999871134758, 0.15898866951465607, 0.1624527871608734, 0.14321735501289368, 0.13350041210651398, 0.13587306439876556, 0.13390715420246124, 0.13924451172351837, 0.1418902724981308, 0.1253601461648941, 0.13026833534240723, 0.13364772498607635, 0.12333822250366211, 0.12220246344804764, 0.12066923826932907, 0.11997964233160019, 0.14505472779273987, 0.13324563205242157, 0.12156406044960022, 0.11897143721580505, 0.10565522313117981, 0.11215297132730484, 0.10819251090288162, 0.11362893879413605, 0.10700222849845886, 0.11707852780818939, 0.10775425285100937, 0.11712606996297836, 0.10131148248910904, 0.10050742328166962, 0.09171818941831589, 0.1010468602180481, 0.08918916434049606, 0.10922492295503616, 0.09647034108638763, 0.08872557431459427, 0.09399177134037018, 0.08841859549283981, 0.08500577509403229, 0.08440574258565903, 0.0991310179233551, 0.08012712001800537, 0.07423987239599228, 0.07612863928079605, 0.07955846935510635, 0.09717373549938202, 0.07799716293811798, 0.07875408232212067, 0.10488100349903107, 0.08091587573289871, 0.07393647730350494, 0.06547800451517105, 0.07651801407337189, 0.0705939307808876, 0.07100426405668259, 0.06644035875797272, 0.06356275081634521, 0.06742614507675171, 0.059846144169569016, 0.06040593609213829, 0.05703341215848923, 0.09469744563102722, 0.07155490666627884, 0.06262142211198807, 0.055322397500276566, 0.061346691101789474, 0.0622686930000782, 0.06618864089250565, 0.05061422660946846, 0.0524781160056591, 0.0530073456466198, 0.05138356238603592, 0.05593167245388031, 0.05421284958720207, 0.04946312680840492, 0.06511656939983368, 0.04911308363080025, 0.0452607087790966, 0.05006614699959755], 'accuracy': [0.9134125709533691, 0.9224674701690674, 0.9207696914672852, 0.9173740744590759, 0.92840975522995, 0.9281267523765564, 0.9255800843238831, 0.9315223693847656, 0.9281267523765564, 0.92840975522995, 0.9380305409431458, 0.9329372048377991, 0.9385964870452881, 0.9323712587356567, 0.9368987083435059, 0.9329372048377991, 0.9312393665313721, 0.9431239366531372, 0.9335030913352966, 0.9417091012001038, 0.9383135437965393, 0.9385964870452881, 0.9352009296417236, 0.9343519806861877, 0.9462365508079529, 0.9521788358688354, 0.9533106684684753, 0.9533106684684753, 0.9504810571670532, 0.9462365508079529, 0.9530277252197266, 0.9547255039215088, 0.9485002756118774, 0.9550085067749023, 0.9561403393745422, 0.9564233422279358, 0.9578381180763245, 0.9453876614570618, 0.9513299465179443, 0.9541596174240112, 0.9541596174240112, 0.9623655676841736, 0.9603848457336426, 0.9629315137863159, 0.9575551748275757, 0.9632145166397095, 0.9555743932723999, 0.9615166783332825, 0.9589700102806091, 0.9663271307945251, 0.9646292924880981, 0.9705715775489807, 0.9646292924880981, 0.9677419066429138, 0.9589700102806091, 0.9649122953414917, 0.971137523651123, 0.9666100740432739, 0.9668930172920227, 0.974816083908081, 0.9722693562507629, 0.9592529535293579, 0.9742501378059387, 0.9784946441650391, 0.9719864130020142, 0.9728353023529053, 0.9634974598884583, 0.9745330810546875, 0.9725523591041565, 0.961799681186676, 0.9750990271568298, 0.9765138626098633, 0.9818902015686035, 0.9731183052062988, 0.9756649732589722, 0.9750990271568298, 0.9770798087120056, 0.9793435335159302, 0.9782116413116455, 0.9824561476707458, 0.9813242554664612, 0.9827390909194946, 0.9640634059906006, 0.9756649732589722, 0.9787775874137878, 0.9810413122177124, 0.9793435335159302, 0.9793435335159302, 0.9767968058586121, 0.9852858185768127, 0.9830220937728882, 0.9827390909194946, 0.9852858185768127, 0.9810413122177124, 0.9816072583198547, 0.9855687618255615, 0.9756649732589722, 0.9867005944252014, 0.9867005944252014, 0.9844368696212769], 'val_loss': [0.7042410373687744, 0.7030743360519409, 0.7026192545890808, 0.7011663913726807, 0.6981977224349976, 0.6982687711715698, 0.6930314898490906, 0.6898132562637329, 0.6789491176605225, 0.6494242548942566, 0.6404234170913696, 0.6139424443244934, 0.5917842984199524, 0.571418285369873, 0.5300904512405396, 0.5028098225593567, 0.4855720102787018, 0.41990405321121216, 0.4038469195365906, 0.4053710997104645, 0.39231693744659424, 0.34429317712783813, 0.31193089485168457, 0.323438435792923, 0.29795747995376587, 0.29273727536201477, 0.29054930806159973, 0.29962798953056335, 0.3041672110557556, 0.32194942235946655, 0.3348985016345978, 0.3115995526313782, 0.31762591004371643, 0.32225507497787476, 0.31797483563423157, 0.3229348361492157, 0.3363276720046997, 0.385548859834671, 0.33694005012512207, 0.33014512062072754, 0.3381245732307434, 0.3637073338031769, 0.3341570496559143, 0.3348471522331238, 0.3406827747821808, 0.41726088523864746, 0.3436155915260315, 0.3434203565120697, 0.35212570428848267, 0.34929198026657104, 0.35880401730537415, 0.35688167810440063, 0.3523544371128082, 0.3648701310157776, 0.41669121384620667, 0.3502230644226074, 0.36086538434028625, 0.3728550672531128, 0.3649134933948517, 0.3648698925971985, 0.4114387035369873, 0.37109002470970154, 0.38436663150787354, 0.3831537365913391, 0.42203256487846375, 0.4826492965221405, 0.40610548853874207, 0.4351361393928528, 0.4038562774658203, 0.5827799439430237, 0.3866056203842163, 0.38432008028030396, 0.4247134327888489, 0.3958481252193451, 0.39442479610443115, 0.4048597812652588, 0.4128817617893219, 0.4020884335041046, 0.40726107358932495, 0.40817680954933167, 0.40446799993515015, 0.44495201110839844, 0.4203713536262512, 0.4157848656177521, 0.4074116051197052, 0.45627009868621826, 0.4089414179325104, 0.5124526619911194, 0.44985222816467285, 0.42233848571777344, 0.42380595207214355, 0.4196969270706177, 0.4750114679336548, 0.43713587522506714, 0.42647016048431396, 0.44984132051467896, 0.4389853775501251, 0.4334937036037445, 0.4316835403442383, 0.4424431622028351], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.5056561231613159, 0.5101810097694397, 0.5373303294181824, 0.570135772228241, 0.6018099784851074, 0.7036198973655701, 0.733031690120697, 0.7454751133918762, 0.8382353186607361, 0.8269230723381042, 0.8110859990119934, 0.8133484125137329, 0.8529411554336548, 0.8710407018661499, 0.8665158152580261, 0.8733031749725342, 0.8755655884742737, 0.8846153616905212, 0.8766968250274658, 0.8733031749725342, 0.8642534017562866, 0.8699095249176025, 0.8800904750823975, 0.8857465982437134, 0.8823529481887817, 0.8823529481887817, 0.8812217116355896, 0.8766968250274658, 0.8642534017562866, 0.8823529481887817, 0.8857465982437134, 0.8846153616905212, 0.8699095249176025, 0.8834841847419739, 0.877828061580658, 0.8846153616905212, 0.8506787419319153, 0.8846153616905212, 0.8857465982437134, 0.8902714848518372, 0.8755655884742737, 0.8857465982437134, 0.8800904750823975, 0.8834841847419739, 0.8710407018661499, 0.872171938419342, 0.8834841847419739, 0.8744344115257263, 0.8766968250274658, 0.8789592981338501, 0.877828061580658, 0.8653846383094788, 0.8823529481887817, 0.8789592981338501, 0.8766968250274658, 0.872171938419342, 0.8585972785949707, 0.8755655884742737, 0.8653846383094788, 0.8789592981338501, 0.8427602052688599, 0.8834841847419739, 0.8823529481887817, 0.8665158152580261, 0.8755655884742737, 0.8846153616905212, 0.8733031749725342, 0.8733031749725342, 0.8834841847419739, 0.8823529481887817, 0.8800904750823975, 0.877828061580658, 0.8631221652030945, 0.8789592981338501, 0.8676470518112183, 0.8766968250274658, 0.8619909286499023, 0.8766968250274658, 0.8653846383094788, 0.8744344115257263, 0.8744344115257263, 0.8789592981338501, 0.8755655884742737, 0.8642534017562866, 0.8744344115257263, 0.8834841847419739, 0.8687782883644104, 0.8846153616905212, 0.8846153616905212, 0.8755655884742737, 0.8800904750823975]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.2188 - accuracy: 0.9142"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 12s 208ms/step - loss: 0.2188 - accuracy: 0.9142 - val_loss: 0.7081 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1882 - accuracy: 0.9238 - val_loss: 0.7071 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1864 - accuracy: 0.9295 - val_loss: 0.7056 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1950 - accuracy: 0.9238 - val_loss: 0.7050 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1823 - accuracy: 0.9269 - val_loss: 0.7042 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1735 - accuracy: 0.9344 - val_loss: 0.7018 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1735 - accuracy: 0.9315 - val_loss: 0.6892 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1776 - accuracy: 0.9264 - val_loss: 0.6781 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.1683 - accuracy: 0.9331 - val_loss: 0.6673 - val_accuracy: 0.4866\n","Epoch 10/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.1700 - accuracy: 0.9349 - val_loss: 0.6416 - val_accuracy: 0.4938\n","Epoch 11/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.1561 - accuracy: 0.9403 - val_loss: 0.5998 - val_accuracy: 0.5599\n","Epoch 12/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.1670 - accuracy: 0.9370 - val_loss: 0.5839 - val_accuracy: 0.5868\n","Epoch 13/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.1531 - accuracy: 0.9413 - val_loss: 0.5495 - val_accuracy: 0.6663\n","Epoch 14/100\n","31/31 [==============================] - 1s 44ms/step - loss: 0.1515 - accuracy: 0.9419 - val_loss: 0.4992 - val_accuracy: 0.7820\n","Epoch 15/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.1493 - accuracy: 0.9442 - val_loss: 0.5022 - val_accuracy: 0.7211\n","Epoch 16/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.1570 - accuracy: 0.9377 - val_loss: 0.4542 - val_accuracy: 0.7872\n","Epoch 17/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.1441 - accuracy: 0.9468 - val_loss: 0.4068 - val_accuracy: 0.8347\n","Epoch 18/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.1396 - accuracy: 0.9496 - val_loss: 0.3669 - val_accuracy: 0.8543\n","Epoch 19/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1375 - accuracy: 0.9470 - val_loss: 0.4224 - val_accuracy: 0.7862\n","Epoch 20/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1368 - accuracy: 0.9501 - val_loss: 0.3427 - val_accuracy: 0.8471\n","Epoch 21/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.1358 - accuracy: 0.9483 - val_loss: 0.3268 - val_accuracy: 0.8595\n","Epoch 22/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.1245 - accuracy: 0.9553 - val_loss: 0.3106 - val_accuracy: 0.8636\n","Epoch 23/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.1345 - accuracy: 0.9501 - val_loss: 0.3060 - val_accuracy: 0.8750\n","Epoch 24/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.1517 - accuracy: 0.9406 - val_loss: 0.3127 - val_accuracy: 0.8760\n","Epoch 25/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1429 - accuracy: 0.9421 - val_loss: 0.3170 - val_accuracy: 0.8740\n","Epoch 26/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1387 - accuracy: 0.9465 - val_loss: 0.3770 - val_accuracy: 0.8492\n","Epoch 27/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1343 - accuracy: 0.9496 - val_loss: 0.3435 - val_accuracy: 0.8719\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1241 - accuracy: 0.9537 - val_loss: 0.3704 - val_accuracy: 0.8574\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1179 - accuracy: 0.9568 - val_loss: 0.3602 - val_accuracy: 0.8698\n","Epoch 30/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1263 - accuracy: 0.9522 - val_loss: 0.3727 - val_accuracy: 0.8678\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1367 - accuracy: 0.9455 - val_loss: 0.3594 - val_accuracy: 0.8750\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1276 - accuracy: 0.9509 - val_loss: 0.3626 - val_accuracy: 0.8760\n","Epoch 33/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1270 - accuracy: 0.9512 - val_loss: 0.3772 - val_accuracy: 0.8719\n","Epoch 34/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1131 - accuracy: 0.9599 - val_loss: 0.3815 - val_accuracy: 0.8657\n","Epoch 35/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.1216 - accuracy: 0.9540 - val_loss: 0.3733 - val_accuracy: 0.8729\n","Epoch 36/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1214 - accuracy: 0.9532 - val_loss: 0.4184 - val_accuracy: 0.8523\n","Epoch 37/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.1155 - accuracy: 0.9576 - val_loss: 0.4067 - val_accuracy: 0.8605\n","Epoch 38/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.1145 - accuracy: 0.9589 - val_loss: 0.4092 - val_accuracy: 0.8616\n","Epoch 39/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.1234 - accuracy: 0.9522 - val_loss: 0.3897 - val_accuracy: 0.8647\n","Epoch 40/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.1051 - accuracy: 0.9602 - val_loss: 0.3944 - val_accuracy: 0.8678\n","Epoch 41/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.1149 - accuracy: 0.9561 - val_loss: 0.4283 - val_accuracy: 0.8543\n","Epoch 42/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1085 - accuracy: 0.9584 - val_loss: 0.3922 - val_accuracy: 0.8719\n","Epoch 43/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0985 - accuracy: 0.9646 - val_loss: 0.3872 - val_accuracy: 0.8729\n","Epoch 44/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1055 - accuracy: 0.9638 - val_loss: 0.4988 - val_accuracy: 0.8357\n","Epoch 45/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1429 - accuracy: 0.9439 - val_loss: 0.3958 - val_accuracy: 0.8688\n","Epoch 46/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0980 - accuracy: 0.9643 - val_loss: 0.3853 - val_accuracy: 0.8760\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0912 - accuracy: 0.9664 - val_loss: 0.3856 - val_accuracy: 0.8750\n","Epoch 48/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0986 - accuracy: 0.9643 - val_loss: 0.4282 - val_accuracy: 0.8574\n","Epoch 49/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1018 - accuracy: 0.9649 - val_loss: 0.4146 - val_accuracy: 0.8678\n","Epoch 50/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0852 - accuracy: 0.9703 - val_loss: 0.3917 - val_accuracy: 0.8750\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0929 - accuracy: 0.9669 - val_loss: 0.4106 - val_accuracy: 0.8740\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0937 - accuracy: 0.9672 - val_loss: 0.4340 - val_accuracy: 0.8667\n","Epoch 53/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0830 - accuracy: 0.9718 - val_loss: 0.4167 - val_accuracy: 0.8688\n","Epoch 54/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0903 - accuracy: 0.9674 - val_loss: 0.4796 - val_accuracy: 0.8450\n","Epoch 55/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0769 - accuracy: 0.9744 - val_loss: 0.4496 - val_accuracy: 0.8564\n","Epoch 56/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0763 - accuracy: 0.9744 - val_loss: 0.4998 - val_accuracy: 0.8440\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0839 - accuracy: 0.9721 - val_loss: 0.4464 - val_accuracy: 0.8667\n","Epoch 58/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0873 - accuracy: 0.9680 - val_loss: 0.4218 - val_accuracy: 0.8719\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0793 - accuracy: 0.9744 - val_loss: 0.4221 - val_accuracy: 0.8719\n","Epoch 60/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0796 - accuracy: 0.9721 - val_loss: 0.4311 - val_accuracy: 0.8740\n","Epoch 61/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0911 - accuracy: 0.9656 - val_loss: 0.4323 - val_accuracy: 0.8729\n","Epoch 62/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0779 - accuracy: 0.9729 - val_loss: 0.4640 - val_accuracy: 0.8574\n","Epoch 63/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0855 - accuracy: 0.9664 - val_loss: 0.5128 - val_accuracy: 0.8368\n","Epoch 64/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0798 - accuracy: 0.9729 - val_loss: 0.4491 - val_accuracy: 0.8760\n","Epoch 65/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0815 - accuracy: 0.9703 - val_loss: 0.4410 - val_accuracy: 0.8698\n","Epoch 66/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0652 - accuracy: 0.9791 - val_loss: 0.4719 - val_accuracy: 0.8636\n","Epoch 67/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0682 - accuracy: 0.9778 - val_loss: 0.4558 - val_accuracy: 0.8709\n","Epoch 68/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0719 - accuracy: 0.9742 - val_loss: 0.5199 - val_accuracy: 0.8399\n","Epoch 69/100\n","31/31 [==============================] - 2s 62ms/step - loss: 0.0747 - accuracy: 0.9721 - val_loss: 0.4477 - val_accuracy: 0.8771\n","Epoch 70/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0799 - accuracy: 0.9711 - val_loss: 0.5623 - val_accuracy: 0.8388\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0919 - accuracy: 0.9656 - val_loss: 0.4768 - val_accuracy: 0.8585\n","Epoch 72/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0655 - accuracy: 0.9788 - val_loss: 0.4491 - val_accuracy: 0.8678\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0610 - accuracy: 0.9809 - val_loss: 0.4532 - val_accuracy: 0.8740\n","Epoch 74/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0633 - accuracy: 0.9791 - val_loss: 0.4897 - val_accuracy: 0.8616\n","Epoch 75/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0635 - accuracy: 0.9770 - val_loss: 0.4670 - val_accuracy: 0.8791\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0761 - accuracy: 0.9705 - val_loss: 0.4760 - val_accuracy: 0.8636\n","Epoch 77/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0584 - accuracy: 0.9804 - val_loss: 0.5145 - val_accuracy: 0.8543\n","Epoch 78/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0760 - accuracy: 0.9736 - val_loss: 0.4799 - val_accuracy: 0.8657\n","Epoch 79/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0896 - accuracy: 0.9659 - val_loss: 0.4664 - val_accuracy: 0.8667\n","Epoch 80/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0576 - accuracy: 0.9824 - val_loss: 0.4611 - val_accuracy: 0.8750\n","Epoch 81/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0580 - accuracy: 0.9824 - val_loss: 0.4695 - val_accuracy: 0.8740\n","Epoch 82/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0663 - accuracy: 0.9767 - val_loss: 0.5282 - val_accuracy: 0.8512\n","Epoch 83/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0670 - accuracy: 0.9752 - val_loss: 0.4886 - val_accuracy: 0.8657\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0538 - accuracy: 0.9819 - val_loss: 0.4670 - val_accuracy: 0.8781\n","Epoch 85/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0549 - accuracy: 0.9817 - val_loss: 0.4809 - val_accuracy: 0.8729\n","Epoch 86/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0544 - accuracy: 0.9801 - val_loss: 0.4803 - val_accuracy: 0.8729\n","Epoch 87/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0621 - accuracy: 0.9791 - val_loss: 0.5268 - val_accuracy: 0.8595\n","Epoch 88/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0470 - accuracy: 0.9855 - val_loss: 0.4808 - val_accuracy: 0.8740\n","Epoch 89/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0522 - accuracy: 0.9853 - val_loss: 0.5132 - val_accuracy: 0.8667\n","Epoch 90/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.0499 - accuracy: 0.9848 - val_loss: 0.5310 - val_accuracy: 0.8564\n","Epoch 91/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0522 - accuracy: 0.9827 - val_loss: 0.5611 - val_accuracy: 0.8492\n","Epoch 92/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0493 - accuracy: 0.9832 - val_loss: 0.4978 - val_accuracy: 0.8781\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0412 - accuracy: 0.9860 - val_loss: 0.4998 - val_accuracy: 0.8771\n","Epoch 94/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0494 - accuracy: 0.9829 - val_loss: 0.5226 - val_accuracy: 0.8636\n","Epoch 95/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0698 - accuracy: 0.9739 - val_loss: 0.5120 - val_accuracy: 0.8688\n","Epoch 96/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0609 - accuracy: 0.9773 - val_loss: 0.4936 - val_accuracy: 0.8709\n","Epoch 97/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0453 - accuracy: 0.9853 - val_loss: 0.5303 - val_accuracy: 0.8616\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0445 - accuracy: 0.9860 - val_loss: 0.5133 - val_accuracy: 0.8678\n","Epoch 99/100\n","31/31 [==============================] - 2s 69ms/step - loss: 0.0417 - accuracy: 0.9866 - val_loss: 0.5081 - val_accuracy: 0.8812\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0487 - accuracy: 0.9819 - val_loss: 0.5493 - val_accuracy: 0.8585\n","{'loss': [0.21880444884300232, 0.18820001184940338, 0.18643070757389069, 0.19500188529491425, 0.18231959640979767, 0.1734643131494522, 0.17353960871696472, 0.17762544751167297, 0.1683344691991806, 0.1700305938720703, 0.1561146229505539, 0.16696706414222717, 0.1531495749950409, 0.15146788954734802, 0.14933133125305176, 0.15702731907367706, 0.14409507811069489, 0.13958857953548431, 0.13749173283576965, 0.1367916613817215, 0.13583508133888245, 0.12452278286218643, 0.13452112674713135, 0.15165120363235474, 0.14290659129619598, 0.13872072100639343, 0.13429662585258484, 0.12412827461957932, 0.11787314713001251, 0.12626191973686218, 0.13669125735759735, 0.1275930255651474, 0.12702134251594543, 0.11309025436639786, 0.12157469987869263, 0.12139460444450378, 0.1154615730047226, 0.1145360991358757, 0.12336519360542297, 0.105061836540699, 0.114863321185112, 0.10850291699171066, 0.09851322323083878, 0.10552533715963364, 0.14292120933532715, 0.09797535091638565, 0.09117290377616882, 0.09855866432189941, 0.10179316997528076, 0.08520837128162384, 0.09288401156663895, 0.09373697638511658, 0.08302176743745804, 0.09030871838331223, 0.0768742635846138, 0.0762639194726944, 0.08388716727495193, 0.08727728575468063, 0.07929813861846924, 0.07955024391412735, 0.09112190455198288, 0.07786469161510468, 0.08552790433168411, 0.07975928485393524, 0.08153548836708069, 0.0652085617184639, 0.06816336512565613, 0.07192829996347427, 0.07472819089889526, 0.07989712059497833, 0.09192484617233276, 0.0655299723148346, 0.06098133698105812, 0.06332367658615112, 0.06351274251937866, 0.07613090425729752, 0.05838583782315254, 0.07596515864133835, 0.08958083391189575, 0.05760985240340233, 0.05804578959941864, 0.06629425287246704, 0.06698445975780487, 0.05381610617041588, 0.05492651090025902, 0.054430920630693436, 0.06205402687191963, 0.04704864323139191, 0.05215030536055565, 0.049873851239681244, 0.05222300440073013, 0.049282852560281754, 0.04119063913822174, 0.049373507499694824, 0.06984046846628189, 0.06085924804210663, 0.04531743749976158, 0.044458795338869095, 0.04172831028699875, 0.04873378947377205], 'accuracy': [0.9142118692398071, 0.9237726330757141, 0.9294573664665222, 0.9237726330757141, 0.9268733859062195, 0.9343669414520264, 0.9315245747566223, 0.9263566136360168, 0.933074951171875, 0.934883713722229, 0.9403100609779358, 0.9369509220123291, 0.9413436651229858, 0.9418604373931885, 0.9441860318183899, 0.9377260804176331, 0.9467700123786926, 0.9496123790740967, 0.947028398513794, 0.9501292109489441, 0.9483203887939453, 0.9552971720695496, 0.9501292109489441, 0.9405684471130371, 0.9421188831329346, 0.9465116262435913, 0.9496123790740967, 0.9537467956542969, 0.9568475484848022, 0.9521963596343994, 0.9454780220985413, 0.950904369354248, 0.9511628150939941, 0.9599483013153076, 0.9540051817893982, 0.9532299637794495, 0.957622766494751, 0.9589147567749023, 0.9521963596343994, 0.9602067470550537, 0.9560723304748535, 0.9583979249000549, 0.9645994901657104, 0.9638242721557617, 0.9439276456832886, 0.9643411040306091, 0.9664082527160645, 0.9643411040306091, 0.9648578763008118, 0.9702842235565186, 0.9669250845909119, 0.9671834707260132, 0.9718345999717712, 0.9674418568611145, 0.974418580532074, 0.974418580532074, 0.9720930457115173, 0.9679586291313171, 0.974418580532074, 0.9720930457115173, 0.9656330943107605, 0.9728682041168213, 0.9664082527160645, 0.9728682041168213, 0.9702842235565186, 0.9790697693824768, 0.9777777791023254, 0.9741601943969727, 0.9720930457115173, 0.9710594415664673, 0.9656330943107605, 0.9788113832473755, 0.9808785319328308, 0.9790697693824768, 0.9770025610923767, 0.9705426096916199, 0.9803617596626282, 0.97364342212677, 0.9658914804458618, 0.9824289679527283, 0.9824289679527283, 0.9767441749572754, 0.9751937985420227, 0.9819121360778809, 0.9816537499427795, 0.9801033735275269, 0.9790697693824768, 0.9855297207832336, 0.9852713346481323, 0.9847545027732849, 0.9826873540878296, 0.9832041263580322, 0.9860464930534363, 0.9829457402229309, 0.9739018082618713, 0.9772610068321228, 0.9852713346481323, 0.9860464930534363, 0.9865633249282837, 0.9819121360778809], 'val_loss': [0.7081336379051208, 0.7070889472961426, 0.7056248188018799, 0.705028772354126, 0.7042467594146729, 0.7017512321472168, 0.6891975998878479, 0.6781473755836487, 0.6673411130905151, 0.641552209854126, 0.5997670292854309, 0.5838525891304016, 0.5495224595069885, 0.49923285841941833, 0.5021702647209167, 0.45418596267700195, 0.40684500336647034, 0.3668583929538727, 0.42238810658454895, 0.3426801264286041, 0.32676610350608826, 0.3106191158294678, 0.30601054430007935, 0.31274205446243286, 0.3169794976711273, 0.37699493765830994, 0.343517929315567, 0.3704368770122528, 0.3601778745651245, 0.37269875407218933, 0.3594259023666382, 0.36264345049858093, 0.37722501158714294, 0.3814828395843506, 0.3732500970363617, 0.41836681962013245, 0.40674594044685364, 0.40921878814697266, 0.3896515667438507, 0.39439401030540466, 0.4282960295677185, 0.3921954929828644, 0.38719046115875244, 0.4987843334674835, 0.3957785964012146, 0.38525837659835815, 0.3855954706668854, 0.42816469073295593, 0.414551317691803, 0.3917415142059326, 0.4105798304080963, 0.4339958131313324, 0.416698157787323, 0.479591429233551, 0.44961604475975037, 0.49982503056526184, 0.4464460015296936, 0.4218076467514038, 0.4221421778202057, 0.43112313747406006, 0.4323188066482544, 0.4640195369720459, 0.5127716660499573, 0.4490625858306885, 0.44101443886756897, 0.4718896150588989, 0.45575574040412903, 0.5199035406112671, 0.44769197702407837, 0.5623148679733276, 0.47676289081573486, 0.449052095413208, 0.45318207144737244, 0.4897382855415344, 0.46700790524482727, 0.4760379493236542, 0.5145333409309387, 0.4798845946788788, 0.4663826823234558, 0.46111032366752625, 0.46952709555625916, 0.5282493829727173, 0.4885522127151489, 0.4670353829860687, 0.48091059923171997, 0.48030003905296326, 0.5267660617828369, 0.480840265750885, 0.5131976008415222, 0.5309978127479553, 0.561134934425354, 0.49779126048088074, 0.49982497096061707, 0.5225524306297302, 0.5120319128036499, 0.49356764554977417, 0.5303471684455872, 0.513264536857605, 0.5080935955047607, 0.5493247509002686], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.49380165338516235, 0.5599173307418823, 0.586776852607727, 0.6663222908973694, 0.7820248007774353, 0.7210744023323059, 0.7871900796890259, 0.8347107172012329, 0.8543388247489929, 0.7861570119857788, 0.8471074104309082, 0.8595041036605835, 0.8636363744735718, 0.875, 0.8760330677032471, 0.8739669322967529, 0.8491735458374023, 0.8719007968902588, 0.8574380278587341, 0.8698347210884094, 0.8677685856819153, 0.875, 0.8760330677032471, 0.8719007968902588, 0.8657024502754211, 0.8729338645935059, 0.8522727489471436, 0.8605371713638306, 0.8615702390670776, 0.8646694421768188, 0.8677685856819153, 0.8543388247489929, 0.8719007968902588, 0.8729338645935059, 0.83574378490448, 0.8688016533851624, 0.8760330677032471, 0.875, 0.8574380278587341, 0.8677685856819153, 0.875, 0.8739669322967529, 0.8667355179786682, 0.8688016533851624, 0.8450413346290588, 0.8564049601554871, 0.8440082669258118, 0.8667355179786682, 0.8719007968902588, 0.8719007968902588, 0.8739669322967529, 0.8729338645935059, 0.8574380278587341, 0.836776852607727, 0.8760330677032471, 0.8698347210884094, 0.8636363744735718, 0.8708677887916565, 0.8398760557174683, 0.8770661354064941, 0.8388429880142212, 0.8584710955619812, 0.8677685856819153, 0.8739669322967529, 0.8615702390670776, 0.8791322112083435, 0.8636363744735718, 0.8543388247489929, 0.8657024502754211, 0.8667355179786682, 0.875, 0.8739669322967529, 0.8512396812438965, 0.8657024502754211, 0.8780992031097412, 0.8729338645935059, 0.8729338645935059, 0.8595041036605835, 0.8739669322967529, 0.8667355179786682, 0.8564049601554871, 0.8491735458374023, 0.8780992031097412, 0.8770661354064941, 0.8636363744735718, 0.8688016533851624, 0.8708677887916565, 0.8615702390670776, 0.8677685856819153, 0.8811983466148376, 0.8584710955619812]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.1036 - accuracy: 0.9615"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 14s 250ms/step - loss: 0.1020 - accuracy: 0.9617 - val_loss: 0.7211 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0937 - accuracy: 0.9636 - val_loss: 0.7196 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0948 - accuracy: 0.9661 - val_loss: 0.7177 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0810 - accuracy: 0.9717 - val_loss: 0.7175 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0732 - accuracy: 0.9728 - val_loss: 0.7183 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0905 - accuracy: 0.9669 - val_loss: 0.7155 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0788 - accuracy: 0.9747 - val_loss: 0.7106 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0655 - accuracy: 0.9758 - val_loss: 0.6998 - val_accuracy: 0.4860\n","Epoch 9/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.0623 - accuracy: 0.9795 - val_loss: 0.6799 - val_accuracy: 0.4914\n","Epoch 10/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.0662 - accuracy: 0.9776 - val_loss: 0.6472 - val_accuracy: 0.5011\n","Epoch 11/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0671 - accuracy: 0.9763 - val_loss: 0.6016 - val_accuracy: 0.5453\n","Epoch 12/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0696 - accuracy: 0.9771 - val_loss: 0.5732 - val_accuracy: 0.5916\n","Epoch 13/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0684 - accuracy: 0.9760 - val_loss: 0.5197 - val_accuracy: 0.6756\n","Epoch 14/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0636 - accuracy: 0.9776 - val_loss: 0.4925 - val_accuracy: 0.7037\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0599 - accuracy: 0.9806 - val_loss: 0.4932 - val_accuracy: 0.6853\n","Epoch 16/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0578 - accuracy: 0.9809 - val_loss: 0.3995 - val_accuracy: 0.8125\n","Epoch 17/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0541 - accuracy: 0.9828 - val_loss: 0.3542 - val_accuracy: 0.8513\n","Epoch 18/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.0516 - accuracy: 0.9820 - val_loss: 0.3336 - val_accuracy: 0.8588\n","Epoch 19/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0531 - accuracy: 0.9814 - val_loss: 0.3079 - val_accuracy: 0.8675\n","Epoch 20/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0524 - accuracy: 0.9833 - val_loss: 0.3148 - val_accuracy: 0.8621\n","Epoch 21/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.0513 - accuracy: 0.9822 - val_loss: 0.2295 - val_accuracy: 0.9224\n","Epoch 22/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0500 - accuracy: 0.9830 - val_loss: 0.2508 - val_accuracy: 0.8966\n","Epoch 23/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0492 - accuracy: 0.9846 - val_loss: 0.2584 - val_accuracy: 0.8998\n","Epoch 24/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0492 - accuracy: 0.9822 - val_loss: 0.2175 - val_accuracy: 0.9192\n","Epoch 25/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0659 - accuracy: 0.9776 - val_loss: 0.2949 - val_accuracy: 0.8901\n","Epoch 26/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0561 - accuracy: 0.9803 - val_loss: 0.2340 - val_accuracy: 0.9149\n","Epoch 27/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0459 - accuracy: 0.9865 - val_loss: 0.2374 - val_accuracy: 0.9213\n","Epoch 28/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0431 - accuracy: 0.9849 - val_loss: 0.2521 - val_accuracy: 0.9192\n","Epoch 29/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0453 - accuracy: 0.9841 - val_loss: 0.2564 - val_accuracy: 0.9181\n","Epoch 30/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0504 - accuracy: 0.9836 - val_loss: 0.2779 - val_accuracy: 0.9127\n","Epoch 31/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0385 - accuracy: 0.9881 - val_loss: 0.2702 - val_accuracy: 0.9170\n","Epoch 32/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0533 - accuracy: 0.9809 - val_loss: 0.2918 - val_accuracy: 0.9095\n","Epoch 33/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0483 - accuracy: 0.9814 - val_loss: 0.2705 - val_accuracy: 0.9149\n","Epoch 34/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0509 - accuracy: 0.9830 - val_loss: 0.2845 - val_accuracy: 0.9159\n","Epoch 35/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0485 - accuracy: 0.9820 - val_loss: 0.3589 - val_accuracy: 0.8922\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0425 - accuracy: 0.9860 - val_loss: 0.2875 - val_accuracy: 0.9159\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0452 - accuracy: 0.9849 - val_loss: 0.2980 - val_accuracy: 0.9084\n","Epoch 38/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0384 - accuracy: 0.9879 - val_loss: 0.2988 - val_accuracy: 0.9127\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0595 - accuracy: 0.9782 - val_loss: 0.4848 - val_accuracy: 0.8761\n","Epoch 40/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0543 - accuracy: 0.9782 - val_loss: 0.2897 - val_accuracy: 0.9116\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0369 - accuracy: 0.9887 - val_loss: 0.2917 - val_accuracy: 0.9138\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0418 - accuracy: 0.9849 - val_loss: 0.3309 - val_accuracy: 0.9052\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0363 - accuracy: 0.9890 - val_loss: 0.3495 - val_accuracy: 0.9041\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0386 - accuracy: 0.9863 - val_loss: 0.3442 - val_accuracy: 0.9073\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0478 - accuracy: 0.9809 - val_loss: 0.3188 - val_accuracy: 0.9084\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0600 - accuracy: 0.9776 - val_loss: 0.3828 - val_accuracy: 0.8933\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0395 - accuracy: 0.9871 - val_loss: 0.3328 - val_accuracy: 0.9030\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0428 - accuracy: 0.9849 - val_loss: 0.3023 - val_accuracy: 0.9138\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0500 - accuracy: 0.9814 - val_loss: 0.3575 - val_accuracy: 0.8987\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0566 - accuracy: 0.9798 - val_loss: 0.3729 - val_accuracy: 0.8987\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0632 - accuracy: 0.9747 - val_loss: 0.4357 - val_accuracy: 0.8825\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0318 - accuracy: 0.9884 - val_loss: 0.3633 - val_accuracy: 0.8976\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0350 - accuracy: 0.9890 - val_loss: 0.3147 - val_accuracy: 0.9106\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0300 - accuracy: 0.9898 - val_loss: 0.3199 - val_accuracy: 0.9095\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0388 - accuracy: 0.9871 - val_loss: 0.3200 - val_accuracy: 0.9073\n","Epoch 56/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0394 - accuracy: 0.9871 - val_loss: 0.3791 - val_accuracy: 0.8998\n","Epoch 57/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0318 - accuracy: 0.9892 - val_loss: 0.3403 - val_accuracy: 0.9030\n","Epoch 58/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0220 - accuracy: 0.9933 - val_loss: 0.3335 - val_accuracy: 0.9009\n","Epoch 59/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0250 - accuracy: 0.9938 - val_loss: 0.3787 - val_accuracy: 0.8998\n","Epoch 60/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0297 - accuracy: 0.9898 - val_loss: 0.3300 - val_accuracy: 0.9084\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0256 - accuracy: 0.9935 - val_loss: 0.3267 - val_accuracy: 0.9106\n","Epoch 62/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0325 - accuracy: 0.9860 - val_loss: 0.3567 - val_accuracy: 0.9009\n","Epoch 63/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0300 - accuracy: 0.9895 - val_loss: 0.3386 - val_accuracy: 0.9073\n","Epoch 64/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0233 - accuracy: 0.9919 - val_loss: 0.3232 - val_accuracy: 0.9159\n","Epoch 65/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0186 - accuracy: 0.9952 - val_loss: 0.3478 - val_accuracy: 0.9062\n","Epoch 66/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0239 - accuracy: 0.9919 - val_loss: 0.3471 - val_accuracy: 0.9073\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0267 - accuracy: 0.9914 - val_loss: 0.3789 - val_accuracy: 0.9041\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0185 - accuracy: 0.9960 - val_loss: 0.3618 - val_accuracy: 0.9062\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0200 - accuracy: 0.9946 - val_loss: 0.3640 - val_accuracy: 0.9052\n","Epoch 70/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0192 - accuracy: 0.9949 - val_loss: 0.3518 - val_accuracy: 0.9062\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0318 - accuracy: 0.9873 - val_loss: 0.3534 - val_accuracy: 0.9106\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0285 - accuracy: 0.9900 - val_loss: 0.3449 - val_accuracy: 0.9106\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0229 - accuracy: 0.9927 - val_loss: 0.3461 - val_accuracy: 0.9052\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0223 - accuracy: 0.9930 - val_loss: 0.3858 - val_accuracy: 0.8922\n","Epoch 75/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0182 - accuracy: 0.9935 - val_loss: 0.3841 - val_accuracy: 0.8998\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0178 - accuracy: 0.9949 - val_loss: 0.3498 - val_accuracy: 0.9106\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0295 - accuracy: 0.9898 - val_loss: 0.3724 - val_accuracy: 0.9084\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0298 - accuracy: 0.9906 - val_loss: 0.3695 - val_accuracy: 0.9052\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0255 - accuracy: 0.9922 - val_loss: 0.3743 - val_accuracy: 0.9062\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0174 - accuracy: 0.9933 - val_loss: 0.3861 - val_accuracy: 0.9009\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0229 - accuracy: 0.9916 - val_loss: 0.3943 - val_accuracy: 0.8976\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0306 - accuracy: 0.9895 - val_loss: 0.5038 - val_accuracy: 0.8836\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0227 - accuracy: 0.9916 - val_loss: 0.4078 - val_accuracy: 0.8955\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0367 - accuracy: 0.9873 - val_loss: 0.5250 - val_accuracy: 0.8825\n","Epoch 85/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.4105 - val_accuracy: 0.8976\n","Epoch 86/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.3684 - val_accuracy: 0.9041\n","Epoch 87/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.3804 - val_accuracy: 0.9062\n","Epoch 88/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0186 - accuracy: 0.9935 - val_loss: 0.3811 - val_accuracy: 0.9030\n","Epoch 89/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0163 - accuracy: 0.9957 - val_loss: 0.3991 - val_accuracy: 0.9041\n","Epoch 90/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0155 - accuracy: 0.9946 - val_loss: 0.3844 - val_accuracy: 0.9062\n","Epoch 91/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0273 - accuracy: 0.9903 - val_loss: 0.5294 - val_accuracy: 0.8836\n","Epoch 92/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0326 - accuracy: 0.9879 - val_loss: 0.3761 - val_accuracy: 0.9073\n","Epoch 93/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 0.4069 - val_accuracy: 0.8955\n","Epoch 94/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0130 - accuracy: 0.9968 - val_loss: 0.3824 - val_accuracy: 0.9084\n","Epoch 95/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.3840 - val_accuracy: 0.9030\n","Epoch 96/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.3910 - val_accuracy: 0.9095\n","Epoch 97/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.3918 - val_accuracy: 0.9030\n","Epoch 98/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0112 - accuracy: 0.9957 - val_loss: 0.3937 - val_accuracy: 0.9041\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.4817 - val_accuracy: 0.8847\n","Epoch 100/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.4032 - val_accuracy: 0.9041\n","{'loss': [0.10200125724077225, 0.0937393307685852, 0.09484990686178207, 0.08096714317798615, 0.07319346815347672, 0.09053812175989151, 0.07876107841730118, 0.06547151505947113, 0.0623089000582695, 0.06617304682731628, 0.06707851588726044, 0.06961623579263687, 0.06839406490325928, 0.06359197199344635, 0.059926651418209076, 0.05784352496266365, 0.054059259593486786, 0.05163472518324852, 0.05308160558342934, 0.05239332094788551, 0.051280196756124496, 0.04997359588742256, 0.049189064651727676, 0.049211643636226654, 0.06591832637786865, 0.05610955134034157, 0.045943982899188995, 0.043111711740493774, 0.04531339555978775, 0.05044788867235184, 0.03847535327076912, 0.05328424647450447, 0.04829295724630356, 0.05089736729860306, 0.048500388860702515, 0.04253588989377022, 0.045232031494379044, 0.038435257971286774, 0.05948378145694733, 0.0543380044400692, 0.0368959866464138, 0.04175540432333946, 0.036339014768600464, 0.038600046187639236, 0.047767333686351776, 0.05996427685022354, 0.03950539603829384, 0.04281254857778549, 0.05002151429653168, 0.056585974991321564, 0.06316514313220978, 0.031760431826114655, 0.035035938024520874, 0.029989702627062798, 0.03880896419286728, 0.03937137871980667, 0.031788188964128494, 0.022043360397219658, 0.025039227679371834, 0.02974395826458931, 0.025594227015972137, 0.03251171112060547, 0.029991062358021736, 0.02326388843357563, 0.018634561449289322, 0.023862386122345924, 0.02672087401151657, 0.018470974639058113, 0.019963575527071953, 0.01922496221959591, 0.03178321570158005, 0.028503360226750374, 0.02291283942759037, 0.02230166271328926, 0.01818690076470375, 0.017798995599150658, 0.029542110860347748, 0.029750624671578407, 0.02550259605050087, 0.017386937513947487, 0.022896764799952507, 0.03064439445734024, 0.022697051987051964, 0.036653563380241394, 0.017096787691116333, 0.019928501918911934, 0.015317240729928017, 0.018580373376607895, 0.01626439578831196, 0.015454116277396679, 0.027257844805717468, 0.03261561319231987, 0.0144259724766016, 0.013030024245381355, 0.016294162720441818, 0.014488480985164642, 0.012004881165921688, 0.011239694431424141, 0.016307011246681213, 0.017188100144267082], 'accuracy': [0.9617456793785095, 0.9636314511299133, 0.9660560488700867, 0.9717133641242981, 0.9727909564971924, 0.9668642282485962, 0.9746767282485962, 0.9757543206214905, 0.9795258641242981, 0.9776400923728943, 0.9762930870056152, 0.9771012663841248, 0.9760237336158752, 0.9776400923728943, 0.9806034564971924, 0.9808728694915771, 0.982758641242981, 0.9819504022598267, 0.9814116358757019, 0.9832974076271057, 0.9822198152542114, 0.983027994632721, 0.9846444129943848, 0.9822198152542114, 0.9776400923728943, 0.9803340435028076, 0.9865301847457886, 0.9849137663841248, 0.9841055870056152, 0.9835668206214905, 0.9881465435028076, 0.9808728694915771, 0.9814116358757019, 0.983027994632721, 0.9819504022598267, 0.985991358757019, 0.9849137663841248, 0.9878771305084229, 0.978178858757019, 0.978178858757019, 0.9886853694915771, 0.9849137663841248, 0.9889547228813171, 0.9862607717514038, 0.9808728694915771, 0.9776400923728943, 0.9870689511299133, 0.9849137663841248, 0.9814116358757019, 0.9797952771186829, 0.9746767282485962, 0.9884159564971924, 0.9889547228813171, 0.9897629022598267, 0.9870689511299133, 0.9870689511299133, 0.9892241358757019, 0.9932650923728943, 0.993803858757019, 0.9897629022598267, 0.993534505367279, 0.985991358757019, 0.9894935488700867, 0.9919180870056152, 0.9951508641242981, 0.9919180870056152, 0.9913793206214905, 0.9959590435028076, 0.9946120977401733, 0.9948814511299133, 0.9873383641242981, 0.9900323152542114, 0.9927262663841248, 0.9929956793785095, 0.993534505367279, 0.9948814511299133, 0.9897629022598267, 0.990571141242981, 0.9921875, 0.9932650923728943, 0.9916487336158752, 0.9894935488700867, 0.9916487336158752, 0.9873383641242981, 0.9951508641242981, 0.993803858757019, 0.9948814511299133, 0.993534505367279, 0.9956896305084229, 0.9946120977401733, 0.9903017282485962, 0.9878771305084229, 0.9951508641242981, 0.9967672228813171, 0.9948814511299133, 0.9962284564971924, 0.9962284564971924, 0.9956896305084229, 0.9946120977401733, 0.9948814511299133], 'val_loss': [0.7210643887519836, 0.7196168303489685, 0.7176505923271179, 0.7174598574638367, 0.7182684540748596, 0.7155022025108337, 0.7106103301048279, 0.6997872591018677, 0.6798872947692871, 0.6472362875938416, 0.6015814542770386, 0.573236346244812, 0.5197307467460632, 0.49251213669776917, 0.49319925904273987, 0.3994920551776886, 0.35419827699661255, 0.33358991146087646, 0.30786383152008057, 0.3148389756679535, 0.22945186495780945, 0.25079113245010376, 0.25835898518562317, 0.21747367084026337, 0.2948920726776123, 0.23399193584918976, 0.23742660880088806, 0.25212976336479187, 0.2564339339733124, 0.27787911891937256, 0.2701687514781952, 0.2918195128440857, 0.270508736371994, 0.28450021147727966, 0.35889479517936707, 0.28747421503067017, 0.2979731261730194, 0.29879632592201233, 0.4847516715526581, 0.2896572947502136, 0.2917115092277527, 0.3308967649936676, 0.34948262572288513, 0.34416311979293823, 0.3188055157661438, 0.3827883303165436, 0.3328360319137573, 0.302252858877182, 0.3574537932872772, 0.3729175329208374, 0.4357145130634308, 0.36328333616256714, 0.3147363066673279, 0.3199489116668701, 0.31995922327041626, 0.37905529141426086, 0.3403278589248657, 0.3335164487361908, 0.37866461277008057, 0.32995128631591797, 0.3266594707965851, 0.35668233036994934, 0.33861032128334045, 0.32315805554389954, 0.3478391468524933, 0.3470974564552307, 0.3789142072200775, 0.3618146777153015, 0.3640018701553345, 0.3517899215221405, 0.35344377160072327, 0.3449226915836334, 0.3461291790008545, 0.3858191668987274, 0.384053498506546, 0.349822074174881, 0.3723568022251129, 0.3695113956928253, 0.3742966949939728, 0.3861245810985565, 0.39430001378059387, 0.5037636756896973, 0.40781494975090027, 0.5250245928764343, 0.4104540944099426, 0.36840444803237915, 0.3803533911705017, 0.3811047077178955, 0.3990843594074249, 0.3843524754047394, 0.5294030904769897, 0.3761487603187561, 0.4069195091724396, 0.38244393467903137, 0.3840186297893524, 0.3910224139690399, 0.39181777834892273, 0.39366617798805237, 0.4816967248916626, 0.4031781852245331], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.4913793206214905, 0.5010775923728943, 0.545258641242981, 0.5915948152542114, 0.6756465435028076, 0.7036637663841248, 0.6853448152542114, 0.8125, 0.8512930870056152, 0.8588362336158752, 0.8674569129943848, 0.8620689511299133, 0.9224137663841248, 0.8965517282485962, 0.899784505367279, 0.9191810488700867, 0.8900862336158752, 0.9148706793785095, 0.9213362336158752, 0.9191810488700867, 0.9181034564971924, 0.912715494632721, 0.9170258641242981, 0.9094827771186829, 0.9148706793785095, 0.9159482717514038, 0.892241358757019, 0.9159482717514038, 0.9084051847457886, 0.912715494632721, 0.8760775923728943, 0.9116379022598267, 0.9137930870056152, 0.9051724076271057, 0.9040948152542114, 0.9073275923728943, 0.9084051847457886, 0.8933189511299133, 0.9030172228813171, 0.9137930870056152, 0.8987069129943848, 0.8987069129943848, 0.8825430870056152, 0.8976293206214905, 0.9105603694915771, 0.9094827771186829, 0.9073275923728943, 0.899784505367279, 0.9030172228813171, 0.9008620977401733, 0.899784505367279, 0.9084051847457886, 0.9105603694915771, 0.9008620977401733, 0.9073275923728943, 0.9159482717514038, 0.90625, 0.9073275923728943, 0.9040948152542114, 0.90625, 0.9051724076271057, 0.90625, 0.9105603694915771, 0.9105603694915771, 0.9051724076271057, 0.892241358757019, 0.899784505367279, 0.9105603694915771, 0.9084051847457886, 0.9051724076271057, 0.90625, 0.9008620977401733, 0.8976293206214905, 0.8836206793785095, 0.8954741358757019, 0.8825430870056152, 0.8976293206214905, 0.9040948152542114, 0.90625, 0.9030172228813171, 0.9040948152542114, 0.90625, 0.8836206793785095, 0.9073275923728943, 0.8954741358757019, 0.9084051847457886, 0.9030172228813171, 0.9094827771186829, 0.9030172228813171, 0.9040948152542114, 0.8846982717514038, 0.9040948152542114]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.1292 - accuracy: 0.9533"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 19s 446ms/step - loss: 0.1292 - accuracy: 0.9533 - val_loss: 0.7151 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1268 - accuracy: 0.9502 - val_loss: 0.7150 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1082 - accuracy: 0.9598 - val_loss: 0.7118 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1024 - accuracy: 0.9587 - val_loss: 0.7122 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.1085 - accuracy: 0.9618 - val_loss: 0.7077 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0898 - accuracy: 0.9680 - val_loss: 0.7052 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0824 - accuracy: 0.9720 - val_loss: 0.7044 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0842 - accuracy: 0.9694 - val_loss: 0.6887 - val_accuracy: 0.4966\n","Epoch 9/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0791 - accuracy: 0.9686 - val_loss: 0.6748 - val_accuracy: 0.4989\n","Epoch 10/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0764 - accuracy: 0.9743 - val_loss: 0.6479 - val_accuracy: 0.5090\n","Epoch 11/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0773 - accuracy: 0.9726 - val_loss: 0.6263 - val_accuracy: 0.5271\n","Epoch 12/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0803 - accuracy: 0.9726 - val_loss: 0.5837 - val_accuracy: 0.5747\n","Epoch 13/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0717 - accuracy: 0.9737 - val_loss: 0.5593 - val_accuracy: 0.6007\n","Epoch 14/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0781 - accuracy: 0.9700 - val_loss: 0.4962 - val_accuracy: 0.7262\n","Epoch 15/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0648 - accuracy: 0.9754 - val_loss: 0.4937 - val_accuracy: 0.6957\n","Epoch 16/100\n","28/28 [==============================] - 2s 75ms/step - loss: 0.0849 - accuracy: 0.9677 - val_loss: 0.4504 - val_accuracy: 0.7590\n","Epoch 17/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.0788 - accuracy: 0.9734 - val_loss: 0.3963 - val_accuracy: 0.8235\n","Epoch 18/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.0632 - accuracy: 0.9785 - val_loss: 0.3094 - val_accuracy: 0.9163\n","Epoch 19/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.0765 - accuracy: 0.9740 - val_loss: 0.3293 - val_accuracy: 0.8722\n","Epoch 20/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0657 - accuracy: 0.9776 - val_loss: 0.3275 - val_accuracy: 0.8620\n","Epoch 21/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0622 - accuracy: 0.9785 - val_loss: 0.2733 - val_accuracy: 0.8891\n","Epoch 22/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0566 - accuracy: 0.9802 - val_loss: 0.2245 - val_accuracy: 0.9118\n","Epoch 23/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0549 - accuracy: 0.9808 - val_loss: 0.2165 - val_accuracy: 0.9219\n","Epoch 24/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0608 - accuracy: 0.9827 - val_loss: 0.2188 - val_accuracy: 0.9197\n","Epoch 25/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0661 - accuracy: 0.9759 - val_loss: 0.2318 - val_accuracy: 0.9106\n","Epoch 26/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0543 - accuracy: 0.9827 - val_loss: 0.2404 - val_accuracy: 0.9050\n","Epoch 27/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0559 - accuracy: 0.9816 - val_loss: 0.2299 - val_accuracy: 0.9163\n","Epoch 28/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0569 - accuracy: 0.9805 - val_loss: 0.2468 - val_accuracy: 0.9084\n","Epoch 29/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0474 - accuracy: 0.9856 - val_loss: 0.2462 - val_accuracy: 0.9118\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0490 - accuracy: 0.9847 - val_loss: 0.2578 - val_accuracy: 0.9140\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0482 - accuracy: 0.9844 - val_loss: 0.2647 - val_accuracy: 0.9061\n","Epoch 32/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0593 - accuracy: 0.9791 - val_loss: 0.2719 - val_accuracy: 0.9174\n","Epoch 33/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0464 - accuracy: 0.9833 - val_loss: 0.2873 - val_accuracy: 0.9027\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0552 - accuracy: 0.9782 - val_loss: 0.2822 - val_accuracy: 0.9027\n","Epoch 35/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0714 - accuracy: 0.9759 - val_loss: 0.3642 - val_accuracy: 0.8959\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0576 - accuracy: 0.9830 - val_loss: 0.2760 - val_accuracy: 0.9140\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0454 - accuracy: 0.9873 - val_loss: 0.2875 - val_accuracy: 0.9118\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0584 - accuracy: 0.9808 - val_loss: 0.2791 - val_accuracy: 0.9186\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0448 - accuracy: 0.9873 - val_loss: 0.2745 - val_accuracy: 0.9129\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0453 - accuracy: 0.9839 - val_loss: 0.3475 - val_accuracy: 0.8903\n","Epoch 41/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0469 - accuracy: 0.9859 - val_loss: 0.2884 - val_accuracy: 0.9152\n","Epoch 42/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0401 - accuracy: 0.9898 - val_loss: 0.2957 - val_accuracy: 0.9106\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0399 - accuracy: 0.9884 - val_loss: 0.3061 - val_accuracy: 0.9050\n","Epoch 44/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0461 - accuracy: 0.9859 - val_loss: 0.3204 - val_accuracy: 0.9140\n","Epoch 45/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0395 - accuracy: 0.9898 - val_loss: 0.2985 - val_accuracy: 0.9129\n","Epoch 46/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0433 - accuracy: 0.9844 - val_loss: 0.3057 - val_accuracy: 0.9084\n","Epoch 47/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0505 - accuracy: 0.9836 - val_loss: 0.3277 - val_accuracy: 0.9072\n","Epoch 48/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0408 - accuracy: 0.9856 - val_loss: 0.2923 - val_accuracy: 0.9084\n","Epoch 49/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0394 - accuracy: 0.9875 - val_loss: 0.3259 - val_accuracy: 0.9084\n","Epoch 50/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0416 - accuracy: 0.9864 - val_loss: 0.3129 - val_accuracy: 0.9129\n","Epoch 51/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0356 - accuracy: 0.9881 - val_loss: 0.3187 - val_accuracy: 0.8982\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0409 - accuracy: 0.9853 - val_loss: 0.3291 - val_accuracy: 0.9061\n","Epoch 53/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0423 - accuracy: 0.9844 - val_loss: 0.3138 - val_accuracy: 0.9050\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0405 - accuracy: 0.9878 - val_loss: 0.3141 - val_accuracy: 0.9050\n","Epoch 55/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0289 - accuracy: 0.9924 - val_loss: 0.3233 - val_accuracy: 0.9072\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0314 - accuracy: 0.9915 - val_loss: 0.3264 - val_accuracy: 0.9016\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0549 - accuracy: 0.9768 - val_loss: 0.3317 - val_accuracy: 0.9106\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0384 - accuracy: 0.9867 - val_loss: 0.3315 - val_accuracy: 0.9016\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0258 - accuracy: 0.9946 - val_loss: 0.3120 - val_accuracy: 0.9084\n","Epoch 60/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0331 - accuracy: 0.9890 - val_loss: 0.3208 - val_accuracy: 0.9129\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0322 - accuracy: 0.9878 - val_loss: 0.3257 - val_accuracy: 0.9129\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0304 - accuracy: 0.9898 - val_loss: 0.3267 - val_accuracy: 0.9095\n","Epoch 63/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0518 - accuracy: 0.9825 - val_loss: 0.3626 - val_accuracy: 0.8959\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0372 - accuracy: 0.9884 - val_loss: 0.3445 - val_accuracy: 0.9061\n","Epoch 65/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0307 - accuracy: 0.9898 - val_loss: 0.3319 - val_accuracy: 0.9118\n","Epoch 66/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0330 - accuracy: 0.9881 - val_loss: 0.3928 - val_accuracy: 0.9061\n","Epoch 67/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0259 - accuracy: 0.9924 - val_loss: 0.3408 - val_accuracy: 0.9084\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0240 - accuracy: 0.9935 - val_loss: 0.3279 - val_accuracy: 0.9072\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0305 - accuracy: 0.9918 - val_loss: 0.3514 - val_accuracy: 0.9072\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0266 - accuracy: 0.9921 - val_loss: 0.3358 - val_accuracy: 0.9095\n","Epoch 71/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.3445 - val_accuracy: 0.9050\n","Epoch 72/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0281 - accuracy: 0.9918 - val_loss: 0.3448 - val_accuracy: 0.9095\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0384 - accuracy: 0.9853 - val_loss: 0.3539 - val_accuracy: 0.9050\n","Epoch 74/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0357 - accuracy: 0.9844 - val_loss: 0.3482 - val_accuracy: 0.9050\n","Epoch 75/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0264 - accuracy: 0.9904 - val_loss: 0.3583 - val_accuracy: 0.9038\n","Epoch 76/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0277 - accuracy: 0.9907 - val_loss: 0.3497 - val_accuracy: 0.9027\n","Epoch 77/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0202 - accuracy: 0.9932 - val_loss: 0.3736 - val_accuracy: 0.9038\n","Epoch 78/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0438 - accuracy: 0.9839 - val_loss: 0.3544 - val_accuracy: 0.9084\n","Epoch 79/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.3557 - val_accuracy: 0.9050\n","Epoch 80/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0231 - accuracy: 0.9918 - val_loss: 0.3658 - val_accuracy: 0.9050\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 0.3696 - val_accuracy: 0.9027\n","Epoch 82/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0281 - accuracy: 0.9901 - val_loss: 0.4047 - val_accuracy: 0.9027\n","Epoch 83/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0287 - accuracy: 0.9898 - val_loss: 0.3725 - val_accuracy: 0.9084\n","Epoch 84/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0181 - accuracy: 0.9941 - val_loss: 0.3767 - val_accuracy: 0.9084\n","Epoch 85/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.4459 - val_accuracy: 0.8880\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0208 - accuracy: 0.9938 - val_loss: 0.3798 - val_accuracy: 0.9050\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0250 - accuracy: 0.9904 - val_loss: 0.3840 - val_accuracy: 0.9038\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0212 - accuracy: 0.9946 - val_loss: 0.4428 - val_accuracy: 0.8812\n","Epoch 89/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0294 - accuracy: 0.9890 - val_loss: 0.4066 - val_accuracy: 0.8971\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.3882 - val_accuracy: 0.9005\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0262 - accuracy: 0.9924 - val_loss: 0.4016 - val_accuracy: 0.8982\n","Epoch 92/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0332 - accuracy: 0.9861 - val_loss: 0.3791 - val_accuracy: 0.9038\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.3978 - val_accuracy: 0.9050\n","Epoch 94/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0158 - accuracy: 0.9955 - val_loss: 0.3762 - val_accuracy: 0.9084\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0178 - accuracy: 0.9941 - val_loss: 0.3910 - val_accuracy: 0.9072\n","Epoch 96/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0177 - accuracy: 0.9926 - val_loss: 0.5336 - val_accuracy: 0.8857\n","Epoch 97/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.4341 - val_accuracy: 0.9016\n","Epoch 98/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.3936 - val_accuracy: 0.9072\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.4003 - val_accuracy: 0.9016\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.4498 - val_accuracy: 0.8982\n","{'loss': [0.12922561168670654, 0.1268261820077896, 0.10818041115999222, 0.1023801937699318, 0.10846185684204102, 0.08980782330036163, 0.08244601637125015, 0.0841708853840828, 0.07911121845245361, 0.0764331966638565, 0.077349953353405, 0.08034643530845642, 0.07168992608785629, 0.07809673994779587, 0.06484615057706833, 0.08487114310264587, 0.07878216356039047, 0.06317124515771866, 0.07646600902080536, 0.06570333242416382, 0.0622062012553215, 0.056649260222911835, 0.054945606738328934, 0.06076178327202797, 0.06606728583574295, 0.0543174222111702, 0.055906742811203, 0.05694324150681496, 0.04742646962404251, 0.04895784333348274, 0.048236291855573654, 0.059345319867134094, 0.04637093469500542, 0.05515434220433235, 0.07144740223884583, 0.05755981430411339, 0.04542456567287445, 0.05836012214422226, 0.04481921344995499, 0.04525330662727356, 0.04688943922519684, 0.04010234400629997, 0.039901167154312134, 0.04611669480800629, 0.039461661130189896, 0.04332013055682182, 0.05045801028609276, 0.040806617587804794, 0.039370346814394, 0.041615743190050125, 0.03560439497232437, 0.040927544236183167, 0.042251650243997574, 0.040473051369190216, 0.028914103284478188, 0.03138256445527077, 0.05486876890063286, 0.038378600031137466, 0.025756793096661568, 0.03308338299393654, 0.032150834798812866, 0.030365338549017906, 0.051770299673080444, 0.03715357929468155, 0.030732857063412666, 0.03298266977071762, 0.025886792689561844, 0.024047965183854103, 0.030462266877293587, 0.026559431105852127, 0.021646153181791306, 0.02813924103975296, 0.038354068994522095, 0.03566417470574379, 0.026448329910635948, 0.02770085074007511, 0.02016773261129856, 0.04377242550253868, 0.022699221968650818, 0.02311163768172264, 0.020863091573119164, 0.028143523260951042, 0.028671875596046448, 0.018065528944134712, 0.022731008008122444, 0.02076554484665394, 0.025010498240590096, 0.02124778740108013, 0.02939331904053688, 0.019373396411538124, 0.026177452877163887, 0.03318087384104729, 0.012770677916705608, 0.015840165317058563, 0.017819944769144058, 0.01767302304506302, 0.021568680182099342, 0.015487225726246834, 0.013923544436693192, 0.01859074831008911], 'accuracy': [0.9533106684684753, 0.9501980543136597, 0.9598188996315002, 0.9586870670318604, 0.961799681186676, 0.9680249094963074, 0.9719864130020142, 0.9694397449493408, 0.9685908555984497, 0.9742501378059387, 0.9725523591041565, 0.9725523591041565, 0.9736841917037964, 0.9700056314468384, 0.9753820300102234, 0.9677419066429138, 0.9734012484550476, 0.9784946441650391, 0.9739671945571899, 0.977645754814148, 0.9784946441650391, 0.9801924228668213, 0.9807583689689636, 0.9827390909194946, 0.975947916507721, 0.9827390909194946, 0.9816072583198547, 0.9804753661155701, 0.9855687618255615, 0.9847198724746704, 0.9844368696212769, 0.9790605306625366, 0.983305037021637, 0.9782116413116455, 0.975947916507721, 0.9830220937728882, 0.9872665405273438, 0.9807583689689636, 0.9872665405273438, 0.9838709831237793, 0.9858517050743103, 0.9898132681846619, 0.9883984327316284, 0.9858517050743103, 0.9898132681846619, 0.9844368696212769, 0.9835879802703857, 0.9855687618255615, 0.9875495433807373, 0.9864176511764526, 0.9881154298782349, 0.9852858185768127, 0.9844368696212769, 0.9878324866294861, 0.9923599362373352, 0.9915110468864441, 0.9767968058586121, 0.9867005944252014, 0.9946236610412598, 0.988964319229126, 0.9878324866294861, 0.9898132681846619, 0.9824561476707458, 0.9883984327316284, 0.9898132681846619, 0.9881154298782349, 0.9923599362373352, 0.9934917688369751, 0.9917939901351929, 0.9920769929885864, 0.9937747716903687, 0.9917939901351929, 0.9852858185768127, 0.9844368696212769, 0.9903791546821594, 0.990662157535553, 0.9932088255882263, 0.9838709831237793, 0.992642879486084, 0.9917939901351929, 0.9934917688369751, 0.9900962114334106, 0.9898132681846619, 0.9940577149391174, 0.9932088255882263, 0.9937747716903687, 0.9903791546821594, 0.9946236610412598, 0.988964319229126, 0.9940577149391174, 0.9923599362373352, 0.9861347079277039, 0.996321439743042, 0.9954725503921509, 0.9940577149391174, 0.992642879486084, 0.992642879486084, 0.9949066042900085, 0.9957554936408997, 0.9940577149391174], 'val_loss': [0.7150644063949585, 0.7149964570999146, 0.7117531299591064, 0.7121660709381104, 0.7077411413192749, 0.7052222490310669, 0.7043648958206177, 0.6887302398681641, 0.6747545003890991, 0.6479339003562927, 0.6262709498405457, 0.5836557745933533, 0.5592987537384033, 0.4962359070777893, 0.49371978640556335, 0.45038118958473206, 0.3962639272212982, 0.3094078600406647, 0.32929614186286926, 0.32748711109161377, 0.2732953429222107, 0.2244916558265686, 0.21647751331329346, 0.2188308835029602, 0.23181535303592682, 0.24041536450386047, 0.2298661768436432, 0.2467890977859497, 0.2462145835161209, 0.2577677369117737, 0.26474952697753906, 0.27189767360687256, 0.287288635969162, 0.28217700123786926, 0.3642042577266693, 0.27599605917930603, 0.2874979078769684, 0.27911046147346497, 0.2745179831981659, 0.34753620624542236, 0.2883854806423187, 0.29570096731185913, 0.3061200976371765, 0.3203641474246979, 0.2984861433506012, 0.3057347238063812, 0.3276952803134918, 0.29233402013778687, 0.3258509337902069, 0.31287676095962524, 0.3186517655849457, 0.3290629982948303, 0.3137814700603485, 0.3140508830547333, 0.32327842712402344, 0.32637715339660645, 0.3317166864871979, 0.33153045177459717, 0.3119542598724365, 0.32077598571777344, 0.32574328780174255, 0.32665374875068665, 0.3626267910003662, 0.3444520831108093, 0.3319336175918579, 0.39282742142677307, 0.3407727777957916, 0.32794561982154846, 0.3514214754104614, 0.3358161151409149, 0.3445129692554474, 0.34475424885749817, 0.3539283275604248, 0.34819161891937256, 0.3583317697048187, 0.34967732429504395, 0.37362316250801086, 0.35444605350494385, 0.3557462990283966, 0.36575081944465637, 0.3695712685585022, 0.4047482907772064, 0.3724929094314575, 0.37670809030532837, 0.4458637535572052, 0.37981581687927246, 0.3839890956878662, 0.44277581572532654, 0.40663063526153564, 0.38815921545028687, 0.4016304612159729, 0.3790801167488098, 0.39782780408859253, 0.3762136697769165, 0.3909682631492615, 0.5335630774497986, 0.4340716600418091, 0.39361873269081116, 0.40029600262641907, 0.449789822101593], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.49886876344680786, 0.5090497732162476, 0.5271493196487427, 0.5746606588363647, 0.6006787419319153, 0.726244330406189, 0.6957013607025146, 0.7590497732162476, 0.8235294222831726, 0.9162895679473877, 0.872171938419342, 0.8619909286499023, 0.889140248298645, 0.9117646813392639, 0.9219456911087036, 0.9196832776069641, 0.9106335043907166, 0.9049773812294006, 0.9162895679473877, 0.9083710312843323, 0.9117646813392639, 0.9140271544456482, 0.9061086177825928, 0.9174208045005798, 0.9027149081230164, 0.9027149081230164, 0.8959276080131531, 0.9140271544456482, 0.9117646813392639, 0.918552041053772, 0.912895917892456, 0.8902714848518372, 0.9151583909988403, 0.9106335043907166, 0.9049773812294006, 0.9140271544456482, 0.912895917892456, 0.9083710312843323, 0.9072397947311401, 0.9083710312843323, 0.9083710312843323, 0.912895917892456, 0.8981900215148926, 0.9061086177825928, 0.9049773812294006, 0.9049773812294006, 0.9072397947311401, 0.901583731174469, 0.9106335043907166, 0.901583731174469, 0.9083710312843323, 0.912895917892456, 0.912895917892456, 0.9095022678375244, 0.8959276080131531, 0.9061086177825928, 0.9117646813392639, 0.9061086177825928, 0.9083710312843323, 0.9072397947311401, 0.9072397947311401, 0.9095022678375244, 0.9049773812294006, 0.9095022678375244, 0.9049773812294006, 0.9049773812294006, 0.9038461446762085, 0.9027149081230164, 0.9038461446762085, 0.9083710312843323, 0.9049773812294006, 0.9049773812294006, 0.9027149081230164, 0.9027149081230164, 0.9083710312843323, 0.9083710312843323, 0.8880090713500977, 0.9049773812294006, 0.9038461446762085, 0.8812217116355896, 0.8970588445663452, 0.9004524946212769, 0.8981900215148926, 0.9038461446762085, 0.9049773812294006, 0.9083710312843323, 0.9072397947311401, 0.8857465982437134, 0.901583731174469, 0.9072397947311401, 0.901583731174469, 0.8981900215148926]}\n","45/45 [==============================] - 1s 6ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.1418 - accuracy: 0.9477"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 12s 200ms/step - loss: 0.1388 - accuracy: 0.9494 - val_loss: 0.7221 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0983 - accuracy: 0.9605 - val_loss: 0.7210 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0878 - accuracy: 0.9664 - val_loss: 0.7187 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0881 - accuracy: 0.9661 - val_loss: 0.7176 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0812 - accuracy: 0.9708 - val_loss: 0.7184 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1015 - accuracy: 0.9605 - val_loss: 0.7124 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0735 - accuracy: 0.9713 - val_loss: 0.7069 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0745 - accuracy: 0.9731 - val_loss: 0.6976 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0686 - accuracy: 0.9780 - val_loss: 0.6660 - val_accuracy: 0.4938\n","Epoch 10/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0725 - accuracy: 0.9731 - val_loss: 0.6371 - val_accuracy: 0.5010\n","Epoch 11/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0655 - accuracy: 0.9786 - val_loss: 0.6004 - val_accuracy: 0.5455\n","Epoch 12/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0632 - accuracy: 0.9770 - val_loss: 0.5591 - val_accuracy: 0.6033\n","Epoch 13/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0805 - accuracy: 0.9705 - val_loss: 0.4818 - val_accuracy: 0.7562\n","Epoch 14/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0710 - accuracy: 0.9731 - val_loss: 0.4825 - val_accuracy: 0.7190\n","Epoch 15/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0667 - accuracy: 0.9765 - val_loss: 0.4064 - val_accuracy: 0.8275\n","Epoch 16/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0631 - accuracy: 0.9749 - val_loss: 0.4181 - val_accuracy: 0.7862\n","Epoch 17/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0609 - accuracy: 0.9778 - val_loss: 0.3316 - val_accuracy: 0.8729\n","Epoch 18/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0541 - accuracy: 0.9827 - val_loss: 0.2766 - val_accuracy: 0.8936\n","Epoch 19/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0623 - accuracy: 0.9762 - val_loss: 0.3265 - val_accuracy: 0.8585\n","Epoch 20/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0539 - accuracy: 0.9850 - val_loss: 0.2598 - val_accuracy: 0.8884\n","Epoch 21/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0555 - accuracy: 0.9827 - val_loss: 0.3085 - val_accuracy: 0.8729\n","Epoch 22/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0548 - accuracy: 0.9798 - val_loss: 0.2752 - val_accuracy: 0.8936\n","Epoch 23/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0555 - accuracy: 0.9806 - val_loss: 0.3353 - val_accuracy: 0.8709\n","Epoch 24/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.0581 - accuracy: 0.9811 - val_loss: 0.2758 - val_accuracy: 0.9050\n","Epoch 25/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0528 - accuracy: 0.9837 - val_loss: 0.2955 - val_accuracy: 0.8926\n","Epoch 26/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0505 - accuracy: 0.9837 - val_loss: 0.4438 - val_accuracy: 0.8554\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0553 - accuracy: 0.9809 - val_loss: 0.3355 - val_accuracy: 0.8988\n","Epoch 28/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0524 - accuracy: 0.9829 - val_loss: 0.3511 - val_accuracy: 0.8905\n","Epoch 29/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0462 - accuracy: 0.9866 - val_loss: 0.3659 - val_accuracy: 0.8812\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0628 - accuracy: 0.9734 - val_loss: 0.3940 - val_accuracy: 0.8874\n","Epoch 31/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0658 - accuracy: 0.9760 - val_loss: 0.3315 - val_accuracy: 0.9029\n","Epoch 32/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0464 - accuracy: 0.9863 - val_loss: 0.3791 - val_accuracy: 0.8915\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0524 - accuracy: 0.9824 - val_loss: 0.3567 - val_accuracy: 0.9019\n","Epoch 34/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0471 - accuracy: 0.9837 - val_loss: 0.3509 - val_accuracy: 0.8977\n","Epoch 35/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0514 - accuracy: 0.9814 - val_loss: 0.3917 - val_accuracy: 0.8915\n","Epoch 36/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0441 - accuracy: 0.9871 - val_loss: 0.3869 - val_accuracy: 0.8822\n","Epoch 37/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0470 - accuracy: 0.9858 - val_loss: 0.3571 - val_accuracy: 0.9060\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0399 - accuracy: 0.9873 - val_loss: 0.3616 - val_accuracy: 0.8946\n","Epoch 39/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0372 - accuracy: 0.9876 - val_loss: 0.3856 - val_accuracy: 0.9008\n","Epoch 40/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0378 - accuracy: 0.9876 - val_loss: 0.3905 - val_accuracy: 0.8833\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0401 - accuracy: 0.9858 - val_loss: 0.3810 - val_accuracy: 0.8998\n","Epoch 42/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0389 - accuracy: 0.9889 - val_loss: 0.4212 - val_accuracy: 0.8833\n","Epoch 43/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0375 - accuracy: 0.9873 - val_loss: 0.5738 - val_accuracy: 0.8502\n","Epoch 44/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0527 - accuracy: 0.9796 - val_loss: 0.4521 - val_accuracy: 0.8884\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0407 - accuracy: 0.9850 - val_loss: 0.4347 - val_accuracy: 0.8853\n","Epoch 46/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0327 - accuracy: 0.9884 - val_loss: 0.3842 - val_accuracy: 0.8946\n","Epoch 47/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0487 - accuracy: 0.9811 - val_loss: 0.4558 - val_accuracy: 0.8771\n","Epoch 48/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0318 - accuracy: 0.9899 - val_loss: 0.4065 - val_accuracy: 0.8874\n","Epoch 49/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0319 - accuracy: 0.9912 - val_loss: 0.3869 - val_accuracy: 0.8957\n","Epoch 50/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0451 - accuracy: 0.9840 - val_loss: 0.4916 - val_accuracy: 0.8802\n","Epoch 51/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0388 - accuracy: 0.9876 - val_loss: 0.4023 - val_accuracy: 0.8926\n","Epoch 52/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0314 - accuracy: 0.9897 - val_loss: 0.4002 - val_accuracy: 0.8926\n","Epoch 53/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0314 - accuracy: 0.9881 - val_loss: 0.4599 - val_accuracy: 0.8802\n","Epoch 54/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0541 - accuracy: 0.9806 - val_loss: 0.4428 - val_accuracy: 0.8802\n","Epoch 55/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0277 - accuracy: 0.9910 - val_loss: 0.4129 - val_accuracy: 0.9008\n","Epoch 56/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0298 - accuracy: 0.9907 - val_loss: 0.4177 - val_accuracy: 0.8864\n","Epoch 57/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0315 - accuracy: 0.9897 - val_loss: 0.4149 - val_accuracy: 0.8967\n","Epoch 58/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0301 - accuracy: 0.9907 - val_loss: 0.4002 - val_accuracy: 0.8967\n","Epoch 59/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0283 - accuracy: 0.9899 - val_loss: 0.4028 - val_accuracy: 0.8998\n","Epoch 60/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.4111 - val_accuracy: 0.8957\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0423 - accuracy: 0.9837 - val_loss: 0.4119 - val_accuracy: 0.9029\n","Epoch 62/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0308 - accuracy: 0.9891 - val_loss: 0.4109 - val_accuracy: 0.8998\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0243 - accuracy: 0.9941 - val_loss: 0.4544 - val_accuracy: 0.8977\n","Epoch 64/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 0.4311 - val_accuracy: 0.8967\n","Epoch 65/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0235 - accuracy: 0.9941 - val_loss: 0.4474 - val_accuracy: 0.8884\n","Epoch 66/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0266 - accuracy: 0.9904 - val_loss: 0.5385 - val_accuracy: 0.8740\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0304 - accuracy: 0.9894 - val_loss: 0.4340 - val_accuracy: 0.8998\n","Epoch 68/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0395 - accuracy: 0.9853 - val_loss: 0.4287 - val_accuracy: 0.8884\n","Epoch 69/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0265 - accuracy: 0.9904 - val_loss: 0.4934 - val_accuracy: 0.8781\n","Epoch 70/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0271 - accuracy: 0.9917 - val_loss: 0.4435 - val_accuracy: 0.8915\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0187 - accuracy: 0.9946 - val_loss: 0.4251 - val_accuracy: 0.8915\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0252 - accuracy: 0.9925 - val_loss: 0.4888 - val_accuracy: 0.8812\n","Epoch 73/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0263 - accuracy: 0.9928 - val_loss: 0.4283 - val_accuracy: 0.8946\n","Epoch 74/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0230 - accuracy: 0.9920 - val_loss: 0.4394 - val_accuracy: 0.8895\n","Epoch 75/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0250 - accuracy: 0.9925 - val_loss: 0.4941 - val_accuracy: 0.8936\n","Epoch 76/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0296 - accuracy: 0.9899 - val_loss: 0.4469 - val_accuracy: 0.8926\n","Epoch 77/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0175 - accuracy: 0.9953 - val_loss: 0.4662 - val_accuracy: 0.8843\n","Epoch 78/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0227 - accuracy: 0.9928 - val_loss: 0.4650 - val_accuracy: 0.8864\n","Epoch 79/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0370 - accuracy: 0.9866 - val_loss: 0.4907 - val_accuracy: 0.8905\n","Epoch 80/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0384 - accuracy: 0.9868 - val_loss: 0.4368 - val_accuracy: 0.8998\n","Epoch 81/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0341 - accuracy: 0.9868 - val_loss: 0.4857 - val_accuracy: 0.8833\n","Epoch 82/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0166 - accuracy: 0.9956 - val_loss: 0.4550 - val_accuracy: 0.8936\n","Epoch 83/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0299 - accuracy: 0.9891 - val_loss: 0.4464 - val_accuracy: 0.8957\n","Epoch 84/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 0.4606 - val_accuracy: 0.8874\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 0.5380 - val_accuracy: 0.8822\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.4695 - val_accuracy: 0.8884\n","Epoch 87/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0142 - accuracy: 0.9964 - val_loss: 0.4743 - val_accuracy: 0.8915\n","Epoch 88/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.6912 - val_accuracy: 0.8481\n","Epoch 89/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0410 - accuracy: 0.9866 - val_loss: 0.4647 - val_accuracy: 0.8988\n","Epoch 90/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0300 - accuracy: 0.9891 - val_loss: 0.5136 - val_accuracy: 0.8781\n","Epoch 91/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0385 - accuracy: 0.9855 - val_loss: 0.4879 - val_accuracy: 0.8957\n","Epoch 92/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0515 - accuracy: 0.9796 - val_loss: 0.4894 - val_accuracy: 0.8884\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 0.4951 - val_accuracy: 0.8822\n","Epoch 94/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0136 - accuracy: 0.9972 - val_loss: 0.4601 - val_accuracy: 0.8926\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0149 - accuracy: 0.9964 - val_loss: 0.4675 - val_accuracy: 0.8988\n","Epoch 96/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0192 - accuracy: 0.9943 - val_loss: 0.4757 - val_accuracy: 0.8833\n","Epoch 97/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.0357 - accuracy: 0.9866 - val_loss: 0.4886 - val_accuracy: 0.8905\n","Epoch 98/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0201 - accuracy: 0.9948 - val_loss: 0.4754 - val_accuracy: 0.8864\n","Epoch 99/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0127 - accuracy: 0.9972 - val_loss: 0.4709 - val_accuracy: 0.8936\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.4808 - val_accuracy: 0.8998\n","{'loss': [0.13882975280284882, 0.09826646745204926, 0.08779110014438629, 0.08813106268644333, 0.08115168660879135, 0.1015460416674614, 0.07352229207754135, 0.07448180764913559, 0.06855195760726929, 0.07249175757169724, 0.06546676903963089, 0.06324257701635361, 0.08053230494260788, 0.07097318023443222, 0.06666137278079987, 0.063106968998909, 0.0608903206884861, 0.05407840386033058, 0.06234530732035637, 0.053921863436698914, 0.05554765462875366, 0.05483657121658325, 0.05545682832598686, 0.05807999521493912, 0.052779797464609146, 0.05053110048174858, 0.05530562251806259, 0.05236275866627693, 0.0462045781314373, 0.06283202767372131, 0.06583134829998016, 0.046423785388469696, 0.05241921916604042, 0.04711693897843361, 0.05137183889746666, 0.04406654089689255, 0.04704149812459946, 0.03987167775630951, 0.03722025081515312, 0.03779371455311775, 0.040123533457517624, 0.03887239843606949, 0.037510890513658524, 0.05273077264428139, 0.04069942608475685, 0.03266909345984459, 0.048685234040021896, 0.03182239457964897, 0.03187144920229912, 0.045050740242004395, 0.03879772126674652, 0.031446874141693115, 0.031374938786029816, 0.05410691723227501, 0.027665983885526657, 0.02984052151441574, 0.031532060354948044, 0.03013818897306919, 0.02825481817126274, 0.027801888063549995, 0.042272720485925674, 0.030820857733488083, 0.024273237213492393, 0.024717124179005623, 0.02346830815076828, 0.02664691023528576, 0.030371498316526413, 0.03952744975686073, 0.026546696200966835, 0.027109438553452492, 0.018749184906482697, 0.025190096348524094, 0.026340428739786148, 0.02299846149981022, 0.02496100217103958, 0.029587525874376297, 0.017491165548563004, 0.022704001516103745, 0.03696966916322708, 0.038401294499635696, 0.03411608934402466, 0.016585400328040123, 0.02986944653093815, 0.020634541288018227, 0.014061461202800274, 0.017269974574446678, 0.014211675152182579, 0.019175145775079727, 0.0409812293946743, 0.02995161898434162, 0.0385466106235981, 0.051546066999435425, 0.023126764222979546, 0.013563059270381927, 0.014919591136276722, 0.01920047402381897, 0.035721730440855026, 0.02011696994304657, 0.01274543721228838, 0.01331309787929058], 'accuracy': [0.9493539929389954, 0.960465133190155, 0.9664082527160645, 0.9661498665809631, 0.970801055431366, 0.960465133190155, 0.9713178277015686, 0.9731265902519226, 0.9780361652374268, 0.9731265902519226, 0.9785529971122742, 0.9770025610923767, 0.9705426096916199, 0.9731265902519226, 0.9764857888221741, 0.9749354124069214, 0.9777777791023254, 0.9826873540878296, 0.9762274026870728, 0.985012948513031, 0.9826873540878296, 0.9798449873924255, 0.9806201457977295, 0.9811369776725769, 0.9837209582328796, 0.9837209582328796, 0.9808785319328308, 0.9829457402229309, 0.9865633249282837, 0.9733850359916687, 0.9759690165519714, 0.9863049387931824, 0.9824289679527283, 0.9837209582328796, 0.9813953638076782, 0.9870800971984863, 0.985788106918335, 0.9873384833335876, 0.987596869468689, 0.987596869468689, 0.985788106918335, 0.9888888597488403, 0.9873384833335876, 0.9795865416526794, 0.985012948513031, 0.9883720874786377, 0.9811369776725769, 0.9899224638938904, 0.9912144541740417, 0.983979344367981, 0.987596869468689, 0.9896640777587891, 0.9881137013435364, 0.9806201457977295, 0.9909560680389404, 0.9906976819038391, 0.9896640777587891, 0.9906976819038391, 0.9899224638938904, 0.9912144541740417, 0.9837209582328796, 0.9891473054885864, 0.9940568208694458, 0.9919896721839905, 0.9940568208694458, 0.9904392957687378, 0.9894056916236877, 0.9852713346481323, 0.9904392957687378, 0.9917312860488892, 0.9945736527442932, 0.9925064444541931, 0.9927648305892944, 0.9919896721839905, 0.9925064444541931, 0.9899224638938904, 0.9953488111495972, 0.9927648305892944, 0.9865633249282837, 0.986821711063385, 0.986821711063385, 0.9956072568893433, 0.9891473054885864, 0.9940568208694458, 0.9974160194396973, 0.9943152666091919, 0.9963824152946472, 0.9940568208694458, 0.9865633249282837, 0.9891473054885864, 0.9855297207832336, 0.9795865416526794, 0.9927648305892944, 0.997157633304596, 0.9963824152946472, 0.9943152666091919, 0.9865633249282837, 0.9948320388793945, 0.997157633304596, 0.9966408014297485], 'val_loss': [0.7221331596374512, 0.7209726572036743, 0.718692421913147, 0.7176467180252075, 0.7184157967567444, 0.7124345302581787, 0.7068718671798706, 0.6975906491279602, 0.6660212874412537, 0.6370948553085327, 0.6003903746604919, 0.5590640902519226, 0.48176640272140503, 0.48251500725746155, 0.40643152594566345, 0.4180937707424164, 0.331633985042572, 0.2765568196773529, 0.3264760971069336, 0.25983116030693054, 0.3084516227245331, 0.27522093057632446, 0.3353410065174103, 0.2757900655269623, 0.29554563760757446, 0.44379448890686035, 0.33554142713546753, 0.35109743475914, 0.36590373516082764, 0.3940456211566925, 0.3314701318740845, 0.37911456823349, 0.3567308187484741, 0.3508729040622711, 0.39166319370269775, 0.3868992328643799, 0.3570568859577179, 0.3616323471069336, 0.3856167495250702, 0.3904523253440857, 0.3809729516506195, 0.4211738407611847, 0.5737874507904053, 0.4521305561065674, 0.43467918038368225, 0.3842412829399109, 0.4557774066925049, 0.4064606726169586, 0.3868677616119385, 0.49155193567276, 0.402294397354126, 0.40023016929626465, 0.45993927121162415, 0.44279050827026367, 0.4128818213939667, 0.4176751673221588, 0.41488999128341675, 0.4001907706260681, 0.40276747941970825, 0.4111136496067047, 0.4118543863296509, 0.41094282269477844, 0.45437493920326233, 0.4311293661594391, 0.44743770360946655, 0.5384901762008667, 0.43402817845344543, 0.4287186563014984, 0.49342313408851624, 0.44348764419555664, 0.4251176118850708, 0.4888398051261902, 0.4283002018928528, 0.439383864402771, 0.4941308796405792, 0.446943461894989, 0.46618250012397766, 0.465045303106308, 0.4907403886318207, 0.436766117811203, 0.4857250452041626, 0.4550248086452484, 0.4464075565338135, 0.4605599641799927, 0.5379915237426758, 0.46946170926094055, 0.47430333495140076, 0.6912298202514648, 0.464722216129303, 0.5136300921440125, 0.4878828823566437, 0.4894437789916992, 0.4951210021972656, 0.4600605070590973, 0.4674900472164154, 0.47569364309310913, 0.4885956346988678, 0.4753635823726654, 0.47087809443473816, 0.48079702258110046], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.49380165338516235, 0.5010330677032471, 0.5454545617103577, 0.6033057570457458, 0.7561983466148376, 0.7190082669258118, 0.827479362487793, 0.7861570119857788, 0.8729338645935059, 0.8935950398445129, 0.8584710955619812, 0.8884297609329224, 0.8729338645935059, 0.8935950398445129, 0.8708677887916565, 0.9049586653709412, 0.8925619721412659, 0.85537189245224, 0.8987603187561035, 0.8904958963394165, 0.8811983466148376, 0.8873966932296753, 0.9028925895690918, 0.8915289044380188, 0.9018595218658447, 0.8977272510528564, 0.8915289044380188, 0.8822314143180847, 0.9059917330741882, 0.89462810754776, 0.9008264541625977, 0.8832644820213318, 0.8997933864593506, 0.8832644820213318, 0.8502066135406494, 0.8884297609329224, 0.8853305578231812, 0.89462810754776, 0.8770661354064941, 0.8873966932296753, 0.8956611752510071, 0.8801652789115906, 0.8925619721412659, 0.8925619721412659, 0.8801652789115906, 0.8801652789115906, 0.9008264541625977, 0.8863636255264282, 0.8966942429542542, 0.8966942429542542, 0.8997933864593506, 0.8956611752510071, 0.9028925895690918, 0.8997933864593506, 0.8977272510528564, 0.8966942429542542, 0.8884297609329224, 0.8739669322967529, 0.8997933864593506, 0.8884297609329224, 0.8780992031097412, 0.8915289044380188, 0.8915289044380188, 0.8811983466148376, 0.89462810754776, 0.8894628286361694, 0.8935950398445129, 0.8925619721412659, 0.8842975497245789, 0.8863636255264282, 0.8904958963394165, 0.8997933864593506, 0.8832644820213318, 0.8935950398445129, 0.8956611752510071, 0.8873966932296753, 0.8822314143180847, 0.8884297609329224, 0.8915289044380188, 0.8481404781341553, 0.8987603187561035, 0.8780992031097412, 0.8956611752510071, 0.8884297609329224, 0.8822314143180847, 0.8925619721412659, 0.8987603187561035, 0.8832644820213318, 0.8904958963394165, 0.8863636255264282, 0.8935950398445129, 0.8997933864593506]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.0770 - accuracy: 0.9743"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 20s 460ms/step - loss: 0.0762 - accuracy: 0.9744 - val_loss: 0.7352 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0482 - accuracy: 0.9833 - val_loss: 0.7322 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0433 - accuracy: 0.9846 - val_loss: 0.7320 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0359 - accuracy: 0.9879 - val_loss: 0.7298 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0398 - accuracy: 0.9879 - val_loss: 0.7290 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0332 - accuracy: 0.9881 - val_loss: 0.7244 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0322 - accuracy: 0.9892 - val_loss: 0.7159 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0296 - accuracy: 0.9898 - val_loss: 0.6940 - val_accuracy: 0.4903\n","Epoch 9/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0392 - accuracy: 0.9860 - val_loss: 0.7050 - val_accuracy: 0.4903\n","Epoch 10/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0611 - accuracy: 0.9760 - val_loss: 0.5988 - val_accuracy: 0.5603\n","Epoch 11/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0557 - accuracy: 0.9798 - val_loss: 0.5874 - val_accuracy: 0.5722\n","Epoch 12/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0331 - accuracy: 0.9895 - val_loss: 0.5802 - val_accuracy: 0.5841\n","Epoch 13/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0298 - accuracy: 0.9906 - val_loss: 0.4963 - val_accuracy: 0.6864\n","Epoch 14/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0355 - accuracy: 0.9873 - val_loss: 0.4375 - val_accuracy: 0.7662\n","Epoch 15/100\n","29/29 [==============================] - 1s 42ms/step - loss: 0.0268 - accuracy: 0.9911 - val_loss: 0.4185 - val_accuracy: 0.7672\n","Epoch 16/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0373 - accuracy: 0.9865 - val_loss: 0.3957 - val_accuracy: 0.7856\n","Epoch 17/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.0407 - accuracy: 0.9836 - val_loss: 0.3406 - val_accuracy: 0.8470\n","Epoch 18/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0353 - accuracy: 0.9855 - val_loss: 0.2770 - val_accuracy: 0.8944\n","Epoch 19/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.0261 - accuracy: 0.9908 - val_loss: 0.2354 - val_accuracy: 0.9170\n","Epoch 20/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 0.2314 - val_accuracy: 0.9181\n","Epoch 21/100\n","29/29 [==============================] - 1s 41ms/step - loss: 0.0178 - accuracy: 0.9957 - val_loss: 0.2086 - val_accuracy: 0.9310\n","Epoch 22/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0208 - accuracy: 0.9938 - val_loss: 0.2775 - val_accuracy: 0.8836\n","Epoch 23/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.0252 - accuracy: 0.9925 - val_loss: 0.1791 - val_accuracy: 0.9397\n","Epoch 24/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0243 - accuracy: 0.9925 - val_loss: 0.2276 - val_accuracy: 0.9149\n","Epoch 25/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0409 - accuracy: 0.9838 - val_loss: 0.2024 - val_accuracy: 0.9343\n","Epoch 26/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0186 - accuracy: 0.9927 - val_loss: 0.2149 - val_accuracy: 0.9332\n","Epoch 27/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0201 - accuracy: 0.9941 - val_loss: 0.2157 - val_accuracy: 0.9321\n","Epoch 28/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.0146 - accuracy: 0.9962 - val_loss: 0.2116 - val_accuracy: 0.9429\n","Epoch 29/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.0141 - accuracy: 0.9965 - val_loss: 0.2509 - val_accuracy: 0.9300\n","Epoch 30/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.2282 - val_accuracy: 0.9397\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0286 - accuracy: 0.9892 - val_loss: 0.2632 - val_accuracy: 0.9343\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0189 - accuracy: 0.9925 - val_loss: 0.2791 - val_accuracy: 0.9278\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0231 - accuracy: 0.9914 - val_loss: 0.2701 - val_accuracy: 0.9289\n","Epoch 34/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0202 - accuracy: 0.9922 - val_loss: 0.2471 - val_accuracy: 0.9461\n","Epoch 35/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0173 - accuracy: 0.9938 - val_loss: 0.2577 - val_accuracy: 0.9386\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.2648 - val_accuracy: 0.9353\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0258 - accuracy: 0.9900 - val_loss: 0.2592 - val_accuracy: 0.9353\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0210 - accuracy: 0.9927 - val_loss: 0.2486 - val_accuracy: 0.9343\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 0.2934 - val_accuracy: 0.9256\n","Epoch 40/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 0.3290 - val_accuracy: 0.9192\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 0.2594 - val_accuracy: 0.9364\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0271 - accuracy: 0.9900 - val_loss: 0.2972 - val_accuracy: 0.9289\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.2583 - val_accuracy: 0.9407\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0159 - accuracy: 0.9960 - val_loss: 0.2549 - val_accuracy: 0.9418\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0159 - accuracy: 0.9941 - val_loss: 0.2590 - val_accuracy: 0.9386\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0257 - accuracy: 0.9908 - val_loss: 0.2771 - val_accuracy: 0.9321\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0175 - accuracy: 0.9941 - val_loss: 0.2970 - val_accuracy: 0.9300\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.2779 - val_accuracy: 0.9343\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0225 - accuracy: 0.9914 - val_loss: 0.2882 - val_accuracy: 0.9321\n","Epoch 50/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0143 - accuracy: 0.9938 - val_loss: 0.2969 - val_accuracy: 0.9300\n","Epoch 51/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0165 - accuracy: 0.9938 - val_loss: 0.2657 - val_accuracy: 0.9364\n","Epoch 52/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.3715 - val_accuracy: 0.9138\n","Epoch 53/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0130 - accuracy: 0.9946 - val_loss: 0.2674 - val_accuracy: 0.9364\n","Epoch 54/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0085 - accuracy: 0.9987 - val_loss: 0.3077 - val_accuracy: 0.9267\n","Epoch 55/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.2846 - val_accuracy: 0.9321\n","Epoch 56/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.2841 - val_accuracy: 0.9343\n","Epoch 57/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0080 - accuracy: 0.9984 - val_loss: 0.2822 - val_accuracy: 0.9300\n","Epoch 58/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0094 - accuracy: 0.9965 - val_loss: 0.2816 - val_accuracy: 0.9364\n","Epoch 59/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.2821 - val_accuracy: 0.9310\n","Epoch 60/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.2958 - val_accuracy: 0.9321\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0118 - accuracy: 0.9952 - val_loss: 0.4789 - val_accuracy: 0.8976\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.2954 - val_accuracy: 0.9332\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.3100 - val_accuracy: 0.9310\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0087 - accuracy: 0.9981 - val_loss: 0.2929 - val_accuracy: 0.9353\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 0.3115 - val_accuracy: 0.9332\n","Epoch 66/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.2966 - val_accuracy: 0.9364\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.2910 - val_accuracy: 0.9397\n","Epoch 68/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.3014 - val_accuracy: 0.9310\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.3011 - val_accuracy: 0.9310\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.2944 - val_accuracy: 0.9300\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 0.3349 - val_accuracy: 0.9256\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.3041 - val_accuracy: 0.9332\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.4363 - val_accuracy: 0.9084\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0109 - accuracy: 0.9949 - val_loss: 0.3358 - val_accuracy: 0.9267\n","Epoch 75/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.3159 - val_accuracy: 0.9289\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 0.3203 - val_accuracy: 0.9278\n","Epoch 77/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.0419 - accuracy: 0.9817 - val_loss: 0.5314 - val_accuracy: 0.8922\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.3186 - val_accuracy: 0.9300\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.3139 - val_accuracy: 0.9300\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0096 - accuracy: 0.9960 - val_loss: 0.3378 - val_accuracy: 0.9246\n","Epoch 81/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.1018 - accuracy: 0.9655 - val_loss: 0.3084 - val_accuracy: 0.9300\n","Epoch 82/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0461 - accuracy: 0.9817 - val_loss: 0.3367 - val_accuracy: 0.9203\n","Epoch 83/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.3292 - val_accuracy: 0.9267\n","Epoch 84/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0075 - accuracy: 0.9987 - val_loss: 0.3468 - val_accuracy: 0.9192\n","Epoch 85/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.3201 - val_accuracy: 0.9192\n","Epoch 86/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.0075 - accuracy: 0.9987 - val_loss: 0.4427 - val_accuracy: 0.8998\n","Epoch 87/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.2944 - val_accuracy: 0.9310\n","Epoch 88/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.2974 - val_accuracy: 0.9300\n","Epoch 89/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.3398 - val_accuracy: 0.9246\n","Epoch 90/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.0096 - accuracy: 0.9978 - val_loss: 0.3194 - val_accuracy: 0.9267\n","Epoch 91/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.2955 - val_accuracy: 0.9321\n","Epoch 92/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0055 - accuracy: 0.9995 - val_loss: 0.3120 - val_accuracy: 0.9256\n","Epoch 93/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.3061 - val_accuracy: 0.9332\n","Epoch 94/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 0.3494 - val_accuracy: 0.9235\n","Epoch 95/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.3348 - val_accuracy: 0.9310\n","Epoch 96/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0077 - accuracy: 0.9968 - val_loss: 0.3105 - val_accuracy: 0.9300\n","Epoch 97/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.3161 - val_accuracy: 0.9235\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.3158 - val_accuracy: 0.9278\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 0.3529 - val_accuracy: 0.9203\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.3451 - val_accuracy: 0.9289\n","{'loss': [0.07623447477817535, 0.048233989626169205, 0.04326113685965538, 0.03591174632310867, 0.039782073348760605, 0.033216334879398346, 0.032247394323349, 0.029638882726430893, 0.03921984136104584, 0.06105643883347511, 0.055665649473667145, 0.03310500457882881, 0.02983834221959114, 0.03550908342003822, 0.026834050193428993, 0.037337418645620346, 0.040726251900196075, 0.035256464034318924, 0.026100408285856247, 0.02388734742999077, 0.017799854278564453, 0.020849021151661873, 0.025211798027157784, 0.024318357929587364, 0.040942903608083725, 0.018578071147203445, 0.02009904384613037, 0.014562513679265976, 0.014063209295272827, 0.016465818509459496, 0.02860100194811821, 0.0189294945448637, 0.02309633418917656, 0.020215298980474472, 0.017294511198997498, 0.013950640335679054, 0.0258163008838892, 0.020953726023435593, 0.01689322292804718, 0.020616017282009125, 0.019078083336353302, 0.02710479125380516, 0.018720941618084908, 0.015943333506584167, 0.01589656062424183, 0.02573959343135357, 0.017458615824580193, 0.014320770278573036, 0.022543037310242653, 0.014349935576319695, 0.01649080030620098, 0.012070158496499062, 0.01296006515622139, 0.00851211603730917, 0.014474134892225266, 0.010200893506407738, 0.008004470728337765, 0.00939906295388937, 0.007912954315543175, 0.007510330993682146, 0.011824343353509903, 0.012945168651640415, 0.010723432525992393, 0.008745105005800724, 0.011837475933134556, 0.009669753722846508, 0.011932860128581524, 0.012710021808743477, 0.005828232504427433, 0.013952067121863365, 0.011453433893620968, 0.012093769386410713, 0.01003570668399334, 0.010856940411031246, 0.007262802217155695, 0.02088584005832672, 0.041929151862859726, 0.014709287323057652, 0.011089951731264591, 0.009609878063201904, 0.10175590217113495, 0.04605862870812416, 0.009187757037580013, 0.007514254190027714, 0.0077889603562653065, 0.007480798754841089, 0.00758000835776329, 0.009440227411687374, 0.010714457370340824, 0.009583123959600925, 0.0057854545302689075, 0.005475974176079035, 0.004319869913160801, 0.00800040178000927, 0.008094720542430878, 0.007704292424023151, 0.009263554587960243, 0.006120219361037016, 0.0053017158061265945, 0.0069984863512218], 'accuracy': [0.9744073152542114, 0.9832974076271057, 0.9846444129943848, 0.9878771305084229, 0.9878771305084229, 0.9881465435028076, 0.9892241358757019, 0.9897629022598267, 0.985991358757019, 0.9760237336158752, 0.9797952771186829, 0.9894935488700867, 0.990571141242981, 0.9873383641242981, 0.9911099076271057, 0.9865301847457886, 0.9835668206214905, 0.9854525923728943, 0.990840494632721, 0.9921875, 0.9956896305084229, 0.993803858757019, 0.9924569129943848, 0.9924569129943848, 0.9838362336158752, 0.9927262663841248, 0.9940732717514038, 0.9962284564971924, 0.9964978694915771, 0.9954202771186829, 0.9892241358757019, 0.9924569129943848, 0.9913793206214905, 0.9921875, 0.993803858757019, 0.9954202771186829, 0.9900323152542114, 0.9927262663841248, 0.9951508641242981, 0.9940732717514038, 0.9932650923728943, 0.9900323152542114, 0.9943426847457886, 0.9959590435028076, 0.9940732717514038, 0.990840494632721, 0.9940732717514038, 0.9951508641242981, 0.9913793206214905, 0.993803858757019, 0.993803858757019, 0.9962284564971924, 0.9946120977401733, 0.998652994632721, 0.9956896305084229, 0.9975754022598267, 0.998383641242981, 0.9964978694915771, 0.998383641242981, 0.9978448152542114, 0.9951508641242981, 0.9956896305084229, 0.9962284564971924, 0.9981142282485962, 0.9956896305084229, 0.9970366358757019, 0.9967672228813171, 0.9959590435028076, 0.998383641242981, 0.9951508641242981, 0.9959590435028076, 0.9970366358757019, 0.9967672228813171, 0.9948814511299133, 0.998383641242981, 0.9929956793785095, 0.9816810488700867, 0.9956896305084229, 0.9962284564971924, 0.9959590435028076, 0.9655172228813171, 0.9816810488700867, 0.9973060488700867, 0.998652994632721, 0.9978448152542114, 0.998652994632721, 0.9989224076271057, 0.9970366358757019, 0.9970366358757019, 0.9978448152542114, 0.9989224076271057, 0.9994612336158752, 0.9991918206214905, 0.9981142282485962, 0.9978448152542114, 0.9967672228813171, 0.9975754022598267, 0.9975754022598267, 0.9994612336158752, 0.9978448152542114], 'val_loss': [0.73521888256073, 0.7321973443031311, 0.7319753170013428, 0.729806661605835, 0.7290011048316956, 0.7244408130645752, 0.7159273028373718, 0.6939946413040161, 0.7050151228904724, 0.598750650882721, 0.5873897671699524, 0.5801753997802734, 0.49632617831230164, 0.4375324547290802, 0.418545126914978, 0.3956562876701355, 0.3406435549259186, 0.27702057361602783, 0.23540343344211578, 0.2313520759344101, 0.20857542753219604, 0.2775490880012512, 0.1790606677532196, 0.22764930129051208, 0.20236024260520935, 0.21490536630153656, 0.21571996808052063, 0.2116294503211975, 0.2508852481842041, 0.22817325592041016, 0.26319095492362976, 0.27910393476486206, 0.2701233923435211, 0.24713793396949768, 0.2576617896556854, 0.2647685408592224, 0.2591552734375, 0.2486231029033661, 0.29337385296821594, 0.3290409445762634, 0.2593845725059509, 0.2971653342247009, 0.2582586407661438, 0.25486668944358826, 0.258980929851532, 0.27705276012420654, 0.29700249433517456, 0.277892142534256, 0.28820812702178955, 0.2968606948852539, 0.2657381296157837, 0.37145546078681946, 0.26737135648727417, 0.3077490031719208, 0.2845643162727356, 0.28408926725387573, 0.2821669280529022, 0.28160160779953003, 0.28210732340812683, 0.29576605558395386, 0.4788600206375122, 0.2954476773738861, 0.30996668338775635, 0.29285570979118347, 0.31154894828796387, 0.29663342237472534, 0.29095742106437683, 0.3014014661312103, 0.3011244833469391, 0.2943621873855591, 0.3348943889141083, 0.30406707525253296, 0.43633362650871277, 0.3357517123222351, 0.31590041518211365, 0.32032009959220886, 0.5314212441444397, 0.3185664415359497, 0.31391575932502747, 0.3378147482872009, 0.3083769977092743, 0.3366691470146179, 0.3292112648487091, 0.34675586223602295, 0.3200870454311371, 0.4427282214164734, 0.2944146990776062, 0.2973918914794922, 0.33978861570358276, 0.31939876079559326, 0.29547351598739624, 0.31200772523880005, 0.306053102016449, 0.3494051992893219, 0.33475178480148315, 0.31053903698921204, 0.3160620927810669, 0.3158055543899536, 0.35290536284446716, 0.34506264328956604], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.4903017282485962, 0.4903017282485962, 0.5603448152542114, 0.5721982717514038, 0.5840517282485962, 0.6864224076271057, 0.7661637663841248, 0.767241358757019, 0.7855603694915771, 0.8469827771186829, 0.8943965435028076, 0.9170258641242981, 0.9181034564971924, 0.931034505367279, 0.8836206793785095, 0.9396551847457886, 0.9148706793785095, 0.9342672228813171, 0.9331896305084229, 0.9321120977401733, 0.9428879022598267, 0.9299569129943848, 0.9396551847457886, 0.9342672228813171, 0.9278017282485962, 0.9288793206214905, 0.9461206793785095, 0.9385775923728943, 0.9353448152542114, 0.9353448152542114, 0.9342672228813171, 0.9256465435028076, 0.9191810488700867, 0.9364224076271057, 0.9288793206214905, 0.9407327771186829, 0.9418103694915771, 0.9385775923728943, 0.9321120977401733, 0.9299569129943848, 0.9342672228813171, 0.9321120977401733, 0.9299569129943848, 0.9364224076271057, 0.9137930870056152, 0.9364224076271057, 0.9267241358757019, 0.9321120977401733, 0.9342672228813171, 0.9299569129943848, 0.9364224076271057, 0.931034505367279, 0.9321120977401733, 0.8976293206214905, 0.9331896305084229, 0.931034505367279, 0.9353448152542114, 0.9331896305084229, 0.9364224076271057, 0.9396551847457886, 0.931034505367279, 0.931034505367279, 0.9299569129943848, 0.9256465435028076, 0.9331896305084229, 0.9084051847457886, 0.9267241358757019, 0.9288793206214905, 0.9278017282485962, 0.892241358757019, 0.9299569129943848, 0.9299569129943848, 0.9245689511299133, 0.9299569129943848, 0.920258641242981, 0.9267241358757019, 0.9191810488700867, 0.9191810488700867, 0.899784505367279, 0.931034505367279, 0.9299569129943848, 0.9245689511299133, 0.9267241358757019, 0.9321120977401733, 0.9256465435028076, 0.9331896305084229, 0.923491358757019, 0.931034505367279, 0.9299569129943848, 0.923491358757019, 0.9278017282485962, 0.920258641242981, 0.9288793206214905]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.0764 - accuracy: 0.9750"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 12s 221ms/step - loss: 0.0751 - accuracy: 0.9759 - val_loss: 0.7287 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0592 - accuracy: 0.9791 - val_loss: 0.7280 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0420 - accuracy: 0.9842 - val_loss: 0.7252 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0484 - accuracy: 0.9859 - val_loss: 0.7261 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0486 - accuracy: 0.9819 - val_loss: 0.7217 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0360 - accuracy: 0.9887 - val_loss: 0.7149 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0381 - accuracy: 0.9898 - val_loss: 0.7136 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.0383 - accuracy: 0.9875 - val_loss: 0.6991 - val_accuracy: 0.4966\n","Epoch 9/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0325 - accuracy: 0.9912 - val_loss: 0.6747 - val_accuracy: 0.5057\n","Epoch 10/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0377 - accuracy: 0.9881 - val_loss: 0.6284 - val_accuracy: 0.5294\n","Epoch 11/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0443 - accuracy: 0.9836 - val_loss: 0.6255 - val_accuracy: 0.5339\n","Epoch 12/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0358 - accuracy: 0.9878 - val_loss: 0.5412 - val_accuracy: 0.6290\n","Epoch 13/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0320 - accuracy: 0.9904 - val_loss: 0.5005 - val_accuracy: 0.6889\n","Epoch 14/100\n","28/28 [==============================] - 3s 114ms/step - loss: 0.0318 - accuracy: 0.9895 - val_loss: 0.4269 - val_accuracy: 0.8224\n","Epoch 15/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0301 - accuracy: 0.9895 - val_loss: 0.4069 - val_accuracy: 0.8088\n","Epoch 16/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0367 - accuracy: 0.9875 - val_loss: 0.3718 - val_accuracy: 0.8360\n","Epoch 17/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0298 - accuracy: 0.9890 - val_loss: 0.3138 - val_accuracy: 0.8812\n","Epoch 18/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.2705 - val_accuracy: 0.8982\n","Epoch 19/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.0290 - accuracy: 0.9898 - val_loss: 0.2262 - val_accuracy: 0.9265\n","Epoch 20/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0297 - accuracy: 0.9907 - val_loss: 0.1975 - val_accuracy: 0.9378\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0280 - accuracy: 0.9898 - val_loss: 0.1852 - val_accuracy: 0.9310\n","Epoch 22/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0317 - accuracy: 0.9890 - val_loss: 0.1873 - val_accuracy: 0.9355\n","Epoch 23/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0269 - accuracy: 0.9909 - val_loss: 0.2009 - val_accuracy: 0.9219\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0310 - accuracy: 0.9875 - val_loss: 0.2168 - val_accuracy: 0.9174\n","Epoch 25/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0242 - accuracy: 0.9912 - val_loss: 0.1863 - val_accuracy: 0.9287\n","Epoch 26/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0186 - accuracy: 0.9952 - val_loss: 0.2333 - val_accuracy: 0.9253\n","Epoch 27/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 0.2075 - val_accuracy: 0.9344\n","Epoch 28/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.2117 - val_accuracy: 0.9355\n","Epoch 29/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.3076 - val_accuracy: 0.9061\n","Epoch 30/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.2226 - val_accuracy: 0.9344\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0253 - accuracy: 0.9904 - val_loss: 0.2919 - val_accuracy: 0.9219\n","Epoch 32/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0211 - accuracy: 0.9924 - val_loss: 0.2500 - val_accuracy: 0.9367\n","Epoch 33/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0182 - accuracy: 0.9955 - val_loss: 0.2439 - val_accuracy: 0.9367\n","Epoch 34/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.2543 - val_accuracy: 0.9344\n","Epoch 35/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0294 - accuracy: 0.9895 - val_loss: 0.4358 - val_accuracy: 0.8880\n","Epoch 36/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0527 - accuracy: 0.9791 - val_loss: 0.2961 - val_accuracy: 0.9299\n","Epoch 37/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0298 - accuracy: 0.9884 - val_loss: 0.2764 - val_accuracy: 0.9299\n","Epoch 38/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.2518 - val_accuracy: 0.9367\n","Epoch 39/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.2579 - val_accuracy: 0.9344\n","Epoch 40/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0197 - accuracy: 0.9949 - val_loss: 0.2841 - val_accuracy: 0.9310\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.0199 - accuracy: 0.9924 - val_loss: 0.3004 - val_accuracy: 0.9321\n","Epoch 42/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0300 - accuracy: 0.9881 - val_loss: 0.2595 - val_accuracy: 0.9287\n","Epoch 43/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0233 - accuracy: 0.9901 - val_loss: 0.3379 - val_accuracy: 0.9095\n","Epoch 44/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0237 - accuracy: 0.9929 - val_loss: 0.2961 - val_accuracy: 0.9208\n","Epoch 45/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 0.2658 - val_accuracy: 0.9287\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0155 - accuracy: 0.9960 - val_loss: 0.2823 - val_accuracy: 0.9344\n","Epoch 47/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.2998 - val_accuracy: 0.9310\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 0.2763 - val_accuracy: 0.9310\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.2714 - val_accuracy: 0.9355\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 0.3413 - val_accuracy: 0.9253\n","Epoch 51/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0208 - accuracy: 0.9921 - val_loss: 0.2762 - val_accuracy: 0.9321\n","Epoch 52/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0106 - accuracy: 0.9975 - val_loss: 0.2740 - val_accuracy: 0.9299\n","Epoch 53/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0143 - accuracy: 0.9946 - val_loss: 0.3006 - val_accuracy: 0.9242\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0499 - accuracy: 0.9791 - val_loss: 0.3338 - val_accuracy: 0.9219\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0722 - accuracy: 0.9709 - val_loss: 0.2961 - val_accuracy: 0.9265\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0197 - accuracy: 0.9924 - val_loss: 0.2764 - val_accuracy: 0.9276\n","Epoch 57/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.2846 - val_accuracy: 0.9242\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.2916 - val_accuracy: 0.9321\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0124 - accuracy: 0.9966 - val_loss: 0.2914 - val_accuracy: 0.9299\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.2859 - val_accuracy: 0.9276\n","Epoch 61/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0173 - accuracy: 0.9938 - val_loss: 0.2985 - val_accuracy: 0.9276\n","Epoch 62/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0107 - accuracy: 0.9975 - val_loss: 0.3480 - val_accuracy: 0.9253\n","Epoch 63/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.2978 - val_accuracy: 0.9299\n","Epoch 64/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.2937 - val_accuracy: 0.9253\n","Epoch 65/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.2937 - val_accuracy: 0.9299\n","Epoch 66/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.2955 - val_accuracy: 0.9276\n","Epoch 67/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: 0.3025 - val_accuracy: 0.9265\n","Epoch 68/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0096 - accuracy: 0.9977 - val_loss: 0.3018 - val_accuracy: 0.9265\n","Epoch 69/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.3499 - val_accuracy: 0.9253\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.3105 - val_accuracy: 0.9321\n","Epoch 71/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.3122 - val_accuracy: 0.9355\n","Epoch 72/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 0.3697 - val_accuracy: 0.9152\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0428 - accuracy: 0.9861 - val_loss: 0.5230 - val_accuracy: 0.8925\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0350 - accuracy: 0.9867 - val_loss: 0.3191 - val_accuracy: 0.9287\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0204 - accuracy: 0.9929 - val_loss: 0.2969 - val_accuracy: 0.9276\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.2933 - val_accuracy: 0.9299\n","Epoch 77/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.2955 - val_accuracy: 0.9287\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.3066 - val_accuracy: 0.9287\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: 0.3323 - val_accuracy: 0.9265\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.3153 - val_accuracy: 0.9333\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0085 - accuracy: 0.9960 - val_loss: 0.3179 - val_accuracy: 0.9310\n","Epoch 82/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.3194 - val_accuracy: 0.9276\n","Epoch 83/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0157 - accuracy: 0.9941 - val_loss: 0.3248 - val_accuracy: 0.9276\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.3280 - val_accuracy: 0.9197\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.3239 - val_accuracy: 0.9333\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.3597 - val_accuracy: 0.9231\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.0143 - accuracy: 0.9932 - val_loss: 0.3947 - val_accuracy: 0.9106\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.3163 - val_accuracy: 0.9276\n","Epoch 89/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.3734 - val_accuracy: 0.9265\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.3230 - val_accuracy: 0.9344\n","Epoch 91/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.3627 - val_accuracy: 0.9265\n","Epoch 92/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0088 - accuracy: 0.9977 - val_loss: 0.3362 - val_accuracy: 0.9253\n","Epoch 93/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.3363 - val_accuracy: 0.9276\n","Epoch 94/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.3255 - val_accuracy: 0.9276\n","Epoch 95/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.3377 - val_accuracy: 0.9219\n","Epoch 96/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.3731 - val_accuracy: 0.9208\n","Epoch 97/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.3907 - val_accuracy: 0.9174\n","Epoch 98/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.3356 - val_accuracy: 0.9231\n","Epoch 99/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.3529 - val_accuracy: 0.9186\n","Epoch 100/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.3489 - val_accuracy: 0.9152\n","{'loss': [0.07507418841123581, 0.05919734388589859, 0.04199211671948433, 0.048399876803159714, 0.04860113933682442, 0.03598438575863838, 0.038138337433338165, 0.03829953819513321, 0.03248661011457443, 0.03768670931458473, 0.04430924728512764, 0.035808295011520386, 0.031983524560928345, 0.031805261969566345, 0.030124418437480927, 0.036724288016557693, 0.02983512170612812, 0.02350461483001709, 0.029017707332968712, 0.02972065471112728, 0.027997063472867012, 0.03169860318303108, 0.02694624289870262, 0.03103984333574772, 0.024170348420739174, 0.01861785538494587, 0.022549370303750038, 0.021464137360453606, 0.01791957952082157, 0.021928293630480766, 0.025286605581641197, 0.02108052186667919, 0.018158476799726486, 0.0196701493114233, 0.029375839978456497, 0.05274796113371849, 0.029808199033141136, 0.0165041983127594, 0.015059365890920162, 0.019672323018312454, 0.019921114668250084, 0.029993528500199318, 0.023308563977479935, 0.023651359602808952, 0.014878986403346062, 0.015512178651988506, 0.014631802216172218, 0.012567590922117233, 0.011253192089498043, 0.013336324132978916, 0.0208087470382452, 0.010634314268827438, 0.014278959482908249, 0.0499417781829834, 0.07218170911073685, 0.01973986066877842, 0.016497943550348282, 0.010405550710856915, 0.012407386675477028, 0.01047733798623085, 0.017338043078780174, 0.010652617551386356, 0.01006612554192543, 0.009202123619616032, 0.007109649479389191, 0.007850730791687965, 0.008890599943697453, 0.009569142013788223, 0.01052824966609478, 0.013891448266804218, 0.009395753964781761, 0.010560426861047745, 0.042752351611852646, 0.035013504326343536, 0.020433884114027023, 0.01917188987135887, 0.00781925953924656, 0.006947114132344723, 0.008922296576201916, 0.006025826558470726, 0.008530877530574799, 0.0069981105625629425, 0.015740111470222473, 0.00977904163300991, 0.007468990050256252, 0.008314542472362518, 0.014269283041357994, 0.009500850923359394, 0.006208434700965881, 0.009661994874477386, 0.01041983813047409, 0.008829984813928604, 0.00562285678461194, 0.00981907919049263, 0.01157990749925375, 0.010193941183388233, 0.010258136317133904, 0.007737781852483749, 0.00774296373128891, 0.00959999393671751], 'accuracy': [0.975947916507721, 0.9790605306625366, 0.9841539263725281, 0.9858517050743103, 0.9818902015686035, 0.9886813759803772, 0.9898132681846619, 0.9875495433807373, 0.9912280440330505, 0.9881154298782349, 0.9835879802703857, 0.9878324866294861, 0.9903791546821594, 0.9895302653312683, 0.9895302653312683, 0.9875495433807373, 0.988964319229126, 0.992642879486084, 0.9898132681846619, 0.990662157535553, 0.9898132681846619, 0.988964319229126, 0.9909451007843018, 0.9875495433807373, 0.9912280440330505, 0.9951896071434021, 0.9923599362373352, 0.9932088255882263, 0.994340717792511, 0.9932088255882263, 0.9903791546821594, 0.9923599362373352, 0.9954725503921509, 0.9937747716903687, 0.9895302653312683, 0.9790605306625366, 0.9883984327316284, 0.9951896071434021, 0.9957554936408997, 0.9949066042900085, 0.9923599362373352, 0.9881154298782349, 0.9900962114334106, 0.9929258823394775, 0.9954725503921509, 0.9960384964942932, 0.9957554936408997, 0.9960384964942932, 0.9968873858451843, 0.9951896071434021, 0.9920769929885864, 0.9974533319473267, 0.9946236610412598, 0.9790605306625366, 0.9708545804023743, 0.9923599362373352, 0.9949066042900085, 0.9966044425964355, 0.9966044425964355, 0.9971703290939331, 0.9937747716903687, 0.9974533319473267, 0.9966044425964355, 0.9977362751960754, 0.9991511106491089, 0.9980192184448242, 0.9980192184448242, 0.9977362751960754, 0.9966044425964355, 0.9960384964942932, 0.9971703290939331, 0.9971703290939331, 0.9861347079277039, 0.9867005944252014, 0.9929258823394775, 0.9937747716903687, 0.9980192184448242, 0.9985851645469666, 0.9980192184448242, 0.9985851645469666, 0.9960384964942932, 0.9977362751960754, 0.9940577149391174, 0.9971703290939331, 0.9980192184448242, 0.9974533319473267, 0.9932088255882263, 0.9966044425964355, 0.9988681674003601, 0.9974533319473267, 0.9968873858451843, 0.9977362751960754, 0.9985851645469666, 0.9968873858451843, 0.9968873858451843, 0.9966044425964355, 0.9968873858451843, 0.9974533319473267, 0.9977362751960754, 0.9968873858451843], 'val_loss': [0.72871994972229, 0.7280126810073853, 0.7252421379089355, 0.7260829210281372, 0.7216959595680237, 0.7148711681365967, 0.7136136293411255, 0.6990615129470825, 0.6746856570243835, 0.6283939480781555, 0.6254693865776062, 0.5412489175796509, 0.5004546642303467, 0.42691633105278015, 0.4069208800792694, 0.3717876374721527, 0.31378692388534546, 0.2704654932022095, 0.2262074053287506, 0.1974528431892395, 0.18523584306240082, 0.1872790902853012, 0.20089960098266602, 0.21682998538017273, 0.18634401261806488, 0.233340784907341, 0.20745204389095306, 0.21165095269680023, 0.3076181411743164, 0.22260795533657074, 0.29186803102493286, 0.24998591840267181, 0.24394789338111877, 0.2542809844017029, 0.43576741218566895, 0.2961227595806122, 0.2763980031013489, 0.2517709732055664, 0.2579386532306671, 0.2841278314590454, 0.3004380166530609, 0.2594949007034302, 0.3378763794898987, 0.2960866391658783, 0.2657913863658905, 0.2823244631290436, 0.2998058497905731, 0.276326447725296, 0.27141323685646057, 0.34126943349838257, 0.2762475609779358, 0.2739609479904175, 0.300632506608963, 0.33381420373916626, 0.2961457669734955, 0.27638334035873413, 0.28456830978393555, 0.291606068611145, 0.2914429306983948, 0.28585752844810486, 0.2984704375267029, 0.3480220139026642, 0.297779381275177, 0.2937002182006836, 0.2937024235725403, 0.2954731285572052, 0.3024538457393646, 0.30178290605545044, 0.34991273283958435, 0.310489684343338, 0.312203049659729, 0.36965933442115784, 0.5229840278625488, 0.31906068325042725, 0.29694342613220215, 0.29326537251472473, 0.29549574851989746, 0.30659958720207214, 0.33230459690093994, 0.3153165578842163, 0.3179332911968231, 0.3193766474723816, 0.32484671473503113, 0.3279918432235718, 0.32393893599510193, 0.3596719205379486, 0.3946622312068939, 0.3162524402141571, 0.37336406111717224, 0.32300353050231934, 0.362697958946228, 0.3362272381782532, 0.3362938463687897, 0.32551851868629456, 0.33772575855255127, 0.37306827306747437, 0.39071398973464966, 0.33558300137519836, 0.35293513536453247, 0.3489166498184204], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.5056561231613159, 0.529411792755127, 0.5339366793632507, 0.6289592981338501, 0.6889140009880066, 0.8223981857299805, 0.8088235259056091, 0.8359728455543518, 0.8812217116355896, 0.8981900215148926, 0.9264705777168274, 0.9377828240394592, 0.9309954643249512, 0.935520350933075, 0.9219456911087036, 0.9174208045005798, 0.9287330508232117, 0.9253393411636353, 0.9343891143798828, 0.935520350933075, 0.9061086177825928, 0.9343891143798828, 0.9219456911087036, 0.9366515874862671, 0.9366515874862671, 0.9343891143798828, 0.8880090713500977, 0.929864227771759, 0.929864227771759, 0.9366515874862671, 0.9343891143798828, 0.9309954643249512, 0.9321267008781433, 0.9287330508232117, 0.9095022678375244, 0.9208144545555115, 0.9287330508232117, 0.9343891143798828, 0.9309954643249512, 0.9309954643249512, 0.935520350933075, 0.9253393411636353, 0.9321267008781433, 0.929864227771759, 0.9242081642150879, 0.9219456911087036, 0.9264705777168274, 0.9276018142700195, 0.9242081642150879, 0.9321267008781433, 0.929864227771759, 0.9276018142700195, 0.9276018142700195, 0.9253393411636353, 0.929864227771759, 0.9253393411636353, 0.929864227771759, 0.9276018142700195, 0.9264705777168274, 0.9264705777168274, 0.9253393411636353, 0.9321267008781433, 0.935520350933075, 0.9151583909988403, 0.8925339579582214, 0.9287330508232117, 0.9276018142700195, 0.929864227771759, 0.9287330508232117, 0.9287330508232117, 0.9264705777168274, 0.9332579374313354, 0.9309954643249512, 0.9276018142700195, 0.9276018142700195, 0.9196832776069641, 0.9332579374313354, 0.9230769276618958, 0.9106335043907166, 0.9276018142700195, 0.9264705777168274, 0.9343891143798828, 0.9264705777168274, 0.9253393411636353, 0.9276018142700195, 0.9276018142700195, 0.9219456911087036, 0.9208144545555115, 0.9174208045005798, 0.9230769276618958, 0.918552041053772, 0.9151583909988403]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.0807 - accuracy: 0.9717"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 19s 397ms/step - loss: 0.0787 - accuracy: 0.9724 - val_loss: 0.7346 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0521 - accuracy: 0.9796 - val_loss: 0.7349 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0410 - accuracy: 0.9858 - val_loss: 0.7325 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0371 - accuracy: 0.9871 - val_loss: 0.7299 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0385 - accuracy: 0.9848 - val_loss: 0.7336 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0431 - accuracy: 0.9832 - val_loss: 0.7235 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0356 - accuracy: 0.9876 - val_loss: 0.7128 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0337 - accuracy: 0.9876 - val_loss: 0.7056 - val_accuracy: 0.4907\n","Epoch 9/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0360 - accuracy: 0.9873 - val_loss: 0.6813 - val_accuracy: 0.4948\n","Epoch 10/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0324 - accuracy: 0.9879 - val_loss: 0.6247 - val_accuracy: 0.5258\n","Epoch 11/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.0421 - accuracy: 0.9853 - val_loss: 0.5718 - val_accuracy: 0.5868\n","Epoch 12/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.0266 - accuracy: 0.9917 - val_loss: 0.5529 - val_accuracy: 0.6116\n","Epoch 13/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.0374 - accuracy: 0.9848 - val_loss: 0.4569 - val_accuracy: 0.7438\n","Epoch 14/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0395 - accuracy: 0.9853 - val_loss: 0.4602 - val_accuracy: 0.7221\n","Epoch 15/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.0242 - accuracy: 0.9928 - val_loss: 0.3785 - val_accuracy: 0.8275\n","Epoch 16/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.0246 - accuracy: 0.9915 - val_loss: 0.3216 - val_accuracy: 0.8709\n","Epoch 17/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.3093 - val_accuracy: 0.8729\n","Epoch 18/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 0.2199 - val_accuracy: 0.9184\n","Epoch 19/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0243 - accuracy: 0.9935 - val_loss: 0.2202 - val_accuracy: 0.9132\n","Epoch 20/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.0376 - accuracy: 0.9848 - val_loss: 0.2205 - val_accuracy: 0.9194\n","Epoch 21/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0389 - accuracy: 0.9853 - val_loss: 0.2406 - val_accuracy: 0.9101\n","Epoch 22/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0340 - accuracy: 0.9886 - val_loss: 0.2327 - val_accuracy: 0.9132\n","Epoch 23/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0207 - accuracy: 0.9928 - val_loss: 0.2414 - val_accuracy: 0.9174\n","Epoch 24/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0208 - accuracy: 0.9935 - val_loss: 0.2625 - val_accuracy: 0.9153\n","Epoch 25/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0212 - accuracy: 0.9920 - val_loss: 0.2746 - val_accuracy: 0.9163\n","Epoch 26/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0212 - accuracy: 0.9928 - val_loss: 0.2976 - val_accuracy: 0.9112\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0296 - accuracy: 0.9871 - val_loss: 0.3846 - val_accuracy: 0.8915\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0283 - accuracy: 0.9894 - val_loss: 0.3269 - val_accuracy: 0.9153\n","Epoch 29/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0249 - accuracy: 0.9912 - val_loss: 0.3152 - val_accuracy: 0.9194\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.4460 - val_accuracy: 0.8874\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0204 - accuracy: 0.9928 - val_loss: 0.3959 - val_accuracy: 0.9039\n","Epoch 32/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.3717 - val_accuracy: 0.9081\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.3595 - val_accuracy: 0.9174\n","Epoch 34/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.3865 - val_accuracy: 0.9060\n","Epoch 35/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0252 - accuracy: 0.9912 - val_loss: 0.4067 - val_accuracy: 0.9070\n","Epoch 36/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0297 - accuracy: 0.9897 - val_loss: 0.5373 - val_accuracy: 0.8853\n","Epoch 37/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0333 - accuracy: 0.9876 - val_loss: 0.4521 - val_accuracy: 0.8915\n","Epoch 38/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0317 - accuracy: 0.9884 - val_loss: 0.3668 - val_accuracy: 0.9070\n","Epoch 39/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0268 - accuracy: 0.9917 - val_loss: 0.4363 - val_accuracy: 0.8998\n","Epoch 40/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.3518 - val_accuracy: 0.9163\n","Epoch 41/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0253 - accuracy: 0.9910 - val_loss: 0.3941 - val_accuracy: 0.9112\n","Epoch 42/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0287 - accuracy: 0.9904 - val_loss: 0.3507 - val_accuracy: 0.9184\n","Epoch 43/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0130 - accuracy: 0.9964 - val_loss: 0.3467 - val_accuracy: 0.9174\n","Epoch 44/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.3446 - val_accuracy: 0.9163\n","Epoch 45/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.3537 - val_accuracy: 0.9174\n","Epoch 46/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0210 - accuracy: 0.9920 - val_loss: 0.3790 - val_accuracy: 0.9153\n","Epoch 47/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0178 - accuracy: 0.9935 - val_loss: 0.3846 - val_accuracy: 0.9101\n","Epoch 48/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0198 - accuracy: 0.9920 - val_loss: 0.4044 - val_accuracy: 0.9029\n","Epoch 49/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0116 - accuracy: 0.9956 - val_loss: 0.3927 - val_accuracy: 0.9132\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0175 - accuracy: 0.9951 - val_loss: 0.3689 - val_accuracy: 0.9163\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0100 - accuracy: 0.9977 - val_loss: 0.3789 - val_accuracy: 0.9184\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0222 - accuracy: 0.9907 - val_loss: 0.3793 - val_accuracy: 0.9143\n","Epoch 53/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0332 - accuracy: 0.9860 - val_loss: 0.5388 - val_accuracy: 0.8833\n","Epoch 54/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0453 - accuracy: 0.9809 - val_loss: 0.5270 - val_accuracy: 0.8843\n","Epoch 55/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0256 - accuracy: 0.9902 - val_loss: 0.3661 - val_accuracy: 0.9184\n","Epoch 56/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.3673 - val_accuracy: 0.9122\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.3969 - val_accuracy: 0.9132\n","Epoch 58/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0188 - accuracy: 0.9933 - val_loss: 0.3774 - val_accuracy: 0.9163\n","Epoch 59/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.4347 - val_accuracy: 0.9008\n","Epoch 60/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.3841 - val_accuracy: 0.9091\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0270 - accuracy: 0.9899 - val_loss: 0.3741 - val_accuracy: 0.9132\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.3911 - val_accuracy: 0.9163\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.3880 - val_accuracy: 0.9163\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0322 - accuracy: 0.9884 - val_loss: 0.4410 - val_accuracy: 0.8967\n","Epoch 65/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.4451 - val_accuracy: 0.9008\n","Epoch 66/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.3838 - val_accuracy: 0.9143\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.4162 - val_accuracy: 0.9081\n","Epoch 68/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0097 - accuracy: 0.9977 - val_loss: 0.3939 - val_accuracy: 0.9163\n","Epoch 69/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.3833 - val_accuracy: 0.9184\n","Epoch 70/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0080 - accuracy: 0.9984 - val_loss: 0.3986 - val_accuracy: 0.9143\n","Epoch 71/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.4051 - val_accuracy: 0.9163\n","Epoch 72/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0157 - accuracy: 0.9943 - val_loss: 0.4061 - val_accuracy: 0.9132\n","Epoch 73/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0275 - accuracy: 0.9897 - val_loss: 0.4757 - val_accuracy: 0.9060\n","Epoch 74/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.0183 - accuracy: 0.9925 - val_loss: 0.3892 - val_accuracy: 0.9184\n","Epoch 75/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.3982 - val_accuracy: 0.9163\n","Epoch 76/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.3987 - val_accuracy: 0.9143\n","Epoch 77/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0147 - accuracy: 0.9946 - val_loss: 0.4674 - val_accuracy: 0.8957\n","Epoch 78/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.4279 - val_accuracy: 0.9050\n","Epoch 79/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.4080 - val_accuracy: 0.9101\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.4295 - val_accuracy: 0.9029\n","Epoch 81/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.4003 - val_accuracy: 0.9184\n","Epoch 82/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.4030 - val_accuracy: 0.9122\n","Epoch 83/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0061 - accuracy: 0.9995 - val_loss: 0.4090 - val_accuracy: 0.9153\n","Epoch 84/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 0.4309 - val_accuracy: 0.9050\n","Epoch 85/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 0.6410 - val_accuracy: 0.8750\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0268 - accuracy: 0.9904 - val_loss: 0.4683 - val_accuracy: 0.9060\n","Epoch 87/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0257 - accuracy: 0.9889 - val_loss: 0.4232 - val_accuracy: 0.9122\n","Epoch 88/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.4223 - val_accuracy: 0.8998\n","Epoch 89/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0161 - accuracy: 0.9938 - val_loss: 0.4995 - val_accuracy: 0.8998\n","Epoch 90/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.4931 - val_accuracy: 0.9029\n","Epoch 91/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.4281 - val_accuracy: 0.9122\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.4307 - val_accuracy: 0.9101\n","Epoch 93/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.0195 - accuracy: 0.9935 - val_loss: 0.4237 - val_accuracy: 0.9112\n","Epoch 94/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.4608 - val_accuracy: 0.9070\n","Epoch 95/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.0276 - accuracy: 0.9894 - val_loss: 0.5670 - val_accuracy: 0.8812\n","Epoch 96/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0210 - accuracy: 0.9930 - val_loss: 0.4745 - val_accuracy: 0.9008\n","Epoch 97/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.4197 - val_accuracy: 0.9101\n","Epoch 98/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.4185 - val_accuracy: 0.9091\n","Epoch 99/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.0100 - accuracy: 0.9977 - val_loss: 0.4158 - val_accuracy: 0.9091\n","Epoch 100/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.7011 - val_accuracy: 0.8709\n","{'loss': [0.07874376326799393, 0.05214487761259079, 0.04104175791144371, 0.03713822737336159, 0.03853033483028412, 0.043067749589681625, 0.035625994205474854, 0.03367650881409645, 0.036009352654218674, 0.03244895115494728, 0.042135268449783325, 0.026598621159791946, 0.03738703578710556, 0.03953336924314499, 0.02421296201646328, 0.02460567094385624, 0.02378721721470356, 0.024133935570716858, 0.024319134652614594, 0.03763474151492119, 0.03892863169312477, 0.03398476168513298, 0.020651260390877724, 0.02081725001335144, 0.021237501874566078, 0.021164176985621452, 0.029629865661263466, 0.028262754902243614, 0.024946661666035652, 0.01953413151204586, 0.02036430314183235, 0.01768426038324833, 0.015719134360551834, 0.014811108820140362, 0.025196826085448265, 0.02966935932636261, 0.033284496515989304, 0.03172857686877251, 0.026774834841489792, 0.019502421841025352, 0.025265835225582123, 0.028745142742991447, 0.012968897819519043, 0.014798082411289215, 0.011997425928711891, 0.0209659431129694, 0.017756851390004158, 0.019818464294075966, 0.011561242863535881, 0.01746336743235588, 0.009955310262739658, 0.02217753604054451, 0.033226240426301956, 0.045313384383916855, 0.02564334124326706, 0.015531087294220924, 0.012618927285075188, 0.01880780979990959, 0.017128417268395424, 0.010955571196973324, 0.02702919766306877, 0.012263316661119461, 0.01702701859176159, 0.03215424343943596, 0.017367340624332428, 0.013386701233685017, 0.010378554463386536, 0.009735994972288609, 0.0069529274478554726, 0.008001490496098995, 0.00683812377974391, 0.015730025246739388, 0.027493594214320183, 0.018260808661580086, 0.009243636392056942, 0.008011451922357082, 0.014721141196787357, 0.01034506969153881, 0.012301127426326275, 0.007179528009146452, 0.006651321426033974, 0.008434100076556206, 0.006071408744901419, 0.005389433354139328, 0.011215153150260448, 0.026821529492735863, 0.02570808306336403, 0.00861130841076374, 0.01614479161798954, 0.007525074761360884, 0.0063489992171525955, 0.007150659337639809, 0.019463174045085907, 0.01083277352154255, 0.02764737792313099, 0.020990882068872452, 0.009416086599230766, 0.008802207186818123, 0.009956082329154015, 0.009979130700230598], 'accuracy': [0.9723514318466187, 0.9795865416526794, 0.985788106918335, 0.9870800971984863, 0.9847545027732849, 0.9832041263580322, 0.987596869468689, 0.987596869468689, 0.9873384833335876, 0.9878553152084351, 0.9852713346481323, 0.9917312860488892, 0.9847545027732849, 0.9852713346481323, 0.9927648305892944, 0.9914728403091431, 0.9932816624641418, 0.9919896721839905, 0.9935400485992432, 0.9847545027732849, 0.9852713346481323, 0.988630473613739, 0.9927648305892944, 0.9935400485992432, 0.9919896721839905, 0.9927648305892944, 0.9870800971984863, 0.9894056916236877, 0.9912144541740417, 0.9943152666091919, 0.9927648305892944, 0.9950904250144958, 0.9948320388793945, 0.9956072568893433, 0.9912144541740417, 0.9896640777587891, 0.987596869468689, 0.9883720874786377, 0.9917312860488892, 0.9937984347343445, 0.9909560680389404, 0.9904392957687378, 0.9963824152946472, 0.9956072568893433, 0.9974160194396973, 0.9919896721839905, 0.9935400485992432, 0.9919896721839905, 0.9956072568893433, 0.9950904250144958, 0.9976744055747986, 0.9906976819038391, 0.9860464930534363, 0.9808785319328308, 0.9901808500289917, 0.9953488111495972, 0.9968992471694946, 0.9932816624641418, 0.9948320388793945, 0.9961240291595459, 0.9899224638938904, 0.9961240291595459, 0.9945736527442932, 0.9883720874786377, 0.9950904250144958, 0.9958656430244446, 0.9968992471694946, 0.9976744055747986, 0.998191237449646, 0.9984496235847473, 0.998191237449646, 0.9943152666091919, 0.9896640777587891, 0.9925064444541931, 0.9968992471694946, 0.997157633304596, 0.9945736527442932, 0.9966408014297485, 0.9968992471694946, 0.9979327917098999, 0.998191237449646, 0.9976744055747986, 0.9994832277297974, 0.99896639585495, 0.997157633304596, 0.9904392957687378, 0.9888888597488403, 0.9976744055747986, 0.9937984347343445, 0.9984496235847473, 0.9979327917098999, 0.9974160194396973, 0.9935400485992432, 0.9966408014297485, 0.9894056916236877, 0.9930232763290405, 0.997157633304596, 0.997157633304596, 0.9976744055747986, 0.997157633304596], 'val_loss': [0.7345598340034485, 0.7348982691764832, 0.7324764132499695, 0.7299032211303711, 0.7335764169692993, 0.7234647870063782, 0.7128228545188904, 0.7055566310882568, 0.6813045144081116, 0.6247227191925049, 0.5718322992324829, 0.5529419183731079, 0.456877738237381, 0.4601592421531677, 0.37850093841552734, 0.3216167688369751, 0.30926713347435, 0.2199203372001648, 0.220238596200943, 0.22052191197872162, 0.24064117670059204, 0.23270896077156067, 0.2413768172264099, 0.26252833008766174, 0.27455243468284607, 0.29756149649620056, 0.3846452534198761, 0.32693251967430115, 0.3151555359363556, 0.4459681212902069, 0.3958587050437927, 0.37168461084365845, 0.35949769616127014, 0.3865155279636383, 0.4066760838031769, 0.5373077988624573, 0.45208001136779785, 0.36681321263313293, 0.43631067872047424, 0.3517589867115021, 0.3941490650177002, 0.35068705677986145, 0.34665191173553467, 0.34460699558258057, 0.3536735475063324, 0.3789897859096527, 0.38455450534820557, 0.40438738465309143, 0.3927271366119385, 0.3688877820968628, 0.37893667817115784, 0.3792831599712372, 0.5387744307518005, 0.5270332098007202, 0.36613667011260986, 0.36727529764175415, 0.39693304896354675, 0.37735506892204285, 0.4346525967121124, 0.3840878903865814, 0.37411922216415405, 0.39107546210289, 0.38800594210624695, 0.4409903883934021, 0.4450763165950775, 0.383840948343277, 0.41624635457992554, 0.393907755613327, 0.38326317071914673, 0.39859530329704285, 0.40511471033096313, 0.40607935190200806, 0.475669801235199, 0.3891984522342682, 0.3981667160987854, 0.3987027704715729, 0.4674318730831146, 0.42785555124282837, 0.40803802013397217, 0.4295378625392914, 0.40027084946632385, 0.40298449993133545, 0.40899723768234253, 0.43086546659469604, 0.6409586668014526, 0.46830010414123535, 0.4231589436531067, 0.42229726910591125, 0.49954482913017273, 0.4931412935256958, 0.4281272292137146, 0.4307456314563751, 0.4237131178379059, 0.4607628583908081, 0.5669840574264526, 0.474500447511673, 0.4197068512439728, 0.4184872508049011, 0.4157874584197998, 0.7010990381240845], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.49070248007774353, 0.4948347210884094, 0.5258264541625977, 0.586776852607727, 0.6115702390670776, 0.7438016533851624, 0.7221074104309082, 0.827479362487793, 0.8708677887916565, 0.8729338645935059, 0.9183884263038635, 0.913223147392273, 0.9194214940071106, 0.9101239442825317, 0.913223147392273, 0.9173553586006165, 0.9152892827987671, 0.9163222908973694, 0.9111570119857788, 0.8915289044380188, 0.9152892827987671, 0.9194214940071106, 0.8873966932296753, 0.9039255976676941, 0.9080578684806824, 0.9173553586006165, 0.9059917330741882, 0.9070248007774353, 0.8853305578231812, 0.8915289044380188, 0.9070248007774353, 0.8997933864593506, 0.9163222908973694, 0.9111570119857788, 0.9183884263038635, 0.9173553586006165, 0.9163222908973694, 0.9173553586006165, 0.9152892827987671, 0.9101239442825317, 0.9028925895690918, 0.913223147392273, 0.9163222908973694, 0.9183884263038635, 0.91425621509552, 0.8832644820213318, 0.8842975497245789, 0.9183884263038635, 0.9121900796890259, 0.913223147392273, 0.9163222908973694, 0.9008264541625977, 0.9090909361839294, 0.913223147392273, 0.9163222908973694, 0.9163222908973694, 0.8966942429542542, 0.9008264541625977, 0.91425621509552, 0.9080578684806824, 0.9163222908973694, 0.9183884263038635, 0.91425621509552, 0.9163222908973694, 0.913223147392273, 0.9059917330741882, 0.9183884263038635, 0.9163222908973694, 0.91425621509552, 0.8956611752510071, 0.9049586653709412, 0.9101239442825317, 0.9028925895690918, 0.9183884263038635, 0.9121900796890259, 0.9152892827987671, 0.9049586653709412, 0.875, 0.9059917330741882, 0.9121900796890259, 0.8997933864593506, 0.8997933864593506, 0.9028925895690918, 0.9121900796890259, 0.9101239442825317, 0.9111570119857788, 0.9070248007774353, 0.8811983466148376, 0.9008264541625977, 0.9101239442825317, 0.9090909361839294, 0.9090909361839294, 0.8708677887916565]}\n","32/32 [==============================] - 1s 4ms/step\n"]}],"source":["global_model, metrics_df = federated_learning(Theta_data)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1717404317788,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"Ik5JoVP2NPvY","outputId":"938d5aac-dfd5-4b4d-e8e6-132f360c41aa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.750      0.749   0.754  0.751        0.754        0.747   \n","1        1     0.787      0.735   0.895  0.808        0.895        0.678   \n","2        2     0.743      0.717   0.803  0.758        0.803        0.683   \n","3        0     0.789      0.791   0.786  0.788        0.786        0.792   \n","4        1     0.793      0.734   0.919  0.816        0.919        0.667   \n","5        2     0.751      0.679   0.952  0.793        0.952        0.550   \n","6        0     0.800      0.756   0.884  0.815        0.884        0.715   \n","7        1     0.858      0.852   0.867  0.859        0.867        0.849   \n","8        2     0.834      0.832   0.837  0.835        0.837        0.831   \n","9        0     0.845      0.820   0.884  0.851        0.884        0.806   \n","10       1     0.862      0.812   0.944  0.873        0.944        0.781   \n","11       2     0.872      0.835   0.928  0.879        0.928        0.817   \n","12       0     0.869      0.835   0.921  0.876        0.921        0.817   \n","13       1     0.889      0.851   0.944  0.895        0.944        0.835   \n","14       2     0.874      0.915   0.825  0.868        0.825        0.924   \n","\n","    Kappa  \n","0   0.501  \n","1   0.573  \n","2   0.486  \n","3   0.578  \n","4   0.586  \n","5   0.502  \n","6   0.600  \n","7   0.716  \n","8   0.669  \n","9   0.690  \n","10  0.725  \n","11  0.745  \n","12  0.739  \n","13  0.778  \n","14  0.749  "],"text/html":["\n","  <div id=\"df-b286a254-a436-409d-870a-8ed3b953f454\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.750</td>\n","      <td>0.749</td>\n","      <td>0.754</td>\n","      <td>0.751</td>\n","      <td>0.754</td>\n","      <td>0.747</td>\n","      <td>0.501</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.787</td>\n","      <td>0.735</td>\n","      <td>0.895</td>\n","      <td>0.808</td>\n","      <td>0.895</td>\n","      <td>0.678</td>\n","      <td>0.573</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.743</td>\n","      <td>0.717</td>\n","      <td>0.803</td>\n","      <td>0.758</td>\n","      <td>0.803</td>\n","      <td>0.683</td>\n","      <td>0.486</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.789</td>\n","      <td>0.791</td>\n","      <td>0.786</td>\n","      <td>0.788</td>\n","      <td>0.786</td>\n","      <td>0.792</td>\n","      <td>0.578</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.793</td>\n","      <td>0.734</td>\n","      <td>0.919</td>\n","      <td>0.816</td>\n","      <td>0.919</td>\n","      <td>0.667</td>\n","      <td>0.586</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.751</td>\n","      <td>0.679</td>\n","      <td>0.952</td>\n","      <td>0.793</td>\n","      <td>0.952</td>\n","      <td>0.550</td>\n","      <td>0.502</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.800</td>\n","      <td>0.756</td>\n","      <td>0.884</td>\n","      <td>0.815</td>\n","      <td>0.884</td>\n","      <td>0.715</td>\n","      <td>0.600</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.858</td>\n","      <td>0.852</td>\n","      <td>0.867</td>\n","      <td>0.859</td>\n","      <td>0.867</td>\n","      <td>0.849</td>\n","      <td>0.716</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.834</td>\n","      <td>0.832</td>\n","      <td>0.837</td>\n","      <td>0.835</td>\n","      <td>0.837</td>\n","      <td>0.831</td>\n","      <td>0.669</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.845</td>\n","      <td>0.820</td>\n","      <td>0.884</td>\n","      <td>0.851</td>\n","      <td>0.884</td>\n","      <td>0.806</td>\n","      <td>0.690</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.862</td>\n","      <td>0.812</td>\n","      <td>0.944</td>\n","      <td>0.873</td>\n","      <td>0.944</td>\n","      <td>0.781</td>\n","      <td>0.725</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.872</td>\n","      <td>0.835</td>\n","      <td>0.928</td>\n","      <td>0.879</td>\n","      <td>0.928</td>\n","      <td>0.817</td>\n","      <td>0.745</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.869</td>\n","      <td>0.835</td>\n","      <td>0.921</td>\n","      <td>0.876</td>\n","      <td>0.921</td>\n","      <td>0.817</td>\n","      <td>0.739</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.889</td>\n","      <td>0.851</td>\n","      <td>0.944</td>\n","      <td>0.895</td>\n","      <td>0.944</td>\n","      <td>0.835</td>\n","      <td>0.778</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.874</td>\n","      <td>0.915</td>\n","      <td>0.825</td>\n","      <td>0.868</td>\n","      <td>0.825</td>\n","      <td>0.924</td>\n","      <td>0.749</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b286a254-a436-409d-870a-8ed3b953f454')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b286a254-a436-409d-870a-8ed3b953f454 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b286a254-a436-409d-870a-8ed3b953f454');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0a4e7c62-32f1-4a5b-8ae0-be2503eedb8c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a4e7c62-32f1-4a5b-8ae0-be2503eedb8c')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0a4e7c62-32f1-4a5b-8ae0-be2503eedb8c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0504004913052395,\n        \"min\": 0.743,\n        \"max\": 0.889,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.845,\n          0.872,\n          0.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06368022792493308,\n        \"min\": 0.679,\n        \"max\": 0.915,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.82,\n          0.835,\n          0.749\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06245363994882238,\n        \"min\": 0.754,\n        \"max\": 0.952,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.921,\n          0.944,\n          0.754\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0453478618176047,\n        \"min\": 0.751,\n        \"max\": 0.895,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.851,\n          0.879,\n          0.751\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06245363994882238,\n        \"min\": 0.754,\n        \"max\": 0.952,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.921,\n          0.944,\n          0.754\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09357721537903999,\n        \"min\": 0.55,\n        \"max\": 0.924,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.806,\n          0.817,\n          0.747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10104162272949463,\n        \"min\": 0.486,\n        \"max\": 0.778,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.69,\n          0.745,\n          0.501\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}],"source":["\n","metrics_df.round(3)"]},{"cell_type":"code","source":["metrics_df.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/TF Domain/CNN_LSTM/Total_CNN_LSTM.csv', index = False)"],"metadata":{"id":"XI9_UuhpMrbv","executionInfo":{"status":"ok","timestamp":1717404318619,"user_tz":-360,"elapsed":848,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VNy6-RxAKjH8"},"source":["#Draw CNN_LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"executionInfo":{"elapsed":5773,"status":"ok","timestamp":1716752271557,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"},"user_tz":-360},"id":"e-S2thS6KnXT","outputId":"3941d26a-915f-4d07-fa63-4b562bbd151a"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 1500x450 with 10 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re\n","import os\n","\n","# Function to read CSV logs and extract accuracy and validation accuracy\n","def read_logs(log_dir, num_clients, local_epochs):\n","    dataframes = []\n","    for epoch in range(local_epochs):\n","        for client in range(num_clients):\n","            log_file = os.path.join(log_dir, f'training_log_epoch_{epoch}_client_{client}.csv')\n","            if os.path.exists(log_file):\n","                df = pd.read_csv(log_file, sep=';')\n","                df['epoch_number'] = epoch\n","                df['client_number'] = client\n","                dataframes.append(df)\n","            else:\n","                print(f\"Log file not found: {log_file}\")\n","\n","    return pd.concat(dataframes) if dataframes else pd.DataFrame()\n","\n","# Function to plot the training and validation accuracy\n","def plot_accuracy(all_metrics_df, unique_epochs, output_dir):\n","    # Set the Seaborn style\n","    sns.set(style=\"whitegrid\")\n","\n","    # Create subplots for each epoch\n","    fig, axes = plt.subplots(2, len(unique_epochs), figsize=(len(unique_epochs) * 3, 4.5), sharex=True)\n","\n","    # Set the color palette\n","    palette = sns.color_palette(\"Set1\", n_colors=all_metrics_df['client_number'].nunique())\n","\n","    # Store the lines and labels for the legend\n","    lines = []\n","    labels = []\n","\n","    # Iterate through each epoch and plot the training and validation accuracy\n","    for i, epoch in enumerate(unique_epochs):\n","        epoch_df = all_metrics_df[all_metrics_df['epoch_number'] == epoch]\n","        for j, client in enumerate(epoch_df['client_number'].unique()):\n","            client_df = epoch_df[epoch_df['client_number'] == client].dropna(subset=['accuracy', 'val_accuracy'])\n","            if not client_df.empty:\n","                line, = axes[0, i].plot(client_df.index, client_df['accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","                axes[1, i].plot(client_df.index, client_df['val_accuracy'], label=f'Client {client}', alpha=0.6, color=palette[j], linewidth=2.0)\n","\n","                if i == 0:\n","                    lines.append(line)\n","                    labels.append(f'Client {client}')\n","\n","        axes[0, i].set_title(f'Epoch {epoch}', fontsize=12, fontweight='bold')\n","        axes[0, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","        axes[1, i].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","        axes[1, i].set_xlabel('Steps', fontsize=10, fontweight='bold')\n","        axes[0, i].grid(True)\n","        axes[1, i].grid(True)\n","        axes[0, i].tick_params(axis='both', which='major', labelsize=10)\n","        axes[1, i].tick_params(axis='both', which='major', labelsize=10)\n","\n","    # Add a single legend for the entire figure\n","    fig.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 1.0), ncol=len(labels), fontsize=10, frameon=True)\n","\n","    # Add row labels\n","    fig.text(0.04, 0.75, 'Training Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","    fig.text(0.04, 0.25, 'Validation Accuracy', ha='center', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n","\n","    plt.tight_layout(rect=[0.05, 0, 1, 0.95])\n","    plt.subplots_adjust(hspace=0.2, top=0.88)  # Add some space between the rows and reduce space between the legend and plot\n","\n","    # Save the figure in high DPI PNG and PDF\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    fig.savefig(os.path.join(output_dir, 'accuracy_plot.png'), dpi=300, format='png')\n","    fig.savefig(os.path.join(output_dir, 'accuracy_plot.pdf'), dpi=300, format='pdf')\n","\n","    plt.show()\n","\n","# Directory where CSV logs are saved\n","log_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Total'\n","\n","# Output directory for saving plots\n","output_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Total/plots'\n","\n","# Number of clients and local epochs\n","num_clients = 3\n","local_epochs = 5\n","\n","# Read logs and generate the dataframe\n","all_metrics_df = read_logs(log_dir, num_clients, local_epochs)\n","\n","# Get unique epochs from the dataframe\n","unique_epochs = sorted(all_metrics_df['epoch_number'].unique())\n","\n","# Plot the accuracy\n","plot_accuracy(all_metrics_df, unique_epochs, output_dir)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2941,"status":"ok","timestamp":1716752281801,"user":{"displayName":"raihan rabby","userId":"04907331798657563551"},"user_tz":-360},"id":"NlC1cJDfRFjG","outputId":"b6781ded-06c4-4d66-98a9-0057144fec5f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Final Epoch: 4\n","Average Training Accuracy: 0.9972\n","Average Validation Accuracy: 0.9058\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 1200x450 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re\n","import os\n","\n","# Function to read CSV logs and extract accuracy and validation accuracy\n","def read_logs(log_dir, num_clients, local_epochs):\n","    dataframes = []\n","    for epoch in range(local_epochs):\n","        for client in range(num_clients):\n","            log_file = os.path.join(log_dir, f'training_log_epoch_{epoch}_client_{client}.csv')\n","            if os.path.exists(log_file):\n","                df = pd.read_csv(log_file, sep=';')\n","                df['epoch_number'] = epoch\n","                df['client_number'] = client\n","                dataframes.append(df)\n","            else:\n","                print(f\"Log file not found: {log_file}\")\n","\n","    return pd.concat(dataframes) if dataframes else pd.DataFrame()\n","\n","# Function to plot the training and validation accuracy for the final epoch\n","def plot_final_epoch_accuracy(all_metrics_df, output_dir):\n","    # Set the Seaborn style\n","    sns.set(style=\"whitegrid\")\n","\n","    # Get the final epoch number\n","    final_epoch = all_metrics_df['epoch_number'].max()\n","\n","    # Filter the data for the final epoch\n","    final_epoch_df = all_metrics_df[all_metrics_df['epoch_number'] == final_epoch]\n","\n","    # Calculate the average training and validation accuracy for the final epoch\n","    avg_train_accuracy = final_epoch_df['accuracy'].mean()\n","    avg_val_accuracy = final_epoch_df['val_accuracy'].mean()\n","\n","    print(f\"Final Epoch: {final_epoch}\")\n","    print(f\"Average Training Accuracy: {avg_train_accuracy:.4f}\")\n","    print(f\"Average Validation Accuracy: {avg_val_accuracy:.4f}\")\n","\n","    # Create subplots for the final epoch\n","    fig, axes = plt.subplots(1, 2, figsize=(12, 4.5), sharex=True)\n","\n","    # Set the color palette\n","    palette = sns.color_palette(\"Set1\", n_colors=final_epoch_df['client_number'].nunique())\n","\n","    # Store the lines and labels for the legend\n","    lines = []\n","    labels = []\n","\n","    # Plot the training and validation accuracy for the final epoch\n","    for client in final_epoch_df['client_number'].unique():\n","        client_df = final_epoch_df[final_epoch_df['client_number'] == client].dropna(subset=['accuracy', 'val_accuracy'])\n","        if not client_df.empty:\n","            line, = axes[0].plot(client_df.index, client_df['accuracy'], label=f'Client {client}', alpha=0.6, color=palette[client], linewidth=2.0)\n","            axes[1].plot(client_df.index, client_df['val_accuracy'], label=f'Client {client}', alpha=0.6, color=palette[client], linewidth=2.0)\n","\n","            if len(lines) < final_epoch_df['client_number'].nunique():\n","                lines.append(line)\n","                labels.append(f'Client {client}')\n","\n","    axes[0].set_title(f'Training Accuracy (Epoch {final_epoch})', fontsize=12, fontweight='bold')\n","    axes[0].set_xlim(0, 100)  # Ensure x-axis covers exactly 100 steps\n","\n","    axes[1].set_title(f'Validation Accuracy (Epoch {final_epoch})', fontsize=12, fontweight='bold')\n","\n","\n","    for ax in axes:\n","        ax.set_xlabel('Steps', fontsize=10, fontweight='bold')\n","        ax.grid(True)\n","        ax.tick_params(axis='both', which='major', labelsize=10)\n","\n","    # Add a single legend for the entire figure\n","    fig.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncol=len(labels), fontsize=10, frameon=True)\n","\n","    plt.tight_layout(rect=[0.05, 0.05, 1, 0.95])\n","    plt.subplots_adjust(hspace=0.2, top=0.85)  # Add some space between the rows and reduce space between the legend and plot\n","\n","    # Save the figure in high DPI PNG and PDF\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    fig.savefig(os.path.join(output_dir, 'final_epoch_accuracy_plot.png'), dpi=300, format='png')\n","    fig.savefig(os.path.join(output_dir, 'final_epoch_accuracy_plot.pdf'), dpi=300, format='pdf')\n","\n","    plt.show()\n","\n","# Directory where CSV logs are saved\n","log_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Total'\n","\n","# Output directory for saving plots\n","output_dir = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Frequency_domain/Total/plots'\n","\n","# Number of clients and local epochs\n","num_clients = 3\n","local_epochs = 5\n","\n","# Read logs and generate the dataframe\n","all_metrics_df = read_logs(log_dir, num_clients, local_epochs)\n","\n","# Plot the accuracy for the final epoch\n","plot_final_epoch_accuracy(all_metrics_df, output_dir)\n"]},{"cell_type":"markdown","metadata":{"id":"QUuWzfMHSNmi"},"source":["# CNN"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":831,"status":"ok","timestamp":1717404319442,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"8xrx_fxBSWGd","outputId":"36f8aadb-f993-4e7a-ad87-ee45ae824973"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    # model.add(Dropout(0.5))\n","    # model.add(LSTM(256, return_sequences=True))\n","    # model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time+Frequency/Total/CNN/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time+Frequency/Total/CNN/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1TaNdIbSfkq","outputId":"6cd90634-a1e3-4aad-cccf-6b642c824253","collapsed":true,"executionInfo":{"status":"ok","timestamp":1717405466283,"user_tz":-360,"elapsed":1146851,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 37, 29), Test shape: (1194, 37, 29)\n","Train shape: (4418, 37, 29), Test shape: (1416, 37, 29)\n","Train shape: (4838, 37, 29), Test shape: (996, 37, 29)\n","Train shape: (4640, 37, 29), Test shape: (1194, 37, 29)\n","Train shape: (4418, 37, 29), Test shape: (1416, 37, 29)\n","Train shape: (4838, 37, 29), Test shape: (996, 37, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 4s 32ms/step - loss: 1.9174 - accuracy: 0.6802 - val_loss: 1.9500 - val_accuracy: 0.7371\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 1s 23ms/step - loss: 1.8359 - accuracy: 0.7325 - val_loss: 1.9311 - val_accuracy: 0.7543\n","Epoch 3/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.7792 - accuracy: 0.7489 - val_loss: 1.9118 - val_accuracy: 0.7565\n","Epoch 4/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.7427 - accuracy: 0.7532 - val_loss: 1.8921 - val_accuracy: 0.7597\n","Epoch 5/100\n","29/29 [==============================] - 1s 37ms/step - loss: 1.7164 - accuracy: 0.7562 - val_loss: 1.8736 - val_accuracy: 0.7672\n","Epoch 6/100\n","29/29 [==============================] - 1s 31ms/step - loss: 1.6935 - accuracy: 0.7667 - val_loss: 1.8547 - val_accuracy: 0.7694\n","Epoch 7/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.6708 - accuracy: 0.7742 - val_loss: 1.8352 - val_accuracy: 0.7748\n","Epoch 8/100\n","29/29 [==============================] - 1s 32ms/step - loss: 1.6522 - accuracy: 0.7791 - val_loss: 1.8157 - val_accuracy: 0.7834\n","Epoch 9/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.6335 - accuracy: 0.7810 - val_loss: 1.7945 - val_accuracy: 0.7780\n","Epoch 10/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.6145 - accuracy: 0.7866 - val_loss: 1.7747 - val_accuracy: 0.7823\n","Epoch 11/100\n","29/29 [==============================] - 1s 47ms/step - loss: 1.5978 - accuracy: 0.7874 - val_loss: 1.7509 - val_accuracy: 0.7866\n","Epoch 12/100\n","29/29 [==============================] - 1s 49ms/step - loss: 1.5818 - accuracy: 0.7947 - val_loss: 1.7279 - val_accuracy: 0.7909\n","Epoch 13/100\n","29/29 [==============================] - 1s 51ms/step - loss: 1.5684 - accuracy: 0.7947 - val_loss: 1.7035 - val_accuracy: 0.7920\n","Epoch 14/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.5480 - accuracy: 0.7977 - val_loss: 1.6772 - val_accuracy: 0.7866\n","Epoch 15/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.5316 - accuracy: 0.7993 - val_loss: 1.6516 - val_accuracy: 0.7942\n","Epoch 16/100\n","29/29 [==============================] - 1s 32ms/step - loss: 1.5183 - accuracy: 0.8028 - val_loss: 1.6295 - val_accuracy: 0.8006\n","Epoch 17/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5029 - accuracy: 0.8033 - val_loss: 1.5987 - val_accuracy: 0.7920\n","Epoch 18/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.4890 - accuracy: 0.8101 - val_loss: 1.5738 - val_accuracy: 0.7985\n","Epoch 19/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.4720 - accuracy: 0.8109 - val_loss: 1.5478 - val_accuracy: 0.8017\n","Epoch 20/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.4574 - accuracy: 0.8125 - val_loss: 1.5215 - val_accuracy: 0.8017\n","Epoch 21/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.4410 - accuracy: 0.8211 - val_loss: 1.4995 - val_accuracy: 0.8050\n","Epoch 22/100\n","29/29 [==============================] - 1s 31ms/step - loss: 1.4274 - accuracy: 0.8214 - val_loss: 1.4751 - val_accuracy: 0.8071\n","Epoch 23/100\n","29/29 [==============================] - 1s 33ms/step - loss: 1.4129 - accuracy: 0.8211 - val_loss: 1.4540 - val_accuracy: 0.8093\n","Epoch 24/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3999 - accuracy: 0.8281 - val_loss: 1.4389 - val_accuracy: 0.8028\n","Epoch 25/100\n","29/29 [==============================] - 1s 39ms/step - loss: 1.3864 - accuracy: 0.8297 - val_loss: 1.4211 - val_accuracy: 0.8125\n","Epoch 26/100\n","29/29 [==============================] - 1s 34ms/step - loss: 1.3714 - accuracy: 0.8365 - val_loss: 1.4053 - val_accuracy: 0.8136\n","Epoch 27/100\n","29/29 [==============================] - 1s 51ms/step - loss: 1.3570 - accuracy: 0.8389 - val_loss: 1.3945 - val_accuracy: 0.8157\n","Epoch 28/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.3434 - accuracy: 0.8400 - val_loss: 1.3763 - val_accuracy: 0.8125\n","Epoch 29/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.3341 - accuracy: 0.8362 - val_loss: 1.3696 - val_accuracy: 0.8039\n","Epoch 30/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.3217 - accuracy: 0.8400 - val_loss: 1.3553 - val_accuracy: 0.8093\n","Epoch 31/100\n","29/29 [==============================] - 2s 54ms/step - loss: 1.3028 - accuracy: 0.8456 - val_loss: 1.3472 - val_accuracy: 0.8168\n","Epoch 32/100\n","29/29 [==============================] - 1s 39ms/step - loss: 1.2915 - accuracy: 0.8481 - val_loss: 1.3308 - val_accuracy: 0.8211\n","Epoch 33/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.2832 - accuracy: 0.8489 - val_loss: 1.3280 - val_accuracy: 0.8071\n","Epoch 34/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.2698 - accuracy: 0.8494 - val_loss: 1.3124 - val_accuracy: 0.8157\n","Epoch 35/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.2542 - accuracy: 0.8521 - val_loss: 1.3177 - val_accuracy: 0.8147\n","Epoch 36/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2429 - accuracy: 0.8510 - val_loss: 1.3110 - val_accuracy: 0.8179\n","Epoch 37/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.2363 - accuracy: 0.8524 - val_loss: 1.2887 - val_accuracy: 0.8330\n","Epoch 38/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2177 - accuracy: 0.8570 - val_loss: 1.2772 - val_accuracy: 0.8330\n","Epoch 39/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.2071 - accuracy: 0.8599 - val_loss: 1.2670 - val_accuracy: 0.8341\n","Epoch 40/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.1943 - accuracy: 0.8621 - val_loss: 1.2576 - val_accuracy: 0.8287\n","Epoch 41/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.1827 - accuracy: 0.8653 - val_loss: 1.2518 - val_accuracy: 0.8373\n","Epoch 42/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.1726 - accuracy: 0.8653 - val_loss: 1.2454 - val_accuracy: 0.8373\n","Epoch 43/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1625 - accuracy: 0.8653 - val_loss: 1.2314 - val_accuracy: 0.8351\n","Epoch 44/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.1508 - accuracy: 0.8715 - val_loss: 1.2255 - val_accuracy: 0.8222\n","Epoch 45/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.1391 - accuracy: 0.8726 - val_loss: 1.2155 - val_accuracy: 0.8384\n","Epoch 46/100\n","29/29 [==============================] - 1s 40ms/step - loss: 1.1285 - accuracy: 0.8761 - val_loss: 1.2111 - val_accuracy: 0.8416\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1170 - accuracy: 0.8785 - val_loss: 1.2013 - val_accuracy: 0.8416\n","Epoch 48/100\n","29/29 [==============================] - 1s 29ms/step - loss: 1.1047 - accuracy: 0.8823 - val_loss: 1.1935 - val_accuracy: 0.8362\n","Epoch 49/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.0981 - accuracy: 0.8847 - val_loss: 1.1854 - val_accuracy: 0.8341\n","Epoch 50/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.0899 - accuracy: 0.8839 - val_loss: 1.1849 - val_accuracy: 0.8394\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0757 - accuracy: 0.8855 - val_loss: 1.1774 - val_accuracy: 0.8287\n","Epoch 52/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.0649 - accuracy: 0.8901 - val_loss: 1.1803 - val_accuracy: 0.8427\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0574 - accuracy: 0.8887 - val_loss: 1.1697 - val_accuracy: 0.8222\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0513 - accuracy: 0.8869 - val_loss: 1.1529 - val_accuracy: 0.8351\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0354 - accuracy: 0.8960 - val_loss: 1.1508 - val_accuracy: 0.8265\n","Epoch 56/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.0247 - accuracy: 0.8974 - val_loss: 1.1441 - val_accuracy: 0.8448\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0173 - accuracy: 0.8971 - val_loss: 1.1474 - val_accuracy: 0.8438\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0051 - accuracy: 0.9006 - val_loss: 1.1296 - val_accuracy: 0.8405\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9958 - accuracy: 0.9027 - val_loss: 1.1263 - val_accuracy: 0.8427\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9873 - accuracy: 0.9049 - val_loss: 1.1202 - val_accuracy: 0.8384\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9822 - accuracy: 0.9060 - val_loss: 1.1130 - val_accuracy: 0.8373\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9801 - accuracy: 0.9046 - val_loss: 1.1260 - val_accuracy: 0.8416\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9728 - accuracy: 0.9036 - val_loss: 1.1033 - val_accuracy: 0.8405\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9536 - accuracy: 0.9095 - val_loss: 1.0990 - val_accuracy: 0.8394\n","Epoch 65/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.9479 - accuracy: 0.9106 - val_loss: 1.1062 - val_accuracy: 0.8481\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9373 - accuracy: 0.9184 - val_loss: 1.0950 - val_accuracy: 0.8319\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9302 - accuracy: 0.9176 - val_loss: 1.1033 - val_accuracy: 0.8448\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9231 - accuracy: 0.9162 - val_loss: 1.0852 - val_accuracy: 0.8448\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9072 - accuracy: 0.9232 - val_loss: 1.0755 - val_accuracy: 0.8384\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9026 - accuracy: 0.9251 - val_loss: 1.0816 - val_accuracy: 0.8373\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8998 - accuracy: 0.9165 - val_loss: 1.0682 - val_accuracy: 0.8373\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8869 - accuracy: 0.9305 - val_loss: 1.0621 - val_accuracy: 0.8416\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8796 - accuracy: 0.9273 - val_loss: 1.0588 - val_accuracy: 0.8384\n","Epoch 74/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8676 - accuracy: 0.9316 - val_loss: 1.0573 - val_accuracy: 0.8405\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8624 - accuracy: 0.9329 - val_loss: 1.0504 - val_accuracy: 0.8405\n","Epoch 76/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8523 - accuracy: 0.9359 - val_loss: 1.0480 - val_accuracy: 0.8427\n","Epoch 77/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8466 - accuracy: 0.9375 - val_loss: 1.0465 - val_accuracy: 0.8438\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8397 - accuracy: 0.9397 - val_loss: 1.0429 - val_accuracy: 0.8416\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8361 - accuracy: 0.9332 - val_loss: 1.0506 - val_accuracy: 0.8470\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8368 - accuracy: 0.9335 - val_loss: 1.0387 - val_accuracy: 0.8427\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8221 - accuracy: 0.9394 - val_loss: 1.0323 - val_accuracy: 0.8448\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8110 - accuracy: 0.9445 - val_loss: 1.0292 - val_accuracy: 0.8416\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8018 - accuracy: 0.9494 - val_loss: 1.0280 - val_accuracy: 0.8394\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7993 - accuracy: 0.9442 - val_loss: 1.0265 - val_accuracy: 0.8427\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7918 - accuracy: 0.9453 - val_loss: 1.0208 - val_accuracy: 0.8427\n","Epoch 86/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7820 - accuracy: 0.9515 - val_loss: 1.0193 - val_accuracy: 0.8416\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7762 - accuracy: 0.9529 - val_loss: 1.0190 - val_accuracy: 0.8416\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7689 - accuracy: 0.9537 - val_loss: 1.0244 - val_accuracy: 0.8438\n","Epoch 89/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7630 - accuracy: 0.9561 - val_loss: 1.0168 - val_accuracy: 0.8448\n","Epoch 90/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7589 - accuracy: 0.9564 - val_loss: 1.0094 - val_accuracy: 0.8384\n","Epoch 91/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7504 - accuracy: 0.9585 - val_loss: 1.0164 - val_accuracy: 0.8405\n","Epoch 92/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7468 - accuracy: 0.9537 - val_loss: 1.0084 - val_accuracy: 0.8459\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7386 - accuracy: 0.9599 - val_loss: 1.0042 - val_accuracy: 0.8438\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7296 - accuracy: 0.9628 - val_loss: 1.0013 - val_accuracy: 0.8394\n","Epoch 95/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7267 - accuracy: 0.9628 - val_loss: 0.9971 - val_accuracy: 0.8416\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7277 - accuracy: 0.9574 - val_loss: 1.0454 - val_accuracy: 0.8200\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7210 - accuracy: 0.9572 - val_loss: 1.0049 - val_accuracy: 0.8448\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7068 - accuracy: 0.9677 - val_loss: 0.9966 - val_accuracy: 0.8448\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6986 - accuracy: 0.9709 - val_loss: 0.9920 - val_accuracy: 0.8394\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6978 - accuracy: 0.9671 - val_loss: 0.9941 - val_accuracy: 0.8481\n","{'loss': [1.9174201488494873, 1.8359001874923706, 1.7791619300842285, 1.7426711320877075, 1.7164279222488403, 1.6934765577316284, 1.6708199977874756, 1.652169108390808, 1.6334664821624756, 1.6145133972167969, 1.5977857112884521, 1.5818263292312622, 1.5683660507202148, 1.5480018854141235, 1.5315768718719482, 1.5183395147323608, 1.5029006004333496, 1.4890027046203613, 1.4719938039779663, 1.4574239253997803, 1.4409995079040527, 1.427352786064148, 1.4129430055618286, 1.3998912572860718, 1.3864107131958008, 1.3713674545288086, 1.3569769859313965, 1.3434321880340576, 1.3340973854064941, 1.321670413017273, 1.3028481006622314, 1.2914787530899048, 1.2832318544387817, 1.269818902015686, 1.2541706562042236, 1.2428590059280396, 1.2363340854644775, 1.2176640033721924, 1.2070841789245605, 1.194311499595642, 1.1827208995819092, 1.172590970993042, 1.1624728441238403, 1.1507959365844727, 1.1391171216964722, 1.1285068988800049, 1.1170201301574707, 1.1047074794769287, 1.0980730056762695, 1.0898668766021729, 1.0757023096084595, 1.064918041229248, 1.0573804378509521, 1.0512843132019043, 1.0353937149047852, 1.0246502161026, 1.0172910690307617, 1.005147933959961, 0.9958293437957764, 0.9873109459877014, 0.9822131395339966, 0.9800533652305603, 0.9727643132209778, 0.9535847306251526, 0.9478880167007446, 0.9373050928115845, 0.930185854434967, 0.9231008887290955, 0.90721195936203, 0.9025885462760925, 0.8997610807418823, 0.8868632316589355, 0.8795850276947021, 0.8676213622093201, 0.8624289035797119, 0.852342963218689, 0.8465559482574463, 0.8396722674369812, 0.8361441493034363, 0.8367648124694824, 0.8220940828323364, 0.8109532594680786, 0.8017913103103638, 0.799329400062561, 0.7918211817741394, 0.7820265293121338, 0.7761658430099487, 0.7689107656478882, 0.7629773616790771, 0.7589119076728821, 0.750410258769989, 0.7468149065971375, 0.738589882850647, 0.7295817136764526, 0.726654052734375, 0.7276983857154846, 0.7210400104522705, 0.7067858576774597, 0.6986189484596252, 0.6978055238723755], 'accuracy': [0.6802262663841248, 0.7324892282485962, 0.7489224076271057, 0.7532327771186829, 0.756196141242981, 0.7667025923728943, 0.7742456793785095, 0.7790948152542114, 0.7809805870056152, 0.7866379022598267, 0.787446141242981, 0.7947198152542114, 0.7947198152542114, 0.7976831793785095, 0.7992995977401733, 0.8028017282485962, 0.803340494632721, 0.8100754022598267, 0.810883641242981, 0.8125, 0.8211206793785095, 0.8213900923728943, 0.8211206793785095, 0.828125, 0.829741358757019, 0.8364762663841248, 0.8389008641242981, 0.8399784564971924, 0.8362069129943848, 0.8399784564971924, 0.8456357717514038, 0.8480603694915771, 0.8488685488700867, 0.8494073152542114, 0.8521012663841248, 0.8510237336158752, 0.8523706793785095, 0.8569504022598267, 0.8599137663841248, 0.8620689511299133, 0.8653017282485962, 0.8653017282485962, 0.8653017282485962, 0.8714978694915771, 0.8725754022598267, 0.8760775923728943, 0.8785021305084229, 0.8822737336158752, 0.8846982717514038, 0.8838900923728943, 0.8855064511299133, 0.8900862336158752, 0.8887392282485962, 0.8868534564971924, 0.8960129022598267, 0.8973599076271057, 0.897090494632721, 0.9005926847457886, 0.9027478694915771, 0.904902994632721, 0.9059805870056152, 0.904633641242981, 0.9035560488700867, 0.9094827771186829, 0.9105603694915771, 0.9183728694915771, 0.9175646305084229, 0.9162176847457886, 0.923222005367279, 0.9251077771186829, 0.9164870977401733, 0.9304956793785095, 0.9272629022598267, 0.9315732717514038, 0.9329202771186829, 0.935883641242981, 0.9375, 0.9396551847457886, 0.9331896305084229, 0.9334590435028076, 0.9393857717514038, 0.9445043206214905, 0.9493534564971924, 0.9442349076271057, 0.9453125, 0.951508641242981, 0.9528555870056152, 0.9536637663841248, 0.9560883641242981, 0.9563577771186829, 0.9585129022598267, 0.9536637663841248, 0.9598599076271057, 0.9628232717514038, 0.9628232717514038, 0.9574353694915771, 0.9571659564971924, 0.9676724076271057, 0.9709051847457886, 0.967133641242981], 'val_loss': [1.9499856233596802, 1.9311416149139404, 1.9118165969848633, 1.8921282291412354, 1.8735685348510742, 1.8547476530075073, 1.8351949453353882, 1.8157216310501099, 1.7944785356521606, 1.7746776342391968, 1.750893473625183, 1.7279223203659058, 1.7035030126571655, 1.6771799325942993, 1.6515724658966064, 1.6295392513275146, 1.598671793937683, 1.5738343000411987, 1.5478384494781494, 1.5214526653289795, 1.4994784593582153, 1.4751105308532715, 1.4539517164230347, 1.4388816356658936, 1.4210712909698486, 1.405317783355713, 1.3945200443267822, 1.37630033493042, 1.3695579767227173, 1.3552656173706055, 1.3471925258636475, 1.3308297395706177, 1.3279858827590942, 1.3124016523361206, 1.317703366279602, 1.3110222816467285, 1.2887011766433716, 1.2772213220596313, 1.2670023441314697, 1.2575690746307373, 1.2517520189285278, 1.2453889846801758, 1.2314032316207886, 1.2255398035049438, 1.2154794931411743, 1.2111141681671143, 1.201312780380249, 1.1934924125671387, 1.1854488849639893, 1.1849439144134521, 1.1773897409439087, 1.1803208589553833, 1.169700264930725, 1.1528642177581787, 1.1507863998413086, 1.1441208124160767, 1.147445559501648, 1.129551887512207, 1.1263397932052612, 1.1202154159545898, 1.1130355596542358, 1.126013159751892, 1.1032716035842896, 1.0989700555801392, 1.1062169075012207, 1.095020055770874, 1.103333592414856, 1.0852267742156982, 1.0754932165145874, 1.0816235542297363, 1.068158745765686, 1.0620532035827637, 1.0587904453277588, 1.0573099851608276, 1.0504286289215088, 1.0480189323425293, 1.046534538269043, 1.0429363250732422, 1.0505934953689575, 1.0387314558029175, 1.0322988033294678, 1.0291974544525146, 1.0280485153198242, 1.0265415906906128, 1.0207877159118652, 1.0193289518356323, 1.0190273523330688, 1.024440050125122, 1.0167715549468994, 1.0094263553619385, 1.0164297819137573, 1.0084480047225952, 1.004160761833191, 1.0012682676315308, 0.9970580339431763, 1.0453864336013794, 1.0049185752868652, 0.9965876340866089, 0.9920143485069275, 0.994101881980896], 'val_accuracy': [0.7370689511299133, 0.7543103694915771, 0.756465494632721, 0.7596982717514038, 0.767241358757019, 0.7693965435028076, 0.774784505367279, 0.7834051847457886, 0.7780172228813171, 0.7823275923728943, 0.7866379022598267, 0.7909482717514038, 0.7920258641242981, 0.7866379022598267, 0.7941810488700867, 0.8006465435028076, 0.7920258641242981, 0.798491358757019, 0.8017241358757019, 0.8017241358757019, 0.8049569129943848, 0.8071120977401733, 0.8092672228813171, 0.8028017282485962, 0.8125, 0.8135775923728943, 0.8157327771186829, 0.8125, 0.8038793206214905, 0.8092672228813171, 0.8168103694915771, 0.8211206793785095, 0.8071120977401733, 0.8157327771186829, 0.8146551847457886, 0.8178879022598267, 0.8329741358757019, 0.8329741358757019, 0.8340517282485962, 0.8286637663841248, 0.837284505367279, 0.837284505367279, 0.8351293206214905, 0.8221982717514038, 0.8383620977401733, 0.8415948152542114, 0.8415948152542114, 0.8362069129943848, 0.8340517282485962, 0.8394396305084229, 0.8286637663841248, 0.8426724076271057, 0.8221982717514038, 0.8351293206214905, 0.826508641242981, 0.8448275923728943, 0.84375, 0.8405172228813171, 0.8426724076271057, 0.8383620977401733, 0.837284505367279, 0.8415948152542114, 0.8405172228813171, 0.8394396305084229, 0.8480603694915771, 0.8318965435028076, 0.8448275923728943, 0.8448275923728943, 0.8383620977401733, 0.837284505367279, 0.837284505367279, 0.8415948152542114, 0.8383620977401733, 0.8405172228813171, 0.8405172228813171, 0.8426724076271057, 0.84375, 0.8415948152542114, 0.8469827771186829, 0.8426724076271057, 0.8448275923728943, 0.8415948152542114, 0.8394396305084229, 0.8426724076271057, 0.8426724076271057, 0.8415948152542114, 0.8415948152542114, 0.84375, 0.8448275923728943, 0.8383620977401733, 0.8405172228813171, 0.8459051847457886, 0.84375, 0.8394396305084229, 0.8415948152542114, 0.8200430870056152, 0.8448275923728943, 0.8448275923728943, 0.8394396305084229, 0.8480603694915771]}\n","38/38 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 1.9316 - accuracy: 0.6628"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 5s 36ms/step - loss: 1.9275 - accuracy: 0.6684 - val_loss: 1.9515 - val_accuracy: 0.6844\n","Epoch 2/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.8599 - accuracy: 0.7216 - val_loss: 1.9346 - val_accuracy: 0.7059\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.8096 - accuracy: 0.7309 - val_loss: 1.9170 - val_accuracy: 0.7104\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.7746 - accuracy: 0.7349 - val_loss: 1.8994 - val_accuracy: 0.7127\n","Epoch 5/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.7496 - accuracy: 0.7397 - val_loss: 1.8822 - val_accuracy: 0.7195\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.7288 - accuracy: 0.7411 - val_loss: 1.8651 - val_accuracy: 0.7285\n","Epoch 7/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.7054 - accuracy: 0.7524 - val_loss: 1.8481 - val_accuracy: 0.7285\n","Epoch 8/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.6862 - accuracy: 0.7527 - val_loss: 1.8300 - val_accuracy: 0.7353\n","Epoch 9/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.6682 - accuracy: 0.7530 - val_loss: 1.8117 - val_accuracy: 0.7342\n","Epoch 10/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.6502 - accuracy: 0.7598 - val_loss: 1.7929 - val_accuracy: 0.7432\n","Epoch 11/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.6308 - accuracy: 0.7612 - val_loss: 1.7732 - val_accuracy: 0.7443\n","Epoch 12/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6135 - accuracy: 0.7674 - val_loss: 1.7533 - val_accuracy: 0.7432\n","Epoch 13/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.5970 - accuracy: 0.7736 - val_loss: 1.7316 - val_accuracy: 0.7579\n","Epoch 14/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.5797 - accuracy: 0.7762 - val_loss: 1.7099 - val_accuracy: 0.7523\n","Epoch 15/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.5643 - accuracy: 0.7801 - val_loss: 1.6867 - val_accuracy: 0.7658\n","Epoch 16/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.5503 - accuracy: 0.7827 - val_loss: 1.6641 - val_accuracy: 0.7670\n","Epoch 17/100\n","28/28 [==============================] - 1s 30ms/step - loss: 1.5316 - accuracy: 0.7898 - val_loss: 1.6381 - val_accuracy: 0.7704\n","Epoch 18/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.5159 - accuracy: 0.7923 - val_loss: 1.6157 - val_accuracy: 0.7760\n","Epoch 19/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4996 - accuracy: 0.7988 - val_loss: 1.5902 - val_accuracy: 0.7760\n","Epoch 20/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4867 - accuracy: 0.7968 - val_loss: 1.5675 - val_accuracy: 0.7760\n","Epoch 21/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.4709 - accuracy: 0.8070 - val_loss: 1.5466 - val_accuracy: 0.7862\n","Epoch 22/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4545 - accuracy: 0.8110 - val_loss: 1.5268 - val_accuracy: 0.7862\n","Epoch 23/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4428 - accuracy: 0.8110 - val_loss: 1.5053 - val_accuracy: 0.7862\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.4266 - accuracy: 0.8164 - val_loss: 1.4852 - val_accuracy: 0.7783\n","Epoch 25/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.4126 - accuracy: 0.8158 - val_loss: 1.4708 - val_accuracy: 0.7930\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3991 - accuracy: 0.8240 - val_loss: 1.4557 - val_accuracy: 0.7930\n","Epoch 27/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3845 - accuracy: 0.8271 - val_loss: 1.4413 - val_accuracy: 0.7771\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3745 - accuracy: 0.8282 - val_loss: 1.4327 - val_accuracy: 0.7726\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3611 - accuracy: 0.8274 - val_loss: 1.4150 - val_accuracy: 0.7907\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3497 - accuracy: 0.8316 - val_loss: 1.4043 - val_accuracy: 0.7885\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3370 - accuracy: 0.8314 - val_loss: 1.3938 - val_accuracy: 0.7919\n","Epoch 32/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.3272 - accuracy: 0.8308 - val_loss: 1.3891 - val_accuracy: 0.7964\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3130 - accuracy: 0.8390 - val_loss: 1.3943 - val_accuracy: 0.7885\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2991 - accuracy: 0.8367 - val_loss: 1.3911 - val_accuracy: 0.7941\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2916 - accuracy: 0.8398 - val_loss: 1.3571 - val_accuracy: 0.7873\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2741 - accuracy: 0.8447 - val_loss: 1.3590 - val_accuracy: 0.7907\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2621 - accuracy: 0.8466 - val_loss: 1.3427 - val_accuracy: 0.7851\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2485 - accuracy: 0.8509 - val_loss: 1.3344 - val_accuracy: 0.7873\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2401 - accuracy: 0.8540 - val_loss: 1.3276 - val_accuracy: 0.7862\n","Epoch 40/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.2320 - accuracy: 0.8495 - val_loss: 1.3138 - val_accuracy: 0.7998\n","Epoch 41/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.2231 - accuracy: 0.8517 - val_loss: 1.3062 - val_accuracy: 0.8032\n","Epoch 42/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.2045 - accuracy: 0.8605 - val_loss: 1.3029 - val_accuracy: 0.8054\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1960 - accuracy: 0.8599 - val_loss: 1.2904 - val_accuracy: 0.7975\n","Epoch 44/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1835 - accuracy: 0.8647 - val_loss: 1.2840 - val_accuracy: 0.7986\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1728 - accuracy: 0.8653 - val_loss: 1.2749 - val_accuracy: 0.8043\n","Epoch 46/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.1640 - accuracy: 0.8656 - val_loss: 1.2859 - val_accuracy: 0.8066\n","Epoch 47/100\n","28/28 [==============================] - 1s 17ms/step - loss: 1.1603 - accuracy: 0.8673 - val_loss: 1.2627 - val_accuracy: 0.8054\n","Epoch 48/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.1448 - accuracy: 0.8721 - val_loss: 1.2531 - val_accuracy: 0.8088\n","Epoch 49/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1337 - accuracy: 0.8732 - val_loss: 1.2489 - val_accuracy: 0.7986\n","Epoch 50/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.1269 - accuracy: 0.8735 - val_loss: 1.2387 - val_accuracy: 0.8111\n","Epoch 51/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1132 - accuracy: 0.8749 - val_loss: 1.2387 - val_accuracy: 0.8066\n","Epoch 52/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1020 - accuracy: 0.8755 - val_loss: 1.2270 - val_accuracy: 0.7975\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0947 - accuracy: 0.8809 - val_loss: 1.2297 - val_accuracy: 0.8077\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0844 - accuracy: 0.8857 - val_loss: 1.2152 - val_accuracy: 0.8077\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0771 - accuracy: 0.8797 - val_loss: 1.2087 - val_accuracy: 0.7998\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0687 - accuracy: 0.8817 - val_loss: 1.1997 - val_accuracy: 0.8100\n","Epoch 57/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.0556 - accuracy: 0.8865 - val_loss: 1.1961 - val_accuracy: 0.8122\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0500 - accuracy: 0.8851 - val_loss: 1.1876 - val_accuracy: 0.8077\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0397 - accuracy: 0.8919 - val_loss: 1.1810 - val_accuracy: 0.8100\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0278 - accuracy: 0.8939 - val_loss: 1.1767 - val_accuracy: 0.8100\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0185 - accuracy: 0.8956 - val_loss: 1.1739 - val_accuracy: 0.8122\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0103 - accuracy: 0.8964 - val_loss: 1.1813 - val_accuracy: 0.8066\n","Epoch 63/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.0058 - accuracy: 0.8928 - val_loss: 1.1721 - val_accuracy: 0.8213\n","Epoch 64/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9978 - accuracy: 0.8998 - val_loss: 1.1547 - val_accuracy: 0.8145\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9830 - accuracy: 0.9052 - val_loss: 1.1520 - val_accuracy: 0.8179\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9738 - accuracy: 0.9092 - val_loss: 1.1437 - val_accuracy: 0.8100\n","Epoch 67/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9656 - accuracy: 0.9069 - val_loss: 1.1442 - val_accuracy: 0.8224\n","Epoch 68/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.9566 - accuracy: 0.9117 - val_loss: 1.1362 - val_accuracy: 0.8145\n","Epoch 69/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9491 - accuracy: 0.9131 - val_loss: 1.1522 - val_accuracy: 0.8020\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9444 - accuracy: 0.9160 - val_loss: 1.1333 - val_accuracy: 0.8133\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9398 - accuracy: 0.9100 - val_loss: 1.1245 - val_accuracy: 0.8077\n","Epoch 72/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9239 - accuracy: 0.9199 - val_loss: 1.1193 - val_accuracy: 0.8235\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9156 - accuracy: 0.9174 - val_loss: 1.1123 - val_accuracy: 0.8156\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9136 - accuracy: 0.9157 - val_loss: 1.1069 - val_accuracy: 0.8179\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9015 - accuracy: 0.9230 - val_loss: 1.1127 - val_accuracy: 0.8156\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8932 - accuracy: 0.9230 - val_loss: 1.1012 - val_accuracy: 0.8145\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8856 - accuracy: 0.9281 - val_loss: 1.0973 - val_accuracy: 0.8179\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8838 - accuracy: 0.9256 - val_loss: 1.1053 - val_accuracy: 0.8190\n","Epoch 79/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.8703 - accuracy: 0.9332 - val_loss: 1.0889 - val_accuracy: 0.8247\n","Epoch 80/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8640 - accuracy: 0.9327 - val_loss: 1.0872 - val_accuracy: 0.8224\n","Epoch 81/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.8542 - accuracy: 0.9344 - val_loss: 1.0847 - val_accuracy: 0.8258\n","Epoch 82/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8496 - accuracy: 0.9321 - val_loss: 1.0768 - val_accuracy: 0.8167\n","Epoch 83/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8390 - accuracy: 0.9414 - val_loss: 1.0761 - val_accuracy: 0.8213\n","Epoch 84/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8323 - accuracy: 0.9411 - val_loss: 1.0717 - val_accuracy: 0.8247\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8313 - accuracy: 0.9349 - val_loss: 1.0789 - val_accuracy: 0.8179\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8210 - accuracy: 0.9423 - val_loss: 1.0654 - val_accuracy: 0.8224\n","Epoch 87/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.8099 - accuracy: 0.9479 - val_loss: 1.0603 - val_accuracy: 0.8156\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8024 - accuracy: 0.9522 - val_loss: 1.0614 - val_accuracy: 0.8213\n","Epoch 89/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7967 - accuracy: 0.9525 - val_loss: 1.0551 - val_accuracy: 0.8179\n","Epoch 90/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7906 - accuracy: 0.9485 - val_loss: 1.0562 - val_accuracy: 0.8201\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7845 - accuracy: 0.9553 - val_loss: 1.0521 - val_accuracy: 0.8213\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7817 - accuracy: 0.9516 - val_loss: 1.0480 - val_accuracy: 0.8235\n","Epoch 93/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7721 - accuracy: 0.9564 - val_loss: 1.0489 - val_accuracy: 0.8269\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7688 - accuracy: 0.9536 - val_loss: 1.0596 - val_accuracy: 0.8201\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7603 - accuracy: 0.9544 - val_loss: 1.0385 - val_accuracy: 0.8190\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7539 - accuracy: 0.9584 - val_loss: 1.0461 - val_accuracy: 0.8179\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7443 - accuracy: 0.9629 - val_loss: 1.0403 - val_accuracy: 0.8235\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7417 - accuracy: 0.9598 - val_loss: 1.0358 - val_accuracy: 0.8213\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7340 - accuracy: 0.9646 - val_loss: 1.0351 - val_accuracy: 0.8224\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7273 - accuracy: 0.9660 - val_loss: 1.0301 - val_accuracy: 0.8224\n","{'loss': [1.9274829626083374, 1.8599050045013428, 1.8095800876617432, 1.7746456861495972, 1.7495923042297363, 1.7287721633911133, 1.7054215669631958, 1.6861709356307983, 1.6682109832763672, 1.6502217054367065, 1.6308385133743286, 1.6135125160217285, 1.5969862937927246, 1.5797332525253296, 1.5642718076705933, 1.5502574443817139, 1.5315968990325928, 1.515939712524414, 1.4996497631072998, 1.4866571426391602, 1.4708889722824097, 1.4544569253921509, 1.4427521228790283, 1.4266254901885986, 1.4125627279281616, 1.3990997076034546, 1.3844859600067139, 1.3745206594467163, 1.3611228466033936, 1.3496592044830322, 1.3370444774627686, 1.327175259590149, 1.3130491971969604, 1.2990591526031494, 1.2916078567504883, 1.2740893363952637, 1.262093186378479, 1.2484536170959473, 1.2401106357574463, 1.231959581375122, 1.2230603694915771, 1.2045464515686035, 1.1959933042526245, 1.1835259199142456, 1.1728301048278809, 1.1640249490737915, 1.160270094871521, 1.1447967290878296, 1.1336816549301147, 1.126889705657959, 1.1132432222366333, 1.1019525527954102, 1.0946553945541382, 1.0843738317489624, 1.077127456665039, 1.0687377452850342, 1.055566668510437, 1.0499931573867798, 1.0397090911865234, 1.0278240442276, 1.0185250043869019, 1.0102605819702148, 1.0058162212371826, 0.9978141188621521, 0.9829996228218079, 0.9738028049468994, 0.9655544757843018, 0.9566429853439331, 0.9491072297096252, 0.9443874955177307, 0.9398049712181091, 0.9239089488983154, 0.9156150221824646, 0.9135880470275879, 0.9014882445335388, 0.8932101130485535, 0.8856433033943176, 0.8838069438934326, 0.8703466653823853, 0.863969087600708, 0.8542364835739136, 0.8496195077896118, 0.8390384912490845, 0.8323005437850952, 0.831291139125824, 0.8209927082061768, 0.8098950982093811, 0.8024006485939026, 0.7967474460601807, 0.7905619144439697, 0.7844846844673157, 0.7817105650901794, 0.7720679640769958, 0.7688390612602234, 0.7603068351745605, 0.75394606590271, 0.7443234920501709, 0.7416702508926392, 0.7340047955513, 0.7272650003433228], 'accuracy': [0.6683644652366638, 0.7215619683265686, 0.7308998107910156, 0.7348613739013672, 0.7396717667579651, 0.7410866022109985, 0.7524052262306213, 0.7526881694793701, 0.7529711127281189, 0.7597622871398926, 0.761177122592926, 0.7674023509025574, 0.7736276388168335, 0.7761743068695068, 0.7801358103752136, 0.7826825380325317, 0.7897566556930542, 0.7923033237457275, 0.7988115549087524, 0.7968307733535767, 0.8070175647735596, 0.8109790682792664, 0.8109790682792664, 0.8163554072380066, 0.8157894611358643, 0.8239954710006714, 0.8271080851554871, 0.8282399773597717, 0.8273910880088806, 0.8316355347633362, 0.8313525915145874, 0.8307866454124451, 0.8389926552772522, 0.8367289304733276, 0.8398415446281433, 0.8446519374847412, 0.846632719039917, 0.8508771657943726, 0.853989839553833, 0.8494623899459839, 0.8517261147499084, 0.8604980111122131, 0.8599320650100708, 0.8647425174713135, 0.865308403968811, 0.8655914068222046, 0.8672891855239868, 0.8720995783805847, 0.8732314705848694, 0.8735144138336182, 0.8749292492866516, 0.875495195388794, 0.8808715343475342, 0.8856819272041321, 0.8797396421432495, 0.8817204236984253, 0.8865308165550232, 0.8851160407066345, 0.8919072151184082, 0.8938879370689392, 0.8955857157707214, 0.8964346647262573, 0.8927561044692993, 0.8998302221298218, 0.905206561088562, 0.9091680645942688, 0.9069043397903442, 0.9117147922515869, 0.9131296277046204, 0.9159592390060425, 0.9100169539451599, 0.9199207425117493, 0.9173740744590759, 0.9156762957572937, 0.9230334162712097, 0.9230334162712097, 0.9281267523765564, 0.9255800843238831, 0.9332201480865479, 0.9326542019844055, 0.9343519806861877, 0.9320882558822632, 0.941426157951355, 0.9411431550979614, 0.9349179267883301, 0.9422750473022461, 0.9479343295097351, 0.9521788358688354, 0.9524617791175842, 0.9485002756118774, 0.9552914500236511, 0.9516128897666931, 0.9564233422279358, 0.9535936713218689, 0.95444256067276, 0.9584040641784668, 0.9629315137863159, 0.9598188996315002, 0.9646292924880981, 0.9660441279411316], 'val_loss': [1.9514689445495605, 1.934589147567749, 1.9169868230819702, 1.8994497060775757, 1.8821901082992554, 1.8651164770126343, 1.8481024503707886, 1.8299734592437744, 1.8117223978042603, 1.7928917407989502, 1.7731691598892212, 1.7532520294189453, 1.731622576713562, 1.709851622581482, 1.6866737604141235, 1.6640828847885132, 1.6380724906921387, 1.6157342195510864, 1.5901684761047363, 1.567513346672058, 1.546573281288147, 1.5267912149429321, 1.5053037405014038, 1.4852088689804077, 1.4707770347595215, 1.4556926488876343, 1.4412974119186401, 1.4326704740524292, 1.415023922920227, 1.4042786359786987, 1.3937855958938599, 1.38909113407135, 1.3943235874176025, 1.3911455869674683, 1.3570504188537598, 1.359013319015503, 1.3426778316497803, 1.3343709707260132, 1.3276158571243286, 1.3138097524642944, 1.3062156438827515, 1.3029025793075562, 1.29035222530365, 1.2839529514312744, 1.274868130683899, 1.2859218120574951, 1.2626557350158691, 1.2531113624572754, 1.248907208442688, 1.2387330532073975, 1.2386529445648193, 1.226988673210144, 1.229722261428833, 1.215217113494873, 1.2087091207504272, 1.199662685394287, 1.1961058378219604, 1.1875752210617065, 1.180966854095459, 1.1766865253448486, 1.1739287376403809, 1.1812841892242432, 1.172142744064331, 1.1547170877456665, 1.1519724130630493, 1.143748164176941, 1.144152045249939, 1.1362390518188477, 1.152234673500061, 1.1333041191101074, 1.124502182006836, 1.1192820072174072, 1.1122804880142212, 1.1069467067718506, 1.1127099990844727, 1.1012187004089355, 1.0972665548324585, 1.1053037643432617, 1.088921308517456, 1.0871789455413818, 1.0847489833831787, 1.0768076181411743, 1.0760657787322998, 1.0716800689697266, 1.078853726387024, 1.0654171705245972, 1.0602596998214722, 1.0613847970962524, 1.0550514459609985, 1.0562044382095337, 1.052085518836975, 1.0479801893234253, 1.048922061920166, 1.059638261795044, 1.0385125875473022, 1.0461008548736572, 1.0403122901916504, 1.0357834100723267, 1.035127878189087, 1.0301215648651123], 'val_accuracy': [0.6843891143798828, 0.7058823704719543, 0.7104072570800781, 0.7126696705818176, 0.7194570302963257, 0.7285068035125732, 0.7285068035125732, 0.7352941036224365, 0.7341628670692444, 0.7432126402854919, 0.7443438768386841, 0.7432126402854919, 0.7579185366630554, 0.7522624731063843, 0.7658371329307556, 0.766968309879303, 0.7703620195388794, 0.7760180830955505, 0.7760180830955505, 0.7760180830955505, 0.7861990928649902, 0.7861990928649902, 0.7861990928649902, 0.7782805562019348, 0.7929864525794983, 0.7929864525794983, 0.7771493196487427, 0.7726244330406189, 0.790723979473114, 0.7884615659713745, 0.7918552160263062, 0.7963801026344299, 0.7884615659713745, 0.7941176295280457, 0.7873303294181824, 0.790723979473114, 0.7850678563117981, 0.7873303294181824, 0.7861990928649902, 0.7997737526893616, 0.8031674027442932, 0.8054298758506775, 0.7975113391876221, 0.7986425161361694, 0.8042986392974854, 0.8065611124038696, 0.8054298758506775, 0.8088235259056091, 0.7986425161361694, 0.8110859990119934, 0.8065611124038696, 0.7975113391876221, 0.807692289352417, 0.807692289352417, 0.7997737526893616, 0.8099547624588013, 0.8122171759605408, 0.807692289352417, 0.8099547624588013, 0.8099547624588013, 0.8122171759605408, 0.8065611124038696, 0.8212669491767883, 0.814479649066925, 0.8178732991218567, 0.8099547624588013, 0.8223981857299805, 0.814479649066925, 0.8020362257957458, 0.8133484125137329, 0.807692289352417, 0.8235294222831726, 0.8156108856201172, 0.8178732991218567, 0.8156108856201172, 0.814479649066925, 0.8178732991218567, 0.8190045356750488, 0.8246606588363647, 0.8223981857299805, 0.8257918357849121, 0.8167420625686646, 0.8212669491767883, 0.8246606588363647, 0.8178732991218567, 0.8223981857299805, 0.8156108856201172, 0.8212669491767883, 0.8178732991218567, 0.820135772228241, 0.8212669491767883, 0.8235294222831726, 0.8269230723381042, 0.820135772228241, 0.8190045356750488, 0.8178732991218567, 0.8235294222831726, 0.8212669491767883, 0.8223981857299805, 0.8223981857299805]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 1.9242 - accuracy: 0.6563"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 5s 51ms/step - loss: 1.9242 - accuracy: 0.6563 - val_loss: 1.9499 - val_accuracy: 0.6952\n","Epoch 2/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.8464 - accuracy: 0.7204 - val_loss: 1.9310 - val_accuracy: 0.7242\n","Epoch 3/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.7918 - accuracy: 0.7341 - val_loss: 1.9113 - val_accuracy: 0.7479\n","Epoch 4/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.7555 - accuracy: 0.7403 - val_loss: 1.8919 - val_accuracy: 0.7500\n","Epoch 5/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.7281 - accuracy: 0.7465 - val_loss: 1.8728 - val_accuracy: 0.7479\n","Epoch 6/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.7018 - accuracy: 0.7499 - val_loss: 1.8535 - val_accuracy: 0.7593\n","Epoch 7/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.6782 - accuracy: 0.7566 - val_loss: 1.8339 - val_accuracy: 0.7521\n","Epoch 8/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.6566 - accuracy: 0.7628 - val_loss: 1.8126 - val_accuracy: 0.7634\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.6343 - accuracy: 0.7705 - val_loss: 1.7918 - val_accuracy: 0.7696\n","Epoch 10/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.6159 - accuracy: 0.7736 - val_loss: 1.7690 - val_accuracy: 0.7686\n","Epoch 11/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.5977 - accuracy: 0.7765 - val_loss: 1.7456 - val_accuracy: 0.7696\n","Epoch 12/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.5762 - accuracy: 0.7848 - val_loss: 1.7229 - val_accuracy: 0.7572\n","Epoch 13/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.5567 - accuracy: 0.7930 - val_loss: 1.6957 - val_accuracy: 0.7738\n","Epoch 14/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.5383 - accuracy: 0.7997 - val_loss: 1.6682 - val_accuracy: 0.7810\n","Epoch 15/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.5209 - accuracy: 0.8031 - val_loss: 1.6430 - val_accuracy: 0.7748\n","Epoch 16/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.5023 - accuracy: 0.8101 - val_loss: 1.6154 - val_accuracy: 0.7779\n","Epoch 17/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4856 - accuracy: 0.8140 - val_loss: 1.5887 - val_accuracy: 0.7769\n","Epoch 18/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.4680 - accuracy: 0.8181 - val_loss: 1.5585 - val_accuracy: 0.7903\n","Epoch 19/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.4507 - accuracy: 0.8235 - val_loss: 1.5335 - val_accuracy: 0.7975\n","Epoch 20/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4337 - accuracy: 0.8300 - val_loss: 1.5057 - val_accuracy: 0.7924\n","Epoch 21/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.4184 - accuracy: 0.8307 - val_loss: 1.4867 - val_accuracy: 0.8017\n","Epoch 22/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.4014 - accuracy: 0.8351 - val_loss: 1.4892 - val_accuracy: 0.7634\n","Epoch 23/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.3887 - accuracy: 0.8295 - val_loss: 1.4495 - val_accuracy: 0.7996\n","Epoch 24/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.3709 - accuracy: 0.8398 - val_loss: 1.4338 - val_accuracy: 0.8037\n","Epoch 25/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.3572 - accuracy: 0.8406 - val_loss: 1.4193 - val_accuracy: 0.8037\n","Epoch 26/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.3404 - accuracy: 0.8432 - val_loss: 1.4045 - val_accuracy: 0.8068\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3253 - accuracy: 0.8437 - val_loss: 1.3933 - val_accuracy: 0.8058\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3107 - accuracy: 0.8506 - val_loss: 1.3814 - val_accuracy: 0.8068\n","Epoch 29/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2977 - accuracy: 0.8509 - val_loss: 1.3698 - val_accuracy: 0.8089\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2875 - accuracy: 0.8530 - val_loss: 1.3617 - val_accuracy: 0.8089\n","Epoch 31/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2726 - accuracy: 0.8563 - val_loss: 1.3509 - val_accuracy: 0.8110\n","Epoch 32/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2565 - accuracy: 0.8581 - val_loss: 1.3395 - val_accuracy: 0.8171\n","Epoch 33/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2431 - accuracy: 0.8612 - val_loss: 1.3315 - val_accuracy: 0.8151\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2319 - accuracy: 0.8620 - val_loss: 1.3217 - val_accuracy: 0.8161\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2197 - accuracy: 0.8605 - val_loss: 1.3135 - val_accuracy: 0.8171\n","Epoch 36/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2081 - accuracy: 0.8633 - val_loss: 1.3027 - val_accuracy: 0.8202\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1936 - accuracy: 0.8698 - val_loss: 1.2930 - val_accuracy: 0.8192\n","Epoch 38/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.1880 - accuracy: 0.8682 - val_loss: 1.2858 - val_accuracy: 0.8233\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1742 - accuracy: 0.8695 - val_loss: 1.2847 - val_accuracy: 0.8120\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1608 - accuracy: 0.8788 - val_loss: 1.2724 - val_accuracy: 0.8151\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1485 - accuracy: 0.8762 - val_loss: 1.2611 - val_accuracy: 0.8213\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1390 - accuracy: 0.8760 - val_loss: 1.2626 - val_accuracy: 0.8058\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1306 - accuracy: 0.8767 - val_loss: 1.2492 - val_accuracy: 0.8140\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1196 - accuracy: 0.8835 - val_loss: 1.2406 - val_accuracy: 0.8223\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1036 - accuracy: 0.8848 - val_loss: 1.2296 - val_accuracy: 0.8202\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0964 - accuracy: 0.8853 - val_loss: 1.2248 - val_accuracy: 0.8140\n","Epoch 47/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0861 - accuracy: 0.8866 - val_loss: 1.2176 - val_accuracy: 0.8120\n","Epoch 48/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0747 - accuracy: 0.8907 - val_loss: 1.2168 - val_accuracy: 0.8192\n","Epoch 49/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0674 - accuracy: 0.8897 - val_loss: 1.2108 - val_accuracy: 0.8058\n","Epoch 50/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0532 - accuracy: 0.8922 - val_loss: 1.2024 - val_accuracy: 0.8099\n","Epoch 51/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0477 - accuracy: 0.8928 - val_loss: 1.1906 - val_accuracy: 0.8202\n","Epoch 52/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0393 - accuracy: 0.8979 - val_loss: 1.1860 - val_accuracy: 0.8130\n","Epoch 53/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0244 - accuracy: 0.8987 - val_loss: 1.1823 - val_accuracy: 0.8161\n","Epoch 54/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0201 - accuracy: 0.8961 - val_loss: 1.1717 - val_accuracy: 0.8171\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0053 - accuracy: 0.9021 - val_loss: 1.1648 - val_accuracy: 0.8233\n","Epoch 56/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9968 - accuracy: 0.9054 - val_loss: 1.1605 - val_accuracy: 0.8161\n","Epoch 57/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9900 - accuracy: 0.9090 - val_loss: 1.1590 - val_accuracy: 0.8171\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9763 - accuracy: 0.9083 - val_loss: 1.1496 - val_accuracy: 0.8182\n","Epoch 59/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9710 - accuracy: 0.9109 - val_loss: 1.1616 - val_accuracy: 0.8161\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9611 - accuracy: 0.9101 - val_loss: 1.1419 - val_accuracy: 0.8223\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9531 - accuracy: 0.9158 - val_loss: 1.1369 - val_accuracy: 0.8099\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9438 - accuracy: 0.9147 - val_loss: 1.1331 - val_accuracy: 0.8099\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9323 - accuracy: 0.9171 - val_loss: 1.1247 - val_accuracy: 0.8171\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9268 - accuracy: 0.9202 - val_loss: 1.1215 - val_accuracy: 0.8120\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9174 - accuracy: 0.9168 - val_loss: 1.1176 - val_accuracy: 0.8202\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9172 - accuracy: 0.9155 - val_loss: 1.1112 - val_accuracy: 0.8110\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9000 - accuracy: 0.9261 - val_loss: 1.1061 - val_accuracy: 0.8213\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8935 - accuracy: 0.9240 - val_loss: 1.1235 - val_accuracy: 0.8192\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8886 - accuracy: 0.9274 - val_loss: 1.1007 - val_accuracy: 0.8182\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8855 - accuracy: 0.9202 - val_loss: 1.0938 - val_accuracy: 0.8202\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8692 - accuracy: 0.9313 - val_loss: 1.0989 - val_accuracy: 0.8037\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8602 - accuracy: 0.9336 - val_loss: 1.0845 - val_accuracy: 0.8140\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8537 - accuracy: 0.9336 - val_loss: 1.0808 - val_accuracy: 0.8140\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8453 - accuracy: 0.9375 - val_loss: 1.0789 - val_accuracy: 0.8130\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8410 - accuracy: 0.9372 - val_loss: 1.0891 - val_accuracy: 0.8037\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8323 - accuracy: 0.9364 - val_loss: 1.0742 - val_accuracy: 0.8140\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8256 - accuracy: 0.9382 - val_loss: 1.0720 - val_accuracy: 0.8171\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8250 - accuracy: 0.9357 - val_loss: 1.0818 - val_accuracy: 0.8192\n","Epoch 79/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8156 - accuracy: 0.9393 - val_loss: 1.0660 - val_accuracy: 0.8089\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8033 - accuracy: 0.9444 - val_loss: 1.0689 - val_accuracy: 0.8192\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8162 - accuracy: 0.9310 - val_loss: 1.0582 - val_accuracy: 0.8151\n","Epoch 82/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7946 - accuracy: 0.9444 - val_loss: 1.0776 - val_accuracy: 0.8006\n","Epoch 83/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7985 - accuracy: 0.9380 - val_loss: 1.0505 - val_accuracy: 0.8068\n","Epoch 84/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7795 - accuracy: 0.9475 - val_loss: 1.0642 - val_accuracy: 0.8110\n","Epoch 85/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7697 - accuracy: 0.9535 - val_loss: 1.0459 - val_accuracy: 0.8130\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7634 - accuracy: 0.9556 - val_loss: 1.0400 - val_accuracy: 0.8089\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7696 - accuracy: 0.9457 - val_loss: 1.0569 - val_accuracy: 0.8202\n","Epoch 88/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7586 - accuracy: 0.9532 - val_loss: 1.0366 - val_accuracy: 0.8120\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7467 - accuracy: 0.9527 - val_loss: 1.0337 - val_accuracy: 0.8140\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7446 - accuracy: 0.9522 - val_loss: 1.0354 - val_accuracy: 0.8130\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7370 - accuracy: 0.9581 - val_loss: 1.0353 - val_accuracy: 0.8110\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7312 - accuracy: 0.9581 - val_loss: 1.0351 - val_accuracy: 0.8130\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7240 - accuracy: 0.9602 - val_loss: 1.0286 - val_accuracy: 0.8130\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7188 - accuracy: 0.9599 - val_loss: 1.0249 - val_accuracy: 0.8068\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7156 - accuracy: 0.9587 - val_loss: 1.0306 - val_accuracy: 0.8099\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7082 - accuracy: 0.9636 - val_loss: 1.0260 - val_accuracy: 0.8130\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7026 - accuracy: 0.9628 - val_loss: 1.0249 - val_accuracy: 0.8120\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6953 - accuracy: 0.9667 - val_loss: 1.0170 - val_accuracy: 0.8099\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6899 - accuracy: 0.9690 - val_loss: 1.0218 - val_accuracy: 0.8120\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6861 - accuracy: 0.9674 - val_loss: 1.0169 - val_accuracy: 0.8068\n","{'loss': [1.9241546392440796, 1.846420168876648, 1.7917770147323608, 1.7554501295089722, 1.7280793190002441, 1.7018370628356934, 1.678191065788269, 1.656562089920044, 1.6342989206314087, 1.6159330606460571, 1.597707748413086, 1.576154112815857, 1.5567418336868286, 1.538289189338684, 1.5209335088729858, 1.5022859573364258, 1.4855544567108154, 1.4679886102676392, 1.450724720954895, 1.4336796998977661, 1.4184359312057495, 1.401376485824585, 1.3886573314666748, 1.370905876159668, 1.3572123050689697, 1.3404223918914795, 1.325312614440918, 1.3106904029846191, 1.2977298498153687, 1.2874629497528076, 1.2725602388381958, 1.2565451860427856, 1.2431303262710571, 1.2319366931915283, 1.2197238206863403, 1.208074688911438, 1.193631649017334, 1.1880067586898804, 1.1742109060287476, 1.160805344581604, 1.1484555006027222, 1.1390182971954346, 1.1305533647537231, 1.1196033954620361, 1.1035785675048828, 1.0963659286499023, 1.086130976676941, 1.0747090578079224, 1.067440390586853, 1.053229570388794, 1.0476937294006348, 1.0392597913742065, 1.0244096517562866, 1.020074725151062, 1.0052732229232788, 0.9967864155769348, 0.9900148510932922, 0.9762535691261292, 0.971038818359375, 0.961143970489502, 0.95308917760849, 0.9438022971153259, 0.9323098063468933, 0.9267604351043701, 0.9173812866210938, 0.9172301292419434, 0.9000181555747986, 0.893490195274353, 0.8886348605155945, 0.8854735493659973, 0.8691608309745789, 0.8601510524749756, 0.8536625504493713, 0.8453235030174255, 0.8409839272499084, 0.832251787185669, 0.8255931735038757, 0.8250114321708679, 0.8155905604362488, 0.8033194541931152, 0.8162275552749634, 0.7945905923843384, 0.7985256314277649, 0.7794921398162842, 0.7697420716285706, 0.763405978679657, 0.7696244120597839, 0.7586315870285034, 0.7467347979545593, 0.7445948123931885, 0.7370352745056152, 0.7312045097351074, 0.7239784002304077, 0.7187837958335876, 0.7156025767326355, 0.7082064151763916, 0.7025895118713379, 0.6953271627426147, 0.689885675907135, 0.6860765814781189], 'accuracy': [0.6563307642936707, 0.7204134464263916, 0.7341085076332092, 0.7403100728988647, 0.7465116381645203, 0.749870777130127, 0.7565891742706299, 0.7627906799316406, 0.7705426216125488, 0.773643434047699, 0.776485800743103, 0.7847545146942139, 0.7930232286453247, 0.7997416257858276, 0.8031007647514343, 0.8100775480270386, 0.8139534592628479, 0.8180878758430481, 0.8235142230987549, 0.8299741744995117, 0.8307493329048157, 0.8351421356201172, 0.8294573426246643, 0.8397932648658752, 0.840568482875824, 0.8431524634361267, 0.8436692357063293, 0.8506460189819336, 0.8509044051170349, 0.8529715538024902, 0.8563307523727417, 0.8581395149230957, 0.8612403273582458, 0.8620154857635498, 0.8604651093482971, 0.8633074760437012, 0.869767427444458, 0.8682170510292053, 0.8695090413093567, 0.8788113594055176, 0.8762273788452148, 0.8759689927101135, 0.8767442107200623, 0.8834625482559204, 0.8847545385360718, 0.8852713108062744, 0.8865633010864258, 0.8906976580619812, 0.8896640539169312, 0.8922480344772339, 0.8927648663520813, 0.8979328274726868, 0.8987079858779907, 0.896124005317688, 0.9020671844482422, 0.9054263830184937, 0.9090439081192017, 0.9082687497138977, 0.9108527302742004, 0.9100775122642517, 0.9157622456550598, 0.9147287011146545, 0.9170542359352112, 0.9201550483703613, 0.9167958498001099, 0.9155038595199585, 0.9260981678962708, 0.9240310192108154, 0.9273901581764221, 0.9201550483703613, 0.9312661290168762, 0.9335917234420776, 0.9335917234420776, 0.9374676942825317, 0.9372093081474304, 0.9364340901374817, 0.9382429122924805, 0.9356589317321777, 0.9392764568328857, 0.9444444179534912, 0.9310077428817749, 0.9444444179534912, 0.9379844665527344, 0.9475452303886414, 0.9534883499145508, 0.9555555582046509, 0.9457364082336426, 0.9532299637794495, 0.9527131915092468, 0.9521963596343994, 0.9581395387649536, 0.9581395387649536, 0.9602067470550537, 0.9599483013153076, 0.9586563110351562, 0.9635658860206604, 0.9627906680107117, 0.9666666388511658, 0.9689922332763672, 0.9674418568611145], 'val_loss': [1.9498817920684814, 1.9309799671173096, 1.9113386869430542, 1.8918637037277222, 1.872786521911621, 1.8534579277038574, 1.833923101425171, 1.81259286403656, 1.791823148727417, 1.769024133682251, 1.7456415891647339, 1.7228960990905762, 1.6957067251205444, 1.668154239654541, 1.643039584159851, 1.6153709888458252, 1.5887179374694824, 1.5584604740142822, 1.5335171222686768, 1.5056889057159424, 1.4866682291030884, 1.4891945123672485, 1.4495128393173218, 1.4337811470031738, 1.4192734956741333, 1.4045236110687256, 1.3932944536209106, 1.3814349174499512, 1.3697668313980103, 1.3616900444030762, 1.3509169816970825, 1.3394588232040405, 1.3314920663833618, 1.3217092752456665, 1.3134552240371704, 1.3026518821716309, 1.2929905652999878, 1.2858095169067383, 1.2847093343734741, 1.2723968029022217, 1.261073112487793, 1.262600302696228, 1.249152660369873, 1.2405911684036255, 1.2295888662338257, 1.224849820137024, 1.2175711393356323, 1.216833472251892, 1.2107526063919067, 1.2023811340332031, 1.1905944347381592, 1.1860220432281494, 1.1822856664657593, 1.1716800928115845, 1.164839267730713, 1.1605358123779297, 1.1589704751968384, 1.1496142148971558, 1.161567211151123, 1.1419183015823364, 1.1369010210037231, 1.1330684423446655, 1.1246981620788574, 1.1214525699615479, 1.1176265478134155, 1.1111737489700317, 1.1061211824417114, 1.1234745979309082, 1.1007057428359985, 1.0938196182250977, 1.0988682508468628, 1.0845454931259155, 1.080771803855896, 1.0789461135864258, 1.0890626907348633, 1.074222445487976, 1.0720421075820923, 1.0818233489990234, 1.0659534931182861, 1.068865180015564, 1.05823814868927, 1.077641248703003, 1.0504679679870605, 1.0641827583312988, 1.045920729637146, 1.0399593114852905, 1.0569112300872803, 1.0365742444992065, 1.0337259769439697, 1.0354204177856445, 1.0353056192398071, 1.0351204872131348, 1.0286469459533691, 1.0248512029647827, 1.0306366682052612, 1.025968074798584, 1.0248836278915405, 1.0170422792434692, 1.0217560529708862, 1.0169341564178467], 'val_accuracy': [0.6952479481697083, 0.7241735458374023, 0.7479338645935059, 0.75, 0.7479338645935059, 0.7592975497245789, 0.7520661354064941, 0.7634297609329224, 0.76962810754776, 0.7685950398445129, 0.76962810754776, 0.7572314143180847, 0.7737603187561035, 0.7809917330741882, 0.7747933864593506, 0.7778925895690918, 0.7768595218658447, 0.7902892827987671, 0.797520637512207, 0.7923553586006165, 0.8016529083251953, 0.7634297609329224, 0.7995867729187012, 0.8037189841270447, 0.8037189841270447, 0.8068181872367859, 0.8057851195335388, 0.8068181872367859, 0.80888432264328, 0.80888432264328, 0.8109503984451294, 0.817148745059967, 0.8150826692581177, 0.81611567735672, 0.817148745059967, 0.8202479481697083, 0.8192148804664612, 0.8233470916748047, 0.8119834661483765, 0.8150826692581177, 0.8212810158729553, 0.8057851195335388, 0.8140496015548706, 0.8223140239715576, 0.8202479481697083, 0.8140496015548706, 0.8119834661483765, 0.8192148804664612, 0.8057851195335388, 0.8099173307418823, 0.8202479481697083, 0.8130165338516235, 0.81611567735672, 0.817148745059967, 0.8233470916748047, 0.81611567735672, 0.817148745059967, 0.8181818127632141, 0.81611567735672, 0.8223140239715576, 0.8099173307418823, 0.8099173307418823, 0.817148745059967, 0.8119834661483765, 0.8202479481697083, 0.8109503984451294, 0.8212810158729553, 0.8192148804664612, 0.8181818127632141, 0.8202479481697083, 0.8037189841270447, 0.8140496015548706, 0.8140496015548706, 0.8130165338516235, 0.8037189841270447, 0.8140496015548706, 0.817148745059967, 0.8192148804664612, 0.80888432264328, 0.8192148804664612, 0.8150826692581177, 0.8006198406219482, 0.8068181872367859, 0.8109503984451294, 0.8130165338516235, 0.80888432264328, 0.8202479481697083, 0.8119834661483765, 0.8140496015548706, 0.8130165338516235, 0.8109503984451294, 0.8130165338516235, 0.8130165338516235, 0.8068181872367859, 0.8099173307418823, 0.8130165338516235, 0.8119834661483765, 0.8099173307418823, 0.8119834661483765, 0.8068181872367859]}\n","32/32 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 4s 32ms/step - loss: 0.8116 - accuracy: 0.9038 - val_loss: 1.2628 - val_accuracy: 0.4849\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 1s 19ms/step - loss: 0.7876 - accuracy: 0.9146 - val_loss: 1.2564 - val_accuracy: 0.4860\n","Epoch 3/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.7729 - accuracy: 0.9256 - val_loss: 1.2424 - val_accuracy: 0.4925\n","Epoch 4/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.7625 - accuracy: 0.9308 - val_loss: 1.2282 - val_accuracy: 0.4989\n","Epoch 5/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7543 - accuracy: 0.9335 - val_loss: 1.2143 - val_accuracy: 0.5119\n","Epoch 6/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.7465 - accuracy: 0.9343 - val_loss: 1.1960 - val_accuracy: 0.5388\n","Epoch 7/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7412 - accuracy: 0.9378 - val_loss: 1.1571 - val_accuracy: 0.6864\n","Epoch 8/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7305 - accuracy: 0.9405 - val_loss: 1.1505 - val_accuracy: 0.6509\n","Epoch 9/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7251 - accuracy: 0.9445 - val_loss: 1.1275 - val_accuracy: 0.6940\n","Epoch 10/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7194 - accuracy: 0.9456 - val_loss: 1.0836 - val_accuracy: 0.8491\n","Epoch 11/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7160 - accuracy: 0.9386 - val_loss: 1.0637 - val_accuracy: 0.8481\n","Epoch 12/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.7033 - accuracy: 0.9526 - val_loss: 1.0377 - val_accuracy: 0.8610\n","Epoch 13/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6979 - accuracy: 0.9542 - val_loss: 1.0119 - val_accuracy: 0.8631\n","Epoch 14/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6925 - accuracy: 0.9529 - val_loss: 0.9755 - val_accuracy: 0.8782\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6874 - accuracy: 0.9545 - val_loss: 0.9656 - val_accuracy: 0.8621\n","Epoch 16/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6818 - accuracy: 0.9547 - val_loss: 0.9355 - val_accuracy: 0.8685\n","Epoch 17/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6748 - accuracy: 0.9585 - val_loss: 0.8975 - val_accuracy: 0.8793\n","Epoch 18/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6676 - accuracy: 0.9585 - val_loss: 0.8712 - val_accuracy: 0.8804\n","Epoch 19/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6690 - accuracy: 0.9580 - val_loss: 0.8488 - val_accuracy: 0.8772\n","Epoch 20/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6603 - accuracy: 0.9593 - val_loss: 0.8367 - val_accuracy: 0.8836\n","Epoch 21/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6544 - accuracy: 0.9604 - val_loss: 0.8193 - val_accuracy: 0.8804\n","Epoch 22/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6514 - accuracy: 0.9642 - val_loss: 0.8141 - val_accuracy: 0.8707\n","Epoch 23/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6425 - accuracy: 0.9663 - val_loss: 0.8057 - val_accuracy: 0.8739\n","Epoch 24/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6426 - accuracy: 0.9620 - val_loss: 0.7945 - val_accuracy: 0.8847\n","Epoch 25/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6410 - accuracy: 0.9636 - val_loss: 0.7925 - val_accuracy: 0.8793\n","Epoch 26/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6265 - accuracy: 0.9693 - val_loss: 0.8084 - val_accuracy: 0.8739\n","Epoch 27/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6239 - accuracy: 0.9679 - val_loss: 0.7950 - val_accuracy: 0.8685\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6161 - accuracy: 0.9725 - val_loss: 0.7928 - val_accuracy: 0.8718\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6123 - accuracy: 0.9704 - val_loss: 0.7852 - val_accuracy: 0.8804\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6114 - accuracy: 0.9701 - val_loss: 0.7859 - val_accuracy: 0.8761\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6095 - accuracy: 0.9720 - val_loss: 0.7843 - val_accuracy: 0.8772\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6004 - accuracy: 0.9733 - val_loss: 0.7920 - val_accuracy: 0.8739\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6014 - accuracy: 0.9725 - val_loss: 0.8130 - val_accuracy: 0.8685\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6033 - accuracy: 0.9688 - val_loss: 0.8008 - val_accuracy: 0.8707\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5930 - accuracy: 0.9714 - val_loss: 0.8282 - val_accuracy: 0.8653\n","Epoch 36/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5915 - accuracy: 0.9704 - val_loss: 0.7885 - val_accuracy: 0.8858\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5812 - accuracy: 0.9798 - val_loss: 0.7814 - val_accuracy: 0.8847\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5761 - accuracy: 0.9793 - val_loss: 0.7813 - val_accuracy: 0.8772\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5714 - accuracy: 0.9811 - val_loss: 0.7795 - val_accuracy: 0.8825\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5688 - accuracy: 0.9803 - val_loss: 0.7824 - val_accuracy: 0.8728\n","Epoch 41/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5633 - accuracy: 0.9820 - val_loss: 0.7797 - val_accuracy: 0.8782\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5594 - accuracy: 0.9828 - val_loss: 0.7832 - val_accuracy: 0.8761\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5565 - accuracy: 0.9830 - val_loss: 0.7810 - val_accuracy: 0.8761\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5532 - accuracy: 0.9836 - val_loss: 0.7787 - val_accuracy: 0.8782\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5490 - accuracy: 0.9852 - val_loss: 0.7898 - val_accuracy: 0.8664\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5474 - accuracy: 0.9830 - val_loss: 0.7929 - val_accuracy: 0.8696\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5439 - accuracy: 0.9857 - val_loss: 0.7937 - val_accuracy: 0.8728\n","Epoch 48/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5391 - accuracy: 0.9865 - val_loss: 0.7800 - val_accuracy: 0.8825\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5358 - accuracy: 0.9873 - val_loss: 0.7800 - val_accuracy: 0.8793\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5336 - accuracy: 0.9868 - val_loss: 0.7882 - val_accuracy: 0.8675\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5287 - accuracy: 0.9881 - val_loss: 0.7808 - val_accuracy: 0.8772\n","Epoch 52/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5277 - accuracy: 0.9879 - val_loss: 0.7776 - val_accuracy: 0.8782\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5237 - accuracy: 0.9908 - val_loss: 0.7940 - val_accuracy: 0.8815\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5218 - accuracy: 0.9887 - val_loss: 0.7834 - val_accuracy: 0.8728\n","Epoch 55/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5178 - accuracy: 0.9895 - val_loss: 0.7962 - val_accuracy: 0.8707\n","Epoch 56/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5166 - accuracy: 0.9890 - val_loss: 0.8085 - val_accuracy: 0.8642\n","Epoch 57/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5130 - accuracy: 0.9903 - val_loss: 0.7848 - val_accuracy: 0.8718\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5118 - accuracy: 0.9906 - val_loss: 0.7814 - val_accuracy: 0.8772\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5046 - accuracy: 0.9925 - val_loss: 0.7917 - val_accuracy: 0.8718\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5039 - accuracy: 0.9927 - val_loss: 0.7910 - val_accuracy: 0.8696\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5025 - accuracy: 0.9908 - val_loss: 0.8011 - val_accuracy: 0.8664\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5033 - accuracy: 0.9908 - val_loss: 0.7852 - val_accuracy: 0.8825\n","Epoch 63/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4977 - accuracy: 0.9933 - val_loss: 0.7863 - val_accuracy: 0.8847\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4932 - accuracy: 0.9930 - val_loss: 0.8079 - val_accuracy: 0.8675\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4930 - accuracy: 0.9935 - val_loss: 0.8046 - val_accuracy: 0.8631\n","Epoch 66/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4893 - accuracy: 0.9935 - val_loss: 0.7904 - val_accuracy: 0.8696\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4863 - accuracy: 0.9943 - val_loss: 0.7849 - val_accuracy: 0.8750\n","Epoch 68/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4832 - accuracy: 0.9946 - val_loss: 0.7918 - val_accuracy: 0.8847\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4816 - accuracy: 0.9946 - val_loss: 0.7867 - val_accuracy: 0.8739\n","Epoch 70/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4805 - accuracy: 0.9946 - val_loss: 0.7930 - val_accuracy: 0.8718\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4787 - accuracy: 0.9943 - val_loss: 0.8167 - val_accuracy: 0.8588\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4775 - accuracy: 0.9960 - val_loss: 0.7953 - val_accuracy: 0.8685\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4721 - accuracy: 0.9960 - val_loss: 0.7864 - val_accuracy: 0.8772\n","Epoch 74/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4691 - accuracy: 0.9965 - val_loss: 0.7907 - val_accuracy: 0.8696\n","Epoch 75/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4687 - accuracy: 0.9970 - val_loss: 0.7923 - val_accuracy: 0.8750\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4664 - accuracy: 0.9973 - val_loss: 0.7931 - val_accuracy: 0.8836\n","Epoch 77/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4650 - accuracy: 0.9973 - val_loss: 0.7888 - val_accuracy: 0.8750\n","Epoch 78/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4622 - accuracy: 0.9957 - val_loss: 0.7994 - val_accuracy: 0.8696\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4611 - accuracy: 0.9962 - val_loss: 0.7953 - val_accuracy: 0.8707\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4583 - accuracy: 0.9970 - val_loss: 0.7895 - val_accuracy: 0.8761\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4560 - accuracy: 0.9970 - val_loss: 0.7941 - val_accuracy: 0.8847\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4554 - accuracy: 0.9970 - val_loss: 0.7944 - val_accuracy: 0.8825\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4529 - accuracy: 0.9981 - val_loss: 0.8073 - val_accuracy: 0.8675\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4500 - accuracy: 0.9981 - val_loss: 0.7960 - val_accuracy: 0.8739\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4479 - accuracy: 0.9978 - val_loss: 0.7930 - val_accuracy: 0.8739\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4471 - accuracy: 0.9976 - val_loss: 0.7954 - val_accuracy: 0.8718\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4453 - accuracy: 0.9987 - val_loss: 0.8017 - val_accuracy: 0.8696\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4439 - accuracy: 0.9984 - val_loss: 0.7951 - val_accuracy: 0.8739\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4425 - accuracy: 0.9981 - val_loss: 0.8091 - val_accuracy: 0.8653\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4423 - accuracy: 0.9984 - val_loss: 0.8334 - val_accuracy: 0.8578\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4388 - accuracy: 0.9984 - val_loss: 0.8041 - val_accuracy: 0.8739\n","Epoch 92/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4360 - accuracy: 0.9978 - val_loss: 0.8119 - val_accuracy: 0.8685\n","Epoch 93/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4348 - accuracy: 0.9981 - val_loss: 0.8038 - val_accuracy: 0.8707\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4351 - accuracy: 0.9981 - val_loss: 0.7998 - val_accuracy: 0.8772\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4322 - accuracy: 0.9992 - val_loss: 0.8037 - val_accuracy: 0.8739\n","Epoch 96/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4312 - accuracy: 0.9989 - val_loss: 0.8090 - val_accuracy: 0.8782\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4295 - accuracy: 0.9989 - val_loss: 0.8049 - val_accuracy: 0.8707\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4267 - accuracy: 0.9984 - val_loss: 0.8030 - val_accuracy: 0.8761\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4267 - accuracy: 0.9987 - val_loss: 0.8045 - val_accuracy: 0.8739\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4236 - accuracy: 0.9992 - val_loss: 0.8053 - val_accuracy: 0.8761\n","{'loss': [0.8116005659103394, 0.7876012325286865, 0.7728816270828247, 0.7625386714935303, 0.7542659044265747, 0.7465456128120422, 0.7411596775054932, 0.7304776906967163, 0.7251060605049133, 0.7193847298622131, 0.7159735560417175, 0.7032501101493835, 0.6978509426116943, 0.6925296783447266, 0.6874477863311768, 0.6818271279335022, 0.6748281717300415, 0.6675768494606018, 0.6690249443054199, 0.6603032350540161, 0.6543506383895874, 0.6513676047325134, 0.6424936652183533, 0.6425524950027466, 0.6410049796104431, 0.6265012621879578, 0.6239305138587952, 0.6161376237869263, 0.6122610569000244, 0.6113606691360474, 0.6094908714294434, 0.6003798842430115, 0.6013749241828918, 0.6032674908638, 0.5929973125457764, 0.591472864151001, 0.5811766982078552, 0.5761319398880005, 0.5713979601860046, 0.56881183385849, 0.5633314847946167, 0.5593901872634888, 0.5565323829650879, 0.5531921982765198, 0.549030065536499, 0.5474161505699158, 0.5439420938491821, 0.5391011238098145, 0.53581303358078, 0.5336400270462036, 0.5287231802940369, 0.5277459025382996, 0.5237201452255249, 0.5218175649642944, 0.5178300142288208, 0.5166075229644775, 0.5129824280738831, 0.5118378400802612, 0.5046127438545227, 0.5038978457450867, 0.5025483965873718, 0.5033482313156128, 0.49772751331329346, 0.4932292699813843, 0.49295493960380554, 0.4893346428871155, 0.4862949252128601, 0.48323944211006165, 0.48161259293556213, 0.48054659366607666, 0.4786888659000397, 0.47745397686958313, 0.4720782935619354, 0.469082772731781, 0.46870163083076477, 0.4664062261581421, 0.46499520540237427, 0.462210476398468, 0.46106329560279846, 0.4582558870315552, 0.4560353457927704, 0.45537394285202026, 0.4529277980327606, 0.45001038908958435, 0.4478789269924164, 0.4471149444580078, 0.4453405737876892, 0.44386348128318787, 0.44247570633888245, 0.4422595798969269, 0.43883246183395386, 0.43596747517585754, 0.43483638763427734, 0.4350835084915161, 0.4322182238101959, 0.43115270137786865, 0.4294850528240204, 0.42672309279441833, 0.42673659324645996, 0.4236377775669098], 'accuracy': [0.9038254022598267, 0.9146012663841248, 0.9256465435028076, 0.9307650923728943, 0.9334590435028076, 0.9342672228813171, 0.9377694129943848, 0.9404633641242981, 0.9445043206214905, 0.9455819129943848, 0.9385775923728943, 0.9525862336158752, 0.9542025923728943, 0.9528555870056152, 0.954472005367279, 0.954741358757019, 0.9585129022598267, 0.9585129022598267, 0.9579741358757019, 0.959321141242981, 0.9603987336158752, 0.9641702771186829, 0.9663254022598267, 0.9620150923728943, 0.9636314511299133, 0.9692887663841248, 0.9679418206214905, 0.9725215435028076, 0.970366358757019, 0.970097005367279, 0.9719827771186829, 0.9733297228813171, 0.9725215435028076, 0.96875, 0.9714439511299133, 0.970366358757019, 0.9797952771186829, 0.9792564511299133, 0.9811422228813171, 0.9803340435028076, 0.9819504022598267, 0.982758641242981, 0.983027994632721, 0.9835668206214905, 0.9851831793785095, 0.983027994632721, 0.985722005367279, 0.9865301847457886, 0.9873383641242981, 0.9867995977401733, 0.9881465435028076, 0.9878771305084229, 0.990840494632721, 0.9886853694915771, 0.9894935488700867, 0.9889547228813171, 0.9903017282485962, 0.990571141242981, 0.9924569129943848, 0.9927262663841248, 0.990840494632721, 0.990840494632721, 0.9932650923728943, 0.9929956793785095, 0.993534505367279, 0.993534505367279, 0.9943426847457886, 0.9946120977401733, 0.9946120977401733, 0.9946120977401733, 0.9943426847457886, 0.9959590435028076, 0.9959590435028076, 0.9964978694915771, 0.9970366358757019, 0.9973060488700867, 0.9973060488700867, 0.9956896305084229, 0.9962284564971924, 0.9970366358757019, 0.9970366358757019, 0.9970366358757019, 0.9981142282485962, 0.9981142282485962, 0.9978448152542114, 0.9975754022598267, 0.998652994632721, 0.998383641242981, 0.9981142282485962, 0.998383641242981, 0.998383641242981, 0.9978448152542114, 0.9981142282485962, 0.9981142282485962, 0.9991918206214905, 0.9989224076271057, 0.9989224076271057, 0.998383641242981, 0.998652994632721, 0.9991918206214905], 'val_loss': [1.2627818584442139, 1.25640070438385, 1.242403268814087, 1.228166103363037, 1.2142566442489624, 1.1959843635559082, 1.1571087837219238, 1.150546669960022, 1.127518653869629, 1.083629846572876, 1.0637215375900269, 1.037699580192566, 1.0118908882141113, 0.9754900336265564, 0.9655905961990356, 0.9355331659317017, 0.8974920511245728, 0.8711962699890137, 0.8487572073936462, 0.8367405533790588, 0.8192929625511169, 0.8141106963157654, 0.8056833744049072, 0.7944536805152893, 0.7925168871879578, 0.8083591461181641, 0.7950100302696228, 0.7928355932235718, 0.7851912975311279, 0.7858843803405762, 0.7843246459960938, 0.7919599413871765, 0.813037633895874, 0.800796389579773, 0.8282189965248108, 0.7885283827781677, 0.7814255952835083, 0.7813376784324646, 0.7795388698577881, 0.7823517322540283, 0.7796992063522339, 0.7832186222076416, 0.7810311913490295, 0.7787026166915894, 0.7897688746452332, 0.7929404973983765, 0.7936649322509766, 0.7800235748291016, 0.7800057530403137, 0.7881799340248108, 0.7807605862617493, 0.7775541543960571, 0.7939702868461609, 0.7834474444389343, 0.7962203025817871, 0.8084532618522644, 0.7847599387168884, 0.7813870906829834, 0.7917085289955139, 0.7909530401229858, 0.8010685443878174, 0.7851506471633911, 0.7863432765007019, 0.8079072833061218, 0.8045860528945923, 0.7904252409934998, 0.7848701477050781, 0.7917807102203369, 0.7867180109024048, 0.7930145263671875, 0.8166746497154236, 0.7953240871429443, 0.7863559722900391, 0.7906964421272278, 0.7922940254211426, 0.7930516600608826, 0.7888346314430237, 0.7993717193603516, 0.7952766418457031, 0.7894838452339172, 0.7940544486045837, 0.7944321036338806, 0.8073089718818665, 0.795993983745575, 0.7929674386978149, 0.7954336404800415, 0.801748514175415, 0.7951327562332153, 0.8090749382972717, 0.8333651423454285, 0.8040682673454285, 0.8118969202041626, 0.8038026094436646, 0.7998179793357849, 0.8037198185920715, 0.8090337514877319, 0.8049119710922241, 0.8030397891998291, 0.8045478463172913, 0.8053023219108582], 'val_accuracy': [0.48491379618644714, 0.48599138855934143, 0.4924568831920624, 0.4989224076271057, 0.5118534564971924, 0.5387930870056152, 0.6864224076271057, 0.6508620977401733, 0.693965494632721, 0.8491379022598267, 0.8480603694915771, 0.860991358757019, 0.8631465435028076, 0.8782327771186829, 0.8620689511299133, 0.868534505367279, 0.8793103694915771, 0.8803879022598267, 0.8771551847457886, 0.8836206793785095, 0.8803879022598267, 0.8706896305084229, 0.8739224076271057, 0.8846982717514038, 0.8793103694915771, 0.8739224076271057, 0.868534505367279, 0.8717672228813171, 0.8803879022598267, 0.8760775923728943, 0.8771551847457886, 0.8739224076271057, 0.868534505367279, 0.8706896305084229, 0.8653017282485962, 0.8857758641242981, 0.8846982717514038, 0.8771551847457886, 0.8825430870056152, 0.8728448152542114, 0.8782327771186829, 0.8760775923728943, 0.8760775923728943, 0.8782327771186829, 0.8663793206214905, 0.8696120977401733, 0.8728448152542114, 0.8825430870056152, 0.8793103694915771, 0.8674569129943848, 0.8771551847457886, 0.8782327771186829, 0.881465494632721, 0.8728448152542114, 0.8706896305084229, 0.8642241358757019, 0.8717672228813171, 0.8771551847457886, 0.8717672228813171, 0.8696120977401733, 0.8663793206214905, 0.8825430870056152, 0.8846982717514038, 0.8674569129943848, 0.8631465435028076, 0.8696120977401733, 0.875, 0.8846982717514038, 0.8739224076271057, 0.8717672228813171, 0.8588362336158752, 0.868534505367279, 0.8771551847457886, 0.8696120977401733, 0.875, 0.8836206793785095, 0.875, 0.8696120977401733, 0.8706896305084229, 0.8760775923728943, 0.8846982717514038, 0.8825430870056152, 0.8674569129943848, 0.8739224076271057, 0.8739224076271057, 0.8717672228813171, 0.8696120977401733, 0.8739224076271057, 0.8653017282485962, 0.857758641242981, 0.8739224076271057, 0.868534505367279, 0.8706896305084229, 0.8771551847457886, 0.8739224076271057, 0.8782327771186829, 0.8706896305084229, 0.8760775923728943, 0.8739224076271057, 0.8760775923728943]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 35ms/step - loss: 0.8180 - accuracy: 0.9021 - val_loss: 1.2621 - val_accuracy: 0.4966\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7953 - accuracy: 0.9177 - val_loss: 1.2559 - val_accuracy: 0.4966\n","Epoch 3/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7891 - accuracy: 0.9177 - val_loss: 1.2440 - val_accuracy: 0.4977\n","Epoch 4/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.7813 - accuracy: 0.9196 - val_loss: 1.2287 - val_accuracy: 0.5079\n","Epoch 5/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.7690 - accuracy: 0.9284 - val_loss: 1.2133 - val_accuracy: 0.5294\n","Epoch 6/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.7610 - accuracy: 0.9287 - val_loss: 1.1890 - val_accuracy: 0.5984\n","Epoch 7/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.7508 - accuracy: 0.9363 - val_loss: 1.1636 - val_accuracy: 0.6900\n","Epoch 8/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.7474 - accuracy: 0.9315 - val_loss: 1.1480 - val_accuracy: 0.7138\n","Epoch 9/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.7410 - accuracy: 0.9349 - val_loss: 1.1179 - val_accuracy: 0.8100\n","Epoch 10/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7301 - accuracy: 0.9468 - val_loss: 1.0931 - val_accuracy: 0.8518\n","Epoch 11/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7289 - accuracy: 0.9372 - val_loss: 1.0827 - val_accuracy: 0.8054\n","Epoch 12/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7201 - accuracy: 0.9443 - val_loss: 1.0498 - val_accuracy: 0.8552\n","Epoch 13/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7136 - accuracy: 0.9488 - val_loss: 1.0344 - val_accuracy: 0.8303\n","Epoch 14/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7067 - accuracy: 0.9474 - val_loss: 0.9952 - val_accuracy: 0.8676\n","Epoch 15/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6992 - accuracy: 0.9536 - val_loss: 0.9660 - val_accuracy: 0.8722\n","Epoch 16/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6947 - accuracy: 0.9530 - val_loss: 0.9505 - val_accuracy: 0.8643\n","Epoch 17/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6872 - accuracy: 0.9576 - val_loss: 0.9238 - val_accuracy: 0.8631\n","Epoch 18/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6820 - accuracy: 0.9547 - val_loss: 0.8965 - val_accuracy: 0.8710\n","Epoch 19/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6800 - accuracy: 0.9559 - val_loss: 0.8748 - val_accuracy: 0.8744\n","Epoch 20/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6719 - accuracy: 0.9601 - val_loss: 0.8600 - val_accuracy: 0.8665\n","Epoch 21/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6681 - accuracy: 0.9570 - val_loss: 0.8443 - val_accuracy: 0.8699\n","Epoch 22/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6614 - accuracy: 0.9618 - val_loss: 0.8359 - val_accuracy: 0.8688\n","Epoch 23/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6570 - accuracy: 0.9590 - val_loss: 0.8243 - val_accuracy: 0.8733\n","Epoch 24/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6547 - accuracy: 0.9624 - val_loss: 0.8186 - val_accuracy: 0.8710\n","Epoch 25/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6459 - accuracy: 0.9669 - val_loss: 0.8233 - val_accuracy: 0.8597\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6540 - accuracy: 0.9570 - val_loss: 0.8115 - val_accuracy: 0.8654\n","Epoch 27/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6392 - accuracy: 0.9643 - val_loss: 0.8253 - val_accuracy: 0.8643\n","Epoch 28/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6329 - accuracy: 0.9680 - val_loss: 0.8068 - val_accuracy: 0.8733\n","Epoch 29/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6259 - accuracy: 0.9700 - val_loss: 0.8057 - val_accuracy: 0.8744\n","Epoch 30/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6224 - accuracy: 0.9723 - val_loss: 0.8073 - val_accuracy: 0.8767\n","Epoch 31/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6170 - accuracy: 0.9717 - val_loss: 0.8018 - val_accuracy: 0.8710\n","Epoch 32/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6136 - accuracy: 0.9731 - val_loss: 0.8124 - val_accuracy: 0.8665\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6091 - accuracy: 0.9731 - val_loss: 0.8070 - val_accuracy: 0.8710\n","Epoch 34/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6048 - accuracy: 0.9751 - val_loss: 0.7992 - val_accuracy: 0.8688\n","Epoch 35/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6124 - accuracy: 0.9666 - val_loss: 0.8145 - val_accuracy: 0.8654\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5973 - accuracy: 0.9771 - val_loss: 0.8204 - val_accuracy: 0.8609\n","Epoch 37/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5912 - accuracy: 0.9791 - val_loss: 0.7991 - val_accuracy: 0.8688\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5859 - accuracy: 0.9813 - val_loss: 0.7969 - val_accuracy: 0.8756\n","Epoch 39/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5833 - accuracy: 0.9802 - val_loss: 0.7957 - val_accuracy: 0.8699\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5812 - accuracy: 0.9793 - val_loss: 0.7959 - val_accuracy: 0.8756\n","Epoch 41/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5761 - accuracy: 0.9822 - val_loss: 0.7939 - val_accuracy: 0.8767\n","Epoch 42/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5771 - accuracy: 0.9791 - val_loss: 0.7943 - val_accuracy: 0.8778\n","Epoch 43/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5686 - accuracy: 0.9850 - val_loss: 0.8028 - val_accuracy: 0.8733\n","Epoch 44/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5632 - accuracy: 0.9842 - val_loss: 0.7958 - val_accuracy: 0.8643\n","Epoch 45/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5595 - accuracy: 0.9847 - val_loss: 0.8048 - val_accuracy: 0.8722\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5573 - accuracy: 0.9864 - val_loss: 0.7903 - val_accuracy: 0.8688\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5543 - accuracy: 0.9867 - val_loss: 0.7900 - val_accuracy: 0.8744\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5508 - accuracy: 0.9859 - val_loss: 0.7958 - val_accuracy: 0.8699\n","Epoch 49/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5497 - accuracy: 0.9853 - val_loss: 0.7918 - val_accuracy: 0.8790\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5432 - accuracy: 0.9864 - val_loss: 0.7878 - val_accuracy: 0.8733\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5398 - accuracy: 0.9895 - val_loss: 0.7880 - val_accuracy: 0.8733\n","Epoch 52/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5373 - accuracy: 0.9884 - val_loss: 0.7896 - val_accuracy: 0.8722\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5340 - accuracy: 0.9878 - val_loss: 0.7918 - val_accuracy: 0.8744\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5314 - accuracy: 0.9890 - val_loss: 0.8023 - val_accuracy: 0.8643\n","Epoch 55/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5363 - accuracy: 0.9859 - val_loss: 0.8024 - val_accuracy: 0.8597\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5288 - accuracy: 0.9873 - val_loss: 0.7886 - val_accuracy: 0.8688\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5230 - accuracy: 0.9895 - val_loss: 0.7901 - val_accuracy: 0.8631\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5190 - accuracy: 0.9924 - val_loss: 0.7922 - val_accuracy: 0.8609\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5187 - accuracy: 0.9901 - val_loss: 0.8244 - val_accuracy: 0.8643\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5133 - accuracy: 0.9915 - val_loss: 0.7917 - val_accuracy: 0.8733\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5110 - accuracy: 0.9912 - val_loss: 0.8191 - val_accuracy: 0.8643\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5093 - accuracy: 0.9924 - val_loss: 0.7847 - val_accuracy: 0.8699\n","Epoch 63/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5055 - accuracy: 0.9932 - val_loss: 0.7969 - val_accuracy: 0.8688\n","Epoch 64/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5030 - accuracy: 0.9935 - val_loss: 0.7882 - val_accuracy: 0.8699\n","Epoch 65/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4991 - accuracy: 0.9938 - val_loss: 0.7909 - val_accuracy: 0.8722\n","Epoch 66/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4960 - accuracy: 0.9955 - val_loss: 0.7879 - val_accuracy: 0.8597\n","Epoch 67/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4992 - accuracy: 0.9921 - val_loss: 0.8175 - val_accuracy: 0.8416\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4986 - accuracy: 0.9926 - val_loss: 0.7892 - val_accuracy: 0.8620\n","Epoch 69/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4951 - accuracy: 0.9932 - val_loss: 0.8303 - val_accuracy: 0.8597\n","Epoch 70/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4921 - accuracy: 0.9932 - val_loss: 0.8050 - val_accuracy: 0.8643\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4898 - accuracy: 0.9932 - val_loss: 0.7876 - val_accuracy: 0.8654\n","Epoch 72/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4814 - accuracy: 0.9952 - val_loss: 0.7896 - val_accuracy: 0.8733\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4799 - accuracy: 0.9958 - val_loss: 0.7885 - val_accuracy: 0.8620\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4770 - accuracy: 0.9960 - val_loss: 0.7891 - val_accuracy: 0.8643\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4747 - accuracy: 0.9966 - val_loss: 0.7978 - val_accuracy: 0.8744\n","Epoch 76/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4745 - accuracy: 0.9963 - val_loss: 0.8003 - val_accuracy: 0.8710\n","Epoch 77/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4723 - accuracy: 0.9963 - val_loss: 0.7942 - val_accuracy: 0.8722\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4729 - accuracy: 0.9963 - val_loss: 0.7887 - val_accuracy: 0.8643\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4696 - accuracy: 0.9955 - val_loss: 0.7936 - val_accuracy: 0.8643\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4661 - accuracy: 0.9963 - val_loss: 0.8044 - val_accuracy: 0.8631\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4634 - accuracy: 0.9969 - val_loss: 0.7891 - val_accuracy: 0.8665\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4624 - accuracy: 0.9963 - val_loss: 0.8020 - val_accuracy: 0.8756\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4602 - accuracy: 0.9969 - val_loss: 0.7936 - val_accuracy: 0.8676\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4576 - accuracy: 0.9969 - val_loss: 0.7991 - val_accuracy: 0.8756\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4561 - accuracy: 0.9975 - val_loss: 0.7973 - val_accuracy: 0.8756\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4564 - accuracy: 0.9966 - val_loss: 0.7994 - val_accuracy: 0.8710\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4551 - accuracy: 0.9966 - val_loss: 0.7958 - val_accuracy: 0.8688\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4542 - accuracy: 0.9958 - val_loss: 0.8064 - val_accuracy: 0.8518\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4516 - accuracy: 0.9969 - val_loss: 0.7931 - val_accuracy: 0.8665\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4503 - accuracy: 0.9972 - val_loss: 0.7977 - val_accuracy: 0.8620\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4450 - accuracy: 0.9980 - val_loss: 0.8033 - val_accuracy: 0.8710\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4437 - accuracy: 0.9975 - val_loss: 0.8148 - val_accuracy: 0.8722\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4429 - accuracy: 0.9977 - val_loss: 0.7950 - val_accuracy: 0.8620\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4417 - accuracy: 0.9977 - val_loss: 0.7968 - val_accuracy: 0.8597\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4418 - accuracy: 0.9977 - val_loss: 0.8041 - val_accuracy: 0.8643\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4384 - accuracy: 0.9983 - val_loss: 0.8268 - val_accuracy: 0.8654\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4380 - accuracy: 0.9986 - val_loss: 0.7956 - val_accuracy: 0.8563\n","Epoch 98/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4351 - accuracy: 0.9983 - val_loss: 0.8284 - val_accuracy: 0.8688\n","Epoch 99/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4333 - accuracy: 0.9977 - val_loss: 0.8060 - val_accuracy: 0.8620\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4314 - accuracy: 0.9986 - val_loss: 0.8055 - val_accuracy: 0.8620\n","{'loss': [0.818038821220398, 0.7953407764434814, 0.7890781164169312, 0.7813352942466736, 0.7689891457557678, 0.761040210723877, 0.7507832646369934, 0.7474464774131775, 0.74104905128479, 0.730146586894989, 0.7289363145828247, 0.720124363899231, 0.7135894894599915, 0.7067172527313232, 0.6992453336715698, 0.6946813464164734, 0.6871654987335205, 0.6819747090339661, 0.679979681968689, 0.6719171404838562, 0.6681132316589355, 0.6614417433738708, 0.6570164561271667, 0.6547079086303711, 0.6458582878112793, 0.6539787650108337, 0.6391849517822266, 0.6329336762428284, 0.6259390711784363, 0.6224158406257629, 0.6170086860656738, 0.6135872602462769, 0.609052300453186, 0.6047529578208923, 0.6123815178871155, 0.5972927808761597, 0.591170072555542, 0.5859283804893494, 0.5833290219306946, 0.5812086462974548, 0.5761170387268066, 0.5770623087882996, 0.5685916543006897, 0.5631595849990845, 0.559509813785553, 0.5572932958602905, 0.5542930960655212, 0.5507568717002869, 0.5497230887413025, 0.5431755781173706, 0.5398054718971252, 0.5373256802558899, 0.5339757800102234, 0.5313799381256104, 0.5362849831581116, 0.5287644267082214, 0.5230433940887451, 0.5189775824546814, 0.5186551213264465, 0.513344407081604, 0.5109567642211914, 0.5093400478363037, 0.505461573600769, 0.5029786825180054, 0.49909350275993347, 0.4959721267223358, 0.49923601746559143, 0.4985606372356415, 0.49514615535736084, 0.49211928248405457, 0.4898258149623871, 0.48136675357818604, 0.4798542857170105, 0.47696858644485474, 0.47474953532218933, 0.47449666261672974, 0.47233977913856506, 0.4728570878505707, 0.46958208084106445, 0.46614789962768555, 0.46343573927879333, 0.46242839097976685, 0.46015098690986633, 0.45755788683891296, 0.45609787106513977, 0.4563518464565277, 0.4551151990890503, 0.45424243807792664, 0.4515926241874695, 0.45029741525650024, 0.4449566900730133, 0.4437125027179718, 0.44289207458496094, 0.44171270728111267, 0.44177594780921936, 0.43836432695388794, 0.43800801038742065, 0.4350678622722626, 0.43332287669181824, 0.4313773214817047], 'accuracy': [0.9020939469337463, 0.9176570177078247, 0.9176570177078247, 0.9196377992630005, 0.92840975522995, 0.9286926984786987, 0.9363327622413635, 0.9315223693847656, 0.9349179267883301, 0.9468024969100952, 0.9371816515922546, 0.9442558288574219, 0.9487832188606262, 0.9473684430122375, 0.9535936713218689, 0.9530277252197266, 0.9575551748275757, 0.9547255039215088, 0.9558573961257935, 0.960101842880249, 0.9569892287254333, 0.961799681186676, 0.9589700102806091, 0.9623655676841736, 0.9668930172920227, 0.9569892287254333, 0.9643463492393494, 0.9680249094963074, 0.9700056314468384, 0.9722693562507629, 0.9717034697532654, 0.9731183052062988, 0.9731183052062988, 0.9750990271568298, 0.9666100740432739, 0.9770798087120056, 0.9790605306625366, 0.9813242554664612, 0.9801924228668213, 0.9793435335159302, 0.9821732044219971, 0.9790605306625366, 0.9850028157234192, 0.9841539263725281, 0.9847198724746704, 0.9864176511764526, 0.9867005944252014, 0.9858517050743103, 0.9852858185768127, 0.9864176511764526, 0.9895302653312683, 0.9883984327316284, 0.9878324866294861, 0.988964319229126, 0.9858517050743103, 0.9872665405273438, 0.9895302653312683, 0.9923599362373352, 0.9900962114334106, 0.9915110468864441, 0.9912280440330505, 0.9923599362373352, 0.9932088255882263, 0.9934917688369751, 0.9937747716903687, 0.9954725503921509, 0.9920769929885864, 0.992642879486084, 0.9932088255882263, 0.9932088255882263, 0.9932088255882263, 0.9951896071434021, 0.9957554936408997, 0.9960384964942932, 0.9966044425964355, 0.996321439743042, 0.996321439743042, 0.996321439743042, 0.9954725503921509, 0.996321439743042, 0.9968873858451843, 0.996321439743042, 0.9968873858451843, 0.9968873858451843, 0.9974533319473267, 0.9966044425964355, 0.9966044425964355, 0.9957554936408997, 0.9968873858451843, 0.9971703290939331, 0.9980192184448242, 0.9974533319473267, 0.9977362751960754, 0.9977362751960754, 0.9977362751960754, 0.9983022212982178, 0.9985851645469666, 0.9983022212982178, 0.9977362751960754, 0.9985851645469666], 'val_loss': [1.2621201276779175, 1.2558541297912598, 1.2440330982208252, 1.228735327720642, 1.2132542133331299, 1.1889996528625488, 1.1635686159133911, 1.1479800939559937, 1.117884874343872, 1.0931153297424316, 1.0826982259750366, 1.049781322479248, 1.0343539714813232, 0.9952389597892761, 0.9660120606422424, 0.9504804611206055, 0.9237708449363708, 0.8964971303939819, 0.8747887015342712, 0.8600118160247803, 0.8443238139152527, 0.8359454870223999, 0.8243473768234253, 0.8185718655586243, 0.8232853412628174, 0.8115499019622803, 0.8252850770950317, 0.8067535161972046, 0.8057007789611816, 0.8073251247406006, 0.801820695400238, 0.8123873472213745, 0.8070178627967834, 0.7991976737976074, 0.8145360350608826, 0.8204215168952942, 0.7991255521774292, 0.7969169616699219, 0.7956873178482056, 0.7958888411521912, 0.7939267158508301, 0.7943305373191833, 0.8028396964073181, 0.7958207726478577, 0.8047882318496704, 0.7902787327766418, 0.7899761199951172, 0.7957836389541626, 0.7918449640274048, 0.787846028804779, 0.7880437970161438, 0.789605975151062, 0.7918161153793335, 0.8023451566696167, 0.8023533225059509, 0.7886477708816528, 0.7900840044021606, 0.7921671271324158, 0.8243542909622192, 0.7917014956474304, 0.8191083669662476, 0.7846943140029907, 0.7968894243240356, 0.7881974577903748, 0.7908511757850647, 0.7878854274749756, 0.8174992203712463, 0.7892066240310669, 0.8302599787712097, 0.8050484657287598, 0.7876186370849609, 0.7895739674568176, 0.788507878780365, 0.7890632152557373, 0.7978233098983765, 0.8002871870994568, 0.7941511869430542, 0.7886500358581543, 0.7936321496963501, 0.8043997287750244, 0.789075493812561, 0.802040696144104, 0.7935848832130432, 0.7991153001785278, 0.7972710132598877, 0.7993813753128052, 0.795820415019989, 0.8063721060752869, 0.7930846810340881, 0.7976899147033691, 0.8032967448234558, 0.8147640824317932, 0.7950252294540405, 0.7968135476112366, 0.8041287660598755, 0.8267927765846252, 0.7955711483955383, 0.8284236192703247, 0.8060497641563416, 0.8054616451263428], 'val_accuracy': [0.49660632014274597, 0.49660632014274597, 0.4977375566959381, 0.5079185366630554, 0.529411792755127, 0.598416268825531, 0.6900452375411987, 0.7138009071350098, 0.8099547624588013, 0.8518099784851074, 0.8054298758506775, 0.8552036285400391, 0.8303167223930359, 0.8676470518112183, 0.872171938419342, 0.8642534017562866, 0.8631221652030945, 0.8710407018661499, 0.8744344115257263, 0.8665158152580261, 0.8699095249176025, 0.8687782883644104, 0.8733031749725342, 0.8710407018661499, 0.8597285151481628, 0.8653846383094788, 0.8642534017562866, 0.8733031749725342, 0.8744344115257263, 0.8766968250274658, 0.8710407018661499, 0.8665158152580261, 0.8710407018661499, 0.8687782883644104, 0.8653846383094788, 0.860859751701355, 0.8687782883644104, 0.8755655884742737, 0.8699095249176025, 0.8755655884742737, 0.8766968250274658, 0.877828061580658, 0.8733031749725342, 0.8642534017562866, 0.872171938419342, 0.8687782883644104, 0.8744344115257263, 0.8699095249176025, 0.8789592981338501, 0.8733031749725342, 0.8733031749725342, 0.872171938419342, 0.8744344115257263, 0.8642534017562866, 0.8597285151481628, 0.8687782883644104, 0.8631221652030945, 0.860859751701355, 0.8642534017562866, 0.8733031749725342, 0.8642534017562866, 0.8699095249176025, 0.8687782883644104, 0.8699095249176025, 0.872171938419342, 0.8597285151481628, 0.8416289687156677, 0.8619909286499023, 0.8597285151481628, 0.8642534017562866, 0.8653846383094788, 0.8733031749725342, 0.8619909286499023, 0.8642534017562866, 0.8744344115257263, 0.8710407018661499, 0.872171938419342, 0.8642534017562866, 0.8642534017562866, 0.8631221652030945, 0.8665158152580261, 0.8755655884742737, 0.8676470518112183, 0.8755655884742737, 0.8755655884742737, 0.8710407018661499, 0.8687782883644104, 0.8518099784851074, 0.8665158152580261, 0.8619909286499023, 0.8710407018661499, 0.872171938419342, 0.8619909286499023, 0.8597285151481628, 0.8642534017562866, 0.8653846383094788, 0.8563348650932312, 0.8687782883644104, 0.8619909286499023, 0.8619909286499023]}\n","45/45 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 5s 32ms/step - loss: 0.7964 - accuracy: 0.9114 - val_loss: 1.2650 - val_accuracy: 0.4855\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 13ms/step - loss: 0.7736 - accuracy: 0.9274 - val_loss: 1.2566 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7668 - accuracy: 0.9235 - val_loss: 1.2482 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7575 - accuracy: 0.9315 - val_loss: 1.2244 - val_accuracy: 0.5062\n","Epoch 5/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7487 - accuracy: 0.9336 - val_loss: 1.2017 - val_accuracy: 0.5465\n","Epoch 6/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7421 - accuracy: 0.9346 - val_loss: 1.1750 - val_accuracy: 0.6405\n","Epoch 7/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7471 - accuracy: 0.9297 - val_loss: 1.1626 - val_accuracy: 0.6353\n","Epoch 8/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.7378 - accuracy: 0.9328 - val_loss: 1.1423 - val_accuracy: 0.6756\n","Epoch 9/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7361 - accuracy: 0.9287 - val_loss: 1.1066 - val_accuracy: 0.7893\n","Epoch 10/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7169 - accuracy: 0.9416 - val_loss: 1.0745 - val_accuracy: 0.8285\n","Epoch 11/100\n","31/31 [==============================] - 1s 37ms/step - loss: 0.7059 - accuracy: 0.9465 - val_loss: 1.0463 - val_accuracy: 0.8450\n","Epoch 12/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7008 - accuracy: 0.9473 - val_loss: 1.0214 - val_accuracy: 0.8481\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6965 - accuracy: 0.9491 - val_loss: 0.9963 - val_accuracy: 0.8502\n","Epoch 14/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6946 - accuracy: 0.9481 - val_loss: 0.9803 - val_accuracy: 0.8357\n","Epoch 15/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6872 - accuracy: 0.9488 - val_loss: 0.9386 - val_accuracy: 0.8616\n","Epoch 16/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6793 - accuracy: 0.9535 - val_loss: 0.9218 - val_accuracy: 0.8554\n","Epoch 17/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6760 - accuracy: 0.9530 - val_loss: 0.9065 - val_accuracy: 0.8481\n","Epoch 18/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6717 - accuracy: 0.9512 - val_loss: 0.8710 - val_accuracy: 0.8616\n","Epoch 19/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6648 - accuracy: 0.9558 - val_loss: 0.8613 - val_accuracy: 0.8657\n","Epoch 20/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6599 - accuracy: 0.9579 - val_loss: 0.8617 - val_accuracy: 0.8564\n","Epoch 21/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6535 - accuracy: 0.9589 - val_loss: 0.8576 - val_accuracy: 0.8492\n","Epoch 22/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6498 - accuracy: 0.9579 - val_loss: 0.8412 - val_accuracy: 0.8636\n","Epoch 23/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6415 - accuracy: 0.9623 - val_loss: 0.8336 - val_accuracy: 0.8616\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6379 - accuracy: 0.9638 - val_loss: 0.8321 - val_accuracy: 0.8605\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6344 - accuracy: 0.9597 - val_loss: 0.8332 - val_accuracy: 0.8657\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6330 - accuracy: 0.9623 - val_loss: 0.8341 - val_accuracy: 0.8657\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6295 - accuracy: 0.9605 - val_loss: 0.8483 - val_accuracy: 0.8533\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6283 - accuracy: 0.9597 - val_loss: 0.8352 - val_accuracy: 0.8605\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6184 - accuracy: 0.9649 - val_loss: 0.8618 - val_accuracy: 0.8523\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6269 - accuracy: 0.9584 - val_loss: 0.8314 - val_accuracy: 0.8647\n","Epoch 31/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6116 - accuracy: 0.9661 - val_loss: 0.8374 - val_accuracy: 0.8626\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6006 - accuracy: 0.9703 - val_loss: 0.8343 - val_accuracy: 0.8605\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6013 - accuracy: 0.9716 - val_loss: 0.8396 - val_accuracy: 0.8616\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5982 - accuracy: 0.9708 - val_loss: 0.8301 - val_accuracy: 0.8595\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5926 - accuracy: 0.9734 - val_loss: 0.8313 - val_accuracy: 0.8626\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5954 - accuracy: 0.9685 - val_loss: 0.8392 - val_accuracy: 0.8574\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5927 - accuracy: 0.9703 - val_loss: 0.8517 - val_accuracy: 0.8564\n","Epoch 38/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5816 - accuracy: 0.9711 - val_loss: 0.8266 - val_accuracy: 0.8626\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5747 - accuracy: 0.9762 - val_loss: 0.8269 - val_accuracy: 0.8605\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5728 - accuracy: 0.9757 - val_loss: 0.8284 - val_accuracy: 0.8626\n","Epoch 41/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5671 - accuracy: 0.9798 - val_loss: 0.8372 - val_accuracy: 0.8523\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5646 - accuracy: 0.9806 - val_loss: 0.8306 - val_accuracy: 0.8605\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5612 - accuracy: 0.9773 - val_loss: 0.8853 - val_accuracy: 0.8316\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5704 - accuracy: 0.9721 - val_loss: 0.8282 - val_accuracy: 0.8595\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5566 - accuracy: 0.9780 - val_loss: 0.8309 - val_accuracy: 0.8574\n","Epoch 46/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5523 - accuracy: 0.9786 - val_loss: 0.8232 - val_accuracy: 0.8554\n","Epoch 47/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5458 - accuracy: 0.9811 - val_loss: 0.8278 - val_accuracy: 0.8574\n","Epoch 48/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5422 - accuracy: 0.9837 - val_loss: 0.8258 - val_accuracy: 0.8595\n","Epoch 49/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5436 - accuracy: 0.9835 - val_loss: 0.8296 - val_accuracy: 0.8616\n","Epoch 50/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5377 - accuracy: 0.9840 - val_loss: 0.8252 - val_accuracy: 0.8574\n","Epoch 51/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5332 - accuracy: 0.9848 - val_loss: 0.8260 - val_accuracy: 0.8595\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5327 - accuracy: 0.9829 - val_loss: 0.8292 - val_accuracy: 0.8574\n","Epoch 53/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5286 - accuracy: 0.9840 - val_loss: 0.8238 - val_accuracy: 0.8574\n","Epoch 54/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5241 - accuracy: 0.9868 - val_loss: 0.8247 - val_accuracy: 0.8564\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5246 - accuracy: 0.9848 - val_loss: 0.8337 - val_accuracy: 0.8595\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5236 - accuracy: 0.9860 - val_loss: 0.8417 - val_accuracy: 0.8585\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5196 - accuracy: 0.9855 - val_loss: 0.8368 - val_accuracy: 0.8585\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5155 - accuracy: 0.9866 - val_loss: 0.8288 - val_accuracy: 0.8564\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5108 - accuracy: 0.9881 - val_loss: 0.8333 - val_accuracy: 0.8543\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5064 - accuracy: 0.9899 - val_loss: 0.8412 - val_accuracy: 0.8512\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5084 - accuracy: 0.9881 - val_loss: 0.8391 - val_accuracy: 0.8523\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5024 - accuracy: 0.9915 - val_loss: 0.8395 - val_accuracy: 0.8574\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5007 - accuracy: 0.9904 - val_loss: 0.8251 - val_accuracy: 0.8471\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4980 - accuracy: 0.9910 - val_loss: 0.8423 - val_accuracy: 0.8512\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4943 - accuracy: 0.9928 - val_loss: 0.8306 - val_accuracy: 0.8543\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4919 - accuracy: 0.9915 - val_loss: 0.8278 - val_accuracy: 0.8585\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4902 - accuracy: 0.9922 - val_loss: 0.8340 - val_accuracy: 0.8523\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4908 - accuracy: 0.9907 - val_loss: 0.8374 - val_accuracy: 0.8543\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4858 - accuracy: 0.9920 - val_loss: 0.8382 - val_accuracy: 0.8564\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4832 - accuracy: 0.9933 - val_loss: 0.8348 - val_accuracy: 0.8533\n","Epoch 71/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4844 - accuracy: 0.9933 - val_loss: 0.8302 - val_accuracy: 0.8502\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4768 - accuracy: 0.9938 - val_loss: 0.8336 - val_accuracy: 0.8523\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4754 - accuracy: 0.9941 - val_loss: 0.8313 - val_accuracy: 0.8543\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4733 - accuracy: 0.9946 - val_loss: 0.8376 - val_accuracy: 0.8502\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4712 - accuracy: 0.9951 - val_loss: 0.8397 - val_accuracy: 0.8533\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4715 - accuracy: 0.9951 - val_loss: 0.8432 - val_accuracy: 0.8554\n","Epoch 77/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4688 - accuracy: 0.9964 - val_loss: 0.8558 - val_accuracy: 0.8471\n","Epoch 78/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4644 - accuracy: 0.9953 - val_loss: 0.8338 - val_accuracy: 0.8492\n","Epoch 79/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4644 - accuracy: 0.9953 - val_loss: 0.8415 - val_accuracy: 0.8533\n","Epoch 80/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4633 - accuracy: 0.9948 - val_loss: 0.8321 - val_accuracy: 0.8554\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4611 - accuracy: 0.9943 - val_loss: 0.8444 - val_accuracy: 0.8564\n","Epoch 82/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4657 - accuracy: 0.9920 - val_loss: 0.8610 - val_accuracy: 0.8512\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4571 - accuracy: 0.9964 - val_loss: 0.8398 - val_accuracy: 0.8512\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4517 - accuracy: 0.9974 - val_loss: 0.8367 - val_accuracy: 0.8543\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4511 - accuracy: 0.9979 - val_loss: 0.8430 - val_accuracy: 0.8461\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4493 - accuracy: 0.9979 - val_loss: 0.8451 - val_accuracy: 0.8533\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4490 - accuracy: 0.9964 - val_loss: 0.8409 - val_accuracy: 0.8523\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4446 - accuracy: 0.9979 - val_loss: 0.8456 - val_accuracy: 0.8502\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4448 - accuracy: 0.9974 - val_loss: 0.8478 - val_accuracy: 0.8492\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4409 - accuracy: 0.9977 - val_loss: 0.8430 - val_accuracy: 0.8523\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4403 - accuracy: 0.9977 - val_loss: 0.8564 - val_accuracy: 0.8502\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4378 - accuracy: 0.9979 - val_loss: 0.8462 - val_accuracy: 0.8543\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4363 - accuracy: 0.9982 - val_loss: 0.8575 - val_accuracy: 0.8523\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4373 - accuracy: 0.9982 - val_loss: 0.8513 - val_accuracy: 0.8512\n","Epoch 95/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4333 - accuracy: 0.9984 - val_loss: 0.8442 - val_accuracy: 0.8543\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4316 - accuracy: 0.9984 - val_loss: 0.8471 - val_accuracy: 0.8502\n","Epoch 97/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4294 - accuracy: 0.9987 - val_loss: 0.8487 - val_accuracy: 0.8533\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4290 - accuracy: 0.9982 - val_loss: 0.8534 - val_accuracy: 0.8543\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4267 - accuracy: 0.9984 - val_loss: 0.8505 - val_accuracy: 0.8502\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4250 - accuracy: 0.9990 - val_loss: 0.8565 - val_accuracy: 0.8492\n","{'loss': [0.7964338660240173, 0.7736240029335022, 0.7668360471725464, 0.7574776411056519, 0.7487174868583679, 0.7421264052391052, 0.7470688223838806, 0.737824559211731, 0.7360880374908447, 0.7169353365898132, 0.7059084177017212, 0.7007767558097839, 0.6964771747589111, 0.6945755481719971, 0.6871519088745117, 0.679325520992279, 0.676028311252594, 0.6716997623443604, 0.6648231744766235, 0.6598666906356812, 0.6535266637802124, 0.6497722268104553, 0.6415369510650635, 0.6379075050354004, 0.6343896985054016, 0.6330238580703735, 0.6294558644294739, 0.628290057182312, 0.6184428334236145, 0.6269071102142334, 0.6116335391998291, 0.6005953550338745, 0.6012625694274902, 0.5982398390769958, 0.5926090478897095, 0.5954047441482544, 0.59268718957901, 0.5816278457641602, 0.574733316898346, 0.5728105902671814, 0.5671347379684448, 0.5645667910575867, 0.5612220168113708, 0.570442259311676, 0.5565804839134216, 0.5523307919502258, 0.5457772016525269, 0.5421828031539917, 0.5435850024223328, 0.5376533269882202, 0.533171534538269, 0.5326752662658691, 0.5286390781402588, 0.5241255164146423, 0.5246444940567017, 0.523608386516571, 0.5196170210838318, 0.515478789806366, 0.5108438730239868, 0.5064433217048645, 0.5084495544433594, 0.5024234652519226, 0.5006953477859497, 0.4979752004146576, 0.49426156282424927, 0.4918935298919678, 0.49017030000686646, 0.49076366424560547, 0.4857613146305084, 0.4832156300544739, 0.48437902331352234, 0.4768178462982178, 0.4754070043563843, 0.47325682640075684, 0.4712083637714386, 0.4714835286140442, 0.46875959634780884, 0.4644165337085724, 0.4643767476081848, 0.4633244276046753, 0.4610546827316284, 0.46570515632629395, 0.45709213614463806, 0.451696515083313, 0.4511411786079407, 0.44933655858039856, 0.44901230931282043, 0.44462350010871887, 0.44476041197776794, 0.4408954679965973, 0.44026267528533936, 0.4377664029598236, 0.43627166748046875, 0.43730413913726807, 0.4333474636077881, 0.43161845207214355, 0.4294332265853882, 0.42896395921707153, 0.42671093344688416, 0.42496371269226074], 'accuracy': [0.9113695025444031, 0.9273901581764221, 0.923514187335968, 0.9315245747566223, 0.9335917234420776, 0.9346253275871277, 0.9297157526016235, 0.9328165650367737, 0.9286821484565735, 0.9416020512580872, 0.9465116262435913, 0.94728684425354, 0.949095606803894, 0.948062002658844, 0.9488372206687927, 0.9534883499145508, 0.9529715776443481, 0.9511628150939941, 0.9558139443397522, 0.9578811526298523, 0.9589147567749023, 0.9578811526298523, 0.962273895740509, 0.9638242721557617, 0.9596899151802063, 0.962273895740509, 0.960465133190155, 0.9596899151802063, 0.9648578763008118, 0.9583979249000549, 0.9661498665809631, 0.9702842235565186, 0.9715762138366699, 0.970801055431366, 0.9733850359916687, 0.9684754610061646, 0.9702842235565186, 0.9710594415664673, 0.9762274026870728, 0.9757105708122253, 0.9798449873924255, 0.9806201457977295, 0.9772610068321228, 0.9720930457115173, 0.9780361652374268, 0.9785529971122742, 0.9811369776725769, 0.9837209582328796, 0.9834625124931335, 0.983979344367981, 0.9847545027732849, 0.9829457402229309, 0.983979344367981, 0.986821711063385, 0.9847545027732849, 0.9860464930534363, 0.9855297207832336, 0.9865633249282837, 0.9881137013435364, 0.9899224638938904, 0.9881137013435364, 0.9914728403091431, 0.9904392957687378, 0.9909560680389404, 0.9927648305892944, 0.9914728403091431, 0.9922480583190918, 0.9906976819038391, 0.9919896721839905, 0.9932816624641418, 0.9932816624641418, 0.9937984347343445, 0.9940568208694458, 0.9945736527442932, 0.9950904250144958, 0.9950904250144958, 0.9963824152946472, 0.9953488111495972, 0.9953488111495972, 0.9948320388793945, 0.9943152666091919, 0.9919896721839905, 0.9963824152946472, 0.9974160194396973, 0.9979327917098999, 0.9979327917098999, 0.9963824152946472, 0.9979327917098999, 0.9974160194396973, 0.9976744055747986, 0.9976744055747986, 0.9979327917098999, 0.998191237449646, 0.998191237449646, 0.9984496235847473, 0.9984496235847473, 0.9987080097198486, 0.998191237449646, 0.9984496235847473, 0.99896639585495], 'val_loss': [1.2649885416030884, 1.2566057443618774, 1.2481651306152344, 1.224352478981018, 1.201744794845581, 1.1749621629714966, 1.1625535488128662, 1.14225172996521, 1.1065645217895508, 1.0745316743850708, 1.046339988708496, 1.0213760137557983, 0.996279239654541, 0.9802736043930054, 0.9386342167854309, 0.92176753282547, 0.906467616558075, 0.8710269927978516, 0.8613104224205017, 0.8616689443588257, 0.8576252460479736, 0.8411560654640198, 0.8336376547813416, 0.832144021987915, 0.8332322239875793, 0.8340672850608826, 0.8482510447502136, 0.835186779499054, 0.8618203401565552, 0.8313518762588501, 0.8374429941177368, 0.8343092799186707, 0.8396355509757996, 0.8300873041152954, 0.8313051462173462, 0.8391643166542053, 0.851706326007843, 0.8266383409500122, 0.8268999457359314, 0.8284167647361755, 0.837185800075531, 0.830621063709259, 0.8852860927581787, 0.8282037377357483, 0.8308985829353333, 0.8232178092002869, 0.8278020620346069, 0.8257681131362915, 0.8296370506286621, 0.8251787424087524, 0.8260162472724915, 0.8292272090911865, 0.8238273859024048, 0.8247337937355042, 0.8337410092353821, 0.841679573059082, 0.836784839630127, 0.8288273215293884, 0.833258867263794, 0.8411747813224792, 0.8391377329826355, 0.8395068645477295, 0.8251469731330872, 0.8422814607620239, 0.830612063407898, 0.8277797698974609, 0.8339967727661133, 0.8373775482177734, 0.8381897211074829, 0.8347952961921692, 0.830171525478363, 0.8335508704185486, 0.8312942385673523, 0.8376481533050537, 0.8397096395492554, 0.8431628346443176, 0.8557707667350769, 0.8338308334350586, 0.8414716720581055, 0.8321401476860046, 0.8444075584411621, 0.8610363602638245, 0.8398391604423523, 0.8366742730140686, 0.8429986834526062, 0.845146656036377, 0.8408909440040588, 0.8455970287322998, 0.8477506637573242, 0.8430278897285461, 0.8563945889472961, 0.8462087512016296, 0.8574776649475098, 0.8512856960296631, 0.844195544719696, 0.8471463322639465, 0.8486899733543396, 0.8534244298934937, 0.8504961133003235, 0.8565128445625305], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.5061983466148376, 0.5464876294136047, 0.6404958963394165, 0.6353305578231812, 0.6756198406219482, 0.78925621509552, 0.8285123705863953, 0.8450413346290588, 0.8481404781341553, 0.8502066135406494, 0.83574378490448, 0.8615702390670776, 0.85537189245224, 0.8481404781341553, 0.8615702390670776, 0.8657024502754211, 0.8564049601554871, 0.8491735458374023, 0.8636363744735718, 0.8615702390670776, 0.8605371713638306, 0.8657024502754211, 0.8657024502754211, 0.8533057570457458, 0.8605371713638306, 0.8522727489471436, 0.8646694421768188, 0.8626033067703247, 0.8605371713638306, 0.8615702390670776, 0.8595041036605835, 0.8626033067703247, 0.8574380278587341, 0.8564049601554871, 0.8626033067703247, 0.8605371713638306, 0.8626033067703247, 0.8522727489471436, 0.8605371713638306, 0.8316115736961365, 0.8595041036605835, 0.8574380278587341, 0.85537189245224, 0.8574380278587341, 0.8595041036605835, 0.8615702390670776, 0.8574380278587341, 0.8595041036605835, 0.8574380278587341, 0.8574380278587341, 0.8564049601554871, 0.8595041036605835, 0.8584710955619812, 0.8584710955619812, 0.8564049601554871, 0.8543388247489929, 0.8512396812438965, 0.8522727489471436, 0.8574380278587341, 0.8471074104309082, 0.8512396812438965, 0.8543388247489929, 0.8584710955619812, 0.8522727489471436, 0.8543388247489929, 0.8564049601554871, 0.8533057570457458, 0.8502066135406494, 0.8522727489471436, 0.8543388247489929, 0.8502066135406494, 0.8533057570457458, 0.85537189245224, 0.8471074104309082, 0.8491735458374023, 0.8533057570457458, 0.85537189245224, 0.8564049601554871, 0.8512396812438965, 0.8512396812438965, 0.8543388247489929, 0.8460744023323059, 0.8533057570457458, 0.8522727489471436, 0.8502066135406494, 0.8491735458374023, 0.8522727489471436, 0.8502066135406494, 0.8543388247489929, 0.8522727489471436, 0.8512396812438965, 0.8543388247489929, 0.8502066135406494, 0.8533057570457458, 0.8543388247489929, 0.8502066135406494, 0.8491735458374023]}\n","32/32 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 4s 32ms/step - loss: 0.4927 - accuracy: 0.9717 - val_loss: 1.1083 - val_accuracy: 0.4871\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 12ms/step - loss: 0.4632 - accuracy: 0.9871 - val_loss: 1.1061 - val_accuracy: 0.4860\n","Epoch 3/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4637 - accuracy: 0.9817 - val_loss: 1.0971 - val_accuracy: 0.4925\n","Epoch 4/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4564 - accuracy: 0.9881 - val_loss: 1.0835 - val_accuracy: 0.5022\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4581 - accuracy: 0.9895 - val_loss: 1.0714 - val_accuracy: 0.5108\n","Epoch 6/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4507 - accuracy: 0.9903 - val_loss: 1.0325 - val_accuracy: 0.5582\n","Epoch 7/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4431 - accuracy: 0.9925 - val_loss: 1.0016 - val_accuracy: 0.6013\n","Epoch 8/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4424 - accuracy: 0.9941 - val_loss: 0.9423 - val_accuracy: 0.7188\n","Epoch 9/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4384 - accuracy: 0.9946 - val_loss: 0.9167 - val_accuracy: 0.7489\n","Epoch 10/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4355 - accuracy: 0.9943 - val_loss: 0.8824 - val_accuracy: 0.7866\n","Epoch 11/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4340 - accuracy: 0.9957 - val_loss: 0.8362 - val_accuracy: 0.8459\n","Epoch 12/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4298 - accuracy: 0.9960 - val_loss: 0.8323 - val_accuracy: 0.8103\n","Epoch 13/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4343 - accuracy: 0.9949 - val_loss: 0.7931 - val_accuracy: 0.8470\n","Epoch 14/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4306 - accuracy: 0.9962 - val_loss: 0.7283 - val_accuracy: 0.9009\n","Epoch 15/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4282 - accuracy: 0.9952 - val_loss: 0.7070 - val_accuracy: 0.9019\n","Epoch 16/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4226 - accuracy: 0.9978 - val_loss: 0.6670 - val_accuracy: 0.9235\n","Epoch 17/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4216 - accuracy: 0.9976 - val_loss: 0.6504 - val_accuracy: 0.9213\n","Epoch 18/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4189 - accuracy: 0.9976 - val_loss: 0.6300 - val_accuracy: 0.9267\n","Epoch 19/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4188 - accuracy: 0.9984 - val_loss: 0.6213 - val_accuracy: 0.9256\n","Epoch 20/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4168 - accuracy: 0.9978 - val_loss: 0.6211 - val_accuracy: 0.9203\n","Epoch 21/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4136 - accuracy: 0.9978 - val_loss: 0.6095 - val_accuracy: 0.9213\n","Epoch 22/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4134 - accuracy: 0.9976 - val_loss: 0.6086 - val_accuracy: 0.9235\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4132 - accuracy: 0.9978 - val_loss: 0.6109 - val_accuracy: 0.9192\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4097 - accuracy: 0.9984 - val_loss: 0.6005 - val_accuracy: 0.9224\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4086 - accuracy: 0.9987 - val_loss: 0.6031 - val_accuracy: 0.9256\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4063 - accuracy: 0.9989 - val_loss: 0.6111 - val_accuracy: 0.9235\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4051 - accuracy: 0.9989 - val_loss: 0.6093 - val_accuracy: 0.9235\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4025 - accuracy: 0.9989 - val_loss: 0.6150 - val_accuracy: 0.9203\n","Epoch 29/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4028 - accuracy: 0.9992 - val_loss: 0.6170 - val_accuracy: 0.9224\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4007 - accuracy: 0.9989 - val_loss: 0.6185 - val_accuracy: 0.9224\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4032 - accuracy: 0.9965 - val_loss: 0.6249 - val_accuracy: 0.9224\n","Epoch 32/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3992 - accuracy: 0.9981 - val_loss: 0.6188 - val_accuracy: 0.9224\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3960 - accuracy: 0.9992 - val_loss: 0.6236 - val_accuracy: 0.9181\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3944 - accuracy: 0.9992 - val_loss: 0.6265 - val_accuracy: 0.9192\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3931 - accuracy: 0.9995 - val_loss: 0.6228 - val_accuracy: 0.9235\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3924 - accuracy: 0.9995 - val_loss: 0.6261 - val_accuracy: 0.9235\n","Epoch 37/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3905 - accuracy: 0.9989 - val_loss: 0.6234 - val_accuracy: 0.9181\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3892 - accuracy: 0.9995 - val_loss: 0.6250 - val_accuracy: 0.9235\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3888 - accuracy: 0.9995 - val_loss: 0.6263 - val_accuracy: 0.9213\n","Epoch 40/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3870 - accuracy: 0.9992 - val_loss: 0.6259 - val_accuracy: 0.9203\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3856 - accuracy: 0.9992 - val_loss: 0.6231 - val_accuracy: 0.9213\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3845 - accuracy: 0.9997 - val_loss: 0.6286 - val_accuracy: 0.9235\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3830 - accuracy: 0.9995 - val_loss: 0.6277 - val_accuracy: 0.9224\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3817 - accuracy: 0.9992 - val_loss: 0.6252 - val_accuracy: 0.9224\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3811 - accuracy: 0.9995 - val_loss: 0.6323 - val_accuracy: 0.9203\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3790 - accuracy: 0.9997 - val_loss: 0.6437 - val_accuracy: 0.9084\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3779 - accuracy: 0.9995 - val_loss: 0.6277 - val_accuracy: 0.9203\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3769 - accuracy: 0.9997 - val_loss: 0.6315 - val_accuracy: 0.9170\n","Epoch 49/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3754 - accuracy: 0.9995 - val_loss: 0.6318 - val_accuracy: 0.9192\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3747 - accuracy: 0.9995 - val_loss: 0.6290 - val_accuracy: 0.9192\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3724 - accuracy: 0.9997 - val_loss: 0.6294 - val_accuracy: 0.9181\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3719 - accuracy: 0.9997 - val_loss: 0.6264 - val_accuracy: 0.9267\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3706 - accuracy: 0.9992 - val_loss: 0.6294 - val_accuracy: 0.9246\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3699 - accuracy: 0.9995 - val_loss: 0.6292 - val_accuracy: 0.9213\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3690 - accuracy: 0.9997 - val_loss: 0.6550 - val_accuracy: 0.9052\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3670 - accuracy: 1.0000 - val_loss: 0.6288 - val_accuracy: 0.9149\n","Epoch 57/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3652 - accuracy: 0.9997 - val_loss: 0.6329 - val_accuracy: 0.9170\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3643 - accuracy: 0.9997 - val_loss: 0.6313 - val_accuracy: 0.9116\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3628 - accuracy: 1.0000 - val_loss: 0.6282 - val_accuracy: 0.9149\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3614 - accuracy: 1.0000 - val_loss: 0.6300 - val_accuracy: 0.9159\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3601 - accuracy: 1.0000 - val_loss: 0.6312 - val_accuracy: 0.9159\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3590 - accuracy: 1.0000 - val_loss: 0.6270 - val_accuracy: 0.9149\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3587 - accuracy: 1.0000 - val_loss: 0.6359 - val_accuracy: 0.9084\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3573 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.9127\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3557 - accuracy: 1.0000 - val_loss: 0.6315 - val_accuracy: 0.9138\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3542 - accuracy: 1.0000 - val_loss: 0.6387 - val_accuracy: 0.9052\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3533 - accuracy: 0.9997 - val_loss: 0.6289 - val_accuracy: 0.9213\n","Epoch 68/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3522 - accuracy: 1.0000 - val_loss: 0.6313 - val_accuracy: 0.9159\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3505 - accuracy: 1.0000 - val_loss: 0.6308 - val_accuracy: 0.9095\n","Epoch 70/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3498 - accuracy: 0.9997 - val_loss: 0.6252 - val_accuracy: 0.9149\n","Epoch 71/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3481 - accuracy: 1.0000 - val_loss: 0.6333 - val_accuracy: 0.9095\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3476 - accuracy: 1.0000 - val_loss: 0.6306 - val_accuracy: 0.9192\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3455 - accuracy: 1.0000 - val_loss: 0.6251 - val_accuracy: 0.9159\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3445 - accuracy: 1.0000 - val_loss: 0.6316 - val_accuracy: 0.9159\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3434 - accuracy: 1.0000 - val_loss: 0.6283 - val_accuracy: 0.9181\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3421 - accuracy: 1.0000 - val_loss: 0.6301 - val_accuracy: 0.9203\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3415 - accuracy: 1.0000 - val_loss: 0.6531 - val_accuracy: 0.9019\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3405 - accuracy: 0.9997 - val_loss: 0.6259 - val_accuracy: 0.9138\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3385 - accuracy: 1.0000 - val_loss: 0.6231 - val_accuracy: 0.9127\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3375 - accuracy: 1.0000 - val_loss: 0.6242 - val_accuracy: 0.9095\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3358 - accuracy: 1.0000 - val_loss: 0.6246 - val_accuracy: 0.9138\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3350 - accuracy: 1.0000 - val_loss: 0.6268 - val_accuracy: 0.9138\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3335 - accuracy: 1.0000 - val_loss: 0.6236 - val_accuracy: 0.9127\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3322 - accuracy: 1.0000 - val_loss: 0.6248 - val_accuracy: 0.9095\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3309 - accuracy: 1.0000 - val_loss: 0.6257 - val_accuracy: 0.9062\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3298 - accuracy: 1.0000 - val_loss: 0.6227 - val_accuracy: 0.9127\n","Epoch 87/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3285 - accuracy: 1.0000 - val_loss: 0.6295 - val_accuracy: 0.9159\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3273 - accuracy: 1.0000 - val_loss: 0.6285 - val_accuracy: 0.9019\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3259 - accuracy: 1.0000 - val_loss: 0.6248 - val_accuracy: 0.9116\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3249 - accuracy: 1.0000 - val_loss: 0.6245 - val_accuracy: 0.9084\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3236 - accuracy: 1.0000 - val_loss: 0.6213 - val_accuracy: 0.9149\n","Epoch 92/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3221 - accuracy: 1.0000 - val_loss: 0.6188 - val_accuracy: 0.9116\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3208 - accuracy: 1.0000 - val_loss: 0.6227 - val_accuracy: 0.9019\n","Epoch 94/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3198 - accuracy: 1.0000 - val_loss: 0.6211 - val_accuracy: 0.9127\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3186 - accuracy: 1.0000 - val_loss: 0.6283 - val_accuracy: 0.9019\n","Epoch 96/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3172 - accuracy: 1.0000 - val_loss: 0.6290 - val_accuracy: 0.9041\n","Epoch 97/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3167 - accuracy: 0.9997 - val_loss: 0.6197 - val_accuracy: 0.9149\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3149 - accuracy: 1.0000 - val_loss: 0.6180 - val_accuracy: 0.9127\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3133 - accuracy: 1.0000 - val_loss: 0.6145 - val_accuracy: 0.9095\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3125 - accuracy: 1.0000 - val_loss: 0.6155 - val_accuracy: 0.9095\n","{'loss': [0.492702454328537, 0.4631638824939728, 0.46372124552726746, 0.45642659068107605, 0.4580938220024109, 0.45065250992774963, 0.44305431842803955, 0.4423847198486328, 0.43841516971588135, 0.4354926347732544, 0.4340152144432068, 0.42983177304267883, 0.4342869520187378, 0.4306371212005615, 0.4281945824623108, 0.4226173162460327, 0.4215645492076874, 0.4189152419567108, 0.41875359416007996, 0.416798859834671, 0.41358256340026855, 0.41343554854393005, 0.4132140278816223, 0.40973585844039917, 0.4086418151855469, 0.40633314847946167, 0.4050542116165161, 0.40251678228378296, 0.4027787446975708, 0.4006664454936981, 0.40316104888916016, 0.39915338158607483, 0.3960458040237427, 0.39440587162971497, 0.39313533902168274, 0.39235907793045044, 0.3904598355293274, 0.3891797959804535, 0.38881251215934753, 0.3869584798812866, 0.385625958442688, 0.3845159411430359, 0.38298553228378296, 0.3817211985588074, 0.381061315536499, 0.3789564371109009, 0.37792301177978516, 0.37693509459495544, 0.3753963112831116, 0.3746938705444336, 0.3723636269569397, 0.3718685209751129, 0.370567262172699, 0.3699074387550354, 0.3689892590045929, 0.36701682209968567, 0.3652130663394928, 0.3642875552177429, 0.3627747595310211, 0.36138081550598145, 0.36007848381996155, 0.3589746356010437, 0.3586800992488861, 0.35729336738586426, 0.355669230222702, 0.3542492091655731, 0.35333436727523804, 0.3521960973739624, 0.35051119327545166, 0.3498036861419678, 0.3480735421180725, 0.3476451635360718, 0.34554803371429443, 0.34445247054100037, 0.34343940019607544, 0.34209874272346497, 0.3414769768714905, 0.3404562771320343, 0.33849915862083435, 0.33753708004951477, 0.33584311604499817, 0.33503031730651855, 0.3334791660308838, 0.3321702778339386, 0.3309342861175537, 0.32982784509658813, 0.32848167419433594, 0.3272608518600464, 0.32594045996665955, 0.324917197227478, 0.32361143827438354, 0.32207411527633667, 0.3207850158214569, 0.31984996795654297, 0.31857627630233765, 0.31723257899284363, 0.31666308641433716, 0.31493523716926575, 0.31334784626960754, 0.31251612305641174], 'accuracy': [0.9717133641242981, 0.9870689511299133, 0.9816810488700867, 0.9881465435028076, 0.9894935488700867, 0.9903017282485962, 0.9924569129943848, 0.9940732717514038, 0.9946120977401733, 0.9943426847457886, 0.9956896305084229, 0.9959590435028076, 0.9948814511299133, 0.9962284564971924, 0.9951508641242981, 0.9978448152542114, 0.9975754022598267, 0.9975754022598267, 0.998383641242981, 0.9978448152542114, 0.9978448152542114, 0.9975754022598267, 0.9978448152542114, 0.998383641242981, 0.998652994632721, 0.9989224076271057, 0.9989224076271057, 0.9989224076271057, 0.9991918206214905, 0.9989224076271057, 0.9964978694915771, 0.9981142282485962, 0.9991918206214905, 0.9991918206214905, 0.9994612336158752, 0.9994612336158752, 0.9989224076271057, 0.9994612336158752, 0.9994612336158752, 0.9991918206214905, 0.9991918206214905, 0.9997305870056152, 0.9994612336158752, 0.9991918206214905, 0.9994612336158752, 0.9997305870056152, 0.9994612336158752, 0.9997305870056152, 0.9994612336158752, 0.9994612336158752, 0.9997305870056152, 0.9997305870056152, 0.9991918206214905, 0.9994612336158752, 0.9997305870056152, 1.0, 0.9997305870056152, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0], 'val_loss': [1.108269214630127, 1.1061217784881592, 1.0971357822418213, 1.0835086107254028, 1.0713692903518677, 1.0325136184692383, 1.0015869140625, 0.9423065781593323, 0.9167342185974121, 0.8823602199554443, 0.8361994028091431, 0.832284688949585, 0.7931393384933472, 0.7283293604850769, 0.7069979310035706, 0.6669999361038208, 0.6503639221191406, 0.6300361752510071, 0.6213234066963196, 0.6211101412773132, 0.6094695925712585, 0.6085734367370605, 0.6109434962272644, 0.6005222201347351, 0.603062093257904, 0.6110726594924927, 0.6093354225158691, 0.615024209022522, 0.6170382499694824, 0.6184751987457275, 0.6249110102653503, 0.618832528591156, 0.6236439943313599, 0.6265424489974976, 0.6227564215660095, 0.6260697841644287, 0.6233972907066345, 0.6250309944152832, 0.6263245940208435, 0.6259322166442871, 0.6231224536895752, 0.6285566687583923, 0.6276822686195374, 0.6252015829086304, 0.6322904229164124, 0.6436899900436401, 0.6276857852935791, 0.6314605474472046, 0.6318386793136597, 0.6290113925933838, 0.6293804049491882, 0.6263867020606995, 0.6294453740119934, 0.6291794180870056, 0.6550194025039673, 0.6288432478904724, 0.632872462272644, 0.6312865018844604, 0.6281687021255493, 0.6300210356712341, 0.6311599612236023, 0.6270474791526794, 0.6358757615089417, 0.6317325830459595, 0.6314804553985596, 0.6387172341346741, 0.6289026141166687, 0.6313276886940002, 0.6308172345161438, 0.6252422332763672, 0.6333068609237671, 0.6306052803993225, 0.6251074075698853, 0.6315836310386658, 0.6282838582992554, 0.6300716400146484, 0.6530553698539734, 0.6258824467658997, 0.6230833530426025, 0.6241549849510193, 0.6246454119682312, 0.6268312931060791, 0.6235805749893188, 0.6248035430908203, 0.6257201433181763, 0.6227242946624756, 0.6295498609542847, 0.6285491585731506, 0.624830424785614, 0.6245322227478027, 0.6213459968566895, 0.6187868714332581, 0.6226505637168884, 0.6210860013961792, 0.6282594203948975, 0.6290023922920227, 0.61965411901474, 0.6180460453033447, 0.614509642124176, 0.6154838800430298], 'val_accuracy': [0.48706895112991333, 0.48599138855934143, 0.4924568831920624, 0.5021551847457886, 0.5107758641242981, 0.5581896305084229, 0.6012930870056152, 0.71875, 0.7489224076271057, 0.7866379022598267, 0.8459051847457886, 0.8103448152542114, 0.8469827771186829, 0.9008620977401733, 0.9019396305084229, 0.923491358757019, 0.9213362336158752, 0.9267241358757019, 0.9256465435028076, 0.920258641242981, 0.9213362336158752, 0.923491358757019, 0.9191810488700867, 0.9224137663841248, 0.9256465435028076, 0.923491358757019, 0.923491358757019, 0.920258641242981, 0.9224137663841248, 0.9224137663841248, 0.9224137663841248, 0.9224137663841248, 0.9181034564971924, 0.9191810488700867, 0.923491358757019, 0.923491358757019, 0.9181034564971924, 0.923491358757019, 0.9213362336158752, 0.920258641242981, 0.9213362336158752, 0.923491358757019, 0.9224137663841248, 0.9224137663841248, 0.920258641242981, 0.9084051847457886, 0.920258641242981, 0.9170258641242981, 0.9191810488700867, 0.9191810488700867, 0.9181034564971924, 0.9267241358757019, 0.9245689511299133, 0.9213362336158752, 0.9051724076271057, 0.9148706793785095, 0.9170258641242981, 0.9116379022598267, 0.9148706793785095, 0.9159482717514038, 0.9159482717514038, 0.9148706793785095, 0.9084051847457886, 0.912715494632721, 0.9137930870056152, 0.9051724076271057, 0.9213362336158752, 0.9159482717514038, 0.9094827771186829, 0.9148706793785095, 0.9094827771186829, 0.9191810488700867, 0.9159482717514038, 0.9159482717514038, 0.9181034564971924, 0.920258641242981, 0.9019396305084229, 0.9137930870056152, 0.912715494632721, 0.9094827771186829, 0.9137930870056152, 0.9137930870056152, 0.912715494632721, 0.9094827771186829, 0.90625, 0.912715494632721, 0.9159482717514038, 0.9019396305084229, 0.9116379022598267, 0.9084051847457886, 0.9148706793785095, 0.9116379022598267, 0.9019396305084229, 0.912715494632721, 0.9019396305084229, 0.9040948152542114, 0.9148706793785095, 0.912715494632721, 0.9094827771186829, 0.9094827771186829]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.4965 - accuracy: 0.9720"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 4s 43ms/step - loss: 0.4965 - accuracy: 0.9720 - val_loss: 1.1058 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4804 - accuracy: 0.9799 - val_loss: 1.0971 - val_accuracy: 0.4977\n","Epoch 3/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.4675 - accuracy: 0.9833 - val_loss: 1.0833 - val_accuracy: 0.5079\n","Epoch 4/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4645 - accuracy: 0.9864 - val_loss: 1.0751 - val_accuracy: 0.5192\n","Epoch 5/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.4663 - accuracy: 0.9844 - val_loss: 1.0501 - val_accuracy: 0.5475\n","Epoch 6/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.4582 - accuracy: 0.9881 - val_loss: 1.0140 - val_accuracy: 0.6063\n","Epoch 7/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4625 - accuracy: 0.9859 - val_loss: 0.9977 - val_accuracy: 0.6244\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4511 - accuracy: 0.9912 - val_loss: 0.9641 - val_accuracy: 0.6855\n","Epoch 9/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4491 - accuracy: 0.9929 - val_loss: 0.9154 - val_accuracy: 0.7658\n","Epoch 10/100\n","28/28 [==============================] - 3s 119ms/step - loss: 0.4444 - accuracy: 0.9926 - val_loss: 0.8667 - val_accuracy: 0.8529\n","Epoch 11/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4411 - accuracy: 0.9946 - val_loss: 0.8516 - val_accuracy: 0.8348\n","Epoch 12/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4397 - accuracy: 0.9941 - val_loss: 0.8023 - val_accuracy: 0.8869\n","Epoch 13/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4363 - accuracy: 0.9955 - val_loss: 0.7754 - val_accuracy: 0.8903\n","Epoch 14/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4341 - accuracy: 0.9958 - val_loss: 0.7389 - val_accuracy: 0.9106\n","Epoch 15/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4325 - accuracy: 0.9955 - val_loss: 0.7219 - val_accuracy: 0.9027\n","Epoch 16/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4302 - accuracy: 0.9958 - val_loss: 0.6973 - val_accuracy: 0.9005\n","Epoch 17/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4287 - accuracy: 0.9958 - val_loss: 0.6857 - val_accuracy: 0.8948\n","Epoch 18/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4278 - accuracy: 0.9969 - val_loss: 0.6481 - val_accuracy: 0.9140\n","Epoch 19/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4242 - accuracy: 0.9969 - val_loss: 0.6385 - val_accuracy: 0.9152\n","Epoch 20/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4213 - accuracy: 0.9972 - val_loss: 0.6220 - val_accuracy: 0.9197\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4214 - accuracy: 0.9969 - val_loss: 0.6152 - val_accuracy: 0.9197\n","Epoch 22/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4186 - accuracy: 0.9972 - val_loss: 0.6106 - val_accuracy: 0.9219\n","Epoch 23/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4171 - accuracy: 0.9975 - val_loss: 0.6137 - val_accuracy: 0.9163\n","Epoch 24/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4149 - accuracy: 0.9977 - val_loss: 0.6055 - val_accuracy: 0.9186\n","Epoch 25/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4130 - accuracy: 0.9975 - val_loss: 0.6055 - val_accuracy: 0.9208\n","Epoch 26/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4115 - accuracy: 0.9983 - val_loss: 0.6087 - val_accuracy: 0.9163\n","Epoch 27/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4092 - accuracy: 0.9980 - val_loss: 0.6176 - val_accuracy: 0.9140\n","Epoch 28/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4088 - accuracy: 0.9975 - val_loss: 0.6134 - val_accuracy: 0.9219\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4071 - accuracy: 0.9980 - val_loss: 0.6309 - val_accuracy: 0.9061\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4056 - accuracy: 0.9986 - val_loss: 0.6135 - val_accuracy: 0.9186\n","Epoch 31/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4035 - accuracy: 0.9989 - val_loss: 0.6327 - val_accuracy: 0.9118\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4023 - accuracy: 0.9986 - val_loss: 0.6183 - val_accuracy: 0.9118\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4026 - accuracy: 0.9986 - val_loss: 0.6738 - val_accuracy: 0.9016\n","Epoch 34/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4050 - accuracy: 0.9972 - val_loss: 0.6408 - val_accuracy: 0.9038\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3995 - accuracy: 0.9994 - val_loss: 0.6246 - val_accuracy: 0.9174\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3968 - accuracy: 0.9989 - val_loss: 0.6220 - val_accuracy: 0.9186\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3964 - accuracy: 0.9989 - val_loss: 0.6228 - val_accuracy: 0.9129\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3961 - accuracy: 0.9983 - val_loss: 0.6201 - val_accuracy: 0.9140\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3929 - accuracy: 0.9986 - val_loss: 0.6276 - val_accuracy: 0.9106\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3915 - accuracy: 0.9989 - val_loss: 0.6262 - val_accuracy: 0.9174\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3900 - accuracy: 0.9992 - val_loss: 0.6235 - val_accuracy: 0.9219\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3900 - accuracy: 0.9992 - val_loss: 0.6374 - val_accuracy: 0.9050\n","Epoch 43/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3888 - accuracy: 0.9997 - val_loss: 0.6230 - val_accuracy: 0.9163\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3865 - accuracy: 0.9992 - val_loss: 0.6438 - val_accuracy: 0.9084\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3856 - accuracy: 0.9994 - val_loss: 0.6249 - val_accuracy: 0.9174\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3835 - accuracy: 0.9989 - val_loss: 0.6311 - val_accuracy: 0.9186\n","Epoch 47/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3818 - accuracy: 0.9997 - val_loss: 0.6356 - val_accuracy: 0.9118\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3821 - accuracy: 0.9992 - val_loss: 0.6233 - val_accuracy: 0.9129\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3802 - accuracy: 0.9989 - val_loss: 0.6288 - val_accuracy: 0.9140\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3792 - accuracy: 0.9992 - val_loss: 0.6594 - val_accuracy: 0.9038\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3766 - accuracy: 0.9994 - val_loss: 0.6209 - val_accuracy: 0.9084\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3751 - accuracy: 1.0000 - val_loss: 0.6277 - val_accuracy: 0.9174\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3735 - accuracy: 1.0000 - val_loss: 0.6422 - val_accuracy: 0.9106\n","Epoch 54/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3723 - accuracy: 0.9994 - val_loss: 0.6362 - val_accuracy: 0.9163\n","Epoch 55/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3710 - accuracy: 0.9997 - val_loss: 0.6301 - val_accuracy: 0.9118\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3703 - accuracy: 0.9994 - val_loss: 0.6278 - val_accuracy: 0.9095\n","Epoch 57/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3687 - accuracy: 1.0000 - val_loss: 0.6233 - val_accuracy: 0.9106\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3674 - accuracy: 0.9997 - val_loss: 0.6396 - val_accuracy: 0.9027\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3661 - accuracy: 1.0000 - val_loss: 0.6250 - val_accuracy: 0.9106\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3655 - accuracy: 0.9994 - val_loss: 0.6383 - val_accuracy: 0.9050\n","Epoch 61/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3650 - accuracy: 1.0000 - val_loss: 0.6389 - val_accuracy: 0.9072\n","Epoch 62/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3638 - accuracy: 0.9997 - val_loss: 0.6951 - val_accuracy: 0.8971\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3667 - accuracy: 1.0000 - val_loss: 0.6393 - val_accuracy: 0.9118\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3607 - accuracy: 0.9997 - val_loss: 0.6323 - val_accuracy: 0.9129\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3591 - accuracy: 0.9997 - val_loss: 0.6200 - val_accuracy: 0.9118\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3579 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 0.9084\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3567 - accuracy: 1.0000 - val_loss: 0.6259 - val_accuracy: 0.9106\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3556 - accuracy: 1.0000 - val_loss: 0.6243 - val_accuracy: 0.9095\n","Epoch 69/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3545 - accuracy: 1.0000 - val_loss: 0.6215 - val_accuracy: 0.9084\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3536 - accuracy: 1.0000 - val_loss: 0.6234 - val_accuracy: 0.9106\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3525 - accuracy: 0.9997 - val_loss: 0.6262 - val_accuracy: 0.9140\n","Epoch 72/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3509 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 0.9061\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3504 - accuracy: 1.0000 - val_loss: 0.6239 - val_accuracy: 0.9163\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3486 - accuracy: 1.0000 - val_loss: 0.6332 - val_accuracy: 0.9118\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3479 - accuracy: 0.9997 - val_loss: 0.6296 - val_accuracy: 0.9140\n","Epoch 76/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3463 - accuracy: 1.0000 - val_loss: 0.6347 - val_accuracy: 0.9129\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3456 - accuracy: 0.9997 - val_loss: 0.6208 - val_accuracy: 0.9095\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3444 - accuracy: 1.0000 - val_loss: 0.6390 - val_accuracy: 0.9118\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3432 - accuracy: 1.0000 - val_loss: 0.6285 - val_accuracy: 0.9084\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3419 - accuracy: 1.0000 - val_loss: 0.6341 - val_accuracy: 0.9084\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3406 - accuracy: 1.0000 - val_loss: 0.6256 - val_accuracy: 0.9106\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3395 - accuracy: 1.0000 - val_loss: 0.6289 - val_accuracy: 0.9095\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3382 - accuracy: 1.0000 - val_loss: 0.6233 - val_accuracy: 0.9072\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3374 - accuracy: 1.0000 - val_loss: 0.6445 - val_accuracy: 0.9061\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3364 - accuracy: 1.0000 - val_loss: 0.6202 - val_accuracy: 0.9050\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3352 - accuracy: 1.0000 - val_loss: 0.6287 - val_accuracy: 0.9050\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3338 - accuracy: 1.0000 - val_loss: 0.6295 - val_accuracy: 0.9118\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3327 - accuracy: 1.0000 - val_loss: 0.6326 - val_accuracy: 0.9106\n","Epoch 89/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3315 - accuracy: 1.0000 - val_loss: 0.6173 - val_accuracy: 0.9084\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3301 - accuracy: 1.0000 - val_loss: 0.6278 - val_accuracy: 0.9084\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3289 - accuracy: 1.0000 - val_loss: 0.6231 - val_accuracy: 0.9061\n","Epoch 92/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3278 - accuracy: 1.0000 - val_loss: 0.6143 - val_accuracy: 0.9005\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3267 - accuracy: 1.0000 - val_loss: 0.6216 - val_accuracy: 0.9072\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3256 - accuracy: 1.0000 - val_loss: 0.6131 - val_accuracy: 0.9038\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3245 - accuracy: 1.0000 - val_loss: 0.6194 - val_accuracy: 0.9061\n","Epoch 96/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3232 - accuracy: 1.0000 - val_loss: 0.6114 - val_accuracy: 0.9061\n","Epoch 97/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3221 - accuracy: 1.0000 - val_loss: 0.6407 - val_accuracy: 0.9061\n","Epoch 98/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3208 - accuracy: 1.0000 - val_loss: 0.6134 - val_accuracy: 0.9038\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3194 - accuracy: 1.0000 - val_loss: 0.6138 - val_accuracy: 0.9072\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3184 - accuracy: 1.0000 - val_loss: 0.6128 - val_accuracy: 0.9061\n","{'loss': [0.4965267777442932, 0.48040851950645447, 0.46746787428855896, 0.46448761224746704, 0.4663088619709015, 0.4581511318683624, 0.46248674392700195, 0.45113739371299744, 0.4491075873374939, 0.44444435834884644, 0.4411497116088867, 0.43970805406570435, 0.4362753629684448, 0.43411844968795776, 0.4325049817562103, 0.4301840364933014, 0.428718626499176, 0.42777392268180847, 0.4242284893989563, 0.42125487327575684, 0.4213980436325073, 0.4186164438724518, 0.41710102558135986, 0.41490986943244934, 0.4129793047904968, 0.41150081157684326, 0.4091610908508301, 0.4088197648525238, 0.40710169076919556, 0.40559080243110657, 0.4035419523715973, 0.40225040912628174, 0.4025726020336151, 0.4049836993217468, 0.3995330333709717, 0.39676567912101746, 0.3963642418384552, 0.39607036113739014, 0.3929279148578644, 0.39145392179489136, 0.38995760679244995, 0.39003002643585205, 0.38877496123313904, 0.3865482807159424, 0.3856365978717804, 0.3835177421569824, 0.3817873001098633, 0.38210877776145935, 0.3801679313182831, 0.3791968822479248, 0.3765846788883209, 0.3750886619091034, 0.3734854459762573, 0.37226012349128723, 0.37102577090263367, 0.3703174293041229, 0.36873114109039307, 0.3673601448535919, 0.366108238697052, 0.36545491218566895, 0.36497217416763306, 0.3637509047985077, 0.36665186285972595, 0.3607408106327057, 0.3591339588165283, 0.35789769887924194, 0.3566960394382477, 0.35564732551574707, 0.35449108481407166, 0.3535808324813843, 0.35248857736587524, 0.3509451150894165, 0.3503606617450714, 0.34860822558403015, 0.3479453921318054, 0.3463321030139923, 0.3456293046474457, 0.34439995884895325, 0.3431778848171234, 0.34194067120552063, 0.34063541889190674, 0.3394918739795685, 0.33824431896209717, 0.3373792767524719, 0.3364179730415344, 0.335178017616272, 0.3338446617126465, 0.33265164494514465, 0.3314943313598633, 0.33013567328453064, 0.32894283533096313, 0.32778555154800415, 0.3267187476158142, 0.3256460428237915, 0.32446861267089844, 0.32320961356163025, 0.3220725953578949, 0.32083144783973694, 0.3194258511066437, 0.31836023926734924], 'accuracy': [0.9719864130020142, 0.9799094796180725, 0.983305037021637, 0.9864176511764526, 0.9844368696212769, 0.9881154298782349, 0.9858517050743103, 0.9912280440330505, 0.9929258823394775, 0.992642879486084, 0.9946236610412598, 0.9940577149391174, 0.9954725503921509, 0.9957554936408997, 0.9954725503921509, 0.9957554936408997, 0.9957554936408997, 0.9968873858451843, 0.9968873858451843, 0.9971703290939331, 0.9968873858451843, 0.9971703290939331, 0.9974533319473267, 0.9977362751960754, 0.9974533319473267, 0.9983022212982178, 0.9980192184448242, 0.9974533319473267, 0.9980192184448242, 0.9985851645469666, 0.9988681674003601, 0.9985851645469666, 0.9985851645469666, 0.9971703290939331, 0.9994340538978577, 0.9988681674003601, 0.9988681674003601, 0.9983022212982178, 0.9985851645469666, 0.9988681674003601, 0.9991511106491089, 0.9991511106491089, 0.9997170567512512, 0.9991511106491089, 0.9994340538978577, 0.9988681674003601, 0.9997170567512512, 0.9991511106491089, 0.9988681674003601, 0.9991511106491089, 0.9994340538978577, 1.0, 1.0, 0.9994340538978577, 0.9997170567512512, 0.9994340538978577, 1.0, 0.9997170567512512, 1.0, 0.9994340538978577, 1.0, 0.9997170567512512, 1.0, 0.9997170567512512, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997170567512512, 1.0, 1.0, 1.0, 0.9997170567512512, 1.0, 0.9997170567512512, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [1.1058454513549805, 1.097122073173523, 1.083281397819519, 1.0750880241394043, 1.0501141548156738, 1.013965129852295, 0.9976665377616882, 0.9641295671463013, 0.9153929948806763, 0.8667054176330566, 0.8515963554382324, 0.80232834815979, 0.7754459977149963, 0.7388997673988342, 0.7219297885894775, 0.6972917914390564, 0.685712456703186, 0.6480742692947388, 0.6385036706924438, 0.6219595074653625, 0.6151562333106995, 0.6106058955192566, 0.6136534810066223, 0.6055481433868408, 0.6054590940475464, 0.6087183356285095, 0.6176155805587769, 0.6134395599365234, 0.630917489528656, 0.6135398745536804, 0.6327134370803833, 0.6182696223258972, 0.6737796664237976, 0.6408487558364868, 0.6246349811553955, 0.6219648718833923, 0.6227967739105225, 0.6200966835021973, 0.6275997757911682, 0.6261530518531799, 0.6234585046768188, 0.637405276298523, 0.6230223178863525, 0.643826425075531, 0.6248529553413391, 0.6310986280441284, 0.6355738639831543, 0.6232622265815735, 0.6288443207740784, 0.6594020128250122, 0.6209211945533752, 0.6276657581329346, 0.6421666741371155, 0.6361567974090576, 0.6301422119140625, 0.6278184056282043, 0.6233102679252625, 0.6395869255065918, 0.6249768733978271, 0.6382892727851868, 0.6388912796974182, 0.6950775980949402, 0.6393032670021057, 0.6323276162147522, 0.6199862957000732, 0.6476229429244995, 0.6258718371391296, 0.6243255734443665, 0.6214978694915771, 0.623369574546814, 0.6261990666389465, 0.6475608348846436, 0.6238882541656494, 0.6331583857536316, 0.6295519471168518, 0.6347373127937317, 0.6207662224769592, 0.6389754414558411, 0.6285330057144165, 0.6340784430503845, 0.6256221532821655, 0.6289271116256714, 0.6233344674110413, 0.6445161700248718, 0.6201598644256592, 0.6286974549293518, 0.6295126676559448, 0.6325793862342834, 0.6172775626182556, 0.6277832984924316, 0.6231420636177063, 0.6143437623977661, 0.6216156482696533, 0.6131134033203125, 0.6194010376930237, 0.6113672256469727, 0.6407146453857422, 0.6133537888526917, 0.6137790083885193, 0.6127943396568298], 'val_accuracy': [0.4954751133918762, 0.4977375566959381, 0.5079185366630554, 0.5192307829856873, 0.5475113391876221, 0.6063348650932312, 0.6244344115257263, 0.685520350933075, 0.7658371329307556, 0.8529411554336548, 0.8348416090011597, 0.8868778347969055, 0.8902714848518372, 0.9106335043907166, 0.9027149081230164, 0.9004524946212769, 0.8947963714599609, 0.9140271544456482, 0.9151583909988403, 0.9196832776069641, 0.9196832776069641, 0.9219456911087036, 0.9162895679473877, 0.918552041053772, 0.9208144545555115, 0.9162895679473877, 0.9140271544456482, 0.9219456911087036, 0.9061086177825928, 0.918552041053772, 0.9117646813392639, 0.9117646813392639, 0.901583731174469, 0.9038461446762085, 0.9174208045005798, 0.918552041053772, 0.912895917892456, 0.9140271544456482, 0.9106335043907166, 0.9174208045005798, 0.9219456911087036, 0.9049773812294006, 0.9162895679473877, 0.9083710312843323, 0.9174208045005798, 0.918552041053772, 0.9117646813392639, 0.912895917892456, 0.9140271544456482, 0.9038461446762085, 0.9083710312843323, 0.9174208045005798, 0.9106335043907166, 0.9162895679473877, 0.9117646813392639, 0.9095022678375244, 0.9106335043907166, 0.9027149081230164, 0.9106335043907166, 0.9049773812294006, 0.9072397947311401, 0.8970588445663452, 0.9117646813392639, 0.912895917892456, 0.9117646813392639, 0.9083710312843323, 0.9106335043907166, 0.9095022678375244, 0.9083710312843323, 0.9106335043907166, 0.9140271544456482, 0.9061086177825928, 0.9162895679473877, 0.9117646813392639, 0.9140271544456482, 0.912895917892456, 0.9095022678375244, 0.9117646813392639, 0.9083710312843323, 0.9083710312843323, 0.9106335043907166, 0.9095022678375244, 0.9072397947311401, 0.9061086177825928, 0.9049773812294006, 0.9049773812294006, 0.9117646813392639, 0.9106335043907166, 0.9083710312843323, 0.9083710312843323, 0.9061086177825928, 0.9004524946212769, 0.9072397947311401, 0.9038461446762085, 0.9061086177825928, 0.9061086177825928, 0.9061086177825928, 0.9038461446762085, 0.9072397947311401, 0.9061086177825928]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.4790 - accuracy: 0.9738"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 4s 35ms/step - loss: 0.4798 - accuracy: 0.9736 - val_loss: 1.1111 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4666 - accuracy: 0.9824 - val_loss: 1.1042 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4590 - accuracy: 0.9855 - val_loss: 1.0982 - val_accuracy: 0.4907\n","Epoch 4/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4537 - accuracy: 0.9866 - val_loss: 1.0877 - val_accuracy: 0.5041\n","Epoch 5/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4524 - accuracy: 0.9884 - val_loss: 1.0557 - val_accuracy: 0.5331\n","Epoch 6/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4522 - accuracy: 0.9881 - val_loss: 1.0293 - val_accuracy: 0.5589\n","Epoch 7/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4425 - accuracy: 0.9915 - val_loss: 0.9767 - val_accuracy: 0.6436\n","Epoch 8/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4421 - accuracy: 0.9917 - val_loss: 0.9466 - val_accuracy: 0.6973\n","Epoch 9/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4425 - accuracy: 0.9922 - val_loss: 0.9099 - val_accuracy: 0.7479\n","Epoch 10/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4372 - accuracy: 0.9930 - val_loss: 0.8567 - val_accuracy: 0.8285\n","Epoch 11/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4362 - accuracy: 0.9935 - val_loss: 0.8145 - val_accuracy: 0.8636\n","Epoch 12/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4310 - accuracy: 0.9946 - val_loss: 0.7916 - val_accuracy: 0.8605\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4288 - accuracy: 0.9964 - val_loss: 0.7312 - val_accuracy: 0.8998\n","Epoch 14/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4306 - accuracy: 0.9941 - val_loss: 0.7270 - val_accuracy: 0.8905\n","Epoch 15/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4234 - accuracy: 0.9961 - val_loss: 0.6947 - val_accuracy: 0.9050\n","Epoch 16/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4242 - accuracy: 0.9964 - val_loss: 0.6714 - val_accuracy: 0.9039\n","Epoch 17/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4198 - accuracy: 0.9974 - val_loss: 0.6509 - val_accuracy: 0.9029\n","Epoch 18/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4191 - accuracy: 0.9972 - val_loss: 0.6556 - val_accuracy: 0.8967\n","Epoch 19/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4183 - accuracy: 0.9979 - val_loss: 0.6619 - val_accuracy: 0.8905\n","Epoch 20/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4148 - accuracy: 0.9979 - val_loss: 0.6434 - val_accuracy: 0.9050\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4136 - accuracy: 0.9974 - val_loss: 0.6531 - val_accuracy: 0.8957\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4130 - accuracy: 0.9977 - val_loss: 0.6463 - val_accuracy: 0.9029\n","Epoch 23/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4098 - accuracy: 0.9995 - val_loss: 0.6590 - val_accuracy: 0.8988\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4084 - accuracy: 0.9984 - val_loss: 0.6547 - val_accuracy: 0.9019\n","Epoch 25/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4069 - accuracy: 0.9984 - val_loss: 0.6654 - val_accuracy: 0.9060\n","Epoch 26/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4040 - accuracy: 0.9995 - val_loss: 0.6689 - val_accuracy: 0.9050\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4041 - accuracy: 0.9982 - val_loss: 0.6721 - val_accuracy: 0.9019\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4038 - accuracy: 0.9982 - val_loss: 0.6844 - val_accuracy: 0.8967\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4002 - accuracy: 0.9997 - val_loss: 0.6826 - val_accuracy: 0.9060\n","Epoch 30/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3996 - accuracy: 0.9990 - val_loss: 0.6846 - val_accuracy: 0.9039\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3985 - accuracy: 0.9987 - val_loss: 0.6792 - val_accuracy: 0.9008\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3957 - accuracy: 0.9997 - val_loss: 0.6797 - val_accuracy: 0.9029\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3953 - accuracy: 0.9997 - val_loss: 0.6833 - val_accuracy: 0.8998\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3930 - accuracy: 0.9995 - val_loss: 0.6843 - val_accuracy: 0.9019\n","Epoch 35/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3911 - accuracy: 0.9992 - val_loss: 0.6939 - val_accuracy: 0.8957\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3894 - accuracy: 0.9997 - val_loss: 0.6935 - val_accuracy: 0.9008\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3876 - accuracy: 0.9997 - val_loss: 0.6923 - val_accuracy: 0.9008\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3871 - accuracy: 0.9997 - val_loss: 0.6882 - val_accuracy: 0.8998\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3875 - accuracy: 0.9995 - val_loss: 0.6966 - val_accuracy: 0.8926\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3846 - accuracy: 0.9995 - val_loss: 0.6880 - val_accuracy: 0.9029\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3825 - accuracy: 0.9995 - val_loss: 0.7120 - val_accuracy: 0.9029\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3821 - accuracy: 1.0000 - val_loss: 0.6898 - val_accuracy: 0.8977\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3799 - accuracy: 0.9997 - val_loss: 0.6929 - val_accuracy: 0.8998\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3789 - accuracy: 0.9995 - val_loss: 0.7026 - val_accuracy: 0.8905\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3798 - accuracy: 0.9995 - val_loss: 0.7374 - val_accuracy: 0.8864\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3840 - accuracy: 0.9982 - val_loss: 0.7296 - val_accuracy: 0.8967\n","Epoch 47/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3767 - accuracy: 0.9995 - val_loss: 0.7005 - val_accuracy: 0.9019\n","Epoch 48/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3736 - accuracy: 0.9997 - val_loss: 0.6884 - val_accuracy: 0.8988\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3723 - accuracy: 0.9997 - val_loss: 0.6960 - val_accuracy: 0.9008\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3722 - accuracy: 0.9995 - val_loss: 0.6865 - val_accuracy: 0.8946\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3703 - accuracy: 0.9997 - val_loss: 0.6922 - val_accuracy: 0.8946\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3686 - accuracy: 0.9997 - val_loss: 0.6931 - val_accuracy: 0.8977\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3668 - accuracy: 0.9997 - val_loss: 0.6973 - val_accuracy: 0.8988\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3662 - accuracy: 0.9997 - val_loss: 0.6916 - val_accuracy: 0.8967\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3652 - accuracy: 0.9997 - val_loss: 0.6911 - val_accuracy: 0.8988\n","Epoch 56/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3635 - accuracy: 0.9997 - val_loss: 0.6987 - val_accuracy: 0.8998\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3625 - accuracy: 0.9997 - val_loss: 0.6994 - val_accuracy: 0.8988\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3610 - accuracy: 0.9997 - val_loss: 0.6908 - val_accuracy: 0.8988\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3598 - accuracy: 1.0000 - val_loss: 0.6988 - val_accuracy: 0.8936\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3591 - accuracy: 0.9997 - val_loss: 0.6968 - val_accuracy: 0.8946\n","Epoch 61/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3579 - accuracy: 0.9997 - val_loss: 0.6962 - val_accuracy: 0.8957\n","Epoch 62/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3562 - accuracy: 0.9997 - val_loss: 0.6966 - val_accuracy: 0.9019\n","Epoch 63/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3552 - accuracy: 0.9997 - val_loss: 0.6954 - val_accuracy: 0.8957\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3538 - accuracy: 1.0000 - val_loss: 0.7060 - val_accuracy: 0.8988\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3537 - accuracy: 0.9997 - val_loss: 0.6918 - val_accuracy: 0.8957\n","Epoch 66/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3542 - accuracy: 1.0000 - val_loss: 0.7181 - val_accuracy: 0.8946\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3505 - accuracy: 0.9997 - val_loss: 0.6922 - val_accuracy: 0.8977\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3494 - accuracy: 0.9997 - val_loss: 0.6957 - val_accuracy: 0.8946\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3493 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.8967\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3511 - accuracy: 0.9997 - val_loss: 0.7190 - val_accuracy: 0.8884\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3469 - accuracy: 1.0000 - val_loss: 0.6987 - val_accuracy: 0.8905\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3442 - accuracy: 0.9997 - val_loss: 0.7035 - val_accuracy: 0.8967\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3436 - accuracy: 0.9997 - val_loss: 0.6965 - val_accuracy: 0.8977\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3418 - accuracy: 1.0000 - val_loss: 0.6916 - val_accuracy: 0.8957\n","Epoch 75/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3407 - accuracy: 1.0000 - val_loss: 0.6912 - val_accuracy: 0.8967\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3395 - accuracy: 1.0000 - val_loss: 0.6912 - val_accuracy: 0.8967\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3383 - accuracy: 1.0000 - val_loss: 0.6962 - val_accuracy: 0.8977\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3372 - accuracy: 0.9997 - val_loss: 0.6951 - val_accuracy: 0.8977\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3369 - accuracy: 0.9997 - val_loss: 0.6957 - val_accuracy: 0.8946\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3350 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.8936\n","Epoch 81/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3334 - accuracy: 1.0000 - val_loss: 0.6908 - val_accuracy: 0.8946\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3325 - accuracy: 1.0000 - val_loss: 0.6899 - val_accuracy: 0.8905\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3314 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.8946\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3301 - accuracy: 1.0000 - val_loss: 0.6891 - val_accuracy: 0.8957\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3290 - accuracy: 1.0000 - val_loss: 0.6991 - val_accuracy: 0.8946\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3280 - accuracy: 1.0000 - val_loss: 0.7126 - val_accuracy: 0.8915\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3267 - accuracy: 0.9997 - val_loss: 0.6930 - val_accuracy: 0.8967\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3251 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.8946\n","Epoch 89/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3239 - accuracy: 1.0000 - val_loss: 0.6946 - val_accuracy: 0.8957\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3228 - accuracy: 1.0000 - val_loss: 0.6910 - val_accuracy: 0.8926\n","Epoch 91/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3215 - accuracy: 1.0000 - val_loss: 0.7024 - val_accuracy: 0.8864\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3205 - accuracy: 1.0000 - val_loss: 0.6900 - val_accuracy: 0.8926\n","Epoch 93/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3194 - accuracy: 1.0000 - val_loss: 0.6915 - val_accuracy: 0.8915\n","Epoch 94/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3177 - accuracy: 1.0000 - val_loss: 0.6919 - val_accuracy: 0.8915\n","Epoch 95/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3165 - accuracy: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.8926\n","Epoch 96/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3156 - accuracy: 0.9997 - val_loss: 0.6904 - val_accuracy: 0.8946\n","Epoch 97/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3142 - accuracy: 1.0000 - val_loss: 0.6934 - val_accuracy: 0.8957\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3128 - accuracy: 1.0000 - val_loss: 0.6836 - val_accuracy: 0.8926\n","Epoch 99/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3118 - accuracy: 1.0000 - val_loss: 0.6826 - val_accuracy: 0.8967\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3101 - accuracy: 1.0000 - val_loss: 0.6867 - val_accuracy: 0.8915\n","{'loss': [0.4798336625099182, 0.4666452407836914, 0.45903727412223816, 0.4537290036678314, 0.4523579776287079, 0.45221343636512756, 0.442471444606781, 0.4420933127403259, 0.44245147705078125, 0.43717822432518005, 0.4361514151096344, 0.43095967173576355, 0.4288254678249359, 0.43059808015823364, 0.42337796092033386, 0.42421868443489075, 0.41980087757110596, 0.41908708214759827, 0.41825392842292786, 0.4148349165916443, 0.4136282503604889, 0.41298893094062805, 0.40975967049598694, 0.40835317969322205, 0.4069407880306244, 0.40402472019195557, 0.4041130244731903, 0.4037608504295349, 0.40023452043533325, 0.39957016706466675, 0.3984631299972534, 0.3957359492778778, 0.39531567692756653, 0.39296889305114746, 0.3910544514656067, 0.3894110918045044, 0.3876408338546753, 0.38711225986480713, 0.387503057718277, 0.38460779190063477, 0.3824516534805298, 0.38209855556488037, 0.3799099624156952, 0.37886059284210205, 0.37978410720825195, 0.3839888870716095, 0.3766983151435852, 0.3736042082309723, 0.3723190128803253, 0.3722003400325775, 0.3702981173992157, 0.36856502294540405, 0.3667922914028168, 0.36622780561447144, 0.36515358090400696, 0.3634607493877411, 0.36253687739372253, 0.36095836758613586, 0.35981643199920654, 0.3590548038482666, 0.3579099476337433, 0.3561743199825287, 0.35521382093429565, 0.3538057506084442, 0.35367369651794434, 0.35424333810806274, 0.3505261540412903, 0.3493587076663971, 0.349284291267395, 0.3510666787624359, 0.34692054986953735, 0.34419968724250793, 0.3435823321342468, 0.34177395701408386, 0.34074369072914124, 0.3395124077796936, 0.33827927708625793, 0.3371846079826355, 0.33687472343444824, 0.33501723408699036, 0.33337974548339844, 0.33252668380737305, 0.33140623569488525, 0.3300933241844177, 0.32898393273353577, 0.32802706956863403, 0.32672226428985596, 0.3250932991504669, 0.3238872289657593, 0.32280272245407104, 0.32147037982940674, 0.3204679489135742, 0.3193855881690979, 0.31771329045295715, 0.31652307510375977, 0.31557726860046387, 0.3142029345035553, 0.31284794211387634, 0.3117966651916504, 0.3101429343223572], 'accuracy': [0.97364342212677, 0.9824289679527283, 0.9855297207832336, 0.9865633249282837, 0.9883720874786377, 0.9881137013435364, 0.9914728403091431, 0.9917312860488892, 0.9922480583190918, 0.9930232763290405, 0.9935400485992432, 0.9945736527442932, 0.9963824152946472, 0.9940568208694458, 0.9961240291595459, 0.9963824152946472, 0.9974160194396973, 0.997157633304596, 0.9979327917098999, 0.9979327917098999, 0.9974160194396973, 0.9976744055747986, 0.9994832277297974, 0.9984496235847473, 0.9984496235847473, 0.9994832277297974, 0.998191237449646, 0.998191237449646, 0.9997416138648987, 0.99896639585495, 0.9987080097198486, 0.9997416138648987, 0.9997416138648987, 0.9994832277297974, 0.9992247819900513, 0.9997416138648987, 0.9997416138648987, 0.9997416138648987, 0.9994832277297974, 0.9994832277297974, 0.9994832277297974, 1.0, 0.9997416138648987, 0.9994832277297974, 0.9994832277297974, 0.998191237449646, 0.9994832277297974, 0.9997416138648987, 0.9997416138648987, 0.9994832277297974, 0.9997416138648987, 0.9997416138648987, 0.9997416138648987, 0.9997416138648987, 0.9997416138648987, 0.9997416138648987, 0.9997416138648987, 0.9997416138648987, 1.0, 0.9997416138648987, 0.9997416138648987, 0.9997416138648987, 0.9997416138648987, 1.0, 0.9997416138648987, 1.0, 0.9997416138648987, 0.9997416138648987, 1.0, 0.9997416138648987, 1.0, 0.9997416138648987, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0], 'val_loss': [1.1110774278640747, 1.104225754737854, 1.0981992483139038, 1.0877050161361694, 1.0557388067245483, 1.0293474197387695, 0.9766719341278076, 0.9466244578361511, 0.9098555445671082, 0.8567236661911011, 0.8144873976707458, 0.7915920615196228, 0.7311832904815674, 0.7269667387008667, 0.6946711540222168, 0.6713680028915405, 0.6508753299713135, 0.6555654406547546, 0.6619393229484558, 0.6434269547462463, 0.6531424522399902, 0.6463181972503662, 0.6590068936347961, 0.654691219329834, 0.6653974652290344, 0.668941855430603, 0.6720792651176453, 0.6843535304069519, 0.6825865507125854, 0.6845870018005371, 0.6792298555374146, 0.679716169834137, 0.6832858920097351, 0.6842849850654602, 0.6938751935958862, 0.6934608221054077, 0.6923434734344482, 0.6882352232933044, 0.6965774297714233, 0.6879755854606628, 0.712016761302948, 0.6898099184036255, 0.6928743720054626, 0.7025580406188965, 0.7374356985092163, 0.7296391129493713, 0.7005180716514587, 0.6883818507194519, 0.6959847211837769, 0.6864877343177795, 0.6921865344047546, 0.6931312084197998, 0.697320818901062, 0.6915774345397949, 0.6911441683769226, 0.6987134218215942, 0.6993817687034607, 0.6908304691314697, 0.6988106966018677, 0.6968331933021545, 0.6961813569068909, 0.696646511554718, 0.6954314708709717, 0.705988883972168, 0.6917572617530823, 0.7180930972099304, 0.6921589970588684, 0.6957398056983948, 0.6905543208122253, 0.7190176844596863, 0.6986727714538574, 0.7035194039344788, 0.6965134143829346, 0.6916128396987915, 0.6912384629249573, 0.691198468208313, 0.6962167024612427, 0.695149302482605, 0.6957098245620728, 0.6906487345695496, 0.690830409526825, 0.6899117231369019, 0.6906121969223022, 0.6890931129455566, 0.6990835666656494, 0.7126269936561584, 0.6929829716682434, 0.6929147243499756, 0.694561243057251, 0.6910237669944763, 0.7023817300796509, 0.6899545192718506, 0.6915161609649658, 0.6918615102767944, 0.6885176301002502, 0.6903575658798218, 0.69339519739151, 0.6835971474647522, 0.6826475858688354, 0.6867328882217407], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.49070248007774353, 0.5041322112083435, 0.5330578684806824, 0.55888432264328, 0.6435950398445129, 0.6973140239715576, 0.7479338645935059, 0.8285123705863953, 0.8636363744735718, 0.8605371713638306, 0.8997933864593506, 0.8904958963394165, 0.9049586653709412, 0.9039255976676941, 0.9028925895690918, 0.8966942429542542, 0.8904958963394165, 0.9049586653709412, 0.8956611752510071, 0.9028925895690918, 0.8987603187561035, 0.9018595218658447, 0.9059917330741882, 0.9049586653709412, 0.9018595218658447, 0.8966942429542542, 0.9059917330741882, 0.9039255976676941, 0.9008264541625977, 0.9028925895690918, 0.8997933864593506, 0.9018595218658447, 0.8956611752510071, 0.9008264541625977, 0.9008264541625977, 0.8997933864593506, 0.8925619721412659, 0.9028925895690918, 0.9028925895690918, 0.8977272510528564, 0.8997933864593506, 0.8904958963394165, 0.8863636255264282, 0.8966942429542542, 0.9018595218658447, 0.8987603187561035, 0.9008264541625977, 0.89462810754776, 0.89462810754776, 0.8977272510528564, 0.8987603187561035, 0.8966942429542542, 0.8987603187561035, 0.8997933864593506, 0.8987603187561035, 0.8987603187561035, 0.8935950398445129, 0.89462810754776, 0.8956611752510071, 0.9018595218658447, 0.8956611752510071, 0.8987603187561035, 0.8956611752510071, 0.89462810754776, 0.8977272510528564, 0.89462810754776, 0.8966942429542542, 0.8884297609329224, 0.8904958963394165, 0.8966942429542542, 0.8977272510528564, 0.8956611752510071, 0.8966942429542542, 0.8966942429542542, 0.8977272510528564, 0.8977272510528564, 0.89462810754776, 0.8935950398445129, 0.89462810754776, 0.8904958963394165, 0.89462810754776, 0.8956611752510071, 0.89462810754776, 0.8915289044380188, 0.8966942429542542, 0.89462810754776, 0.8956611752510071, 0.8925619721412659, 0.8863636255264282, 0.8925619721412659, 0.8915289044380188, 0.8915289044380188, 0.8925619721412659, 0.89462810754776, 0.8956611752510071, 0.8925619721412659, 0.8966942429542542, 0.8915289044380188]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 5s 33ms/step - loss: 0.3502 - accuracy: 0.9879 - val_loss: 1.0212 - val_accuracy: 0.4871\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 1s 19ms/step - loss: 0.3322 - accuracy: 0.9949 - val_loss: 1.0108 - val_accuracy: 0.4925\n","Epoch 3/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3265 - accuracy: 0.9960 - val_loss: 1.0053 - val_accuracy: 0.4968\n","Epoch 4/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3232 - accuracy: 0.9968 - val_loss: 0.9877 - val_accuracy: 0.5065\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3211 - accuracy: 0.9989 - val_loss: 0.9681 - val_accuracy: 0.5194\n","Epoch 6/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3207 - accuracy: 0.9984 - val_loss: 0.9192 - val_accuracy: 0.5797\n","Epoch 7/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3189 - accuracy: 0.9989 - val_loss: 0.8811 - val_accuracy: 0.6336\n","Epoch 8/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3173 - accuracy: 0.9997 - val_loss: 0.8243 - val_accuracy: 0.7177\n","Epoch 9/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3173 - accuracy: 0.9992 - val_loss: 0.7924 - val_accuracy: 0.7511\n","Epoch 10/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3150 - accuracy: 0.9995 - val_loss: 0.7560 - val_accuracy: 0.7845\n","Epoch 11/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3156 - accuracy: 0.9995 - val_loss: 0.6952 - val_accuracy: 0.8610\n","Epoch 12/100\n","29/29 [==============================] - 2s 65ms/step - loss: 0.3131 - accuracy: 0.9997 - val_loss: 0.6520 - val_accuracy: 0.8825\n","Epoch 13/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3119 - accuracy: 0.9997 - val_loss: 0.6183 - val_accuracy: 0.8976\n","Epoch 14/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3113 - accuracy: 0.9997 - val_loss: 0.5808 - val_accuracy: 0.9192\n","Epoch 15/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3102 - accuracy: 0.9997 - val_loss: 0.5336 - val_accuracy: 0.9450\n","Epoch 16/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3097 - accuracy: 0.9997 - val_loss: 0.5388 - val_accuracy: 0.9289\n","Epoch 17/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3082 - accuracy: 1.0000 - val_loss: 0.5057 - val_accuracy: 0.9450\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3073 - accuracy: 0.9997 - val_loss: 0.4994 - val_accuracy: 0.9440\n","Epoch 19/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3067 - accuracy: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.9472\n","Epoch 20/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3055 - accuracy: 0.9997 - val_loss: 0.4789 - val_accuracy: 0.9440\n","Epoch 21/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3046 - accuracy: 1.0000 - val_loss: 0.4704 - val_accuracy: 0.9450\n","Epoch 22/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3038 - accuracy: 0.9997 - val_loss: 0.4670 - val_accuracy: 0.9472\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3025 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 0.9450\n","Epoch 24/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3018 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 0.9461\n","Epoch 25/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3008 - accuracy: 1.0000 - val_loss: 0.4731 - val_accuracy: 0.9418\n","Epoch 26/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2998 - accuracy: 1.0000 - val_loss: 0.4840 - val_accuracy: 0.9418\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2993 - accuracy: 1.0000 - val_loss: 0.4884 - val_accuracy: 0.9353\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2991 - accuracy: 0.9997 - val_loss: 0.4807 - val_accuracy: 0.9429\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2968 - accuracy: 1.0000 - val_loss: 0.4831 - val_accuracy: 0.9429\n","Epoch 30/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2958 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.9418\n","Epoch 31/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2949 - accuracy: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.9418\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2942 - accuracy: 1.0000 - val_loss: 0.4865 - val_accuracy: 0.9418\n","Epoch 33/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2931 - accuracy: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.9429\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2924 - accuracy: 1.0000 - val_loss: 0.4862 - val_accuracy: 0.9440\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2909 - accuracy: 1.0000 - val_loss: 0.4911 - val_accuracy: 0.9418\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2898 - accuracy: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.9429\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2891 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.9418\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2881 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.9418\n","Epoch 39/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2869 - accuracy: 1.0000 - val_loss: 0.4886 - val_accuracy: 0.9429\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2871 - accuracy: 0.9997 - val_loss: 0.5024 - val_accuracy: 0.9321\n","Epoch 41/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2855 - accuracy: 1.0000 - val_loss: 0.4993 - val_accuracy: 0.9332\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2841 - accuracy: 1.0000 - val_loss: 0.4975 - val_accuracy: 0.9429\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2829 - accuracy: 1.0000 - val_loss: 0.4947 - val_accuracy: 0.9429\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2818 - accuracy: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.9397\n","Epoch 45/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2806 - accuracy: 1.0000 - val_loss: 0.4914 - val_accuracy: 0.9407\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2795 - accuracy: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.9429\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2785 - accuracy: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.9386\n","Epoch 48/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2775 - accuracy: 1.0000 - val_loss: 0.4878 - val_accuracy: 0.9418\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2764 - accuracy: 1.0000 - val_loss: 0.4916 - val_accuracy: 0.9407\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2756 - accuracy: 1.0000 - val_loss: 0.4867 - val_accuracy: 0.9418\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2743 - accuracy: 1.0000 - val_loss: 0.4935 - val_accuracy: 0.9397\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2732 - accuracy: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.9289\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2723 - accuracy: 1.0000 - val_loss: 0.4927 - val_accuracy: 0.9386\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2717 - accuracy: 1.0000 - val_loss: 0.4834 - val_accuracy: 0.9407\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2703 - accuracy: 1.0000 - val_loss: 0.4932 - val_accuracy: 0.9386\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2687 - accuracy: 1.0000 - val_loss: 0.4824 - val_accuracy: 0.9397\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2677 - accuracy: 1.0000 - val_loss: 0.4833 - val_accuracy: 0.9343\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2668 - accuracy: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.9407\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2655 - accuracy: 1.0000 - val_loss: 0.4832 - val_accuracy: 0.9343\n","Epoch 60/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2645 - accuracy: 1.0000 - val_loss: 0.4849 - val_accuracy: 0.9343\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2633 - accuracy: 1.0000 - val_loss: 0.4855 - val_accuracy: 0.9407\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2621 - accuracy: 1.0000 - val_loss: 0.4830 - val_accuracy: 0.9375\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2609 - accuracy: 1.0000 - val_loss: 0.4879 - val_accuracy: 0.9407\n","Epoch 64/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2600 - accuracy: 1.0000 - val_loss: 0.4986 - val_accuracy: 0.9397\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2589 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.9364\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2574 - accuracy: 1.0000 - val_loss: 0.4800 - val_accuracy: 0.9332\n","Epoch 67/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2563 - accuracy: 1.0000 - val_loss: 0.4805 - val_accuracy: 0.9310\n","Epoch 68/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2551 - accuracy: 1.0000 - val_loss: 0.4800 - val_accuracy: 0.9343\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2539 - accuracy: 1.0000 - val_loss: 0.4783 - val_accuracy: 0.9343\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2529 - accuracy: 1.0000 - val_loss: 0.4757 - val_accuracy: 0.9343\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2517 - accuracy: 1.0000 - val_loss: 0.4793 - val_accuracy: 0.9386\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2506 - accuracy: 1.0000 - val_loss: 0.4765 - val_accuracy: 0.9364\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2493 - accuracy: 1.0000 - val_loss: 0.4756 - val_accuracy: 0.9343\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2488 - accuracy: 1.0000 - val_loss: 0.4850 - val_accuracy: 0.9386\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2473 - accuracy: 1.0000 - val_loss: 0.4804 - val_accuracy: 0.9364\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2459 - accuracy: 1.0000 - val_loss: 0.4797 - val_accuracy: 0.9332\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2446 - accuracy: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.9364\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2435 - accuracy: 1.0000 - val_loss: 0.4766 - val_accuracy: 0.9343\n","Epoch 79/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2423 - accuracy: 1.0000 - val_loss: 0.4742 - val_accuracy: 0.9375\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2412 - accuracy: 1.0000 - val_loss: 0.4734 - val_accuracy: 0.9310\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2399 - accuracy: 1.0000 - val_loss: 0.4729 - val_accuracy: 0.9289\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2387 - accuracy: 1.0000 - val_loss: 0.4708 - val_accuracy: 0.9343\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2376 - accuracy: 1.0000 - val_loss: 0.4724 - val_accuracy: 0.9289\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2364 - accuracy: 1.0000 - val_loss: 0.4697 - val_accuracy: 0.9310\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2352 - accuracy: 1.0000 - val_loss: 0.4732 - val_accuracy: 0.9343\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2342 - accuracy: 1.0000 - val_loss: 0.4800 - val_accuracy: 0.9353\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2328 - accuracy: 1.0000 - val_loss: 0.4710 - val_accuracy: 0.9321\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2315 - accuracy: 1.0000 - val_loss: 0.4703 - val_accuracy: 0.9310\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2304 - accuracy: 1.0000 - val_loss: 0.4684 - val_accuracy: 0.9332\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2292 - accuracy: 1.0000 - val_loss: 0.4832 - val_accuracy: 0.9321\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2288 - accuracy: 1.0000 - val_loss: 0.5521 - val_accuracy: 0.9009\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2486 - accuracy: 0.9922 - val_loss: 0.5155 - val_accuracy: 0.9149\n","Epoch 93/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2489 - accuracy: 0.9930 - val_loss: 0.5511 - val_accuracy: 0.9138\n","Epoch 94/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2312 - accuracy: 0.9989 - val_loss: 0.4799 - val_accuracy: 0.9300\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2265 - accuracy: 1.0000 - val_loss: 0.4795 - val_accuracy: 0.9289\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2253 - accuracy: 1.0000 - val_loss: 0.4736 - val_accuracy: 0.9267\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2247 - accuracy: 1.0000 - val_loss: 0.4700 - val_accuracy: 0.9267\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2242 - accuracy: 1.0000 - val_loss: 0.4752 - val_accuracy: 0.9278\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2238 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.9267\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2233 - accuracy: 1.0000 - val_loss: 0.4737 - val_accuracy: 0.9267\n","{'loss': [0.350243479013443, 0.33224621415138245, 0.3264649510383606, 0.32321566343307495, 0.32110247015953064, 0.32072949409484863, 0.31894832849502563, 0.3172735571861267, 0.3172631561756134, 0.31495019793510437, 0.3155730068683624, 0.31311243772506714, 0.311930775642395, 0.3113117516040802, 0.310246080160141, 0.30973145365715027, 0.3082396686077118, 0.30731722712516785, 0.30665239691734314, 0.305514931678772, 0.30457982420921326, 0.30375367403030396, 0.3025209307670593, 0.30178302526474, 0.3007878363132477, 0.2998185455799103, 0.2992555797100067, 0.2991403341293335, 0.29680541157722473, 0.29580819606781006, 0.29487788677215576, 0.29423800110816956, 0.2930523753166199, 0.29237568378448486, 0.2909333109855652, 0.28982850909233093, 0.28909510374069214, 0.2881132960319519, 0.28694531321525574, 0.28706836700439453, 0.2855255603790283, 0.28405076265335083, 0.28287169337272644, 0.28184643387794495, 0.2806435525417328, 0.2795292139053345, 0.2785176932811737, 0.2774512469768524, 0.27636653184890747, 0.27555128931999207, 0.2743456959724426, 0.2732306122779846, 0.27225252985954285, 0.27174752950668335, 0.27033019065856934, 0.26872092485427856, 0.2677440643310547, 0.2667767405509949, 0.2655041217803955, 0.2645033597946167, 0.2633309066295624, 0.26212769746780396, 0.26091858744621277, 0.2600357234477997, 0.25891101360321045, 0.2574443519115448, 0.2562936544418335, 0.2551424503326416, 0.2539392411708832, 0.25291523337364197, 0.2517004609107971, 0.25059041380882263, 0.2492956668138504, 0.24877797067165375, 0.24725082516670227, 0.24585215747356415, 0.24463266134262085, 0.2434968501329422, 0.24230660498142242, 0.24115391075611115, 0.23994582891464233, 0.2386782467365265, 0.23755162954330444, 0.236398383975029, 0.23515331745147705, 0.23422569036483765, 0.23279458284378052, 0.2315434068441391, 0.23041044175624847, 0.22916032373905182, 0.22877556085586548, 0.2485724538564682, 0.24892999231815338, 0.23122438788414001, 0.22646060585975647, 0.22530432045459747, 0.22470860183238983, 0.2242230474948883, 0.22375266253948212, 0.22329199314117432], 'accuracy': [0.9878771305084229, 0.9948814511299133, 0.9959590435028076, 0.9967672228813171, 0.9989224076271057, 0.998383641242981, 0.9989224076271057, 0.9997305870056152, 0.9991918206214905, 0.9994612336158752, 0.9994612336158752, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152, 1.0, 0.9997305870056152, 1.0, 0.9997305870056152, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921875, 0.9929956793785095, 0.9989224076271057, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [1.0212215185165405, 1.0107996463775635, 1.005309820175171, 0.9877429008483887, 0.9681210517883301, 0.9192241430282593, 0.8811283707618713, 0.8243322968482971, 0.7924140691757202, 0.7560480833053589, 0.6952171325683594, 0.6520470976829529, 0.618320882320404, 0.5807711482048035, 0.533575177192688, 0.5388244390487671, 0.5057272911071777, 0.49941933155059814, 0.47699519991874695, 0.4788617789745331, 0.4704478979110718, 0.4669722318649292, 0.4682089388370514, 0.46815699338912964, 0.4730689525604248, 0.4840371310710907, 0.48837244510650635, 0.48066243529319763, 0.4831351935863495, 0.4815629720687866, 0.48452824354171753, 0.4864806830883026, 0.4874657690525055, 0.48620301485061646, 0.4911406934261322, 0.5046465396881104, 0.49086228013038635, 0.486277312040329, 0.4885571300983429, 0.5024289488792419, 0.49927863478660583, 0.49748462438583374, 0.4946945011615753, 0.4925258159637451, 0.4913865029811859, 0.49065592885017395, 0.4888994097709656, 0.4877735376358032, 0.4916171729564667, 0.48666858673095703, 0.4935378432273865, 0.4899507761001587, 0.49265652894973755, 0.4833778440952301, 0.4931623637676239, 0.482438325881958, 0.48331037163734436, 0.4876461327075958, 0.4831886887550354, 0.48493534326553345, 0.4854974150657654, 0.4829631447792053, 0.48794013261795044, 0.4986051917076111, 0.4866259694099426, 0.4800218641757965, 0.4805199205875397, 0.47996923327445984, 0.47832033038139343, 0.47567301988601685, 0.4792814254760742, 0.4764905869960785, 0.47563135623931885, 0.48504552245140076, 0.4803730845451355, 0.47967618703842163, 0.47696396708488464, 0.4765670597553253, 0.47420206665992737, 0.47341227531433105, 0.4729105830192566, 0.4707580804824829, 0.4724191725254059, 0.4697171449661255, 0.4731781780719757, 0.4799824059009552, 0.47101157903671265, 0.4703070819377899, 0.468414306640625, 0.48324230313301086, 0.5520833730697632, 0.5154537558555603, 0.5510709285736084, 0.4799312353134155, 0.4794856309890747, 0.4735729396343231, 0.4699886441230774, 0.47522473335266113, 0.4727092385292053, 0.47365280985832214], 'val_accuracy': [0.48706895112991333, 0.4924568831920624, 0.4967672526836395, 0.506465494632721, 0.5193965435028076, 0.579741358757019, 0.6336206793785095, 0.7176724076271057, 0.7510775923728943, 0.7844827771186829, 0.860991358757019, 0.8825430870056152, 0.8976293206214905, 0.9191810488700867, 0.9450430870056152, 0.9288793206214905, 0.9450430870056152, 0.943965494632721, 0.9471982717514038, 0.943965494632721, 0.9450430870056152, 0.9471982717514038, 0.9450430870056152, 0.9461206793785095, 0.9418103694915771, 0.9418103694915771, 0.9353448152542114, 0.9428879022598267, 0.9428879022598267, 0.9418103694915771, 0.9418103694915771, 0.9418103694915771, 0.9428879022598267, 0.943965494632721, 0.9418103694915771, 0.9428879022598267, 0.9418103694915771, 0.9418103694915771, 0.9428879022598267, 0.9321120977401733, 0.9331896305084229, 0.9428879022598267, 0.9428879022598267, 0.9396551847457886, 0.9407327771186829, 0.9428879022598267, 0.9385775923728943, 0.9418103694915771, 0.9407327771186829, 0.9418103694915771, 0.9396551847457886, 0.9288793206214905, 0.9385775923728943, 0.9407327771186829, 0.9385775923728943, 0.9396551847457886, 0.9342672228813171, 0.9407327771186829, 0.9342672228813171, 0.9342672228813171, 0.9407327771186829, 0.9375, 0.9407327771186829, 0.9396551847457886, 0.9364224076271057, 0.9331896305084229, 0.931034505367279, 0.9342672228813171, 0.9342672228813171, 0.9342672228813171, 0.9385775923728943, 0.9364224076271057, 0.9342672228813171, 0.9385775923728943, 0.9364224076271057, 0.9331896305084229, 0.9364224076271057, 0.9342672228813171, 0.9375, 0.931034505367279, 0.9288793206214905, 0.9342672228813171, 0.9288793206214905, 0.931034505367279, 0.9342672228813171, 0.9353448152542114, 0.9321120977401733, 0.931034505367279, 0.9331896305084229, 0.9321120977401733, 0.9008620977401733, 0.9148706793785095, 0.9137930870056152, 0.9299569129943848, 0.9288793206214905, 0.9267241358757019, 0.9267241358757019, 0.9278017282485962, 0.9267241358757019, 0.9267241358757019]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.3649 - accuracy: 0.9838"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 4s 35ms/step - loss: 0.3629 - accuracy: 0.9844 - val_loss: 1.0120 - val_accuracy: 0.4977\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3371 - accuracy: 0.9932 - val_loss: 1.0046 - val_accuracy: 0.5011\n","Epoch 3/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3328 - accuracy: 0.9952 - val_loss: 0.9912 - val_accuracy: 0.5113\n","Epoch 4/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3295 - accuracy: 0.9963 - val_loss: 0.9714 - val_accuracy: 0.5351\n","Epoch 5/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3264 - accuracy: 0.9975 - val_loss: 0.9421 - val_accuracy: 0.5679\n","Epoch 6/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.3271 - accuracy: 0.9983 - val_loss: 0.9299 - val_accuracy: 0.5758\n","Epoch 7/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3251 - accuracy: 0.9983 - val_loss: 0.8613 - val_accuracy: 0.6889\n","Epoch 8/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3218 - accuracy: 0.9989 - val_loss: 0.8278 - val_accuracy: 0.7251\n","Epoch 9/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3198 - accuracy: 0.9986 - val_loss: 0.8035 - val_accuracy: 0.7455\n","Epoch 10/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3199 - accuracy: 0.9992 - val_loss: 0.7115 - val_accuracy: 0.8937\n","Epoch 11/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3191 - accuracy: 0.9992 - val_loss: 0.7070 - val_accuracy: 0.8541\n","Epoch 12/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3184 - accuracy: 0.9989 - val_loss: 0.6467 - val_accuracy: 0.9219\n","Epoch 13/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3159 - accuracy: 0.9992 - val_loss: 0.6317 - val_accuracy: 0.9016\n","Epoch 14/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3150 - accuracy: 0.9992 - val_loss: 0.5828 - val_accuracy: 0.9299\n","Epoch 15/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3130 - accuracy: 0.9994 - val_loss: 0.5585 - val_accuracy: 0.9389\n","Epoch 16/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3123 - accuracy: 0.9994 - val_loss: 0.5351 - val_accuracy: 0.9423\n","Epoch 17/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3104 - accuracy: 1.0000 - val_loss: 0.5135 - val_accuracy: 0.9446\n","Epoch 18/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3101 - accuracy: 0.9997 - val_loss: 0.4958 - val_accuracy: 0.9457\n","Epoch 19/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3092 - accuracy: 1.0000 - val_loss: 0.4829 - val_accuracy: 0.9434\n","Epoch 20/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3083 - accuracy: 1.0000 - val_loss: 0.4777 - val_accuracy: 0.9468\n","Epoch 21/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3074 - accuracy: 0.9997 - val_loss: 0.4718 - val_accuracy: 0.9468\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3073 - accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 0.9378\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3063 - accuracy: 0.9994 - val_loss: 0.4701 - val_accuracy: 0.9423\n","Epoch 24/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3061 - accuracy: 0.9994 - val_loss: 0.4680 - val_accuracy: 0.9400\n","Epoch 25/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3039 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9446\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3030 - accuracy: 1.0000 - val_loss: 0.4718 - val_accuracy: 0.9423\n","Epoch 27/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3026 - accuracy: 1.0000 - val_loss: 0.4771 - val_accuracy: 0.9389\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3015 - accuracy: 1.0000 - val_loss: 0.4780 - val_accuracy: 0.9400\n","Epoch 29/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3008 - accuracy: 1.0000 - val_loss: 0.4976 - val_accuracy: 0.9287\n","Epoch 30/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3007 - accuracy: 1.0000 - val_loss: 0.4795 - val_accuracy: 0.9378\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2986 - accuracy: 1.0000 - val_loss: 0.4823 - val_accuracy: 0.9389\n","Epoch 32/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2976 - accuracy: 1.0000 - val_loss: 0.4840 - val_accuracy: 0.9367\n","Epoch 33/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2968 - accuracy: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.9333\n","Epoch 34/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2961 - accuracy: 1.0000 - val_loss: 0.4799 - val_accuracy: 0.9434\n","Epoch 35/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2951 - accuracy: 1.0000 - val_loss: 0.4861 - val_accuracy: 0.9378\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2942 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.9412\n","Epoch 37/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.2939 - accuracy: 1.0000 - val_loss: 0.4811 - val_accuracy: 0.9480\n","Epoch 38/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2929 - accuracy: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.9367\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2918 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.9423\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2913 - accuracy: 1.0000 - val_loss: 0.4936 - val_accuracy: 0.9321\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2904 - accuracy: 1.0000 - val_loss: 0.4882 - val_accuracy: 0.9378\n","Epoch 42/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2892 - accuracy: 1.0000 - val_loss: 0.4848 - val_accuracy: 0.9378\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2881 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.9333\n","Epoch 44/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2871 - accuracy: 1.0000 - val_loss: 0.4837 - val_accuracy: 0.9389\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2860 - accuracy: 1.0000 - val_loss: 0.4851 - val_accuracy: 0.9389\n","Epoch 46/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2851 - accuracy: 1.0000 - val_loss: 0.4865 - val_accuracy: 0.9367\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2844 - accuracy: 1.0000 - val_loss: 0.4809 - val_accuracy: 0.9423\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2834 - accuracy: 1.0000 - val_loss: 0.4974 - val_accuracy: 0.9310\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2824 - accuracy: 1.0000 - val_loss: 0.4865 - val_accuracy: 0.9333\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2814 - accuracy: 1.0000 - val_loss: 0.4812 - val_accuracy: 0.9355\n","Epoch 51/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2806 - accuracy: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.9400\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2799 - accuracy: 1.0000 - val_loss: 0.4927 - val_accuracy: 0.9276\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2789 - accuracy: 1.0000 - val_loss: 0.4804 - val_accuracy: 0.9355\n","Epoch 54/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2776 - accuracy: 1.0000 - val_loss: 0.4778 - val_accuracy: 0.9412\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2766 - accuracy: 1.0000 - val_loss: 0.4862 - val_accuracy: 0.9333\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2757 - accuracy: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.9389\n","Epoch 57/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2748 - accuracy: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.9299\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2736 - accuracy: 1.0000 - val_loss: 0.4854 - val_accuracy: 0.9333\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2729 - accuracy: 1.0000 - val_loss: 0.4817 - val_accuracy: 0.9400\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2721 - accuracy: 1.0000 - val_loss: 0.4823 - val_accuracy: 0.9367\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2714 - accuracy: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.9321\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2700 - accuracy: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.9287\n","Epoch 63/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2687 - accuracy: 1.0000 - val_loss: 0.4872 - val_accuracy: 0.9287\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2675 - accuracy: 1.0000 - val_loss: 0.4784 - val_accuracy: 0.9355\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2666 - accuracy: 1.0000 - val_loss: 0.5021 - val_accuracy: 0.9253\n","Epoch 66/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2661 - accuracy: 1.0000 - val_loss: 0.4829 - val_accuracy: 0.9333\n","Epoch 67/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2646 - accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.9287\n","Epoch 68/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2634 - accuracy: 1.0000 - val_loss: 0.4744 - val_accuracy: 0.9355\n","Epoch 69/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2626 - accuracy: 1.0000 - val_loss: 0.4833 - val_accuracy: 0.9276\n","Epoch 70/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2616 - accuracy: 1.0000 - val_loss: 0.4740 - val_accuracy: 0.9367\n","Epoch 71/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2606 - accuracy: 1.0000 - val_loss: 0.4767 - val_accuracy: 0.9299\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2595 - accuracy: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.9265\n","Epoch 73/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2583 - accuracy: 1.0000 - val_loss: 0.4776 - val_accuracy: 0.9287\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2572 - accuracy: 1.0000 - val_loss: 0.4769 - val_accuracy: 0.9333\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2561 - accuracy: 1.0000 - val_loss: 0.4836 - val_accuracy: 0.9253\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2554 - accuracy: 1.0000 - val_loss: 0.4874 - val_accuracy: 0.9253\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2543 - accuracy: 1.0000 - val_loss: 0.4936 - val_accuracy: 0.9219\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2530 - accuracy: 1.0000 - val_loss: 0.4720 - val_accuracy: 0.9344\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2519 - accuracy: 1.0000 - val_loss: 0.4711 - val_accuracy: 0.9321\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2508 - accuracy: 1.0000 - val_loss: 0.4721 - val_accuracy: 0.9287\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2497 - accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.9333\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2486 - accuracy: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.9253\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2476 - accuracy: 1.0000 - val_loss: 0.4607 - val_accuracy: 0.9367\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2464 - accuracy: 1.0000 - val_loss: 0.4782 - val_accuracy: 0.9242\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2453 - accuracy: 1.0000 - val_loss: 0.4617 - val_accuracy: 0.9355\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2441 - accuracy: 1.0000 - val_loss: 0.4640 - val_accuracy: 0.9321\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2431 - accuracy: 1.0000 - val_loss: 0.4812 - val_accuracy: 0.9242\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2421 - accuracy: 1.0000 - val_loss: 0.4604 - val_accuracy: 0.9333\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2409 - accuracy: 1.0000 - val_loss: 0.4622 - val_accuracy: 0.9287\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2398 - accuracy: 1.0000 - val_loss: 0.4915 - val_accuracy: 0.9197\n","Epoch 91/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2390 - accuracy: 1.0000 - val_loss: 0.4610 - val_accuracy: 0.9333\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2374 - accuracy: 1.0000 - val_loss: 0.4695 - val_accuracy: 0.9265\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2363 - accuracy: 1.0000 - val_loss: 0.4639 - val_accuracy: 0.9287\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2351 - accuracy: 1.0000 - val_loss: 0.4608 - val_accuracy: 0.9299\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2342 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.9310\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2329 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.9265\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2318 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 0.9310\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2306 - accuracy: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.9242\n","Epoch 99/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2295 - accuracy: 1.0000 - val_loss: 0.4558 - val_accuracy: 0.9287\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2286 - accuracy: 1.0000 - val_loss: 0.4647 - val_accuracy: 0.9242\n","{'loss': [0.3629453182220459, 0.3371393084526062, 0.33283767104148865, 0.3295363485813141, 0.32637426257133484, 0.3270859718322754, 0.32510021328926086, 0.321790874004364, 0.3197581171989441, 0.31994056701660156, 0.3191327750682831, 0.3183734714984894, 0.31593039631843567, 0.3150033950805664, 0.31299257278442383, 0.3122590482234955, 0.31042641401290894, 0.31013649702072144, 0.3092491924762726, 0.30828961730003357, 0.30736419558525085, 0.30727437138557434, 0.3063167929649353, 0.3061048686504364, 0.3038563132286072, 0.3030068874359131, 0.3025832772254944, 0.3015243709087372, 0.30083537101745605, 0.3006577491760254, 0.2986406683921814, 0.2975936830043793, 0.29679253697395325, 0.29613903164863586, 0.29512476921081543, 0.2941765785217285, 0.29387035965919495, 0.2928940951824188, 0.291831910610199, 0.29133912920951843, 0.29042842984199524, 0.2891676723957062, 0.2881329357624054, 0.2870839238166809, 0.2860252559185028, 0.2850883901119232, 0.284371554851532, 0.2834114730358124, 0.2824406027793884, 0.28135454654693604, 0.2806469798088074, 0.2799200117588043, 0.2788929045200348, 0.2775537073612213, 0.2766259014606476, 0.2757376432418823, 0.27484577894210815, 0.2736493945121765, 0.2728589177131653, 0.27205944061279297, 0.27136102318763733, 0.2699832022190094, 0.2687491178512573, 0.2675250470638275, 0.2666378915309906, 0.2661384046077728, 0.2646294832229614, 0.26341500878334045, 0.2625666856765747, 0.2615855634212494, 0.26055243611335754, 0.2594667673110962, 0.25829756259918213, 0.2571716904640198, 0.25614163279533386, 0.2553824186325073, 0.25427496433258057, 0.25300347805023193, 0.25193721055984497, 0.2507994472980499, 0.24966883659362793, 0.24864360690116882, 0.2475571632385254, 0.24644465744495392, 0.2453002780675888, 0.24413461983203888, 0.2430523782968521, 0.24212712049484253, 0.24089080095291138, 0.23980869352817535, 0.23898150026798248, 0.237436443567276, 0.23631498217582703, 0.23511716723442078, 0.23424158990383148, 0.2329050749540329, 0.23177668452262878, 0.2305813878774643, 0.2295350879430771, 0.22861409187316895], 'accuracy': [0.9844368696212769, 0.9932088255882263, 0.9951896071434021, 0.996321439743042, 0.9974533319473267, 0.9983022212982178, 0.9983022212982178, 0.9988681674003601, 0.9985851645469666, 0.9991511106491089, 0.9991511106491089, 0.9988681674003601, 0.9991511106491089, 0.9991511106491089, 0.9994340538978577, 0.9994340538978577, 1.0, 0.9997170567512512, 1.0, 1.0, 0.9997170567512512, 1.0, 0.9994340538978577, 0.9994340538978577, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [1.0119553804397583, 1.0046290159225464, 0.9911753535270691, 0.9713867902755737, 0.9421144127845764, 0.9298878908157349, 0.861286997795105, 0.8278477191925049, 0.8034640550613403, 0.7115051746368408, 0.7069870829582214, 0.6467183828353882, 0.631714403629303, 0.582798421382904, 0.5584792494773865, 0.5351046323776245, 0.5135242342948914, 0.49584445357322693, 0.482860803604126, 0.47769078612327576, 0.47179195284843445, 0.47460126876831055, 0.47012603282928467, 0.4679870009422302, 0.4676345884799957, 0.47176653146743774, 0.47708675265312195, 0.4780329763889313, 0.49762603640556335, 0.47945600748062134, 0.4823286235332489, 0.48399826884269714, 0.492489755153656, 0.47991400957107544, 0.48605111241340637, 0.4808103144168854, 0.48110976815223694, 0.4846760928630829, 0.48825332522392273, 0.49363163113594055, 0.4881901144981384, 0.4848002791404724, 0.48827603459358215, 0.48369812965393066, 0.4850640594959259, 0.4864554703235626, 0.4808584749698639, 0.49738532304763794, 0.4865421652793884, 0.4811985194683075, 0.4797699749469757, 0.4926513135433197, 0.4803512990474701, 0.47784748673439026, 0.48620522022247314, 0.479799747467041, 0.49221864342689514, 0.48544755578041077, 0.481664776802063, 0.4822916090488434, 0.4845001697540283, 0.4899579882621765, 0.4872201085090637, 0.4783741533756256, 0.5020791292190552, 0.4829230010509491, 0.48218849301338196, 0.47443386912345886, 0.48330026865005493, 0.47396257519721985, 0.4766903817653656, 0.4900517761707306, 0.477632075548172, 0.4768858551979065, 0.4835547208786011, 0.48738619685173035, 0.4936377704143524, 0.47195547819137573, 0.4710924029350281, 0.47207164764404297, 0.4691289961338043, 0.47957974672317505, 0.4606967866420746, 0.47816523909568787, 0.46172210574150085, 0.4639856815338135, 0.481196790933609, 0.4603571891784668, 0.46223267912864685, 0.49145182967185974, 0.46103009581565857, 0.46951931715011597, 0.463939368724823, 0.4608151316642761, 0.45503318309783936, 0.46276819705963135, 0.45737001299858093, 0.46767526865005493, 0.45583418011665344, 0.46470463275909424], 'val_accuracy': [0.4977375566959381, 0.5011312365531921, 0.5113122463226318, 0.5350678563117981, 0.5678732991218567, 0.5757918357849121, 0.6889140009880066, 0.7251130938529968, 0.7454751133918762, 0.8936651349067688, 0.8540723919868469, 0.9219456911087036, 0.901583731174469, 0.929864227771759, 0.9389140009880066, 0.942307710647583, 0.9445701241493225, 0.9457013607025146, 0.9434388875961304, 0.9468325972557068, 0.9468325972557068, 0.9377828240394592, 0.942307710647583, 0.9400452375411987, 0.9445701241493225, 0.942307710647583, 0.9389140009880066, 0.9400452375411987, 0.9287330508232117, 0.9377828240394592, 0.9389140009880066, 0.9366515874862671, 0.9332579374313354, 0.9434388875961304, 0.9377828240394592, 0.9411764740943909, 0.9479637742042542, 0.9366515874862671, 0.942307710647583, 0.9321267008781433, 0.9377828240394592, 0.9377828240394592, 0.9332579374313354, 0.9389140009880066, 0.9389140009880066, 0.9366515874862671, 0.942307710647583, 0.9309954643249512, 0.9332579374313354, 0.935520350933075, 0.9400452375411987, 0.9276018142700195, 0.935520350933075, 0.9411764740943909, 0.9332579374313354, 0.9389140009880066, 0.929864227771759, 0.9332579374313354, 0.9400452375411987, 0.9366515874862671, 0.9321267008781433, 0.9287330508232117, 0.9287330508232117, 0.935520350933075, 0.9253393411636353, 0.9332579374313354, 0.9287330508232117, 0.935520350933075, 0.9276018142700195, 0.9366515874862671, 0.929864227771759, 0.9264705777168274, 0.9287330508232117, 0.9332579374313354, 0.9253393411636353, 0.9253393411636353, 0.9219456911087036, 0.9343891143798828, 0.9321267008781433, 0.9287330508232117, 0.9332579374313354, 0.9253393411636353, 0.9366515874862671, 0.9242081642150879, 0.935520350933075, 0.9321267008781433, 0.9242081642150879, 0.9332579374313354, 0.9287330508232117, 0.9196832776069641, 0.9332579374313354, 0.9264705777168274, 0.9287330508232117, 0.929864227771759, 0.9309954643249512, 0.9264705777168274, 0.9309954643249512, 0.9242081642150879, 0.9287330508232117, 0.9242081642150879]}\n","45/45 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 5s 31ms/step - loss: 0.3453 - accuracy: 0.9897 - val_loss: 1.0211 - val_accuracy: 0.4855\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 15ms/step - loss: 0.3311 - accuracy: 0.9943 - val_loss: 1.0197 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3288 - accuracy: 0.9961 - val_loss: 1.0055 - val_accuracy: 0.4979\n","Epoch 4/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3280 - accuracy: 0.9969 - val_loss: 0.9877 - val_accuracy: 0.5145\n","Epoch 5/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3233 - accuracy: 0.9979 - val_loss: 0.9745 - val_accuracy: 0.5289\n","Epoch 6/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3299 - accuracy: 0.9953 - val_loss: 0.9348 - val_accuracy: 0.5630\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3205 - accuracy: 0.9992 - val_loss: 0.8896 - val_accuracy: 0.6105\n","Epoch 8/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3184 - accuracy: 0.9995 - val_loss: 0.8215 - val_accuracy: 0.7169\n","Epoch 9/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3182 - accuracy: 0.9992 - val_loss: 0.8065 - val_accuracy: 0.7262\n","Epoch 10/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3179 - accuracy: 0.9992 - val_loss: 0.7394 - val_accuracy: 0.8130\n","Epoch 11/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3155 - accuracy: 0.9995 - val_loss: 0.6880 - val_accuracy: 0.8512\n","Epoch 12/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3138 - accuracy: 1.0000 - val_loss: 0.6340 - val_accuracy: 0.8988\n","Epoch 13/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3129 - accuracy: 1.0000 - val_loss: 0.6062 - val_accuracy: 0.9060\n","Epoch 14/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3119 - accuracy: 1.0000 - val_loss: 0.5779 - val_accuracy: 0.9081\n","Epoch 15/100\n","31/31 [==============================] - 3s 109ms/step - loss: 0.3116 - accuracy: 0.9997 - val_loss: 0.5507 - val_accuracy: 0.9153\n","Epoch 16/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3115 - accuracy: 1.0000 - val_loss: 0.5480 - val_accuracy: 0.9153\n","Epoch 17/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3104 - accuracy: 1.0000 - val_loss: 0.5107 - val_accuracy: 0.9349\n","Epoch 18/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3096 - accuracy: 1.0000 - val_loss: 0.5068 - val_accuracy: 0.9205\n","Epoch 19/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3085 - accuracy: 0.9997 - val_loss: 0.5040 - val_accuracy: 0.9205\n","Epoch 20/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3074 - accuracy: 0.9997 - val_loss: 0.5061 - val_accuracy: 0.9308\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3062 - accuracy: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.9267\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3050 - accuracy: 1.0000 - val_loss: 0.5164 - val_accuracy: 0.9236\n","Epoch 23/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3041 - accuracy: 1.0000 - val_loss: 0.5197 - val_accuracy: 0.9329\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3033 - accuracy: 1.0000 - val_loss: 0.5284 - val_accuracy: 0.9267\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3024 - accuracy: 0.9997 - val_loss: 0.5293 - val_accuracy: 0.9267\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3017 - accuracy: 0.9997 - val_loss: 0.5560 - val_accuracy: 0.9163\n","Epoch 27/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3021 - accuracy: 1.0000 - val_loss: 0.5417 - val_accuracy: 0.9298\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2997 - accuracy: 1.0000 - val_loss: 0.5425 - val_accuracy: 0.9277\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2991 - accuracy: 1.0000 - val_loss: 0.5467 - val_accuracy: 0.9246\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2979 - accuracy: 1.0000 - val_loss: 0.5503 - val_accuracy: 0.9215\n","Epoch 31/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2972 - accuracy: 1.0000 - val_loss: 0.5473 - val_accuracy: 0.9287\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2961 - accuracy: 1.0000 - val_loss: 0.5623 - val_accuracy: 0.9184\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2957 - accuracy: 1.0000 - val_loss: 0.5564 - val_accuracy: 0.9215\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2946 - accuracy: 1.0000 - val_loss: 0.5532 - val_accuracy: 0.9184\n","Epoch 35/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2930 - accuracy: 1.0000 - val_loss: 0.5543 - val_accuracy: 0.9225\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2928 - accuracy: 1.0000 - val_loss: 0.5598 - val_accuracy: 0.9236\n","Epoch 37/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2913 - accuracy: 1.0000 - val_loss: 0.5549 - val_accuracy: 0.9194\n","Epoch 38/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2904 - accuracy: 1.0000 - val_loss: 0.5534 - val_accuracy: 0.9194\n","Epoch 39/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2893 - accuracy: 1.0000 - val_loss: 0.5524 - val_accuracy: 0.9246\n","Epoch 40/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2897 - accuracy: 1.0000 - val_loss: 0.5587 - val_accuracy: 0.9205\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2875 - accuracy: 1.0000 - val_loss: 0.5647 - val_accuracy: 0.9174\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2866 - accuracy: 1.0000 - val_loss: 0.5585 - val_accuracy: 0.9205\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2857 - accuracy: 1.0000 - val_loss: 0.5585 - val_accuracy: 0.9205\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2852 - accuracy: 1.0000 - val_loss: 0.5654 - val_accuracy: 0.9205\n","Epoch 45/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2839 - accuracy: 1.0000 - val_loss: 0.5581 - val_accuracy: 0.9205\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2825 - accuracy: 1.0000 - val_loss: 0.5504 - val_accuracy: 0.9236\n","Epoch 47/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2814 - accuracy: 1.0000 - val_loss: 0.5557 - val_accuracy: 0.9225\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2805 - accuracy: 1.0000 - val_loss: 0.5581 - val_accuracy: 0.9215\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2795 - accuracy: 1.0000 - val_loss: 0.5560 - val_accuracy: 0.9236\n","Epoch 50/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2784 - accuracy: 1.0000 - val_loss: 0.5559 - val_accuracy: 0.9194\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2776 - accuracy: 1.0000 - val_loss: 0.5556 - val_accuracy: 0.9215\n","Epoch 52/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2767 - accuracy: 1.0000 - val_loss: 0.5585 - val_accuracy: 0.9194\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2756 - accuracy: 1.0000 - val_loss: 0.5742 - val_accuracy: 0.9132\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2744 - accuracy: 1.0000 - val_loss: 0.5615 - val_accuracy: 0.9205\n","Epoch 55/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2740 - accuracy: 0.9997 - val_loss: 0.5510 - val_accuracy: 0.9215\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2724 - accuracy: 1.0000 - val_loss: 0.5551 - val_accuracy: 0.9205\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2711 - accuracy: 1.0000 - val_loss: 0.5499 - val_accuracy: 0.9184\n","Epoch 58/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2701 - accuracy: 1.0000 - val_loss: 0.5576 - val_accuracy: 0.9163\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2689 - accuracy: 1.0000 - val_loss: 0.5559 - val_accuracy: 0.9184\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2679 - accuracy: 1.0000 - val_loss: 0.5604 - val_accuracy: 0.9194\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2670 - accuracy: 1.0000 - val_loss: 0.5545 - val_accuracy: 0.9205\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2661 - accuracy: 1.0000 - val_loss: 0.5493 - val_accuracy: 0.9174\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2648 - accuracy: 1.0000 - val_loss: 0.5582 - val_accuracy: 0.9184\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2636 - accuracy: 1.0000 - val_loss: 0.5750 - val_accuracy: 0.9101\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2631 - accuracy: 1.0000 - val_loss: 0.5487 - val_accuracy: 0.9194\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2616 - accuracy: 1.0000 - val_loss: 0.5478 - val_accuracy: 0.9184\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2601 - accuracy: 1.0000 - val_loss: 0.5486 - val_accuracy: 0.9174\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2590 - accuracy: 1.0000 - val_loss: 0.5499 - val_accuracy: 0.9194\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2579 - accuracy: 1.0000 - val_loss: 0.5535 - val_accuracy: 0.9194\n","Epoch 70/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2569 - accuracy: 1.0000 - val_loss: 0.5484 - val_accuracy: 0.9163\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2557 - accuracy: 1.0000 - val_loss: 0.5465 - val_accuracy: 0.9132\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2547 - accuracy: 1.0000 - val_loss: 0.5456 - val_accuracy: 0.9194\n","Epoch 73/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2534 - accuracy: 1.0000 - val_loss: 0.5468 - val_accuracy: 0.9184\n","Epoch 74/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2525 - accuracy: 1.0000 - val_loss: 0.5531 - val_accuracy: 0.9184\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2512 - accuracy: 1.0000 - val_loss: 0.5482 - val_accuracy: 0.9174\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2499 - accuracy: 1.0000 - val_loss: 0.5461 - val_accuracy: 0.9163\n","Epoch 77/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2491 - accuracy: 1.0000 - val_loss: 0.5481 - val_accuracy: 0.9205\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2477 - accuracy: 1.0000 - val_loss: 0.5463 - val_accuracy: 0.9174\n","Epoch 79/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2468 - accuracy: 1.0000 - val_loss: 0.5438 - val_accuracy: 0.9184\n","Epoch 80/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2454 - accuracy: 1.0000 - val_loss: 0.5484 - val_accuracy: 0.9163\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2443 - accuracy: 1.0000 - val_loss: 0.5430 - val_accuracy: 0.9194\n","Epoch 82/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2430 - accuracy: 1.0000 - val_loss: 0.5547 - val_accuracy: 0.9153\n","Epoch 83/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2421 - accuracy: 1.0000 - val_loss: 0.5517 - val_accuracy: 0.9174\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2407 - accuracy: 1.0000 - val_loss: 0.5477 - val_accuracy: 0.9143\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2399 - accuracy: 1.0000 - val_loss: 0.5500 - val_accuracy: 0.9143\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2385 - accuracy: 1.0000 - val_loss: 0.5454 - val_accuracy: 0.9132\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2371 - accuracy: 1.0000 - val_loss: 0.5423 - val_accuracy: 0.9174\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2361 - accuracy: 1.0000 - val_loss: 0.5357 - val_accuracy: 0.9143\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2348 - accuracy: 1.0000 - val_loss: 0.5350 - val_accuracy: 0.9132\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2336 - accuracy: 1.0000 - val_loss: 0.5492 - val_accuracy: 0.9132\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2324 - accuracy: 1.0000 - val_loss: 0.5368 - val_accuracy: 0.9153\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2313 - accuracy: 1.0000 - val_loss: 0.5520 - val_accuracy: 0.9132\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2302 - accuracy: 1.0000 - val_loss: 0.5391 - val_accuracy: 0.9153\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2287 - accuracy: 1.0000 - val_loss: 0.5634 - val_accuracy: 0.9132\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2280 - accuracy: 1.0000 - val_loss: 0.5492 - val_accuracy: 0.9091\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2408 - accuracy: 0.9961 - val_loss: 0.5756 - val_accuracy: 0.9091\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2314 - accuracy: 0.9984 - val_loss: 0.5487 - val_accuracy: 0.9081\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2258 - accuracy: 1.0000 - val_loss: 0.5559 - val_accuracy: 0.9112\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2254 - accuracy: 1.0000 - val_loss: 0.5372 - val_accuracy: 0.9112\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2240 - accuracy: 1.0000 - val_loss: 0.5388 - val_accuracy: 0.9143\n","{'loss': [0.3452548384666443, 0.33106735348701477, 0.3287737965583801, 0.3280245065689087, 0.32331526279449463, 0.3299393653869629, 0.32047075033187866, 0.318401962518692, 0.31818199157714844, 0.3178882300853729, 0.3154834806919098, 0.31377094984054565, 0.31289157271385193, 0.31191545724868774, 0.3116108179092407, 0.3114596903324127, 0.3103792667388916, 0.3096318244934082, 0.308546245098114, 0.30741992592811584, 0.30618077516555786, 0.30500108003616333, 0.3040706217288971, 0.30327197909355164, 0.3023725152015686, 0.30169373750686646, 0.3020627498626709, 0.2996861934661865, 0.2991041839122772, 0.2979331314563751, 0.29719260334968567, 0.2960990369319916, 0.29569533467292786, 0.294602632522583, 0.29297932982444763, 0.29280540347099304, 0.2913302779197693, 0.2904214859008789, 0.289287805557251, 0.28965795040130615, 0.28751349449157715, 0.2866334021091461, 0.28566214442253113, 0.285249799489975, 0.28387659788131714, 0.28254520893096924, 0.28138861060142517, 0.28047657012939453, 0.2794836461544037, 0.2784097492694855, 0.27758264541625977, 0.2767394185066223, 0.27555251121520996, 0.2743702828884125, 0.27398863434791565, 0.272359699010849, 0.27113330364227295, 0.27010980248451233, 0.2689323425292969, 0.2679332196712494, 0.26697656512260437, 0.2661294639110565, 0.26475709676742554, 0.26360321044921875, 0.2631077468395233, 0.26158407330513, 0.2600992023944855, 0.2589704394340515, 0.25791263580322266, 0.2569321095943451, 0.2557297945022583, 0.2546709477901459, 0.2533983588218689, 0.252535879611969, 0.25116613507270813, 0.24989573657512665, 0.24908733367919922, 0.24768324196338654, 0.2467970848083496, 0.24540944397449493, 0.24426671862602234, 0.2430284023284912, 0.2421281486749649, 0.2406795173883438, 0.239906445145607, 0.23851586878299713, 0.23712047934532166, 0.23607900738716125, 0.23480550944805145, 0.2335832267999649, 0.2323625385761261, 0.23130038380622864, 0.2302064746618271, 0.2286832183599472, 0.22799360752105713, 0.24080555140972137, 0.23135831952095032, 0.2258121371269226, 0.2253536731004715, 0.22399844229221344], 'accuracy': [0.9896640777587891, 0.9943152666091919, 0.9961240291595459, 0.9968992471694946, 0.9979327917098999, 0.9953488111495972, 0.9992247819900513, 0.9994832277297974, 0.9992247819900513, 0.9992247819900513, 0.9994832277297974, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0, 1.0, 1.0, 0.9997416138648987, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9961240291595459, 0.9984496235847473, 1.0, 1.0, 1.0], 'val_loss': [1.0211247205734253, 1.019669532775879, 1.0055441856384277, 0.9876982569694519, 0.9744872450828552, 0.9348328709602356, 0.8895662426948547, 0.8214632868766785, 0.8064572215080261, 0.73935467004776, 0.6879754662513733, 0.6340369582176208, 0.6061652898788452, 0.5778750777244568, 0.5507307648658752, 0.5479778051376343, 0.51067715883255, 0.5068057179450989, 0.5040379166603088, 0.5060546398162842, 0.5082138180732727, 0.5164312124252319, 0.5196596384048462, 0.5284073352813721, 0.5292695760726929, 0.5559983253479004, 0.5416572093963623, 0.5425256490707397, 0.546689510345459, 0.5503392219543457, 0.5473426580429077, 0.5623232126235962, 0.5563657879829407, 0.553163468837738, 0.5543122291564941, 0.5598305463790894, 0.5548897981643677, 0.5534000992774963, 0.5524441003799438, 0.5587263107299805, 0.5646834373474121, 0.5585384368896484, 0.5585336089134216, 0.56535404920578, 0.5580639839172363, 0.5504065155982971, 0.5556861162185669, 0.5581392645835876, 0.5560413599014282, 0.5558554530143738, 0.55560302734375, 0.5584654808044434, 0.574193000793457, 0.5614566206932068, 0.551042377948761, 0.5550583600997925, 0.5499395132064819, 0.5576274991035461, 0.5559408664703369, 0.5603542923927307, 0.5544676184654236, 0.5493375062942505, 0.558169424533844, 0.5749983787536621, 0.5487085580825806, 0.5477738976478577, 0.548618495464325, 0.5499231219291687, 0.5535467863082886, 0.5484408736228943, 0.5465285778045654, 0.5455808043479919, 0.5467681288719177, 0.5530614256858826, 0.5481836199760437, 0.546067476272583, 0.5481101870536804, 0.5462673306465149, 0.5438011884689331, 0.5484126806259155, 0.5429859757423401, 0.5547439455986023, 0.5516781210899353, 0.5476721525192261, 0.5499760508537292, 0.5453916192054749, 0.5422970652580261, 0.5357007384300232, 0.5349843502044678, 0.5492129325866699, 0.5367575883865356, 0.5519728660583496, 0.5390783548355103, 0.5634384751319885, 0.549206018447876, 0.5756356120109558, 0.5486947298049927, 0.5558763146400452, 0.5372474789619446, 0.5387565493583679], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.49793389439582825, 0.5144628286361694, 0.5289255976676941, 0.5630165338516235, 0.6105371713638306, 0.7169421315193176, 0.7262396812438965, 0.8130165338516235, 0.8512396812438965, 0.8987603187561035, 0.9059917330741882, 0.9080578684806824, 0.9152892827987671, 0.9152892827987671, 0.9349173307418823, 0.9204545617103577, 0.9204545617103577, 0.9307851195335388, 0.9266529083251953, 0.9235537052154541, 0.932851254940033, 0.9266529083251953, 0.9266529083251953, 0.9163222908973694, 0.9297520518302917, 0.9276859760284424, 0.9245867729187012, 0.9214876294136047, 0.9287189841270447, 0.9183884263038635, 0.9214876294136047, 0.9183884263038635, 0.922520637512207, 0.9235537052154541, 0.9194214940071106, 0.9194214940071106, 0.9245867729187012, 0.9204545617103577, 0.9173553586006165, 0.9204545617103577, 0.9204545617103577, 0.9204545617103577, 0.9204545617103577, 0.9235537052154541, 0.922520637512207, 0.9214876294136047, 0.9235537052154541, 0.9194214940071106, 0.9214876294136047, 0.9194214940071106, 0.913223147392273, 0.9204545617103577, 0.9214876294136047, 0.9204545617103577, 0.9183884263038635, 0.9163222908973694, 0.9183884263038635, 0.9194214940071106, 0.9204545617103577, 0.9173553586006165, 0.9183884263038635, 0.9101239442825317, 0.9194214940071106, 0.9183884263038635, 0.9173553586006165, 0.9194214940071106, 0.9194214940071106, 0.9163222908973694, 0.913223147392273, 0.9194214940071106, 0.9183884263038635, 0.9183884263038635, 0.9173553586006165, 0.9163222908973694, 0.9204545617103577, 0.9173553586006165, 0.9183884263038635, 0.9163222908973694, 0.9194214940071106, 0.9152892827987671, 0.9173553586006165, 0.91425621509552, 0.91425621509552, 0.913223147392273, 0.9173553586006165, 0.91425621509552, 0.913223147392273, 0.913223147392273, 0.9152892827987671, 0.913223147392273, 0.9152892827987671, 0.913223147392273, 0.9090909361839294, 0.9090909361839294, 0.9080578684806824, 0.9111570119857788, 0.9111570119857788, 0.91425621509552]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.2422 - accuracy: 0.9958"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 4s 42ms/step - loss: 0.2429 - accuracy: 0.9957 - val_loss: 0.9325 - val_accuracy: 0.4903\n","Epoch 2/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2357 - accuracy: 0.9973 - val_loss: 0.9344 - val_accuracy: 0.4903\n","Epoch 3/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.2315 - accuracy: 0.9992 - val_loss: 0.9191 - val_accuracy: 0.4946\n","Epoch 4/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.2298 - accuracy: 0.9997 - val_loss: 0.9069 - val_accuracy: 0.5032\n","Epoch 5/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.2283 - accuracy: 0.9997 - val_loss: 0.8660 - val_accuracy: 0.5388\n","Epoch 6/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.2272 - accuracy: 0.9997 - val_loss: 0.8209 - val_accuracy: 0.6002\n","Epoch 7/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.2265 - accuracy: 1.0000 - val_loss: 0.7906 - val_accuracy: 0.6390\n","Epoch 8/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.2257 - accuracy: 1.0000 - val_loss: 0.7426 - val_accuracy: 0.7004\n","Epoch 9/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2253 - accuracy: 1.0000 - val_loss: 0.6771 - val_accuracy: 0.7834\n","Epoch 10/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.2241 - accuracy: 0.9997 - val_loss: 0.6512 - val_accuracy: 0.7985\n","Epoch 11/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2237 - accuracy: 1.0000 - val_loss: 0.5877 - val_accuracy: 0.8718\n","Epoch 12/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2226 - accuracy: 1.0000 - val_loss: 0.5314 - val_accuracy: 0.9127\n","Epoch 13/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2220 - accuracy: 1.0000 - val_loss: 0.5131 - val_accuracy: 0.9062\n","Epoch 14/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2211 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.9332\n","Epoch 15/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2202 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.9461\n","Epoch 16/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2194 - accuracy: 1.0000 - val_loss: 0.4183 - val_accuracy: 0.9494\n","Epoch 17/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2187 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.9569\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2178 - accuracy: 1.0000 - val_loss: 0.3831 - val_accuracy: 0.9591\n","Epoch 19/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.9515\n","Epoch 20/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9515\n","Epoch 21/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2154 - accuracy: 1.0000 - val_loss: 0.3626 - val_accuracy: 0.9547\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.9569\n","Epoch 23/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2137 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.9569\n","Epoch 24/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2133 - accuracy: 1.0000 - val_loss: 0.3728 - val_accuracy: 0.9515\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.9547\n","Epoch 26/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.3661 - val_accuracy: 0.9537\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2102 - accuracy: 1.0000 - val_loss: 0.3725 - val_accuracy: 0.9504\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.3681 - val_accuracy: 0.9526\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.3824 - val_accuracy: 0.9547\n","Epoch 30/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2080 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.9526\n","Epoch 31/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2066 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.9537\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2058 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.9515\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2056 - accuracy: 1.0000 - val_loss: 0.3813 - val_accuracy: 0.9515\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2045 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 0.9515\n","Epoch 35/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2032 - accuracy: 1.0000 - val_loss: 0.3772 - val_accuracy: 0.9494\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2024 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.9504\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2016 - accuracy: 1.0000 - val_loss: 0.3750 - val_accuracy: 0.9504\n","Epoch 38/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2005 - accuracy: 1.0000 - val_loss: 0.3746 - val_accuracy: 0.9515\n","Epoch 39/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1994 - accuracy: 1.0000 - val_loss: 0.3756 - val_accuracy: 0.9515\n","Epoch 40/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1988 - accuracy: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.9429\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1979 - accuracy: 1.0000 - val_loss: 0.3727 - val_accuracy: 0.9515\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1966 - accuracy: 1.0000 - val_loss: 0.3756 - val_accuracy: 0.9504\n","Epoch 43/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1956 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.9472\n","Epoch 44/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1948 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.9504\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1943 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.9504\n","Epoch 46/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1929 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.9472\n","Epoch 47/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1919 - accuracy: 1.0000 - val_loss: 0.3729 - val_accuracy: 0.9515\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1910 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.9515\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1900 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.9407\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1891 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.9537\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1880 - accuracy: 1.0000 - val_loss: 0.3706 - val_accuracy: 0.9504\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1870 - accuracy: 1.0000 - val_loss: 0.3688 - val_accuracy: 0.9515\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1861 - accuracy: 1.0000 - val_loss: 0.3688 - val_accuracy: 0.9537\n","Epoch 54/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1851 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.9515\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1843 - accuracy: 1.0000 - val_loss: 0.3691 - val_accuracy: 0.9504\n","Epoch 56/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1832 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 0.9397\n","Epoch 57/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1823 - accuracy: 1.0000 - val_loss: 0.3743 - val_accuracy: 0.9483\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1814 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.9483\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1804 - accuracy: 1.0000 - val_loss: 0.3695 - val_accuracy: 0.9504\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1792 - accuracy: 1.0000 - val_loss: 0.3756 - val_accuracy: 0.9472\n","Epoch 61/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1782 - accuracy: 1.0000 - val_loss: 0.3680 - val_accuracy: 0.9504\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1772 - accuracy: 1.0000 - val_loss: 0.3665 - val_accuracy: 0.9504\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1762 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.9504\n","Epoch 64/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1752 - accuracy: 1.0000 - val_loss: 0.3750 - val_accuracy: 0.9494\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1744 - accuracy: 1.0000 - val_loss: 0.3680 - val_accuracy: 0.9483\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1731 - accuracy: 1.0000 - val_loss: 0.3676 - val_accuracy: 0.9483\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1723 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.9461\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1713 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9461\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1703 - accuracy: 1.0000 - val_loss: 0.3676 - val_accuracy: 0.9494\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1693 - accuracy: 1.0000 - val_loss: 0.3719 - val_accuracy: 0.9483\n","Epoch 71/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1683 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.9461\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1673 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.9429\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1663 - accuracy: 1.0000 - val_loss: 0.3614 - val_accuracy: 0.9494\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1653 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.9450\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1643 - accuracy: 1.0000 - val_loss: 0.3611 - val_accuracy: 0.9429\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1633 - accuracy: 1.0000 - val_loss: 0.3616 - val_accuracy: 0.9494\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1623 - accuracy: 1.0000 - val_loss: 0.3635 - val_accuracy: 0.9472\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1613 - accuracy: 1.0000 - val_loss: 0.3589 - val_accuracy: 0.9450\n","Epoch 79/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.1604 - accuracy: 1.0000 - val_loss: 0.3660 - val_accuracy: 0.9461\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1595 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.9375\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1586 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9397\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1576 - accuracy: 1.0000 - val_loss: 0.3647 - val_accuracy: 0.9364\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1565 - accuracy: 1.0000 - val_loss: 0.3576 - val_accuracy: 0.9450\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1553 - accuracy: 1.0000 - val_loss: 0.3561 - val_accuracy: 0.9418\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1544 - accuracy: 1.0000 - val_loss: 0.3563 - val_accuracy: 0.9429\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1534 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.9407\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1524 - accuracy: 1.0000 - val_loss: 0.3555 - val_accuracy: 0.9386\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.1515 - accuracy: 1.0000 - val_loss: 0.3609 - val_accuracy: 0.9364\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1508 - accuracy: 1.0000 - val_loss: 0.4047 - val_accuracy: 0.9256\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1511 - accuracy: 1.0000 - val_loss: 0.3675 - val_accuracy: 0.9375\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1502 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.9397\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1496 - accuracy: 0.9997 - val_loss: 0.3544 - val_accuracy: 0.9440\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1822 - accuracy: 0.9865 - val_loss: 0.6093 - val_accuracy: 0.8879\n","Epoch 94/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1663 - accuracy: 0.9949 - val_loss: 0.4182 - val_accuracy: 0.9213\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1497 - accuracy: 0.9995 - val_loss: 0.3807 - val_accuracy: 0.9289\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1479 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.9353\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1469 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.9343\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.1466 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.9321\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1464 - accuracy: 1.0000 - val_loss: 0.3667 - val_accuracy: 0.9353\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.1461 - accuracy: 1.0000 - val_loss: 0.3685 - val_accuracy: 0.9353\n","{'loss': [0.24291880428791046, 0.23566438257694244, 0.2314702719449997, 0.2297549545764923, 0.2282681167125702, 0.2272220104932785, 0.22654250264167786, 0.22565056383609772, 0.2252563089132309, 0.2241022288799286, 0.22373278439044952, 0.22258895635604858, 0.2219724953174591, 0.221083864569664, 0.22021399438381195, 0.21935400366783142, 0.2186831831932068, 0.2178012877702713, 0.2174026370048523, 0.21658550202846527, 0.21537084877490997, 0.21460169553756714, 0.21367895603179932, 0.21332426369190216, 0.2126327008008957, 0.2114424854516983, 0.21019317209720612, 0.20947422087192535, 0.20858797430992126, 0.20799396932125092, 0.20664682984352112, 0.20580679178237915, 0.20561550557613373, 0.20446056127548218, 0.20317256450653076, 0.20237767696380615, 0.20162731409072876, 0.20049349963665009, 0.19940854609012604, 0.1987808346748352, 0.1979343742132187, 0.19660572707653046, 0.19564074277877808, 0.1948426365852356, 0.19428130984306335, 0.19289490580558777, 0.19194968044757843, 0.19099636375904083, 0.18999160826206207, 0.18905507028102875, 0.18802127242088318, 0.18703247606754303, 0.18611153960227966, 0.1851227581501007, 0.1843062788248062, 0.1831865906715393, 0.18227936327457428, 0.18144617974758148, 0.18041734397411346, 0.17920516431331635, 0.17818640172481537, 0.17716635763645172, 0.17615444958209991, 0.17521187663078308, 0.17444922029972076, 0.1731332391500473, 0.17226198315620422, 0.1713385432958603, 0.170302614569664, 0.1692722588777542, 0.1683284044265747, 0.16734054684638977, 0.1663355827331543, 0.16530250012874603, 0.16429094970226288, 0.1632651835680008, 0.16230201721191406, 0.16129110753536224, 0.16038207709789276, 0.1594938337802887, 0.15857669711112976, 0.15760505199432373, 0.1564565896987915, 0.15532833337783813, 0.154367133975029, 0.15339723229408264, 0.15244372189044952, 0.1514597088098526, 0.1507541537284851, 0.15109455585479736, 0.1501835584640503, 0.14956437051296234, 0.18224956095218658, 0.16628886759281158, 0.14969773590564728, 0.1479329764842987, 0.14690451323986053, 0.146592915058136, 0.14639094471931458, 0.14613066613674164], 'accuracy': [0.9956896305084229, 0.9973060488700867, 0.9991918206214905, 0.9997305870056152, 0.9997305870056152, 0.9997305870056152, 1.0, 1.0, 1.0, 0.9997305870056152, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997305870056152, 0.9865301847457886, 0.9948814511299133, 0.9994612336158752, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.9324968457221985, 0.9344484210014343, 0.9190627336502075, 0.9068762063980103, 0.8659824728965759, 0.8208950757980347, 0.7906457781791687, 0.7425993084907532, 0.6771257519721985, 0.651190459728241, 0.5876849889755249, 0.5313689708709717, 0.5131052732467651, 0.4726644456386566, 0.4441887140274048, 0.4182833433151245, 0.3973005414009094, 0.3830944299697876, 0.39018142223358154, 0.3793095648288727, 0.36262595653533936, 0.35708868503570557, 0.3598416745662689, 0.3727757930755615, 0.37408027052879333, 0.36606472730636597, 0.3724954128265381, 0.3681493103504181, 0.3824242353439331, 0.3788818418979645, 0.37149596214294434, 0.37382766604423523, 0.3813008666038513, 0.38173773884773254, 0.37715184688568115, 0.39798399806022644, 0.37502315640449524, 0.37459665536880493, 0.375641793012619, 0.4061392843723297, 0.37272414565086365, 0.3755703866481781, 0.3733338415622711, 0.37236034870147705, 0.37244024872779846, 0.37510186433792114, 0.3729245066642761, 0.3761393129825592, 0.37571007013320923, 0.3701690435409546, 0.3705943524837494, 0.36878183484077454, 0.36878129839897156, 0.3750881850719452, 0.3691434860229492, 0.37621602416038513, 0.3742886185646057, 0.364982008934021, 0.3694990277290344, 0.3755900263786316, 0.3680243194103241, 0.3664524555206299, 0.3673405051231384, 0.37502574920654297, 0.36801666021347046, 0.3676488399505615, 0.3602612614631653, 0.36459824442863464, 0.36760449409484863, 0.37187522649765015, 0.3673195242881775, 0.3612573742866516, 0.36137908697128296, 0.3613361418247223, 0.3611379563808441, 0.3615823984146118, 0.36353427171707153, 0.3588676452636719, 0.3659532070159912, 0.38200825452804565, 0.35858801007270813, 0.3646848797798157, 0.357556015253067, 0.35607001185417175, 0.35628220438957214, 0.3558833599090576, 0.355480819940567, 0.36087682843208313, 0.40465018153190613, 0.36750686168670654, 0.3623276650905609, 0.35441726446151733, 0.609282374382019, 0.4182029664516449, 0.3806692361831665, 0.3723627030849457, 0.37020379304885864, 0.37150007486343384, 0.36673736572265625, 0.36850008368492126], 'val_accuracy': [0.4903017282485962, 0.4903017282485962, 0.49461206793785095, 0.5032327771186829, 0.5387930870056152, 0.600215494632721, 0.639008641242981, 0.7004310488700867, 0.7834051847457886, 0.798491358757019, 0.8717672228813171, 0.912715494632721, 0.90625, 0.9331896305084229, 0.9461206793785095, 0.9493534564971924, 0.9568965435028076, 0.9590517282485962, 0.951508641242981, 0.951508641242981, 0.954741358757019, 0.9568965435028076, 0.9568965435028076, 0.951508641242981, 0.954741358757019, 0.9536637663841248, 0.9504310488700867, 0.9525862336158752, 0.954741358757019, 0.9525862336158752, 0.9536637663841248, 0.951508641242981, 0.951508641242981, 0.951508641242981, 0.9493534564971924, 0.9504310488700867, 0.9504310488700867, 0.951508641242981, 0.951508641242981, 0.9428879022598267, 0.951508641242981, 0.9504310488700867, 0.9471982717514038, 0.9504310488700867, 0.9504310488700867, 0.9471982717514038, 0.951508641242981, 0.951508641242981, 0.9407327771186829, 0.9536637663841248, 0.9504310488700867, 0.951508641242981, 0.9536637663841248, 0.951508641242981, 0.9504310488700867, 0.9396551847457886, 0.9482758641242981, 0.9482758641242981, 0.9504310488700867, 0.9471982717514038, 0.9504310488700867, 0.9504310488700867, 0.9504310488700867, 0.9493534564971924, 0.9482758641242981, 0.9482758641242981, 0.9461206793785095, 0.9461206793785095, 0.9493534564971924, 0.9482758641242981, 0.9461206793785095, 0.9428879022598267, 0.9493534564971924, 0.9450430870056152, 0.9428879022598267, 0.9493534564971924, 0.9471982717514038, 0.9450430870056152, 0.9461206793785095, 0.9375, 0.9396551847457886, 0.9364224076271057, 0.9450430870056152, 0.9418103694915771, 0.9428879022598267, 0.9407327771186829, 0.9385775923728943, 0.9364224076271057, 0.9256465435028076, 0.9375, 0.9396551847457886, 0.943965494632721, 0.8879310488700867, 0.9213362336158752, 0.9288793206214905, 0.9353448152542114, 0.9342672228813171, 0.9321120977401733, 0.9353448152542114, 0.9353448152542114]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.2472 - accuracy: 0.9931"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 5s 44ms/step - loss: 0.2476 - accuracy: 0.9932 - val_loss: 0.9254 - val_accuracy: 0.5000\n","Epoch 2/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.2380 - accuracy: 0.9969 - val_loss: 0.9136 - val_accuracy: 0.5057\n","Epoch 3/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2331 - accuracy: 0.9983 - val_loss: 0.9038 - val_accuracy: 0.5147\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2315 - accuracy: 0.9992 - val_loss: 0.8766 - val_accuracy: 0.5441\n","Epoch 5/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2295 - accuracy: 0.9994 - val_loss: 0.8524 - val_accuracy: 0.5656\n","Epoch 6/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2286 - accuracy: 0.9994 - val_loss: 0.8111 - val_accuracy: 0.6176\n","Epoch 7/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.2274 - accuracy: 0.9997 - val_loss: 0.7552 - val_accuracy: 0.7081\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2276 - accuracy: 0.9994 - val_loss: 0.7026 - val_accuracy: 0.7805\n","Epoch 9/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2263 - accuracy: 1.0000 - val_loss: 0.6725 - val_accuracy: 0.8054\n","Epoch 10/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2251 - accuracy: 1.0000 - val_loss: 0.6434 - val_accuracy: 0.8224\n","Epoch 11/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.2246 - accuracy: 1.0000 - val_loss: 0.5759 - val_accuracy: 0.9061\n","Epoch 12/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2244 - accuracy: 1.0000 - val_loss: 0.5400 - val_accuracy: 0.9253\n","Epoch 13/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2235 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.9412\n","Epoch 14/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2222 - accuracy: 1.0000 - val_loss: 0.4807 - val_accuracy: 0.9423\n","Epoch 15/100\n","28/28 [==============================] - 1s 49ms/step - loss: 0.2216 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.9548\n","Epoch 16/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2208 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.9412\n","Epoch 17/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2206 - accuracy: 1.0000 - val_loss: 0.4015 - val_accuracy: 0.9548\n","Epoch 18/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.2192 - accuracy: 1.0000 - val_loss: 0.3831 - val_accuracy: 0.9570\n","Epoch 19/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2184 - accuracy: 1.0000 - val_loss: 0.3712 - val_accuracy: 0.9525\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2179 - accuracy: 1.0000 - val_loss: 0.3644 - val_accuracy: 0.9570\n","Epoch 21/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.9548\n","Epoch 22/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.3546 - val_accuracy: 0.9536\n","Epoch 23/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2159 - accuracy: 1.0000 - val_loss: 0.3503 - val_accuracy: 0.9559\n","Epoch 24/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2147 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.9559\n","Epoch 25/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2141 - accuracy: 1.0000 - val_loss: 0.3578 - val_accuracy: 0.9570\n","Epoch 26/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.3551 - val_accuracy: 0.9559\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.3543 - val_accuracy: 0.9548\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.3546 - val_accuracy: 0.9548\n","Epoch 29/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2107 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 0.9525\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2098 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.9536\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2097 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.9536\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2084 - accuracy: 1.0000 - val_loss: 0.3621 - val_accuracy: 0.9559\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2074 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.9559\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2066 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 0.9559\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2057 - accuracy: 1.0000 - val_loss: 0.3614 - val_accuracy: 0.9514\n","Epoch 36/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2049 - accuracy: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.9468\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2042 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.9514\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2032 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.9548\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2024 - accuracy: 1.0000 - val_loss: 0.3614 - val_accuracy: 0.9525\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2014 - accuracy: 1.0000 - val_loss: 0.3589 - val_accuracy: 0.9548\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2006 - accuracy: 1.0000 - val_loss: 0.3574 - val_accuracy: 0.9548\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1997 - accuracy: 1.0000 - val_loss: 0.3610 - val_accuracy: 0.9514\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1989 - accuracy: 1.0000 - val_loss: 0.3597 - val_accuracy: 0.9514\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1979 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9491\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1970 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.9525\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1960 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.9536\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1951 - accuracy: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.9480\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1943 - accuracy: 1.0000 - val_loss: 0.3557 - val_accuracy: 0.9536\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1934 - accuracy: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.9525\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1926 - accuracy: 1.0000 - val_loss: 0.3557 - val_accuracy: 0.9480\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1914 - accuracy: 1.0000 - val_loss: 0.3549 - val_accuracy: 0.9514\n","Epoch 52/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1906 - accuracy: 1.0000 - val_loss: 0.3587 - val_accuracy: 0.9468\n","Epoch 53/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1899 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.9434\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1888 - accuracy: 1.0000 - val_loss: 0.3624 - val_accuracy: 0.9491\n","Epoch 55/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1879 - accuracy: 1.0000 - val_loss: 0.3583 - val_accuracy: 0.9502\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1870 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.9468\n","Epoch 57/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1860 - accuracy: 1.0000 - val_loss: 0.3547 - val_accuracy: 0.9502\n","Epoch 58/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1850 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 0.9502\n","Epoch 59/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1840 - accuracy: 1.0000 - val_loss: 0.3570 - val_accuracy: 0.9491\n","Epoch 60/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1831 - accuracy: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.9378\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1823 - accuracy: 1.0000 - val_loss: 0.3499 - val_accuracy: 0.9491\n","Epoch 62/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1811 - accuracy: 1.0000 - val_loss: 0.3533 - val_accuracy: 0.9480\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1802 - accuracy: 1.0000 - val_loss: 0.3553 - val_accuracy: 0.9514\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1792 - accuracy: 1.0000 - val_loss: 0.3477 - val_accuracy: 0.9514\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1783 - accuracy: 1.0000 - val_loss: 0.3466 - val_accuracy: 0.9514\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1773 - accuracy: 1.0000 - val_loss: 0.3469 - val_accuracy: 0.9491\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1768 - accuracy: 1.0000 - val_loss: 0.3500 - val_accuracy: 0.9468\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1755 - accuracy: 1.0000 - val_loss: 0.3500 - val_accuracy: 0.9491\n","Epoch 69/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1745 - accuracy: 1.0000 - val_loss: 0.3521 - val_accuracy: 0.9480\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1739 - accuracy: 1.0000 - val_loss: 0.3519 - val_accuracy: 0.9446\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1728 - accuracy: 1.0000 - val_loss: 0.3468 - val_accuracy: 0.9502\n","Epoch 72/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1717 - accuracy: 1.0000 - val_loss: 0.3653 - val_accuracy: 0.9378\n","Epoch 73/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1708 - accuracy: 1.0000 - val_loss: 0.3546 - val_accuracy: 0.9412\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1697 - accuracy: 1.0000 - val_loss: 0.3437 - val_accuracy: 0.9491\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1692 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.9446\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1691 - accuracy: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.9423\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1676 - accuracy: 1.0000 - val_loss: 0.3461 - val_accuracy: 0.9480\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1663 - accuracy: 1.0000 - val_loss: 0.3635 - val_accuracy: 0.9344\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1654 - accuracy: 1.0000 - val_loss: 0.3496 - val_accuracy: 0.9412\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1644 - accuracy: 1.0000 - val_loss: 0.3451 - val_accuracy: 0.9423\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1634 - accuracy: 1.0000 - val_loss: 0.3459 - val_accuracy: 0.9400\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1625 - accuracy: 1.0000 - val_loss: 0.3425 - val_accuracy: 0.9412\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1616 - accuracy: 1.0000 - val_loss: 0.3455 - val_accuracy: 0.9412\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1608 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9412\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1599 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9321\n","Epoch 86/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1590 - accuracy: 1.0000 - val_loss: 0.3502 - val_accuracy: 0.9378\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1581 - accuracy: 1.0000 - val_loss: 0.3402 - val_accuracy: 0.9457\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1572 - accuracy: 1.0000 - val_loss: 0.3391 - val_accuracy: 0.9468\n","Epoch 89/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1563 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.9389\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1554 - accuracy: 1.0000 - val_loss: 0.3442 - val_accuracy: 0.9400\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1545 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.9457\n","Epoch 92/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1537 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 0.9378\n","Epoch 93/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.1526 - accuracy: 1.0000 - val_loss: 0.3527 - val_accuracy: 0.9355\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1518 - accuracy: 1.0000 - val_loss: 0.3323 - val_accuracy: 0.9457\n","Epoch 95/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.1511 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.9502\n","Epoch 96/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1506 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.9299\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1493 - accuracy: 1.0000 - val_loss: 0.3440 - val_accuracy: 0.9446\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.1485 - accuracy: 1.0000 - val_loss: 0.3334 - val_accuracy: 0.9412\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.1474 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9412\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.1468 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 0.9446\n","{'loss': [0.24758270382881165, 0.2379777729511261, 0.2331310212612152, 0.2315327227115631, 0.2294600009918213, 0.22863835096359253, 0.22738134860992432, 0.22755156457424164, 0.22626721858978271, 0.22510331869125366, 0.22459761798381805, 0.22435031831264496, 0.22347135841846466, 0.2222270518541336, 0.22161336243152618, 0.2208428829908371, 0.22063027322292328, 0.21923677623271942, 0.21835577487945557, 0.2179218977689743, 0.21722730994224548, 0.21635626256465912, 0.2158581018447876, 0.21466881036758423, 0.21414612233638763, 0.21341551840305328, 0.21250608563423157, 0.21159148216247559, 0.21071650087833405, 0.20984694361686707, 0.2097291499376297, 0.20838354527950287, 0.20742155611515045, 0.20661661028862, 0.20572683215141296, 0.20493853092193604, 0.20422038435935974, 0.2032092660665512, 0.2023685872554779, 0.20136575400829315, 0.20059853792190552, 0.19970953464508057, 0.19888359308242798, 0.19789500534534454, 0.19704242050647736, 0.19598570466041565, 0.19514362514019012, 0.19431790709495544, 0.19344931840896606, 0.19263680279254913, 0.19141758978366852, 0.19062407314777374, 0.18990162014961243, 0.18883948028087616, 0.18787957727909088, 0.18698500096797943, 0.18600334227085114, 0.18497920036315918, 0.18404421210289001, 0.18307633697986603, 0.18226554989814758, 0.18109716475009918, 0.18021339178085327, 0.1791839897632599, 0.1783195585012436, 0.1773441731929779, 0.17676734924316406, 0.17549334466457367, 0.17451995611190796, 0.1739162653684616, 0.1727752834558487, 0.17174838483333588, 0.17083176970481873, 0.16969053447246552, 0.1692482978105545, 0.16907723248004913, 0.16760912537574768, 0.1662747859954834, 0.16537216305732727, 0.16436050832271576, 0.1633702963590622, 0.16250479221343994, 0.16161611676216125, 0.1607903093099594, 0.1599438190460205, 0.1589958369731903, 0.15811504423618317, 0.15724538266658783, 0.15629169344902039, 0.1553950011730194, 0.15454387664794922, 0.1537380814552307, 0.1526298224925995, 0.15184049308300018, 0.15105223655700684, 0.15056800842285156, 0.14932698011398315, 0.14846689999103546, 0.14742708206176758, 0.14679217338562012], 'accuracy': [0.9932088255882263, 0.9968873858451843, 0.9983022212982178, 0.9991511106491089, 0.9994340538978577, 0.9994340538978577, 0.9997170567512512, 0.9994340538978577, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.9253721833229065, 0.9136253595352173, 0.903780996799469, 0.8766114115715027, 0.8523999452590942, 0.8110643029212952, 0.7552414536476135, 0.7026476263999939, 0.6724585890769958, 0.6434388756752014, 0.5758535265922546, 0.5399812459945679, 0.505595326423645, 0.48070386052131653, 0.4380340576171875, 0.438338965177536, 0.40148869156837463, 0.3831252455711365, 0.37121015787124634, 0.3643881678581238, 0.3601188361644745, 0.35455453395843506, 0.35031434893608093, 0.3510548770427704, 0.3578123152256012, 0.3551343083381653, 0.3542926013469696, 0.3546355962753296, 0.3639875650405884, 0.35637104511260986, 0.3614822328090668, 0.3620814383029938, 0.3619360327720642, 0.3634262681007385, 0.3614400029182434, 0.37304848432540894, 0.3619029223918915, 0.3604915142059326, 0.3613539934158325, 0.35885974764823914, 0.35736992955207825, 0.3610478639602661, 0.359653502702713, 0.3585408627986908, 0.3611590564250946, 0.3566604554653168, 0.3606455326080322, 0.35572102665901184, 0.360364705324173, 0.35567131638526917, 0.3548692762851715, 0.3586713671684265, 0.3612286448478699, 0.36242151260375977, 0.35830527544021606, 0.362330824136734, 0.3547304570674896, 0.3550092577934265, 0.35701417922973633, 0.36639338731765747, 0.3498825430870056, 0.35331010818481445, 0.3552992343902588, 0.3476690649986267, 0.3466016948223114, 0.34690532088279724, 0.3500107526779175, 0.3499724864959717, 0.35213902592658997, 0.35189419984817505, 0.3467920422554016, 0.3652696907520294, 0.3546445667743683, 0.3436727821826935, 0.35073330998420715, 0.3458050489425659, 0.34608620405197144, 0.36351659893989563, 0.34956982731819153, 0.34511515498161316, 0.3458646237850189, 0.3424699306488037, 0.3454877436161041, 0.3430357575416565, 0.36328721046447754, 0.3501996397972107, 0.34018880128860474, 0.33909523487091064, 0.34096696972846985, 0.3442142903804779, 0.33256444334983826, 0.34054508805274963, 0.3526883125305176, 0.3322584331035614, 0.33579930663108826, 0.3567071855068207, 0.34404638409614563, 0.3334094285964966, 0.3346810042858124, 0.3408239781856537], 'val_accuracy': [0.5, 0.5056561231613159, 0.5147058963775635, 0.5441176295280457, 0.5656108856201172, 0.6176470518112183, 0.7081447839736938, 0.7805429697036743, 0.8054298758506775, 0.8223981857299805, 0.9061086177825928, 0.9253393411636353, 0.9411764740943909, 0.942307710647583, 0.9547511339187622, 0.9411764740943909, 0.9547511339187622, 0.9570135474205017, 0.9524886608123779, 0.9570135474205017, 0.9547511339187622, 0.9536198973655701, 0.9558823704719543, 0.9558823704719543, 0.9570135474205017, 0.9558823704719543, 0.9547511339187622, 0.9547511339187622, 0.9524886608123779, 0.9536198973655701, 0.9536198973655701, 0.9558823704719543, 0.9558823704719543, 0.9558823704719543, 0.9513574838638306, 0.9468325972557068, 0.9513574838638306, 0.9547511339187622, 0.9524886608123779, 0.9547511339187622, 0.9547511339187622, 0.9513574838638306, 0.9513574838638306, 0.9490950107574463, 0.9524886608123779, 0.9536198973655701, 0.9479637742042542, 0.9536198973655701, 0.9524886608123779, 0.9479637742042542, 0.9513574838638306, 0.9468325972557068, 0.9434388875961304, 0.9490950107574463, 0.9502262473106384, 0.9468325972557068, 0.9502262473106384, 0.9502262473106384, 0.9490950107574463, 0.9377828240394592, 0.9490950107574463, 0.9479637742042542, 0.9513574838638306, 0.9513574838638306, 0.9513574838638306, 0.9490950107574463, 0.9468325972557068, 0.9490950107574463, 0.9479637742042542, 0.9445701241493225, 0.9502262473106384, 0.9377828240394592, 0.9411764740943909, 0.9490950107574463, 0.9445701241493225, 0.942307710647583, 0.9479637742042542, 0.9343891143798828, 0.9411764740943909, 0.942307710647583, 0.9400452375411987, 0.9411764740943909, 0.9411764740943909, 0.9411764740943909, 0.9321267008781433, 0.9377828240394592, 0.9457013607025146, 0.9468325972557068, 0.9389140009880066, 0.9400452375411987, 0.9457013607025146, 0.9377828240394592, 0.935520350933075, 0.9457013607025146, 0.9502262473106384, 0.929864227771759, 0.9445701241493225, 0.9411764740943909, 0.9411764740943909, 0.9445701241493225]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.2481 - accuracy: 0.9920"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 4s 40ms/step - loss: 0.2481 - accuracy: 0.9920 - val_loss: 0.9399 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.2345 - accuracy: 0.9982 - val_loss: 0.9337 - val_accuracy: 0.4866\n","Epoch 3/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.2319 - accuracy: 0.9997 - val_loss: 0.9222 - val_accuracy: 0.4979\n","Epoch 4/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.2313 - accuracy: 0.9995 - val_loss: 0.9074 - val_accuracy: 0.5124\n","Epoch 5/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.2302 - accuracy: 0.9997 - val_loss: 0.8734 - val_accuracy: 0.5413\n","Epoch 6/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.2288 - accuracy: 1.0000 - val_loss: 0.8445 - val_accuracy: 0.5651\n","Epoch 7/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2282 - accuracy: 1.0000 - val_loss: 0.7870 - val_accuracy: 0.6333\n","Epoch 8/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2274 - accuracy: 1.0000 - val_loss: 0.7143 - val_accuracy: 0.7376\n","Epoch 9/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2266 - accuracy: 1.0000 - val_loss: 0.6658 - val_accuracy: 0.7975\n","Epoch 10/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2261 - accuracy: 1.0000 - val_loss: 0.6043 - val_accuracy: 0.8729\n","Epoch 11/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2257 - accuracy: 0.9997 - val_loss: 0.5538 - val_accuracy: 0.9081\n","Epoch 12/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2247 - accuracy: 1.0000 - val_loss: 0.5378 - val_accuracy: 0.8977\n","Epoch 13/100\n","31/31 [==============================] - 2s 62ms/step - loss: 0.2240 - accuracy: 1.0000 - val_loss: 0.4934 - val_accuracy: 0.9205\n","Epoch 14/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2234 - accuracy: 1.0000 - val_loss: 0.4520 - val_accuracy: 0.9360\n","Epoch 15/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2229 - accuracy: 1.0000 - val_loss: 0.4413 - val_accuracy: 0.9318\n","Epoch 16/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2220 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.9380\n","Epoch 17/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2215 - accuracy: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.9370\n","Epoch 18/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2209 - accuracy: 1.0000 - val_loss: 0.3986 - val_accuracy: 0.9432\n","Epoch 19/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2201 - accuracy: 1.0000 - val_loss: 0.3938 - val_accuracy: 0.9370\n","Epoch 20/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2193 - accuracy: 1.0000 - val_loss: 0.3949 - val_accuracy: 0.9370\n","Epoch 21/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2187 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9349\n","Epoch 22/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2185 - accuracy: 1.0000 - val_loss: 0.4026 - val_accuracy: 0.9380\n","Epoch 23/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2176 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.9411\n","Epoch 24/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.9390\n","Epoch 25/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2159 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.9380\n","Epoch 26/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2150 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.9370\n","Epoch 27/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2142 - accuracy: 1.0000 - val_loss: 0.4261 - val_accuracy: 0.9349\n","Epoch 28/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.9349\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2335 - accuracy: 0.9930 - val_loss: 0.4641 - val_accuracy: 0.9267\n","Epoch 30/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2176 - accuracy: 0.9990 - val_loss: 0.4386 - val_accuracy: 0.9360\n","Epoch 31/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.4458 - val_accuracy: 0.9349\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2118 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.9349\n","Epoch 33/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2112 - accuracy: 1.0000 - val_loss: 0.4493 - val_accuracy: 0.9318\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2107 - accuracy: 1.0000 - val_loss: 0.4427 - val_accuracy: 0.9360\n","Epoch 35/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2102 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.9370\n","Epoch 36/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2097 - accuracy: 1.0000 - val_loss: 0.4435 - val_accuracy: 0.9370\n","Epoch 37/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2092 - accuracy: 1.0000 - val_loss: 0.4427 - val_accuracy: 0.9360\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.4436 - val_accuracy: 0.9360\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2082 - accuracy: 1.0000 - val_loss: 0.4471 - val_accuracy: 0.9329\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2079 - accuracy: 1.0000 - val_loss: 0.4426 - val_accuracy: 0.9360\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2073 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.9339\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2068 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.9370\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2063 - accuracy: 1.0000 - val_loss: 0.4417 - val_accuracy: 0.9370\n","Epoch 44/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2059 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.9349\n","Epoch 45/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2053 - accuracy: 1.0000 - val_loss: 0.4446 - val_accuracy: 0.9349\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2048 - accuracy: 1.0000 - val_loss: 0.4465 - val_accuracy: 0.9349\n","Epoch 47/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2042 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.9329\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2037 - accuracy: 1.0000 - val_loss: 0.4475 - val_accuracy: 0.9349\n","Epoch 49/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2032 - accuracy: 1.0000 - val_loss: 0.4450 - val_accuracy: 0.9349\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2027 - accuracy: 1.0000 - val_loss: 0.4489 - val_accuracy: 0.9329\n","Epoch 51/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2021 - accuracy: 1.0000 - val_loss: 0.4454 - val_accuracy: 0.9308\n","Epoch 52/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2016 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.9308\n","Epoch 53/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2009 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.9380\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2004 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 0.9277\n","Epoch 55/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1998 - accuracy: 1.0000 - val_loss: 0.4429 - val_accuracy: 0.9360\n","Epoch 56/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1992 - accuracy: 1.0000 - val_loss: 0.4421 - val_accuracy: 0.9360\n","Epoch 57/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1985 - accuracy: 1.0000 - val_loss: 0.4395 - val_accuracy: 0.9370\n","Epoch 58/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1980 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.9370\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1973 - accuracy: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.9339\n","Epoch 60/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1968 - accuracy: 1.0000 - val_loss: 0.4418 - val_accuracy: 0.9339\n","Epoch 61/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1960 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.9349\n","Epoch 62/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1955 - accuracy: 1.0000 - val_loss: 0.4488 - val_accuracy: 0.9318\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1949 - accuracy: 1.0000 - val_loss: 0.4398 - val_accuracy: 0.9360\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1942 - accuracy: 1.0000 - val_loss: 0.4400 - val_accuracy: 0.9349\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1935 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.9360\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1929 - accuracy: 1.0000 - val_loss: 0.4449 - val_accuracy: 0.9287\n","Epoch 67/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1923 - accuracy: 1.0000 - val_loss: 0.4379 - val_accuracy: 0.9339\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1916 - accuracy: 1.0000 - val_loss: 0.4395 - val_accuracy: 0.9329\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1909 - accuracy: 1.0000 - val_loss: 0.4458 - val_accuracy: 0.9318\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1903 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.9339\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1897 - accuracy: 1.0000 - val_loss: 0.4453 - val_accuracy: 0.9308\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1888 - accuracy: 1.0000 - val_loss: 0.4379 - val_accuracy: 0.9339\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1881 - accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.9339\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1875 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.9329\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1869 - accuracy: 1.0000 - val_loss: 0.4516 - val_accuracy: 0.9236\n","Epoch 76/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1860 - accuracy: 1.0000 - val_loss: 0.4356 - val_accuracy: 0.9339\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1853 - accuracy: 1.0000 - val_loss: 0.4428 - val_accuracy: 0.9308\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1848 - accuracy: 1.0000 - val_loss: 0.4435 - val_accuracy: 0.9308\n","Epoch 79/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1838 - accuracy: 1.0000 - val_loss: 0.4351 - val_accuracy: 0.9318\n","Epoch 80/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1832 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 0.9329\n","Epoch 81/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1825 - accuracy: 1.0000 - val_loss: 0.4434 - val_accuracy: 0.9256\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1817 - accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.9339\n","Epoch 83/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1809 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.9329\n","Epoch 84/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1801 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.9308\n","Epoch 85/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1794 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.9298\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1788 - accuracy: 1.0000 - val_loss: 0.4357 - val_accuracy: 0.9298\n","Epoch 87/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1780 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.9298\n","Epoch 88/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.1771 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.9298\n","Epoch 89/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1764 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.9298\n","Epoch 90/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1756 - accuracy: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.9236\n","Epoch 91/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1749 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.9308\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1741 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.9308\n","Epoch 93/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1731 - accuracy: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.9246\n","Epoch 94/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1724 - accuracy: 1.0000 - val_loss: 0.4296 - val_accuracy: 0.9298\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1717 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.9308\n","Epoch 96/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.1709 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.9277\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1700 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 0.9277\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1692 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.9318\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.1684 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.9287\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.1676 - accuracy: 1.0000 - val_loss: 0.4410 - val_accuracy: 0.9277\n","{'loss': [0.24809867143630981, 0.23454724252223969, 0.23193202912807465, 0.2313118278980255, 0.23017171025276184, 0.2287801206111908, 0.22817100584506989, 0.22743509709835052, 0.22658434510231018, 0.22611548006534576, 0.2257496565580368, 0.22468741238117218, 0.22404782474040985, 0.22335031628608704, 0.22290731966495514, 0.22196288406848907, 0.22149859368801117, 0.22090905904769897, 0.22005850076675415, 0.2192632108926773, 0.21874549984931946, 0.21848702430725098, 0.2176184505224228, 0.2167222648859024, 0.21594002842903137, 0.21495281159877777, 0.21422475576400757, 0.21459323167800903, 0.2334931194782257, 0.21761517226696014, 0.2127176821231842, 0.2118084877729416, 0.21119660139083862, 0.21070164442062378, 0.21021580696105957, 0.2096550017595291, 0.20920753479003906, 0.2087954431772232, 0.20824553072452545, 0.20789578557014465, 0.2073381096124649, 0.20675936341285706, 0.20628918707370758, 0.2058822214603424, 0.20532694458961487, 0.20475263893604279, 0.20421835780143738, 0.20373868942260742, 0.20323911309242249, 0.2026948779821396, 0.2020556479692459, 0.2015610635280609, 0.20092664659023285, 0.20038317143917084, 0.19982555508613586, 0.19921563565731049, 0.19853131473064423, 0.19795459508895874, 0.19734932482242584, 0.1967669576406479, 0.19604669511318207, 0.19551588594913483, 0.19491557776927948, 0.19416983425617218, 0.19354739785194397, 0.19291353225708008, 0.19228936731815338, 0.19158662855625153, 0.19090452790260315, 0.19026049971580505, 0.18968231976032257, 0.18884342908859253, 0.18813590705394745, 0.18751275539398193, 0.18688207864761353, 0.18603187799453735, 0.18533803522586823, 0.18476004898548126, 0.18381257355213165, 0.18317441642284393, 0.1824808269739151, 0.1817035675048828, 0.1809312105178833, 0.1801314353942871, 0.17942902445793152, 0.17879362404346466, 0.17798738181591034, 0.17706948518753052, 0.17635126411914825, 0.17557494342327118, 0.17485162615776062, 0.17410103976726532, 0.1731191724538803, 0.17241714894771576, 0.1716897338628769, 0.17087456583976746, 0.17003081738948822, 0.16920073330402374, 0.16840015351772308, 0.1676197052001953], 'accuracy': [0.9919896721839905, 0.998191237449646, 0.9997416138648987, 0.9994832277297974, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997416138648987, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9930232763290405, 0.99896639585495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.9399370551109314, 0.9337242245674133, 0.9221705198287964, 0.9073879718780518, 0.8733994960784912, 0.8445158004760742, 0.7869676351547241, 0.7142500877380371, 0.6657957434654236, 0.6043080687522888, 0.5538280606269836, 0.5378322601318359, 0.4934213161468506, 0.45196425914764404, 0.44129082560539246, 0.4092467725276947, 0.40275445580482483, 0.39856526255607605, 0.39384526014328003, 0.3949415981769562, 0.4005460739135742, 0.40260618925094604, 0.406191885471344, 0.41591233015060425, 0.42082592844963074, 0.42315998673439026, 0.42611756920814514, 0.4358551800251007, 0.4640752971172333, 0.43862390518188477, 0.4458071291446686, 0.4467772841453552, 0.44928449392318726, 0.4427395761013031, 0.44451218843460083, 0.4434944987297058, 0.4426879584789276, 0.44363194704055786, 0.447062224149704, 0.4425966441631317, 0.44656267762184143, 0.4425100088119507, 0.4417288899421692, 0.4497775137424469, 0.4445591866970062, 0.44645920395851135, 0.4517243504524231, 0.4475131034851074, 0.4450214207172394, 0.44890227913856506, 0.4453813433647156, 0.4467732012271881, 0.4431073069572449, 0.45371076464653015, 0.44286078214645386, 0.4421086609363556, 0.4394581913948059, 0.44117024540901184, 0.44073718786239624, 0.44179001450538635, 0.4432079792022705, 0.44879335165023804, 0.4397548735141754, 0.44004979729652405, 0.44081100821495056, 0.44487932324409485, 0.43790292739868164, 0.43951448798179626, 0.44579604268074036, 0.43856582045555115, 0.4452938735485077, 0.43789613246917725, 0.4370860159397125, 0.4442034661769867, 0.45161768794059753, 0.43564099073410034, 0.44283998012542725, 0.44347885251045227, 0.43508875370025635, 0.43271559476852417, 0.44344016909599304, 0.43703019618988037, 0.4328738749027252, 0.43961387872695923, 0.43759050965309143, 0.4356856644153595, 0.43773284554481506, 0.43863824009895325, 0.43410399556159973, 0.43849167227745056, 0.4379519522190094, 0.43168097734451294, 0.4384654760360718, 0.4295748174190521, 0.43174850940704346, 0.43434035778045654, 0.42935115098953247, 0.43433311581611633, 0.4312315285205841, 0.4410065710544586], 'val_accuracy': [0.48553720116615295, 0.48657023906707764, 0.49793389439582825, 0.5123966932296753, 0.5413222908973694, 0.5650826692581177, 0.6332644820213318, 0.7376033067703247, 0.797520637512207, 0.8729338645935059, 0.9080578684806824, 0.8977272510528564, 0.9204545617103577, 0.9359503984451294, 0.9318181872367859, 0.9380165338516235, 0.9369834661483765, 0.9431818127632141, 0.9369834661483765, 0.9369834661483765, 0.9349173307418823, 0.9380165338516235, 0.94111567735672, 0.9390496015548706, 0.9380165338516235, 0.9369834661483765, 0.9349173307418823, 0.9349173307418823, 0.9266529083251953, 0.9359503984451294, 0.9349173307418823, 0.9349173307418823, 0.9318181872367859, 0.9359503984451294, 0.9369834661483765, 0.9369834661483765, 0.9359503984451294, 0.9359503984451294, 0.932851254940033, 0.9359503984451294, 0.93388432264328, 0.9369834661483765, 0.9369834661483765, 0.9349173307418823, 0.9349173307418823, 0.9349173307418823, 0.932851254940033, 0.9349173307418823, 0.9349173307418823, 0.932851254940033, 0.9307851195335388, 0.9307851195335388, 0.9380165338516235, 0.9276859760284424, 0.9359503984451294, 0.9359503984451294, 0.9369834661483765, 0.9369834661483765, 0.93388432264328, 0.93388432264328, 0.9349173307418823, 0.9318181872367859, 0.9359503984451294, 0.9349173307418823, 0.9359503984451294, 0.9287189841270447, 0.93388432264328, 0.932851254940033, 0.9318181872367859, 0.93388432264328, 0.9307851195335388, 0.93388432264328, 0.93388432264328, 0.932851254940033, 0.9235537052154541, 0.93388432264328, 0.9307851195335388, 0.9307851195335388, 0.9318181872367859, 0.932851254940033, 0.9256198406219482, 0.93388432264328, 0.932851254940033, 0.9307851195335388, 0.9297520518302917, 0.9297520518302917, 0.9297520518302917, 0.9297520518302917, 0.9297520518302917, 0.9235537052154541, 0.9307851195335388, 0.9307851195335388, 0.9245867729187012, 0.9297520518302917, 0.9307851195335388, 0.9276859760284424, 0.9276859760284424, 0.9318181872367859, 0.9287189841270447, 0.9276859760284424]}\n","32/32 [==============================] - 0s 4ms/step\n"]}],"source":["global_model_CNN, metrics_df_CNN = federated_learning(Theta_data)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"id":"y3RXIk-qZ7ts","executionInfo":{"status":"ok","timestamp":1717405466284,"user_tz":-360,"elapsed":49,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"988b83ce-14d4-434a-e915-5a20df1712b5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.750      0.724   0.807  0.763        0.807        0.692   \n","1        1     0.814      0.807   0.823  0.815        0.823        0.804   \n","2        2     0.740      0.715   0.797  0.754        0.797        0.683   \n","3        0     0.819      0.826   0.809  0.817        0.809        0.829   \n","4        1     0.855      0.829   0.893  0.860        0.893        0.816   \n","5        2     0.811      0.773   0.882  0.824        0.882        0.741   \n","6        0     0.860      0.827   0.911  0.867        0.911        0.809   \n","7        1     0.888      0.862   0.924  0.892        0.924        0.852   \n","8        2     0.860      0.836   0.898  0.865        0.898        0.823   \n","9        0     0.879      0.849   0.923  0.884        0.923        0.836   \n","10       1     0.910      0.884   0.944  0.913        0.944        0.876   \n","11       2     0.897      0.853   0.958  0.903        0.958        0.835   \n","12       0     0.888      0.851   0.940  0.893        0.940        0.836   \n","13       1     0.927      0.903   0.956  0.929        0.956        0.897   \n","14       2     0.901      0.854   0.966  0.907        0.966        0.835   \n","\n","    Kappa  \n","0   0.499  \n","1   0.627  \n","2   0.480  \n","3   0.638  \n","4   0.709  \n","5   0.622  \n","6   0.720  \n","7   0.775  \n","8   0.721  \n","9   0.759  \n","10  0.819  \n","11  0.793  \n","12  0.776  \n","13  0.853  \n","14  0.801  "],"text/html":["\n","  <div id=\"df-7fa3b759-6260-45a0-841d-07e1839cd36f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.750</td>\n","      <td>0.724</td>\n","      <td>0.807</td>\n","      <td>0.763</td>\n","      <td>0.807</td>\n","      <td>0.692</td>\n","      <td>0.499</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.814</td>\n","      <td>0.807</td>\n","      <td>0.823</td>\n","      <td>0.815</td>\n","      <td>0.823</td>\n","      <td>0.804</td>\n","      <td>0.627</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.740</td>\n","      <td>0.715</td>\n","      <td>0.797</td>\n","      <td>0.754</td>\n","      <td>0.797</td>\n","      <td>0.683</td>\n","      <td>0.480</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.819</td>\n","      <td>0.826</td>\n","      <td>0.809</td>\n","      <td>0.817</td>\n","      <td>0.809</td>\n","      <td>0.829</td>\n","      <td>0.638</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.855</td>\n","      <td>0.829</td>\n","      <td>0.893</td>\n","      <td>0.860</td>\n","      <td>0.893</td>\n","      <td>0.816</td>\n","      <td>0.709</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.811</td>\n","      <td>0.773</td>\n","      <td>0.882</td>\n","      <td>0.824</td>\n","      <td>0.882</td>\n","      <td>0.741</td>\n","      <td>0.622</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.860</td>\n","      <td>0.827</td>\n","      <td>0.911</td>\n","      <td>0.867</td>\n","      <td>0.911</td>\n","      <td>0.809</td>\n","      <td>0.720</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.888</td>\n","      <td>0.862</td>\n","      <td>0.924</td>\n","      <td>0.892</td>\n","      <td>0.924</td>\n","      <td>0.852</td>\n","      <td>0.775</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.860</td>\n","      <td>0.836</td>\n","      <td>0.898</td>\n","      <td>0.865</td>\n","      <td>0.898</td>\n","      <td>0.823</td>\n","      <td>0.721</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.879</td>\n","      <td>0.849</td>\n","      <td>0.923</td>\n","      <td>0.884</td>\n","      <td>0.923</td>\n","      <td>0.836</td>\n","      <td>0.759</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.910</td>\n","      <td>0.884</td>\n","      <td>0.944</td>\n","      <td>0.913</td>\n","      <td>0.944</td>\n","      <td>0.876</td>\n","      <td>0.819</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.897</td>\n","      <td>0.853</td>\n","      <td>0.958</td>\n","      <td>0.903</td>\n","      <td>0.958</td>\n","      <td>0.835</td>\n","      <td>0.793</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.888</td>\n","      <td>0.851</td>\n","      <td>0.940</td>\n","      <td>0.893</td>\n","      <td>0.940</td>\n","      <td>0.836</td>\n","      <td>0.776</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.927</td>\n","      <td>0.903</td>\n","      <td>0.956</td>\n","      <td>0.929</td>\n","      <td>0.956</td>\n","      <td>0.897</td>\n","      <td>0.853</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.901</td>\n","      <td>0.854</td>\n","      <td>0.966</td>\n","      <td>0.907</td>\n","      <td>0.966</td>\n","      <td>0.835</td>\n","      <td>0.801</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fa3b759-6260-45a0-841d-07e1839cd36f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7fa3b759-6260-45a0-841d-07e1839cd36f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7fa3b759-6260-45a0-841d-07e1839cd36f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-4fb4e5cb-dbbe-40d0-ba9f-80607fa6a5d0\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4fb4e5cb-dbbe-40d0-ba9f-80607fa6a5d0')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-4fb4e5cb-dbbe-40d0-ba9f-80607fa6a5d0 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df_CNN\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05606815580379024,\n        \"min\": 0.74,\n        \"max\": 0.927,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.927,\n          0.91,\n          0.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05295577669824404,\n        \"min\": 0.715,\n        \"max\": 0.903,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.849,\n          0.853,\n          0.724\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.059248628676113656,\n        \"min\": 0.797,\n        \"max\": 0.966,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.923,\n          0.958,\n          0.807\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05358100231914117,\n        \"min\": 0.754,\n        \"max\": 0.929,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.884,\n          0.903,\n          0.763\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.059248628676113656,\n        \"min\": 0.797,\n        \"max\": 0.966,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.923,\n          0.958,\n          0.807\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06076590522731672,\n        \"min\": 0.683,\n        \"max\": 0.897,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.835,\n          0.836,\n          0.692\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11203243577940572,\n        \"min\": 0.48,\n        \"max\": 0.853,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.759,\n          0.793,\n          0.499\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":15}],"source":["metrics_df_CNN.round(3)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"_iOLsKpkfzdG","executionInfo":{"status":"ok","timestamp":1717405467180,"user_tz":-360,"elapsed":907,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"outputs":[],"source":["metrics_df.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/TF Domain/CNN/Total_CNN.csv', index = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ieXSN-9PI4Dx"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# GRU"],"metadata":{"id":"qKjAMm3WKlg4"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model_gru(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(GRU(256, return_sequences=True))\n","    model.add(GRU(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning_gru(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model_gru(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model_gru(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time+Frequency/Total/CNN_GRU/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time+Frequency/Total/CNN_GRU/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"zFXclc_DKnDR","executionInfo":{"status":"ok","timestamp":1717405467181,"user_tz":-360,"elapsed":25,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["global_model_gru, metrics_df_gru = federated_learning_gru(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QJ8QBmlfK8bV","executionInfo":{"status":"ok","timestamp":1717406713725,"user_tz":-360,"elapsed":0,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"c6510968-44fb-477d-ccc2-fb7fe2b9d612"},"execution_count":18,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train shape: (4640, 37, 29), Test shape: (1194, 37, 29)\n","Train shape: (4418, 37, 29), Test shape: (1416, 37, 29)\n","Train shape: (4838, 37, 29), Test shape: (996, 37, 29)\n","Train shape: (4640, 37, 29), Test shape: (1194, 37, 29)\n","Train shape: (4418, 37, 29), Test shape: (1416, 37, 29)\n","Train shape: (4838, 37, 29), Test shape: (996, 37, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/29 [========================>.....] - ETA: 0s - loss: 1.7014 - accuracy: 0.5081"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 8s 55ms/step - loss: 1.7001 - accuracy: 0.5075 - val_loss: 1.6994 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.6829 - accuracy: 0.5145 - val_loss: 1.6904 - val_accuracy: 0.7166\n","Epoch 3/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.6580 - accuracy: 0.6005 - val_loss: 1.6812 - val_accuracy: 0.6961\n","Epoch 4/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.6223 - accuracy: 0.6816 - val_loss: 1.6712 - val_accuracy: 0.6659\n","Epoch 5/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5756 - accuracy: 0.7293 - val_loss: 1.6599 - val_accuracy: 0.6509\n","Epoch 6/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.5264 - accuracy: 0.7416 - val_loss: 1.6432 - val_accuracy: 0.7058\n","Epoch 7/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.4907 - accuracy: 0.7454 - val_loss: 1.6256 - val_accuracy: 0.7371\n","Epoch 8/100\n","29/29 [==============================] - 1s 31ms/step - loss: 1.4709 - accuracy: 0.7530 - val_loss: 1.6049 - val_accuracy: 0.7489\n","Epoch 9/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4523 - accuracy: 0.7610 - val_loss: 1.5921 - val_accuracy: 0.7478\n","Epoch 10/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.4447 - accuracy: 0.7621 - val_loss: 1.5709 - val_accuracy: 0.7662\n","Epoch 11/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4315 - accuracy: 0.7635 - val_loss: 1.5600 - val_accuracy: 0.7522\n","Epoch 12/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.4236 - accuracy: 0.7702 - val_loss: 1.5408 - val_accuracy: 0.7629\n","Epoch 13/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.4098 - accuracy: 0.7756 - val_loss: 1.5174 - val_accuracy: 0.7769\n","Epoch 14/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3981 - accuracy: 0.7780 - val_loss: 1.5010 - val_accuracy: 0.7705\n","Epoch 15/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.3908 - accuracy: 0.7777 - val_loss: 1.4775 - val_accuracy: 0.7791\n","Epoch 16/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3808 - accuracy: 0.7818 - val_loss: 1.4581 - val_accuracy: 0.7769\n","Epoch 17/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.3732 - accuracy: 0.7880 - val_loss: 1.4382 - val_accuracy: 0.7834\n","Epoch 18/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.3626 - accuracy: 0.7883 - val_loss: 1.4188 - val_accuracy: 0.7877\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3587 - accuracy: 0.7864 - val_loss: 1.3975 - val_accuracy: 0.7856\n","Epoch 20/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3474 - accuracy: 0.7901 - val_loss: 1.3813 - val_accuracy: 0.7877\n","Epoch 21/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.3385 - accuracy: 0.7928 - val_loss: 1.3615 - val_accuracy: 0.7856\n","Epoch 22/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.3319 - accuracy: 0.7907 - val_loss: 1.3474 - val_accuracy: 0.7909\n","Epoch 23/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.3260 - accuracy: 0.7880 - val_loss: 1.3336 - val_accuracy: 0.7985\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3155 - accuracy: 0.7942 - val_loss: 1.3250 - val_accuracy: 0.7931\n","Epoch 25/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.3041 - accuracy: 0.8004 - val_loss: 1.3172 - val_accuracy: 0.7996\n","Epoch 26/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.3018 - accuracy: 0.7966 - val_loss: 1.3030 - val_accuracy: 0.8006\n","Epoch 27/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.2929 - accuracy: 0.7982 - val_loss: 1.2907 - val_accuracy: 0.8071\n","Epoch 28/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.2813 - accuracy: 0.7988 - val_loss: 1.2815 - val_accuracy: 0.8082\n","Epoch 29/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.2765 - accuracy: 0.8052 - val_loss: 1.2738 - val_accuracy: 0.8093\n","Epoch 30/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2685 - accuracy: 0.8052 - val_loss: 1.2692 - val_accuracy: 0.8093\n","Epoch 31/100\n","29/29 [==============================] - 1s 40ms/step - loss: 1.2592 - accuracy: 0.8095 - val_loss: 1.2580 - val_accuracy: 0.8136\n","Epoch 32/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2486 - accuracy: 0.8098 - val_loss: 1.2494 - val_accuracy: 0.8114\n","Epoch 33/100\n","29/29 [==============================] - 1s 35ms/step - loss: 1.2376 - accuracy: 0.8152 - val_loss: 1.2437 - val_accuracy: 0.8168\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2325 - accuracy: 0.8093 - val_loss: 1.2340 - val_accuracy: 0.8114\n","Epoch 35/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2222 - accuracy: 0.8200 - val_loss: 1.2265 - val_accuracy: 0.8125\n","Epoch 36/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2084 - accuracy: 0.8214 - val_loss: 1.2196 - val_accuracy: 0.8114\n","Epoch 37/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.2070 - accuracy: 0.8230 - val_loss: 1.2178 - val_accuracy: 0.8244\n","Epoch 38/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2012 - accuracy: 0.8155 - val_loss: 1.2073 - val_accuracy: 0.8082\n","Epoch 39/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.1952 - accuracy: 0.8219 - val_loss: 1.1984 - val_accuracy: 0.8254\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1930 - accuracy: 0.8249 - val_loss: 1.1993 - val_accuracy: 0.8244\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1770 - accuracy: 0.8284 - val_loss: 1.1856 - val_accuracy: 0.8200\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1656 - accuracy: 0.8341 - val_loss: 1.1791 - val_accuracy: 0.8244\n","Epoch 43/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1606 - accuracy: 0.8308 - val_loss: 1.1735 - val_accuracy: 0.8222\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1469 - accuracy: 0.8351 - val_loss: 1.1700 - val_accuracy: 0.8179\n","Epoch 45/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.1443 - accuracy: 0.8373 - val_loss: 1.1752 - val_accuracy: 0.8276\n","Epoch 46/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.1349 - accuracy: 0.8397 - val_loss: 1.1547 - val_accuracy: 0.8287\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1302 - accuracy: 0.8402 - val_loss: 1.1868 - val_accuracy: 0.8222\n","Epoch 48/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1183 - accuracy: 0.8411 - val_loss: 1.1446 - val_accuracy: 0.8287\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1091 - accuracy: 0.8448 - val_loss: 1.1412 - val_accuracy: 0.8222\n","Epoch 50/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.1010 - accuracy: 0.8486 - val_loss: 1.1310 - val_accuracy: 0.8351\n","Epoch 51/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0954 - accuracy: 0.8486 - val_loss: 1.1256 - val_accuracy: 0.8200\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0879 - accuracy: 0.8481 - val_loss: 1.1195 - val_accuracy: 0.8287\n","Epoch 53/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0896 - accuracy: 0.8446 - val_loss: 1.1204 - val_accuracy: 0.8265\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0703 - accuracy: 0.8553 - val_loss: 1.1129 - val_accuracy: 0.8308\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0670 - accuracy: 0.8508 - val_loss: 1.1070 - val_accuracy: 0.8341\n","Epoch 56/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0573 - accuracy: 0.8513 - val_loss: 1.1034 - val_accuracy: 0.8319\n","Epoch 57/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0542 - accuracy: 0.8618 - val_loss: 1.0963 - val_accuracy: 0.8341\n","Epoch 58/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0501 - accuracy: 0.8572 - val_loss: 1.1268 - val_accuracy: 0.8287\n","Epoch 59/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0385 - accuracy: 0.8570 - val_loss: 1.1135 - val_accuracy: 0.8330\n","Epoch 60/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0333 - accuracy: 0.8583 - val_loss: 1.0875 - val_accuracy: 0.8351\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0247 - accuracy: 0.8637 - val_loss: 1.0814 - val_accuracy: 0.8276\n","Epoch 62/100\n","29/29 [==============================] - 1s 34ms/step - loss: 1.0201 - accuracy: 0.8675 - val_loss: 1.0752 - val_accuracy: 0.8362\n","Epoch 63/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0058 - accuracy: 0.8688 - val_loss: 1.0715 - val_accuracy: 0.8362\n","Epoch 64/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.9997 - accuracy: 0.8704 - val_loss: 1.0846 - val_accuracy: 0.8373\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0012 - accuracy: 0.8726 - val_loss: 1.0638 - val_accuracy: 0.8373\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9970 - accuracy: 0.8629 - val_loss: 1.0608 - val_accuracy: 0.8362\n","Epoch 67/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9834 - accuracy: 0.8734 - val_loss: 1.0561 - val_accuracy: 0.8330\n","Epoch 68/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9828 - accuracy: 0.8677 - val_loss: 1.0550 - val_accuracy: 0.8405\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9649 - accuracy: 0.8758 - val_loss: 1.0490 - val_accuracy: 0.8405\n","Epoch 70/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9657 - accuracy: 0.8772 - val_loss: 1.0448 - val_accuracy: 0.8319\n","Epoch 71/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9670 - accuracy: 0.8699 - val_loss: 1.0762 - val_accuracy: 0.8308\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9459 - accuracy: 0.8812 - val_loss: 1.0376 - val_accuracy: 0.8405\n","Epoch 73/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.9520 - accuracy: 0.8788 - val_loss: 1.0516 - val_accuracy: 0.8438\n","Epoch 74/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9372 - accuracy: 0.8847 - val_loss: 1.0461 - val_accuracy: 0.8394\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9291 - accuracy: 0.8895 - val_loss: 1.0434 - val_accuracy: 0.8405\n","Epoch 76/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.9267 - accuracy: 0.8812 - val_loss: 1.0280 - val_accuracy: 0.8491\n","Epoch 77/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9230 - accuracy: 0.8863 - val_loss: 1.0385 - val_accuracy: 0.8416\n","Epoch 78/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9231 - accuracy: 0.8844 - val_loss: 1.0246 - val_accuracy: 0.8297\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8975 - accuracy: 0.8906 - val_loss: 1.0157 - val_accuracy: 0.8416\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8923 - accuracy: 0.8955 - val_loss: 1.0233 - val_accuracy: 0.8438\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8890 - accuracy: 0.8944 - val_loss: 1.0243 - val_accuracy: 0.8438\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8868 - accuracy: 0.8928 - val_loss: 1.0073 - val_accuracy: 0.8416\n","Epoch 83/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8980 - accuracy: 0.8877 - val_loss: 1.0208 - val_accuracy: 0.8427\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8774 - accuracy: 0.8925 - val_loss: 1.0018 - val_accuracy: 0.8427\n","Epoch 85/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8661 - accuracy: 0.9003 - val_loss: 1.0341 - val_accuracy: 0.8297\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8666 - accuracy: 0.9041 - val_loss: 0.9977 - val_accuracy: 0.8448\n","Epoch 87/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8559 - accuracy: 0.9033 - val_loss: 0.9954 - val_accuracy: 0.8438\n","Epoch 88/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8529 - accuracy: 0.8995 - val_loss: 0.9981 - val_accuracy: 0.8459\n","Epoch 89/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8484 - accuracy: 0.9027 - val_loss: 0.9943 - val_accuracy: 0.8491\n","Epoch 90/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.8363 - accuracy: 0.9087 - val_loss: 0.9908 - val_accuracy: 0.8491\n","Epoch 91/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.8301 - accuracy: 0.9073 - val_loss: 0.9941 - val_accuracy: 0.8502\n","Epoch 92/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8272 - accuracy: 0.9049 - val_loss: 1.0032 - val_accuracy: 0.8362\n","Epoch 93/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8279 - accuracy: 0.9062 - val_loss: 0.9879 - val_accuracy: 0.8481\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8151 - accuracy: 0.9108 - val_loss: 1.0156 - val_accuracy: 0.8222\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8200 - accuracy: 0.9084 - val_loss: 1.0007 - val_accuracy: 0.8330\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8049 - accuracy: 0.9154 - val_loss: 0.9920 - val_accuracy: 0.8405\n","Epoch 97/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.7933 - accuracy: 0.9197 - val_loss: 0.9722 - val_accuracy: 0.8524\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8018 - accuracy: 0.9108 - val_loss: 0.9740 - val_accuracy: 0.8448\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7834 - accuracy: 0.9208 - val_loss: 0.9911 - val_accuracy: 0.8341\n","Epoch 100/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7818 - accuracy: 0.9176 - val_loss: 0.9707 - val_accuracy: 0.8524\n","{'loss': [1.7000997066497803, 1.6828932762145996, 1.6580326557159424, 1.6223212480545044, 1.5755513906478882, 1.5264381170272827, 1.4907082319259644, 1.4709124565124512, 1.4522926807403564, 1.4447299242019653, 1.4314508438110352, 1.4236468076705933, 1.4098411798477173, 1.3980562686920166, 1.3908339738845825, 1.3808436393737793, 1.373246192932129, 1.3626444339752197, 1.3586626052856445, 1.3474200963974, 1.3384793996810913, 1.3319013118743896, 1.3259917497634888, 1.3154993057250977, 1.3041151762008667, 1.3018368482589722, 1.2928539514541626, 1.2812881469726562, 1.2765082120895386, 1.2685383558273315, 1.259210228919983, 1.2485764026641846, 1.2376128435134888, 1.2324706315994263, 1.2222317457199097, 1.2083710432052612, 1.2069553136825562, 1.2011770009994507, 1.1951521635055542, 1.193022608757019, 1.1770261526107788, 1.165631651878357, 1.1606295108795166, 1.1469340324401855, 1.1442723274230957, 1.1349135637283325, 1.1302095651626587, 1.1183065176010132, 1.1091232299804688, 1.101006031036377, 1.0953991413116455, 1.0879360437393188, 1.0896098613739014, 1.0703166723251343, 1.067028522491455, 1.0572925806045532, 1.054184079170227, 1.0501320362091064, 1.0384575128555298, 1.0333397388458252, 1.0247493982315063, 1.020093321800232, 1.0057744979858398, 0.9996908903121948, 1.0011625289916992, 0.9969567060470581, 0.9833881855010986, 0.982816755771637, 0.9649354815483093, 0.965673565864563, 0.9669617414474487, 0.9458524584770203, 0.9519864916801453, 0.9372344613075256, 0.9291115999221802, 0.9267265200614929, 0.9230183959007263, 0.9230573773384094, 0.8975380063056946, 0.8922543525695801, 0.8889666795730591, 0.8867706060409546, 0.8979769349098206, 0.8774020671844482, 0.8661395907402039, 0.8665629625320435, 0.8558589816093445, 0.8529038429260254, 0.8483975529670715, 0.836330771446228, 0.8300806879997253, 0.8271552920341492, 0.827883243560791, 0.8150588274002075, 0.8200287818908691, 0.8049393892288208, 0.7932624816894531, 0.8017908930778503, 0.7833825349807739, 0.7817672491073608], 'accuracy': [0.5075430870056152, 0.5145474076271057, 0.6004849076271057, 0.6815732717514038, 0.7292564511299133, 0.7416487336158752, 0.7454202771186829, 0.7529633641242981, 0.7610452771186829, 0.7621228694915771, 0.7634698152542114, 0.7702047228813171, 0.7755926847457886, 0.7780172228813171, 0.7777478694915771, 0.7817887663841248, 0.7879849076271057, 0.7882543206214905, 0.7863685488700867, 0.7901400923728943, 0.7928340435028076, 0.790678858757019, 0.7879849076271057, 0.7941810488700867, 0.8003771305084229, 0.7966055870056152, 0.798222005367279, 0.7987607717514038, 0.8052262663841248, 0.8052262663841248, 0.8095366358757019, 0.8098060488700867, 0.8151939511299133, 0.8092672228813171, 0.8200430870056152, 0.8213900923728943, 0.8230064511299133, 0.8154633641242981, 0.821928858757019, 0.8248922228813171, 0.8283944129943848, 0.8340517282485962, 0.8308189511299133, 0.8351293206214905, 0.837284505367279, 0.8397090435028076, 0.8402478694915771, 0.8410560488700867, 0.8448275923728943, 0.8485991358757019, 0.8485991358757019, 0.8480603694915771, 0.8445581793785095, 0.8553340435028076, 0.8507543206214905, 0.8512930870056152, 0.8617995977401733, 0.8572198152542114, 0.8569504022598267, 0.8582974076271057, 0.8636853694915771, 0.8674569129943848, 0.868803858757019, 0.8704202771186829, 0.8725754022598267, 0.8628771305084229, 0.873383641242981, 0.8677262663841248, 0.8758081793785095, 0.8771551847457886, 0.8698814511299133, 0.881196141242981, 0.8787715435028076, 0.8846982717514038, 0.8895474076271057, 0.881196141242981, 0.8863146305084229, 0.884428858757019, 0.890625, 0.8954741358757019, 0.8943965435028076, 0.8927801847457886, 0.8876616358757019, 0.8925107717514038, 0.9003232717514038, 0.9040948152542114, 0.9032866358757019, 0.8995150923728943, 0.9027478694915771, 0.9086745977401733, 0.9073275923728943, 0.904902994632721, 0.90625, 0.9108297228813171, 0.9084051847457886, 0.915409505367279, 0.9197198152542114, 0.9108297228813171, 0.9207974076271057, 0.9175646305084229], 'val_loss': [1.6993731260299683, 1.6904410123825073, 1.681177020072937, 1.6711909770965576, 1.659938931465149, 1.6432212591171265, 1.6256439685821533, 1.6048575639724731, 1.5921108722686768, 1.57090163230896, 1.5599663257598877, 1.540799856185913, 1.5173919200897217, 1.5010031461715698, 1.4775468111038208, 1.4581236839294434, 1.438233494758606, 1.4187815189361572, 1.3975331783294678, 1.3813451528549194, 1.3614609241485596, 1.3474351167678833, 1.3335902690887451, 1.3250397443771362, 1.3172341585159302, 1.3030239343643188, 1.2907007932662964, 1.2814613580703735, 1.2737553119659424, 1.269187092781067, 1.2579818964004517, 1.249391794204712, 1.2437350749969482, 1.2340202331542969, 1.226473093032837, 1.2195732593536377, 1.2177655696868896, 1.2072858810424805, 1.198354959487915, 1.1993011236190796, 1.1856471300125122, 1.1790704727172852, 1.1734811067581177, 1.1699613332748413, 1.1751935482025146, 1.1547118425369263, 1.1868020296096802, 1.1445705890655518, 1.1411644220352173, 1.130987286567688, 1.1255806684494019, 1.1194651126861572, 1.1203999519348145, 1.1128876209259033, 1.1069539785385132, 1.1034321784973145, 1.096259355545044, 1.126816749572754, 1.1135320663452148, 1.08747136592865, 1.0813877582550049, 1.075158715248108, 1.0715017318725586, 1.084601640701294, 1.0638432502746582, 1.0607682466506958, 1.0560848712921143, 1.0549840927124023, 1.0489859580993652, 1.0448288917541504, 1.0762317180633545, 1.0375598669052124, 1.051627278327942, 1.0461101531982422, 1.0433838367462158, 1.0279866456985474, 1.0385310649871826, 1.024614691734314, 1.0157041549682617, 1.0232844352722168, 1.024271011352539, 1.0073364973068237, 1.0208450555801392, 1.0017966032028198, 1.0341413021087646, 0.9976701140403748, 0.995367169380188, 0.9980928301811218, 0.9942781329154968, 0.9908221960067749, 0.9940596222877502, 1.0032309293746948, 0.9878739714622498, 1.015629768371582, 1.0006874799728394, 0.9920254945755005, 0.972196102142334, 0.974026620388031, 0.9910607933998108, 0.970659077167511], 'val_accuracy': [0.48491379618644714, 0.7165948152542114, 0.6961206793785095, 0.6659482717514038, 0.6508620977401733, 0.7058189511299133, 0.7370689511299133, 0.7489224076271057, 0.7478448152542114, 0.7661637663841248, 0.7521551847457886, 0.7629310488700867, 0.7769396305084229, 0.7704741358757019, 0.7790948152542114, 0.7769396305084229, 0.7834051847457886, 0.787715494632721, 0.7855603694915771, 0.787715494632721, 0.7855603694915771, 0.7909482717514038, 0.798491358757019, 0.7931034564971924, 0.7995689511299133, 0.8006465435028076, 0.8071120977401733, 0.8081896305084229, 0.8092672228813171, 0.8092672228813171, 0.8135775923728943, 0.8114224076271057, 0.8168103694915771, 0.8114224076271057, 0.8125, 0.8114224076271057, 0.8243534564971924, 0.8081896305084229, 0.8254310488700867, 0.8243534564971924, 0.8200430870056152, 0.8243534564971924, 0.8221982717514038, 0.8178879022598267, 0.8275862336158752, 0.8286637663841248, 0.8221982717514038, 0.8286637663841248, 0.8221982717514038, 0.8351293206214905, 0.8200430870056152, 0.8286637663841248, 0.826508641242981, 0.8308189511299133, 0.8340517282485962, 0.8318965435028076, 0.8340517282485962, 0.8286637663841248, 0.8329741358757019, 0.8351293206214905, 0.8275862336158752, 0.8362069129943848, 0.8362069129943848, 0.837284505367279, 0.837284505367279, 0.8362069129943848, 0.8329741358757019, 0.8405172228813171, 0.8405172228813171, 0.8318965435028076, 0.8308189511299133, 0.8405172228813171, 0.84375, 0.8394396305084229, 0.8405172228813171, 0.8491379022598267, 0.8415948152542114, 0.829741358757019, 0.8415948152542114, 0.84375, 0.84375, 0.8415948152542114, 0.8426724076271057, 0.8426724076271057, 0.829741358757019, 0.8448275923728943, 0.84375, 0.8459051847457886, 0.8491379022598267, 0.8491379022598267, 0.850215494632721, 0.8362069129943848, 0.8480603694915771, 0.8221982717514038, 0.8329741358757019, 0.8405172228813171, 0.8523706793785095, 0.8448275923728943, 0.8340517282485962, 0.8523706793785095]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 1.7015 - accuracy: 0.5034"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 9s 57ms/step - loss: 1.7011 - accuracy: 0.5017 - val_loss: 1.6996 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.6862 - accuracy: 0.5059 - val_loss: 1.6910 - val_accuracy: 0.6980\n","Epoch 3/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.6661 - accuracy: 0.5772 - val_loss: 1.6825 - val_accuracy: 0.6346\n","Epoch 4/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6360 - accuracy: 0.6610 - val_loss: 1.6734 - val_accuracy: 0.6357\n","Epoch 5/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.5971 - accuracy: 0.7088 - val_loss: 1.6641 - val_accuracy: 0.6075\n","Epoch 6/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.5566 - accuracy: 0.7210 - val_loss: 1.6529 - val_accuracy: 0.6278\n","Epoch 7/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.5266 - accuracy: 0.7227 - val_loss: 1.6346 - val_accuracy: 0.7104\n","Epoch 8/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.5032 - accuracy: 0.7329 - val_loss: 1.6207 - val_accuracy: 0.7172\n","Epoch 9/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.4867 - accuracy: 0.7377 - val_loss: 1.6054 - val_accuracy: 0.7195\n","Epoch 10/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.4739 - accuracy: 0.7417 - val_loss: 1.5905 - val_accuracy: 0.7342\n","Epoch 11/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4646 - accuracy: 0.7397 - val_loss: 1.5816 - val_accuracy: 0.7195\n","Epoch 12/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.4553 - accuracy: 0.7479 - val_loss: 1.5609 - val_accuracy: 0.7410\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4450 - accuracy: 0.7482 - val_loss: 1.5476 - val_accuracy: 0.7410\n","Epoch 14/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4348 - accuracy: 0.7465 - val_loss: 1.5267 - val_accuracy: 0.7308\n","Epoch 15/100\n","28/28 [==============================] - 1s 34ms/step - loss: 1.4263 - accuracy: 0.7527 - val_loss: 1.5142 - val_accuracy: 0.7477\n","Epoch 16/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4138 - accuracy: 0.7581 - val_loss: 1.4947 - val_accuracy: 0.7477\n","Epoch 17/100\n","28/28 [==============================] - 1s 33ms/step - loss: 1.4087 - accuracy: 0.7586 - val_loss: 1.4769 - val_accuracy: 0.7500\n","Epoch 18/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.3968 - accuracy: 0.7634 - val_loss: 1.4588 - val_accuracy: 0.7455\n","Epoch 19/100\n","28/28 [==============================] - 1s 31ms/step - loss: 1.3950 - accuracy: 0.7572 - val_loss: 1.4420 - val_accuracy: 0.7523\n","Epoch 20/100\n","28/28 [==============================] - 1s 31ms/step - loss: 1.3805 - accuracy: 0.7705 - val_loss: 1.4253 - val_accuracy: 0.7545\n","Epoch 21/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3731 - accuracy: 0.7691 - val_loss: 1.4091 - val_accuracy: 0.7523\n","Epoch 22/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3592 - accuracy: 0.7756 - val_loss: 1.3941 - val_accuracy: 0.7545\n","Epoch 23/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.3544 - accuracy: 0.7733 - val_loss: 1.3816 - val_accuracy: 0.7613\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3480 - accuracy: 0.7770 - val_loss: 1.3758 - val_accuracy: 0.7590\n","Epoch 25/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.3356 - accuracy: 0.7787 - val_loss: 1.3599 - val_accuracy: 0.7658\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3269 - accuracy: 0.7807 - val_loss: 1.3500 - val_accuracy: 0.7647\n","Epoch 27/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.3223 - accuracy: 0.7799 - val_loss: 1.3385 - val_accuracy: 0.7681\n","Epoch 28/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.3117 - accuracy: 0.7782 - val_loss: 1.3284 - val_accuracy: 0.7692\n","Epoch 29/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2981 - accuracy: 0.7898 - val_loss: 1.3204 - val_accuracy: 0.7692\n","Epoch 30/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.2922 - accuracy: 0.7932 - val_loss: 1.3143 - val_accuracy: 0.7726\n","Epoch 31/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.2835 - accuracy: 0.7932 - val_loss: 1.3044 - val_accuracy: 0.7760\n","Epoch 32/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2851 - accuracy: 0.7909 - val_loss: 1.2997 - val_accuracy: 0.7738\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2642 - accuracy: 0.7982 - val_loss: 1.2951 - val_accuracy: 0.7704\n","Epoch 34/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.2625 - accuracy: 0.7994 - val_loss: 1.2838 - val_accuracy: 0.7828\n","Epoch 35/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.2502 - accuracy: 0.8031 - val_loss: 1.2805 - val_accuracy: 0.7896\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2489 - accuracy: 0.7985 - val_loss: 1.2981 - val_accuracy: 0.7839\n","Epoch 37/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.2329 - accuracy: 0.8042 - val_loss: 1.2677 - val_accuracy: 0.7964\n","Epoch 38/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2238 - accuracy: 0.8081 - val_loss: 1.2786 - val_accuracy: 0.7862\n","Epoch 39/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2179 - accuracy: 0.8079 - val_loss: 1.2522 - val_accuracy: 0.7885\n","Epoch 40/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2047 - accuracy: 0.8189 - val_loss: 1.2455 - val_accuracy: 0.7896\n","Epoch 41/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2023 - accuracy: 0.8186 - val_loss: 1.2604 - val_accuracy: 0.7738\n","Epoch 42/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1934 - accuracy: 0.8209 - val_loss: 1.2345 - val_accuracy: 0.7862\n","Epoch 43/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1895 - accuracy: 0.8169 - val_loss: 1.2436 - val_accuracy: 0.7885\n","Epoch 44/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1783 - accuracy: 0.8203 - val_loss: 1.2384 - val_accuracy: 0.7896\n","Epoch 45/100\n","28/28 [==============================] - 1s 31ms/step - loss: 1.1731 - accuracy: 0.8268 - val_loss: 1.2186 - val_accuracy: 0.8032\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1612 - accuracy: 0.8226 - val_loss: 1.2180 - val_accuracy: 0.7986\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1579 - accuracy: 0.8220 - val_loss: 1.2183 - val_accuracy: 0.7952\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1516 - accuracy: 0.8231 - val_loss: 1.2396 - val_accuracy: 0.7885\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1437 - accuracy: 0.8282 - val_loss: 1.1941 - val_accuracy: 0.7919\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1328 - accuracy: 0.8364 - val_loss: 1.1915 - val_accuracy: 0.8020\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1203 - accuracy: 0.8387 - val_loss: 1.1830 - val_accuracy: 0.7930\n","Epoch 52/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1135 - accuracy: 0.8364 - val_loss: 1.1941 - val_accuracy: 0.7952\n","Epoch 53/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1088 - accuracy: 0.8407 - val_loss: 1.1975 - val_accuracy: 0.8009\n","Epoch 54/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.0979 - accuracy: 0.8461 - val_loss: 1.1700 - val_accuracy: 0.8054\n","Epoch 55/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0914 - accuracy: 0.8441 - val_loss: 1.1707 - val_accuracy: 0.7986\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0860 - accuracy: 0.8362 - val_loss: 1.1623 - val_accuracy: 0.7930\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0795 - accuracy: 0.8438 - val_loss: 1.1836 - val_accuracy: 0.7919\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0744 - accuracy: 0.8472 - val_loss: 1.1573 - val_accuracy: 0.7975\n","Epoch 59/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0708 - accuracy: 0.8444 - val_loss: 1.1467 - val_accuracy: 0.8020\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0522 - accuracy: 0.8526 - val_loss: 1.1456 - val_accuracy: 0.8032\n","Epoch 61/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.0517 - accuracy: 0.8514 - val_loss: 1.1375 - val_accuracy: 0.8066\n","Epoch 62/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.0406 - accuracy: 0.8616 - val_loss: 1.1333 - val_accuracy: 0.8122\n","Epoch 63/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0359 - accuracy: 0.8596 - val_loss: 1.1308 - val_accuracy: 0.8077\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0255 - accuracy: 0.8580 - val_loss: 1.1337 - val_accuracy: 0.8020\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0200 - accuracy: 0.8591 - val_loss: 1.1279 - val_accuracy: 0.7998\n","Epoch 66/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0148 - accuracy: 0.8633 - val_loss: 1.1237 - val_accuracy: 0.7998\n","Epoch 67/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0069 - accuracy: 0.8653 - val_loss: 1.1181 - val_accuracy: 0.8020\n","Epoch 68/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9939 - accuracy: 0.8673 - val_loss: 1.1118 - val_accuracy: 0.8009\n","Epoch 69/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9938 - accuracy: 0.8715 - val_loss: 1.1087 - val_accuracy: 0.8122\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9901 - accuracy: 0.8673 - val_loss: 1.1291 - val_accuracy: 0.8088\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9821 - accuracy: 0.8642 - val_loss: 1.1111 - val_accuracy: 0.8077\n","Epoch 72/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9866 - accuracy: 0.8605 - val_loss: 1.1114 - val_accuracy: 0.8032\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9675 - accuracy: 0.8729 - val_loss: 1.0953 - val_accuracy: 0.8122\n","Epoch 74/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9571 - accuracy: 0.8780 - val_loss: 1.1136 - val_accuracy: 0.8066\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9534 - accuracy: 0.8769 - val_loss: 1.0919 - val_accuracy: 0.8009\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9478 - accuracy: 0.8803 - val_loss: 1.0880 - val_accuracy: 0.7986\n","Epoch 77/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.9395 - accuracy: 0.8786 - val_loss: 1.0836 - val_accuracy: 0.8133\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9324 - accuracy: 0.8851 - val_loss: 1.0804 - val_accuracy: 0.8054\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9323 - accuracy: 0.8831 - val_loss: 1.0769 - val_accuracy: 0.8043\n","Epoch 80/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9144 - accuracy: 0.8902 - val_loss: 1.0750 - val_accuracy: 0.8111\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9070 - accuracy: 0.8860 - val_loss: 1.0745 - val_accuracy: 0.8088\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9140 - accuracy: 0.8882 - val_loss: 1.0780 - val_accuracy: 0.8077\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9066 - accuracy: 0.8885 - val_loss: 1.0758 - val_accuracy: 0.8100\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8878 - accuracy: 0.8959 - val_loss: 1.0679 - val_accuracy: 0.8100\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8930 - accuracy: 0.8933 - val_loss: 1.0657 - val_accuracy: 0.8111\n","Epoch 86/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8789 - accuracy: 0.8967 - val_loss: 1.0646 - val_accuracy: 0.8122\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8817 - accuracy: 0.9018 - val_loss: 1.0618 - val_accuracy: 0.8122\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8714 - accuracy: 0.9024 - val_loss: 1.0775 - val_accuracy: 0.8054\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8808 - accuracy: 0.8894 - val_loss: 1.0516 - val_accuracy: 0.8077\n","Epoch 90/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8585 - accuracy: 0.9032 - val_loss: 1.0512 - val_accuracy: 0.8077\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8537 - accuracy: 0.9032 - val_loss: 1.0600 - val_accuracy: 0.8100\n","Epoch 92/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8413 - accuracy: 0.9109 - val_loss: 1.0553 - val_accuracy: 0.8111\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8372 - accuracy: 0.9106 - val_loss: 1.0609 - val_accuracy: 0.8088\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8417 - accuracy: 0.9072 - val_loss: 1.0784 - val_accuracy: 0.8032\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8443 - accuracy: 0.8981 - val_loss: 1.0552 - val_accuracy: 0.8122\n","Epoch 96/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8325 - accuracy: 0.9083 - val_loss: 1.0368 - val_accuracy: 0.8111\n","Epoch 97/100\n","28/28 [==============================] - 2s 73ms/step - loss: 0.8237 - accuracy: 0.9086 - val_loss: 1.0461 - val_accuracy: 0.8145\n","Epoch 98/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8122 - accuracy: 0.9151 - val_loss: 1.0627 - val_accuracy: 0.8043\n","Epoch 99/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8132 - accuracy: 0.9089 - val_loss: 1.0879 - val_accuracy: 0.7975\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8094 - accuracy: 0.9131 - val_loss: 1.0785 - val_accuracy: 0.7998\n","{'loss': [1.7010904550552368, 1.6861817836761475, 1.6660901308059692, 1.635969638824463, 1.5970505475997925, 1.556593656539917, 1.5266064405441284, 1.5032016038894653, 1.4866572618484497, 1.473858118057251, 1.4645767211914062, 1.4552980661392212, 1.4449753761291504, 1.4347695112228394, 1.4263039827346802, 1.4137862920761108, 1.4087332487106323, 1.3967922925949097, 1.3950421810150146, 1.3805103302001953, 1.3731409311294556, 1.359213948249817, 1.354368805885315, 1.3480174541473389, 1.3356378078460693, 1.3269448280334473, 1.322311520576477, 1.3116756677627563, 1.2981171607971191, 1.292175531387329, 1.2835122346878052, 1.285082221031189, 1.264185905456543, 1.2624682188034058, 1.2502061128616333, 1.2489055395126343, 1.2328605651855469, 1.2238413095474243, 1.217934250831604, 1.2047462463378906, 1.202307105064392, 1.1933895349502563, 1.1895060539245605, 1.1782547235488892, 1.1730527877807617, 1.161198616027832, 1.1579067707061768, 1.1516432762145996, 1.1437294483184814, 1.1327589750289917, 1.120280146598816, 1.1135205030441284, 1.1088130474090576, 1.0979328155517578, 1.091427206993103, 1.0859776735305786, 1.0794745683670044, 1.0744093656539917, 1.070813775062561, 1.0521732568740845, 1.0516504049301147, 1.040557622909546, 1.0358914136886597, 1.0254682302474976, 1.0200401544570923, 1.0148018598556519, 1.0068581104278564, 0.9939286708831787, 0.9938071370124817, 0.9901139736175537, 0.9820860624313354, 0.9866005182266235, 0.9675354361534119, 0.9570906758308411, 0.953362226486206, 0.9477592706680298, 0.9395118355751038, 0.9324423670768738, 0.9323180317878723, 0.9144077897071838, 0.9069770574569702, 0.9140419960021973, 0.906554102897644, 0.8877888917922974, 0.8929975032806396, 0.8789013624191284, 0.881722092628479, 0.871366024017334, 0.8808056116104126, 0.8584862351417542, 0.8537338376045227, 0.8413369655609131, 0.837233304977417, 0.841738224029541, 0.8443395495414734, 0.8324578404426575, 0.8237038254737854, 0.8122374415397644, 0.8131808042526245, 0.8094183802604675], 'accuracy': [0.5016977787017822, 0.5059422850608826, 0.5772495865821838, 0.6610073447227478, 0.7088285088539124, 0.7209960222244263, 0.7226938605308533, 0.7328805923461914, 0.7376909852027893, 0.7416524887084961, 0.7396717667579651, 0.7478777766227722, 0.748160719871521, 0.7464629411697388, 0.7526881694793701, 0.7580645084381104, 0.7586304545402527, 0.7634408473968506, 0.7572156190872192, 0.7705150246620178, 0.7691001892089844, 0.7756083607673645, 0.7733446359634399, 0.777023196220398, 0.7787209749221802, 0.780701756477356, 0.7798528671264648, 0.7781550884246826, 0.7897566556930542, 0.7931522130966187, 0.7931522130966187, 0.7908884882926941, 0.7982456088066101, 0.7993775010108948, 0.803056001663208, 0.7985285520553589, 0.8041878938674927, 0.8081493973731995, 0.8078664541244507, 0.8189020752906799, 0.8186191320419312, 0.8208828568458557, 0.8169213533401489, 0.8203169107437134, 0.8268251419067383, 0.8225806355476379, 0.8220146894454956, 0.8231465816497803, 0.8282399773597717, 0.8364459276199341, 0.8387096524238586, 0.8364459276199341, 0.8406904339790344, 0.8460667729377747, 0.8440860509872437, 0.8361629843711853, 0.8438030481338501, 0.8471986651420593, 0.8443689942359924, 0.8525750041007996, 0.8514431118965149, 0.8616299033164978, 0.859649121761322, 0.8579513430595398, 0.8590831756591797, 0.86332768201828, 0.865308403968811, 0.8672891855239868, 0.8715336918830872, 0.8672891855239868, 0.8641765713691711, 0.8604980111122131, 0.8729485273361206, 0.8780418634414673, 0.8769100308418274, 0.8803055882453918, 0.8786078095436096, 0.8851160407066345, 0.8831352591514587, 0.8902093768119812, 0.8859649300575256, 0.8882286548614502, 0.888511598110199, 0.895868718624115, 0.8933219909667969, 0.8967176079750061, 0.9018110036849976, 0.9023768901824951, 0.8893604874610901, 0.9032257795333862, 0.9032257795333862, 0.9108659029006958, 0.9105829000473022, 0.9071873426437378, 0.8981324434280396, 0.9083191752433777, 0.9086021780967712, 0.9151103496551514, 0.90888512134552, 0.9131296277046204], 'val_loss': [1.6995779275894165, 1.6910423040390015, 1.6824599504470825, 1.673388957977295, 1.6640839576721191, 1.6529279947280884, 1.6346267461776733, 1.6207109689712524, 1.6054496765136719, 1.5904852151870728, 1.581573724746704, 1.5608896017074585, 1.5475879907608032, 1.5267152786254883, 1.5142309665679932, 1.4947134256362915, 1.4769185781478882, 1.4587887525558472, 1.4419543743133545, 1.4252822399139404, 1.4091453552246094, 1.3941010236740112, 1.3816394805908203, 1.3757597208023071, 1.3598783016204834, 1.3499633073806763, 1.3384994268417358, 1.3284159898757935, 1.320379376411438, 1.3142882585525513, 1.304402470588684, 1.2997177839279175, 1.2951221466064453, 1.2837960720062256, 1.2804611921310425, 1.2981133460998535, 1.2676951885223389, 1.2786033153533936, 1.2522330284118652, 1.2455202341079712, 1.2604091167449951, 1.2345365285873413, 1.2436156272888184, 1.2383925914764404, 1.218622088432312, 1.2179794311523438, 1.218327283859253, 1.2396440505981445, 1.1941057443618774, 1.1915161609649658, 1.1829791069030762, 1.194092035293579, 1.1975380182266235, 1.1700299978256226, 1.1706855297088623, 1.1622868776321411, 1.1835956573486328, 1.1573259830474854, 1.1466971635818481, 1.145568609237671, 1.1374852657318115, 1.1332749128341675, 1.1307562589645386, 1.1336755752563477, 1.1278940439224243, 1.1237058639526367, 1.118065357208252, 1.1117894649505615, 1.1087085008621216, 1.1290923357009888, 1.1110955476760864, 1.111433744430542, 1.0953396558761597, 1.1135916709899902, 1.0919218063354492, 1.088028073310852, 1.083596110343933, 1.0803844928741455, 1.0769245624542236, 1.0749571323394775, 1.0744986534118652, 1.0780444145202637, 1.075791358947754, 1.0678762197494507, 1.065717339515686, 1.0645984411239624, 1.0617908239364624, 1.0774561166763306, 1.0515758991241455, 1.051159381866455, 1.0600154399871826, 1.0552902221679688, 1.0609424114227295, 1.0784069299697876, 1.0551542043685913, 1.036808967590332, 1.0460792779922485, 1.0626671314239502, 1.0878825187683105, 1.0784677267074585], 'val_accuracy': [0.4954751133918762, 0.6979637742042542, 0.6346153616905212, 0.6357465982437134, 0.6074660420417786, 0.627828061580658, 0.7104072570800781, 0.7171945571899414, 0.7194570302963257, 0.7341628670692444, 0.7194570302963257, 0.7409502267837524, 0.7409502267837524, 0.7307692170143127, 0.7477375268936157, 0.7477375268936157, 0.75, 0.7454751133918762, 0.7522624731063843, 0.7545248866081238, 0.7522624731063843, 0.7545248866081238, 0.7613122463226318, 0.7590497732162476, 0.7658371329307556, 0.7647058963775635, 0.7680995464324951, 0.7692307829856873, 0.7692307829856873, 0.7726244330406189, 0.7760180830955505, 0.773755669593811, 0.7703620195388794, 0.7828054428100586, 0.7895927429199219, 0.7839366793632507, 0.7963801026344299, 0.7861990928649902, 0.7884615659713745, 0.7895927429199219, 0.773755669593811, 0.7861990928649902, 0.7884615659713745, 0.7895927429199219, 0.8031674027442932, 0.7986425161361694, 0.7952488660812378, 0.7884615659713745, 0.7918552160263062, 0.8020362257957458, 0.7929864525794983, 0.7952488660812378, 0.8009049892425537, 0.8054298758506775, 0.7986425161361694, 0.7929864525794983, 0.7918552160263062, 0.7975113391876221, 0.8020362257957458, 0.8031674027442932, 0.8065611124038696, 0.8122171759605408, 0.807692289352417, 0.8020362257957458, 0.7997737526893616, 0.7997737526893616, 0.8020362257957458, 0.8009049892425537, 0.8122171759605408, 0.8088235259056091, 0.807692289352417, 0.8031674027442932, 0.8122171759605408, 0.8065611124038696, 0.8009049892425537, 0.7986425161361694, 0.8133484125137329, 0.8054298758506775, 0.8042986392974854, 0.8110859990119934, 0.8088235259056091, 0.807692289352417, 0.8099547624588013, 0.8099547624588013, 0.8110859990119934, 0.8122171759605408, 0.8122171759605408, 0.8054298758506775, 0.807692289352417, 0.807692289352417, 0.8099547624588013, 0.8110859990119934, 0.8088235259056091, 0.8031674027442932, 0.8122171759605408, 0.8110859990119934, 0.814479649066925, 0.8042986392974854, 0.7975113391876221, 0.7997737526893616]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 1.7005 - accuracy: 0.4978"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 7s 55ms/step - loss: 1.6996 - accuracy: 0.5003 - val_loss: 1.6987 - val_accuracy: 0.5114\n","Epoch 2/100\n","31/31 [==============================] - 1s 31ms/step - loss: 1.6811 - accuracy: 0.5313 - val_loss: 1.6892 - val_accuracy: 0.6808\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.6549 - accuracy: 0.6039 - val_loss: 1.6799 - val_accuracy: 0.5733\n","Epoch 4/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.6167 - accuracy: 0.6956 - val_loss: 1.6687 - val_accuracy: 0.6343\n","Epoch 5/100\n","31/31 [==============================] - 1s 29ms/step - loss: 1.5701 - accuracy: 0.7256 - val_loss: 1.6545 - val_accuracy: 0.6890\n","Epoch 6/100\n","31/31 [==============================] - 1s 31ms/step - loss: 1.5280 - accuracy: 0.7297 - val_loss: 1.6388 - val_accuracy: 0.7066\n","Epoch 7/100\n","31/31 [==============================] - 1s 30ms/step - loss: 1.5006 - accuracy: 0.7339 - val_loss: 1.6201 - val_accuracy: 0.7583\n","Epoch 8/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.4818 - accuracy: 0.7395 - val_loss: 1.6065 - val_accuracy: 0.7459\n","Epoch 9/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.4688 - accuracy: 0.7434 - val_loss: 1.5881 - val_accuracy: 0.7572\n","Epoch 10/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.4502 - accuracy: 0.7478 - val_loss: 1.5728 - val_accuracy: 0.7603\n","Epoch 11/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.4429 - accuracy: 0.7558 - val_loss: 1.5549 - val_accuracy: 0.7686\n","Epoch 12/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.4281 - accuracy: 0.7589 - val_loss: 1.5375 - val_accuracy: 0.7707\n","Epoch 13/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.4161 - accuracy: 0.7620 - val_loss: 1.5197 - val_accuracy: 0.7717\n","Epoch 14/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4096 - accuracy: 0.7597 - val_loss: 1.4979 - val_accuracy: 0.7624\n","Epoch 15/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3923 - accuracy: 0.7713 - val_loss: 1.4777 - val_accuracy: 0.7645\n","Epoch 16/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.3835 - accuracy: 0.7744 - val_loss: 1.4574 - val_accuracy: 0.7665\n","Epoch 17/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3714 - accuracy: 0.7755 - val_loss: 1.4427 - val_accuracy: 0.7521\n","Epoch 18/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3655 - accuracy: 0.7775 - val_loss: 1.4206 - val_accuracy: 0.7655\n","Epoch 19/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.3541 - accuracy: 0.7827 - val_loss: 1.4012 - val_accuracy: 0.7727\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3386 - accuracy: 0.7889 - val_loss: 1.3837 - val_accuracy: 0.7717\n","Epoch 21/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.3342 - accuracy: 0.7853 - val_loss: 1.3681 - val_accuracy: 0.7748\n","Epoch 22/100\n","31/31 [==============================] - 1s 26ms/step - loss: 1.3198 - accuracy: 0.7915 - val_loss: 1.3504 - val_accuracy: 0.7820\n","Epoch 23/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.3102 - accuracy: 0.7982 - val_loss: 1.3410 - val_accuracy: 0.7810\n","Epoch 24/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3006 - accuracy: 0.8059 - val_loss: 1.3300 - val_accuracy: 0.7800\n","Epoch 25/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2870 - accuracy: 0.8031 - val_loss: 1.3229 - val_accuracy: 0.7800\n","Epoch 26/100\n","31/31 [==============================] - 1s 32ms/step - loss: 1.2824 - accuracy: 0.8028 - val_loss: 1.3090 - val_accuracy: 0.7903\n","Epoch 27/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2727 - accuracy: 0.8065 - val_loss: 1.3056 - val_accuracy: 0.7800\n","Epoch 28/100\n","31/31 [==============================] - 1s 32ms/step - loss: 1.2582 - accuracy: 0.8158 - val_loss: 1.2929 - val_accuracy: 0.7934\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2461 - accuracy: 0.8173 - val_loss: 1.2937 - val_accuracy: 0.7738\n","Epoch 30/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2402 - accuracy: 0.8196 - val_loss: 1.2847 - val_accuracy: 0.7934\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2329 - accuracy: 0.8196 - val_loss: 1.2714 - val_accuracy: 0.7934\n","Epoch 32/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.2204 - accuracy: 0.8245 - val_loss: 1.2627 - val_accuracy: 0.7975\n","Epoch 33/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2087 - accuracy: 0.8269 - val_loss: 1.2714 - val_accuracy: 0.7769\n","Epoch 34/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.2045 - accuracy: 0.8310 - val_loss: 1.2486 - val_accuracy: 0.7996\n","Epoch 35/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1935 - accuracy: 0.8279 - val_loss: 1.2454 - val_accuracy: 0.7934\n","Epoch 36/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.1845 - accuracy: 0.8341 - val_loss: 1.2359 - val_accuracy: 0.8027\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1763 - accuracy: 0.8408 - val_loss: 1.2397 - val_accuracy: 0.7965\n","Epoch 38/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1691 - accuracy: 0.8375 - val_loss: 1.2300 - val_accuracy: 0.7965\n","Epoch 39/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.1644 - accuracy: 0.8395 - val_loss: 1.2166 - val_accuracy: 0.8079\n","Epoch 40/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1537 - accuracy: 0.8388 - val_loss: 1.2125 - val_accuracy: 0.8068\n","Epoch 41/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1466 - accuracy: 0.8403 - val_loss: 1.2154 - val_accuracy: 0.8027\n","Epoch 42/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1366 - accuracy: 0.8468 - val_loss: 1.1994 - val_accuracy: 0.8048\n","Epoch 43/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1245 - accuracy: 0.8434 - val_loss: 1.1956 - val_accuracy: 0.8058\n","Epoch 44/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.1141 - accuracy: 0.8475 - val_loss: 1.1936 - val_accuracy: 0.8099\n","Epoch 45/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.1055 - accuracy: 0.8506 - val_loss: 1.1911 - val_accuracy: 0.8130\n","Epoch 46/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.1034 - accuracy: 0.8486 - val_loss: 1.1889 - val_accuracy: 0.8068\n","Epoch 47/100\n","31/31 [==============================] - 1s 31ms/step - loss: 1.1080 - accuracy: 0.8442 - val_loss: 1.1736 - val_accuracy: 0.8140\n","Epoch 48/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0853 - accuracy: 0.8576 - val_loss: 1.1664 - val_accuracy: 0.8130\n","Epoch 49/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0780 - accuracy: 0.8543 - val_loss: 1.1637 - val_accuracy: 0.8130\n","Epoch 50/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0728 - accuracy: 0.8579 - val_loss: 1.1710 - val_accuracy: 0.8037\n","Epoch 51/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0683 - accuracy: 0.8571 - val_loss: 1.1674 - val_accuracy: 0.8037\n","Epoch 52/100\n","31/31 [==============================] - 1s 29ms/step - loss: 1.0562 - accuracy: 0.8623 - val_loss: 1.1494 - val_accuracy: 0.8171\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0432 - accuracy: 0.8646 - val_loss: 1.1488 - val_accuracy: 0.8110\n","Epoch 54/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0453 - accuracy: 0.8592 - val_loss: 1.1460 - val_accuracy: 0.8089\n","Epoch 55/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0446 - accuracy: 0.8568 - val_loss: 1.1599 - val_accuracy: 0.8027\n","Epoch 56/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.0432 - accuracy: 0.8576 - val_loss: 1.1300 - val_accuracy: 0.8223\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0249 - accuracy: 0.8638 - val_loss: 1.1280 - val_accuracy: 0.8182\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0177 - accuracy: 0.8654 - val_loss: 1.1251 - val_accuracy: 0.8151\n","Epoch 59/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0104 - accuracy: 0.8682 - val_loss: 1.1192 - val_accuracy: 0.8171\n","Epoch 60/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0020 - accuracy: 0.8695 - val_loss: 1.1150 - val_accuracy: 0.8151\n","Epoch 61/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9943 - accuracy: 0.8711 - val_loss: 1.1081 - val_accuracy: 0.8213\n","Epoch 62/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9915 - accuracy: 0.8765 - val_loss: 1.1045 - val_accuracy: 0.8192\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9793 - accuracy: 0.8788 - val_loss: 1.1181 - val_accuracy: 0.8079\n","Epoch 64/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9782 - accuracy: 0.8721 - val_loss: 1.0975 - val_accuracy: 0.8182\n","Epoch 65/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9663 - accuracy: 0.8848 - val_loss: 1.1048 - val_accuracy: 0.8089\n","Epoch 66/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9579 - accuracy: 0.8814 - val_loss: 1.0960 - val_accuracy: 0.8068\n","Epoch 67/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9533 - accuracy: 0.8837 - val_loss: 1.0943 - val_accuracy: 0.8130\n","Epoch 68/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9494 - accuracy: 0.8824 - val_loss: 1.0841 - val_accuracy: 0.8120\n","Epoch 69/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9451 - accuracy: 0.8806 - val_loss: 1.0851 - val_accuracy: 0.8151\n","Epoch 70/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9312 - accuracy: 0.8884 - val_loss: 1.0762 - val_accuracy: 0.8110\n","Epoch 71/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9313 - accuracy: 0.8871 - val_loss: 1.1430 - val_accuracy: 0.7986\n","Epoch 72/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9542 - accuracy: 0.8734 - val_loss: 1.0889 - val_accuracy: 0.8079\n","Epoch 73/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9245 - accuracy: 0.8871 - val_loss: 1.0838 - val_accuracy: 0.8151\n","Epoch 74/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9091 - accuracy: 0.8928 - val_loss: 1.0612 - val_accuracy: 0.8151\n","Epoch 75/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9024 - accuracy: 0.8946 - val_loss: 1.0596 - val_accuracy: 0.8161\n","Epoch 76/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8923 - accuracy: 0.8979 - val_loss: 1.0618 - val_accuracy: 0.8089\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8951 - accuracy: 0.8946 - val_loss: 1.0535 - val_accuracy: 0.8089\n","Epoch 78/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8901 - accuracy: 0.8912 - val_loss: 1.0516 - val_accuracy: 0.8151\n","Epoch 79/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8844 - accuracy: 0.8941 - val_loss: 1.0482 - val_accuracy: 0.8171\n","Epoch 80/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8771 - accuracy: 0.8961 - val_loss: 1.0462 - val_accuracy: 0.8110\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8627 - accuracy: 0.9054 - val_loss: 1.0435 - val_accuracy: 0.8120\n","Epoch 82/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8618 - accuracy: 0.9008 - val_loss: 1.0483 - val_accuracy: 0.8171\n","Epoch 83/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8582 - accuracy: 0.9005 - val_loss: 1.0387 - val_accuracy: 0.8089\n","Epoch 84/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8531 - accuracy: 0.9039 - val_loss: 1.0939 - val_accuracy: 0.7913\n","Epoch 85/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8447 - accuracy: 0.9005 - val_loss: 1.0716 - val_accuracy: 0.8140\n","Epoch 86/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8509 - accuracy: 0.8982 - val_loss: 1.1056 - val_accuracy: 0.8017\n","Epoch 87/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8731 - accuracy: 0.8879 - val_loss: 1.0322 - val_accuracy: 0.8027\n","Epoch 88/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8230 - accuracy: 0.9106 - val_loss: 1.0236 - val_accuracy: 0.8048\n","Epoch 89/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8557 - accuracy: 0.8915 - val_loss: 1.0199 - val_accuracy: 0.8110\n","Epoch 90/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8197 - accuracy: 0.9083 - val_loss: 1.0179 - val_accuracy: 0.8130\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8129 - accuracy: 0.9121 - val_loss: 1.0151 - val_accuracy: 0.8110\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8091 - accuracy: 0.9127 - val_loss: 1.0313 - val_accuracy: 0.8027\n","Epoch 93/100\n","31/31 [==============================] - 2s 59ms/step - loss: 0.8010 - accuracy: 0.9168 - val_loss: 1.0288 - val_accuracy: 0.8244\n","Epoch 94/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7968 - accuracy: 0.9119 - val_loss: 1.0105 - val_accuracy: 0.8037\n","Epoch 95/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7876 - accuracy: 0.9150 - val_loss: 1.0166 - val_accuracy: 0.8006\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7804 - accuracy: 0.9194 - val_loss: 1.0128 - val_accuracy: 0.8027\n","Epoch 97/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7779 - accuracy: 0.9173 - val_loss: 1.0086 - val_accuracy: 0.8058\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7866 - accuracy: 0.9152 - val_loss: 1.0051 - val_accuracy: 0.8110\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7826 - accuracy: 0.9129 - val_loss: 1.0027 - val_accuracy: 0.8068\n","Epoch 100/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7729 - accuracy: 0.9168 - val_loss: 1.0094 - val_accuracy: 0.8130\n","{'loss': [1.6996408700942993, 1.6811473369598389, 1.6548669338226318, 1.6166900396347046, 1.570138931274414, 1.5279641151428223, 1.500556468963623, 1.481764554977417, 1.4687950611114502, 1.4501829147338867, 1.4429168701171875, 1.4280529022216797, 1.4160631895065308, 1.409619688987732, 1.3923293352127075, 1.3835091590881348, 1.3714087009429932, 1.3654980659484863, 1.354149580001831, 1.3386473655700684, 1.3342241048812866, 1.3198484182357788, 1.3101660013198853, 1.300596833229065, 1.2870420217514038, 1.282447099685669, 1.2726643085479736, 1.258189082145691, 1.2461297512054443, 1.2401634454727173, 1.2329312562942505, 1.220379114151001, 1.2087033987045288, 1.2045416831970215, 1.1935179233551025, 1.1844611167907715, 1.1762768030166626, 1.1690959930419922, 1.1643664836883545, 1.1536543369293213, 1.1466161012649536, 1.1365934610366821, 1.1244864463806152, 1.11412513256073, 1.1055312156677246, 1.1034246683120728, 1.1079590320587158, 1.0852909088134766, 1.0780457258224487, 1.0728440284729004, 1.0683262348175049, 1.056158185005188, 1.043188452720642, 1.0452510118484497, 1.044630527496338, 1.0432323217391968, 1.0248870849609375, 1.0177247524261475, 1.0103669166564941, 1.001997709274292, 0.9942544102668762, 0.99149489402771, 0.9793293476104736, 0.9781782031059265, 0.9662749767303467, 0.9579398036003113, 0.9533358216285706, 0.9494073987007141, 0.9451302886009216, 0.9311767816543579, 0.9313256740570068, 0.954225480556488, 0.9244839549064636, 0.9090964198112488, 0.902397096157074, 0.8923160433769226, 0.8950634598731995, 0.8901240229606628, 0.8844411373138428, 0.8771315217018127, 0.8626846075057983, 0.8617571592330933, 0.8582177758216858, 0.8531451225280762, 0.8446645736694336, 0.8509316444396973, 0.8731182217597961, 0.8229723572731018, 0.855664849281311, 0.8196548223495483, 0.812860369682312, 0.8090853095054626, 0.8009843230247498, 0.7967849969863892, 0.7875667214393616, 0.7803635597229004, 0.7779260873794556, 0.7865719795227051, 0.7826043367385864, 0.7729142308235168], 'accuracy': [0.5002583861351013, 0.5312661528587341, 0.603875994682312, 0.6956072449684143, 0.7255814075469971, 0.7297157645225525, 0.7338501214981079, 0.739534854888916, 0.7434108257293701, 0.7478036284446716, 0.7558139562606812, 0.7589147090911865, 0.7620155215263367, 0.7596899271011353, 0.7713178396224976, 0.7744185924530029, 0.775452196598053, 0.7775194048881531, 0.7826873660087585, 0.7888888716697693, 0.7852713465690613, 0.791472852230072, 0.7981911897659302, 0.8059431314468384, 0.8031007647514343, 0.802842378616333, 0.8064599633216858, 0.8157622814178467, 0.8173126578330994, 0.8196382522583008, 0.8196382522583008, 0.8245478272438049, 0.8268733620643616, 0.8310077786445618, 0.8279069662094116, 0.8341085314750671, 0.8408268690109253, 0.8374677300453186, 0.8395348787307739, 0.8387596607208252, 0.8403100967407227, 0.8467700481414795, 0.843410849571228, 0.8475452065467834, 0.8506460189819336, 0.8485788106918335, 0.8441860675811768, 0.8576227426528931, 0.8542635440826416, 0.8578811287879944, 0.8571059703826904, 0.8622739315032959, 0.8645994663238525, 0.8591731190681458, 0.8568475246429443, 0.8576227426528931, 0.8638243079185486, 0.8653746843338013, 0.8682170510292053, 0.8695090413093567, 0.8710594177246094, 0.8764857649803162, 0.8788113594055176, 0.8720930218696594, 0.8847545385360718, 0.8813953399658203, 0.8837209343910217, 0.8824289441108704, 0.8806201815605164, 0.8883720636367798, 0.8870801329612732, 0.8733850121498108, 0.8870801329612732, 0.8927648663520813, 0.8945736289024353, 0.8979328274726868, 0.8945736289024353, 0.8912144899368286, 0.8940568566322327, 0.896124005317688, 0.9054263830184937, 0.9007751941680908, 0.9005168080329895, 0.9038759469985962, 0.9005168080329895, 0.8981912136077881, 0.8878552913665771, 0.9105943441390991, 0.8914728760719299, 0.9082687497138977, 0.9121447205543518, 0.9126614928245544, 0.9167958498001099, 0.9118863344192505, 0.9149870872497559, 0.9193798303604126, 0.9173126816749573, 0.9152454733848572, 0.9129198789596558, 0.9167958498001099], 'val_loss': [1.6986756324768066, 1.6891556978225708, 1.679882526397705, 1.6687374114990234, 1.6545424461364746, 1.6387511491775513, 1.6200995445251465, 1.606460690498352, 1.5881255865097046, 1.5727509260177612, 1.5549023151397705, 1.537459135055542, 1.51967453956604, 1.497912049293518, 1.4776546955108643, 1.4574415683746338, 1.4427204132080078, 1.420579433441162, 1.4011666774749756, 1.383721947669983, 1.3681141138076782, 1.35041081905365, 1.341007947921753, 1.3300169706344604, 1.3228713274002075, 1.3089877367019653, 1.3055710792541504, 1.2928829193115234, 1.2936861515045166, 1.2847459316253662, 1.2714059352874756, 1.2626699209213257, 1.2713792324066162, 1.248605489730835, 1.2454051971435547, 1.2358829975128174, 1.2396936416625977, 1.230035424232483, 1.2166088819503784, 1.212453007698059, 1.215360164642334, 1.199438452720642, 1.1955722570419312, 1.1935951709747314, 1.1911426782608032, 1.1888755559921265, 1.173641324043274, 1.1663634777069092, 1.1636744737625122, 1.170989751815796, 1.1673545837402344, 1.149389386177063, 1.148777723312378, 1.1460388898849487, 1.1599030494689941, 1.1300089359283447, 1.128011703491211, 1.1251349449157715, 1.1191705465316772, 1.1150248050689697, 1.1081137657165527, 1.1044738292694092, 1.118092656135559, 1.0975459814071655, 1.1047673225402832, 1.0959515571594238, 1.0942509174346924, 1.084094524383545, 1.0850869417190552, 1.0761655569076538, 1.142968773841858, 1.088944911956787, 1.0838452577590942, 1.0612223148345947, 1.059584379196167, 1.0618497133255005, 1.0535409450531006, 1.0516064167022705, 1.0482468605041504, 1.0461899042129517, 1.0434914827346802, 1.048290491104126, 1.0387400388717651, 1.0939184427261353, 1.071617841720581, 1.1055983304977417, 1.032158374786377, 1.0236331224441528, 1.01985764503479, 1.0178683996200562, 1.0150891542434692, 1.0312762260437012, 1.0287786722183228, 1.010494351387024, 1.0166128873825073, 1.0127865076065063, 1.0085750818252563, 1.005112648010254, 1.0026648044586182, 1.0093964338302612], 'val_accuracy': [0.5113636255264282, 0.6807851195335388, 0.5733470916748047, 0.6342975497245789, 0.6890496015548706, 0.7066115736961365, 0.7582644820213318, 0.7458677887916565, 0.7572314143180847, 0.7603305578231812, 0.7685950398445129, 0.7706611752510071, 0.7716942429542542, 0.7623966932296753, 0.7644628286361694, 0.7665289044380188, 0.7520661354064941, 0.7654958963394165, 0.7727272510528564, 0.7716942429542542, 0.7747933864593506, 0.7820248007774353, 0.7809917330741882, 0.7799586653709412, 0.7799586653709412, 0.7902892827987671, 0.7799586653709412, 0.7933884263038635, 0.7737603187561035, 0.7933884263038635, 0.7933884263038635, 0.797520637512207, 0.7768595218658447, 0.7995867729187012, 0.7933884263038635, 0.8026859760284424, 0.7964876294136047, 0.7964876294136047, 0.807851254940033, 0.8068181872367859, 0.8026859760284424, 0.8047520518302917, 0.8057851195335388, 0.8099173307418823, 0.8130165338516235, 0.8068181872367859, 0.8140496015548706, 0.8130165338516235, 0.8130165338516235, 0.8037189841270447, 0.8037189841270447, 0.817148745059967, 0.8109503984451294, 0.80888432264328, 0.8026859760284424, 0.8223140239715576, 0.8181818127632141, 0.8150826692581177, 0.817148745059967, 0.8150826692581177, 0.8212810158729553, 0.8192148804664612, 0.807851254940033, 0.8181818127632141, 0.80888432264328, 0.8068181872367859, 0.8130165338516235, 0.8119834661483765, 0.8150826692581177, 0.8109503984451294, 0.7985537052154541, 0.807851254940033, 0.8150826692581177, 0.8150826692581177, 0.81611567735672, 0.80888432264328, 0.80888432264328, 0.8150826692581177, 0.817148745059967, 0.8109503984451294, 0.8119834661483765, 0.817148745059967, 0.80888432264328, 0.7913222908973694, 0.8140496015548706, 0.8016529083251953, 0.8026859760284424, 0.8047520518302917, 0.8109503984451294, 0.8130165338516235, 0.8109503984451294, 0.8026859760284424, 0.8243801593780518, 0.8037189841270447, 0.8006198406219482, 0.8026859760284424, 0.8057851195335388, 0.8109503984451294, 0.8068181872367859, 0.8130165338516235]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.8945 - accuracy: 0.8588"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 7s 56ms/step - loss: 0.8917 - accuracy: 0.8607 - val_loss: 1.2698 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8630 - accuracy: 0.8726 - val_loss: 1.2661 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8544 - accuracy: 0.8772 - val_loss: 1.2636 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8567 - accuracy: 0.8710 - val_loss: 1.2588 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8383 - accuracy: 0.8834 - val_loss: 1.2536 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8361 - accuracy: 0.8769 - val_loss: 1.2451 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.8292 - accuracy: 0.8898 - val_loss: 1.2371 - val_accuracy: 0.4860\n","Epoch 8/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.8266 - accuracy: 0.8860 - val_loss: 1.2178 - val_accuracy: 0.4871\n","Epoch 9/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.8257 - accuracy: 0.8823 - val_loss: 1.1758 - val_accuracy: 0.5097\n","Epoch 10/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8125 - accuracy: 0.8887 - val_loss: 1.1701 - val_accuracy: 0.5086\n","Epoch 11/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.8057 - accuracy: 0.8922 - val_loss: 1.1210 - val_accuracy: 0.6196\n","Epoch 12/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.7984 - accuracy: 0.8963 - val_loss: 1.0877 - val_accuracy: 0.7198\n","Epoch 13/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.7945 - accuracy: 0.8947 - val_loss: 1.0697 - val_accuracy: 0.7403\n","Epoch 14/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.7823 - accuracy: 0.8995 - val_loss: 1.0317 - val_accuracy: 0.8136\n","Epoch 15/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.7746 - accuracy: 0.9044 - val_loss: 1.0124 - val_accuracy: 0.8157\n","Epoch 16/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.7740 - accuracy: 0.9003 - val_loss: 0.9812 - val_accuracy: 0.8351\n","Epoch 17/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.7679 - accuracy: 0.9038 - val_loss: 0.9362 - val_accuracy: 0.8847\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7679 - accuracy: 0.9071 - val_loss: 0.9205 - val_accuracy: 0.8599\n","Epoch 19/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7795 - accuracy: 0.8939 - val_loss: 0.9800 - val_accuracy: 0.7683\n","Epoch 20/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7676 - accuracy: 0.8960 - val_loss: 0.8758 - val_accuracy: 0.8782\n","Epoch 21/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7509 - accuracy: 0.9079 - val_loss: 0.8947 - val_accuracy: 0.8448\n","Epoch 22/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.7493 - accuracy: 0.9027 - val_loss: 0.8329 - val_accuracy: 0.8858\n","Epoch 23/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7353 - accuracy: 0.9108 - val_loss: 0.8236 - val_accuracy: 0.8847\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7303 - accuracy: 0.9114 - val_loss: 0.8336 - val_accuracy: 0.8761\n","Epoch 25/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7191 - accuracy: 0.9184 - val_loss: 0.8533 - val_accuracy: 0.8534\n","Epoch 26/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7325 - accuracy: 0.9154 - val_loss: 0.8012 - val_accuracy: 0.8804\n","Epoch 27/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7149 - accuracy: 0.9178 - val_loss: 0.8395 - val_accuracy: 0.8588\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7226 - accuracy: 0.9127 - val_loss: 0.7952 - val_accuracy: 0.8858\n","Epoch 29/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6984 - accuracy: 0.9230 - val_loss: 0.7936 - val_accuracy: 0.8847\n","Epoch 30/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.6906 - accuracy: 0.9273 - val_loss: 0.7925 - val_accuracy: 0.8869\n","Epoch 31/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6907 - accuracy: 0.9251 - val_loss: 0.8061 - val_accuracy: 0.8750\n","Epoch 32/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6883 - accuracy: 0.9256 - val_loss: 0.8106 - val_accuracy: 0.8761\n","Epoch 33/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6903 - accuracy: 0.9157 - val_loss: 0.8051 - val_accuracy: 0.8750\n","Epoch 34/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6846 - accuracy: 0.9256 - val_loss: 0.7948 - val_accuracy: 0.8728\n","Epoch 35/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6820 - accuracy: 0.9232 - val_loss: 0.7878 - val_accuracy: 0.8793\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6642 - accuracy: 0.9313 - val_loss: 0.8051 - val_accuracy: 0.8718\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6654 - accuracy: 0.9329 - val_loss: 0.7846 - val_accuracy: 0.8782\n","Epoch 38/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6568 - accuracy: 0.9308 - val_loss: 0.7834 - val_accuracy: 0.8782\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6667 - accuracy: 0.9283 - val_loss: 0.7975 - val_accuracy: 0.8739\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6560 - accuracy: 0.9262 - val_loss: 0.7806 - val_accuracy: 0.8782\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6442 - accuracy: 0.9356 - val_loss: 0.7880 - val_accuracy: 0.8675\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6401 - accuracy: 0.9372 - val_loss: 0.8408 - val_accuracy: 0.8610\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6480 - accuracy: 0.9294 - val_loss: 0.7980 - val_accuracy: 0.8664\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6385 - accuracy: 0.9318 - val_loss: 0.7770 - val_accuracy: 0.8804\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6277 - accuracy: 0.9388 - val_loss: 0.7788 - val_accuracy: 0.8772\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6267 - accuracy: 0.9399 - val_loss: 0.7741 - val_accuracy: 0.8772\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6218 - accuracy: 0.9407 - val_loss: 0.7783 - val_accuracy: 0.8772\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6417 - accuracy: 0.9300 - val_loss: 0.8179 - val_accuracy: 0.8696\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6169 - accuracy: 0.9402 - val_loss: 0.7690 - val_accuracy: 0.8782\n","Epoch 50/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6083 - accuracy: 0.9461 - val_loss: 0.7684 - val_accuracy: 0.8750\n","Epoch 51/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6011 - accuracy: 0.9491 - val_loss: 0.7758 - val_accuracy: 0.8750\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6071 - accuracy: 0.9415 - val_loss: 0.7832 - val_accuracy: 0.8793\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5962 - accuracy: 0.9475 - val_loss: 0.7978 - val_accuracy: 0.8718\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6019 - accuracy: 0.9388 - val_loss: 0.7640 - val_accuracy: 0.8815\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5878 - accuracy: 0.9504 - val_loss: 0.7657 - val_accuracy: 0.8793\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5916 - accuracy: 0.9440 - val_loss: 0.7741 - val_accuracy: 0.8772\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5852 - accuracy: 0.9477 - val_loss: 0.7658 - val_accuracy: 0.8772\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5785 - accuracy: 0.9507 - val_loss: 0.7689 - val_accuracy: 0.8772\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5705 - accuracy: 0.9534 - val_loss: 0.7661 - val_accuracy: 0.8772\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5719 - accuracy: 0.9520 - val_loss: 0.7890 - val_accuracy: 0.8728\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5585 - accuracy: 0.9569 - val_loss: 0.7642 - val_accuracy: 0.8782\n","Epoch 62/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5571 - accuracy: 0.9591 - val_loss: 0.7728 - val_accuracy: 0.8642\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5594 - accuracy: 0.9553 - val_loss: 0.7865 - val_accuracy: 0.8728\n","Epoch 64/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5541 - accuracy: 0.9558 - val_loss: 0.7636 - val_accuracy: 0.8836\n","Epoch 65/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5484 - accuracy: 0.9564 - val_loss: 0.7885 - val_accuracy: 0.8707\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5418 - accuracy: 0.9620 - val_loss: 0.7650 - val_accuracy: 0.8793\n","Epoch 67/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5513 - accuracy: 0.9555 - val_loss: 0.7680 - val_accuracy: 0.8782\n","Epoch 68/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5382 - accuracy: 0.9620 - val_loss: 0.7671 - val_accuracy: 0.8718\n","Epoch 69/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5306 - accuracy: 0.9620 - val_loss: 0.7930 - val_accuracy: 0.8750\n","Epoch 70/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5359 - accuracy: 0.9582 - val_loss: 0.8339 - val_accuracy: 0.8653\n","Epoch 71/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5363 - accuracy: 0.9577 - val_loss: 0.8181 - val_accuracy: 0.8707\n","Epoch 72/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5316 - accuracy: 0.9601 - val_loss: 0.7696 - val_accuracy: 0.8793\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5218 - accuracy: 0.9658 - val_loss: 0.7760 - val_accuracy: 0.8664\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5304 - accuracy: 0.9566 - val_loss: 0.7908 - val_accuracy: 0.8707\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5444 - accuracy: 0.9494 - val_loss: 0.7684 - val_accuracy: 0.8728\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5296 - accuracy: 0.9545 - val_loss: 0.9018 - val_accuracy: 0.8384\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5241 - accuracy: 0.9604 - val_loss: 0.7774 - val_accuracy: 0.8675\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5128 - accuracy: 0.9666 - val_loss: 0.7656 - val_accuracy: 0.8696\n","Epoch 79/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4940 - accuracy: 0.9758 - val_loss: 0.7885 - val_accuracy: 0.8664\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5004 - accuracy: 0.9677 - val_loss: 0.7930 - val_accuracy: 0.8761\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5115 - accuracy: 0.9626 - val_loss: 0.7974 - val_accuracy: 0.8631\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4942 - accuracy: 0.9690 - val_loss: 0.8126 - val_accuracy: 0.8621\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4919 - accuracy: 0.9731 - val_loss: 0.7858 - val_accuracy: 0.8621\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4919 - accuracy: 0.9714 - val_loss: 0.7813 - val_accuracy: 0.8707\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5075 - accuracy: 0.9604 - val_loss: 0.7675 - val_accuracy: 0.8707\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4827 - accuracy: 0.9736 - val_loss: 0.7708 - val_accuracy: 0.8696\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4763 - accuracy: 0.9758 - val_loss: 0.7731 - val_accuracy: 0.8739\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4787 - accuracy: 0.9739 - val_loss: 0.8347 - val_accuracy: 0.8653\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4973 - accuracy: 0.9623 - val_loss: 0.7713 - val_accuracy: 0.8739\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4765 - accuracy: 0.9749 - val_loss: 0.8080 - val_accuracy: 0.8728\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4785 - accuracy: 0.9704 - val_loss: 0.7918 - val_accuracy: 0.8675\n","Epoch 92/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4687 - accuracy: 0.9755 - val_loss: 0.8088 - val_accuracy: 0.8610\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4651 - accuracy: 0.9758 - val_loss: 0.7891 - val_accuracy: 0.8782\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4714 - accuracy: 0.9728 - val_loss: 0.7799 - val_accuracy: 0.8728\n","Epoch 95/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4609 - accuracy: 0.9774 - val_loss: 0.7750 - val_accuracy: 0.8750\n","Epoch 96/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4577 - accuracy: 0.9806 - val_loss: 0.7789 - val_accuracy: 0.8653\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4620 - accuracy: 0.9744 - val_loss: 0.7891 - val_accuracy: 0.8675\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4523 - accuracy: 0.9779 - val_loss: 0.7868 - val_accuracy: 0.8675\n","Epoch 99/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4541 - accuracy: 0.9755 - val_loss: 0.7758 - val_accuracy: 0.8642\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4506 - accuracy: 0.9814 - val_loss: 0.7860 - val_accuracy: 0.8664\n","{'loss': [0.8916579484939575, 0.8629598021507263, 0.8544268012046814, 0.8567232489585876, 0.8383021354675293, 0.8360599279403687, 0.8292092084884644, 0.8266036510467529, 0.8257265686988831, 0.8125432729721069, 0.8056738376617432, 0.7984057664871216, 0.7944827079772949, 0.7822898626327515, 0.7746468186378479, 0.7740176916122437, 0.7679048180580139, 0.767852783203125, 0.7795211672782898, 0.7675977349281311, 0.7509162425994873, 0.7492555379867554, 0.7352741956710815, 0.730344831943512, 0.7191060781478882, 0.7324899435043335, 0.7149288654327393, 0.7225967645645142, 0.6984483599662781, 0.6906047463417053, 0.6906977891921997, 0.6882886290550232, 0.6903115510940552, 0.6845637559890747, 0.6819790601730347, 0.6642338037490845, 0.6654213070869446, 0.6567863821983337, 0.6666610836982727, 0.6560446619987488, 0.6441633701324463, 0.6401048898696899, 0.6479991674423218, 0.6385026574134827, 0.6276772022247314, 0.6266833543777466, 0.6217808127403259, 0.6416639089584351, 0.61685711145401, 0.6082572340965271, 0.601074755191803, 0.6071115136146545, 0.5961988568305969, 0.6019155383110046, 0.5877533555030823, 0.5915522575378418, 0.5851955413818359, 0.5784921050071716, 0.5704509615898132, 0.5719349384307861, 0.5584962368011475, 0.5570836663246155, 0.559439480304718, 0.5540630221366882, 0.548379123210907, 0.5418362021446228, 0.5513318181037903, 0.538202702999115, 0.5305743217468262, 0.535949170589447, 0.5363154411315918, 0.5315897464752197, 0.5218445062637329, 0.5303548574447632, 0.5444045662879944, 0.5295552015304565, 0.5241385698318481, 0.5127837657928467, 0.49400752782821655, 0.5004499554634094, 0.5115430951118469, 0.494212806224823, 0.491876482963562, 0.49188703298568726, 0.507490336894989, 0.48270711302757263, 0.4763486683368683, 0.4787498116493225, 0.4973050355911255, 0.4765409529209137, 0.4785456955432892, 0.4687160551548004, 0.4651345908641815, 0.47144731879234314, 0.4609299302101135, 0.457675039768219, 0.46202096343040466, 0.45226985216140747, 0.4541199803352356, 0.45057737827301025], 'accuracy': [0.860722005367279, 0.8725754022598267, 0.8771551847457886, 0.8709590435028076, 0.8833512663841248, 0.8768857717514038, 0.8898168206214905, 0.8860452771186829, 0.8822737336158752, 0.8887392282485962, 0.892241358757019, 0.8962823152542114, 0.8946659564971924, 0.8995150923728943, 0.9043642282485962, 0.9003232717514038, 0.9038254022598267, 0.9070581793785095, 0.8938577771186829, 0.8960129022598267, 0.907866358757019, 0.9027478694915771, 0.9108297228813171, 0.9113685488700867, 0.9183728694915771, 0.915409505367279, 0.9178340435028076, 0.912715494632721, 0.9229525923728943, 0.9272629022598267, 0.9251077771186829, 0.9256465435028076, 0.915678858757019, 0.9256465435028076, 0.923222005367279, 0.931303858757019, 0.9329202771186829, 0.9307650923728943, 0.928340494632721, 0.9261853694915771, 0.9356142282485962, 0.9372305870056152, 0.9294180870056152, 0.9318426847457886, 0.938847005367279, 0.9399245977401733, 0.9407327771186829, 0.9299569129943848, 0.9401939511299133, 0.9461206793785095, 0.9490840435028076, 0.9415409564971924, 0.9474676847457886, 0.938847005367279, 0.9504310488700867, 0.943965494632721, 0.9477370977401733, 0.9507004022598267, 0.9533944129943848, 0.9520474076271057, 0.9568965435028076, 0.9590517282485962, 0.9552801847457886, 0.9558189511299133, 0.9563577771186829, 0.9620150923728943, 0.9555495977401733, 0.9620150923728943, 0.9620150923728943, 0.9582435488700867, 0.9577047228813171, 0.9601293206214905, 0.9657866358757019, 0.9566271305084229, 0.9493534564971924, 0.954472005367279, 0.9603987336158752, 0.9665948152542114, 0.9757543206214905, 0.9676724076271057, 0.962553858757019, 0.9690194129943848, 0.9730603694915771, 0.9714439511299133, 0.9603987336158752, 0.9735991358757019, 0.9757543206214905, 0.9738685488700867, 0.962284505367279, 0.974946141242981, 0.970366358757019, 0.9754849076271057, 0.9757543206214905, 0.9727909564971924, 0.9773706793785095, 0.9806034564971924, 0.9744073152542114, 0.977909505367279, 0.9754849076271057, 0.9814116358757019], 'val_loss': [1.2698417901992798, 1.2661346197128296, 1.263601541519165, 1.2588061094284058, 1.253609538078308, 1.24505615234375, 1.2371000051498413, 1.2177720069885254, 1.1757773160934448, 1.170096516609192, 1.1209543943405151, 1.0877045392990112, 1.0696991682052612, 1.031670093536377, 1.0124062299728394, 0.9812096357345581, 0.9361521005630493, 0.9205377697944641, 0.9799641370773315, 0.8757638335227966, 0.8947158455848694, 0.832876980304718, 0.8236117362976074, 0.8335806131362915, 0.8532567620277405, 0.8011553287506104, 0.8394795656204224, 0.7951902151107788, 0.793612539768219, 0.7924591302871704, 0.806062638759613, 0.8106170296669006, 0.8050795793533325, 0.7948267459869385, 0.7877835631370544, 0.8051181435585022, 0.7845726013183594, 0.7833555340766907, 0.7975097894668579, 0.7805670499801636, 0.7880235910415649, 0.8407944440841675, 0.7979763746261597, 0.7769560813903809, 0.7788405418395996, 0.7740660905838013, 0.7782981991767883, 0.8178738355636597, 0.7689912915229797, 0.7683869004249573, 0.775766909122467, 0.7832254767417908, 0.7977955937385559, 0.7640271782875061, 0.7656847834587097, 0.7741376757621765, 0.7657660841941833, 0.7689213156700134, 0.7661253213882446, 0.7889612317085266, 0.764193058013916, 0.7727644443511963, 0.7865437269210815, 0.7635892629623413, 0.7885248064994812, 0.7650452256202698, 0.7680041790008545, 0.7670972943305969, 0.7930017113685608, 0.8339106440544128, 0.8180814385414124, 0.7695607542991638, 0.7759793996810913, 0.7907893657684326, 0.7683895826339722, 0.9018433094024658, 0.7773623466491699, 0.7656115293502808, 0.7884769439697266, 0.7930300235748291, 0.797381579875946, 0.812640905380249, 0.7858028411865234, 0.7813408970832825, 0.767539381980896, 0.7707668542861938, 0.7730950713157654, 0.8346583843231201, 0.7713010907173157, 0.8080282807350159, 0.7917991876602173, 0.8087515234947205, 0.789050281047821, 0.7798511981964111, 0.7749966979026794, 0.7789175510406494, 0.7890591621398926, 0.7868404984474182, 0.7758065462112427, 0.785975992679596], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.48706895112991333, 0.5096982717514038, 0.5086206793785095, 0.6196120977401733, 0.7198275923728943, 0.7403017282485962, 0.8135775923728943, 0.8157327771186829, 0.8351293206214905, 0.8846982717514038, 0.8599137663841248, 0.7683189511299133, 0.8782327771186829, 0.8448275923728943, 0.8857758641242981, 0.8846982717514038, 0.8760775923728943, 0.8534482717514038, 0.8803879022598267, 0.8588362336158752, 0.8857758641242981, 0.8846982717514038, 0.8868534564971924, 0.875, 0.8760775923728943, 0.875, 0.8728448152542114, 0.8793103694915771, 0.8717672228813171, 0.8782327771186829, 0.8782327771186829, 0.8739224076271057, 0.8782327771186829, 0.8674569129943848, 0.860991358757019, 0.8663793206214905, 0.8803879022598267, 0.8771551847457886, 0.8771551847457886, 0.8771551847457886, 0.8696120977401733, 0.8782327771186829, 0.875, 0.875, 0.8793103694915771, 0.8717672228813171, 0.881465494632721, 0.8793103694915771, 0.8771551847457886, 0.8771551847457886, 0.8771551847457886, 0.8771551847457886, 0.8728448152542114, 0.8782327771186829, 0.8642241358757019, 0.8728448152542114, 0.8836206793785095, 0.8706896305084229, 0.8793103694915771, 0.8782327771186829, 0.8717672228813171, 0.875, 0.8653017282485962, 0.8706896305084229, 0.8793103694915771, 0.8663793206214905, 0.8706896305084229, 0.8728448152542114, 0.8383620977401733, 0.8674569129943848, 0.8696120977401733, 0.8663793206214905, 0.8760775923728943, 0.8631465435028076, 0.8620689511299133, 0.8620689511299133, 0.8706896305084229, 0.8706896305084229, 0.8696120977401733, 0.8739224076271057, 0.8653017282485962, 0.8739224076271057, 0.8728448152542114, 0.8674569129943848, 0.860991358757019, 0.8782327771186829, 0.8728448152542114, 0.875, 0.8653017282485962, 0.8674569129943848, 0.8674569129943848, 0.8642241358757019, 0.8663793206214905]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.9154 - accuracy: 0.8449"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 10s 99ms/step - loss: 0.9136 - accuracy: 0.8461 - val_loss: 1.2678 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.8801 - accuracy: 0.8676 - val_loss: 1.2636 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8646 - accuracy: 0.8744 - val_loss: 1.2597 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8666 - accuracy: 0.8738 - val_loss: 1.2556 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8582 - accuracy: 0.8772 - val_loss: 1.2518 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8509 - accuracy: 0.8789 - val_loss: 1.2475 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.8377 - accuracy: 0.8829 - val_loss: 1.2361 - val_accuracy: 0.4966\n","Epoch 8/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8304 - accuracy: 0.8834 - val_loss: 1.2195 - val_accuracy: 0.4966\n","Epoch 9/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.8276 - accuracy: 0.8843 - val_loss: 1.2021 - val_accuracy: 0.5011\n","Epoch 10/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.8234 - accuracy: 0.8882 - val_loss: 1.1786 - val_accuracy: 0.5192\n","Epoch 11/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.8176 - accuracy: 0.8823 - val_loss: 1.1498 - val_accuracy: 0.5667\n","Epoch 12/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.8160 - accuracy: 0.8862 - val_loss: 1.1152 - val_accuracy: 0.6674\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8087 - accuracy: 0.8854 - val_loss: 1.1213 - val_accuracy: 0.6063\n","Epoch 14/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7960 - accuracy: 0.8930 - val_loss: 1.0573 - val_accuracy: 0.7941\n","Epoch 15/100\n","28/28 [==============================] - 1s 17ms/step - loss: 0.7952 - accuracy: 0.8905 - val_loss: 1.0686 - val_accuracy: 0.7014\n","Epoch 16/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7816 - accuracy: 0.8998 - val_loss: 1.0370 - val_accuracy: 0.7557\n","Epoch 17/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.8152 - accuracy: 0.8806 - val_loss: 0.9680 - val_accuracy: 0.8462\n","Epoch 18/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7799 - accuracy: 0.8950 - val_loss: 0.9680 - val_accuracy: 0.8145\n","Epoch 19/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7716 - accuracy: 0.9007 - val_loss: 0.9586 - val_accuracy: 0.8122\n","Epoch 20/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7585 - accuracy: 0.9044 - val_loss: 0.9118 - val_accuracy: 0.8439\n","Epoch 21/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7690 - accuracy: 0.8959 - val_loss: 0.9016 - val_accuracy: 0.8371\n","Epoch 22/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7639 - accuracy: 0.9007 - val_loss: 0.8885 - val_accuracy: 0.8462\n","Epoch 23/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.7493 - accuracy: 0.9083 - val_loss: 0.8687 - val_accuracy: 0.8484\n","Epoch 24/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7463 - accuracy: 0.9078 - val_loss: 0.8819 - val_accuracy: 0.8292\n","Epoch 25/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7356 - accuracy: 0.9106 - val_loss: 0.8799 - val_accuracy: 0.8258\n","Epoch 26/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7238 - accuracy: 0.9174 - val_loss: 0.8569 - val_accuracy: 0.8428\n","Epoch 27/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7192 - accuracy: 0.9162 - val_loss: 0.8540 - val_accuracy: 0.8439\n","Epoch 28/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7228 - accuracy: 0.9154 - val_loss: 0.8562 - val_accuracy: 0.8416\n","Epoch 29/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7184 - accuracy: 0.9148 - val_loss: 0.8495 - val_accuracy: 0.8507\n","Epoch 30/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7078 - accuracy: 0.9202 - val_loss: 0.8498 - val_accuracy: 0.8416\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7107 - accuracy: 0.9162 - val_loss: 0.9531 - val_accuracy: 0.8077\n","Epoch 32/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7110 - accuracy: 0.9165 - val_loss: 0.8504 - val_accuracy: 0.8416\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6925 - accuracy: 0.9281 - val_loss: 0.8630 - val_accuracy: 0.8314\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6949 - accuracy: 0.9208 - val_loss: 0.8536 - val_accuracy: 0.8394\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6924 - accuracy: 0.9244 - val_loss: 0.8491 - val_accuracy: 0.8484\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6753 - accuracy: 0.9290 - val_loss: 0.8601 - val_accuracy: 0.8382\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6671 - accuracy: 0.9321 - val_loss: 0.8709 - val_accuracy: 0.8281\n","Epoch 38/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6758 - accuracy: 0.9239 - val_loss: 0.8605 - val_accuracy: 0.8360\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6688 - accuracy: 0.9287 - val_loss: 0.8692 - val_accuracy: 0.8314\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6599 - accuracy: 0.9346 - val_loss: 0.8447 - val_accuracy: 0.8473\n","Epoch 41/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6595 - accuracy: 0.9284 - val_loss: 0.8434 - val_accuracy: 0.8473\n","Epoch 42/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6613 - accuracy: 0.9335 - val_loss: 0.8536 - val_accuracy: 0.8394\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6396 - accuracy: 0.9375 - val_loss: 0.8421 - val_accuracy: 0.8428\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6478 - accuracy: 0.9335 - val_loss: 0.8426 - val_accuracy: 0.8484\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6351 - accuracy: 0.9400 - val_loss: 0.8497 - val_accuracy: 0.8360\n","Epoch 46/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6304 - accuracy: 0.9411 - val_loss: 0.8400 - val_accuracy: 0.8450\n","Epoch 47/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6358 - accuracy: 0.9355 - val_loss: 0.8580 - val_accuracy: 0.8348\n","Epoch 48/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6392 - accuracy: 0.9346 - val_loss: 0.8711 - val_accuracy: 0.8360\n","Epoch 49/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6280 - accuracy: 0.9358 - val_loss: 0.8390 - val_accuracy: 0.8450\n","Epoch 50/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6136 - accuracy: 0.9443 - val_loss: 0.8532 - val_accuracy: 0.8348\n","Epoch 51/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6168 - accuracy: 0.9386 - val_loss: 0.8419 - val_accuracy: 0.8473\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6162 - accuracy: 0.9369 - val_loss: 0.8706 - val_accuracy: 0.8258\n","Epoch 53/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6120 - accuracy: 0.9414 - val_loss: 0.8345 - val_accuracy: 0.8462\n","Epoch 54/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6012 - accuracy: 0.9420 - val_loss: 0.8610 - val_accuracy: 0.8360\n","Epoch 55/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6035 - accuracy: 0.9420 - val_loss: 0.8304 - val_accuracy: 0.8462\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6011 - accuracy: 0.9443 - val_loss: 0.8486 - val_accuracy: 0.8382\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5890 - accuracy: 0.9544 - val_loss: 0.8609 - val_accuracy: 0.8337\n","Epoch 58/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6069 - accuracy: 0.9363 - val_loss: 0.8483 - val_accuracy: 0.8382\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5965 - accuracy: 0.9471 - val_loss: 0.8837 - val_accuracy: 0.8179\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5906 - accuracy: 0.9479 - val_loss: 0.8503 - val_accuracy: 0.8416\n","Epoch 61/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5756 - accuracy: 0.9556 - val_loss: 0.8482 - val_accuracy: 0.8314\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5740 - accuracy: 0.9510 - val_loss: 0.8454 - val_accuracy: 0.8462\n","Epoch 63/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5664 - accuracy: 0.9553 - val_loss: 0.8319 - val_accuracy: 0.8382\n","Epoch 64/100\n","28/28 [==============================] - 2s 64ms/step - loss: 0.5553 - accuracy: 0.9573 - val_loss: 0.8382 - val_accuracy: 0.8518\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5637 - accuracy: 0.9598 - val_loss: 0.8477 - val_accuracy: 0.8473\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5627 - accuracy: 0.9516 - val_loss: 0.8323 - val_accuracy: 0.8484\n","Epoch 67/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5643 - accuracy: 0.9505 - val_loss: 0.8883 - val_accuracy: 0.8201\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5588 - accuracy: 0.9578 - val_loss: 0.8609 - val_accuracy: 0.8326\n","Epoch 69/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5410 - accuracy: 0.9635 - val_loss: 0.8394 - val_accuracy: 0.8529\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5396 - accuracy: 0.9632 - val_loss: 0.8414 - val_accuracy: 0.8292\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5358 - accuracy: 0.9658 - val_loss: 0.8404 - val_accuracy: 0.8348\n","Epoch 72/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5468 - accuracy: 0.9598 - val_loss: 0.8654 - val_accuracy: 0.8450\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5428 - accuracy: 0.9590 - val_loss: 0.8430 - val_accuracy: 0.8473\n","Epoch 74/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5416 - accuracy: 0.9584 - val_loss: 0.8345 - val_accuracy: 0.8428\n","Epoch 75/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5353 - accuracy: 0.9601 - val_loss: 0.8336 - val_accuracy: 0.8473\n","Epoch 76/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5292 - accuracy: 0.9643 - val_loss: 0.8465 - val_accuracy: 0.8507\n","Epoch 77/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5272 - accuracy: 0.9607 - val_loss: 0.8379 - val_accuracy: 0.8484\n","Epoch 78/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5252 - accuracy: 0.9607 - val_loss: 0.8366 - val_accuracy: 0.8450\n","Epoch 79/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5257 - accuracy: 0.9610 - val_loss: 0.8436 - val_accuracy: 0.8348\n","Epoch 80/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5109 - accuracy: 0.9689 - val_loss: 0.8402 - val_accuracy: 0.8382\n","Epoch 81/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5056 - accuracy: 0.9711 - val_loss: 0.8435 - val_accuracy: 0.8360\n","Epoch 82/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5140 - accuracy: 0.9641 - val_loss: 0.8468 - val_accuracy: 0.8337\n","Epoch 83/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5090 - accuracy: 0.9646 - val_loss: 0.9688 - val_accuracy: 0.8077\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5106 - accuracy: 0.9643 - val_loss: 0.8437 - val_accuracy: 0.8382\n","Epoch 85/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4975 - accuracy: 0.9726 - val_loss: 0.9015 - val_accuracy: 0.8258\n","Epoch 86/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4990 - accuracy: 0.9697 - val_loss: 0.8436 - val_accuracy: 0.8337\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4956 - accuracy: 0.9720 - val_loss: 0.8797 - val_accuracy: 0.8314\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5014 - accuracy: 0.9641 - val_loss: 0.8468 - val_accuracy: 0.8462\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4875 - accuracy: 0.9740 - val_loss: 0.8492 - val_accuracy: 0.8348\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4848 - accuracy: 0.9740 - val_loss: 0.8422 - val_accuracy: 0.8462\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4804 - accuracy: 0.9771 - val_loss: 0.8434 - val_accuracy: 0.8495\n","Epoch 92/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4841 - accuracy: 0.9726 - val_loss: 0.8536 - val_accuracy: 0.8337\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4797 - accuracy: 0.9731 - val_loss: 0.8575 - val_accuracy: 0.8450\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4748 - accuracy: 0.9774 - val_loss: 0.8766 - val_accuracy: 0.8314\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4774 - accuracy: 0.9728 - val_loss: 0.8466 - val_accuracy: 0.8371\n","Epoch 96/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4649 - accuracy: 0.9776 - val_loss: 0.8608 - val_accuracy: 0.8326\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4687 - accuracy: 0.9788 - val_loss: 0.8545 - val_accuracy: 0.8394\n","Epoch 98/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4636 - accuracy: 0.9771 - val_loss: 0.8752 - val_accuracy: 0.8462\n","Epoch 99/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4685 - accuracy: 0.9757 - val_loss: 0.8536 - val_accuracy: 0.8382\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4582 - accuracy: 0.9808 - val_loss: 0.8953 - val_accuracy: 0.8314\n","{'loss': [0.9135795831680298, 0.8800564408302307, 0.8645575642585754, 0.8666485548019409, 0.8581978678703308, 0.8509483337402344, 0.8377042412757874, 0.8303642272949219, 0.8275829553604126, 0.8233956694602966, 0.8176419734954834, 0.8159869313240051, 0.80867600440979, 0.795978307723999, 0.7952181696891785, 0.7815626263618469, 0.8151943683624268, 0.7798619866371155, 0.7715827226638794, 0.7584632039070129, 0.7689517736434937, 0.763897716999054, 0.7492589354515076, 0.7462636828422546, 0.735554575920105, 0.72381192445755, 0.7192308306694031, 0.7228225469589233, 0.7183966636657715, 0.70775306224823, 0.7106738686561584, 0.7109938859939575, 0.692484438419342, 0.6949396133422852, 0.6924431324005127, 0.6753330826759338, 0.6671319603919983, 0.6757559776306152, 0.668842613697052, 0.659855306148529, 0.659474790096283, 0.6613078713417053, 0.6396026611328125, 0.647797703742981, 0.6351193189620972, 0.6303784251213074, 0.6358391046524048, 0.6392319798469543, 0.6279725432395935, 0.6136382222175598, 0.6167691349983215, 0.6161926984786987, 0.6120336055755615, 0.6011819243431091, 0.6034528017044067, 0.6010677218437195, 0.5890196561813354, 0.6068889498710632, 0.5964919328689575, 0.5906366109848022, 0.5755746364593506, 0.5740470886230469, 0.5664000511169434, 0.555284857749939, 0.5636690855026245, 0.562716007232666, 0.5642731785774231, 0.5588033199310303, 0.540981650352478, 0.5395854115486145, 0.5358144044876099, 0.5467869639396667, 0.5427968502044678, 0.5415500402450562, 0.5352769494056702, 0.5291629433631897, 0.5272338390350342, 0.5252167582511902, 0.5256748795509338, 0.5109389424324036, 0.5056183338165283, 0.5140482187271118, 0.5090065002441406, 0.5106279253959656, 0.4975111782550812, 0.4990358352661133, 0.4955785274505615, 0.5014469623565674, 0.4875071346759796, 0.4847624897956848, 0.48039135336875916, 0.48412269353866577, 0.47970980405807495, 0.47476187348365784, 0.47744497656822205, 0.46486395597457886, 0.46874362230300903, 0.4635894000530243, 0.46854835748672485, 0.4581539034843445], 'accuracy': [0.8460667729377747, 0.8675721287727356, 0.8743633031845093, 0.8737974166870117, 0.8771929740905762, 0.8788907527923584, 0.88285231590271, 0.8834182024002075, 0.8842670917510986, 0.8882286548614502, 0.8822863698005676, 0.8862478733062744, 0.8853989839553833, 0.8930390477180481, 0.8904923796653748, 0.8998302221298218, 0.8805885910987854, 0.8950198292732239, 0.9006791114807129, 0.9043576717376709, 0.895868718624115, 0.9006791114807129, 0.9083191752433777, 0.9077532291412354, 0.9105829000473022, 0.9173740744590759, 0.916242241859436, 0.9153932929039001, 0.9148274064064026, 0.9202037453651428, 0.916242241859436, 0.9165251851081848, 0.9281267523765564, 0.9207696914672852, 0.9244481921195984, 0.9289756417274475, 0.9320882558822632, 0.9238823056221008, 0.9286926984786987, 0.9346349835395813, 0.92840975522995, 0.9335030913352966, 0.9374646544456482, 0.9335030913352966, 0.9400113224983215, 0.9411431550979614, 0.9354838728904724, 0.9346349835395813, 0.9357668161392212, 0.9442558288574219, 0.9385964870452881, 0.9368987083435059, 0.941426157951355, 0.9419921040534973, 0.9419921040534973, 0.9442558288574219, 0.95444256067276, 0.9363327622413635, 0.947085440158844, 0.9479343295097351, 0.9555743932723999, 0.9510469436645508, 0.9552914500236511, 0.9572722315788269, 0.9598188996315002, 0.9516128897666931, 0.9504810571670532, 0.9578381180763245, 0.9634974598884583, 0.9632145166397095, 0.9657611846923828, 0.9598188996315002, 0.9589700102806091, 0.9584040641784668, 0.960101842880249, 0.9643463492393494, 0.9606677889823914, 0.9606677889823914, 0.9609507918357849, 0.9688737988471985, 0.971137523651123, 0.9640634059906006, 0.9646292924880981, 0.9643463492393494, 0.9725523591041565, 0.9697226881980896, 0.9719864130020142, 0.9640634059906006, 0.9739671945571899, 0.9739671945571899, 0.9770798087120056, 0.9725523591041565, 0.9731183052062988, 0.9773627519607544, 0.9728353023529053, 0.977645754814148, 0.9787775874137878, 0.9770798087120056, 0.9756649732589722, 0.9807583689689636], 'val_loss': [1.2678377628326416, 1.263587236404419, 1.2596690654754639, 1.2556298971176147, 1.2517876625061035, 1.2475011348724365, 1.2360894680023193, 1.2195122241973877, 1.202136516571045, 1.1786340475082397, 1.1498370170593262, 1.1152026653289795, 1.1213395595550537, 1.0573055744171143, 1.068605899810791, 1.0370118618011475, 0.9680202007293701, 0.9679747223854065, 0.958561360836029, 0.9117609262466431, 0.9016371965408325, 0.8885490894317627, 0.8687212467193604, 0.8818944096565247, 0.8799005150794983, 0.8569475412368774, 0.8539865016937256, 0.8562091588973999, 0.849450945854187, 0.8497586250305176, 0.9531342387199402, 0.8504384756088257, 0.8630070090293884, 0.8535987734794617, 0.8490532040596008, 0.8601460456848145, 0.8709325790405273, 0.86053466796875, 0.8692319989204407, 0.8446935415267944, 0.8433860540390015, 0.8535845279693604, 0.8421364426612854, 0.842582643032074, 0.8497278094291687, 0.8399986028671265, 0.8580031991004944, 0.8711175918579102, 0.8389527797698975, 0.8531656861305237, 0.8418552279472351, 0.8706353902816772, 0.8344643712043762, 0.8610050678253174, 0.830419659614563, 0.8485517501831055, 0.8609117269515991, 0.8483389019966125, 0.8836919069290161, 0.8502620458602905, 0.8482187390327454, 0.8453946113586426, 0.8318742513656616, 0.8382061123847961, 0.8477059006690979, 0.8323233127593994, 0.8882912397384644, 0.8609338402748108, 0.8394359946250916, 0.8413614630699158, 0.8403502106666565, 0.8654210567474365, 0.8429667353630066, 0.8345159292221069, 0.8336180448532104, 0.8464544415473938, 0.8378807306289673, 0.8365970253944397, 0.8435916900634766, 0.8401512503623962, 0.8434908986091614, 0.8468078374862671, 0.9688473343849182, 0.8436552286148071, 0.9014813303947449, 0.8435570001602173, 0.8797078728675842, 0.8467803001403809, 0.8492476344108582, 0.8422476053237915, 0.8434176445007324, 0.8535523414611816, 0.8575185537338257, 0.8765733242034912, 0.8465929627418518, 0.8608188033103943, 0.8545272350311279, 0.8751931190490723, 0.8535873889923096, 0.8953427672386169], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.49660632014274597, 0.5011312365531921, 0.5192307829856873, 0.5667420625686646, 0.6674208045005798, 0.6063348650932312, 0.7941176295280457, 0.7013574838638306, 0.7556561231613159, 0.8461538553237915, 0.814479649066925, 0.8122171759605408, 0.8438913822174072, 0.837104082107544, 0.8461538553237915, 0.848416268825531, 0.8291855454444885, 0.8257918357849121, 0.8427602052688599, 0.8438913822174072, 0.8416289687156677, 0.8506787419319153, 0.8416289687156677, 0.807692289352417, 0.8416289687156677, 0.831447958946228, 0.8393664956092834, 0.848416268825531, 0.8382353186607361, 0.8280543088912964, 0.8359728455543518, 0.831447958946228, 0.8472850918769836, 0.8472850918769836, 0.8393664956092834, 0.8427602052688599, 0.848416268825531, 0.8359728455543518, 0.8450226187705994, 0.8348416090011597, 0.8359728455543518, 0.8450226187705994, 0.8348416090011597, 0.8472850918769836, 0.8257918357849121, 0.8461538553237915, 0.8359728455543518, 0.8461538553237915, 0.8382353186607361, 0.8337104320526123, 0.8382353186607361, 0.8178732991218567, 0.8416289687156677, 0.831447958946228, 0.8461538553237915, 0.8382353186607361, 0.8518099784851074, 0.8472850918769836, 0.848416268825531, 0.820135772228241, 0.8325791954994202, 0.8529411554336548, 0.8291855454444885, 0.8348416090011597, 0.8450226187705994, 0.8472850918769836, 0.8427602052688599, 0.8472850918769836, 0.8506787419319153, 0.848416268825531, 0.8450226187705994, 0.8348416090011597, 0.8382353186607361, 0.8359728455543518, 0.8337104320526123, 0.807692289352417, 0.8382353186607361, 0.8257918357849121, 0.8337104320526123, 0.831447958946228, 0.8461538553237915, 0.8348416090011597, 0.8461538553237915, 0.8495475053787231, 0.8337104320526123, 0.8450226187705994, 0.831447958946228, 0.837104082107544, 0.8325791954994202, 0.8393664956092834, 0.8461538553237915, 0.8382353186607361, 0.831447958946228]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 0.8802 - accuracy: 0.8629"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 8s 69ms/step - loss: 0.8795 - accuracy: 0.8638 - val_loss: 1.2709 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8614 - accuracy: 0.8775 - val_loss: 1.2674 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8460 - accuracy: 0.8845 - val_loss: 1.2636 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8476 - accuracy: 0.8806 - val_loss: 1.2593 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8272 - accuracy: 0.8910 - val_loss: 1.2529 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8227 - accuracy: 0.8858 - val_loss: 1.2453 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8195 - accuracy: 0.8855 - val_loss: 1.2192 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8160 - accuracy: 0.8912 - val_loss: 1.2071 - val_accuracy: 0.4855\n","Epoch 9/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8091 - accuracy: 0.8959 - val_loss: 1.1674 - val_accuracy: 0.5248\n","Epoch 10/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8009 - accuracy: 0.8943 - val_loss: 1.1699 - val_accuracy: 0.5072\n","Epoch 11/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8025 - accuracy: 0.8884 - val_loss: 1.1192 - val_accuracy: 0.6043\n","Epoch 12/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7976 - accuracy: 0.8928 - val_loss: 1.0934 - val_accuracy: 0.6736\n","Epoch 13/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.7763 - accuracy: 0.8979 - val_loss: 1.0523 - val_accuracy: 0.7614\n","Epoch 14/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7754 - accuracy: 0.9039 - val_loss: 1.0179 - val_accuracy: 0.8037\n","Epoch 15/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.7634 - accuracy: 0.9039 - val_loss: 0.9821 - val_accuracy: 0.8316\n","Epoch 16/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7630 - accuracy: 0.9065 - val_loss: 0.9648 - val_accuracy: 0.8285\n","Epoch 17/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.7579 - accuracy: 0.9088 - val_loss: 0.9300 - val_accuracy: 0.8502\n","Epoch 18/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7491 - accuracy: 0.9067 - val_loss: 0.9165 - val_accuracy: 0.8388\n","Epoch 19/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7447 - accuracy: 0.9096 - val_loss: 0.9122 - val_accuracy: 0.8285\n","Epoch 20/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.7386 - accuracy: 0.9103 - val_loss: 0.8657 - val_accuracy: 0.8554\n","Epoch 21/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7375 - accuracy: 0.9103 - val_loss: 0.8628 - val_accuracy: 0.8574\n","Epoch 22/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7208 - accuracy: 0.9178 - val_loss: 0.8570 - val_accuracy: 0.8533\n","Epoch 23/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7246 - accuracy: 0.9140 - val_loss: 0.8456 - val_accuracy: 0.8564\n","Epoch 24/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7129 - accuracy: 0.9191 - val_loss: 0.8432 - val_accuracy: 0.8574\n","Epoch 25/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.7232 - accuracy: 0.9109 - val_loss: 0.8683 - val_accuracy: 0.8419\n","Epoch 26/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7157 - accuracy: 0.9147 - val_loss: 0.8729 - val_accuracy: 0.8419\n","Epoch 27/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.7071 - accuracy: 0.9168 - val_loss: 0.8385 - val_accuracy: 0.8605\n","Epoch 28/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.6955 - accuracy: 0.9243 - val_loss: 0.8376 - val_accuracy: 0.8626\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6887 - accuracy: 0.9243 - val_loss: 0.8502 - val_accuracy: 0.8492\n","Epoch 30/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7061 - accuracy: 0.9121 - val_loss: 0.8432 - val_accuracy: 0.8605\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6928 - accuracy: 0.9191 - val_loss: 0.8345 - val_accuracy: 0.8616\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6814 - accuracy: 0.9251 - val_loss: 0.8477 - val_accuracy: 0.8523\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6878 - accuracy: 0.9189 - val_loss: 0.8423 - val_accuracy: 0.8502\n","Epoch 34/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6736 - accuracy: 0.9233 - val_loss: 0.8407 - val_accuracy: 0.8502\n","Epoch 35/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6593 - accuracy: 0.9318 - val_loss: 0.8490 - val_accuracy: 0.8502\n","Epoch 36/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6695 - accuracy: 0.9256 - val_loss: 0.8572 - val_accuracy: 0.8502\n","Epoch 37/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6666 - accuracy: 0.9235 - val_loss: 0.8259 - val_accuracy: 0.8585\n","Epoch 38/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6524 - accuracy: 0.9377 - val_loss: 0.8276 - val_accuracy: 0.8564\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6473 - accuracy: 0.9320 - val_loss: 0.8394 - val_accuracy: 0.8523\n","Epoch 40/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6570 - accuracy: 0.9279 - val_loss: 0.8258 - val_accuracy: 0.8595\n","Epoch 41/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6384 - accuracy: 0.9364 - val_loss: 0.8277 - val_accuracy: 0.8554\n","Epoch 42/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6285 - accuracy: 0.9401 - val_loss: 0.8263 - val_accuracy: 0.8554\n","Epoch 43/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6213 - accuracy: 0.9388 - val_loss: 0.8244 - val_accuracy: 0.8574\n","Epoch 44/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6363 - accuracy: 0.9336 - val_loss: 0.8233 - val_accuracy: 0.8585\n","Epoch 45/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6219 - accuracy: 0.9419 - val_loss: 0.8229 - val_accuracy: 0.8564\n","Epoch 46/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6184 - accuracy: 0.9398 - val_loss: 0.8312 - val_accuracy: 0.8543\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6122 - accuracy: 0.9429 - val_loss: 0.8445 - val_accuracy: 0.8450\n","Epoch 48/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6172 - accuracy: 0.9367 - val_loss: 0.8436 - val_accuracy: 0.8450\n","Epoch 49/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6057 - accuracy: 0.9437 - val_loss: 0.8150 - val_accuracy: 0.8564\n","Epoch 50/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6023 - accuracy: 0.9424 - val_loss: 0.8155 - val_accuracy: 0.8605\n","Epoch 51/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5980 - accuracy: 0.9413 - val_loss: 0.8159 - val_accuracy: 0.8595\n","Epoch 52/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5909 - accuracy: 0.9463 - val_loss: 0.8172 - val_accuracy: 0.8605\n","Epoch 53/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5858 - accuracy: 0.9494 - val_loss: 0.8165 - val_accuracy: 0.8605\n","Epoch 54/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5841 - accuracy: 0.9517 - val_loss: 0.8492 - val_accuracy: 0.8481\n","Epoch 55/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5830 - accuracy: 0.9470 - val_loss: 0.8171 - val_accuracy: 0.8523\n","Epoch 56/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5836 - accuracy: 0.9452 - val_loss: 0.8705 - val_accuracy: 0.8337\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5822 - accuracy: 0.9463 - val_loss: 0.8106 - val_accuracy: 0.8595\n","Epoch 58/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5728 - accuracy: 0.9517 - val_loss: 0.8191 - val_accuracy: 0.8523\n","Epoch 59/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5648 - accuracy: 0.9501 - val_loss: 0.8118 - val_accuracy: 0.8523\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5626 - accuracy: 0.9527 - val_loss: 0.8123 - val_accuracy: 0.8605\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5669 - accuracy: 0.9494 - val_loss: 0.8067 - val_accuracy: 0.8574\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5620 - accuracy: 0.9512 - val_loss: 0.8265 - val_accuracy: 0.8533\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5535 - accuracy: 0.9543 - val_loss: 0.8106 - val_accuracy: 0.8564\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5424 - accuracy: 0.9587 - val_loss: 0.8079 - val_accuracy: 0.8574\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5411 - accuracy: 0.9605 - val_loss: 0.8069 - val_accuracy: 0.8595\n","Epoch 66/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5393 - accuracy: 0.9594 - val_loss: 0.8064 - val_accuracy: 0.8564\n","Epoch 67/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5313 - accuracy: 0.9612 - val_loss: 0.8163 - val_accuracy: 0.8492\n","Epoch 68/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5406 - accuracy: 0.9535 - val_loss: 0.8317 - val_accuracy: 0.8388\n","Epoch 69/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5271 - accuracy: 0.9641 - val_loss: 0.8060 - val_accuracy: 0.8585\n","Epoch 70/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5221 - accuracy: 0.9651 - val_loss: 0.8088 - val_accuracy: 0.8595\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5228 - accuracy: 0.9638 - val_loss: 0.8105 - val_accuracy: 0.8605\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5162 - accuracy: 0.9656 - val_loss: 0.8281 - val_accuracy: 0.8440\n","Epoch 73/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5287 - accuracy: 0.9592 - val_loss: 0.8064 - val_accuracy: 0.8585\n","Epoch 74/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5191 - accuracy: 0.9597 - val_loss: 0.8082 - val_accuracy: 0.8512\n","Epoch 75/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5284 - accuracy: 0.9540 - val_loss: 0.8031 - val_accuracy: 0.8574\n","Epoch 76/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5090 - accuracy: 0.9674 - val_loss: 0.8258 - val_accuracy: 0.8523\n","Epoch 77/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5059 - accuracy: 0.9646 - val_loss: 0.8147 - val_accuracy: 0.8533\n","Epoch 78/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5018 - accuracy: 0.9682 - val_loss: 0.8180 - val_accuracy: 0.8554\n","Epoch 79/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5117 - accuracy: 0.9623 - val_loss: 0.8038 - val_accuracy: 0.8616\n","Epoch 80/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4973 - accuracy: 0.9680 - val_loss: 0.8060 - val_accuracy: 0.8543\n","Epoch 81/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4928 - accuracy: 0.9677 - val_loss: 0.8079 - val_accuracy: 0.8554\n","Epoch 82/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4907 - accuracy: 0.9677 - val_loss: 0.8065 - val_accuracy: 0.8595\n","Epoch 83/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4860 - accuracy: 0.9731 - val_loss: 0.8081 - val_accuracy: 0.8595\n","Epoch 84/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4833 - accuracy: 0.9703 - val_loss: 0.8082 - val_accuracy: 0.8595\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4887 - accuracy: 0.9682 - val_loss: 0.8488 - val_accuracy: 0.8378\n","Epoch 86/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5008 - accuracy: 0.9579 - val_loss: 0.8439 - val_accuracy: 0.8409\n","Epoch 87/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4815 - accuracy: 0.9685 - val_loss: 0.8284 - val_accuracy: 0.8554\n","Epoch 88/100\n","31/31 [==============================] - 2s 55ms/step - loss: 0.4746 - accuracy: 0.9734 - val_loss: 0.8072 - val_accuracy: 0.8657\n","Epoch 89/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4670 - accuracy: 0.9765 - val_loss: 0.8091 - val_accuracy: 0.8574\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4642 - accuracy: 0.9726 - val_loss: 0.8286 - val_accuracy: 0.8543\n","Epoch 91/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4751 - accuracy: 0.9667 - val_loss: 0.8845 - val_accuracy: 0.8399\n","Epoch 92/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4661 - accuracy: 0.9739 - val_loss: 0.8076 - val_accuracy: 0.8554\n","Epoch 93/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4654 - accuracy: 0.9734 - val_loss: 0.8391 - val_accuracy: 0.8533\n","Epoch 94/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4619 - accuracy: 0.9721 - val_loss: 0.8861 - val_accuracy: 0.8440\n","Epoch 95/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4737 - accuracy: 0.9646 - val_loss: 0.8474 - val_accuracy: 0.8523\n","Epoch 96/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4506 - accuracy: 0.9757 - val_loss: 0.8114 - val_accuracy: 0.8564\n","Epoch 97/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4614 - accuracy: 0.9718 - val_loss: 0.8153 - val_accuracy: 0.8595\n","Epoch 98/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4487 - accuracy: 0.9773 - val_loss: 0.8074 - val_accuracy: 0.8626\n","Epoch 99/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4527 - accuracy: 0.9721 - val_loss: 0.8122 - val_accuracy: 0.8585\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4445 - accuracy: 0.9780 - val_loss: 0.8143 - val_accuracy: 0.8616\n","{'loss': [0.8794626593589783, 0.8614128828048706, 0.8460322618484497, 0.8476441502571106, 0.827235758304596, 0.8227308392524719, 0.8194641470909119, 0.8159974217414856, 0.8091285228729248, 0.8008546233177185, 0.8025220036506653, 0.79763263463974, 0.7763242125511169, 0.7754323482513428, 0.7633652091026306, 0.7629662156105042, 0.757931649684906, 0.7491247653961182, 0.7446669936180115, 0.7386343479156494, 0.7374523282051086, 0.7208399176597595, 0.724577009677887, 0.7129213809967041, 0.7231519222259521, 0.7157027721405029, 0.7071402072906494, 0.6954574584960938, 0.6887044310569763, 0.7060537338256836, 0.6928110122680664, 0.681378960609436, 0.6877907514572144, 0.673601508140564, 0.6592770218849182, 0.6695180535316467, 0.6666491627693176, 0.652440071105957, 0.6472509503364563, 0.6570057272911072, 0.6384402513504028, 0.6285063624382019, 0.6213406324386597, 0.636280357837677, 0.6218705773353577, 0.6183866262435913, 0.6122279167175293, 0.6172443628311157, 0.6057383418083191, 0.6023141741752625, 0.5980246067047119, 0.5909317135810852, 0.585847795009613, 0.5841001272201538, 0.5829547643661499, 0.583647608757019, 0.5821735262870789, 0.5728184580802917, 0.5648240447044373, 0.5625890493392944, 0.5669124126434326, 0.5619783401489258, 0.5534692406654358, 0.5423662066459656, 0.5411104559898376, 0.5393233299255371, 0.5312700867652893, 0.5406177639961243, 0.5271044373512268, 0.5220794081687927, 0.5228128433227539, 0.5162186026573181, 0.5286961793899536, 0.5191192030906677, 0.5284121036529541, 0.5090188980102539, 0.5058720707893372, 0.501775860786438, 0.5117458701133728, 0.4972692131996155, 0.4927672743797302, 0.4907209873199463, 0.48595044016838074, 0.48325759172439575, 0.488663911819458, 0.5008248090744019, 0.4814627766609192, 0.47462770342826843, 0.4669675827026367, 0.4641895592212677, 0.4751008152961731, 0.46605658531188965, 0.4653570055961609, 0.4618662893772125, 0.4737025499343872, 0.4505540132522583, 0.46143683791160583, 0.4486759305000305, 0.452713280916214, 0.44451630115509033], 'accuracy': [0.8638243079185486, 0.8775193691253662, 0.8844961524009705, 0.8806201815605164, 0.8909560441970825, 0.8857881426811218, 0.8855296969413757, 0.8912144899368286, 0.8958656191825867, 0.894315242767334, 0.8883720636367798, 0.8927648663520813, 0.8979328274726868, 0.9038759469985962, 0.9038759469985962, 0.9064599275588989, 0.9087855219841003, 0.906718373298645, 0.9095607399940491, 0.910335898399353, 0.910335898399353, 0.9178294539451599, 0.9139534831047058, 0.9191214442253113, 0.9108527302742004, 0.9147287011146545, 0.9167958498001099, 0.9242894053459167, 0.9242894053459167, 0.9121447205543518, 0.9191214442253113, 0.9250646233558655, 0.91886305809021, 0.9232558012008667, 0.9317829608917236, 0.9255813956260681, 0.923514187335968, 0.9377260804176331, 0.932041347026825, 0.9279069900512695, 0.9364340901374817, 0.9400516748428345, 0.9387596845626831, 0.9335917234420776, 0.9418604373931885, 0.9397932887077332, 0.9428940415382385, 0.9366925358772278, 0.9436692595481873, 0.9423772692680359, 0.9413436651229858, 0.94625324010849, 0.9493539929389954, 0.9516795873641968, 0.947028398513794, 0.9452196359634399, 0.94625324010849, 0.9516795873641968, 0.9501292109489441, 0.9527131915092468, 0.9493539929389954, 0.9511628150939941, 0.9542635679244995, 0.9586563110351562, 0.960465133190155, 0.959431529045105, 0.961240291595459, 0.9534883499145508, 0.964082658290863, 0.9651162624359131, 0.9638242721557617, 0.9656330943107605, 0.9591731429100037, 0.9596899151802063, 0.9540051817893982, 0.9674418568611145, 0.9645994901657104, 0.9682170748710632, 0.962273895740509, 0.9679586291313171, 0.9677002429962158, 0.9677002429962158, 0.9731265902519226, 0.9702842235565186, 0.9682170748710632, 0.9578811526298523, 0.9684754610061646, 0.9733850359916687, 0.9764857888221741, 0.97260981798172, 0.9666666388511658, 0.9739018082618713, 0.9733850359916687, 0.9720930457115173, 0.9645994901657104, 0.9757105708122253, 0.9718345999717712, 0.9772610068321228, 0.9720930457115173, 0.9780361652374268], 'val_loss': [1.2708770036697388, 1.2673771381378174, 1.2636375427246094, 1.2593179941177368, 1.252905249595642, 1.2453268766403198, 1.2191849946975708, 1.2071374654769897, 1.1673686504364014, 1.1699278354644775, 1.1191686391830444, 1.0934048891067505, 1.0522717237472534, 1.0179383754730225, 0.9821228384971619, 0.9647799134254456, 0.9299806356430054, 0.9164754152297974, 0.9121715426445007, 0.8657454252243042, 0.8627998232841492, 0.8570193648338318, 0.8456166982650757, 0.8431668281555176, 0.8683329224586487, 0.8728845119476318, 0.8384551405906677, 0.8376185297966003, 0.8501585125923157, 0.8432369828224182, 0.8344883322715759, 0.847745418548584, 0.8423471450805664, 0.8407337665557861, 0.8489798307418823, 0.8572119474411011, 0.8259272575378418, 0.8275789022445679, 0.8394365310668945, 0.8257665038108826, 0.8276976346969604, 0.8263224959373474, 0.8243643641471863, 0.8232659697532654, 0.8228577971458435, 0.8311657905578613, 0.8445460796356201, 0.8435705900192261, 0.8149700164794922, 0.8154662847518921, 0.8159386515617371, 0.8171801567077637, 0.816474437713623, 0.8491910696029663, 0.8171253800392151, 0.8705333471298218, 0.8105863332748413, 0.819103479385376, 0.8117883801460266, 0.8123001456260681, 0.8067029118537903, 0.8265043497085571, 0.8105701804161072, 0.8078630566596985, 0.8069121837615967, 0.8063980340957642, 0.8163154721260071, 0.8317313194274902, 0.8060329556465149, 0.8087517619132996, 0.8105461001396179, 0.8281192183494568, 0.8063822388648987, 0.8081780076026917, 0.8030826449394226, 0.8258379101753235, 0.814735472202301, 0.8179975748062134, 0.803752601146698, 0.8060086965560913, 0.8079149127006531, 0.8064911365509033, 0.8080792427062988, 0.8081645965576172, 0.8488277196884155, 0.8439383506774902, 0.8283901810646057, 0.8072226047515869, 0.8090581297874451, 0.8285687565803528, 0.8844828605651855, 0.8076232671737671, 0.8390804529190063, 0.8860501646995544, 0.8473594784736633, 0.8113695383071899, 0.8153262734413147, 0.8073699474334717, 0.8121620416641235, 0.8142566680908203], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.5247933864593506, 0.5072314143180847, 0.6043388247489929, 0.6735537052154541, 0.7613636255264282, 0.8037189841270447, 0.8316115736961365, 0.8285123705863953, 0.8502066135406494, 0.8388429880142212, 0.8285123705863953, 0.85537189245224, 0.8574380278587341, 0.8533057570457458, 0.8564049601554871, 0.8574380278587341, 0.8419421315193176, 0.8419421315193176, 0.8605371713638306, 0.8626033067703247, 0.8491735458374023, 0.8605371713638306, 0.8615702390670776, 0.8522727489471436, 0.8502066135406494, 0.8502066135406494, 0.8502066135406494, 0.8502066135406494, 0.8584710955619812, 0.8564049601554871, 0.8522727489471436, 0.8595041036605835, 0.85537189245224, 0.85537189245224, 0.8574380278587341, 0.8584710955619812, 0.8564049601554871, 0.8543388247489929, 0.8450413346290588, 0.8450413346290588, 0.8564049601554871, 0.8605371713638306, 0.8595041036605835, 0.8605371713638306, 0.8605371713638306, 0.8481404781341553, 0.8522727489471436, 0.8336777091026306, 0.8595041036605835, 0.8522727489471436, 0.8522727489471436, 0.8605371713638306, 0.8574380278587341, 0.8533057570457458, 0.8564049601554871, 0.8574380278587341, 0.8595041036605835, 0.8564049601554871, 0.8491735458374023, 0.8388429880142212, 0.8584710955619812, 0.8595041036605835, 0.8605371713638306, 0.8440082669258118, 0.8584710955619812, 0.8512396812438965, 0.8574380278587341, 0.8522727489471436, 0.8533057570457458, 0.85537189245224, 0.8615702390670776, 0.8543388247489929, 0.85537189245224, 0.8595041036605835, 0.8595041036605835, 0.8595041036605835, 0.8378099203109741, 0.8409090638160706, 0.85537189245224, 0.8657024502754211, 0.8574380278587341, 0.8543388247489929, 0.8398760557174683, 0.85537189245224, 0.8533057570457458, 0.8440082669258118, 0.8522727489471436, 0.8564049601554871, 0.8595041036605835, 0.8626033067703247, 0.8584710955619812, 0.8615702390670776]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.5394 - accuracy: 0.9386"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 8s 60ms/step - loss: 0.5394 - accuracy: 0.9386 - val_loss: 1.1204 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5179 - accuracy: 0.9488 - val_loss: 1.1170 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5160 - accuracy: 0.9488 - val_loss: 1.1165 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5200 - accuracy: 0.9456 - val_loss: 1.1114 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5049 - accuracy: 0.9518 - val_loss: 1.1079 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4977 - accuracy: 0.9547 - val_loss: 1.1008 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5040 - accuracy: 0.9488 - val_loss: 1.1023 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4933 - accuracy: 0.9534 - val_loss: 1.0816 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4884 - accuracy: 0.9596 - val_loss: 1.0814 - val_accuracy: 0.4860\n","Epoch 10/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4830 - accuracy: 0.9604 - val_loss: 1.0574 - val_accuracy: 0.4989\n","Epoch 11/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.4717 - accuracy: 0.9655 - val_loss: 0.9968 - val_accuracy: 0.5388\n","Epoch 12/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.4649 - accuracy: 0.9690 - val_loss: 0.9474 - val_accuracy: 0.5873\n","Epoch 13/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.4660 - accuracy: 0.9647 - val_loss: 0.9238 - val_accuracy: 0.6121\n","Epoch 14/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.4705 - accuracy: 0.9617 - val_loss: 0.8832 - val_accuracy: 0.6606\n","Epoch 15/100\n","29/29 [==============================] - 1s 35ms/step - loss: 0.4550 - accuracy: 0.9725 - val_loss: 0.7936 - val_accuracy: 0.7780\n","Epoch 16/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.4664 - accuracy: 0.9617 - val_loss: 0.6930 - val_accuracy: 0.9052\n","Epoch 17/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4624 - accuracy: 0.9674 - val_loss: 0.7563 - val_accuracy: 0.8114\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4530 - accuracy: 0.9682 - val_loss: 0.7454 - val_accuracy: 0.8179\n","Epoch 19/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4530 - accuracy: 0.9712 - val_loss: 0.6589 - val_accuracy: 0.8825\n","Epoch 20/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4445 - accuracy: 0.9712 - val_loss: 0.6155 - val_accuracy: 0.9106\n","Epoch 21/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4422 - accuracy: 0.9720 - val_loss: 0.6251 - val_accuracy: 0.8912\n","Epoch 22/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4481 - accuracy: 0.9688 - val_loss: 0.5861 - val_accuracy: 0.9192\n","Epoch 23/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4384 - accuracy: 0.9736 - val_loss: 0.5788 - val_accuracy: 0.9170\n","Epoch 24/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4284 - accuracy: 0.9760 - val_loss: 0.5840 - val_accuracy: 0.9127\n","Epoch 25/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4359 - accuracy: 0.9714 - val_loss: 0.5770 - val_accuracy: 0.9106\n","Epoch 26/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4364 - accuracy: 0.9728 - val_loss: 0.5876 - val_accuracy: 0.9116\n","Epoch 27/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4372 - accuracy: 0.9717 - val_loss: 0.6403 - val_accuracy: 0.8912\n","Epoch 28/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4286 - accuracy: 0.9741 - val_loss: 0.5902 - val_accuracy: 0.9127\n","Epoch 29/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4261 - accuracy: 0.9768 - val_loss: 0.5797 - val_accuracy: 0.9138\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4179 - accuracy: 0.9795 - val_loss: 0.5842 - val_accuracy: 0.9127\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4183 - accuracy: 0.9790 - val_loss: 0.6016 - val_accuracy: 0.9106\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4169 - accuracy: 0.9782 - val_loss: 0.6202 - val_accuracy: 0.9009\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4166 - accuracy: 0.9763 - val_loss: 0.6507 - val_accuracy: 0.8976\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4153 - accuracy: 0.9744 - val_loss: 0.5866 - val_accuracy: 0.9149\n","Epoch 35/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4045 - accuracy: 0.9825 - val_loss: 0.5914 - val_accuracy: 0.9149\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4061 - accuracy: 0.9793 - val_loss: 0.5921 - val_accuracy: 0.9116\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4052 - accuracy: 0.9798 - val_loss: 0.6065 - val_accuracy: 0.9052\n","Epoch 38/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.4011 - accuracy: 0.9820 - val_loss: 0.5929 - val_accuracy: 0.9149\n","Epoch 39/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4022 - accuracy: 0.9803 - val_loss: 0.5982 - val_accuracy: 0.9127\n","Epoch 40/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3963 - accuracy: 0.9822 - val_loss: 0.6236 - val_accuracy: 0.8998\n","Epoch 41/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3966 - accuracy: 0.9830 - val_loss: 0.6056 - val_accuracy: 0.9095\n","Epoch 42/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3924 - accuracy: 0.9828 - val_loss: 0.5997 - val_accuracy: 0.9095\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3888 - accuracy: 0.9863 - val_loss: 0.6141 - val_accuracy: 0.9041\n","Epoch 44/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3900 - accuracy: 0.9846 - val_loss: 0.6076 - val_accuracy: 0.9041\n","Epoch 45/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4008 - accuracy: 0.9795 - val_loss: 0.7568 - val_accuracy: 0.8653\n","Epoch 46/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3975 - accuracy: 0.9782 - val_loss: 0.6952 - val_accuracy: 0.8836\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3903 - accuracy: 0.9814 - val_loss: 0.6080 - val_accuracy: 0.9041\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3826 - accuracy: 0.9830 - val_loss: 0.6259 - val_accuracy: 0.8998\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3778 - accuracy: 0.9876 - val_loss: 0.6154 - val_accuracy: 0.9062\n","Epoch 50/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3744 - accuracy: 0.9884 - val_loss: 0.6201 - val_accuracy: 0.9030\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3722 - accuracy: 0.9898 - val_loss: 0.6060 - val_accuracy: 0.9116\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3799 - accuracy: 0.9860 - val_loss: 0.6836 - val_accuracy: 0.8815\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3718 - accuracy: 0.9868 - val_loss: 0.6234 - val_accuracy: 0.9019\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3701 - accuracy: 0.9881 - val_loss: 0.6085 - val_accuracy: 0.9095\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3899 - accuracy: 0.9776 - val_loss: 0.6225 - val_accuracy: 0.9073\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3866 - accuracy: 0.9776 - val_loss: 0.6099 - val_accuracy: 0.9019\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3696 - accuracy: 0.9868 - val_loss: 0.5999 - val_accuracy: 0.9116\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3670 - accuracy: 0.9881 - val_loss: 0.6099 - val_accuracy: 0.9084\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3665 - accuracy: 0.9884 - val_loss: 0.6086 - val_accuracy: 0.9116\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3640 - accuracy: 0.9890 - val_loss: 0.6266 - val_accuracy: 0.8987\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3603 - accuracy: 0.9898 - val_loss: 0.6150 - val_accuracy: 0.8998\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3567 - accuracy: 0.9900 - val_loss: 0.6871 - val_accuracy: 0.8815\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3644 - accuracy: 0.9863 - val_loss: 0.6376 - val_accuracy: 0.9052\n","Epoch 64/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3513 - accuracy: 0.9911 - val_loss: 0.6352 - val_accuracy: 0.9041\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3575 - accuracy: 0.9860 - val_loss: 0.6191 - val_accuracy: 0.9052\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3622 - accuracy: 0.9838 - val_loss: 0.8780 - val_accuracy: 0.8459\n","Epoch 67/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3736 - accuracy: 0.9793 - val_loss: 0.6220 - val_accuracy: 0.9019\n","Epoch 68/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3515 - accuracy: 0.9900 - val_loss: 0.6125 - val_accuracy: 0.9073\n","Epoch 69/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3473 - accuracy: 0.9906 - val_loss: 0.6388 - val_accuracy: 0.8976\n","Epoch 70/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3435 - accuracy: 0.9925 - val_loss: 0.6332 - val_accuracy: 0.9019\n","Epoch 71/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3461 - accuracy: 0.9908 - val_loss: 0.6210 - val_accuracy: 0.9052\n","Epoch 72/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3436 - accuracy: 0.9925 - val_loss: 0.6267 - val_accuracy: 0.9052\n","Epoch 73/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3458 - accuracy: 0.9908 - val_loss: 0.6334 - val_accuracy: 0.9030\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3426 - accuracy: 0.9914 - val_loss: 0.6170 - val_accuracy: 0.9073\n","Epoch 75/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3429 - accuracy: 0.9911 - val_loss: 0.6552 - val_accuracy: 0.8933\n","Epoch 76/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3452 - accuracy: 0.9890 - val_loss: 0.6428 - val_accuracy: 0.8998\n","Epoch 77/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3346 - accuracy: 0.9927 - val_loss: 0.6301 - val_accuracy: 0.9009\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3324 - accuracy: 0.9933 - val_loss: 0.6309 - val_accuracy: 0.9009\n","Epoch 79/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3391 - accuracy: 0.9914 - val_loss: 0.6449 - val_accuracy: 0.9106\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3409 - accuracy: 0.9898 - val_loss: 0.6282 - val_accuracy: 0.9030\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3320 - accuracy: 0.9930 - val_loss: 0.6227 - val_accuracy: 0.9009\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3399 - accuracy: 0.9898 - val_loss: 0.6290 - val_accuracy: 0.9095\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3299 - accuracy: 0.9922 - val_loss: 0.6677 - val_accuracy: 0.8976\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3379 - accuracy: 0.9892 - val_loss: 0.6447 - val_accuracy: 0.9030\n","Epoch 85/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3337 - accuracy: 0.9908 - val_loss: 0.6317 - val_accuracy: 0.9052\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3233 - accuracy: 0.9946 - val_loss: 0.6249 - val_accuracy: 0.9052\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3279 - accuracy: 0.9922 - val_loss: 0.6464 - val_accuracy: 0.8987\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3228 - accuracy: 0.9933 - val_loss: 0.6292 - val_accuracy: 0.9062\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3210 - accuracy: 0.9943 - val_loss: 0.6347 - val_accuracy: 0.8976\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3253 - accuracy: 0.9908 - val_loss: 0.6288 - val_accuracy: 0.9084\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3241 - accuracy: 0.9908 - val_loss: 0.6527 - val_accuracy: 0.8955\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3197 - accuracy: 0.9960 - val_loss: 0.6817 - val_accuracy: 0.8922\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3258 - accuracy: 0.9914 - val_loss: 0.6793 - val_accuracy: 0.8944\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3172 - accuracy: 0.9941 - val_loss: 0.6309 - val_accuracy: 0.9041\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3155 - accuracy: 0.9946 - val_loss: 0.6222 - val_accuracy: 0.9106\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3146 - accuracy: 0.9938 - val_loss: 0.6690 - val_accuracy: 0.8987\n","Epoch 97/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3172 - accuracy: 0.9927 - val_loss: 0.6257 - val_accuracy: 0.9052\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3125 - accuracy: 0.9943 - val_loss: 0.6277 - val_accuracy: 0.9073\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3120 - accuracy: 0.9943 - val_loss: 0.6427 - val_accuracy: 0.8998\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3105 - accuracy: 0.9943 - val_loss: 0.6527 - val_accuracy: 0.9041\n","{'loss': [0.5393593311309814, 0.5179431438446045, 0.5159550309181213, 0.5200396776199341, 0.5049071907997131, 0.49766626954078674, 0.5039817690849304, 0.49327948689460754, 0.4883576035499573, 0.48296791315078735, 0.4716959595680237, 0.464900404214859, 0.46601593494415283, 0.4705004394054413, 0.45500701665878296, 0.4664490818977356, 0.46243956685066223, 0.45295950770378113, 0.4529632031917572, 0.4445299506187439, 0.44224613904953003, 0.44808074831962585, 0.43835869431495667, 0.4284094572067261, 0.43587741255760193, 0.4363502264022827, 0.4372323155403137, 0.4285999536514282, 0.4261402487754822, 0.4179358184337616, 0.4182530641555786, 0.416947603225708, 0.41658464074134827, 0.4152980148792267, 0.40445655584335327, 0.40606606006622314, 0.40518125891685486, 0.40113961696624756, 0.4021979570388794, 0.396250456571579, 0.3965556025505066, 0.3923652172088623, 0.3888476490974426, 0.39002731442451477, 0.4007504880428314, 0.39745548367500305, 0.39030835032463074, 0.38261500000953674, 0.37784332036972046, 0.37437623739242554, 0.37219807505607605, 0.3799424469470978, 0.3718285858631134, 0.37012165784835815, 0.3898523449897766, 0.38655728101730347, 0.36963629722595215, 0.36699771881103516, 0.36651259660720825, 0.3639552891254425, 0.3603289723396301, 0.35673779249191284, 0.3643952012062073, 0.35126787424087524, 0.35754361748695374, 0.3622421622276306, 0.3736479580402374, 0.35146263241767883, 0.34730663895606995, 0.34352871775627136, 0.34613245725631714, 0.34361040592193604, 0.3457542359828949, 0.3425837755203247, 0.34285005927085876, 0.3451642096042633, 0.3345693349838257, 0.33239707350730896, 0.3390941917896271, 0.34093940258026123, 0.33201542496681213, 0.33989864587783813, 0.32986903190612793, 0.33793774247169495, 0.333671510219574, 0.3233066499233246, 0.3278666138648987, 0.3227721154689789, 0.3210376501083374, 0.32525435090065, 0.3240613341331482, 0.31968122720718384, 0.32575684785842896, 0.3171589970588684, 0.3155389428138733, 0.3145919442176819, 0.31724268198013306, 0.3125419616699219, 0.31202876567840576, 0.31049391627311707], 'accuracy': [0.9385775923728943, 0.9488146305084229, 0.9488146305084229, 0.9455819129943848, 0.951777994632721, 0.954741358757019, 0.9488146305084229, 0.9533944129943848, 0.959590494632721, 0.9603987336158752, 0.9655172228813171, 0.9690194129943848, 0.9647090435028076, 0.9617456793785095, 0.9725215435028076, 0.9617456793785095, 0.967402994632721, 0.9682112336158752, 0.9711745977401733, 0.9711745977401733, 0.9719827771186829, 0.96875, 0.9735991358757019, 0.9760237336158752, 0.9714439511299133, 0.9727909564971924, 0.9717133641242981, 0.9741379022598267, 0.9768319129943848, 0.9795258641242981, 0.9789870977401733, 0.978178858757019, 0.9762930870056152, 0.9744073152542114, 0.9824892282485962, 0.9792564511299133, 0.9797952771186829, 0.9819504022598267, 0.9803340435028076, 0.9822198152542114, 0.983027994632721, 0.982758641242981, 0.9862607717514038, 0.9846444129943848, 0.9795258641242981, 0.978178858757019, 0.9814116358757019, 0.983027994632721, 0.9876077771186829, 0.9884159564971924, 0.9897629022598267, 0.985991358757019, 0.9867995977401733, 0.9881465435028076, 0.9776400923728943, 0.9776400923728943, 0.9867995977401733, 0.9881465435028076, 0.9884159564971924, 0.9889547228813171, 0.9897629022598267, 0.9900323152542114, 0.9862607717514038, 0.9911099076271057, 0.985991358757019, 0.9838362336158752, 0.9792564511299133, 0.9900323152542114, 0.990571141242981, 0.9924569129943848, 0.990840494632721, 0.9924569129943848, 0.990840494632721, 0.9913793206214905, 0.9911099076271057, 0.9889547228813171, 0.9927262663841248, 0.9932650923728943, 0.9913793206214905, 0.9897629022598267, 0.9929956793785095, 0.9897629022598267, 0.9921875, 0.9892241358757019, 0.990840494632721, 0.9946120977401733, 0.9921875, 0.9932650923728943, 0.9943426847457886, 0.990840494632721, 0.990840494632721, 0.9959590435028076, 0.9913793206214905, 0.9940732717514038, 0.9946120977401733, 0.993803858757019, 0.9927262663841248, 0.9943426847457886, 0.9943426847457886, 0.9943426847457886], 'val_loss': [1.1204068660736084, 1.1169590950012207, 1.1164799928665161, 1.111388921737671, 1.1078907251358032, 1.1007510423660278, 1.1022557020187378, 1.0815646648406982, 1.0813682079315186, 1.0573594570159912, 0.9968002438545227, 0.947404146194458, 0.923751175403595, 0.883213222026825, 0.7935709357261658, 0.6929867267608643, 0.7562966346740723, 0.7453534603118896, 0.6588588356971741, 0.6154919266700745, 0.6250828504562378, 0.5860956311225891, 0.5787572264671326, 0.5840064883232117, 0.577046275138855, 0.5876449346542358, 0.6402749419212341, 0.590210497379303, 0.5796801447868347, 0.5842492580413818, 0.6015933752059937, 0.6202316880226135, 0.650726854801178, 0.5865516066551208, 0.591383695602417, 0.5920888185501099, 0.6065341234207153, 0.592898428440094, 0.5982413291931152, 0.6235736608505249, 0.6055793166160583, 0.5996510982513428, 0.6140685081481934, 0.6076468229293823, 0.756802499294281, 0.6952193975448608, 0.6080136895179749, 0.6258872747421265, 0.615435779094696, 0.620098888874054, 0.6060431003570557, 0.6835551857948303, 0.6234033703804016, 0.6085473299026489, 0.6224700212478638, 0.609866738319397, 0.5998992919921875, 0.6098626852035522, 0.6086317300796509, 0.6266248226165771, 0.6150003671646118, 0.6870667934417725, 0.637593686580658, 0.6352189183235168, 0.6190884113311768, 0.8779988884925842, 0.6220414638519287, 0.6125074028968811, 0.6387616991996765, 0.6332489252090454, 0.6209596395492554, 0.6266756653785706, 0.6333940625190735, 0.6169859170913696, 0.6552491784095764, 0.6427667140960693, 0.6300761699676514, 0.6309137940406799, 0.644852876663208, 0.6282423138618469, 0.622661828994751, 0.6290373802185059, 0.667740523815155, 0.6446770429611206, 0.631715714931488, 0.6249446868896484, 0.6464151740074158, 0.6291900873184204, 0.6347444653511047, 0.6288492679595947, 0.6527493000030518, 0.6816709041595459, 0.6792600154876709, 0.6308842301368713, 0.6222449541091919, 0.6689531207084656, 0.6256973743438721, 0.6277400851249695, 0.6426532864570618, 0.6527453660964966], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48599138855934143, 0.4989224076271057, 0.5387930870056152, 0.587284505367279, 0.6120689511299133, 0.6605603694915771, 0.7780172228813171, 0.9051724076271057, 0.8114224076271057, 0.8178879022598267, 0.8825430870056152, 0.9105603694915771, 0.8911637663841248, 0.9191810488700867, 0.9170258641242981, 0.912715494632721, 0.9105603694915771, 0.9116379022598267, 0.8911637663841248, 0.912715494632721, 0.9137930870056152, 0.912715494632721, 0.9105603694915771, 0.9008620977401733, 0.8976293206214905, 0.9148706793785095, 0.9148706793785095, 0.9116379022598267, 0.9051724076271057, 0.9148706793785095, 0.912715494632721, 0.899784505367279, 0.9094827771186829, 0.9094827771186829, 0.9040948152542114, 0.9040948152542114, 0.8653017282485962, 0.8836206793785095, 0.9040948152542114, 0.899784505367279, 0.90625, 0.9030172228813171, 0.9116379022598267, 0.881465494632721, 0.9019396305084229, 0.9094827771186829, 0.9073275923728943, 0.9019396305084229, 0.9116379022598267, 0.9084051847457886, 0.9116379022598267, 0.8987069129943848, 0.899784505367279, 0.881465494632721, 0.9051724076271057, 0.9040948152542114, 0.9051724076271057, 0.8459051847457886, 0.9019396305084229, 0.9073275923728943, 0.8976293206214905, 0.9019396305084229, 0.9051724076271057, 0.9051724076271057, 0.9030172228813171, 0.9073275923728943, 0.8933189511299133, 0.899784505367279, 0.9008620977401733, 0.9008620977401733, 0.9105603694915771, 0.9030172228813171, 0.9008620977401733, 0.9094827771186829, 0.8976293206214905, 0.9030172228813171, 0.9051724076271057, 0.9051724076271057, 0.8987069129943848, 0.90625, 0.8976293206214905, 0.9084051847457886, 0.8954741358757019, 0.892241358757019, 0.8943965435028076, 0.9040948152542114, 0.9105603694915771, 0.8987069129943848, 0.9051724076271057, 0.9073275923728943, 0.899784505367279, 0.9040948152542114]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.5400 - accuracy: 0.9403"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 72ms/step - loss: 0.5400 - accuracy: 0.9403 - val_loss: 1.1154 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5173 - accuracy: 0.9505 - val_loss: 1.1119 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5163 - accuracy: 0.9508 - val_loss: 1.1127 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5066 - accuracy: 0.9539 - val_loss: 1.1070 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5003 - accuracy: 0.9570 - val_loss: 1.1020 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4985 - accuracy: 0.9530 - val_loss: 1.1019 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4940 - accuracy: 0.9559 - val_loss: 1.0991 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.4956 - accuracy: 0.9544 - val_loss: 1.0798 - val_accuracy: 0.4977\n","Epoch 9/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4990 - accuracy: 0.9496 - val_loss: 1.0699 - val_accuracy: 0.4977\n","Epoch 10/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4843 - accuracy: 0.9621 - val_loss: 1.0546 - val_accuracy: 0.5090\n","Epoch 11/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4748 - accuracy: 0.9629 - val_loss: 1.0278 - val_accuracy: 0.5249\n","Epoch 12/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4708 - accuracy: 0.9641 - val_loss: 0.9941 - val_accuracy: 0.5486\n","Epoch 13/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.4722 - accuracy: 0.9624 - val_loss: 0.9478 - val_accuracy: 0.5995\n","Epoch 14/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4724 - accuracy: 0.9643 - val_loss: 0.9585 - val_accuracy: 0.5928\n","Epoch 15/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4816 - accuracy: 0.9547 - val_loss: 0.8342 - val_accuracy: 0.7534\n","Epoch 16/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4585 - accuracy: 0.9663 - val_loss: 0.7907 - val_accuracy: 0.7986\n","Epoch 17/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4517 - accuracy: 0.9714 - val_loss: 0.7311 - val_accuracy: 0.8473\n","Epoch 18/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4500 - accuracy: 0.9723 - val_loss: 0.7224 - val_accuracy: 0.8405\n","Epoch 19/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4563 - accuracy: 0.9672 - val_loss: 0.6982 - val_accuracy: 0.8541\n","Epoch 20/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4471 - accuracy: 0.9706 - val_loss: 0.6651 - val_accuracy: 0.8676\n","Epoch 21/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4430 - accuracy: 0.9726 - val_loss: 0.6254 - val_accuracy: 0.8914\n","Epoch 22/100\n","28/28 [==============================] - 1s 17ms/step - loss: 0.4451 - accuracy: 0.9717 - val_loss: 0.6143 - val_accuracy: 0.8914\n","Epoch 23/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4443 - accuracy: 0.9694 - val_loss: 0.6553 - val_accuracy: 0.8699\n","Epoch 24/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4332 - accuracy: 0.9748 - val_loss: 0.6201 - val_accuracy: 0.8778\n","Epoch 25/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4458 - accuracy: 0.9709 - val_loss: 0.7033 - val_accuracy: 0.8552\n","Epoch 26/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4664 - accuracy: 0.9573 - val_loss: 0.7156 - val_accuracy: 0.8529\n","Epoch 27/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4422 - accuracy: 0.9672 - val_loss: 0.6319 - val_accuracy: 0.8790\n","Epoch 28/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4355 - accuracy: 0.9709 - val_loss: 0.6181 - val_accuracy: 0.8869\n","Epoch 29/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4249 - accuracy: 0.9771 - val_loss: 0.6298 - val_accuracy: 0.8824\n","Epoch 30/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4224 - accuracy: 0.9799 - val_loss: 0.6214 - val_accuracy: 0.8880\n","Epoch 31/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4222 - accuracy: 0.9776 - val_loss: 0.6482 - val_accuracy: 0.8801\n","Epoch 32/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4215 - accuracy: 0.9737 - val_loss: 0.6390 - val_accuracy: 0.8869\n","Epoch 33/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4172 - accuracy: 0.9799 - val_loss: 0.6783 - val_accuracy: 0.8790\n","Epoch 34/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4358 - accuracy: 0.9660 - val_loss: 0.6665 - val_accuracy: 0.8778\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4130 - accuracy: 0.9782 - val_loss: 0.6499 - val_accuracy: 0.8790\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4051 - accuracy: 0.9833 - val_loss: 0.6436 - val_accuracy: 0.8846\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4055 - accuracy: 0.9808 - val_loss: 0.6411 - val_accuracy: 0.8846\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4060 - accuracy: 0.9816 - val_loss: 0.6426 - val_accuracy: 0.8857\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4031 - accuracy: 0.9822 - val_loss: 0.6482 - val_accuracy: 0.8835\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4039 - accuracy: 0.9791 - val_loss: 0.6579 - val_accuracy: 0.8790\n","Epoch 41/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3963 - accuracy: 0.9842 - val_loss: 0.6495 - val_accuracy: 0.8812\n","Epoch 42/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4000 - accuracy: 0.9825 - val_loss: 0.6679 - val_accuracy: 0.8801\n","Epoch 43/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3929 - accuracy: 0.9856 - val_loss: 0.7124 - val_accuracy: 0.8767\n","Epoch 44/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3971 - accuracy: 0.9822 - val_loss: 0.6578 - val_accuracy: 0.8790\n","Epoch 45/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3927 - accuracy: 0.9822 - val_loss: 0.6809 - val_accuracy: 0.8778\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3881 - accuracy: 0.9861 - val_loss: 0.6905 - val_accuracy: 0.8722\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3963 - accuracy: 0.9793 - val_loss: 0.6538 - val_accuracy: 0.8824\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3877 - accuracy: 0.9844 - val_loss: 0.6566 - val_accuracy: 0.8790\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3867 - accuracy: 0.9853 - val_loss: 0.7321 - val_accuracy: 0.8722\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3807 - accuracy: 0.9873 - val_loss: 0.6684 - val_accuracy: 0.8767\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3841 - accuracy: 0.9847 - val_loss: 0.6575 - val_accuracy: 0.8790\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3782 - accuracy: 0.9859 - val_loss: 0.6600 - val_accuracy: 0.8756\n","Epoch 53/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3782 - accuracy: 0.9859 - val_loss: 0.6592 - val_accuracy: 0.8812\n","Epoch 54/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3736 - accuracy: 0.9892 - val_loss: 0.6621 - val_accuracy: 0.8710\n","Epoch 55/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3695 - accuracy: 0.9887 - val_loss: 0.6720 - val_accuracy: 0.8812\n","Epoch 56/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3710 - accuracy: 0.9884 - val_loss: 0.6714 - val_accuracy: 0.8790\n","Epoch 57/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3757 - accuracy: 0.9842 - val_loss: 0.6642 - val_accuracy: 0.8767\n","Epoch 58/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3642 - accuracy: 0.9895 - val_loss: 0.6632 - val_accuracy: 0.8812\n","Epoch 59/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3660 - accuracy: 0.9887 - val_loss: 0.6695 - val_accuracy: 0.8846\n","Epoch 60/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3720 - accuracy: 0.9864 - val_loss: 0.6984 - val_accuracy: 0.8812\n","Epoch 61/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3745 - accuracy: 0.9844 - val_loss: 0.6657 - val_accuracy: 0.8778\n","Epoch 62/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3628 - accuracy: 0.9870 - val_loss: 0.6652 - val_accuracy: 0.8812\n","Epoch 63/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3691 - accuracy: 0.9847 - val_loss: 0.6893 - val_accuracy: 0.8722\n","Epoch 64/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3596 - accuracy: 0.9898 - val_loss: 0.6751 - val_accuracy: 0.8756\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3610 - accuracy: 0.9878 - val_loss: 0.6860 - val_accuracy: 0.8824\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3516 - accuracy: 0.9924 - val_loss: 0.6759 - val_accuracy: 0.8722\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3530 - accuracy: 0.9907 - val_loss: 0.6729 - val_accuracy: 0.8767\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3489 - accuracy: 0.9918 - val_loss: 0.6878 - val_accuracy: 0.8722\n","Epoch 69/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3501 - accuracy: 0.9904 - val_loss: 0.6865 - val_accuracy: 0.8733\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3487 - accuracy: 0.9901 - val_loss: 0.6856 - val_accuracy: 0.8722\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3531 - accuracy: 0.9878 - val_loss: 0.6784 - val_accuracy: 0.8722\n","Epoch 72/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3611 - accuracy: 0.9844 - val_loss: 0.7240 - val_accuracy: 0.8778\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3466 - accuracy: 0.9907 - val_loss: 0.6775 - val_accuracy: 0.8767\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3452 - accuracy: 0.9898 - val_loss: 0.6861 - val_accuracy: 0.8767\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3542 - accuracy: 0.9856 - val_loss: 0.6922 - val_accuracy: 0.8835\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3451 - accuracy: 0.9907 - val_loss: 0.6822 - val_accuracy: 0.8676\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3454 - accuracy: 0.9892 - val_loss: 0.6907 - val_accuracy: 0.8688\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3393 - accuracy: 0.9932 - val_loss: 0.6835 - val_accuracy: 0.8710\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3356 - accuracy: 0.9946 - val_loss: 0.6870 - val_accuracy: 0.8710\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3348 - accuracy: 0.9932 - val_loss: 0.6866 - val_accuracy: 0.8733\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3398 - accuracy: 0.9907 - val_loss: 0.7015 - val_accuracy: 0.8767\n","Epoch 82/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3379 - accuracy: 0.9898 - val_loss: 0.7290 - val_accuracy: 0.8835\n","Epoch 83/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3632 - accuracy: 0.9774 - val_loss: 0.8704 - val_accuracy: 0.8507\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3466 - accuracy: 0.9844 - val_loss: 0.6930 - val_accuracy: 0.8756\n","Epoch 85/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3321 - accuracy: 0.9918 - val_loss: 0.7235 - val_accuracy: 0.8710\n","Epoch 86/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3302 - accuracy: 0.9926 - val_loss: 0.6921 - val_accuracy: 0.8688\n","Epoch 87/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3258 - accuracy: 0.9949 - val_loss: 0.7055 - val_accuracy: 0.8676\n","Epoch 88/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3287 - accuracy: 0.9915 - val_loss: 0.7155 - val_accuracy: 0.8733\n","Epoch 89/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3268 - accuracy: 0.9935 - val_loss: 0.6946 - val_accuracy: 0.8665\n","Epoch 90/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3251 - accuracy: 0.9929 - val_loss: 0.6981 - val_accuracy: 0.8733\n","Epoch 91/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3256 - accuracy: 0.9912 - val_loss: 0.7046 - val_accuracy: 0.8801\n","Epoch 92/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3226 - accuracy: 0.9932 - val_loss: 0.6935 - val_accuracy: 0.8710\n","Epoch 93/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.3211 - accuracy: 0.9926 - val_loss: 0.7434 - val_accuracy: 0.8665\n","Epoch 94/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3327 - accuracy: 0.9890 - val_loss: 0.7177 - val_accuracy: 0.8778\n","Epoch 95/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3220 - accuracy: 0.9924 - val_loss: 0.7109 - val_accuracy: 0.8688\n","Epoch 96/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3187 - accuracy: 0.9932 - val_loss: 0.6999 - val_accuracy: 0.8710\n","Epoch 97/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3233 - accuracy: 0.9915 - val_loss: 0.6960 - val_accuracy: 0.8744\n","Epoch 98/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3170 - accuracy: 0.9943 - val_loss: 0.6996 - val_accuracy: 0.8756\n","Epoch 99/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3127 - accuracy: 0.9935 - val_loss: 0.7038 - val_accuracy: 0.8688\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3113 - accuracy: 0.9949 - val_loss: 0.7471 - val_accuracy: 0.8812\n","{'loss': [0.5399928689002991, 0.5172563791275024, 0.5162572264671326, 0.5066075921058655, 0.50025874376297, 0.49845877289772034, 0.494020938873291, 0.4956006705760956, 0.49896910786628723, 0.48426082730293274, 0.4747543931007385, 0.47077834606170654, 0.47220489382743835, 0.47236019372940063, 0.48162707686424255, 0.4584629535675049, 0.4516914188861847, 0.4499746859073639, 0.4563280940055847, 0.44706833362579346, 0.44304919242858887, 0.44506531953811646, 0.4442586898803711, 0.4331938624382019, 0.44578978419303894, 0.46644726395606995, 0.44215133786201477, 0.4354671537876129, 0.4248984456062317, 0.4223979711532593, 0.42223164439201355, 0.421465128660202, 0.4171808063983917, 0.4358244836330414, 0.41301560401916504, 0.40507569909095764, 0.4054853618144989, 0.4059709310531616, 0.40305230021476746, 0.403857558965683, 0.3963228464126587, 0.4000261723995209, 0.39291951060295105, 0.39709869027137756, 0.39272207021713257, 0.38806799054145813, 0.39625024795532227, 0.38773372769355774, 0.3866581320762634, 0.38070011138916016, 0.3841373920440674, 0.37818455696105957, 0.37823712825775146, 0.37356036901474, 0.36948058009147644, 0.3709859251976013, 0.3756844699382782, 0.3641672134399414, 0.3659844696521759, 0.3719959557056427, 0.37454065680503845, 0.36284250020980835, 0.36906999349594116, 0.3595581352710724, 0.3610130250453949, 0.35162854194641113, 0.3530493378639221, 0.3489232063293457, 0.3500513434410095, 0.34871530532836914, 0.3531459867954254, 0.3610914349555969, 0.3466283679008484, 0.34524741768836975, 0.35415828227996826, 0.3451307713985443, 0.3453868329524994, 0.3393457531929016, 0.3355921804904938, 0.33481642603874207, 0.3397912383079529, 0.33785563707351685, 0.36315280199050903, 0.34656864404678345, 0.3321317732334137, 0.33018189668655396, 0.32579025626182556, 0.32874441146850586, 0.3268451988697052, 0.3250509202480316, 0.32555311918258667, 0.3225540816783905, 0.32105115056037903, 0.3327019512653351, 0.321975439786911, 0.3186778128147125, 0.32329002022743225, 0.31695085763931274, 0.31266045570373535, 0.3112659752368927], 'accuracy': [0.9402942657470703, 0.9504810571670532, 0.950764000415802, 0.9538766145706177, 0.9569892287254333, 0.9530277252197266, 0.9558573961257935, 0.95444256067276, 0.9496321678161621, 0.9620826244354248, 0.9629315137863159, 0.9640634059906006, 0.9623655676841736, 0.9643463492393494, 0.9547255039215088, 0.9663271307945251, 0.9714204668998718, 0.9722693562507629, 0.9671760201454163, 0.9705715775489807, 0.9725523591041565, 0.9717034697532654, 0.9694397449493408, 0.974816083908081, 0.9708545804023743, 0.9572722315788269, 0.9671760201454163, 0.9708545804023743, 0.9770798087120056, 0.9799094796180725, 0.977645754814148, 0.9736841917037964, 0.9799094796180725, 0.9660441279411316, 0.9782116413116455, 0.983305037021637, 0.9807583689689636, 0.9816072583198547, 0.9821732044219971, 0.9790605306625366, 0.9841539263725281, 0.9824561476707458, 0.9855687618255615, 0.9821732044219971, 0.9821732044219971, 0.9861347079277039, 0.9793435335159302, 0.9844368696212769, 0.9852858185768127, 0.9872665405273438, 0.9847198724746704, 0.9858517050743103, 0.9858517050743103, 0.9892473220825195, 0.9886813759803772, 0.9883984327316284, 0.9841539263725281, 0.9895302653312683, 0.9886813759803772, 0.9864176511764526, 0.9844368696212769, 0.986983597278595, 0.9847198724746704, 0.9898132681846619, 0.9878324866294861, 0.9923599362373352, 0.990662157535553, 0.9917939901351929, 0.9903791546821594, 0.9900962114334106, 0.9878324866294861, 0.9844368696212769, 0.990662157535553, 0.9898132681846619, 0.9855687618255615, 0.990662157535553, 0.9892473220825195, 0.9932088255882263, 0.9946236610412598, 0.9932088255882263, 0.990662157535553, 0.9898132681846619, 0.9773627519607544, 0.9844368696212769, 0.9917939901351929, 0.992642879486084, 0.9949066042900085, 0.9915110468864441, 0.9934917688369751, 0.9929258823394775, 0.9912280440330505, 0.9932088255882263, 0.992642879486084, 0.988964319229126, 0.9923599362373352, 0.9932088255882263, 0.9915110468864441, 0.994340717792511, 0.9934917688369751, 0.9949066042900085], 'val_loss': [1.1154190301895142, 1.11186683177948, 1.1126823425292969, 1.1070035696029663, 1.1019800901412964, 1.101942539215088, 1.0990644693374634, 1.0797654390335083, 1.0698529481887817, 1.0546163320541382, 1.027847170829773, 0.9941247701644897, 0.9478152394294739, 0.9584615230560303, 0.8342171907424927, 0.7906512022018433, 0.7311056852340698, 0.7224199175834656, 0.6981614828109741, 0.6651398539543152, 0.6253689527511597, 0.6142594218254089, 0.6553109884262085, 0.6200547218322754, 0.703347384929657, 0.7156442999839783, 0.6319156289100647, 0.618130624294281, 0.6298384666442871, 0.6214471459388733, 0.6482138633728027, 0.6389796733856201, 0.6783469319343567, 0.6664928793907166, 0.6498565077781677, 0.6435684561729431, 0.6411285400390625, 0.6426196694374084, 0.6482356190681458, 0.6579344868659973, 0.6495100259780884, 0.6679120659828186, 0.7123655676841736, 0.6577900052070618, 0.6808818578720093, 0.6904784440994263, 0.6537824273109436, 0.6566378474235535, 0.7321088314056396, 0.6684490442276001, 0.6574680805206299, 0.6599918007850647, 0.6592434048652649, 0.6621184945106506, 0.6720438003540039, 0.6713924407958984, 0.6642225384712219, 0.6632305979728699, 0.6694771647453308, 0.6984433531761169, 0.6656962037086487, 0.6652364134788513, 0.6892606019973755, 0.6750599145889282, 0.6859852075576782, 0.6758920550346375, 0.6729270815849304, 0.6878470182418823, 0.686519980430603, 0.685568630695343, 0.6783652901649475, 0.7239878177642822, 0.6774527430534363, 0.686148464679718, 0.6922394037246704, 0.6821675896644592, 0.6906512379646301, 0.6834517121315002, 0.6870428323745728, 0.6865718960762024, 0.7015379667282104, 0.7289748787879944, 0.8704330921173096, 0.692977786064148, 0.723532497882843, 0.6920729875564575, 0.70554518699646, 0.7155011892318726, 0.6945725083351135, 0.6981484293937683, 0.7045902013778687, 0.6935473680496216, 0.7434285283088684, 0.7177184224128723, 0.7109208703041077, 0.6999001502990723, 0.6960391998291016, 0.6996352076530457, 0.7037511467933655, 0.7470880150794983], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4977375566959381, 0.4977375566959381, 0.5090497732162476, 0.5248869061470032, 0.5486425161361694, 0.5995475053787231, 0.5927602052688599, 0.7533936500549316, 0.7986425161361694, 0.8472850918769836, 0.8404977321624756, 0.8540723919868469, 0.8676470518112183, 0.8914027214050293, 0.8914027214050293, 0.8699095249176025, 0.877828061580658, 0.8552036285400391, 0.8529411554336548, 0.8789592981338501, 0.8868778347969055, 0.8823529481887817, 0.8880090713500977, 0.8800904750823975, 0.8868778347969055, 0.8789592981338501, 0.877828061580658, 0.8789592981338501, 0.8846153616905212, 0.8846153616905212, 0.8857465982437134, 0.8834841847419739, 0.8789592981338501, 0.8812217116355896, 0.8800904750823975, 0.8766968250274658, 0.8789592981338501, 0.877828061580658, 0.872171938419342, 0.8823529481887817, 0.8789592981338501, 0.872171938419342, 0.8766968250274658, 0.8789592981338501, 0.8755655884742737, 0.8812217116355896, 0.8710407018661499, 0.8812217116355896, 0.8789592981338501, 0.8766968250274658, 0.8812217116355896, 0.8846153616905212, 0.8812217116355896, 0.877828061580658, 0.8812217116355896, 0.872171938419342, 0.8755655884742737, 0.8823529481887817, 0.872171938419342, 0.8766968250274658, 0.872171938419342, 0.8733031749725342, 0.872171938419342, 0.872171938419342, 0.877828061580658, 0.8766968250274658, 0.8766968250274658, 0.8834841847419739, 0.8676470518112183, 0.8687782883644104, 0.8710407018661499, 0.8710407018661499, 0.8733031749725342, 0.8766968250274658, 0.8834841847419739, 0.8506787419319153, 0.8755655884742737, 0.8710407018661499, 0.8687782883644104, 0.8676470518112183, 0.8733031749725342, 0.8665158152580261, 0.8733031749725342, 0.8800904750823975, 0.8710407018661499, 0.8665158152580261, 0.877828061580658, 0.8687782883644104, 0.8710407018661499, 0.8744344115257263, 0.8755655884742737, 0.8687782883644104, 0.8812217116355896]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.5348 - accuracy: 0.9426"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 9s 57ms/step - loss: 0.5348 - accuracy: 0.9426 - val_loss: 1.1226 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5121 - accuracy: 0.9506 - val_loss: 1.1214 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5156 - accuracy: 0.9478 - val_loss: 1.1186 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4978 - accuracy: 0.9556 - val_loss: 1.1111 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4922 - accuracy: 0.9561 - val_loss: 1.1126 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4972 - accuracy: 0.9530 - val_loss: 1.1123 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4797 - accuracy: 0.9628 - val_loss: 1.1016 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4922 - accuracy: 0.9527 - val_loss: 1.0823 - val_accuracy: 0.4886\n","Epoch 9/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4794 - accuracy: 0.9623 - val_loss: 1.0843 - val_accuracy: 0.4897\n","Epoch 10/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4758 - accuracy: 0.9584 - val_loss: 1.0373 - val_accuracy: 0.5124\n","Epoch 11/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4687 - accuracy: 0.9659 - val_loss: 0.9714 - val_accuracy: 0.5620\n","Epoch 12/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4672 - accuracy: 0.9643 - val_loss: 0.8981 - val_accuracy: 0.6612\n","Epoch 13/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4668 - accuracy: 0.9630 - val_loss: 0.8718 - val_accuracy: 0.6983\n","Epoch 14/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.4600 - accuracy: 0.9680 - val_loss: 0.8536 - val_accuracy: 0.7097\n","Epoch 15/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.4598 - accuracy: 0.9690 - val_loss: 0.7875 - val_accuracy: 0.7862\n","Epoch 16/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.4575 - accuracy: 0.9672 - val_loss: 0.7495 - val_accuracy: 0.8151\n","Epoch 17/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.4517 - accuracy: 0.9690 - val_loss: 0.6777 - val_accuracy: 0.8791\n","Epoch 18/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4463 - accuracy: 0.9708 - val_loss: 0.6952 - val_accuracy: 0.8502\n","Epoch 19/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4437 - accuracy: 0.9708 - val_loss: 0.7565 - val_accuracy: 0.8037\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4447 - accuracy: 0.9703 - val_loss: 0.6677 - val_accuracy: 0.8698\n","Epoch 21/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4401 - accuracy: 0.9674 - val_loss: 0.6494 - val_accuracy: 0.8853\n","Epoch 22/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4342 - accuracy: 0.9705 - val_loss: 0.6648 - val_accuracy: 0.8833\n","Epoch 23/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4458 - accuracy: 0.9693 - val_loss: 0.7272 - val_accuracy: 0.8378\n","Epoch 24/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4448 - accuracy: 0.9690 - val_loss: 0.6802 - val_accuracy: 0.8771\n","Epoch 25/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4333 - accuracy: 0.9705 - val_loss: 0.6404 - val_accuracy: 0.8884\n","Epoch 26/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4232 - accuracy: 0.9770 - val_loss: 0.6409 - val_accuracy: 0.8905\n","Epoch 27/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4202 - accuracy: 0.9780 - val_loss: 0.6579 - val_accuracy: 0.8957\n","Epoch 28/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4234 - accuracy: 0.9765 - val_loss: 0.6669 - val_accuracy: 0.8936\n","Epoch 29/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4203 - accuracy: 0.9742 - val_loss: 0.6763 - val_accuracy: 0.8853\n","Epoch 30/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4186 - accuracy: 0.9760 - val_loss: 0.6600 - val_accuracy: 0.8905\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4097 - accuracy: 0.9814 - val_loss: 0.6651 - val_accuracy: 0.8864\n","Epoch 32/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4114 - accuracy: 0.9773 - val_loss: 0.6769 - val_accuracy: 0.8843\n","Epoch 33/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4116 - accuracy: 0.9765 - val_loss: 0.6739 - val_accuracy: 0.8864\n","Epoch 34/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4121 - accuracy: 0.9778 - val_loss: 0.6960 - val_accuracy: 0.8853\n","Epoch 35/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4127 - accuracy: 0.9731 - val_loss: 0.7127 - val_accuracy: 0.8791\n","Epoch 36/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4128 - accuracy: 0.9736 - val_loss: 0.7119 - val_accuracy: 0.8874\n","Epoch 37/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4103 - accuracy: 0.9760 - val_loss: 0.6661 - val_accuracy: 0.8946\n","Epoch 38/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3952 - accuracy: 0.9829 - val_loss: 0.6936 - val_accuracy: 0.8895\n","Epoch 39/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3936 - accuracy: 0.9824 - val_loss: 0.6776 - val_accuracy: 0.8915\n","Epoch 40/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3941 - accuracy: 0.9832 - val_loss: 0.6731 - val_accuracy: 0.8926\n","Epoch 41/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3981 - accuracy: 0.9780 - val_loss: 0.6754 - val_accuracy: 0.8946\n","Epoch 42/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3928 - accuracy: 0.9809 - val_loss: 0.6852 - val_accuracy: 0.8874\n","Epoch 43/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3939 - accuracy: 0.9796 - val_loss: 0.7057 - val_accuracy: 0.8905\n","Epoch 44/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4099 - accuracy: 0.9718 - val_loss: 0.6842 - val_accuracy: 0.8874\n","Epoch 45/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3977 - accuracy: 0.9747 - val_loss: 0.7010 - val_accuracy: 0.8833\n","Epoch 46/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3773 - accuracy: 0.9886 - val_loss: 0.6811 - val_accuracy: 0.8853\n","Epoch 47/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3804 - accuracy: 0.9845 - val_loss: 0.6781 - val_accuracy: 0.8946\n","Epoch 48/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3901 - accuracy: 0.9796 - val_loss: 0.6905 - val_accuracy: 0.8822\n","Epoch 49/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3775 - accuracy: 0.9858 - val_loss: 0.6945 - val_accuracy: 0.8864\n","Epoch 50/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3704 - accuracy: 0.9891 - val_loss: 0.6919 - val_accuracy: 0.8864\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3769 - accuracy: 0.9863 - val_loss: 0.6842 - val_accuracy: 0.8895\n","Epoch 52/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3760 - accuracy: 0.9855 - val_loss: 0.7095 - val_accuracy: 0.8812\n","Epoch 53/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3718 - accuracy: 0.9858 - val_loss: 0.7118 - val_accuracy: 0.8864\n","Epoch 54/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3965 - accuracy: 0.9742 - val_loss: 0.6756 - val_accuracy: 0.8905\n","Epoch 55/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3684 - accuracy: 0.9873 - val_loss: 0.6793 - val_accuracy: 0.8874\n","Epoch 56/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3634 - accuracy: 0.9897 - val_loss: 0.6798 - val_accuracy: 0.8915\n","Epoch 57/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3649 - accuracy: 0.9873 - val_loss: 0.7173 - val_accuracy: 0.8853\n","Epoch 58/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3705 - accuracy: 0.9842 - val_loss: 0.7544 - val_accuracy: 0.8802\n","Epoch 59/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3677 - accuracy: 0.9879 - val_loss: 0.7068 - val_accuracy: 0.8905\n","Epoch 60/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3589 - accuracy: 0.9891 - val_loss: 0.7067 - val_accuracy: 0.8833\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3686 - accuracy: 0.9853 - val_loss: 0.6894 - val_accuracy: 0.8822\n","Epoch 62/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3553 - accuracy: 0.9904 - val_loss: 0.6860 - val_accuracy: 0.8926\n","Epoch 63/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3558 - accuracy: 0.9891 - val_loss: 0.7428 - val_accuracy: 0.8678\n","Epoch 64/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3568 - accuracy: 0.9879 - val_loss: 0.6910 - val_accuracy: 0.8864\n","Epoch 65/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3524 - accuracy: 0.9889 - val_loss: 0.6955 - val_accuracy: 0.8874\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3552 - accuracy: 0.9866 - val_loss: 0.7218 - val_accuracy: 0.8781\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3571 - accuracy: 0.9884 - val_loss: 0.7206 - val_accuracy: 0.8853\n","Epoch 68/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3530 - accuracy: 0.9891 - val_loss: 0.7043 - val_accuracy: 0.8833\n","Epoch 69/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3637 - accuracy: 0.9824 - val_loss: 0.7296 - val_accuracy: 0.8853\n","Epoch 70/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3520 - accuracy: 0.9866 - val_loss: 0.6986 - val_accuracy: 0.8905\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3454 - accuracy: 0.9904 - val_loss: 0.6960 - val_accuracy: 0.8926\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3447 - accuracy: 0.9904 - val_loss: 0.7481 - val_accuracy: 0.8667\n","Epoch 73/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3447 - accuracy: 0.9894 - val_loss: 0.7017 - val_accuracy: 0.8915\n","Epoch 74/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3547 - accuracy: 0.9863 - val_loss: 0.8020 - val_accuracy: 0.8750\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3616 - accuracy: 0.9824 - val_loss: 0.7008 - val_accuracy: 0.8884\n","Epoch 76/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3365 - accuracy: 0.9925 - val_loss: 0.7019 - val_accuracy: 0.8895\n","Epoch 77/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3393 - accuracy: 0.9907 - val_loss: 0.6989 - val_accuracy: 0.8915\n","Epoch 78/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3337 - accuracy: 0.9933 - val_loss: 0.7017 - val_accuracy: 0.8853\n","Epoch 79/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3452 - accuracy: 0.9886 - val_loss: 0.7027 - val_accuracy: 0.8936\n","Epoch 80/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3378 - accuracy: 0.9902 - val_loss: 0.6985 - val_accuracy: 0.8946\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3496 - accuracy: 0.9840 - val_loss: 0.7060 - val_accuracy: 0.8864\n","Epoch 82/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3390 - accuracy: 0.9904 - val_loss: 0.6928 - val_accuracy: 0.8864\n","Epoch 83/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3311 - accuracy: 0.9915 - val_loss: 0.7020 - val_accuracy: 0.8915\n","Epoch 84/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3404 - accuracy: 0.9863 - val_loss: 0.7142 - val_accuracy: 0.8874\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3334 - accuracy: 0.9920 - val_loss: 0.7023 - val_accuracy: 0.8915\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3345 - accuracy: 0.9879 - val_loss: 0.7100 - val_accuracy: 0.8905\n","Epoch 87/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3282 - accuracy: 0.9915 - val_loss: 0.7317 - val_accuracy: 0.8771\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3269 - accuracy: 0.9928 - val_loss: 0.7047 - val_accuracy: 0.8833\n","Epoch 89/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3213 - accuracy: 0.9943 - val_loss: 0.7016 - val_accuracy: 0.8905\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3218 - accuracy: 0.9943 - val_loss: 0.7111 - val_accuracy: 0.8895\n","Epoch 91/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3195 - accuracy: 0.9946 - val_loss: 0.7029 - val_accuracy: 0.8905\n","Epoch 92/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3205 - accuracy: 0.9938 - val_loss: 0.7148 - val_accuracy: 0.8864\n","Epoch 93/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3208 - accuracy: 0.9943 - val_loss: 0.7007 - val_accuracy: 0.8895\n","Epoch 94/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3228 - accuracy: 0.9922 - val_loss: 0.7781 - val_accuracy: 0.8771\n","Epoch 95/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3332 - accuracy: 0.9855 - val_loss: 0.7734 - val_accuracy: 0.8812\n","Epoch 96/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3234 - accuracy: 0.9917 - val_loss: 0.7422 - val_accuracy: 0.8833\n","Epoch 97/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3251 - accuracy: 0.9902 - val_loss: 0.7072 - val_accuracy: 0.8915\n","Epoch 98/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3160 - accuracy: 0.9935 - val_loss: 0.7504 - val_accuracy: 0.8719\n","Epoch 99/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3138 - accuracy: 0.9935 - val_loss: 0.7284 - val_accuracy: 0.8843\n","Epoch 100/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3125 - accuracy: 0.9943 - val_loss: 0.7309 - val_accuracy: 0.8833\n","{'loss': [0.5348232984542847, 0.5121004581451416, 0.5156159996986389, 0.49779531359672546, 0.49216902256011963, 0.49719884991645813, 0.4797399342060089, 0.4922056794166565, 0.47943833470344543, 0.47581368684768677, 0.4687046408653259, 0.46716734766960144, 0.46678033471107483, 0.4599640369415283, 0.45981502532958984, 0.4575270116329193, 0.45166298747062683, 0.44625169038772583, 0.4436827003955841, 0.4447193741798401, 0.4401285946369171, 0.4341663420200348, 0.4457659125328064, 0.44483256340026855, 0.4332767128944397, 0.42322975397109985, 0.4202403426170349, 0.4234415888786316, 0.42033615708351135, 0.4186400771141052, 0.40969040989875793, 0.4114099442958832, 0.41158056259155273, 0.4121251702308655, 0.41272059082984924, 0.4127844274044037, 0.4102940559387207, 0.395211786031723, 0.3936263620853424, 0.39405789971351624, 0.3980984389781952, 0.3928113579750061, 0.39389610290527344, 0.40985822677612305, 0.39767971634864807, 0.37727344036102295, 0.3803890347480774, 0.39008674025535583, 0.37752994894981384, 0.3703553080558777, 0.3768537938594818, 0.3760223090648651, 0.37176352739334106, 0.39654162526130676, 0.3684338927268982, 0.3634222447872162, 0.3648679554462433, 0.37053465843200684, 0.36765608191490173, 0.3589443862438202, 0.36857545375823975, 0.35534951090812683, 0.3557772636413574, 0.35678163170814514, 0.35243740677833557, 0.35524699091911316, 0.35706397891044617, 0.3530251979827881, 0.36366572976112366, 0.35202810168266296, 0.34536778926849365, 0.3446616232395172, 0.3447114825248718, 0.3546929955482483, 0.36164531111717224, 0.3364714980125427, 0.3392890989780426, 0.33371710777282715, 0.345152884721756, 0.3378240466117859, 0.3496069610118866, 0.33902043104171753, 0.3310910761356354, 0.34044110774993896, 0.3333556056022644, 0.33445289731025696, 0.32823294401168823, 0.32685452699661255, 0.3212517201900482, 0.32184213399887085, 0.31950071454048157, 0.32053273916244507, 0.32083117961883545, 0.3227609097957611, 0.33318349719047546, 0.32339295744895935, 0.32514530420303345, 0.31600314378738403, 0.3138168752193451, 0.3125184178352356], 'accuracy': [0.9426356554031372, 0.9506459832191467, 0.9478036165237427, 0.9555555582046509, 0.9560723304748535, 0.9529715776443481, 0.9627906680107117, 0.9527131915092468, 0.962273895740509, 0.9583979249000549, 0.9658914804458618, 0.9643411040306091, 0.9630491137504578, 0.9679586291313171, 0.9689922332763672, 0.9671834707260132, 0.9689922332763672, 0.970801055431366, 0.970801055431366, 0.9702842235565186, 0.9674418568611145, 0.9705426096916199, 0.9692506194114685, 0.9689922332763672, 0.9705426096916199, 0.9770025610923767, 0.9780361652374268, 0.9764857888221741, 0.9741601943969727, 0.9759690165519714, 0.9813953638076782, 0.9772610068321228, 0.9764857888221741, 0.9777777791023254, 0.9731265902519226, 0.97364342212677, 0.9759690165519714, 0.9829457402229309, 0.9824289679527283, 0.9832041263580322, 0.9780361652374268, 0.9808785319328308, 0.9795865416526794, 0.9718345999717712, 0.9746770262718201, 0.988630473613739, 0.9844961166381836, 0.9795865416526794, 0.985788106918335, 0.9891473054885864, 0.9863049387931824, 0.9855297207832336, 0.985788106918335, 0.9741601943969727, 0.9873384833335876, 0.9896640777587891, 0.9873384833335876, 0.9842377305030823, 0.9878553152084351, 0.9891473054885864, 0.9852713346481323, 0.9904392957687378, 0.9891473054885864, 0.9878553152084351, 0.9888888597488403, 0.9865633249282837, 0.9883720874786377, 0.9891473054885864, 0.9824289679527283, 0.9865633249282837, 0.9904392957687378, 0.9904392957687378, 0.9894056916236877, 0.9863049387931824, 0.9824289679527283, 0.9925064444541931, 0.9906976819038391, 0.9932816624641418, 0.988630473613739, 0.9901808500289917, 0.983979344367981, 0.9904392957687378, 0.9914728403091431, 0.9863049387931824, 0.9919896721839905, 0.9878553152084351, 0.9914728403091431, 0.9927648305892944, 0.9943152666091919, 0.9943152666091919, 0.9945736527442932, 0.9937984347343445, 0.9943152666091919, 0.9922480583190918, 0.9855297207832336, 0.9917312860488892, 0.9901808500289917, 0.9935400485992432, 0.9935400485992432, 0.9943152666091919], 'val_loss': [1.1225972175598145, 1.1214221715927124, 1.118610143661499, 1.111051082611084, 1.1125648021697998, 1.112278699874878, 1.1016067266464233, 1.082293152809143, 1.084324836730957, 1.0372626781463623, 0.9714253544807434, 0.8980922102928162, 0.8717679381370544, 0.8536183834075928, 0.7874786853790283, 0.7494574785232544, 0.677668571472168, 0.6952325701713562, 0.7564753890037537, 0.6676567792892456, 0.6493579745292664, 0.6648198962211609, 0.7271633148193359, 0.6801596283912659, 0.6403532028198242, 0.6408591866493225, 0.6578877568244934, 0.6668732166290283, 0.6763034462928772, 0.6599830985069275, 0.6651279926300049, 0.676852285861969, 0.6738877892494202, 0.696029543876648, 0.7127344012260437, 0.7118821740150452, 0.6661005020141602, 0.6935791969299316, 0.6776430606842041, 0.6731320023536682, 0.6753544807434082, 0.6851902604103088, 0.7056984901428223, 0.6842489838600159, 0.7009654641151428, 0.6810620427131653, 0.6781444549560547, 0.690515398979187, 0.6944529414176941, 0.6919114589691162, 0.6842396855354309, 0.7095182538032532, 0.7118185758590698, 0.6756080389022827, 0.6793020963668823, 0.6797923445701599, 0.7172953486442566, 0.75437331199646, 0.7067996859550476, 0.7066978812217712, 0.689440131187439, 0.6860362887382507, 0.7428061366081238, 0.6910222172737122, 0.6955466866493225, 0.7218125462532043, 0.7206026315689087, 0.7042818665504456, 0.7296384572982788, 0.6985899209976196, 0.6960288286209106, 0.7480770349502563, 0.7017078399658203, 0.8019888997077942, 0.7007808685302734, 0.7018826603889465, 0.6989017128944397, 0.7017310261726379, 0.7026758193969727, 0.6985125541687012, 0.7059555053710938, 0.6928328275680542, 0.7020045518875122, 0.7142478823661804, 0.7023463845252991, 0.7100304365158081, 0.7316782474517822, 0.7046705484390259, 0.7016100883483887, 0.7110612988471985, 0.7028622031211853, 0.7147969007492065, 0.700702965259552, 0.7780904769897461, 0.7734386324882507, 0.7422181367874146, 0.7072025537490845, 0.7504328489303589, 0.7284421324729919, 0.7309051156044006], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4886363744735718, 0.48966941237449646, 0.5123966932296753, 0.5619834661483765, 0.6611570119857788, 0.6983470916748047, 0.7097107172012329, 0.7861570119857788, 0.8150826692581177, 0.8791322112083435, 0.8502066135406494, 0.8037189841270447, 0.8698347210884094, 0.8853305578231812, 0.8832644820213318, 0.8378099203109741, 0.8770661354064941, 0.8884297609329224, 0.8904958963394165, 0.8956611752510071, 0.8935950398445129, 0.8853305578231812, 0.8904958963394165, 0.8863636255264282, 0.8842975497245789, 0.8863636255264282, 0.8853305578231812, 0.8791322112083435, 0.8873966932296753, 0.89462810754776, 0.8894628286361694, 0.8915289044380188, 0.8925619721412659, 0.89462810754776, 0.8873966932296753, 0.8904958963394165, 0.8873966932296753, 0.8832644820213318, 0.8853305578231812, 0.89462810754776, 0.8822314143180847, 0.8863636255264282, 0.8863636255264282, 0.8894628286361694, 0.8811983466148376, 0.8863636255264282, 0.8904958963394165, 0.8873966932296753, 0.8915289044380188, 0.8853305578231812, 0.8801652789115906, 0.8904958963394165, 0.8832644820213318, 0.8822314143180847, 0.8925619721412659, 0.8677685856819153, 0.8863636255264282, 0.8873966932296753, 0.8780992031097412, 0.8853305578231812, 0.8832644820213318, 0.8853305578231812, 0.8904958963394165, 0.8925619721412659, 0.8667355179786682, 0.8915289044380188, 0.875, 0.8884297609329224, 0.8894628286361694, 0.8915289044380188, 0.8853305578231812, 0.8935950398445129, 0.89462810754776, 0.8863636255264282, 0.8863636255264282, 0.8915289044380188, 0.8873966932296753, 0.8915289044380188, 0.8904958963394165, 0.8770661354064941, 0.8832644820213318, 0.8904958963394165, 0.8894628286361694, 0.8904958963394165, 0.8863636255264282, 0.8894628286361694, 0.8770661354064941, 0.8811983466148376, 0.8832644820213318, 0.8915289044380188, 0.8719007968902588, 0.8842975497245789, 0.8832644820213318]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.3674 - accuracy: 0.9749"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 9s 57ms/step - loss: 0.3676 - accuracy: 0.9747 - val_loss: 1.0718 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3664 - accuracy: 0.9739 - val_loss: 1.0749 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3538 - accuracy: 0.9795 - val_loss: 1.0719 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3428 - accuracy: 0.9825 - val_loss: 1.0712 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3550 - accuracy: 0.9758 - val_loss: 1.0632 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3490 - accuracy: 0.9795 - val_loss: 1.0631 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3299 - accuracy: 0.9881 - val_loss: 1.0565 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3339 - accuracy: 0.9857 - val_loss: 1.0541 - val_accuracy: 0.4849\n","Epoch 9/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3264 - accuracy: 0.9876 - val_loss: 1.0357 - val_accuracy: 0.4871\n","Epoch 10/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3277 - accuracy: 0.9887 - val_loss: 0.9806 - val_accuracy: 0.5108\n","Epoch 11/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3242 - accuracy: 0.9887 - val_loss: 0.9919 - val_accuracy: 0.5194\n","Epoch 12/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3283 - accuracy: 0.9833 - val_loss: 0.9487 - val_accuracy: 0.5496\n","Epoch 13/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3176 - accuracy: 0.9892 - val_loss: 0.8234 - val_accuracy: 0.6422\n","Epoch 14/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3234 - accuracy: 0.9868 - val_loss: 0.6908 - val_accuracy: 0.7920\n","Epoch 15/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3257 - accuracy: 0.9849 - val_loss: 0.7532 - val_accuracy: 0.7144\n","Epoch 16/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3191 - accuracy: 0.9881 - val_loss: 0.6100 - val_accuracy: 0.8491\n","Epoch 17/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.3149 - accuracy: 0.9919 - val_loss: 0.5703 - val_accuracy: 0.8718\n","Epoch 18/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.3130 - accuracy: 0.9903 - val_loss: 0.4945 - val_accuracy: 0.9310\n","Epoch 19/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3146 - accuracy: 0.9898 - val_loss: 0.5436 - val_accuracy: 0.8879\n","Epoch 20/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3111 - accuracy: 0.9898 - val_loss: 0.4786 - val_accuracy: 0.9192\n","Epoch 21/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3100 - accuracy: 0.9914 - val_loss: 0.4486 - val_accuracy: 0.9310\n","Epoch 22/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.3063 - accuracy: 0.9925 - val_loss: 0.4480 - val_accuracy: 0.9321\n","Epoch 23/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.3039 - accuracy: 0.9916 - val_loss: 0.4344 - val_accuracy: 0.9386\n","Epoch 24/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3067 - accuracy: 0.9890 - val_loss: 0.4349 - val_accuracy: 0.9353\n","Epoch 25/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3031 - accuracy: 0.9916 - val_loss: 0.4354 - val_accuracy: 0.9353\n","Epoch 26/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3054 - accuracy: 0.9906 - val_loss: 0.4385 - val_accuracy: 0.9429\n","Epoch 27/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3052 - accuracy: 0.9900 - val_loss: 0.4467 - val_accuracy: 0.9364\n","Epoch 28/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2994 - accuracy: 0.9927 - val_loss: 0.4511 - val_accuracy: 0.9375\n","Epoch 29/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2968 - accuracy: 0.9938 - val_loss: 0.4615 - val_accuracy: 0.9321\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2977 - accuracy: 0.9925 - val_loss: 0.4823 - val_accuracy: 0.9278\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2945 - accuracy: 0.9941 - val_loss: 0.4734 - val_accuracy: 0.9278\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3130 - accuracy: 0.9849 - val_loss: 0.5239 - val_accuracy: 0.9246\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3014 - accuracy: 0.9887 - val_loss: 0.4617 - val_accuracy: 0.9364\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2982 - accuracy: 0.9911 - val_loss: 0.4631 - val_accuracy: 0.9321\n","Epoch 35/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2910 - accuracy: 0.9941 - val_loss: 0.4601 - val_accuracy: 0.9321\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2899 - accuracy: 0.9925 - val_loss: 0.4793 - val_accuracy: 0.9310\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2885 - accuracy: 0.9952 - val_loss: 0.4939 - val_accuracy: 0.9256\n","Epoch 38/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2902 - accuracy: 0.9930 - val_loss: 0.5137 - val_accuracy: 0.9246\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2948 - accuracy: 0.9879 - val_loss: 0.5778 - val_accuracy: 0.9073\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3043 - accuracy: 0.9868 - val_loss: 0.5659 - val_accuracy: 0.9127\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2869 - accuracy: 0.9941 - val_loss: 0.5020 - val_accuracy: 0.9235\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2801 - accuracy: 0.9962 - val_loss: 0.4736 - val_accuracy: 0.9321\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2828 - accuracy: 0.9957 - val_loss: 0.4666 - val_accuracy: 0.9375\n","Epoch 44/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2787 - accuracy: 0.9965 - val_loss: 0.4885 - val_accuracy: 0.9321\n","Epoch 45/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2872 - accuracy: 0.9941 - val_loss: 0.5400 - val_accuracy: 0.9116\n","Epoch 46/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2871 - accuracy: 0.9916 - val_loss: 0.5061 - val_accuracy: 0.9224\n","Epoch 47/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2769 - accuracy: 0.9976 - val_loss: 0.4768 - val_accuracy: 0.9310\n","Epoch 48/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2782 - accuracy: 0.9962 - val_loss: 0.4936 - val_accuracy: 0.9300\n","Epoch 49/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2852 - accuracy: 0.9908 - val_loss: 0.4946 - val_accuracy: 0.9267\n","Epoch 50/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2813 - accuracy: 0.9933 - val_loss: 0.4794 - val_accuracy: 0.9332\n","Epoch 51/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2769 - accuracy: 0.9952 - val_loss: 0.4951 - val_accuracy: 0.9246\n","Epoch 52/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2754 - accuracy: 0.9957 - val_loss: 0.5109 - val_accuracy: 0.9235\n","Epoch 53/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2793 - accuracy: 0.9935 - val_loss: 0.4940 - val_accuracy: 0.9300\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2727 - accuracy: 0.9954 - val_loss: 0.4791 - val_accuracy: 0.9300\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2715 - accuracy: 0.9965 - val_loss: 0.5048 - val_accuracy: 0.9267\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2790 - accuracy: 0.9927 - val_loss: 0.4745 - val_accuracy: 0.9310\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2756 - accuracy: 0.9935 - val_loss: 0.4955 - val_accuracy: 0.9289\n","Epoch 58/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2706 - accuracy: 0.9968 - val_loss: 0.4782 - val_accuracy: 0.9310\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2712 - accuracy: 0.9938 - val_loss: 0.4914 - val_accuracy: 0.9246\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2720 - accuracy: 0.9952 - val_loss: 0.4834 - val_accuracy: 0.9332\n","Epoch 61/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2674 - accuracy: 0.9970 - val_loss: 0.4877 - val_accuracy: 0.9246\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2660 - accuracy: 0.9968 - val_loss: 0.4795 - val_accuracy: 0.9321\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2674 - accuracy: 0.9952 - val_loss: 0.4870 - val_accuracy: 0.9267\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2644 - accuracy: 0.9962 - val_loss: 0.4854 - val_accuracy: 0.9246\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2655 - accuracy: 0.9968 - val_loss: 0.5276 - val_accuracy: 0.9203\n","Epoch 66/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2662 - accuracy: 0.9965 - val_loss: 0.4839 - val_accuracy: 0.9310\n","Epoch 67/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2616 - accuracy: 0.9970 - val_loss: 0.4890 - val_accuracy: 0.9289\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2613 - accuracy: 0.9973 - val_loss: 0.5021 - val_accuracy: 0.9256\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2598 - accuracy: 0.9973 - val_loss: 0.4936 - val_accuracy: 0.9278\n","Epoch 70/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2582 - accuracy: 0.9976 - val_loss: 0.4858 - val_accuracy: 0.9332\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2595 - accuracy: 0.9962 - val_loss: 0.5046 - val_accuracy: 0.9289\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2575 - accuracy: 0.9970 - val_loss: 0.5079 - val_accuracy: 0.9224\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2570 - accuracy: 0.9976 - val_loss: 0.4809 - val_accuracy: 0.9278\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2551 - accuracy: 0.9984 - val_loss: 0.4862 - val_accuracy: 0.9300\n","Epoch 75/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2541 - accuracy: 0.9984 - val_loss: 0.5409 - val_accuracy: 0.9159\n","Epoch 76/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2545 - accuracy: 0.9981 - val_loss: 0.4862 - val_accuracy: 0.9300\n","Epoch 77/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2544 - accuracy: 0.9981 - val_loss: 0.4818 - val_accuracy: 0.9278\n","Epoch 78/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2554 - accuracy: 0.9960 - val_loss: 0.5373 - val_accuracy: 0.9235\n","Epoch 79/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2660 - accuracy: 0.9914 - val_loss: 0.4840 - val_accuracy: 0.9321\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2569 - accuracy: 0.9943 - val_loss: 0.4890 - val_accuracy: 0.9310\n","Epoch 81/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2563 - accuracy: 0.9960 - val_loss: 0.4889 - val_accuracy: 0.9289\n","Epoch 82/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2531 - accuracy: 0.9962 - val_loss: 0.4750 - val_accuracy: 0.9310\n","Epoch 83/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2666 - accuracy: 0.9900 - val_loss: 0.4920 - val_accuracy: 0.9332\n","Epoch 84/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2604 - accuracy: 0.9938 - val_loss: 0.4898 - val_accuracy: 0.9213\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2498 - accuracy: 0.9978 - val_loss: 0.5025 - val_accuracy: 0.9192\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2570 - accuracy: 0.9930 - val_loss: 0.9887 - val_accuracy: 0.8287\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3117 - accuracy: 0.9720 - val_loss: 0.5003 - val_accuracy: 0.9278\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2504 - accuracy: 0.9960 - val_loss: 0.4892 - val_accuracy: 0.9300\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2459 - accuracy: 0.9987 - val_loss: 0.5015 - val_accuracy: 0.9278\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2459 - accuracy: 0.9984 - val_loss: 0.4846 - val_accuracy: 0.9246\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2501 - accuracy: 0.9968 - val_loss: 0.4944 - val_accuracy: 0.9224\n","Epoch 92/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2625 - accuracy: 0.9911 - val_loss: 0.4927 - val_accuracy: 0.9278\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2438 - accuracy: 0.9987 - val_loss: 0.5061 - val_accuracy: 0.9256\n","Epoch 94/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2408 - accuracy: 0.9997 - val_loss: 0.4880 - val_accuracy: 0.9267\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2412 - accuracy: 0.9987 - val_loss: 0.4990 - val_accuracy: 0.9256\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2407 - accuracy: 0.9987 - val_loss: 0.4849 - val_accuracy: 0.9289\n","Epoch 97/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2447 - accuracy: 0.9960 - val_loss: 0.5338 - val_accuracy: 0.9127\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2397 - accuracy: 0.9981 - val_loss: 0.5030 - val_accuracy: 0.9235\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2479 - accuracy: 0.9960 - val_loss: 0.4871 - val_accuracy: 0.9267\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2435 - accuracy: 0.9965 - val_loss: 0.4906 - val_accuracy: 0.9246\n","{'loss': [0.3676145374774933, 0.36640089750289917, 0.35376325249671936, 0.34281259775161743, 0.3549557030200958, 0.34897857904434204, 0.32987192273139954, 0.33391839265823364, 0.32641613483428955, 0.32772666215896606, 0.32419559359550476, 0.32827314734458923, 0.31756821274757385, 0.3234345018863678, 0.3257109224796295, 0.3190796971321106, 0.3149474859237671, 0.3129517734050751, 0.31455180048942566, 0.3110831379890442, 0.30995503067970276, 0.30629467964172363, 0.3039323687553406, 0.3066619038581848, 0.30312520265579224, 0.30544957518577576, 0.3051947355270386, 0.2993828356266022, 0.29678910970687866, 0.29770684242248535, 0.2944914698600769, 0.3129727244377136, 0.3014240562915802, 0.29821452498435974, 0.2909872233867645, 0.28991612792015076, 0.28847363591194153, 0.29021063446998596, 0.2948157489299774, 0.3043232560157776, 0.2868867516517639, 0.2800688147544861, 0.2828260660171509, 0.27869588136672974, 0.28723275661468506, 0.2870800793170929, 0.2768898904323578, 0.2782401144504547, 0.28523629903793335, 0.28131887316703796, 0.2769205570220947, 0.275351345539093, 0.27932626008987427, 0.27274179458618164, 0.27146115899086, 0.27901703119277954, 0.275581419467926, 0.2705571949481964, 0.2712492346763611, 0.27200624346733093, 0.2673640549182892, 0.26604440808296204, 0.26740747690200806, 0.26437538862228394, 0.26548099517822266, 0.26619553565979004, 0.26157379150390625, 0.2612565755844116, 0.25978726148605347, 0.25816160440444946, 0.25948673486709595, 0.2574915289878845, 0.25704988837242126, 0.25511986017227173, 0.2541445791721344, 0.25454461574554443, 0.2543569505214691, 0.25544029474258423, 0.26602569222450256, 0.2568775415420532, 0.2563105821609497, 0.2530900239944458, 0.26659297943115234, 0.26038315892219543, 0.24982605874538422, 0.25700852274894714, 0.3117193281650543, 0.2503959834575653, 0.24592244625091553, 0.24588805437088013, 0.2500794231891632, 0.2625218331813812, 0.24384881556034088, 0.24079392850399017, 0.2411896288394928, 0.24069739878177643, 0.24465149641036987, 0.23969706892967224, 0.24786221981048584, 0.24346370995044708], 'accuracy': [0.9746767282485962, 0.9738685488700867, 0.9795258641242981, 0.9824892282485962, 0.9757543206214905, 0.9795258641242981, 0.9881465435028076, 0.985722005367279, 0.9876077771186829, 0.9886853694915771, 0.9886853694915771, 0.9832974076271057, 0.9892241358757019, 0.9867995977401733, 0.9849137663841248, 0.9881465435028076, 0.9919180870056152, 0.9903017282485962, 0.9897629022598267, 0.9897629022598267, 0.9913793206214905, 0.9924569129943848, 0.9916487336158752, 0.9889547228813171, 0.9916487336158752, 0.990571141242981, 0.9900323152542114, 0.9927262663841248, 0.993803858757019, 0.9924569129943848, 0.9940732717514038, 0.9849137663841248, 0.9886853694915771, 0.9911099076271057, 0.9940732717514038, 0.9924569129943848, 0.9951508641242981, 0.9929956793785095, 0.9878771305084229, 0.9867995977401733, 0.9940732717514038, 0.9962284564971924, 0.9956896305084229, 0.9964978694915771, 0.9940732717514038, 0.9916487336158752, 0.9975754022598267, 0.9962284564971924, 0.990840494632721, 0.9932650923728943, 0.9951508641242981, 0.9956896305084229, 0.993534505367279, 0.9954202771186829, 0.9964978694915771, 0.9927262663841248, 0.993534505367279, 0.9967672228813171, 0.993803858757019, 0.9951508641242981, 0.9970366358757019, 0.9967672228813171, 0.9951508641242981, 0.9962284564971924, 0.9967672228813171, 0.9964978694915771, 0.9970366358757019, 0.9973060488700867, 0.9973060488700867, 0.9975754022598267, 0.9962284564971924, 0.9970366358757019, 0.9975754022598267, 0.998383641242981, 0.998383641242981, 0.9981142282485962, 0.9981142282485962, 0.9959590435028076, 0.9913793206214905, 0.9943426847457886, 0.9959590435028076, 0.9962284564971924, 0.9900323152542114, 0.993803858757019, 0.9978448152542114, 0.9929956793785095, 0.9719827771186829, 0.9959590435028076, 0.998652994632721, 0.998383641242981, 0.9967672228813171, 0.9911099076271057, 0.998652994632721, 0.9997305870056152, 0.998652994632721, 0.998652994632721, 0.9959590435028076, 0.9981142282485962, 0.9959590435028076, 0.9964978694915771], 'val_loss': [1.0717670917510986, 1.074886441230774, 1.0718649625778198, 1.0711575746536255, 1.0632224082946777, 1.0631340742111206, 1.0565325021743774, 1.054091453552246, 1.0356781482696533, 0.9805982708930969, 0.9918585419654846, 0.948739767074585, 0.823373556137085, 0.6907607913017273, 0.7531688809394836, 0.6100412607192993, 0.5703057050704956, 0.49445927143096924, 0.543639600276947, 0.47862961888313293, 0.4486064314842224, 0.4479825496673584, 0.4343789517879486, 0.43490707874298096, 0.43542882800102234, 0.43846023082733154, 0.44672924280166626, 0.45111283659935, 0.46150916814804077, 0.4823460280895233, 0.47337234020233154, 0.5238973498344421, 0.4616577923297882, 0.46310603618621826, 0.460132896900177, 0.4792928099632263, 0.4938669800758362, 0.5136597156524658, 0.5777602791786194, 0.5658766031265259, 0.5020133852958679, 0.4735549986362457, 0.46662166714668274, 0.48847588896751404, 0.540018618106842, 0.5060886144638062, 0.4767686128616333, 0.4936184585094452, 0.494647353887558, 0.4793674349784851, 0.4950563311576843, 0.5109379291534424, 0.4939839839935303, 0.4791288673877716, 0.5048011541366577, 0.4745139181613922, 0.4954585134983063, 0.47819003462791443, 0.4913870394229889, 0.4834069609642029, 0.48765140771865845, 0.47953829169273376, 0.48701760172843933, 0.48535698652267456, 0.5276002883911133, 0.48394477367401123, 0.4890436828136444, 0.5020545721054077, 0.4936004877090454, 0.4857929050922394, 0.5046411752700806, 0.5079100131988525, 0.4809248745441437, 0.4862269163131714, 0.5409490466117859, 0.4861637055873871, 0.48177120089530945, 0.5373333096504211, 0.4839786887168884, 0.488995760679245, 0.48885905742645264, 0.4750150144100189, 0.4919833540916443, 0.48983117938041687, 0.502453625202179, 0.9887024164199829, 0.5003417134284973, 0.48924949765205383, 0.5015468001365662, 0.48456645011901855, 0.49436625838279724, 0.4926932156085968, 0.5060560703277588, 0.48795923590660095, 0.4989805817604065, 0.484886109828949, 0.53382408618927, 0.502958357334137, 0.48712003231048584, 0.4905802011489868], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48706895112991333, 0.5107758641242981, 0.5193965435028076, 0.5495689511299133, 0.642241358757019, 0.7920258641242981, 0.7144396305084229, 0.8491379022598267, 0.8717672228813171, 0.931034505367279, 0.8879310488700867, 0.9191810488700867, 0.931034505367279, 0.9321120977401733, 0.9385775923728943, 0.9353448152542114, 0.9353448152542114, 0.9428879022598267, 0.9364224076271057, 0.9375, 0.9321120977401733, 0.9278017282485962, 0.9278017282485962, 0.9245689511299133, 0.9364224076271057, 0.9321120977401733, 0.9321120977401733, 0.931034505367279, 0.9256465435028076, 0.9245689511299133, 0.9073275923728943, 0.912715494632721, 0.923491358757019, 0.9321120977401733, 0.9375, 0.9321120977401733, 0.9116379022598267, 0.9224137663841248, 0.931034505367279, 0.9299569129943848, 0.9267241358757019, 0.9331896305084229, 0.9245689511299133, 0.923491358757019, 0.9299569129943848, 0.9299569129943848, 0.9267241358757019, 0.931034505367279, 0.9288793206214905, 0.931034505367279, 0.9245689511299133, 0.9331896305084229, 0.9245689511299133, 0.9321120977401733, 0.9267241358757019, 0.9245689511299133, 0.920258641242981, 0.931034505367279, 0.9288793206214905, 0.9256465435028076, 0.9278017282485962, 0.9331896305084229, 0.9288793206214905, 0.9224137663841248, 0.9278017282485962, 0.9299569129943848, 0.9159482717514038, 0.9299569129943848, 0.9278017282485962, 0.923491358757019, 0.9321120977401733, 0.931034505367279, 0.9288793206214905, 0.931034505367279, 0.9331896305084229, 0.9213362336158752, 0.9191810488700867, 0.8286637663841248, 0.9278017282485962, 0.9299569129943848, 0.9278017282485962, 0.9245689511299133, 0.9224137663841248, 0.9278017282485962, 0.9256465435028076, 0.9267241358757019, 0.9256465435028076, 0.9288793206214905, 0.912715494632721, 0.923491358757019, 0.9267241358757019, 0.9245689511299133]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.3703 - accuracy: 0.9705"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 10s 80ms/step - loss: 0.3694 - accuracy: 0.9709 - val_loss: 1.0726 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3549 - accuracy: 0.9785 - val_loss: 1.0731 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3541 - accuracy: 0.9799 - val_loss: 1.0642 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3389 - accuracy: 0.9847 - val_loss: 1.0640 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3441 - accuracy: 0.9816 - val_loss: 1.0702 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3421 - accuracy: 0.9833 - val_loss: 1.0573 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3325 - accuracy: 0.9870 - val_loss: 1.0617 - val_accuracy: 0.4955\n","Epoch 8/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3335 - accuracy: 0.9859 - val_loss: 1.0497 - val_accuracy: 0.4966\n","Epoch 9/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3317 - accuracy: 0.9844 - val_loss: 1.0300 - val_accuracy: 0.5000\n","Epoch 10/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3379 - accuracy: 0.9816 - val_loss: 0.9923 - val_accuracy: 0.5170\n","Epoch 11/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3241 - accuracy: 0.9901 - val_loss: 0.9719 - val_accuracy: 0.5283\n","Epoch 12/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3250 - accuracy: 0.9847 - val_loss: 0.9455 - val_accuracy: 0.5532\n","Epoch 13/100\n","28/28 [==============================] - 4s 143ms/step - loss: 0.3239 - accuracy: 0.9867 - val_loss: 0.9002 - val_accuracy: 0.5871\n","Epoch 14/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3287 - accuracy: 0.9847 - val_loss: 0.8052 - val_accuracy: 0.6663\n","Epoch 15/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3211 - accuracy: 0.9878 - val_loss: 0.6823 - val_accuracy: 0.8043\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3219 - accuracy: 0.9859 - val_loss: 0.7129 - val_accuracy: 0.7692\n","Epoch 17/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.3139 - accuracy: 0.9898 - val_loss: 0.5700 - val_accuracy: 0.8869\n","Epoch 18/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.3150 - accuracy: 0.9909 - val_loss: 0.5373 - val_accuracy: 0.9072\n","Epoch 19/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3075 - accuracy: 0.9926 - val_loss: 0.5547 - val_accuracy: 0.8846\n","Epoch 20/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.3128 - accuracy: 0.9907 - val_loss: 0.4908 - val_accuracy: 0.9186\n","Epoch 21/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3088 - accuracy: 0.9918 - val_loss: 0.5050 - val_accuracy: 0.9095\n","Epoch 22/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.3057 - accuracy: 0.9924 - val_loss: 0.4848 - val_accuracy: 0.9152\n","Epoch 23/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3083 - accuracy: 0.9907 - val_loss: 0.4725 - val_accuracy: 0.9197\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3062 - accuracy: 0.9909 - val_loss: 0.4879 - val_accuracy: 0.9118\n","Epoch 25/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3060 - accuracy: 0.9907 - val_loss: 0.4724 - val_accuracy: 0.9231\n","Epoch 26/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3193 - accuracy: 0.9827 - val_loss: 0.5071 - val_accuracy: 0.9061\n","Epoch 27/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3065 - accuracy: 0.9904 - val_loss: 0.4889 - val_accuracy: 0.9219\n","Epoch 28/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2960 - accuracy: 0.9938 - val_loss: 0.4977 - val_accuracy: 0.9174\n","Epoch 29/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3038 - accuracy: 0.9912 - val_loss: 0.5020 - val_accuracy: 0.9186\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2985 - accuracy: 0.9929 - val_loss: 0.5176 - val_accuracy: 0.9163\n","Epoch 31/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2959 - accuracy: 0.9921 - val_loss: 0.5016 - val_accuracy: 0.9265\n","Epoch 32/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2926 - accuracy: 0.9938 - val_loss: 0.5093 - val_accuracy: 0.9253\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2959 - accuracy: 0.9935 - val_loss: 0.5499 - val_accuracy: 0.9016\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2926 - accuracy: 0.9929 - val_loss: 0.5147 - val_accuracy: 0.9208\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2929 - accuracy: 0.9921 - val_loss: 0.5160 - val_accuracy: 0.9219\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2913 - accuracy: 0.9921 - val_loss: 0.5766 - val_accuracy: 0.9061\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2987 - accuracy: 0.9904 - val_loss: 0.7366 - val_accuracy: 0.8778\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3012 - accuracy: 0.9887 - val_loss: 0.5369 - val_accuracy: 0.9129\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2856 - accuracy: 0.9952 - val_loss: 0.5355 - val_accuracy: 0.9152\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2854 - accuracy: 0.9952 - val_loss: 0.6319 - val_accuracy: 0.8925\n","Epoch 41/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2885 - accuracy: 0.9943 - val_loss: 0.5279 - val_accuracy: 0.9163\n","Epoch 42/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2804 - accuracy: 0.9966 - val_loss: 0.5708 - val_accuracy: 0.9084\n","Epoch 43/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2809 - accuracy: 0.9952 - val_loss: 0.5306 - val_accuracy: 0.9163\n","Epoch 44/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2841 - accuracy: 0.9943 - val_loss: 0.5272 - val_accuracy: 0.9186\n","Epoch 45/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2812 - accuracy: 0.9955 - val_loss: 0.5647 - val_accuracy: 0.9118\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2794 - accuracy: 0.9963 - val_loss: 0.5469 - val_accuracy: 0.9095\n","Epoch 47/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2917 - accuracy: 0.9907 - val_loss: 0.5326 - val_accuracy: 0.9174\n","Epoch 48/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2813 - accuracy: 0.9938 - val_loss: 0.5229 - val_accuracy: 0.9197\n","Epoch 49/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2748 - accuracy: 0.9969 - val_loss: 0.5313 - val_accuracy: 0.9186\n","Epoch 50/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2770 - accuracy: 0.9955 - val_loss: 0.5615 - val_accuracy: 0.9140\n","Epoch 51/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.2762 - accuracy: 0.9960 - val_loss: 0.5377 - val_accuracy: 0.9208\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2737 - accuracy: 0.9969 - val_loss: 0.5323 - val_accuracy: 0.9163\n","Epoch 53/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2736 - accuracy: 0.9960 - val_loss: 0.5346 - val_accuracy: 0.9163\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2716 - accuracy: 0.9966 - val_loss: 0.5355 - val_accuracy: 0.9129\n","Epoch 55/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2695 - accuracy: 0.9977 - val_loss: 0.5416 - val_accuracy: 0.9174\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2702 - accuracy: 0.9960 - val_loss: 0.5574 - val_accuracy: 0.9050\n","Epoch 57/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2732 - accuracy: 0.9946 - val_loss: 0.5416 - val_accuracy: 0.9129\n","Epoch 58/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2725 - accuracy: 0.9952 - val_loss: 0.6283 - val_accuracy: 0.8993\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2732 - accuracy: 0.9949 - val_loss: 0.5627 - val_accuracy: 0.9140\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2705 - accuracy: 0.9960 - val_loss: 0.5407 - val_accuracy: 0.9174\n","Epoch 61/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2714 - accuracy: 0.9949 - val_loss: 0.7227 - val_accuracy: 0.8857\n","Epoch 62/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2706 - accuracy: 0.9941 - val_loss: 0.6342 - val_accuracy: 0.8993\n","Epoch 63/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2675 - accuracy: 0.9969 - val_loss: 0.5605 - val_accuracy: 0.9084\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2640 - accuracy: 0.9972 - val_loss: 0.5425 - val_accuracy: 0.9140\n","Epoch 65/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2700 - accuracy: 0.9935 - val_loss: 0.5612 - val_accuracy: 0.9061\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2619 - accuracy: 0.9983 - val_loss: 0.5963 - val_accuracy: 0.9061\n","Epoch 67/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2685 - accuracy: 0.9943 - val_loss: 0.5726 - val_accuracy: 0.9061\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2645 - accuracy: 0.9955 - val_loss: 0.6372 - val_accuracy: 0.8937\n","Epoch 69/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2672 - accuracy: 0.9941 - val_loss: 0.5744 - val_accuracy: 0.9061\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2611 - accuracy: 0.9969 - val_loss: 0.5792 - val_accuracy: 0.9106\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2628 - accuracy: 0.9952 - val_loss: 0.5763 - val_accuracy: 0.9106\n","Epoch 72/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2615 - accuracy: 0.9960 - val_loss: 0.5550 - val_accuracy: 0.9129\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2558 - accuracy: 0.9992 - val_loss: 0.5553 - val_accuracy: 0.9129\n","Epoch 74/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2576 - accuracy: 0.9975 - val_loss: 0.5567 - val_accuracy: 0.9095\n","Epoch 75/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2546 - accuracy: 0.9977 - val_loss: 0.5815 - val_accuracy: 0.9038\n","Epoch 76/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2568 - accuracy: 0.9972 - val_loss: 0.5556 - val_accuracy: 0.9129\n","Epoch 77/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2536 - accuracy: 0.9989 - val_loss: 0.5576 - val_accuracy: 0.9050\n","Epoch 78/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2513 - accuracy: 1.0000 - val_loss: 0.5669 - val_accuracy: 0.9016\n","Epoch 79/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2518 - accuracy: 0.9989 - val_loss: 0.5634 - val_accuracy: 0.9005\n","Epoch 80/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2519 - accuracy: 0.9983 - val_loss: 0.5616 - val_accuracy: 0.9118\n","Epoch 81/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2551 - accuracy: 0.9969 - val_loss: 0.5614 - val_accuracy: 0.9118\n","Epoch 82/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2527 - accuracy: 0.9966 - val_loss: 0.5679 - val_accuracy: 0.9072\n","Epoch 83/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2591 - accuracy: 0.9946 - val_loss: 0.5753 - val_accuracy: 0.8993\n","Epoch 84/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2628 - accuracy: 0.9918 - val_loss: 0.5969 - val_accuracy: 0.8959\n","Epoch 85/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2518 - accuracy: 0.9955 - val_loss: 0.5750 - val_accuracy: 0.9050\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2471 - accuracy: 0.9986 - val_loss: 0.5704 - val_accuracy: 0.9005\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2506 - accuracy: 0.9966 - val_loss: 0.9015 - val_accuracy: 0.8563\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2656 - accuracy: 0.9909 - val_loss: 0.5946 - val_accuracy: 0.9050\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2488 - accuracy: 0.9969 - val_loss: 0.6281 - val_accuracy: 0.9027\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2448 - accuracy: 0.9992 - val_loss: 0.5661 - val_accuracy: 0.9027\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2447 - accuracy: 0.9980 - val_loss: 0.5804 - val_accuracy: 0.9016\n","Epoch 92/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2456 - accuracy: 0.9983 - val_loss: 0.5639 - val_accuracy: 0.9095\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2431 - accuracy: 0.9986 - val_loss: 0.6644 - val_accuracy: 0.9016\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2430 - accuracy: 0.9977 - val_loss: 0.5911 - val_accuracy: 0.9061\n","Epoch 95/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2422 - accuracy: 0.9980 - val_loss: 0.5663 - val_accuracy: 0.9106\n","Epoch 96/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2434 - accuracy: 0.9983 - val_loss: 0.5634 - val_accuracy: 0.9084\n","Epoch 97/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2432 - accuracy: 0.9966 - val_loss: 0.5877 - val_accuracy: 0.9050\n","Epoch 98/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2418 - accuracy: 0.9980 - val_loss: 0.6237 - val_accuracy: 0.9005\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2379 - accuracy: 0.9989 - val_loss: 0.5934 - val_accuracy: 0.8959\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2385 - accuracy: 0.9989 - val_loss: 0.5758 - val_accuracy: 0.9027\n","{'loss': [0.3693736791610718, 0.3548687696456909, 0.35409384965896606, 0.33887484669685364, 0.34414181113243103, 0.342146635055542, 0.3324999511241913, 0.333539754152298, 0.33166977763175964, 0.3379051387310028, 0.3240993618965149, 0.3250385522842407, 0.3238830864429474, 0.3286934792995453, 0.32113757729530334, 0.32189732789993286, 0.31388604640960693, 0.3149626553058624, 0.307456910610199, 0.31278014183044434, 0.3088322579860687, 0.3056626319885254, 0.3082745373249054, 0.30624276399612427, 0.30603736639022827, 0.3193163573741913, 0.3064926862716675, 0.29598256945610046, 0.3037719130516052, 0.29847031831741333, 0.2959442734718323, 0.29264143109321594, 0.2958826720714569, 0.2926494777202606, 0.2928939759731293, 0.29127171635627747, 0.29870733618736267, 0.30121371150016785, 0.28562426567077637, 0.2853565216064453, 0.28847426176071167, 0.2804296016693115, 0.2808576226234436, 0.28410884737968445, 0.28119075298309326, 0.279359370470047, 0.2917470932006836, 0.28131771087646484, 0.27475762367248535, 0.27697739005088806, 0.2761509418487549, 0.2736937701702118, 0.2736486792564392, 0.27158617973327637, 0.2694583237171173, 0.2701563537120819, 0.27315229177474976, 0.2725367844104767, 0.2731879949569702, 0.27050113677978516, 0.2714167833328247, 0.2705972194671631, 0.2675166130065918, 0.26402777433395386, 0.27001315355300903, 0.2618789076805115, 0.26850780844688416, 0.2645384669303894, 0.26723921298980713, 0.2611267566680908, 0.26281270384788513, 0.26151788234710693, 0.2558024227619171, 0.2576112747192383, 0.25457966327667236, 0.2568041980266571, 0.25356045365333557, 0.251250296831131, 0.2518068850040436, 0.25186118483543396, 0.25510215759277344, 0.2526973783969879, 0.25912365317344666, 0.2628024220466614, 0.2518298923969269, 0.24707910418510437, 0.25061485171318054, 0.2656051516532898, 0.24881857633590698, 0.24479162693023682, 0.24470695853233337, 0.24560688436031342, 0.24312330782413483, 0.24295228719711304, 0.24221080541610718, 0.24337312579154968, 0.24322563409805298, 0.2417597770690918, 0.23792293667793274, 0.2384922206401825], 'accuracy': [0.9708545804023743, 0.9784946441650391, 0.9799094796180725, 0.9847198724746704, 0.9816072583198547, 0.983305037021637, 0.986983597278595, 0.9858517050743103, 0.9844368696212769, 0.9816072583198547, 0.9900962114334106, 0.9847198724746704, 0.9867005944252014, 0.9847198724746704, 0.9878324866294861, 0.9858517050743103, 0.9898132681846619, 0.9909451007843018, 0.992642879486084, 0.990662157535553, 0.9917939901351929, 0.9923599362373352, 0.990662157535553, 0.9909451007843018, 0.990662157535553, 0.9827390909194946, 0.9903791546821594, 0.9937747716903687, 0.9912280440330505, 0.9929258823394775, 0.9920769929885864, 0.9937747716903687, 0.9934917688369751, 0.9929258823394775, 0.9920769929885864, 0.9920769929885864, 0.9903791546821594, 0.9886813759803772, 0.9951896071434021, 0.9951896071434021, 0.994340717792511, 0.9966044425964355, 0.9951896071434021, 0.994340717792511, 0.9954725503921509, 0.996321439743042, 0.990662157535553, 0.9937747716903687, 0.9968873858451843, 0.9954725503921509, 0.9960384964942932, 0.9968873858451843, 0.9960384964942932, 0.9966044425964355, 0.9977362751960754, 0.9960384964942932, 0.9946236610412598, 0.9951896071434021, 0.9949066042900085, 0.9960384964942932, 0.9949066042900085, 0.9940577149391174, 0.9968873858451843, 0.9971703290939331, 0.9934917688369751, 0.9983022212982178, 0.994340717792511, 0.9954725503921509, 0.9940577149391174, 0.9968873858451843, 0.9951896071434021, 0.9960384964942932, 0.9991511106491089, 0.9974533319473267, 0.9977362751960754, 0.9971703290939331, 0.9988681674003601, 1.0, 0.9988681674003601, 0.9983022212982178, 0.9968873858451843, 0.9966044425964355, 0.9946236610412598, 0.9917939901351929, 0.9954725503921509, 0.9985851645469666, 0.9966044425964355, 0.9909451007843018, 0.9968873858451843, 0.9991511106491089, 0.9980192184448242, 0.9983022212982178, 0.9985851645469666, 0.9977362751960754, 0.9980192184448242, 0.9983022212982178, 0.9966044425964355, 0.9980192184448242, 0.9988681674003601, 0.9988681674003601], 'val_loss': [1.0725574493408203, 1.073091983795166, 1.0642352104187012, 1.063995361328125, 1.0701857805252075, 1.0572882890701294, 1.0616929531097412, 1.0496625900268555, 1.0299557447433472, 0.9923079013824463, 0.9718802571296692, 0.9455163478851318, 0.9001781344413757, 0.8052015900611877, 0.6823016405105591, 0.7129205465316772, 0.5700144171714783, 0.5373067855834961, 0.5546970367431641, 0.4908057451248169, 0.5049797296524048, 0.4847649931907654, 0.47247859835624695, 0.4878681004047394, 0.4723610281944275, 0.5071165561676025, 0.4888896048069, 0.49766308069229126, 0.5019707083702087, 0.5176047682762146, 0.5015966892242432, 0.5092578530311584, 0.5498625636100769, 0.5146690607070923, 0.5160399675369263, 0.5765929818153381, 0.7365512251853943, 0.536882758140564, 0.5354909896850586, 0.6319196820259094, 0.5279446840286255, 0.5707598328590393, 0.5306416749954224, 0.527202308177948, 0.5646501779556274, 0.5469335913658142, 0.5325652360916138, 0.5229079723358154, 0.5312630534172058, 0.5614990592002869, 0.5377197265625, 0.5322531461715698, 0.5346028208732605, 0.5354717969894409, 0.5416103601455688, 0.5574306845664978, 0.5416367053985596, 0.6283320188522339, 0.5626590847969055, 0.5407359004020691, 0.7227491140365601, 0.6341570019721985, 0.5605388283729553, 0.5424703359603882, 0.5612148642539978, 0.596336305141449, 0.5725687146186829, 0.6371739506721497, 0.5743950009346008, 0.5792476534843445, 0.5763350129127502, 0.5549573302268982, 0.5553038716316223, 0.5567111968994141, 0.5814809203147888, 0.5555524230003357, 0.5575538277626038, 0.5668601393699646, 0.5633846521377563, 0.5616220235824585, 0.5614461898803711, 0.5678677558898926, 0.5752751231193542, 0.5969448089599609, 0.5749830603599548, 0.5704032778739929, 0.9015330076217651, 0.5946332216262817, 0.6281041502952576, 0.566054105758667, 0.5804455876350403, 0.5639017820358276, 0.664375901222229, 0.5911151170730591, 0.5662763714790344, 0.5634189248085022, 0.5877063274383545, 0.6236692667007446, 0.5934146642684937, 0.5757884383201599], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.5, 0.516968309879303, 0.5282805562019348, 0.5531674027442932, 0.587104082107544, 0.6662895679473877, 0.8042986392974854, 0.7692307829856873, 0.8868778347969055, 0.9072397947311401, 0.8846153616905212, 0.918552041053772, 0.9095022678375244, 0.9151583909988403, 0.9196832776069641, 0.9117646813392639, 0.9230769276618958, 0.9061086177825928, 0.9219456911087036, 0.9174208045005798, 0.918552041053772, 0.9162895679473877, 0.9264705777168274, 0.9253393411636353, 0.901583731174469, 0.9208144545555115, 0.9219456911087036, 0.9061086177825928, 0.877828061580658, 0.912895917892456, 0.9151583909988403, 0.8925339579582214, 0.9162895679473877, 0.9083710312843323, 0.9162895679473877, 0.918552041053772, 0.9117646813392639, 0.9095022678375244, 0.9174208045005798, 0.9196832776069641, 0.918552041053772, 0.9140271544456482, 0.9208144545555115, 0.9162895679473877, 0.9162895679473877, 0.912895917892456, 0.9174208045005798, 0.9049773812294006, 0.912895917892456, 0.8993212580680847, 0.9140271544456482, 0.9174208045005798, 0.8857465982437134, 0.8993212580680847, 0.9083710312843323, 0.9140271544456482, 0.9061086177825928, 0.9061086177825928, 0.9061086177825928, 0.8936651349067688, 0.9061086177825928, 0.9106335043907166, 0.9106335043907166, 0.912895917892456, 0.912895917892456, 0.9095022678375244, 0.9038461446762085, 0.912895917892456, 0.9049773812294006, 0.901583731174469, 0.9004524946212769, 0.9117646813392639, 0.9117646813392639, 0.9072397947311401, 0.8993212580680847, 0.8959276080131531, 0.9049773812294006, 0.9004524946212769, 0.8563348650932312, 0.9049773812294006, 0.9027149081230164, 0.9027149081230164, 0.901583731174469, 0.9095022678375244, 0.901583731174469, 0.9061086177825928, 0.9106335043907166, 0.9083710312843323, 0.9049773812294006, 0.9004524946212769, 0.8959276080131531, 0.9027149081230164]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.3593 - accuracy: 0.9738"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 9s 56ms/step - loss: 0.3571 - accuracy: 0.9739 - val_loss: 1.0780 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3510 - accuracy: 0.9767 - val_loss: 1.0773 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3509 - accuracy: 0.9793 - val_loss: 1.0740 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3409 - accuracy: 0.9819 - val_loss: 1.0673 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3351 - accuracy: 0.9850 - val_loss: 1.0712 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3345 - accuracy: 0.9832 - val_loss: 1.0688 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3305 - accuracy: 0.9850 - val_loss: 1.0720 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.3309 - accuracy: 0.9842 - val_loss: 1.0654 - val_accuracy: 0.4866\n","Epoch 9/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3277 - accuracy: 0.9871 - val_loss: 1.0083 - val_accuracy: 0.5031\n","Epoch 10/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3297 - accuracy: 0.9853 - val_loss: 0.8998 - val_accuracy: 0.5723\n","Epoch 11/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3440 - accuracy: 0.9788 - val_loss: 0.9135 - val_accuracy: 0.5671\n","Epoch 12/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3249 - accuracy: 0.9868 - val_loss: 0.8820 - val_accuracy: 0.6074\n","Epoch 13/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.3307 - accuracy: 0.9837 - val_loss: 0.7718 - val_accuracy: 0.7076\n","Epoch 14/100\n","31/31 [==============================] - 4s 132ms/step - loss: 0.3186 - accuracy: 0.9894 - val_loss: 0.6581 - val_accuracy: 0.8264\n","Epoch 15/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.3213 - accuracy: 0.9891 - val_loss: 0.5639 - val_accuracy: 0.8957\n","Epoch 16/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3345 - accuracy: 0.9791 - val_loss: 0.7703 - val_accuracy: 0.7335\n","Epoch 17/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3203 - accuracy: 0.9881 - val_loss: 0.6755 - val_accuracy: 0.8089\n","Epoch 18/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3221 - accuracy: 0.9850 - val_loss: 0.6300 - val_accuracy: 0.8388\n","Epoch 19/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3148 - accuracy: 0.9889 - val_loss: 0.5225 - val_accuracy: 0.8977\n","Epoch 20/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.3154 - accuracy: 0.9886 - val_loss: 0.5063 - val_accuracy: 0.9050\n","Epoch 21/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3164 - accuracy: 0.9873 - val_loss: 0.6421 - val_accuracy: 0.8440\n","Epoch 22/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3125 - accuracy: 0.9894 - val_loss: 0.4957 - val_accuracy: 0.9153\n","Epoch 23/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3281 - accuracy: 0.9817 - val_loss: 0.6131 - val_accuracy: 0.8771\n","Epoch 24/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3205 - accuracy: 0.9866 - val_loss: 0.7310 - val_accuracy: 0.8430\n","Epoch 25/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3320 - accuracy: 0.9806 - val_loss: 0.6050 - val_accuracy: 0.8884\n","Epoch 26/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3154 - accuracy: 0.9840 - val_loss: 0.5351 - val_accuracy: 0.9091\n","Epoch 27/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3008 - accuracy: 0.9938 - val_loss: 0.5429 - val_accuracy: 0.9081\n","Epoch 28/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2983 - accuracy: 0.9953 - val_loss: 0.5513 - val_accuracy: 0.9091\n","Epoch 29/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2994 - accuracy: 0.9933 - val_loss: 0.5482 - val_accuracy: 0.9132\n","Epoch 30/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2994 - accuracy: 0.9928 - val_loss: 0.5780 - val_accuracy: 0.9101\n","Epoch 31/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2991 - accuracy: 0.9928 - val_loss: 0.5719 - val_accuracy: 0.9101\n","Epoch 32/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3067 - accuracy: 0.9884 - val_loss: 0.5625 - val_accuracy: 0.9143\n","Epoch 33/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2949 - accuracy: 0.9946 - val_loss: 0.5664 - val_accuracy: 0.9060\n","Epoch 34/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.2940 - accuracy: 0.9948 - val_loss: 0.5677 - val_accuracy: 0.9112\n","Epoch 35/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2967 - accuracy: 0.9925 - val_loss: 0.5852 - val_accuracy: 0.9091\n","Epoch 36/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2950 - accuracy: 0.9943 - val_loss: 0.5743 - val_accuracy: 0.9143\n","Epoch 37/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3077 - accuracy: 0.9868 - val_loss: 0.5890 - val_accuracy: 0.9091\n","Epoch 38/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3024 - accuracy: 0.9876 - val_loss: 0.5717 - val_accuracy: 0.9122\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2908 - accuracy: 0.9953 - val_loss: 0.5864 - val_accuracy: 0.9122\n","Epoch 40/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2976 - accuracy: 0.9915 - val_loss: 0.5952 - val_accuracy: 0.9008\n","Epoch 41/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2873 - accuracy: 0.9953 - val_loss: 0.5683 - val_accuracy: 0.9122\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2924 - accuracy: 0.9915 - val_loss: 0.5758 - val_accuracy: 0.9122\n","Epoch 43/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2830 - accuracy: 0.9966 - val_loss: 0.5719 - val_accuracy: 0.9132\n","Epoch 44/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2837 - accuracy: 0.9956 - val_loss: 0.5741 - val_accuracy: 0.9070\n","Epoch 45/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2817 - accuracy: 0.9961 - val_loss: 0.5728 - val_accuracy: 0.9132\n","Epoch 46/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2885 - accuracy: 0.9930 - val_loss: 0.6107 - val_accuracy: 0.9101\n","Epoch 47/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2805 - accuracy: 0.9956 - val_loss: 0.5760 - val_accuracy: 0.9122\n","Epoch 48/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2820 - accuracy: 0.9959 - val_loss: 0.6324 - val_accuracy: 0.8988\n","Epoch 49/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2798 - accuracy: 0.9959 - val_loss: 0.5903 - val_accuracy: 0.9091\n","Epoch 50/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2811 - accuracy: 0.9956 - val_loss: 0.7030 - val_accuracy: 0.8750\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2955 - accuracy: 0.9871 - val_loss: 0.5911 - val_accuracy: 0.9050\n","Epoch 52/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2792 - accuracy: 0.9946 - val_loss: 0.5988 - val_accuracy: 0.9070\n","Epoch 53/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2814 - accuracy: 0.9938 - val_loss: 0.5873 - val_accuracy: 0.9039\n","Epoch 54/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2758 - accuracy: 0.9961 - val_loss: 0.5823 - val_accuracy: 0.9143\n","Epoch 55/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2771 - accuracy: 0.9935 - val_loss: 0.5895 - val_accuracy: 0.9101\n","Epoch 56/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2765 - accuracy: 0.9946 - val_loss: 0.6015 - val_accuracy: 0.9050\n","Epoch 57/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2715 - accuracy: 0.9979 - val_loss: 0.5967 - val_accuracy: 0.9081\n","Epoch 58/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2755 - accuracy: 0.9946 - val_loss: 0.5903 - val_accuracy: 0.9081\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2719 - accuracy: 0.9959 - val_loss: 0.5900 - val_accuracy: 0.9070\n","Epoch 60/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2712 - accuracy: 0.9959 - val_loss: 0.6000 - val_accuracy: 0.9101\n","Epoch 61/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2745 - accuracy: 0.9928 - val_loss: 0.6190 - val_accuracy: 0.9060\n","Epoch 62/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2692 - accuracy: 0.9969 - val_loss: 0.5810 - val_accuracy: 0.9143\n","Epoch 63/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2746 - accuracy: 0.9933 - val_loss: 0.6007 - val_accuracy: 0.9070\n","Epoch 64/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2689 - accuracy: 0.9956 - val_loss: 0.5864 - val_accuracy: 0.9112\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2706 - accuracy: 0.9935 - val_loss: 0.6854 - val_accuracy: 0.8874\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2734 - accuracy: 0.9933 - val_loss: 0.5948 - val_accuracy: 0.9070\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2669 - accuracy: 0.9956 - val_loss: 0.5972 - val_accuracy: 0.9081\n","Epoch 68/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2745 - accuracy: 0.9910 - val_loss: 0.6691 - val_accuracy: 0.9050\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2783 - accuracy: 0.9899 - val_loss: 0.6105 - val_accuracy: 0.9081\n","Epoch 70/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2619 - accuracy: 0.9972 - val_loss: 0.6124 - val_accuracy: 0.9060\n","Epoch 71/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2662 - accuracy: 0.9946 - val_loss: 0.6432 - val_accuracy: 0.9070\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2632 - accuracy: 0.9964 - val_loss: 0.6047 - val_accuracy: 0.9039\n","Epoch 73/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2585 - accuracy: 0.9977 - val_loss: 0.6476 - val_accuracy: 0.9070\n","Epoch 74/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2623 - accuracy: 0.9959 - val_loss: 0.6109 - val_accuracy: 0.9039\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2603 - accuracy: 0.9956 - val_loss: 0.6149 - val_accuracy: 0.9060\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2551 - accuracy: 0.9979 - val_loss: 0.6095 - val_accuracy: 0.9050\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2567 - accuracy: 0.9969 - val_loss: 0.6177 - val_accuracy: 0.9081\n","Epoch 78/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2559 - accuracy: 0.9972 - val_loss: 0.6126 - val_accuracy: 0.9008\n","Epoch 79/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2556 - accuracy: 0.9969 - val_loss: 0.6188 - val_accuracy: 0.9019\n","Epoch 80/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2526 - accuracy: 0.9982 - val_loss: 0.6087 - val_accuracy: 0.9081\n","Epoch 81/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2552 - accuracy: 0.9969 - val_loss: 0.6146 - val_accuracy: 0.8998\n","Epoch 82/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2514 - accuracy: 0.9977 - val_loss: 0.6519 - val_accuracy: 0.9081\n","Epoch 83/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2518 - accuracy: 0.9979 - val_loss: 0.6161 - val_accuracy: 0.9019\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2534 - accuracy: 0.9964 - val_loss: 0.6085 - val_accuracy: 0.9060\n","Epoch 85/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2495 - accuracy: 0.9987 - val_loss: 0.6187 - val_accuracy: 0.8988\n","Epoch 86/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2512 - accuracy: 0.9972 - val_loss: 0.6247 - val_accuracy: 0.8967\n","Epoch 87/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2502 - accuracy: 0.9969 - val_loss: 0.6584 - val_accuracy: 0.9039\n","Epoch 88/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2466 - accuracy: 0.9987 - val_loss: 0.6144 - val_accuracy: 0.9060\n","Epoch 89/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2482 - accuracy: 0.9977 - val_loss: 0.6348 - val_accuracy: 0.8988\n","Epoch 90/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2590 - accuracy: 0.9928 - val_loss: 0.6326 - val_accuracy: 0.9091\n","Epoch 91/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2538 - accuracy: 0.9946 - val_loss: 0.6098 - val_accuracy: 0.9039\n","Epoch 92/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2482 - accuracy: 0.9984 - val_loss: 0.6097 - val_accuracy: 0.8988\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2427 - accuracy: 0.9987 - val_loss: 0.6055 - val_accuracy: 0.9070\n","Epoch 94/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2471 - accuracy: 0.9966 - val_loss: 0.6093 - val_accuracy: 0.9050\n","Epoch 95/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2460 - accuracy: 0.9977 - val_loss: 0.6252 - val_accuracy: 0.9070\n","Epoch 96/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2452 - accuracy: 0.9969 - val_loss: 0.5978 - val_accuracy: 0.9081\n","Epoch 97/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2447 - accuracy: 0.9969 - val_loss: 0.6198 - val_accuracy: 0.9060\n","Epoch 98/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2394 - accuracy: 0.9982 - val_loss: 0.6281 - val_accuracy: 0.8946\n","Epoch 99/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2431 - accuracy: 0.9972 - val_loss: 0.6250 - val_accuracy: 0.9101\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2397 - accuracy: 0.9979 - val_loss: 0.6612 - val_accuracy: 0.8936\n","{'loss': [0.3571215271949768, 0.35103851556777954, 0.3508671522140503, 0.34089359641075134, 0.33509811758995056, 0.33449649810791016, 0.33050382137298584, 0.3308540880680084, 0.3277038633823395, 0.3296985328197479, 0.343962699174881, 0.324937105178833, 0.33072760701179504, 0.3186233341693878, 0.32133933901786804, 0.33445611596107483, 0.32028311491012573, 0.3220899701118469, 0.31484100222587585, 0.3154102563858032, 0.31642523407936096, 0.312533438205719, 0.32811883091926575, 0.32052555680274963, 0.3320152163505554, 0.3153633773326874, 0.300801157951355, 0.29825589060783386, 0.29938194155693054, 0.29939424991607666, 0.29910799860954285, 0.306669682264328, 0.2949446737766266, 0.29403871297836304, 0.2966907322406769, 0.29497474431991577, 0.30773425102233887, 0.3024245798587799, 0.2907758057117462, 0.29757335782051086, 0.287263959646225, 0.2923597991466522, 0.28304818272590637, 0.28366801142692566, 0.28167155385017395, 0.28846800327301025, 0.2804580628871918, 0.2819533050060272, 0.2798079550266266, 0.2810504734516144, 0.29547032713890076, 0.279236376285553, 0.28136125206947327, 0.2757585942745209, 0.277059942483902, 0.2764721214771271, 0.27154138684272766, 0.2754957377910614, 0.2719375789165497, 0.27121588587760925, 0.27448731660842896, 0.2691580653190613, 0.2746208608150482, 0.2688933312892914, 0.2706027030944824, 0.27342382073402405, 0.26691868901252747, 0.27448487281799316, 0.2782721221446991, 0.26192694902420044, 0.2662065923213959, 0.2631649374961853, 0.2584780156612396, 0.2622661292552948, 0.2603186070919037, 0.2550928294658661, 0.25669482350349426, 0.2559138834476471, 0.255643755197525, 0.2525809109210968, 0.2551560699939728, 0.251377135515213, 0.2517876625061035, 0.2534016966819763, 0.24948900938034058, 0.2512366771697998, 0.25022032856941223, 0.24657133221626282, 0.24819031357765198, 0.25895214080810547, 0.25377729535102844, 0.24823646247386932, 0.24271099269390106, 0.24714694917201996, 0.24597062170505524, 0.24521933495998383, 0.24466244876384735, 0.23939330875873566, 0.24310070276260376, 0.23968090116977692], 'accuracy': [0.9739018082618713, 0.9767441749572754, 0.9793281555175781, 0.9819121360778809, 0.985012948513031, 0.9832041263580322, 0.985012948513031, 0.9842377305030823, 0.9870800971984863, 0.9852713346481323, 0.9788113832473755, 0.986821711063385, 0.9837209582328796, 0.9894056916236877, 0.9891473054885864, 0.9790697693824768, 0.9881137013435364, 0.985012948513031, 0.9888888597488403, 0.988630473613739, 0.9873384833335876, 0.9894056916236877, 0.9816537499427795, 0.9865633249282837, 0.9806201457977295, 0.983979344367981, 0.9937984347343445, 0.9953488111495972, 0.9932816624641418, 0.9927648305892944, 0.9927648305892944, 0.9883720874786377, 0.9945736527442932, 0.9948320388793945, 0.9925064444541931, 0.9943152666091919, 0.986821711063385, 0.987596869468689, 0.9953488111495972, 0.9914728403091431, 0.9953488111495972, 0.9914728403091431, 0.9966408014297485, 0.9956072568893433, 0.9961240291595459, 0.9930232763290405, 0.9956072568893433, 0.9958656430244446, 0.9958656430244446, 0.9956072568893433, 0.9870800971984863, 0.9945736527442932, 0.9937984347343445, 0.9961240291595459, 0.9935400485992432, 0.9945736527442932, 0.9979327917098999, 0.9945736527442932, 0.9958656430244446, 0.9958656430244446, 0.9927648305892944, 0.9968992471694946, 0.9932816624641418, 0.9956072568893433, 0.9935400485992432, 0.9932816624641418, 0.9956072568893433, 0.9909560680389404, 0.9899224638938904, 0.997157633304596, 0.9945736527442932, 0.9963824152946472, 0.9976744055747986, 0.9958656430244446, 0.9956072568893433, 0.9979327917098999, 0.9968992471694946, 0.997157633304596, 0.9968992471694946, 0.998191237449646, 0.9968992471694946, 0.9976744055747986, 0.9979327917098999, 0.9963824152946472, 0.9987080097198486, 0.997157633304596, 0.9968992471694946, 0.9987080097198486, 0.9976744055747986, 0.9927648305892944, 0.9945736527442932, 0.9984496235847473, 0.9987080097198486, 0.9966408014297485, 0.9976744055747986, 0.9968992471694946, 0.9968992471694946, 0.998191237449646, 0.997157633304596, 0.9979327917098999], 'val_loss': [1.0780247449874878, 1.0773301124572754, 1.0739672183990479, 1.0672773122787476, 1.071245551109314, 1.0688060522079468, 1.0720282793045044, 1.0654411315917969, 1.0082736015319824, 0.8997674584388733, 0.9134502410888672, 0.8819875121116638, 0.7718095779418945, 0.658079206943512, 0.5639161467552185, 0.7702638506889343, 0.675509512424469, 0.6299879550933838, 0.5225418210029602, 0.5062645077705383, 0.6420854330062866, 0.4956827759742737, 0.6131225228309631, 0.7309778928756714, 0.6049835085868835, 0.5351357460021973, 0.5428783893585205, 0.5513479709625244, 0.5481722950935364, 0.5780166387557983, 0.5719413161277771, 0.5624635219573975, 0.5664003491401672, 0.5676975250244141, 0.5851501226425171, 0.5742641687393188, 0.5889577865600586, 0.5717332363128662, 0.5863651633262634, 0.5952019095420837, 0.5683459043502808, 0.5757706761360168, 0.5719114542007446, 0.5740706920623779, 0.5727874040603638, 0.6106837391853333, 0.5759714245796204, 0.6324354410171509, 0.5903128981590271, 0.7029638290405273, 0.5911450982093811, 0.5987991094589233, 0.5873240828514099, 0.5823495984077454, 0.5895265340805054, 0.6015422344207764, 0.5967061519622803, 0.5903146862983704, 0.5899858474731445, 0.5999919772148132, 0.6189664602279663, 0.5810226202011108, 0.6006540060043335, 0.5864472389221191, 0.6854072213172913, 0.594841718673706, 0.5971866846084595, 0.6691367626190186, 0.6104816794395447, 0.6124488711357117, 0.6432448625564575, 0.6046776175498962, 0.6475856304168701, 0.6108672022819519, 0.614859402179718, 0.6094951033592224, 0.6177477836608887, 0.6126416921615601, 0.6187593340873718, 0.6086676716804504, 0.614588737487793, 0.6519318222999573, 0.6160637140274048, 0.6085231900215149, 0.6187166571617126, 0.6247347593307495, 0.6583534479141235, 0.6144256591796875, 0.6347882151603699, 0.6325838565826416, 0.609825074672699, 0.609691858291626, 0.6054789423942566, 0.6092993021011353, 0.6252204775810242, 0.5978297591209412, 0.6198006272315979, 0.62807297706604, 0.6249804496765137, 0.6612368226051331], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48657023906707764, 0.5030992031097412, 0.5723140239715576, 0.567148745059967, 0.6074380278587341, 0.7076446413993835, 0.8264462947845459, 0.8956611752510071, 0.7334710955619812, 0.80888432264328, 0.8388429880142212, 0.8977272510528564, 0.9049586653709412, 0.8440082669258118, 0.9152892827987671, 0.8770661354064941, 0.8429751992225647, 0.8884297609329224, 0.9090909361839294, 0.9080578684806824, 0.9090909361839294, 0.913223147392273, 0.9101239442825317, 0.9101239442825317, 0.91425621509552, 0.9059917330741882, 0.9111570119857788, 0.9090909361839294, 0.91425621509552, 0.9090909361839294, 0.9121900796890259, 0.9121900796890259, 0.9008264541625977, 0.9121900796890259, 0.9121900796890259, 0.913223147392273, 0.9070248007774353, 0.913223147392273, 0.9101239442825317, 0.9121900796890259, 0.8987603187561035, 0.9090909361839294, 0.875, 0.9049586653709412, 0.9070248007774353, 0.9039255976676941, 0.91425621509552, 0.9101239442825317, 0.9049586653709412, 0.9080578684806824, 0.9080578684806824, 0.9070248007774353, 0.9101239442825317, 0.9059917330741882, 0.91425621509552, 0.9070248007774353, 0.9111570119857788, 0.8873966932296753, 0.9070248007774353, 0.9080578684806824, 0.9049586653709412, 0.9080578684806824, 0.9059917330741882, 0.9070248007774353, 0.9039255976676941, 0.9070248007774353, 0.9039255976676941, 0.9059917330741882, 0.9049586653709412, 0.9080578684806824, 0.9008264541625977, 0.9018595218658447, 0.9080578684806824, 0.8997933864593506, 0.9080578684806824, 0.9018595218658447, 0.9059917330741882, 0.8987603187561035, 0.8966942429542542, 0.9039255976676941, 0.9059917330741882, 0.8987603187561035, 0.9090909361839294, 0.9039255976676941, 0.8987603187561035, 0.9070248007774353, 0.9049586653709412, 0.9070248007774353, 0.9080578684806824, 0.9059917330741882, 0.89462810754776, 0.9101239442825317, 0.8935950398445129]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.2812 - accuracy: 0.9849"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 8s 76ms/step - loss: 0.2812 - accuracy: 0.9849 - val_loss: 1.0587 - val_accuracy: 0.4849\n","Epoch 2/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.2603 - accuracy: 0.9908 - val_loss: 1.0576 - val_accuracy: 0.4849\n","Epoch 3/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2744 - accuracy: 0.9838 - val_loss: 1.0642 - val_accuracy: 0.4849\n","Epoch 4/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.2588 - accuracy: 0.9916 - val_loss: 1.0416 - val_accuracy: 0.4849\n","Epoch 5/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2552 - accuracy: 0.9922 - val_loss: 1.0511 - val_accuracy: 0.4849\n","Epoch 6/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2538 - accuracy: 0.9927 - val_loss: 1.0504 - val_accuracy: 0.4849\n","Epoch 7/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2484 - accuracy: 0.9941 - val_loss: 1.0448 - val_accuracy: 0.4849\n","Epoch 8/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2484 - accuracy: 0.9927 - val_loss: 1.0172 - val_accuracy: 0.4871\n","Epoch 9/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.2535 - accuracy: 0.9903 - val_loss: 0.9846 - val_accuracy: 0.4989\n","Epoch 10/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2450 - accuracy: 0.9968 - val_loss: 0.9323 - val_accuracy: 0.5226\n","Epoch 11/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.2464 - accuracy: 0.9952 - val_loss: 0.8912 - val_accuracy: 0.5528\n","Epoch 12/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2482 - accuracy: 0.9935 - val_loss: 0.7804 - val_accuracy: 0.6293\n","Epoch 13/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2472 - accuracy: 0.9938 - val_loss: 0.8041 - val_accuracy: 0.6293\n","Epoch 14/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2446 - accuracy: 0.9949 - val_loss: 0.5538 - val_accuracy: 0.8610\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2439 - accuracy: 0.9941 - val_loss: 0.5415 - val_accuracy: 0.8556\n","Epoch 16/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2454 - accuracy: 0.9941 - val_loss: 0.4909 - val_accuracy: 0.8955\n","Epoch 17/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.2401 - accuracy: 0.9962 - val_loss: 0.4635 - val_accuracy: 0.9106\n","Epoch 18/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.2399 - accuracy: 0.9954 - val_loss: 0.4277 - val_accuracy: 0.9278\n","Epoch 19/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.2357 - accuracy: 0.9970 - val_loss: 0.3908 - val_accuracy: 0.9472\n","Epoch 20/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2360 - accuracy: 0.9970 - val_loss: 0.4124 - val_accuracy: 0.9321\n","Epoch 21/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.2359 - accuracy: 0.9973 - val_loss: 0.3521 - val_accuracy: 0.9569\n","Epoch 22/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2379 - accuracy: 0.9952 - val_loss: 0.3479 - val_accuracy: 0.9504\n","Epoch 23/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2346 - accuracy: 0.9968 - val_loss: 0.3731 - val_accuracy: 0.9515\n","Epoch 24/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.2308 - accuracy: 0.9987 - val_loss: 0.3500 - val_accuracy: 0.9623\n","Epoch 25/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2324 - accuracy: 0.9981 - val_loss: 0.3543 - val_accuracy: 0.9612\n","Epoch 26/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2310 - accuracy: 0.9978 - val_loss: 0.3748 - val_accuracy: 0.9526\n","Epoch 27/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2338 - accuracy: 0.9970 - val_loss: 0.3685 - val_accuracy: 0.9440\n","Epoch 28/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2346 - accuracy: 0.9946 - val_loss: 0.4344 - val_accuracy: 0.9300\n","Epoch 29/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2347 - accuracy: 0.9949 - val_loss: 0.3680 - val_accuracy: 0.9515\n","Epoch 30/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2535 - accuracy: 0.9863 - val_loss: 0.5375 - val_accuracy: 0.8976\n","Epoch 31/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2355 - accuracy: 0.9952 - val_loss: 0.3816 - val_accuracy: 0.9483\n","Epoch 32/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2283 - accuracy: 0.9984 - val_loss: 0.4132 - val_accuracy: 0.9407\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2388 - accuracy: 0.9911 - val_loss: 0.5118 - val_accuracy: 0.9116\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2314 - accuracy: 0.9960 - val_loss: 0.3883 - val_accuracy: 0.9494\n","Epoch 35/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2336 - accuracy: 0.9943 - val_loss: 0.3789 - val_accuracy: 0.9547\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2271 - accuracy: 0.9962 - val_loss: 0.3856 - val_accuracy: 0.9526\n","Epoch 37/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2250 - accuracy: 0.9978 - val_loss: 0.3932 - val_accuracy: 0.9472\n","Epoch 38/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2227 - accuracy: 0.9992 - val_loss: 0.3786 - val_accuracy: 0.9580\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2260 - accuracy: 0.9965 - val_loss: 0.4011 - val_accuracy: 0.9440\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2259 - accuracy: 0.9973 - val_loss: 0.4018 - val_accuracy: 0.9483\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2233 - accuracy: 0.9981 - val_loss: 0.4198 - val_accuracy: 0.9397\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2301 - accuracy: 0.9952 - val_loss: 0.4173 - val_accuracy: 0.9440\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2364 - accuracy: 0.9903 - val_loss: 0.4275 - val_accuracy: 0.9461\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2214 - accuracy: 0.9987 - val_loss: 0.3771 - val_accuracy: 0.9526\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2199 - accuracy: 0.9984 - val_loss: 0.3837 - val_accuracy: 0.9558\n","Epoch 46/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2188 - accuracy: 0.9989 - val_loss: 0.3960 - val_accuracy: 0.9429\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2206 - accuracy: 0.9973 - val_loss: 0.3829 - val_accuracy: 0.9558\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2189 - accuracy: 0.9987 - val_loss: 0.3922 - val_accuracy: 0.9504\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2178 - accuracy: 0.9987 - val_loss: 0.3833 - val_accuracy: 0.9526\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2177 - accuracy: 0.9987 - val_loss: 0.4537 - val_accuracy: 0.9386\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2192 - accuracy: 0.9981 - val_loss: 0.3830 - val_accuracy: 0.9504\n","Epoch 52/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2175 - accuracy: 0.9976 - val_loss: 0.3841 - val_accuracy: 0.9504\n","Epoch 53/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2151 - accuracy: 0.9987 - val_loss: 0.3907 - val_accuracy: 0.9494\n","Epoch 54/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2150 - accuracy: 0.9989 - val_loss: 0.3828 - val_accuracy: 0.9526\n","Epoch 55/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2158 - accuracy: 0.9978 - val_loss: 0.3912 - val_accuracy: 0.9461\n","Epoch 56/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2156 - accuracy: 0.9989 - val_loss: 0.3902 - val_accuracy: 0.9526\n","Epoch 57/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2123 - accuracy: 0.9995 - val_loss: 0.3914 - val_accuracy: 0.9537\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2140 - accuracy: 0.9981 - val_loss: 0.4089 - val_accuracy: 0.9494\n","Epoch 59/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2116 - accuracy: 0.9992 - val_loss: 0.4124 - val_accuracy: 0.9504\n","Epoch 60/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2126 - accuracy: 0.9981 - val_loss: 0.3932 - val_accuracy: 0.9494\n","Epoch 61/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.2118 - accuracy: 0.9989 - val_loss: 0.3944 - val_accuracy: 0.9494\n","Epoch 62/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.2209 - accuracy: 0.9938 - val_loss: 0.4086 - val_accuracy: 0.9418\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2229 - accuracy: 0.9914 - val_loss: 0.4399 - val_accuracy: 0.9375\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2170 - accuracy: 0.9957 - val_loss: 0.3947 - val_accuracy: 0.9504\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2137 - accuracy: 0.9968 - val_loss: 0.4098 - val_accuracy: 0.9375\n","Epoch 66/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2089 - accuracy: 0.9989 - val_loss: 0.3853 - val_accuracy: 0.9472\n","Epoch 67/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2089 - accuracy: 0.9981 - val_loss: 0.3874 - val_accuracy: 0.9450\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2131 - accuracy: 0.9962 - val_loss: 0.3964 - val_accuracy: 0.9407\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2112 - accuracy: 0.9981 - val_loss: 0.4279 - val_accuracy: 0.9440\n","Epoch 70/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2064 - accuracy: 0.9997 - val_loss: 0.3938 - val_accuracy: 0.9450\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2046 - accuracy: 0.9995 - val_loss: 0.4013 - val_accuracy: 0.9483\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2052 - accuracy: 0.9989 - val_loss: 0.3870 - val_accuracy: 0.9483\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2071 - accuracy: 0.9978 - val_loss: 0.3789 - val_accuracy: 0.9483\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2053 - accuracy: 0.9981 - val_loss: 0.3889 - val_accuracy: 0.9472\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2041 - accuracy: 0.9987 - val_loss: 0.4404 - val_accuracy: 0.9353\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2063 - accuracy: 0.9978 - val_loss: 0.4009 - val_accuracy: 0.9440\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2043 - accuracy: 0.9987 - val_loss: 0.4053 - val_accuracy: 0.9483\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2021 - accuracy: 0.9987 - val_loss: 0.3940 - val_accuracy: 0.9472\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2012 - accuracy: 0.9997 - val_loss: 0.4037 - val_accuracy: 0.9472\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2012 - accuracy: 0.9992 - val_loss: 0.3993 - val_accuracy: 0.9472\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2021 - accuracy: 0.9987 - val_loss: 0.3975 - val_accuracy: 0.9494\n","Epoch 82/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2021 - accuracy: 0.9978 - val_loss: 0.3909 - val_accuracy: 0.9450\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1990 - accuracy: 0.9997 - val_loss: 0.3906 - val_accuracy: 0.9450\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2001 - accuracy: 0.9984 - val_loss: 0.4016 - val_accuracy: 0.9461\n","Epoch 85/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1987 - accuracy: 0.9984 - val_loss: 0.4108 - val_accuracy: 0.9472\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1967 - accuracy: 1.0000 - val_loss: 0.3966 - val_accuracy: 0.9461\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1974 - accuracy: 0.9987 - val_loss: 0.4065 - val_accuracy: 0.9461\n","Epoch 88/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.1981 - accuracy: 0.9989 - val_loss: 0.4368 - val_accuracy: 0.9364\n","Epoch 89/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1987 - accuracy: 0.9992 - val_loss: 0.3981 - val_accuracy: 0.9450\n","Epoch 90/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.1972 - accuracy: 0.9987 - val_loss: 0.3924 - val_accuracy: 0.9397\n","Epoch 91/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.1964 - accuracy: 0.9992 - val_loss: 0.4463 - val_accuracy: 0.9386\n","Epoch 92/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.2013 - accuracy: 0.9962 - val_loss: 0.3905 - val_accuracy: 0.9472\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.2511 - accuracy: 0.9755 - val_loss: 0.4853 - val_accuracy: 0.9278\n","Epoch 94/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3539 - accuracy: 0.9448 - val_loss: 0.6953 - val_accuracy: 0.8610\n","Epoch 95/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2067 - accuracy: 0.9954 - val_loss: 0.4090 - val_accuracy: 0.9397\n","Epoch 96/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1962 - accuracy: 0.9976 - val_loss: 0.3905 - val_accuracy: 0.9472\n","Epoch 97/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1986 - accuracy: 0.9965 - val_loss: 0.4612 - val_accuracy: 0.9224\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1965 - accuracy: 0.9981 - val_loss: 0.4124 - val_accuracy: 0.9386\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.1950 - accuracy: 0.9987 - val_loss: 0.3741 - val_accuracy: 0.9429\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.1926 - accuracy: 0.9989 - val_loss: 0.3718 - val_accuracy: 0.9483\n","{'loss': [0.28118184208869934, 0.26034292578697205, 0.27435553073883057, 0.25876957178115845, 0.25524070858955383, 0.2538125216960907, 0.24841034412384033, 0.2484390288591385, 0.25346848368644714, 0.2450202852487564, 0.24637842178344727, 0.2482365369796753, 0.2472364455461502, 0.24461859464645386, 0.24394574761390686, 0.24542246758937836, 0.24013283848762512, 0.23987330496311188, 0.23568758368492126, 0.23602905869483948, 0.23585714399814606, 0.23794542253017426, 0.23462730646133423, 0.23081190884113312, 0.2323860079050064, 0.2310168296098709, 0.2338167428970337, 0.23456823825836182, 0.23467153310775757, 0.25345492362976074, 0.23552127182483673, 0.22831709682941437, 0.2387801557779312, 0.23136243224143982, 0.23359373211860657, 0.2271040380001068, 0.22499704360961914, 0.22270764410495758, 0.22596561908721924, 0.2258715182542801, 0.2232988178730011, 0.23012278974056244, 0.23644840717315674, 0.2214474231004715, 0.21994876861572266, 0.21878157556056976, 0.22061794996261597, 0.2188621163368225, 0.21782222390174866, 0.21766561269760132, 0.21916283667087555, 0.21750472486019135, 0.21508438885211945, 0.2150130718946457, 0.2158459573984146, 0.2156229466199875, 0.21231549978256226, 0.214030459523201, 0.21161185204982758, 0.21261371672153473, 0.21176260709762573, 0.22088150680065155, 0.222922220826149, 0.217018261551857, 0.21371577680110931, 0.2089128941297531, 0.2088640183210373, 0.21308103203773499, 0.21115989983081818, 0.20643731951713562, 0.204610675573349, 0.205226868391037, 0.20710593461990356, 0.20530302822589874, 0.20411476492881775, 0.20629745721817017, 0.20429199934005737, 0.20208553969860077, 0.20122571289539337, 0.20123818516731262, 0.2021407037973404, 0.20208995044231415, 0.19900858402252197, 0.20006005465984344, 0.19872157275676727, 0.19670239090919495, 0.19742855429649353, 0.19812728464603424, 0.1986561119556427, 0.19721804559230804, 0.1964217722415924, 0.20133356750011444, 0.2510859966278076, 0.3539324700832367, 0.20667043328285217, 0.19617336988449097, 0.1986040472984314, 0.19648966193199158, 0.19500161707401276, 0.1926184594631195], 'accuracy': [0.9849137663841248, 0.990840494632721, 0.9838362336158752, 0.9916487336158752, 0.9921875, 0.9927262663841248, 0.9940732717514038, 0.9927262663841248, 0.9903017282485962, 0.9967672228813171, 0.9951508641242981, 0.993534505367279, 0.993803858757019, 0.9948814511299133, 0.9940732717514038, 0.9940732717514038, 0.9962284564971924, 0.9954202771186829, 0.9970366358757019, 0.9970366358757019, 0.9973060488700867, 0.9951508641242981, 0.9967672228813171, 0.998652994632721, 0.9981142282485962, 0.9978448152542114, 0.9970366358757019, 0.9946120977401733, 0.9948814511299133, 0.9862607717514038, 0.9951508641242981, 0.998383641242981, 0.9911099076271057, 0.9959590435028076, 0.9943426847457886, 0.9962284564971924, 0.9978448152542114, 0.9991918206214905, 0.9964978694915771, 0.9973060488700867, 0.9981142282485962, 0.9951508641242981, 0.9903017282485962, 0.998652994632721, 0.998383641242981, 0.9989224076271057, 0.9973060488700867, 0.998652994632721, 0.998652994632721, 0.998652994632721, 0.9981142282485962, 0.9975754022598267, 0.998652994632721, 0.9989224076271057, 0.9978448152542114, 0.9989224076271057, 0.9994612336158752, 0.9981142282485962, 0.9991918206214905, 0.9981142282485962, 0.9989224076271057, 0.993803858757019, 0.9913793206214905, 0.9956896305084229, 0.9967672228813171, 0.9989224076271057, 0.9981142282485962, 0.9962284564971924, 0.9981142282485962, 0.9997305870056152, 0.9994612336158752, 0.9989224076271057, 0.9978448152542114, 0.9981142282485962, 0.998652994632721, 0.9978448152542114, 0.998652994632721, 0.998652994632721, 0.9997305870056152, 0.9991918206214905, 0.998652994632721, 0.9978448152542114, 0.9997305870056152, 0.998383641242981, 0.998383641242981, 1.0, 0.998652994632721, 0.9989224076271057, 0.9991918206214905, 0.998652994632721, 0.9991918206214905, 0.9962284564971924, 0.9754849076271057, 0.9447737336158752, 0.9954202771186829, 0.9975754022598267, 0.9964978694915771, 0.9981142282485962, 0.998652994632721, 0.9989224076271057], 'val_loss': [1.0587412118911743, 1.0576171875, 1.0641876459121704, 1.0415997505187988, 1.0510656833648682, 1.0503569841384888, 1.0447994470596313, 1.0171551704406738, 0.9846386909484863, 0.9323077201843262, 0.8911980390548706, 0.7804433107376099, 0.80412358045578, 0.5537576079368591, 0.5414692759513855, 0.4909334182739258, 0.4634663760662079, 0.4276815950870514, 0.39075037837028503, 0.4124326705932617, 0.3520873486995697, 0.34790101647377014, 0.37313979864120483, 0.35004615783691406, 0.35434043407440186, 0.37484991550445557, 0.36852744221687317, 0.43435895442962646, 0.36802682280540466, 0.5375491976737976, 0.38159579038619995, 0.4132099449634552, 0.5117735266685486, 0.3883218467235565, 0.3788509964942932, 0.3856141269207001, 0.39323851466178894, 0.37859755754470825, 0.4011499285697937, 0.4017971158027649, 0.4198179841041565, 0.4172886908054352, 0.4275153875350952, 0.3771251142024994, 0.3836786150932312, 0.39602187275886536, 0.382904976606369, 0.39220815896987915, 0.3833469748497009, 0.45371511578559875, 0.38298213481903076, 0.3841096758842468, 0.39066430926322937, 0.3827839493751526, 0.39115631580352783, 0.3901808559894562, 0.391361802816391, 0.40891528129577637, 0.4124145805835724, 0.3932201862335205, 0.3943846523761749, 0.40855658054351807, 0.43991512060165405, 0.39465752243995667, 0.409802109003067, 0.3853158950805664, 0.38737252354621887, 0.39636701345443726, 0.427924245595932, 0.3938453793525696, 0.4012867510318756, 0.3869653344154358, 0.37885743379592896, 0.3889094293117523, 0.440385103225708, 0.40094420313835144, 0.4053176939487457, 0.3939697742462158, 0.40374937653541565, 0.3992903530597687, 0.3974609076976776, 0.39091649651527405, 0.3906456232070923, 0.401623010635376, 0.41078728437423706, 0.3965606987476349, 0.4064646065235138, 0.4367568790912628, 0.39808255434036255, 0.3923613131046295, 0.44626861810684204, 0.39050188660621643, 0.4853464365005493, 0.6952992677688599, 0.4090457260608673, 0.39052850008010864, 0.4612070620059967, 0.4124332070350647, 0.3741207420825958, 0.37175804376602173], 'val_accuracy': [0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48491379618644714, 0.48706895112991333, 0.4989224076271057, 0.5226293206214905, 0.5528017282485962, 0.6293103694915771, 0.6293103694915771, 0.860991358757019, 0.8556034564971924, 0.8954741358757019, 0.9105603694915771, 0.9278017282485962, 0.9471982717514038, 0.9321120977401733, 0.9568965435028076, 0.9504310488700867, 0.951508641242981, 0.962284505367279, 0.9612069129943848, 0.9525862336158752, 0.943965494632721, 0.9299569129943848, 0.951508641242981, 0.8976293206214905, 0.9482758641242981, 0.9407327771186829, 0.9116379022598267, 0.9493534564971924, 0.954741358757019, 0.9525862336158752, 0.9471982717514038, 0.9579741358757019, 0.943965494632721, 0.9482758641242981, 0.9396551847457886, 0.943965494632721, 0.9461206793785095, 0.9525862336158752, 0.9558189511299133, 0.9428879022598267, 0.9558189511299133, 0.9504310488700867, 0.9525862336158752, 0.9385775923728943, 0.9504310488700867, 0.9504310488700867, 0.9493534564971924, 0.9525862336158752, 0.9461206793785095, 0.9525862336158752, 0.9536637663841248, 0.9493534564971924, 0.9504310488700867, 0.9493534564971924, 0.9493534564971924, 0.9418103694915771, 0.9375, 0.9504310488700867, 0.9375, 0.9471982717514038, 0.9450430870056152, 0.9407327771186829, 0.943965494632721, 0.9450430870056152, 0.9482758641242981, 0.9482758641242981, 0.9482758641242981, 0.9471982717514038, 0.9353448152542114, 0.943965494632721, 0.9482758641242981, 0.9471982717514038, 0.9471982717514038, 0.9471982717514038, 0.9493534564971924, 0.9450430870056152, 0.9450430870056152, 0.9461206793785095, 0.9471982717514038, 0.9461206793785095, 0.9461206793785095, 0.9364224076271057, 0.9450430870056152, 0.9396551847457886, 0.9385775923728943, 0.9471982717514038, 0.9278017282485962, 0.860991358757019, 0.9396551847457886, 0.9471982717514038, 0.9224137663841248, 0.9385775923728943, 0.9428879022598267, 0.9482758641242981]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.2930 - accuracy: 0.9800"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 9s 62ms/step - loss: 0.2896 - accuracy: 0.9813 - val_loss: 1.0543 - val_accuracy: 0.4955\n","Epoch 2/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2707 - accuracy: 0.9861 - val_loss: 1.0492 - val_accuracy: 0.4955\n","Epoch 3/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2560 - accuracy: 0.9915 - val_loss: 1.0499 - val_accuracy: 0.4955\n","Epoch 4/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2618 - accuracy: 0.9907 - val_loss: 1.0458 - val_accuracy: 0.4955\n","Epoch 5/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2585 - accuracy: 0.9909 - val_loss: 1.0442 - val_accuracy: 0.4955\n","Epoch 6/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2520 - accuracy: 0.9924 - val_loss: 1.0380 - val_accuracy: 0.4955\n","Epoch 7/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2506 - accuracy: 0.9941 - val_loss: 1.0488 - val_accuracy: 0.4966\n","Epoch 8/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2641 - accuracy: 0.9861 - val_loss: 1.0522 - val_accuracy: 0.4966\n","Epoch 9/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2561 - accuracy: 0.9907 - val_loss: 1.0047 - val_accuracy: 0.5023\n","Epoch 10/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2490 - accuracy: 0.9941 - val_loss: 0.9947 - val_accuracy: 0.5113\n","Epoch 11/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.2466 - accuracy: 0.9943 - val_loss: 0.8969 - val_accuracy: 0.5475\n","Epoch 12/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.2432 - accuracy: 0.9960 - val_loss: 0.8071 - val_accuracy: 0.6120\n","Epoch 13/100\n","28/28 [==============================] - 1s 37ms/step - loss: 0.2425 - accuracy: 0.9958 - val_loss: 0.7801 - val_accuracy: 0.6391\n","Epoch 14/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.2414 - accuracy: 0.9952 - val_loss: 0.7009 - val_accuracy: 0.7195\n","Epoch 15/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2480 - accuracy: 0.9941 - val_loss: 0.7263 - val_accuracy: 0.6946\n","Epoch 16/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.2503 - accuracy: 0.9909 - val_loss: 0.6393 - val_accuracy: 0.7726\n","Epoch 17/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.2402 - accuracy: 0.9963 - val_loss: 0.4755 - val_accuracy: 0.9027\n","Epoch 18/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2407 - accuracy: 0.9960 - val_loss: 0.4939 - val_accuracy: 0.8857\n","Epoch 19/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2385 - accuracy: 0.9975 - val_loss: 0.5171 - val_accuracy: 0.8688\n","Epoch 20/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2423 - accuracy: 0.9952 - val_loss: 0.3970 - val_accuracy: 0.9321\n","Epoch 21/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2391 - accuracy: 0.9958 - val_loss: 0.4438 - val_accuracy: 0.9152\n","Epoch 22/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2357 - accuracy: 0.9977 - val_loss: 0.3872 - val_accuracy: 0.9344\n","Epoch 23/100\n","28/28 [==============================] - 1s 17ms/step - loss: 0.2351 - accuracy: 0.9972 - val_loss: 0.4097 - val_accuracy: 0.9265\n","Epoch 24/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2341 - accuracy: 0.9986 - val_loss: 0.3800 - val_accuracy: 0.9400\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2328 - accuracy: 0.9977 - val_loss: 0.4268 - val_accuracy: 0.9253\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2334 - accuracy: 0.9977 - val_loss: 0.4375 - val_accuracy: 0.9242\n","Epoch 27/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2448 - accuracy: 0.9926 - val_loss: 0.3985 - val_accuracy: 0.9412\n","Epoch 28/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2355 - accuracy: 0.9952 - val_loss: 0.4032 - val_accuracy: 0.9355\n","Epoch 29/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2343 - accuracy: 0.9958 - val_loss: 0.4118 - val_accuracy: 0.9367\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2282 - accuracy: 0.9989 - val_loss: 0.3998 - val_accuracy: 0.9400\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2313 - accuracy: 0.9972 - val_loss: 0.4453 - val_accuracy: 0.9333\n","Epoch 32/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2325 - accuracy: 0.9946 - val_loss: 0.4220 - val_accuracy: 0.9389\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2348 - accuracy: 0.9958 - val_loss: 0.5854 - val_accuracy: 0.9005\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2386 - accuracy: 0.9929 - val_loss: 0.4291 - val_accuracy: 0.9389\n","Epoch 35/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2319 - accuracy: 0.9960 - val_loss: 0.4210 - val_accuracy: 0.9389\n","Epoch 36/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2331 - accuracy: 0.9943 - val_loss: 0.4908 - val_accuracy: 0.9276\n","Epoch 37/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2259 - accuracy: 0.9986 - val_loss: 0.4753 - val_accuracy: 0.9310\n","Epoch 38/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.2240 - accuracy: 0.9989 - val_loss: 0.4271 - val_accuracy: 0.9423\n","Epoch 39/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2265 - accuracy: 0.9977 - val_loss: 0.4515 - val_accuracy: 0.9344\n","Epoch 40/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2250 - accuracy: 0.9980 - val_loss: 0.4225 - val_accuracy: 0.9412\n","Epoch 41/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2294 - accuracy: 0.9966 - val_loss: 0.4324 - val_accuracy: 0.9389\n","Epoch 42/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2305 - accuracy: 0.9949 - val_loss: 0.4402 - val_accuracy: 0.9299\n","Epoch 43/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2255 - accuracy: 0.9975 - val_loss: 0.4449 - val_accuracy: 0.9412\n","Epoch 44/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2228 - accuracy: 0.9980 - val_loss: 0.4762 - val_accuracy: 0.9310\n","Epoch 45/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2224 - accuracy: 0.9980 - val_loss: 0.4219 - val_accuracy: 0.9389\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2211 - accuracy: 0.9986 - val_loss: 0.4459 - val_accuracy: 0.9265\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2216 - accuracy: 0.9980 - val_loss: 0.4397 - val_accuracy: 0.9400\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2303 - accuracy: 0.9941 - val_loss: 0.4615 - val_accuracy: 0.9321\n","Epoch 49/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2237 - accuracy: 0.9966 - val_loss: 0.4389 - val_accuracy: 0.9310\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2181 - accuracy: 0.9986 - val_loss: 0.4959 - val_accuracy: 0.9231\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2185 - accuracy: 0.9975 - val_loss: 0.4328 - val_accuracy: 0.9389\n","Epoch 52/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2177 - accuracy: 0.9986 - val_loss: 0.4343 - val_accuracy: 0.9344\n","Epoch 53/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2163 - accuracy: 0.9992 - val_loss: 0.4383 - val_accuracy: 0.9412\n","Epoch 54/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2164 - accuracy: 0.9989 - val_loss: 0.4477 - val_accuracy: 0.9355\n","Epoch 55/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2151 - accuracy: 0.9989 - val_loss: 0.4763 - val_accuracy: 0.9242\n","Epoch 56/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2155 - accuracy: 0.9989 - val_loss: 0.4308 - val_accuracy: 0.9378\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2221 - accuracy: 0.9972 - val_loss: 0.6003 - val_accuracy: 0.9072\n","Epoch 58/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2304 - accuracy: 0.9912 - val_loss: 0.4739 - val_accuracy: 0.9344\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2152 - accuracy: 0.9977 - val_loss: 0.4349 - val_accuracy: 0.9378\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2323 - accuracy: 0.9912 - val_loss: 0.8288 - val_accuracy: 0.8643\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2959 - accuracy: 0.9723 - val_loss: 0.5692 - val_accuracy: 0.9027\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2187 - accuracy: 0.9963 - val_loss: 0.4415 - val_accuracy: 0.9265\n","Epoch 63/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.2124 - accuracy: 0.9989 - val_loss: 0.4458 - val_accuracy: 0.9344\n","Epoch 64/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2123 - accuracy: 0.9983 - val_loss: 0.4294 - val_accuracy: 0.9321\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2153 - accuracy: 0.9972 - val_loss: 0.4322 - val_accuracy: 0.9367\n","Epoch 66/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2106 - accuracy: 0.9994 - val_loss: 0.4319 - val_accuracy: 0.9378\n","Epoch 67/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2096 - accuracy: 0.9992 - val_loss: 0.4409 - val_accuracy: 0.9344\n","Epoch 68/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2100 - accuracy: 0.9994 - val_loss: 0.4302 - val_accuracy: 0.9333\n","Epoch 69/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2097 - accuracy: 0.9994 - val_loss: 0.4562 - val_accuracy: 0.9287\n","Epoch 70/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2093 - accuracy: 0.9986 - val_loss: 0.4375 - val_accuracy: 0.9389\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2121 - accuracy: 0.9969 - val_loss: 0.4357 - val_accuracy: 0.9333\n","Epoch 72/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.2076 - accuracy: 0.9997 - val_loss: 0.4331 - val_accuracy: 0.9321\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.2071 - accuracy: 0.9992 - val_loss: 0.4414 - val_accuracy: 0.9299\n","Epoch 74/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.2063 - accuracy: 1.0000 - val_loss: 0.4361 - val_accuracy: 0.9321\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2058 - accuracy: 0.9997 - val_loss: 0.4477 - val_accuracy: 0.9321\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2070 - accuracy: 0.9994 - val_loss: 0.4431 - val_accuracy: 0.9333\n","Epoch 77/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2061 - accuracy: 0.9994 - val_loss: 0.4475 - val_accuracy: 0.9231\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2054 - accuracy: 0.9992 - val_loss: 0.4405 - val_accuracy: 0.9355\n","Epoch 79/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2065 - accuracy: 0.9992 - val_loss: 0.4424 - val_accuracy: 0.9321\n","Epoch 80/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2085 - accuracy: 0.9972 - val_loss: 0.4520 - val_accuracy: 0.9299\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2038 - accuracy: 0.9992 - val_loss: 0.4518 - val_accuracy: 0.9310\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2031 - accuracy: 0.9997 - val_loss: 0.4398 - val_accuracy: 0.9310\n","Epoch 83/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2033 - accuracy: 0.9992 - val_loss: 0.4429 - val_accuracy: 0.9299\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2022 - accuracy: 0.9997 - val_loss: 0.4500 - val_accuracy: 0.9321\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2025 - accuracy: 0.9992 - val_loss: 0.4457 - val_accuracy: 0.9367\n","Epoch 86/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2010 - accuracy: 0.9994 - val_loss: 0.4440 - val_accuracy: 0.9310\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2009 - accuracy: 0.9997 - val_loss: 0.4440 - val_accuracy: 0.9310\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2000 - accuracy: 0.9994 - val_loss: 0.4421 - val_accuracy: 0.9321\n","Epoch 89/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.2007 - accuracy: 0.9997 - val_loss: 0.4453 - val_accuracy: 0.9333\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2014 - accuracy: 0.9986 - val_loss: 0.4830 - val_accuracy: 0.9208\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1999 - accuracy: 0.9994 - val_loss: 0.4520 - val_accuracy: 0.9310\n","Epoch 92/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1984 - accuracy: 1.0000 - val_loss: 0.4629 - val_accuracy: 0.9287\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1992 - accuracy: 0.9994 - val_loss: 0.4616 - val_accuracy: 0.9242\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1981 - accuracy: 0.9997 - val_loss: 0.4463 - val_accuracy: 0.9333\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.1985 - accuracy: 0.9994 - val_loss: 0.4673 - val_accuracy: 0.9253\n","Epoch 96/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1966 - accuracy: 1.0000 - val_loss: 0.4441 - val_accuracy: 0.9310\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.1973 - accuracy: 0.9992 - val_loss: 0.4749 - val_accuracy: 0.9197\n","Epoch 98/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1965 - accuracy: 0.9994 - val_loss: 0.4358 - val_accuracy: 0.9310\n","Epoch 99/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.1955 - accuracy: 0.9992 - val_loss: 0.4609 - val_accuracy: 0.9333\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.1975 - accuracy: 0.9986 - val_loss: 0.4530 - val_accuracy: 0.9276\n","{'loss': [0.28963717818260193, 0.27069956064224243, 0.2560373544692993, 0.26181134581565857, 0.25850605964660645, 0.2520422339439392, 0.25056520104408264, 0.2640717923641205, 0.2560867369174957, 0.2489703744649887, 0.2466093897819519, 0.24324312806129456, 0.242479145526886, 0.2413702756166458, 0.24795976281166077, 0.2503012418746948, 0.2402319610118866, 0.24071136116981506, 0.23847897350788116, 0.2422587126493454, 0.23906834423542023, 0.23570819199085236, 0.2350737750530243, 0.23409920930862427, 0.23275922238826752, 0.23336680233478546, 0.24477949738502502, 0.23552298545837402, 0.23431026935577393, 0.228246808052063, 0.23131489753723145, 0.2325189858675003, 0.2347778081893921, 0.23857688903808594, 0.23192158341407776, 0.23313398659229279, 0.22589395940303802, 0.2239651381969452, 0.22653576731681824, 0.22497054934501648, 0.22935740649700165, 0.23049931228160858, 0.22551223635673523, 0.22276869416236877, 0.22244307398796082, 0.2211267501115799, 0.22161974012851715, 0.23025688529014587, 0.22371266782283783, 0.21813662350177765, 0.21847841143608093, 0.2177085280418396, 0.21625319123268127, 0.21638187766075134, 0.21509914100170135, 0.21551968157291412, 0.222087100148201, 0.23044650256633759, 0.21519401669502258, 0.2323300987482071, 0.29585254192352295, 0.21865102648735046, 0.21243423223495483, 0.21234387159347534, 0.2153203934431076, 0.21056252717971802, 0.20964829623699188, 0.2099737823009491, 0.2096763551235199, 0.209347203373909, 0.2121226191520691, 0.2076464593410492, 0.20706689357757568, 0.20631125569343567, 0.20580258965492249, 0.2069898098707199, 0.20607693493366241, 0.2054339200258255, 0.20651096105575562, 0.20849131047725677, 0.20380279421806335, 0.2031324952840805, 0.20331516861915588, 0.202156662940979, 0.2024788111448288, 0.2010447084903717, 0.20094424486160278, 0.1999892294406891, 0.2006557285785675, 0.2013930380344391, 0.19989748299121857, 0.19837069511413574, 0.19919906556606293, 0.19808702170848846, 0.19851405918598175, 0.19655875861644745, 0.1972634196281433, 0.1964550018310547, 0.19547657668590546, 0.19750218093395233], 'accuracy': [0.9813242554664612, 0.9861347079277039, 0.9915110468864441, 0.990662157535553, 0.9909451007843018, 0.9923599362373352, 0.9940577149391174, 0.9861347079277039, 0.990662157535553, 0.9940577149391174, 0.994340717792511, 0.9960384964942932, 0.9957554936408997, 0.9951896071434021, 0.9940577149391174, 0.9909451007843018, 0.996321439743042, 0.9960384964942932, 0.9974533319473267, 0.9951896071434021, 0.9957554936408997, 0.9977362751960754, 0.9971703290939331, 0.9985851645469666, 0.9977362751960754, 0.9977362751960754, 0.992642879486084, 0.9951896071434021, 0.9957554936408997, 0.9988681674003601, 0.9971703290939331, 0.9946236610412598, 0.9957554936408997, 0.9929258823394775, 0.9960384964942932, 0.994340717792511, 0.9985851645469666, 0.9988681674003601, 0.9977362751960754, 0.9980192184448242, 0.9966044425964355, 0.9949066042900085, 0.9974533319473267, 0.9980192184448242, 0.9980192184448242, 0.9985851645469666, 0.9980192184448242, 0.9940577149391174, 0.9966044425964355, 0.9985851645469666, 0.9974533319473267, 0.9985851645469666, 0.9991511106491089, 0.9988681674003601, 0.9988681674003601, 0.9988681674003601, 0.9971703290939331, 0.9912280440330505, 0.9977362751960754, 0.9912280440330505, 0.9722693562507629, 0.996321439743042, 0.9988681674003601, 0.9983022212982178, 0.9971703290939331, 0.9994340538978577, 0.9991511106491089, 0.9994340538978577, 0.9994340538978577, 0.9985851645469666, 0.9968873858451843, 0.9997170567512512, 0.9991511106491089, 1.0, 0.9997170567512512, 0.9994340538978577, 0.9994340538978577, 0.9991511106491089, 0.9991511106491089, 0.9971703290939331, 0.9991511106491089, 0.9997170567512512, 0.9991511106491089, 0.9997170567512512, 0.9991511106491089, 0.9994340538978577, 0.9997170567512512, 0.9994340538978577, 0.9997170567512512, 0.9985851645469666, 0.9994340538978577, 1.0, 0.9994340538978577, 0.9997170567512512, 0.9994340538978577, 1.0, 0.9991511106491089, 0.9994340538978577, 0.9991511106491089, 0.9985851645469666], 'val_loss': [1.0543280839920044, 1.0492451190948486, 1.0498861074447632, 1.0458265542984009, 1.0441999435424805, 1.0380363464355469, 1.0487768650054932, 1.0522314310073853, 1.0046576261520386, 0.9947226047515869, 0.8969364166259766, 0.8071168065071106, 0.7800542116165161, 0.7008551955223083, 0.7262882590293884, 0.6393051743507385, 0.47551050782203674, 0.49386247992515564, 0.5171234011650085, 0.3970068693161011, 0.44377970695495605, 0.38715338706970215, 0.4097113013267517, 0.3800017833709717, 0.4268454611301422, 0.43748366832733154, 0.3985433578491211, 0.4031563997268677, 0.41175150871276855, 0.3998211622238159, 0.44529375433921814, 0.4220069646835327, 0.5854155421257019, 0.4290664494037628, 0.42098110914230347, 0.4907568395137787, 0.4752947986125946, 0.4270693361759186, 0.45148923993110657, 0.42249980568885803, 0.43239107728004456, 0.4402143955230713, 0.4449014365673065, 0.47618043422698975, 0.42193275690078735, 0.44590407609939575, 0.4397486746311188, 0.461546391248703, 0.4388614296913147, 0.49594274163246155, 0.43277496099472046, 0.43427392840385437, 0.43831098079681396, 0.4477081000804901, 0.4763144552707672, 0.43079471588134766, 0.6002980470657349, 0.47394078969955444, 0.4349495470523834, 0.8288370370864868, 0.5692088007926941, 0.44147902727127075, 0.4457748532295227, 0.4294039011001587, 0.43217310309410095, 0.43193209171295166, 0.44088006019592285, 0.4302220344543457, 0.45618170499801636, 0.4374857544898987, 0.43569353222846985, 0.4331471920013428, 0.44135963916778564, 0.4360721707344055, 0.4476654529571533, 0.44307366013526917, 0.44754284620285034, 0.4404619336128235, 0.44238942861557007, 0.45201575756073, 0.451786607503891, 0.43983015418052673, 0.4429399371147156, 0.449993759393692, 0.44572901725769043, 0.44400015473365784, 0.4440327286720276, 0.44212010502815247, 0.44531938433647156, 0.4829612076282501, 0.4520494341850281, 0.462863028049469, 0.4616272747516632, 0.44627460837364197, 0.46734416484832764, 0.4440939724445343, 0.4749267101287842, 0.43581846356391907, 0.4609437882900238, 0.45301878452301025], 'val_accuracy': [0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.4954751133918762, 0.49660632014274597, 0.49660632014274597, 0.5022624731063843, 0.5113122463226318, 0.5475113391876221, 0.6119909286499023, 0.639140248298645, 0.7194570302963257, 0.6945701241493225, 0.7726244330406189, 0.9027149081230164, 0.8857465982437134, 0.8687782883644104, 0.9321267008781433, 0.9151583909988403, 0.9343891143798828, 0.9264705777168274, 0.9400452375411987, 0.9253393411636353, 0.9242081642150879, 0.9411764740943909, 0.935520350933075, 0.9366515874862671, 0.9400452375411987, 0.9332579374313354, 0.9389140009880066, 0.9004524946212769, 0.9389140009880066, 0.9389140009880066, 0.9276018142700195, 0.9309954643249512, 0.942307710647583, 0.9343891143798828, 0.9411764740943909, 0.9389140009880066, 0.929864227771759, 0.9411764740943909, 0.9309954643249512, 0.9389140009880066, 0.9264705777168274, 0.9400452375411987, 0.9321267008781433, 0.9309954643249512, 0.9230769276618958, 0.9389140009880066, 0.9343891143798828, 0.9411764740943909, 0.935520350933075, 0.9242081642150879, 0.9377828240394592, 0.9072397947311401, 0.9343891143798828, 0.9377828240394592, 0.8642534017562866, 0.9027149081230164, 0.9264705777168274, 0.9343891143798828, 0.9321267008781433, 0.9366515874862671, 0.9377828240394592, 0.9343891143798828, 0.9332579374313354, 0.9287330508232117, 0.9389140009880066, 0.9332579374313354, 0.9321267008781433, 0.929864227771759, 0.9321267008781433, 0.9321267008781433, 0.9332579374313354, 0.9230769276618958, 0.935520350933075, 0.9321267008781433, 0.929864227771759, 0.9309954643249512, 0.9309954643249512, 0.929864227771759, 0.9321267008781433, 0.9366515874862671, 0.9309954643249512, 0.9309954643249512, 0.9321267008781433, 0.9332579374313354, 0.9208144545555115, 0.9309954643249512, 0.9287330508232117, 0.9242081642150879, 0.9332579374313354, 0.9253393411636353, 0.9309954643249512, 0.9196832776069641, 0.9309954643249512, 0.9332579374313354, 0.9276018142700195]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.2877 - accuracy: 0.9791"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 8s 74ms/step - loss: 0.2848 - accuracy: 0.9804 - val_loss: 1.0581 - val_accuracy: 0.4855\n","Epoch 2/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2597 - accuracy: 0.9912 - val_loss: 1.0618 - val_accuracy: 0.4855\n","Epoch 3/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2570 - accuracy: 0.9910 - val_loss: 1.0611 - val_accuracy: 0.4855\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2560 - accuracy: 0.9915 - val_loss: 1.0602 - val_accuracy: 0.4855\n","Epoch 5/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2657 - accuracy: 0.9873 - val_loss: 1.0754 - val_accuracy: 0.4855\n","Epoch 6/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.2630 - accuracy: 0.9876 - val_loss: 1.0519 - val_accuracy: 0.4855\n","Epoch 7/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2501 - accuracy: 0.9930 - val_loss: 1.0494 - val_accuracy: 0.4855\n","Epoch 8/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2488 - accuracy: 0.9943 - val_loss: 1.0424 - val_accuracy: 0.4876\n","Epoch 9/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.2582 - accuracy: 0.9886 - val_loss: 1.0472 - val_accuracy: 0.4938\n","Epoch 10/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2481 - accuracy: 0.9941 - val_loss: 0.9464 - val_accuracy: 0.5279\n","Epoch 11/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.2436 - accuracy: 0.9961 - val_loss: 0.8115 - val_accuracy: 0.6116\n","Epoch 12/100\n","31/31 [==============================] - 1s 35ms/step - loss: 0.2430 - accuracy: 0.9969 - val_loss: 0.7537 - val_accuracy: 0.6612\n","Epoch 13/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.2496 - accuracy: 0.9938 - val_loss: 0.7590 - val_accuracy: 0.6746\n","Epoch 14/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2463 - accuracy: 0.9941 - val_loss: 0.6853 - val_accuracy: 0.7459\n","Epoch 15/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.2427 - accuracy: 0.9956 - val_loss: 0.5297 - val_accuracy: 0.8678\n","Epoch 16/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2458 - accuracy: 0.9933 - val_loss: 0.5407 - val_accuracy: 0.8564\n","Epoch 17/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2415 - accuracy: 0.9951 - val_loss: 0.4384 - val_accuracy: 0.9143\n","Epoch 18/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2374 - accuracy: 0.9972 - val_loss: 0.4584 - val_accuracy: 0.9039\n","Epoch 19/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2406 - accuracy: 0.9953 - val_loss: 0.4993 - val_accuracy: 0.8812\n","Epoch 20/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.2410 - accuracy: 0.9946 - val_loss: 0.4136 - val_accuracy: 0.9215\n","Epoch 21/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2437 - accuracy: 0.9925 - val_loss: 0.5077 - val_accuracy: 0.8936\n","Epoch 22/100\n","31/31 [==============================] - 1s 32ms/step - loss: 0.3118 - accuracy: 0.9656 - val_loss: 0.4133 - val_accuracy: 0.9329\n","Epoch 23/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2548 - accuracy: 0.9897 - val_loss: 0.4364 - val_accuracy: 0.9298\n","Epoch 24/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2382 - accuracy: 0.9948 - val_loss: 0.4315 - val_accuracy: 0.9329\n","Epoch 25/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.2354 - accuracy: 0.9977 - val_loss: 0.4323 - val_accuracy: 0.9401\n","Epoch 26/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2342 - accuracy: 0.9974 - val_loss: 0.4384 - val_accuracy: 0.9380\n","Epoch 27/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2358 - accuracy: 0.9966 - val_loss: 0.4433 - val_accuracy: 0.9380\n","Epoch 28/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2348 - accuracy: 0.9974 - val_loss: 0.4459 - val_accuracy: 0.9411\n","Epoch 29/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2327 - accuracy: 0.9984 - val_loss: 0.4564 - val_accuracy: 0.9370\n","Epoch 30/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2304 - accuracy: 0.9987 - val_loss: 0.4587 - val_accuracy: 0.9360\n","Epoch 31/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2299 - accuracy: 0.9987 - val_loss: 0.4866 - val_accuracy: 0.9225\n","Epoch 32/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2290 - accuracy: 0.9984 - val_loss: 0.4627 - val_accuracy: 0.9349\n","Epoch 33/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2350 - accuracy: 0.9956 - val_loss: 0.5091 - val_accuracy: 0.9298\n","Epoch 34/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2452 - accuracy: 0.9902 - val_loss: 0.6370 - val_accuracy: 0.9019\n","Epoch 35/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2433 - accuracy: 0.9925 - val_loss: 0.4723 - val_accuracy: 0.9339\n","Epoch 36/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2388 - accuracy: 0.9948 - val_loss: 0.4845 - val_accuracy: 0.9308\n","Epoch 37/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2327 - accuracy: 0.9966 - val_loss: 0.4786 - val_accuracy: 0.9318\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2286 - accuracy: 0.9982 - val_loss: 0.4745 - val_accuracy: 0.9339\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2284 - accuracy: 0.9969 - val_loss: 0.4800 - val_accuracy: 0.9287\n","Epoch 40/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2263 - accuracy: 0.9974 - val_loss: 0.4760 - val_accuracy: 0.9349\n","Epoch 41/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2262 - accuracy: 0.9987 - val_loss: 0.4891 - val_accuracy: 0.9256\n","Epoch 42/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.2269 - accuracy: 0.9984 - val_loss: 0.4765 - val_accuracy: 0.9308\n","Epoch 43/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2230 - accuracy: 0.9990 - val_loss: 0.4779 - val_accuracy: 0.9349\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2255 - accuracy: 0.9977 - val_loss: 0.4794 - val_accuracy: 0.9370\n","Epoch 45/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2235 - accuracy: 0.9982 - val_loss: 0.5018 - val_accuracy: 0.9225\n","Epoch 46/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2267 - accuracy: 0.9974 - val_loss: 0.5554 - val_accuracy: 0.9153\n","Epoch 47/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2296 - accuracy: 0.9959 - val_loss: 0.5353 - val_accuracy: 0.9184\n","Epoch 48/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2365 - accuracy: 0.9917 - val_loss: 0.5072 - val_accuracy: 0.9246\n","Epoch 49/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2265 - accuracy: 0.9961 - val_loss: 0.5134 - val_accuracy: 0.9236\n","Epoch 50/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.2239 - accuracy: 0.9969 - val_loss: 0.5314 - val_accuracy: 0.9143\n","Epoch 51/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2263 - accuracy: 0.9961 - val_loss: 0.4998 - val_accuracy: 0.9308\n","Epoch 52/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2245 - accuracy: 0.9966 - val_loss: 0.6339 - val_accuracy: 0.9050\n","Epoch 53/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.2277 - accuracy: 0.9948 - val_loss: 0.5032 - val_accuracy: 0.9267\n","Epoch 54/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.2189 - accuracy: 0.9990 - val_loss: 0.4948 - val_accuracy: 0.9287\n","Epoch 55/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2187 - accuracy: 0.9987 - val_loss: 0.4988 - val_accuracy: 0.9329\n","Epoch 56/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2171 - accuracy: 0.9990 - val_loss: 0.4924 - val_accuracy: 0.9339\n","Epoch 57/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2166 - accuracy: 0.9995 - val_loss: 0.4944 - val_accuracy: 0.9308\n","Epoch 58/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.2199 - accuracy: 0.9982 - val_loss: 0.5302 - val_accuracy: 0.9236\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2298 - accuracy: 0.9933 - val_loss: 0.5120 - val_accuracy: 0.9287\n","Epoch 60/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2271 - accuracy: 0.9943 - val_loss: 0.4850 - val_accuracy: 0.9329\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2283 - accuracy: 0.9938 - val_loss: 0.4908 - val_accuracy: 0.9277\n","Epoch 62/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2222 - accuracy: 0.9969 - val_loss: 0.4994 - val_accuracy: 0.9308\n","Epoch 63/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2155 - accuracy: 0.9992 - val_loss: 0.4881 - val_accuracy: 0.9287\n","Epoch 64/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2143 - accuracy: 0.9995 - val_loss: 0.4903 - val_accuracy: 0.9277\n","Epoch 65/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2142 - accuracy: 0.9987 - val_loss: 0.5208 - val_accuracy: 0.9205\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2216 - accuracy: 0.9956 - val_loss: 0.5132 - val_accuracy: 0.9256\n","Epoch 67/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.2135 - accuracy: 0.9982 - val_loss: 0.4973 - val_accuracy: 0.9256\n","Epoch 68/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2185 - accuracy: 0.9966 - val_loss: 0.4996 - val_accuracy: 0.9215\n","Epoch 69/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2148 - accuracy: 0.9972 - val_loss: 0.5155 - val_accuracy: 0.9215\n","Epoch 70/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2126 - accuracy: 0.9977 - val_loss: 0.5201 - val_accuracy: 0.9184\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2108 - accuracy: 0.9990 - val_loss: 0.5095 - val_accuracy: 0.9256\n","Epoch 72/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2101 - accuracy: 0.9987 - val_loss: 0.5141 - val_accuracy: 0.9256\n","Epoch 73/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2123 - accuracy: 0.9982 - val_loss: 0.5080 - val_accuracy: 0.9236\n","Epoch 74/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2156 - accuracy: 0.9956 - val_loss: 0.5024 - val_accuracy: 0.9298\n","Epoch 75/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.2093 - accuracy: 0.9987 - val_loss: 0.4993 - val_accuracy: 0.9236\n","Epoch 76/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2099 - accuracy: 0.9982 - val_loss: 0.5109 - val_accuracy: 0.9318\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2097 - accuracy: 0.9979 - val_loss: 0.4947 - val_accuracy: 0.9287\n","Epoch 78/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.2070 - accuracy: 0.9997 - val_loss: 0.5081 - val_accuracy: 0.9267\n","Epoch 79/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2082 - accuracy: 0.9974 - val_loss: 0.5670 - val_accuracy: 0.9153\n","Epoch 80/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2102 - accuracy: 0.9969 - val_loss: 0.5013 - val_accuracy: 0.9277\n","Epoch 81/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.2112 - accuracy: 0.9961 - val_loss: 0.4919 - val_accuracy: 0.9267\n","Epoch 82/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2043 - accuracy: 0.9995 - val_loss: 0.4973 - val_accuracy: 0.9267\n","Epoch 83/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2051 - accuracy: 0.9990 - val_loss: 0.5075 - val_accuracy: 0.9246\n","Epoch 84/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2102 - accuracy: 0.9969 - val_loss: 0.5320 - val_accuracy: 0.9277\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2048 - accuracy: 0.9984 - val_loss: 0.5039 - val_accuracy: 0.9225\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2066 - accuracy: 0.9977 - val_loss: 0.5191 - val_accuracy: 0.9236\n","Epoch 87/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2030 - accuracy: 0.9992 - val_loss: 0.5725 - val_accuracy: 0.9019\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2095 - accuracy: 0.9956 - val_loss: 0.5197 - val_accuracy: 0.9153\n","Epoch 89/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2033 - accuracy: 0.9987 - val_loss: 0.5126 - val_accuracy: 0.9256\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2011 - accuracy: 0.9990 - val_loss: 0.5147 - val_accuracy: 0.9225\n","Epoch 91/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2012 - accuracy: 0.9990 - val_loss: 0.5077 - val_accuracy: 0.9246\n","Epoch 92/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2024 - accuracy: 0.9990 - val_loss: 0.5136 - val_accuracy: 0.9236\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1984 - accuracy: 0.9997 - val_loss: 0.5065 - val_accuracy: 0.9267\n","Epoch 94/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.1984 - accuracy: 0.9995 - val_loss: 0.5073 - val_accuracy: 0.9256\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.1991 - accuracy: 0.9990 - val_loss: 0.5507 - val_accuracy: 0.9215\n","Epoch 96/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2078 - accuracy: 0.9959 - val_loss: 0.4959 - val_accuracy: 0.9256\n","Epoch 97/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2036 - accuracy: 0.9961 - val_loss: 0.5551 - val_accuracy: 0.9205\n","Epoch 98/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2026 - accuracy: 0.9969 - val_loss: 0.5084 - val_accuracy: 0.9194\n","Epoch 99/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.2013 - accuracy: 0.9966 - val_loss: 0.6586 - val_accuracy: 0.8988\n","Epoch 100/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.2611 - accuracy: 0.9757 - val_loss: 0.5709 - val_accuracy: 0.9050\n","{'loss': [0.2848053276538849, 0.25966593623161316, 0.25696682929992676, 0.2559685707092285, 0.26570963859558105, 0.2630392909049988, 0.25012847781181335, 0.2487986832857132, 0.2581566274166107, 0.24812589585781097, 0.24357672035694122, 0.24299073219299316, 0.2495873123407364, 0.24629122018814087, 0.24267521500587463, 0.24579346179962158, 0.24147416651248932, 0.23738983273506165, 0.24055922031402588, 0.2409643679857254, 0.24365650117397308, 0.3117799162864685, 0.2548336684703827, 0.23815041780471802, 0.23537111282348633, 0.23415617644786835, 0.23580801486968994, 0.2347620725631714, 0.2326788604259491, 0.23035559058189392, 0.22990582883358002, 0.2290147840976715, 0.23497609794139862, 0.24523650109767914, 0.2433411031961441, 0.23881378769874573, 0.23273539543151855, 0.22855067253112793, 0.2283521294593811, 0.22627326846122742, 0.22623875737190247, 0.22685843706130981, 0.2230421006679535, 0.22548969089984894, 0.22352872788906097, 0.2267114818096161, 0.229619562625885, 0.23645290732383728, 0.22649046778678894, 0.22389578819274902, 0.2263144850730896, 0.22445566952228546, 0.22773820161819458, 0.21889802813529968, 0.21874676644802094, 0.21712671220302582, 0.2165670394897461, 0.2199258655309677, 0.22979387640953064, 0.22710514068603516, 0.2282772809267044, 0.22215209901332855, 0.2155091017484665, 0.21433939039707184, 0.21424275636672974, 0.2215975970029831, 0.21346595883369446, 0.21849192678928375, 0.21483919024467468, 0.21263837814331055, 0.21076098084449768, 0.21012306213378906, 0.21232247352600098, 0.2155589759349823, 0.2092573493719101, 0.209865540266037, 0.20968982577323914, 0.20696020126342773, 0.20820201933383942, 0.21017254889011383, 0.21121907234191895, 0.20434705913066864, 0.20508350431919098, 0.21018154919147491, 0.20481131970882416, 0.20656083524227142, 0.202971950173378, 0.20947450399398804, 0.2032690942287445, 0.20106808841228485, 0.20123670995235443, 0.20244307816028595, 0.19842129945755005, 0.19843916594982147, 0.1990933120250702, 0.20778930187225342, 0.20361755788326263, 0.2026432454586029, 0.20130878686904907, 0.26112133264541626], 'accuracy': [0.9803617596626282, 0.9912144541740417, 0.9909560680389404, 0.9914728403091431, 0.9873384833335876, 0.987596869468689, 0.9930232763290405, 0.9943152666091919, 0.988630473613739, 0.9940568208694458, 0.9961240291595459, 0.9968992471694946, 0.9937984347343445, 0.9940568208694458, 0.9956072568893433, 0.9932816624641418, 0.9950904250144958, 0.997157633304596, 0.9953488111495972, 0.9945736527442932, 0.9925064444541931, 0.9656330943107605, 0.9896640777587891, 0.9948320388793945, 0.9976744055747986, 0.9974160194396973, 0.9966408014297485, 0.9974160194396973, 0.9984496235847473, 0.9987080097198486, 0.9987080097198486, 0.9984496235847473, 0.9956072568893433, 0.9901808500289917, 0.9925064444541931, 0.9948320388793945, 0.9966408014297485, 0.998191237449646, 0.9968992471694946, 0.9974160194396973, 0.9987080097198486, 0.9984496235847473, 0.99896639585495, 0.9976744055747986, 0.998191237449646, 0.9974160194396973, 0.9958656430244446, 0.9917312860488892, 0.9961240291595459, 0.9968992471694946, 0.9961240291595459, 0.9966408014297485, 0.9948320388793945, 0.99896639585495, 0.9987080097198486, 0.99896639585495, 0.9994832277297974, 0.998191237449646, 0.9932816624641418, 0.9943152666091919, 0.9937984347343445, 0.9968992471694946, 0.9992247819900513, 0.9994832277297974, 0.9987080097198486, 0.9956072568893433, 0.998191237449646, 0.9966408014297485, 0.997157633304596, 0.9976744055747986, 0.99896639585495, 0.9987080097198486, 0.998191237449646, 0.9956072568893433, 0.9987080097198486, 0.998191237449646, 0.9979327917098999, 0.9997416138648987, 0.9974160194396973, 0.9968992471694946, 0.9961240291595459, 0.9994832277297974, 0.99896639585495, 0.9968992471694946, 0.9984496235847473, 0.9976744055747986, 0.9992247819900513, 0.9956072568893433, 0.9987080097198486, 0.99896639585495, 0.99896639585495, 0.99896639585495, 0.9997416138648987, 0.9994832277297974, 0.99896639585495, 0.9958656430244446, 0.9961240291595459, 0.9968992471694946, 0.9966408014297485, 0.9757105708122253], 'val_loss': [1.0580501556396484, 1.0618375539779663, 1.0610569715499878, 1.0601935386657715, 1.0754191875457764, 1.0519447326660156, 1.0493870973587036, 1.0423641204833984, 1.0471625328063965, 0.9463858008384705, 0.8115087747573853, 0.7536698579788208, 0.7589901089668274, 0.6853252649307251, 0.5297455191612244, 0.5406703352928162, 0.43838879466056824, 0.4584360718727112, 0.4993117153644562, 0.4136013090610504, 0.5077326893806458, 0.4132877290248871, 0.43641120195388794, 0.43147408962249756, 0.432255357503891, 0.4383879601955414, 0.4433078169822693, 0.44588908553123474, 0.4563977122306824, 0.4586825668811798, 0.4865629971027374, 0.4626971483230591, 0.5090837478637695, 0.6369667649269104, 0.47225430607795715, 0.4844546318054199, 0.478608638048172, 0.47453221678733826, 0.4800441563129425, 0.47603484988212585, 0.48906219005584717, 0.4765237271785736, 0.4779451787471771, 0.47938263416290283, 0.5017504692077637, 0.5553791522979736, 0.5353460907936096, 0.5071812868118286, 0.5134081840515137, 0.5313730239868164, 0.4998210370540619, 0.6339173913002014, 0.5031969547271729, 0.4948124289512634, 0.49881479144096375, 0.4923837184906006, 0.49436816573143005, 0.5302388072013855, 0.5120358467102051, 0.48503386974334717, 0.4907676875591278, 0.49942103028297424, 0.48813024163246155, 0.49026116728782654, 0.5208244323730469, 0.5131826996803284, 0.4972967803478241, 0.4995769262313843, 0.5154750347137451, 0.5200607180595398, 0.5094931125640869, 0.514090895652771, 0.5080041289329529, 0.5023675560951233, 0.49933576583862305, 0.5108940601348877, 0.4947018623352051, 0.5081254839897156, 0.5670458078384399, 0.501311182975769, 0.49193671345710754, 0.49726080894470215, 0.5075159668922424, 0.5319525003433228, 0.503854513168335, 0.519115686416626, 0.572546124458313, 0.5197064876556396, 0.512607753276825, 0.514687716960907, 0.5076984167098999, 0.51358562707901, 0.5065264105796814, 0.5072910189628601, 0.5506865978240967, 0.4959430396556854, 0.5551000833511353, 0.5084186792373657, 0.6586219072341919, 0.5709173679351807], 'val_accuracy': [0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.48553720116615295, 0.4876033067703247, 0.49380165338516235, 0.5278925895690918, 0.6115702390670776, 0.6611570119857788, 0.6745867729187012, 0.7458677887916565, 0.8677685856819153, 0.8564049601554871, 0.91425621509552, 0.9039255976676941, 0.8811983466148376, 0.9214876294136047, 0.8935950398445129, 0.932851254940033, 0.9297520518302917, 0.932851254940033, 0.9400826692581177, 0.9380165338516235, 0.9380165338516235, 0.94111567735672, 0.9369834661483765, 0.9359503984451294, 0.922520637512207, 0.9349173307418823, 0.9297520518302917, 0.9018595218658447, 0.93388432264328, 0.9307851195335388, 0.9318181872367859, 0.93388432264328, 0.9287189841270447, 0.9349173307418823, 0.9256198406219482, 0.9307851195335388, 0.9349173307418823, 0.9369834661483765, 0.922520637512207, 0.9152892827987671, 0.9183884263038635, 0.9245867729187012, 0.9235537052154541, 0.91425621509552, 0.9307851195335388, 0.9049586653709412, 0.9266529083251953, 0.9287189841270447, 0.932851254940033, 0.93388432264328, 0.9307851195335388, 0.9235537052154541, 0.9287189841270447, 0.932851254940033, 0.9276859760284424, 0.9307851195335388, 0.9287189841270447, 0.9276859760284424, 0.9204545617103577, 0.9256198406219482, 0.9256198406219482, 0.9214876294136047, 0.9214876294136047, 0.9183884263038635, 0.9256198406219482, 0.9256198406219482, 0.9235537052154541, 0.9297520518302917, 0.9235537052154541, 0.9318181872367859, 0.9287189841270447, 0.9266529083251953, 0.9152892827987671, 0.9276859760284424, 0.9266529083251953, 0.9266529083251953, 0.9245867729187012, 0.9276859760284424, 0.922520637512207, 0.9235537052154541, 0.9018595218658447, 0.9152892827987671, 0.9256198406219482, 0.922520637512207, 0.9245867729187012, 0.9235537052154541, 0.9266529083251953, 0.9256198406219482, 0.9214876294136047, 0.9256198406219482, 0.9204545617103577, 0.9194214940071106, 0.8987603187561035, 0.9049586653709412]}\n","32/32 [==============================] - 1s 4ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_gru"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"id":"qDOklJFjK898","executionInfo":{"status":"ok","timestamp":1717406713797,"user_tz":-360,"elapsed":0,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"7b4fd6dc-6bff-4155-baee-5fd46b7ea135"},"execution_count":19,"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"metrics_df_gru\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.054307187293480025,\n        \"min\": 0.7409638554216867,\n        \"max\": 0.9180790960451978,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.8760469011725294,\n          0.8855421686746988,\n          0.7696817420435511\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05287411713171097,\n        \"min\": 0.7362204724409449,\n        \"max\": 0.8957219251336899,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.8773109243697479,\n          0.8478260869565217,\n          0.7738095238095238\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06115539223445527,\n        \"min\": 0.751004016064257,\n        \"max\": 0.9463276836158192,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.8743718592964824,\n          0.9397590361445783,\n          0.7621440536013401\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05342012803949803,\n        \"min\": 0.7435387673956262,\n        \"max\": 0.9203296703296704,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.8758389261744967,\n          0.8914285714285715,\n          0.7679324894514769\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06115539223445527,\n        \"min\": 0.751004016064257,\n        \"max\": 0.9463276836158192,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.8743718592964824,\n          0.9397590361445783,\n          0.7621440536013401\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05969261960484854,\n        \"min\": 0.7146892655367232,\n        \"max\": 0.8898305084745762,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.8777219430485762,\n          0.8313253012048193,\n          0.7772194304857621\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10861437458696004,\n        \"min\": 0.4819277108433735,\n        \"max\": 0.8361581920903955,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7520938023450586,\n          0.7710843373493976,\n          0.5393634840871022\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"metrics_df_gru"},"text/html":["\n","  <div id=\"df-bb7ffca6-605c-4435-85a2-a703ca995849\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.769682</td>\n","      <td>0.773810</td>\n","      <td>0.762144</td>\n","      <td>0.767932</td>\n","      <td>0.762144</td>\n","      <td>0.777219</td>\n","      <td>0.539363</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.796610</td>\n","      <td>0.754854</td>\n","      <td>0.878531</td>\n","      <td>0.812010</td>\n","      <td>0.878531</td>\n","      <td>0.714689</td>\n","      <td>0.593220</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.740964</td>\n","      <td>0.736220</td>\n","      <td>0.751004</td>\n","      <td>0.743539</td>\n","      <td>0.751004</td>\n","      <td>0.730924</td>\n","      <td>0.481928</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.821608</td>\n","      <td>0.823232</td>\n","      <td>0.819095</td>\n","      <td>0.821159</td>\n","      <td>0.819095</td>\n","      <td>0.824121</td>\n","      <td>0.643216</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.855226</td>\n","      <td>0.853727</td>\n","      <td>0.857345</td>\n","      <td>0.855532</td>\n","      <td>0.857345</td>\n","      <td>0.853107</td>\n","      <td>0.710452</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.791165</td>\n","      <td>0.754386</td>\n","      <td>0.863454</td>\n","      <td>0.805243</td>\n","      <td>0.863454</td>\n","      <td>0.718876</td>\n","      <td>0.582329</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.846734</td>\n","      <td>0.826498</td>\n","      <td>0.877722</td>\n","      <td>0.851340</td>\n","      <td>0.877722</td>\n","      <td>0.815745</td>\n","      <td>0.693467</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.877825</td>\n","      <td>0.850590</td>\n","      <td>0.916667</td>\n","      <td>0.882393</td>\n","      <td>0.916667</td>\n","      <td>0.838983</td>\n","      <td>0.755650</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.863454</td>\n","      <td>0.842803</td>\n","      <td>0.893574</td>\n","      <td>0.867446</td>\n","      <td>0.893574</td>\n","      <td>0.833333</td>\n","      <td>0.726908</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.876047</td>\n","      <td>0.877311</td>\n","      <td>0.874372</td>\n","      <td>0.875839</td>\n","      <td>0.874372</td>\n","      <td>0.877722</td>\n","      <td>0.752094</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.906780</td>\n","      <td>0.887097</td>\n","      <td>0.932203</td>\n","      <td>0.909091</td>\n","      <td>0.932203</td>\n","      <td>0.881356</td>\n","      <td>0.813559</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.885542</td>\n","      <td>0.847826</td>\n","      <td>0.939759</td>\n","      <td>0.891429</td>\n","      <td>0.939759</td>\n","      <td>0.831325</td>\n","      <td>0.771084</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.892797</td>\n","      <td>0.875200</td>\n","      <td>0.916248</td>\n","      <td>0.895254</td>\n","      <td>0.916248</td>\n","      <td>0.869347</td>\n","      <td>0.785595</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.918079</td>\n","      <td>0.895722</td>\n","      <td>0.946328</td>\n","      <td>0.920330</td>\n","      <td>0.946328</td>\n","      <td>0.889831</td>\n","      <td>0.836158</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.906627</td>\n","      <td>0.879925</td>\n","      <td>0.941767</td>\n","      <td>0.909796</td>\n","      <td>0.941767</td>\n","      <td>0.871486</td>\n","      <td>0.813253</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb7ffca6-605c-4435-85a2-a703ca995849')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bb7ffca6-605c-4435-85a2-a703ca995849 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bb7ffca6-605c-4435-85a2-a703ca995849');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-49e749ab-cec2-4b33-8d91-9f1d59454227\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-49e749ab-cec2-4b33-8d91-9f1d59454227')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-49e749ab-cec2-4b33-8d91-9f1d59454227 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_1c5c9e04-2684-4eb6-8b57-dc8d7b96672e\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metrics_df_gru')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_1c5c9e04-2684-4eb6-8b57-dc8d7b96672e button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('metrics_df_gru');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["    Client  Accuracy  Precision    Recall        F1  Sensitivity  Specificity  \\\n","0        0  0.769682   0.773810  0.762144  0.767932     0.762144     0.777219   \n","1        1  0.796610   0.754854  0.878531  0.812010     0.878531     0.714689   \n","2        2  0.740964   0.736220  0.751004  0.743539     0.751004     0.730924   \n","3        0  0.821608   0.823232  0.819095  0.821159     0.819095     0.824121   \n","4        1  0.855226   0.853727  0.857345  0.855532     0.857345     0.853107   \n","5        2  0.791165   0.754386  0.863454  0.805243     0.863454     0.718876   \n","6        0  0.846734   0.826498  0.877722  0.851340     0.877722     0.815745   \n","7        1  0.877825   0.850590  0.916667  0.882393     0.916667     0.838983   \n","8        2  0.863454   0.842803  0.893574  0.867446     0.893574     0.833333   \n","9        0  0.876047   0.877311  0.874372  0.875839     0.874372     0.877722   \n","10       1  0.906780   0.887097  0.932203  0.909091     0.932203     0.881356   \n","11       2  0.885542   0.847826  0.939759  0.891429     0.939759     0.831325   \n","12       0  0.892797   0.875200  0.916248  0.895254     0.916248     0.869347   \n","13       1  0.918079   0.895722  0.946328  0.920330     0.946328     0.889831   \n","14       2  0.906627   0.879925  0.941767  0.909796     0.941767     0.871486   \n","\n","       Kappa  \n","0   0.539363  \n","1   0.593220  \n","2   0.481928  \n","3   0.643216  \n","4   0.710452  \n","5   0.582329  \n","6   0.693467  \n","7   0.755650  \n","8   0.726908  \n","9   0.752094  \n","10  0.813559  \n","11  0.771084  \n","12  0.785595  \n","13  0.836158  \n","14  0.813253  "]},"execution_count":19,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":["metrics_df_gru.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/TF Domain/GRU/TF_domain_GRU.csv', index = False)"],"metadata":{"id":"kMELNDUOLAdU","executionInfo":{"status":"ok","timestamp":1717406713678,"user_tz":-360,"elapsed":3,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"46rzR1pMNSPM"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"collapsed_sections":["VNy6-RxAKjH8"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}