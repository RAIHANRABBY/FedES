{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Mbfw8uvdftFM","executionInfo":{"status":"ok","timestamp":1726144556626,"user_tz":-360,"elapsed":2959,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sb"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"INiFJfLjgOkx","executionInfo":{"status":"ok","timestamp":1726144556627,"user_tz":-360,"elapsed":3,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"outputs":[],"source":["\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"lYo2Uq77gQSH","executionInfo":{"status":"ok","timestamp":1726144562298,"user_tz":-360,"elapsed":5673,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2a84fbba-59c5-46e4-9bbd-8784a290511d"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n"]}],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score, cross_val_predict"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"g66575_xgVzz","executionInfo":{"status":"ok","timestamp":1726144570530,"user_tz":-360,"elapsed":8237,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPool1D, Flatten, Dropout,LSTM"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25637,"status":"ok","timestamp":1726144596156,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"},"user_tz":-360},"id":"MOCNWlamfr3v","outputId":"a1149d3e-b64d-4ae1-ffc8-8619fd975d58"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"iNy9eOGMf2qO","executionInfo":{"status":"ok","timestamp":1726144598640,"user_tz":-360,"elapsed":3,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"outputs":[],"source":["# Raw_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/only data/raw_data.npz'\n","\n","Theta_data = '/content/drive/MyDrive/EEG Signal /Epileptic seizure/data/time frequency domain/RAW/Theta_merged_features.npz'\n","\n","\n","\n","# RAW = np.load(Raw_data, allow_pickle=True)  # Allow loading pickled object arrays\n","# X = RAW['X'].astype('float64')\n","# Y = RAW['Y'].astype('float64')\n","# group = RAW['Group'].astype('float64')"]},{"cell_type":"markdown","metadata":{"id":"PzeABzSyHgKg"},"source":["This is a good performing model"]},{"cell_type":"markdown","metadata":{"id":"6DhAYwXUSE9z"},"source":["# CNN-LSTM"]},{"cell_type":"code","source":["%%capture\n","# Upgrade TensorFlow and TensorFlow Addons to the latest versions\n","!pip install --upgrade tensorflow tensorflow-addons"],"metadata":{"id":"sfpszhNKHUpG","executionInfo":{"status":"ok","timestamp":1726145038944,"user_tz":-360,"elapsed":52619,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"50dah_ANSMDT"}},{"cell_type":"code","source":["!pip install tensorflow-addons==0.11.2\n","!pip install tensorflow==2.2.0\n","\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","\n","print(f\"TensorFlow version: {tf.__version__}\")\n","print(f\"TensorFlow Addons version: {tfa.__version__}\")"],"metadata":{"id":"MXnlcYCiQqid"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6WSfscS6SrQL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"id":"VvjC2xCQNHLP","colab":{"base_uri":"https://localhost:8080/","height":581},"executionInfo":{"status":"error","timestamp":1726144913878,"user_tz":-360,"elapsed":9,"user":{"displayName":"Raihan Rabby","userId":"04881462177269385890"}},"outputId":"2326c902-b61a-49c3-e9f9-c40cc2731fd7"},"outputs":[{"output_type":"error","ename":"ImportError","evalue":"cannot import name 'Tensor' from 'tensorflow.python.framework.ops' (/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-29e8c456a073>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCSVLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mFederatedData\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_addons/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Local project imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_addons/callbacks/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Additional callbacks that conform to Keras API.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_model_checkpoint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAverageModelCheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_stopping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTimeStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm_progress_bar\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTQDMProgressBar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_addons/callbacks/average_model_checkpoint.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtypeguard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypechecked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAveragedOptimizerWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_addons/optimizers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mExponentialCyclicalLearningRate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m )\n\u001b[0;32m---> 30\u001b[0;31m from tensorflow_addons.optimizers.discriminative_layer_training import (\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mMultiOptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_addons/optimizers/discriminative_layer_training.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_adapter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpack_x_y_sample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_adapter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munpack_x_y_sample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_registration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOperation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRegisterGradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_colocate_with\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_to_collection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'Tensor' from 'tensorflow.python.framework.ops' (/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(LSTM(256, return_sequences=True))\n","    model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            # opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","            opt = tfa.optimizers.SWA(opt)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","            # client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time+Frequency/Theta/CNN_LSTM/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time+Frequency/Theta/CNN_LSTM/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVURUnmYNNNg","executionInfo":{"status":"ok","timestamp":1716904751011,"user_tz":-360,"elapsed":9102,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"}},"outputId":"3b0f89ff-90fa-415b-f711-bc95dd155478"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train shape: (4640, 37, 29), Test shape: (1194, 37, 29)\n","Train shape: (4418, 37, 29), Test shape: (1416, 37, 29)\n","Train shape: (4838, 37, 29), Test shape: (996, 37, 29)\n","Train shape: (4640, 37, 29), Test shape: (1194, 37, 29)\n","Train shape: (4418, 37, 29), Test shape: (1416, 37, 29)\n","Train shape: (4838, 37, 29), Test shape: (996, 37, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 1.7037 - accuracy: 0.5131"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 26s 154ms/step - loss: 1.7035 - accuracy: 0.5151 - val_loss: 1.6983 - val_accuracy: 0.5226\n","Epoch 2/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.6930 - accuracy: 0.5547 - val_loss: 1.6881 - val_accuracy: 0.5280\n","Epoch 3/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.6824 - accuracy: 0.5679 - val_loss: 1.6780 - val_accuracy: 0.5291\n","Epoch 4/100\n","29/29 [==============================] - 1s 38ms/step - loss: 1.6718 - accuracy: 0.5539 - val_loss: 1.6679 - val_accuracy: 0.5496\n","Epoch 5/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.6610 - accuracy: 0.5490 - val_loss: 1.6580 - val_accuracy: 0.5571\n","Epoch 6/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.6498 - accuracy: 0.5501 - val_loss: 1.6481 - val_accuracy: 0.5657\n","Epoch 7/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.6385 - accuracy: 0.5523 - val_loss: 1.6382 - val_accuracy: 0.5668\n","Epoch 8/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.6273 - accuracy: 0.5474 - val_loss: 1.6283 - val_accuracy: 0.5711\n","Epoch 9/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.6162 - accuracy: 0.5550 - val_loss: 1.6185 - val_accuracy: 0.5700\n","Epoch 10/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.6063 - accuracy: 0.5630 - val_loss: 1.6086 - val_accuracy: 0.5711\n","Epoch 11/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5961 - accuracy: 0.5754 - val_loss: 1.5989 - val_accuracy: 0.5690\n","Epoch 12/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.5865 - accuracy: 0.5784 - val_loss: 1.5893 - val_accuracy: 0.5744\n","Epoch 13/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.5771 - accuracy: 0.5808 - val_loss: 1.5796 - val_accuracy: 0.5733\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5678 - accuracy: 0.5805 - val_loss: 1.5699 - val_accuracy: 0.5668\n","Epoch 15/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5584 - accuracy: 0.5792 - val_loss: 1.5604 - val_accuracy: 0.5647\n","Epoch 16/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5492 - accuracy: 0.5814 - val_loss: 1.5509 - val_accuracy: 0.5582\n","Epoch 17/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.5405 - accuracy: 0.5808 - val_loss: 1.5415 - val_accuracy: 0.5539\n","Epoch 18/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.5312 - accuracy: 0.5838 - val_loss: 1.5321 - val_accuracy: 0.5485\n","Epoch 19/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.5223 - accuracy: 0.5841 - val_loss: 1.5227 - val_accuracy: 0.5485\n","Epoch 20/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.5134 - accuracy: 0.5881 - val_loss: 1.5136 - val_accuracy: 0.5463\n","Epoch 21/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.5047 - accuracy: 0.5935 - val_loss: 1.5045 - val_accuracy: 0.5539\n","Epoch 22/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4953 - accuracy: 0.5929 - val_loss: 1.4954 - val_accuracy: 0.5571\n","Epoch 23/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.4864 - accuracy: 0.5932 - val_loss: 1.4865 - val_accuracy: 0.5593\n","Epoch 24/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.4770 - accuracy: 0.5943 - val_loss: 1.4774 - val_accuracy: 0.5679\n","Epoch 25/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.4678 - accuracy: 0.5970 - val_loss: 1.4683 - val_accuracy: 0.5657\n","Epoch 26/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.4586 - accuracy: 0.5983 - val_loss: 1.4589 - val_accuracy: 0.5754\n","Epoch 27/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.4487 - accuracy: 0.6032 - val_loss: 1.4505 - val_accuracy: 0.5733\n","Epoch 28/100\n","29/29 [==============================] - 1s 25ms/step - loss: 1.4381 - accuracy: 0.6107 - val_loss: 1.4411 - val_accuracy: 0.5830\n","Epoch 29/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.4283 - accuracy: 0.6102 - val_loss: 1.4332 - val_accuracy: 0.5841\n","Epoch 30/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.4201 - accuracy: 0.6086 - val_loss: 1.4253 - val_accuracy: 0.5884\n","Epoch 31/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4083 - accuracy: 0.6231 - val_loss: 1.4176 - val_accuracy: 0.5873\n","Epoch 32/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.4016 - accuracy: 0.6191 - val_loss: 1.4068 - val_accuracy: 0.5991\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3923 - accuracy: 0.6218 - val_loss: 1.4001 - val_accuracy: 0.5959\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3838 - accuracy: 0.6237 - val_loss: 1.3920 - val_accuracy: 0.5970\n","Epoch 35/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3758 - accuracy: 0.6261 - val_loss: 1.3857 - val_accuracy: 0.5970\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3694 - accuracy: 0.6247 - val_loss: 1.3821 - val_accuracy: 0.5970\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3617 - accuracy: 0.6202 - val_loss: 1.3724 - val_accuracy: 0.5991\n","Epoch 38/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.3536 - accuracy: 0.6255 - val_loss: 1.3662 - val_accuracy: 0.6034\n","Epoch 39/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3458 - accuracy: 0.6282 - val_loss: 1.3613 - val_accuracy: 0.6002\n","Epoch 40/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.3396 - accuracy: 0.6282 - val_loss: 1.3533 - val_accuracy: 0.6045\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3339 - accuracy: 0.6280 - val_loss: 1.3460 - val_accuracy: 0.5959\n","Epoch 42/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3251 - accuracy: 0.6263 - val_loss: 1.3464 - val_accuracy: 0.6002\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3184 - accuracy: 0.6344 - val_loss: 1.3339 - val_accuracy: 0.6024\n","Epoch 44/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.3129 - accuracy: 0.6336 - val_loss: 1.3289 - val_accuracy: 0.6024\n","Epoch 45/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.3077 - accuracy: 0.6312 - val_loss: 1.3227 - val_accuracy: 0.6013\n","Epoch 46/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.3014 - accuracy: 0.6290 - val_loss: 1.3156 - val_accuracy: 0.6045\n","Epoch 47/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.2945 - accuracy: 0.6312 - val_loss: 1.3107 - val_accuracy: 0.6056\n","Epoch 48/100\n","29/29 [==============================] - 1s 30ms/step - loss: 1.2885 - accuracy: 0.6325 - val_loss: 1.3038 - val_accuracy: 0.6088\n","Epoch 49/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2799 - accuracy: 0.6393 - val_loss: 1.2992 - val_accuracy: 0.6078\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2746 - accuracy: 0.6363 - val_loss: 1.2950 - val_accuracy: 0.5948\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2675 - accuracy: 0.6414 - val_loss: 1.2887 - val_accuracy: 0.6045\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2625 - accuracy: 0.6339 - val_loss: 1.2847 - val_accuracy: 0.5959\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2553 - accuracy: 0.6390 - val_loss: 1.2767 - val_accuracy: 0.6088\n","Epoch 54/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.2512 - accuracy: 0.6398 - val_loss: 1.2712 - val_accuracy: 0.6131\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2451 - accuracy: 0.6358 - val_loss: 1.2663 - val_accuracy: 0.6110\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2389 - accuracy: 0.6385 - val_loss: 1.2607 - val_accuracy: 0.6088\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2338 - accuracy: 0.6406 - val_loss: 1.2548 - val_accuracy: 0.6034\n","Epoch 58/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.2272 - accuracy: 0.6412 - val_loss: 1.2504 - val_accuracy: 0.6153\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2215 - accuracy: 0.6457 - val_loss: 1.2481 - val_accuracy: 0.6056\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2155 - accuracy: 0.6428 - val_loss: 1.2390 - val_accuracy: 0.6056\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.2098 - accuracy: 0.6455 - val_loss: 1.2338 - val_accuracy: 0.6078\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.2043 - accuracy: 0.6471 - val_loss: 1.2317 - val_accuracy: 0.6088\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1998 - accuracy: 0.6390 - val_loss: 1.2240 - val_accuracy: 0.6067\n","Epoch 64/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1952 - accuracy: 0.6447 - val_loss: 1.2185 - val_accuracy: 0.6045\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1869 - accuracy: 0.6492 - val_loss: 1.2148 - val_accuracy: 0.6099\n","Epoch 66/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1816 - accuracy: 0.6501 - val_loss: 1.2101 - val_accuracy: 0.6056\n","Epoch 67/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1774 - accuracy: 0.6444 - val_loss: 1.2052 - val_accuracy: 0.6110\n","Epoch 68/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1734 - accuracy: 0.6447 - val_loss: 1.1993 - val_accuracy: 0.6056\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1670 - accuracy: 0.6455 - val_loss: 1.1956 - val_accuracy: 0.6078\n","Epoch 70/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1623 - accuracy: 0.6501 - val_loss: 1.1905 - val_accuracy: 0.6078\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1568 - accuracy: 0.6484 - val_loss: 1.1871 - val_accuracy: 0.6121\n","Epoch 72/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.1514 - accuracy: 0.6519 - val_loss: 1.1820 - val_accuracy: 0.6110\n","Epoch 73/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1454 - accuracy: 0.6501 - val_loss: 1.1794 - val_accuracy: 0.6142\n","Epoch 74/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.1424 - accuracy: 0.6538 - val_loss: 1.1733 - val_accuracy: 0.6121\n","Epoch 75/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.1362 - accuracy: 0.6511 - val_loss: 1.1718 - val_accuracy: 0.6110\n","Epoch 76/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.1313 - accuracy: 0.6482 - val_loss: 1.1650 - val_accuracy: 0.6034\n","Epoch 77/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1276 - accuracy: 0.6527 - val_loss: 1.1589 - val_accuracy: 0.6088\n","Epoch 78/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.1193 - accuracy: 0.6571 - val_loss: 1.1567 - val_accuracy: 0.6121\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.1159 - accuracy: 0.6506 - val_loss: 1.1517 - val_accuracy: 0.6099\n","Epoch 80/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1129 - accuracy: 0.6554 - val_loss: 1.1521 - val_accuracy: 0.6099\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1064 - accuracy: 0.6549 - val_loss: 1.1409 - val_accuracy: 0.6142\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1024 - accuracy: 0.6573 - val_loss: 1.1373 - val_accuracy: 0.6142\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0980 - accuracy: 0.6576 - val_loss: 1.1326 - val_accuracy: 0.6121\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0941 - accuracy: 0.6592 - val_loss: 1.1306 - val_accuracy: 0.6088\n","Epoch 85/100\n","29/29 [==============================] - 2s 58ms/step - loss: 1.0874 - accuracy: 0.6589 - val_loss: 1.1246 - val_accuracy: 0.6164\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0812 - accuracy: 0.6616 - val_loss: 1.1214 - val_accuracy: 0.6121\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0765 - accuracy: 0.6659 - val_loss: 1.1172 - val_accuracy: 0.6099\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0721 - accuracy: 0.6654 - val_loss: 1.1161 - val_accuracy: 0.6110\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0667 - accuracy: 0.6705 - val_loss: 1.1131 - val_accuracy: 0.6131\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0627 - accuracy: 0.6673 - val_loss: 1.1080 - val_accuracy: 0.6121\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0584 - accuracy: 0.6695 - val_loss: 1.1073 - val_accuracy: 0.6164\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0536 - accuracy: 0.6646 - val_loss: 1.0994 - val_accuracy: 0.6078\n","Epoch 93/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0486 - accuracy: 0.6689 - val_loss: 1.0967 - val_accuracy: 0.6121\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0466 - accuracy: 0.6673 - val_loss: 1.1021 - val_accuracy: 0.6131\n","Epoch 95/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.0408 - accuracy: 0.6662 - val_loss: 1.0982 - val_accuracy: 0.6196\n","Epoch 96/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0349 - accuracy: 0.6773 - val_loss: 1.0887 - val_accuracy: 0.6121\n","Epoch 97/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0293 - accuracy: 0.6719 - val_loss: 1.0813 - val_accuracy: 0.6110\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0219 - accuracy: 0.6773 - val_loss: 1.0783 - val_accuracy: 0.6110\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0220 - accuracy: 0.6721 - val_loss: 1.0823 - val_accuracy: 0.6142\n","Epoch 100/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0207 - accuracy: 0.6697 - val_loss: 1.0700 - val_accuracy: 0.6088\n","{'loss': [1.703505516052246, 1.6929800510406494, 1.6824222803115845, 1.6717597246170044, 1.6609565019607544, 1.6498130559921265, 1.6384594440460205, 1.6272755861282349, 1.616194486618042, 1.6062991619110107, 1.596091389656067, 1.5864999294281006, 1.5771379470825195, 1.5678274631500244, 1.5584266185760498, 1.5492113828659058, 1.5405280590057373, 1.5312296152114868, 1.5223336219787598, 1.513408899307251, 1.504740834236145, 1.4953017234802246, 1.4863898754119873, 1.4770046472549438, 1.4677541255950928, 1.4585866928100586, 1.4487318992614746, 1.4381167888641357, 1.4283255338668823, 1.420119047164917, 1.4083389043807983, 1.4015909433364868, 1.3923293352127075, 1.3838385343551636, 1.3758260011672974, 1.3694475889205933, 1.3616557121276855, 1.353563666343689, 1.3457757234573364, 1.3395800590515137, 1.3339204788208008, 1.3250758647918701, 1.3184260129928589, 1.3128823041915894, 1.3077442646026611, 1.301418662071228, 1.2945059537887573, 1.288459062576294, 1.2799367904663086, 1.2745938301086426, 1.267546534538269, 1.2625477313995361, 1.255301594734192, 1.2512253522872925, 1.2451157569885254, 1.2389315366744995, 1.2338355779647827, 1.2272467613220215, 1.2214714288711548, 1.2154796123504639, 1.2097597122192383, 1.2042655944824219, 1.1997872591018677, 1.195207953453064, 1.186903715133667, 1.1815593242645264, 1.1774455308914185, 1.1733763217926025, 1.1670331954956055, 1.162285327911377, 1.1568440198898315, 1.1513909101486206, 1.1453744173049927, 1.142429232597351, 1.1362276077270508, 1.1313097476959229, 1.1275815963745117, 1.119330883026123, 1.1159377098083496, 1.112884283065796, 1.1063940525054932, 1.1024248600006104, 1.0979751348495483, 1.0940815210342407, 1.0874083042144775, 1.0811727046966553, 1.0764821767807007, 1.07210111618042, 1.0667191743850708, 1.0626791715621948, 1.0584208965301514, 1.0536439418792725, 1.0486488342285156, 1.0465997457504272, 1.0408098697662354, 1.0349174737930298, 1.0292561054229736, 1.0219465494155884, 1.0220075845718384, 1.0206588506698608], 'accuracy': [0.5150862336158752, 0.5546875, 0.5678879022598267, 0.5538793206214905, 0.5490301847457886, 0.5501077771186829, 0.5522629022598267, 0.5474137663841248, 0.5549569129943848, 0.5630387663841248, 0.5754310488700867, 0.5783944129943848, 0.5808189511299133, 0.5805495977401733, 0.5792025923728943, 0.5813577771186829, 0.5808189511299133, 0.5837823152542114, 0.5840517282485962, 0.5880926847457886, 0.5934805870056152, 0.5929418206214905, 0.5932112336158752, 0.5942887663841248, 0.5969827771186829, 0.5983297228813171, 0.603178858757019, 0.610722005367279, 0.6101831793785095, 0.6085668206214905, 0.6231142282485962, 0.6190732717514038, 0.6217672228813171, 0.623652994632721, 0.6260775923728943, 0.6247305870056152, 0.6201508641242981, 0.6255387663841248, 0.6282327771186829, 0.6282327771186829, 0.6279633641242981, 0.626347005367279, 0.634428858757019, 0.6336206793785095, 0.631196141242981, 0.6290409564971924, 0.631196141242981, 0.6325430870056152, 0.639277994632721, 0.6363146305084229, 0.6414331793785095, 0.6338900923728943, 0.639008641242981, 0.6398168206214905, 0.6357758641242981, 0.6384698152542114, 0.640625, 0.6411637663841248, 0.6457435488700867, 0.6427801847457886, 0.6454741358757019, 0.647090494632721, 0.639008641242981, 0.6446659564971924, 0.6492456793785095, 0.650053858757019, 0.6443965435028076, 0.6446659564971924, 0.6454741358757019, 0.650053858757019, 0.6484375, 0.6519396305084229, 0.650053858757019, 0.6538254022598267, 0.6511314511299133, 0.6481680870056152, 0.6527478694915771, 0.6570581793785095, 0.6505926847457886, 0.6554418206214905, 0.654902994632721, 0.6573275923728943, 0.657597005367279, 0.6592133641242981, 0.6589439511299133, 0.6616379022598267, 0.6659482717514038, 0.665409505367279, 0.670527994632721, 0.6672952771186829, 0.6694504022598267, 0.6646012663841248, 0.6689116358757019, 0.6672952771186829, 0.6662176847457886, 0.6772629022598267, 0.671875, 0.6772629022598267, 0.6721444129943848, 0.6697198152542114], 'val_loss': [1.698319435119629, 1.688098669052124, 1.6779749393463135, 1.6679481267929077, 1.6580092906951904, 1.648119568824768, 1.638238549232483, 1.6283217668533325, 1.618456244468689, 1.6085560321807861, 1.5989254713058472, 1.5892714262008667, 1.5795737504959106, 1.569853663444519, 1.5604363679885864, 1.55085027217865, 1.5415085554122925, 1.5320849418640137, 1.5226505994796753, 1.5135616064071655, 1.5045192241668701, 1.4954177141189575, 1.4865025281906128, 1.477359652519226, 1.4683152437210083, 1.4588978290557861, 1.4505128860473633, 1.4411485195159912, 1.4331636428833008, 1.425289273262024, 1.4176112413406372, 1.4068232774734497, 1.400065302848816, 1.391960859298706, 1.3856617212295532, 1.382107138633728, 1.3723584413528442, 1.3661998510360718, 1.36127769947052, 1.3533061742782593, 1.345977544784546, 1.346417784690857, 1.3339433670043945, 1.328941822052002, 1.3226568698883057, 1.3155884742736816, 1.3107311725616455, 1.3037575483322144, 1.2992346286773682, 1.2950356006622314, 1.2886615991592407, 1.2847349643707275, 1.2767412662506104, 1.2711985111236572, 1.266348123550415, 1.260744571685791, 1.2547577619552612, 1.2503501176834106, 1.2481356859207153, 1.238998532295227, 1.2337578535079956, 1.2317252159118652, 1.2239667177200317, 1.2184842824935913, 1.214812994003296, 1.2100694179534912, 1.2052372694015503, 1.199289083480835, 1.195615530014038, 1.1905157566070557, 1.1870694160461426, 1.1820307970046997, 1.1793627738952637, 1.1733477115631104, 1.1717783212661743, 1.165012240409851, 1.1588679552078247, 1.1566855907440186, 1.1516940593719482, 1.1521183252334595, 1.1409004926681519, 1.1372718811035156, 1.1326276063919067, 1.1306443214416504, 1.1245930194854736, 1.1213765144348145, 1.1172130107879639, 1.1160902976989746, 1.113060474395752, 1.1080286502838135, 1.1073116064071655, 1.0993754863739014, 1.0966724157333374, 1.1021052598953247, 1.0982452630996704, 1.0886540412902832, 1.0813367366790771, 1.0783028602600098, 1.0822926759719849, 1.069978952407837], 'val_accuracy': [0.5226293206214905, 0.5280172228813171, 0.5290948152542114, 0.5495689511299133, 0.5571120977401733, 0.5657327771186829, 0.5668103694915771, 0.5711206793785095, 0.5700430870056152, 0.5711206793785095, 0.568965494632721, 0.5743534564971924, 0.5732758641242981, 0.5668103694915771, 0.5646551847457886, 0.5581896305084229, 0.5538793206214905, 0.548491358757019, 0.548491358757019, 0.5463362336158752, 0.5538793206214905, 0.5571120977401733, 0.5592672228813171, 0.5678879022598267, 0.5657327771186829, 0.5754310488700867, 0.5732758641242981, 0.5829741358757019, 0.5840517282485962, 0.5883620977401733, 0.587284505367279, 0.5991379022598267, 0.5959051847457886, 0.5969827771186829, 0.5969827771186829, 0.5969827771186829, 0.5991379022598267, 0.6034482717514038, 0.600215494632721, 0.6045258641242981, 0.5959051847457886, 0.600215494632721, 0.6023706793785095, 0.6023706793785095, 0.6012930870056152, 0.6045258641242981, 0.6056034564971924, 0.6088362336158752, 0.607758641242981, 0.5948275923728943, 0.6045258641242981, 0.5959051847457886, 0.6088362336158752, 0.6131465435028076, 0.610991358757019, 0.6088362336158752, 0.6034482717514038, 0.6153017282485962, 0.6056034564971924, 0.6056034564971924, 0.607758641242981, 0.6088362336158752, 0.6066810488700867, 0.6045258641242981, 0.6099137663841248, 0.6056034564971924, 0.610991358757019, 0.6056034564971924, 0.607758641242981, 0.607758641242981, 0.6120689511299133, 0.610991358757019, 0.6142241358757019, 0.6120689511299133, 0.610991358757019, 0.6034482717514038, 0.6088362336158752, 0.6120689511299133, 0.6099137663841248, 0.6099137663841248, 0.6142241358757019, 0.6142241358757019, 0.6120689511299133, 0.6088362336158752, 0.6163793206214905, 0.6120689511299133, 0.6099137663841248, 0.610991358757019, 0.6131465435028076, 0.6120689511299133, 0.6163793206214905, 0.607758641242981, 0.6120689511299133, 0.6131465435028076, 0.6196120977401733, 0.6120689511299133, 0.610991358757019, 0.610991358757019, 0.6142241358757019, 0.6088362336158752]}\n","38/38 [==============================] - 1s 11ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 1.7038 - accuracy: 0.5379"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 81ms/step - loss: 1.7038 - accuracy: 0.5379 - val_loss: 1.6987 - val_accuracy: 0.5147\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.6936 - accuracy: 0.5566 - val_loss: 1.6888 - val_accuracy: 0.5192\n","Epoch 3/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.6835 - accuracy: 0.5470 - val_loss: 1.6790 - val_accuracy: 0.5215\n","Epoch 4/100\n","28/28 [==============================] - 1s 33ms/step - loss: 1.6732 - accuracy: 0.5637 - val_loss: 1.6694 - val_accuracy: 0.5226\n","Epoch 5/100\n","28/28 [==============================] - 1s 31ms/step - loss: 1.6629 - accuracy: 0.5606 - val_loss: 1.6597 - val_accuracy: 0.5351\n","Epoch 6/100\n","28/28 [==============================] - 1s 31ms/step - loss: 1.6524 - accuracy: 0.5603 - val_loss: 1.6502 - val_accuracy: 0.5407\n","Epoch 7/100\n","28/28 [==============================] - 1s 34ms/step - loss: 1.6416 - accuracy: 0.5481 - val_loss: 1.6406 - val_accuracy: 0.5498\n","Epoch 8/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.6307 - accuracy: 0.5453 - val_loss: 1.6310 - val_accuracy: 0.5464\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.6200 - accuracy: 0.5580 - val_loss: 1.6216 - val_accuracy: 0.5486\n","Epoch 10/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.6101 - accuracy: 0.5563 - val_loss: 1.6119 - val_accuracy: 0.5679\n","Epoch 11/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.6005 - accuracy: 0.5654 - val_loss: 1.6026 - val_accuracy: 0.5656\n","Epoch 12/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.5912 - accuracy: 0.5642 - val_loss: 1.5933 - val_accuracy: 0.5690\n","Epoch 13/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.5823 - accuracy: 0.5628 - val_loss: 1.5840 - val_accuracy: 0.5724\n","Epoch 14/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.5731 - accuracy: 0.5707 - val_loss: 1.5750 - val_accuracy: 0.5735\n","Epoch 15/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5642 - accuracy: 0.5699 - val_loss: 1.5656 - val_accuracy: 0.5724\n","Epoch 16/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.5554 - accuracy: 0.5679 - val_loss: 1.5566 - val_accuracy: 0.5701\n","Epoch 17/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.5469 - accuracy: 0.5710 - val_loss: 1.5474 - val_accuracy: 0.5690\n","Epoch 18/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5381 - accuracy: 0.5741 - val_loss: 1.5383 - val_accuracy: 0.5724\n","Epoch 19/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.5296 - accuracy: 0.5756 - val_loss: 1.5296 - val_accuracy: 0.5667\n","Epoch 20/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.5209 - accuracy: 0.5789 - val_loss: 1.5202 - val_accuracy: 0.5814\n","Epoch 21/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5124 - accuracy: 0.5778 - val_loss: 1.5113 - val_accuracy: 0.5792\n","Epoch 22/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5039 - accuracy: 0.5804 - val_loss: 1.5030 - val_accuracy: 0.5803\n","Epoch 23/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.4956 - accuracy: 0.5809 - val_loss: 1.4941 - val_accuracy: 0.5758\n","Epoch 24/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4869 - accuracy: 0.5792 - val_loss: 1.4854 - val_accuracy: 0.5724\n","Epoch 25/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4779 - accuracy: 0.5840 - val_loss: 1.4769 - val_accuracy: 0.5679\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4696 - accuracy: 0.5903 - val_loss: 1.4686 - val_accuracy: 0.5679\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4607 - accuracy: 0.5891 - val_loss: 1.4603 - val_accuracy: 0.5701\n","Epoch 28/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.4514 - accuracy: 0.5931 - val_loss: 1.4520 - val_accuracy: 0.5633\n","Epoch 29/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4418 - accuracy: 0.6078 - val_loss: 1.4443 - val_accuracy: 0.5747\n","Epoch 30/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.4330 - accuracy: 0.6104 - val_loss: 1.4364 - val_accuracy: 0.5781\n","Epoch 31/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4238 - accuracy: 0.6061 - val_loss: 1.4288 - val_accuracy: 0.5724\n","Epoch 32/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.4157 - accuracy: 0.6041 - val_loss: 1.4233 - val_accuracy: 0.5747\n","Epoch 33/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4064 - accuracy: 0.6101 - val_loss: 1.4141 - val_accuracy: 0.5735\n","Epoch 34/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3986 - accuracy: 0.6095 - val_loss: 1.4078 - val_accuracy: 0.5792\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3902 - accuracy: 0.6157 - val_loss: 1.4016 - val_accuracy: 0.5747\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3820 - accuracy: 0.6078 - val_loss: 1.3932 - val_accuracy: 0.5792\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3729 - accuracy: 0.6146 - val_loss: 1.3875 - val_accuracy: 0.5803\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3669 - accuracy: 0.6112 - val_loss: 1.3810 - val_accuracy: 0.5781\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3605 - accuracy: 0.6135 - val_loss: 1.3764 - val_accuracy: 0.5701\n","Epoch 40/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3522 - accuracy: 0.6222 - val_loss: 1.3676 - val_accuracy: 0.5781\n","Epoch 41/100\n","28/28 [==============================] - 1s 54ms/step - loss: 1.3460 - accuracy: 0.6109 - val_loss: 1.3616 - val_accuracy: 0.5826\n","Epoch 42/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3370 - accuracy: 0.6177 - val_loss: 1.3558 - val_accuracy: 0.5792\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3314 - accuracy: 0.6160 - val_loss: 1.3494 - val_accuracy: 0.5814\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3247 - accuracy: 0.6180 - val_loss: 1.3444 - val_accuracy: 0.5792\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3169 - accuracy: 0.6152 - val_loss: 1.3380 - val_accuracy: 0.5781\n","Epoch 46/100\n","28/28 [==============================] - 1s 31ms/step - loss: 1.3110 - accuracy: 0.6174 - val_loss: 1.3326 - val_accuracy: 0.5814\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3042 - accuracy: 0.6200 - val_loss: 1.3291 - val_accuracy: 0.5781\n","Epoch 48/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.2990 - accuracy: 0.6177 - val_loss: 1.3212 - val_accuracy: 0.5860\n","Epoch 49/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2933 - accuracy: 0.6169 - val_loss: 1.3156 - val_accuracy: 0.5848\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2863 - accuracy: 0.6248 - val_loss: 1.3110 - val_accuracy: 0.5826\n","Epoch 51/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2802 - accuracy: 0.6188 - val_loss: 1.3046 - val_accuracy: 0.5860\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2761 - accuracy: 0.6183 - val_loss: 1.2991 - val_accuracy: 0.5860\n","Epoch 53/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.2680 - accuracy: 0.6208 - val_loss: 1.2951 - val_accuracy: 0.5905\n","Epoch 54/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2629 - accuracy: 0.6248 - val_loss: 1.2891 - val_accuracy: 0.5882\n","Epoch 55/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2554 - accuracy: 0.6296 - val_loss: 1.2850 - val_accuracy: 0.5781\n","Epoch 56/100\n","28/28 [==============================] - 1s 30ms/step - loss: 1.2505 - accuracy: 0.6285 - val_loss: 1.2776 - val_accuracy: 0.5928\n","Epoch 57/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2447 - accuracy: 0.6273 - val_loss: 1.2740 - val_accuracy: 0.5916\n","Epoch 58/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2391 - accuracy: 0.6287 - val_loss: 1.2681 - val_accuracy: 0.5882\n","Epoch 59/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.2326 - accuracy: 0.6256 - val_loss: 1.2636 - val_accuracy: 0.5882\n","Epoch 60/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.2278 - accuracy: 0.6222 - val_loss: 1.2582 - val_accuracy: 0.5882\n","Epoch 61/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.2232 - accuracy: 0.6279 - val_loss: 1.2538 - val_accuracy: 0.5950\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2156 - accuracy: 0.6310 - val_loss: 1.2493 - val_accuracy: 0.5939\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2119 - accuracy: 0.6271 - val_loss: 1.2444 - val_accuracy: 0.5950\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2072 - accuracy: 0.6256 - val_loss: 1.2390 - val_accuracy: 0.5916\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2009 - accuracy: 0.6333 - val_loss: 1.2353 - val_accuracy: 0.5928\n","Epoch 66/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1944 - accuracy: 0.6316 - val_loss: 1.2312 - val_accuracy: 0.5939\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1915 - accuracy: 0.6341 - val_loss: 1.2256 - val_accuracy: 0.5950\n","Epoch 68/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1838 - accuracy: 0.6333 - val_loss: 1.2220 - val_accuracy: 0.5905\n","Epoch 69/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.1794 - accuracy: 0.6361 - val_loss: 1.2161 - val_accuracy: 0.5962\n","Epoch 70/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.1741 - accuracy: 0.6392 - val_loss: 1.2124 - val_accuracy: 0.5916\n","Epoch 71/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1686 - accuracy: 0.6378 - val_loss: 1.2083 - val_accuracy: 0.5916\n","Epoch 72/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.1652 - accuracy: 0.6404 - val_loss: 1.2034 - val_accuracy: 0.6029\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1581 - accuracy: 0.6392 - val_loss: 1.1991 - val_accuracy: 0.6029\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1515 - accuracy: 0.6460 - val_loss: 1.1954 - val_accuracy: 0.5916\n","Epoch 75/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1469 - accuracy: 0.6454 - val_loss: 1.1928 - val_accuracy: 0.5905\n","Epoch 76/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1415 - accuracy: 0.6412 - val_loss: 1.1859 - val_accuracy: 0.5950\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1381 - accuracy: 0.6435 - val_loss: 1.1829 - val_accuracy: 0.5984\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1343 - accuracy: 0.6361 - val_loss: 1.1787 - val_accuracy: 0.5950\n","Epoch 79/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1262 - accuracy: 0.6517 - val_loss: 1.1749 - val_accuracy: 0.5984\n","Epoch 80/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1201 - accuracy: 0.6537 - val_loss: 1.1708 - val_accuracy: 0.5939\n","Epoch 81/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1148 - accuracy: 0.6545 - val_loss: 1.1671 - val_accuracy: 0.5984\n","Epoch 82/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.1139 - accuracy: 0.6437 - val_loss: 1.1636 - val_accuracy: 0.6086\n","Epoch 83/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1049 - accuracy: 0.6559 - val_loss: 1.1587 - val_accuracy: 0.6075\n","Epoch 84/100\n","28/28 [==============================] - 1s 30ms/step - loss: 1.1003 - accuracy: 0.6545 - val_loss: 1.1554 - val_accuracy: 0.6109\n","Epoch 85/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0947 - accuracy: 0.6579 - val_loss: 1.1521 - val_accuracy: 0.6086\n","Epoch 86/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0900 - accuracy: 0.6551 - val_loss: 1.1483 - val_accuracy: 0.6075\n","Epoch 87/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0866 - accuracy: 0.6616 - val_loss: 1.1445 - val_accuracy: 0.6086\n","Epoch 88/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0800 - accuracy: 0.6562 - val_loss: 1.1403 - val_accuracy: 0.6075\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0756 - accuracy: 0.6613 - val_loss: 1.1364 - val_accuracy: 0.6029\n","Epoch 90/100\n","28/28 [==============================] - 1s 26ms/step - loss: 1.0694 - accuracy: 0.6647 - val_loss: 1.1337 - val_accuracy: 0.6131\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0617 - accuracy: 0.6723 - val_loss: 1.1301 - val_accuracy: 0.6041\n","Epoch 92/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0567 - accuracy: 0.6715 - val_loss: 1.1291 - val_accuracy: 0.6131\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0568 - accuracy: 0.6664 - val_loss: 1.1240 - val_accuracy: 0.6063\n","Epoch 94/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0499 - accuracy: 0.6638 - val_loss: 1.1181 - val_accuracy: 0.6120\n","Epoch 95/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0446 - accuracy: 0.6701 - val_loss: 1.1133 - val_accuracy: 0.6097\n","Epoch 96/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0370 - accuracy: 0.6743 - val_loss: 1.1191 - val_accuracy: 0.6007\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0325 - accuracy: 0.6802 - val_loss: 1.1110 - val_accuracy: 0.6086\n","Epoch 98/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0294 - accuracy: 0.6763 - val_loss: 1.1057 - val_accuracy: 0.6018\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0238 - accuracy: 0.6788 - val_loss: 1.1043 - val_accuracy: 0.6041\n","Epoch 100/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0178 - accuracy: 0.6811 - val_loss: 1.0992 - val_accuracy: 0.6063\n","{'loss': [1.7037826776504517, 1.6936479806900024, 1.6835097074508667, 1.673222541809082, 1.662889838218689, 1.6523561477661133, 1.6416386365890503, 1.6307017803192139, 1.6200474500656128, 1.6101038455963135, 1.600472092628479, 1.5912184715270996, 1.5822529792785645, 1.5730682611465454, 1.5641543865203857, 1.5553542375564575, 1.5468673706054688, 1.5381355285644531, 1.52963387966156, 1.5208932161331177, 1.5123581886291504, 1.5038683414459229, 1.4956213235855103, 1.4868782758712769, 1.4779325723648071, 1.469605565071106, 1.4606943130493164, 1.451431155204773, 1.4418408870697021, 1.4330333471298218, 1.4238474369049072, 1.4156848192214966, 1.40639328956604, 1.3986411094665527, 1.3901690244674683, 1.381966233253479, 1.3728997707366943, 1.3668720722198486, 1.360503077507019, 1.3522413969039917, 1.3459725379943848, 1.3369568586349487, 1.3314266204833984, 1.3247493505477905, 1.3168631792068481, 1.3109899759292603, 1.30417001247406, 1.2990293502807617, 1.293323040008545, 1.286280632019043, 1.280237078666687, 1.2760519981384277, 1.2680275440216064, 1.262876033782959, 1.2554044723510742, 1.2505089044570923, 1.244685411453247, 1.2391129732131958, 1.2325814962387085, 1.2278350591659546, 1.223201870918274, 1.215588927268982, 1.2119210958480835, 1.2072235345840454, 1.2008781433105469, 1.1943751573562622, 1.1914713382720947, 1.1837860345840454, 1.1793879270553589, 1.1740546226501465, 1.168591856956482, 1.165193796157837, 1.1580517292022705, 1.1514942646026611, 1.1468504667282104, 1.1414897441864014, 1.1381146907806396, 1.1342980861663818, 1.1261558532714844, 1.1200896501541138, 1.11482834815979, 1.1138893365859985, 1.1049171686172485, 1.1002693176269531, 1.0947238206863403, 1.090000867843628, 1.0865954160690308, 1.0800169706344604, 1.0755614042282104, 1.069352149963379, 1.0617341995239258, 1.0567089319229126, 1.0568385124206543, 1.0499008893966675, 1.0446194410324097, 1.0370138883590698, 1.0325113534927368, 1.0294222831726074, 1.023768424987793, 1.0177886486053467], 'accuracy': [0.5379173755645752, 0.556593120098114, 0.5469722747802734, 0.5636672377586365, 0.5605546236038208, 0.5602716207504272, 0.5481041073799133, 0.5452744960784912, 0.5580078959465027, 0.5563101172447205, 0.5653650164604187, 0.5642331838607788, 0.5628183484077454, 0.5707413554191589, 0.5698924660682678, 0.5679117441177368, 0.5710243582725525, 0.5741369724273682, 0.5755518078804016, 0.5789473652839661, 0.5778155326843262, 0.5803622007369995, 0.5809281468391418, 0.5792303085327148, 0.5840407609939575, 0.5902659893035889, 0.5891340970993042, 0.5930956602096558, 0.607809841632843, 0.6103565096855164, 0.6061120629310608, 0.604131281375885, 0.6100735664367676, 0.6095076203346252, 0.6157329082489014, 0.607809841632843, 0.6146010160446167, 0.6112054586410522, 0.6134691834449768, 0.6222410798072815, 0.6109224557876587, 0.6177136301994324, 0.6160158514976501, 0.6179966330528259, 0.615166962146759, 0.6174306869506836, 0.6199773550033569, 0.6177136301994324, 0.6168647408485413, 0.6247877478599548, 0.618845522403717, 0.6182795763015747, 0.620826244354248, 0.6247877478599548, 0.6295982003211975, 0.6284663081169128, 0.627334475517273, 0.6287493109703064, 0.6256366968154907, 0.6222410798072815, 0.6279004216194153, 0.631013035774231, 0.6270514726638794, 0.6256366968154907, 0.6332767605781555, 0.6315789222717285, 0.6341256499290466, 0.6332767605781555, 0.6361063718795776, 0.6392189860343933, 0.6378042101860046, 0.640350878238678, 0.6392189860343933, 0.646010160446167, 0.6454442739486694, 0.6411997675895691, 0.6434634923934937, 0.6361063718795776, 0.6516695022583008, 0.6536502838134766, 0.6544991731643677, 0.6437464356422424, 0.6559139490127563, 0.6544991731643677, 0.6578947305679321, 0.6550650596618652, 0.6615732908248901, 0.6561969518661499, 0.6612903475761414, 0.6646859049797058, 0.6723259687423706, 0.6714770793914795, 0.666383683681488, 0.6638370156288147, 0.670062243938446, 0.6743067502975464, 0.680249035358429, 0.6762874722480774, 0.6788341999053955, 0.6810979247093201], 'val_loss': [1.6986782550811768, 1.6888090372085571, 1.6790294647216797, 1.6693532466888428, 1.6597353219985962, 1.650174617767334, 1.6406093835830688, 1.631026029586792, 1.6215579509735107, 1.6119301319122314, 1.6026285886764526, 1.593337059020996, 1.5840314626693726, 1.5749919414520264, 1.5656143426895142, 1.5566123723983765, 1.5473517179489136, 1.5382987260818481, 1.5296361446380615, 1.5202195644378662, 1.511334776878357, 1.5030341148376465, 1.494097352027893, 1.4854117631912231, 1.4768885374069214, 1.468580722808838, 1.460307002067566, 1.4519871473312378, 1.4442938566207886, 1.436432123184204, 1.4287866353988647, 1.423293948173523, 1.4140920639038086, 1.4078419208526611, 1.401563286781311, 1.393212914466858, 1.3875378370285034, 1.3809776306152344, 1.3764177560806274, 1.3675791025161743, 1.3615624904632568, 1.3558462858200073, 1.349432110786438, 1.344417929649353, 1.3379836082458496, 1.3325773477554321, 1.329149603843689, 1.3212246894836426, 1.3156499862670898, 1.3109824657440186, 1.3046441078186035, 1.2990589141845703, 1.2950589656829834, 1.2890797853469849, 1.284978985786438, 1.277591347694397, 1.2740319967269897, 1.2681142091751099, 1.2636232376098633, 1.2582125663757324, 1.2537553310394287, 1.249332308769226, 1.244384765625, 1.2390422821044922, 1.2352827787399292, 1.2311819791793823, 1.2255710363388062, 1.2219772338867188, 1.2160828113555908, 1.212353229522705, 1.208317518234253, 1.2033679485321045, 1.1990634202957153, 1.1954164505004883, 1.1927803754806519, 1.185928225517273, 1.1828553676605225, 1.1787177324295044, 1.174858808517456, 1.1708085536956787, 1.167145848274231, 1.1635922193527222, 1.1587365865707397, 1.155441164970398, 1.1520732641220093, 1.148302674293518, 1.144530177116394, 1.1402981281280518, 1.1364094018936157, 1.1337380409240723, 1.1301357746124268, 1.129103660583496, 1.1239899396896362, 1.1180872917175293, 1.1132749319076538, 1.1190712451934814, 1.1110365390777588, 1.1057496070861816, 1.1043102741241455, 1.0992045402526855], 'val_accuracy': [0.5147058963775635, 0.5192307829856873, 0.5214931964874268, 0.5226244330406189, 0.5350678563117981, 0.540723979473114, 0.5497737526893616, 0.5463801026344299, 0.5486425161361694, 0.5678732991218567, 0.5656108856201172, 0.5690045356750488, 0.5723981857299805, 0.5735294222831726, 0.5723981857299805, 0.570135772228241, 0.5690045356750488, 0.5723981857299805, 0.5667420625686646, 0.581447958946228, 0.5791855454444885, 0.5803167223930359, 0.5757918357849121, 0.5723981857299805, 0.5678732991218567, 0.5678732991218567, 0.570135772228241, 0.5633484125137329, 0.5746606588363647, 0.5780543088912964, 0.5723981857299805, 0.5746606588363647, 0.5735294222831726, 0.5791855454444885, 0.5746606588363647, 0.5791855454444885, 0.5803167223930359, 0.5780543088912964, 0.570135772228241, 0.5780543088912964, 0.5825791954994202, 0.5791855454444885, 0.581447958946228, 0.5791855454444885, 0.5780543088912964, 0.581447958946228, 0.5780543088912964, 0.5859728455543518, 0.5848416090011597, 0.5825791954994202, 0.5859728455543518, 0.5859728455543518, 0.5904977321624756, 0.5882353186607361, 0.5780543088912964, 0.5927602052688599, 0.5916289687156677, 0.5882353186607361, 0.5882353186607361, 0.5882353186607361, 0.5950226187705994, 0.5938913822174072, 0.5950226187705994, 0.5916289687156677, 0.5927602052688599, 0.5938913822174072, 0.5950226187705994, 0.5904977321624756, 0.5961538553237915, 0.5916289687156677, 0.5916289687156677, 0.6029411554336548, 0.6029411554336548, 0.5916289687156677, 0.5904977321624756, 0.5950226187705994, 0.598416268825531, 0.5950226187705994, 0.598416268825531, 0.5938913822174072, 0.598416268825531, 0.6085972785949707, 0.6074660420417786, 0.610859751701355, 0.6085972785949707, 0.6074660420417786, 0.6085972785949707, 0.6074660420417786, 0.6029411554336548, 0.6131221652030945, 0.6040723919868469, 0.6131221652030945, 0.6063348650932312, 0.6119909286499023, 0.6097285151481628, 0.6006787419319153, 0.6085972785949707, 0.6018099784851074, 0.6040723919868469, 0.6063348650932312]}\n","45/45 [==============================] - 1s 10ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 1.7033 - accuracy: 0.5018"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 7s 71ms/step - loss: 1.7033 - accuracy: 0.5018 - val_loss: 1.6976 - val_accuracy: 0.5196\n","Epoch 2/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.6921 - accuracy: 0.5610 - val_loss: 1.6867 - val_accuracy: 0.5196\n","Epoch 3/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.6808 - accuracy: 0.5724 - val_loss: 1.6759 - val_accuracy: 0.5186\n","Epoch 4/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.6694 - accuracy: 0.5700 - val_loss: 1.6652 - val_accuracy: 0.5248\n","Epoch 5/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.6577 - accuracy: 0.5661 - val_loss: 1.6547 - val_accuracy: 0.5341\n","Epoch 6/100\n","31/31 [==============================] - 1s 33ms/step - loss: 1.6458 - accuracy: 0.5618 - val_loss: 1.6442 - val_accuracy: 0.5413\n","Epoch 7/100\n","31/31 [==============================] - 1s 29ms/step - loss: 1.6335 - accuracy: 0.5548 - val_loss: 1.6337 - val_accuracy: 0.5496\n","Epoch 8/100\n","31/31 [==============================] - 1s 30ms/step - loss: 1.6212 - accuracy: 0.5568 - val_loss: 1.6234 - val_accuracy: 0.5537\n","Epoch 9/100\n","31/31 [==============================] - 1s 30ms/step - loss: 1.6098 - accuracy: 0.5568 - val_loss: 1.6129 - val_accuracy: 0.5640\n","Epoch 10/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.5990 - accuracy: 0.5680 - val_loss: 1.6028 - val_accuracy: 0.5620\n","Epoch 11/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.5888 - accuracy: 0.5677 - val_loss: 1.5926 - val_accuracy: 0.5692\n","Epoch 12/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.5787 - accuracy: 0.5687 - val_loss: 1.5826 - val_accuracy: 0.5671\n","Epoch 13/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5692 - accuracy: 0.5703 - val_loss: 1.5730 - val_accuracy: 0.5682\n","Epoch 14/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.5592 - accuracy: 0.5755 - val_loss: 1.5631 - val_accuracy: 0.5713\n","Epoch 15/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.5495 - accuracy: 0.5773 - val_loss: 1.5532 - val_accuracy: 0.5785\n","Epoch 16/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.5398 - accuracy: 0.5734 - val_loss: 1.5438 - val_accuracy: 0.5806\n","Epoch 17/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.5306 - accuracy: 0.5757 - val_loss: 1.5343 - val_accuracy: 0.5816\n","Epoch 18/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.5214 - accuracy: 0.5744 - val_loss: 1.5249 - val_accuracy: 0.5806\n","Epoch 19/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5120 - accuracy: 0.5804 - val_loss: 1.5157 - val_accuracy: 0.5764\n","Epoch 20/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5028 - accuracy: 0.5791 - val_loss: 1.5067 - val_accuracy: 0.5816\n","Epoch 21/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.4936 - accuracy: 0.5804 - val_loss: 1.4978 - val_accuracy: 0.5847\n","Epoch 22/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.4846 - accuracy: 0.5837 - val_loss: 1.4890 - val_accuracy: 0.5847\n","Epoch 23/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.4752 - accuracy: 0.5853 - val_loss: 1.4803 - val_accuracy: 0.5868\n","Epoch 24/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.4660 - accuracy: 0.5824 - val_loss: 1.4718 - val_accuracy: 0.5899\n","Epoch 25/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.4572 - accuracy: 0.5848 - val_loss: 1.4626 - val_accuracy: 0.5857\n","Epoch 26/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.4477 - accuracy: 0.5899 - val_loss: 1.4542 - val_accuracy: 0.5878\n","Epoch 27/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4381 - accuracy: 0.5876 - val_loss: 1.4456 - val_accuracy: 0.5888\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.4288 - accuracy: 0.5956 - val_loss: 1.4361 - val_accuracy: 0.5837\n","Epoch 29/100\n","31/31 [==============================] - 1s 29ms/step - loss: 1.4194 - accuracy: 0.5969 - val_loss: 1.4281 - val_accuracy: 0.5930\n","Epoch 30/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.4098 - accuracy: 0.5959 - val_loss: 1.4202 - val_accuracy: 0.5888\n","Epoch 31/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.4006 - accuracy: 0.5997 - val_loss: 1.4123 - val_accuracy: 0.5888\n","Epoch 32/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.3912 - accuracy: 0.5995 - val_loss: 1.4025 - val_accuracy: 0.5899\n","Epoch 33/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3841 - accuracy: 0.6057 - val_loss: 1.3985 - val_accuracy: 0.5930\n","Epoch 34/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.3752 - accuracy: 0.6047 - val_loss: 1.3892 - val_accuracy: 0.5971\n","Epoch 35/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.3667 - accuracy: 0.6049 - val_loss: 1.3787 - val_accuracy: 0.5847\n","Epoch 36/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3587 - accuracy: 0.6098 - val_loss: 1.3737 - val_accuracy: 0.5919\n","Epoch 37/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.3509 - accuracy: 0.6067 - val_loss: 1.3668 - val_accuracy: 0.5992\n","Epoch 38/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3433 - accuracy: 0.6114 - val_loss: 1.3558 - val_accuracy: 0.5878\n","Epoch 39/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3351 - accuracy: 0.6085 - val_loss: 1.3498 - val_accuracy: 0.5930\n","Epoch 40/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3277 - accuracy: 0.6134 - val_loss: 1.3449 - val_accuracy: 0.5981\n","Epoch 41/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3210 - accuracy: 0.6121 - val_loss: 1.3340 - val_accuracy: 0.5971\n","Epoch 42/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.3127 - accuracy: 0.6186 - val_loss: 1.3358 - val_accuracy: 0.6064\n","Epoch 43/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3059 - accuracy: 0.6217 - val_loss: 1.3213 - val_accuracy: 0.5919\n","Epoch 44/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3004 - accuracy: 0.6150 - val_loss: 1.3162 - val_accuracy: 0.5909\n","Epoch 45/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2935 - accuracy: 0.6207 - val_loss: 1.3079 - val_accuracy: 0.5961\n","Epoch 46/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2865 - accuracy: 0.6204 - val_loss: 1.3045 - val_accuracy: 0.6012\n","Epoch 47/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2796 - accuracy: 0.6238 - val_loss: 1.2954 - val_accuracy: 0.5992\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2724 - accuracy: 0.6207 - val_loss: 1.2926 - val_accuracy: 0.5971\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2669 - accuracy: 0.6137 - val_loss: 1.2906 - val_accuracy: 0.6054\n","Epoch 50/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.2615 - accuracy: 0.6227 - val_loss: 1.2849 - val_accuracy: 0.6074\n","Epoch 51/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2534 - accuracy: 0.6287 - val_loss: 1.2737 - val_accuracy: 0.6012\n","Epoch 52/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2489 - accuracy: 0.6196 - val_loss: 1.2676 - val_accuracy: 0.6033\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2421 - accuracy: 0.6199 - val_loss: 1.2622 - val_accuracy: 0.6002\n","Epoch 54/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2349 - accuracy: 0.6238 - val_loss: 1.2581 - val_accuracy: 0.6023\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2291 - accuracy: 0.6271 - val_loss: 1.2530 - val_accuracy: 0.6043\n","Epoch 56/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2234 - accuracy: 0.6305 - val_loss: 1.2471 - val_accuracy: 0.6064\n","Epoch 57/100\n","31/31 [==============================] - 1s 30ms/step - loss: 1.2175 - accuracy: 0.6318 - val_loss: 1.2428 - val_accuracy: 0.6095\n","Epoch 58/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2105 - accuracy: 0.6302 - val_loss: 1.2358 - val_accuracy: 0.6074\n","Epoch 59/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.2043 - accuracy: 0.6328 - val_loss: 1.2337 - val_accuracy: 0.6136\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1996 - accuracy: 0.6331 - val_loss: 1.2239 - val_accuracy: 0.6043\n","Epoch 61/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.1930 - accuracy: 0.6297 - val_loss: 1.2212 - val_accuracy: 0.6147\n","Epoch 62/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1892 - accuracy: 0.6307 - val_loss: 1.2173 - val_accuracy: 0.6136\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1829 - accuracy: 0.6370 - val_loss: 1.2136 - val_accuracy: 0.6054\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1768 - accuracy: 0.6382 - val_loss: 1.2039 - val_accuracy: 0.6074\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1725 - accuracy: 0.6341 - val_loss: 1.2000 - val_accuracy: 0.6064\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1648 - accuracy: 0.6411 - val_loss: 1.1935 - val_accuracy: 0.6116\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1602 - accuracy: 0.6437 - val_loss: 1.1890 - val_accuracy: 0.6023\n","Epoch 68/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1522 - accuracy: 0.6408 - val_loss: 1.1853 - val_accuracy: 0.6054\n","Epoch 69/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1486 - accuracy: 0.6434 - val_loss: 1.1825 - val_accuracy: 0.6064\n","Epoch 70/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1422 - accuracy: 0.6460 - val_loss: 1.1799 - val_accuracy: 0.6054\n","Epoch 71/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1354 - accuracy: 0.6434 - val_loss: 1.1748 - val_accuracy: 0.6064\n","Epoch 72/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1326 - accuracy: 0.6447 - val_loss: 1.1767 - val_accuracy: 0.6074\n","Epoch 73/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.1262 - accuracy: 0.6517 - val_loss: 1.1667 - val_accuracy: 0.6095\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1201 - accuracy: 0.6499 - val_loss: 1.1596 - val_accuracy: 0.6095\n","Epoch 75/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1140 - accuracy: 0.6512 - val_loss: 1.1563 - val_accuracy: 0.5961\n","Epoch 76/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1104 - accuracy: 0.6478 - val_loss: 1.1508 - val_accuracy: 0.6126\n","Epoch 77/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.1061 - accuracy: 0.6380 - val_loss: 1.1486 - val_accuracy: 0.6105\n","Epoch 78/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1003 - accuracy: 0.6506 - val_loss: 1.1461 - val_accuracy: 0.6095\n","Epoch 79/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0945 - accuracy: 0.6535 - val_loss: 1.1405 - val_accuracy: 0.6126\n","Epoch 80/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0905 - accuracy: 0.6499 - val_loss: 1.1383 - val_accuracy: 0.6085\n","Epoch 81/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0806 - accuracy: 0.6625 - val_loss: 1.1333 - val_accuracy: 0.6136\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0765 - accuracy: 0.6623 - val_loss: 1.1285 - val_accuracy: 0.6136\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.0713 - accuracy: 0.6589 - val_loss: 1.1248 - val_accuracy: 0.6147\n","Epoch 84/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0644 - accuracy: 0.6633 - val_loss: 1.1278 - val_accuracy: 0.6116\n","Epoch 85/100\n","31/31 [==============================] - 2s 50ms/step - loss: 1.0603 - accuracy: 0.6672 - val_loss: 1.1234 - val_accuracy: 0.6178\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0578 - accuracy: 0.6553 - val_loss: 1.1194 - val_accuracy: 0.6105\n","Epoch 87/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0522 - accuracy: 0.6636 - val_loss: 1.1118 - val_accuracy: 0.6116\n","Epoch 88/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0428 - accuracy: 0.6698 - val_loss: 1.1114 - val_accuracy: 0.6064\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0423 - accuracy: 0.6638 - val_loss: 1.1080 - val_accuracy: 0.6064\n","Epoch 90/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0308 - accuracy: 0.6747 - val_loss: 1.1060 - val_accuracy: 0.6043\n","Epoch 91/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0275 - accuracy: 0.6804 - val_loss: 1.1007 - val_accuracy: 0.6033\n","Epoch 92/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0212 - accuracy: 0.6780 - val_loss: 1.0998 - val_accuracy: 0.6074\n","Epoch 93/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.0185 - accuracy: 0.6744 - val_loss: 1.1013 - val_accuracy: 0.6023\n","Epoch 94/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0108 - accuracy: 0.6770 - val_loss: 1.0927 - val_accuracy: 0.6105\n","Epoch 95/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0061 - accuracy: 0.6850 - val_loss: 1.0961 - val_accuracy: 0.6064\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0008 - accuracy: 0.6850 - val_loss: 1.0942 - val_accuracy: 0.6116\n","Epoch 97/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9933 - accuracy: 0.6855 - val_loss: 1.0909 - val_accuracy: 0.6105\n","Epoch 98/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9885 - accuracy: 0.6884 - val_loss: 1.0910 - val_accuracy: 0.6064\n","Epoch 99/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9869 - accuracy: 0.6775 - val_loss: 1.0883 - val_accuracy: 0.6085\n","Epoch 100/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9779 - accuracy: 0.6912 - val_loss: 1.0832 - val_accuracy: 0.6023\n","{'loss': [1.7033026218414307, 1.6920697689056396, 1.6807632446289062, 1.669356346130371, 1.6577340364456177, 1.6457650661468506, 1.6335474252700806, 1.6212252378463745, 1.6098328828811646, 1.5990382432937622, 1.5888255834579468, 1.5786973237991333, 1.5691617727279663, 1.5592222213745117, 1.5495383739471436, 1.5397863388061523, 1.5306453704833984, 1.5214372873306274, 1.512043833732605, 1.5028061866760254, 1.4935530424118042, 1.4846293926239014, 1.475164532661438, 1.4660000801086426, 1.4571962356567383, 1.4477221965789795, 1.4381147623062134, 1.428825855255127, 1.4194291830062866, 1.4097903966903687, 1.4006372690200806, 1.391201376914978, 1.38412606716156, 1.3752301931381226, 1.366739273071289, 1.3587054014205933, 1.350907802581787, 1.3432999849319458, 1.335103154182434, 1.3277417421340942, 1.3209642171859741, 1.3126840591430664, 1.3058658838272095, 1.3003772497177124, 1.293520450592041, 1.2864519357681274, 1.2795501947402954, 1.2723827362060547, 1.266938328742981, 1.2615106105804443, 1.2533515691757202, 1.2489145994186401, 1.2420872449874878, 1.2348871231079102, 1.2290736436843872, 1.2234238386154175, 1.217522144317627, 1.210516333580017, 1.2042986154556274, 1.199610948562622, 1.1929889917373657, 1.1892162561416626, 1.1828887462615967, 1.1767890453338623, 1.1725258827209473, 1.164799451828003, 1.1602476835250854, 1.152234435081482, 1.14859938621521, 1.1421626806259155, 1.1354081630706787, 1.1325711011886597, 1.1262425184249878, 1.1201361417770386, 1.113962173461914, 1.11044180393219, 1.1060792207717896, 1.1003036499023438, 1.094500184059143, 1.0904505252838135, 1.0806456804275513, 1.0765492916107178, 1.0713269710540771, 1.0644160509109497, 1.0603282451629639, 1.0577852725982666, 1.0522042512893677, 1.042810320854187, 1.042304515838623, 1.0307642221450806, 1.0275137424468994, 1.0212448835372925, 1.0185179710388184, 1.0107522010803223, 1.006069302558899, 1.0008494853973389, 0.9932987689971924, 0.9884876012802124, 0.9869198203086853, 0.9778903722763062], 'accuracy': [0.501808762550354, 0.5609819293022156, 0.5723513960838318, 0.5700258612632751, 0.566149890422821, 0.5617570877075195, 0.5547803640365601, 0.5568475723266602, 0.5568475723266602, 0.567958652973175, 0.5677002668380737, 0.5687338709831238, 0.5702842473983765, 0.5754522085189819, 0.5772609710693359, 0.5733850002288818, 0.5757105946540833, 0.5744186043739319, 0.5803617835044861, 0.5790697932243347, 0.5803617835044861, 0.5837209224700928, 0.5852712988853455, 0.5824289321899414, 0.5847545266151428, 0.5899224877357483, 0.5875968933105469, 0.5956072211265564, 0.5968992114067078, 0.5958656072616577, 0.5997415781021118, 0.5994831919670105, 0.605684757232666, 0.604651153087616, 0.6049095392227173, 0.6098191142082214, 0.6067183613777161, 0.6113694906234741, 0.6085271239280701, 0.6134366989135742, 0.6121447086334229, 0.6186046600341797, 0.6217054128646851, 0.6149870753288269, 0.620671808719635, 0.6204134225845337, 0.6237726211547852, 0.620671808719635, 0.6136950850486755, 0.6227390170097351, 0.6286821961402893, 0.6196382641792297, 0.619896650314331, 0.6237726211547852, 0.6271317601203918, 0.6304909586906433, 0.6317829489707947, 0.630232572555542, 0.6328165531158447, 0.633074939250946, 0.6297157406806946, 0.6307493448257446, 0.6369509100914001, 0.6382429003715515, 0.6341085433959961, 0.6410852670669556, 0.6436692476272583, 0.6408268809318542, 0.643410861492157, 0.6459948420524597, 0.643410861492157, 0.6447028517723083, 0.6516795754432678, 0.6498708128929138, 0.6511628031730652, 0.6478036046028137, 0.6379845142364502, 0.6506459712982178, 0.6534883975982666, 0.6498708128929138, 0.6625322699546814, 0.6622738838195801, 0.6589147448539734, 0.6633074879646301, 0.6671834588050842, 0.6552971601486206, 0.6635658740997314, 0.669767439365387, 0.6638242602348328, 0.6746770143508911, 0.6803617477416992, 0.6780361533164978, 0.6744186282157898, 0.6770026087760925, 0.685012936592102, 0.685012936592102, 0.6855297088623047, 0.6883720755577087, 0.6775193810462952, 0.6912144422531128], 'val_loss': [1.6976200342178345, 1.6867066621780396, 1.6759148836135864, 1.6652376651763916, 1.6546754837036133, 1.6441903114318848, 1.6337454319000244, 1.6233711242675781, 1.6129406690597534, 1.6028103828430176, 1.592606544494629, 1.582606554031372, 1.572983980178833, 1.5631204843521118, 1.5532466173171997, 1.5437970161437988, 1.5342724323272705, 1.5249344110488892, 1.515704870223999, 1.5066800117492676, 1.4977916479110718, 1.488958716392517, 1.4802747964859009, 1.4718431234359741, 1.462591290473938, 1.4541923999786377, 1.4455647468566895, 1.4360840320587158, 1.4281384944915771, 1.4201695919036865, 1.412304401397705, 1.4025412797927856, 1.3985397815704346, 1.389249563217163, 1.3787257671356201, 1.3737094402313232, 1.3667584657669067, 1.3557814359664917, 1.3497636318206787, 1.3448569774627686, 1.333971381187439, 1.3357672691345215, 1.3213154077529907, 1.3161637783050537, 1.3078588247299194, 1.304544448852539, 1.2953814268112183, 1.2925509214401245, 1.2906429767608643, 1.2849314212799072, 1.2736552953720093, 1.2676198482513428, 1.2621715068817139, 1.258098840713501, 1.2530015707015991, 1.2471016645431519, 1.2428319454193115, 1.235848069190979, 1.2336978912353516, 1.2239264249801636, 1.2212051153182983, 1.2172589302062988, 1.2136476039886475, 1.2039297819137573, 1.1999844312667847, 1.1934865713119507, 1.189046025276184, 1.1852633953094482, 1.1825039386749268, 1.1798689365386963, 1.1747958660125732, 1.1767222881317139, 1.1667293310165405, 1.1595994234085083, 1.1563267707824707, 1.1507747173309326, 1.148635745048523, 1.1460505723953247, 1.1404930353164673, 1.1382927894592285, 1.1332523822784424, 1.1285091638565063, 1.1247649192810059, 1.1277518272399902, 1.1233609914779663, 1.1194024085998535, 1.111801028251648, 1.111390471458435, 1.1079760789871216, 1.1059643030166626, 1.1007146835327148, 1.099758267402649, 1.1013233661651611, 1.0927144289016724, 1.09611976146698, 1.0941928625106812, 1.0908966064453125, 1.0910269021987915, 1.0883021354675293, 1.0831892490386963], 'val_accuracy': [0.51962810754776, 0.51962810754776, 0.5185950398445129, 0.5247933864593506, 0.5340909361839294, 0.5413222908973694, 0.5495867729187012, 0.5537189841270447, 0.5640496015548706, 0.5619834661483765, 0.5692148804664612, 0.567148745059967, 0.5681818127632141, 0.5712810158729553, 0.5785123705863953, 0.5805785059928894, 0.5816115736961365, 0.5805785059928894, 0.5764462947845459, 0.5816115736961365, 0.5847107172012329, 0.5847107172012329, 0.586776852607727, 0.5898760557174683, 0.58574378490448, 0.5878099203109741, 0.5888429880142212, 0.5836777091026306, 0.5929751992225647, 0.5888429880142212, 0.5888429880142212, 0.5898760557174683, 0.5929751992225647, 0.5971074104309082, 0.5847107172012329, 0.5919421315193176, 0.5991735458374023, 0.5878099203109741, 0.5929751992225647, 0.5981404781341553, 0.5971074104309082, 0.6064049601554871, 0.5919421315193176, 0.5909090638160706, 0.5960744023323059, 0.6012396812438965, 0.5991735458374023, 0.5971074104309082, 0.60537189245224, 0.6074380278587341, 0.6012396812438965, 0.6033057570457458, 0.6002066135406494, 0.6022727489471436, 0.6043388247489929, 0.6064049601554871, 0.6095041036605835, 0.6074380278587341, 0.6136363744735718, 0.6043388247489929, 0.6146694421768188, 0.6136363744735718, 0.60537189245224, 0.6074380278587341, 0.6064049601554871, 0.6115702390670776, 0.6022727489471436, 0.60537189245224, 0.6064049601554871, 0.60537189245224, 0.6064049601554871, 0.6074380278587341, 0.6095041036605835, 0.6095041036605835, 0.5960744023323059, 0.6126033067703247, 0.6105371713638306, 0.6095041036605835, 0.6126033067703247, 0.6084710955619812, 0.6136363744735718, 0.6136363744735718, 0.6146694421768188, 0.6115702390670776, 0.6177685856819153, 0.6105371713638306, 0.6115702390670776, 0.6064049601554871, 0.6064049601554871, 0.6043388247489929, 0.6033057570457458, 0.6074380278587341, 0.6022727489471436, 0.6105371713638306, 0.6064049601554871, 0.6115702390670776, 0.6105371713638306, 0.6064049601554871, 0.6084710955619812, 0.6022727489471436]}\n","32/32 [==============================] - 1s 11ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 1.0609 - accuracy: 0.6067"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 7s 56ms/step - loss: 1.0592 - accuracy: 0.6121 - val_loss: 1.0989 - val_accuracy: 0.5162\n","Epoch 2/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0363 - accuracy: 0.6522 - val_loss: 1.0968 - val_accuracy: 0.5162\n","Epoch 3/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.0289 - accuracy: 0.6546 - val_loss: 1.0928 - val_accuracy: 0.5183\n","Epoch 4/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0205 - accuracy: 0.6633 - val_loss: 1.0896 - val_accuracy: 0.5183\n","Epoch 5/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.0147 - accuracy: 0.6643 - val_loss: 1.0832 - val_accuracy: 0.5248\n","Epoch 6/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0092 - accuracy: 0.6552 - val_loss: 1.0824 - val_accuracy: 0.5226\n","Epoch 7/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0044 - accuracy: 0.6576 - val_loss: 1.0815 - val_accuracy: 0.5226\n","Epoch 8/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.9991 - accuracy: 0.6657 - val_loss: 1.0728 - val_accuracy: 0.5269\n","Epoch 9/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.9947 - accuracy: 0.6571 - val_loss: 1.0616 - val_accuracy: 0.5409\n","Epoch 10/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9909 - accuracy: 0.6662 - val_loss: 1.0591 - val_accuracy: 0.5399\n","Epoch 11/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9846 - accuracy: 0.6724 - val_loss: 1.0577 - val_accuracy: 0.5399\n","Epoch 12/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.9784 - accuracy: 0.6711 - val_loss: 1.0501 - val_accuracy: 0.5485\n","Epoch 13/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.9746 - accuracy: 0.6659 - val_loss: 1.0341 - val_accuracy: 0.5787\n","Epoch 14/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9682 - accuracy: 0.6724 - val_loss: 1.0275 - val_accuracy: 0.5884\n","Epoch 15/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9629 - accuracy: 0.6762 - val_loss: 1.0252 - val_accuracy: 0.5830\n","Epoch 16/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9604 - accuracy: 0.6721 - val_loss: 1.0188 - val_accuracy: 0.5851\n","Epoch 17/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.9542 - accuracy: 0.6783 - val_loss: 1.0053 - val_accuracy: 0.6078\n","Epoch 18/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.9504 - accuracy: 0.6800 - val_loss: 0.9925 - val_accuracy: 0.6336\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9437 - accuracy: 0.6816 - val_loss: 0.9900 - val_accuracy: 0.6293\n","Epoch 20/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9404 - accuracy: 0.6789 - val_loss: 0.9775 - val_accuracy: 0.6272\n","Epoch 21/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9405 - accuracy: 0.6751 - val_loss: 0.9814 - val_accuracy: 0.6239\n","Epoch 22/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9300 - accuracy: 0.6848 - val_loss: 0.9672 - val_accuracy: 0.6293\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9237 - accuracy: 0.6905 - val_loss: 0.9619 - val_accuracy: 0.6304\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9225 - accuracy: 0.6870 - val_loss: 0.9571 - val_accuracy: 0.6272\n","Epoch 25/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.9189 - accuracy: 0.6835 - val_loss: 0.9585 - val_accuracy: 0.6347\n","Epoch 26/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9120 - accuracy: 0.6902 - val_loss: 0.9506 - val_accuracy: 0.6347\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9077 - accuracy: 0.6915 - val_loss: 0.9481 - val_accuracy: 0.6304\n","Epoch 28/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.9016 - accuracy: 0.6937 - val_loss: 0.9450 - val_accuracy: 0.6433\n","Epoch 29/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9003 - accuracy: 0.6932 - val_loss: 0.9427 - val_accuracy: 0.6336\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8928 - accuracy: 0.6967 - val_loss: 0.9448 - val_accuracy: 0.6304\n","Epoch 31/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.8946 - accuracy: 0.6921 - val_loss: 0.9388 - val_accuracy: 0.6476\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8853 - accuracy: 0.7029 - val_loss: 0.9373 - val_accuracy: 0.6422\n","Epoch 33/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8921 - accuracy: 0.6886 - val_loss: 0.9350 - val_accuracy: 0.6304\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8808 - accuracy: 0.6929 - val_loss: 0.9337 - val_accuracy: 0.6336\n","Epoch 35/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8747 - accuracy: 0.7034 - val_loss: 0.9341 - val_accuracy: 0.6282\n","Epoch 36/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.8676 - accuracy: 0.7104 - val_loss: 0.9300 - val_accuracy: 0.6358\n","Epoch 37/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8699 - accuracy: 0.7031 - val_loss: 0.9269 - val_accuracy: 0.6336\n","Epoch 38/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8625 - accuracy: 0.7055 - val_loss: 0.9268 - val_accuracy: 0.6347\n","Epoch 39/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8582 - accuracy: 0.7031 - val_loss: 0.9227 - val_accuracy: 0.6358\n","Epoch 40/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8560 - accuracy: 0.7053 - val_loss: 0.9212 - val_accuracy: 0.6336\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8525 - accuracy: 0.7082 - val_loss: 0.9222 - val_accuracy: 0.6347\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8438 - accuracy: 0.7142 - val_loss: 0.9194 - val_accuracy: 0.6336\n","Epoch 43/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8469 - accuracy: 0.7004 - val_loss: 0.9187 - val_accuracy: 0.6315\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8411 - accuracy: 0.7128 - val_loss: 0.9207 - val_accuracy: 0.6347\n","Epoch 45/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8431 - accuracy: 0.7047 - val_loss: 0.9157 - val_accuracy: 0.6336\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8365 - accuracy: 0.7193 - val_loss: 0.9178 - val_accuracy: 0.6325\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8275 - accuracy: 0.7247 - val_loss: 0.9109 - val_accuracy: 0.6369\n","Epoch 48/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8273 - accuracy: 0.7177 - val_loss: 0.9140 - val_accuracy: 0.6466\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8197 - accuracy: 0.7231 - val_loss: 0.9094 - val_accuracy: 0.6379\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8206 - accuracy: 0.7244 - val_loss: 0.9224 - val_accuracy: 0.6390\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8144 - accuracy: 0.7263 - val_loss: 0.9112 - val_accuracy: 0.6433\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8172 - accuracy: 0.7179 - val_loss: 0.9106 - val_accuracy: 0.6412\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8104 - accuracy: 0.7239 - val_loss: 0.9095 - val_accuracy: 0.6261\n","Epoch 54/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.8062 - accuracy: 0.7204 - val_loss: 0.9106 - val_accuracy: 0.6336\n","Epoch 55/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.8031 - accuracy: 0.7309 - val_loss: 0.9099 - val_accuracy: 0.6369\n","Epoch 56/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7972 - accuracy: 0.7204 - val_loss: 0.9037 - val_accuracy: 0.6261\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7954 - accuracy: 0.7306 - val_loss: 0.9031 - val_accuracy: 0.6315\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7938 - accuracy: 0.7271 - val_loss: 0.9008 - val_accuracy: 0.6444\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7886 - accuracy: 0.7325 - val_loss: 0.8997 - val_accuracy: 0.6315\n","Epoch 60/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7837 - accuracy: 0.7333 - val_loss: 0.8984 - val_accuracy: 0.6369\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7871 - accuracy: 0.7298 - val_loss: 0.9017 - val_accuracy: 0.6282\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7812 - accuracy: 0.7355 - val_loss: 0.9006 - val_accuracy: 0.6401\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7781 - accuracy: 0.7311 - val_loss: 0.8999 - val_accuracy: 0.6336\n","Epoch 64/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7768 - accuracy: 0.7349 - val_loss: 0.8990 - val_accuracy: 0.6422\n","Epoch 65/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7719 - accuracy: 0.7390 - val_loss: 0.9152 - val_accuracy: 0.6369\n","Epoch 66/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7713 - accuracy: 0.7352 - val_loss: 0.8954 - val_accuracy: 0.6325\n","Epoch 67/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7617 - accuracy: 0.7454 - val_loss: 0.8970 - val_accuracy: 0.6336\n","Epoch 68/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7637 - accuracy: 0.7322 - val_loss: 0.8968 - val_accuracy: 0.6379\n","Epoch 69/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7575 - accuracy: 0.7433 - val_loss: 0.8979 - val_accuracy: 0.6358\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7511 - accuracy: 0.7511 - val_loss: 0.8956 - val_accuracy: 0.6369\n","Epoch 71/100\n","29/29 [==============================] - 2s 61ms/step - loss: 0.7545 - accuracy: 0.7430 - val_loss: 0.9002 - val_accuracy: 0.6552\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7523 - accuracy: 0.7398 - val_loss: 0.9130 - val_accuracy: 0.6433\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7499 - accuracy: 0.7443 - val_loss: 0.8935 - val_accuracy: 0.6369\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7450 - accuracy: 0.7457 - val_loss: 0.8915 - val_accuracy: 0.6336\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7402 - accuracy: 0.7484 - val_loss: 0.8924 - val_accuracy: 0.6379\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7383 - accuracy: 0.7487 - val_loss: 0.8949 - val_accuracy: 0.6325\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7368 - accuracy: 0.7516 - val_loss: 0.8923 - val_accuracy: 0.6455\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7245 - accuracy: 0.7578 - val_loss: 0.8896 - val_accuracy: 0.6433\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7261 - accuracy: 0.7516 - val_loss: 0.9052 - val_accuracy: 0.6455\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7357 - accuracy: 0.7400 - val_loss: 0.8908 - val_accuracy: 0.6390\n","Epoch 81/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7218 - accuracy: 0.7575 - val_loss: 0.9019 - val_accuracy: 0.6487\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7278 - accuracy: 0.7524 - val_loss: 0.9108 - val_accuracy: 0.6390\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7224 - accuracy: 0.7511 - val_loss: 0.9047 - val_accuracy: 0.6422\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7180 - accuracy: 0.7575 - val_loss: 0.8892 - val_accuracy: 0.6401\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7161 - accuracy: 0.7584 - val_loss: 0.8947 - val_accuracy: 0.6487\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7079 - accuracy: 0.7621 - val_loss: 0.8945 - val_accuracy: 0.6422\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7079 - accuracy: 0.7621 - val_loss: 0.8960 - val_accuracy: 0.6369\n","Epoch 88/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7059 - accuracy: 0.7627 - val_loss: 0.8905 - val_accuracy: 0.6455\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6990 - accuracy: 0.7594 - val_loss: 0.9108 - val_accuracy: 0.6401\n","Epoch 90/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.7009 - accuracy: 0.7616 - val_loss: 0.8982 - val_accuracy: 0.6444\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6969 - accuracy: 0.7662 - val_loss: 0.8911 - val_accuracy: 0.6379\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6975 - accuracy: 0.7632 - val_loss: 0.8954 - val_accuracy: 0.6358\n","Epoch 93/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6920 - accuracy: 0.7651 - val_loss: 0.8967 - val_accuracy: 0.6422\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6930 - accuracy: 0.7632 - val_loss: 0.9185 - val_accuracy: 0.6466\n","Epoch 95/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6820 - accuracy: 0.7751 - val_loss: 0.8976 - val_accuracy: 0.6498\n","Epoch 96/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6839 - accuracy: 0.7726 - val_loss: 0.9018 - val_accuracy: 0.6444\n","Epoch 97/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6772 - accuracy: 0.7651 - val_loss: 0.8988 - val_accuracy: 0.6519\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6833 - accuracy: 0.7654 - val_loss: 0.9071 - val_accuracy: 0.6509\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6812 - accuracy: 0.7675 - val_loss: 0.9063 - val_accuracy: 0.6487\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6741 - accuracy: 0.7686 - val_loss: 0.8999 - val_accuracy: 0.6487\n","{'loss': [1.0591750144958496, 1.0362528562545776, 1.028887391090393, 1.0204687118530273, 1.0147004127502441, 1.0091925859451294, 1.0043635368347168, 0.9990633726119995, 0.9947088956832886, 0.9909467101097107, 0.984603226184845, 0.9783868193626404, 0.974646270275116, 0.9681622982025146, 0.9628556370735168, 0.9603941440582275, 0.9542142152786255, 0.9504342079162598, 0.9436588287353516, 0.9404025673866272, 0.940463662147522, 0.929977536201477, 0.9237185120582581, 0.9225043058395386, 0.9188627600669861, 0.9120225310325623, 0.9077231287956238, 0.9016221761703491, 0.9002552628517151, 0.8928322196006775, 0.8946263790130615, 0.8853374719619751, 0.8921482563018799, 0.8808378577232361, 0.8746886849403381, 0.8675726652145386, 0.8698663115501404, 0.8624668121337891, 0.8582166433334351, 0.855996310710907, 0.8525089621543884, 0.8438335657119751, 0.8469097018241882, 0.8410975933074951, 0.8431408405303955, 0.8364974856376648, 0.8275433778762817, 0.8272718191146851, 0.819717526435852, 0.8206338286399841, 0.8143990635871887, 0.8171833753585815, 0.810424268245697, 0.8062190413475037, 0.8030906319618225, 0.7971690893173218, 0.7953737378120422, 0.7938136458396912, 0.7886136174201965, 0.7837411761283875, 0.787056028842926, 0.781233012676239, 0.7780848145484924, 0.7767899632453918, 0.7718717455863953, 0.7712739109992981, 0.7616811394691467, 0.7637390494346619, 0.757457971572876, 0.7511001229286194, 0.7545021176338196, 0.7523242235183716, 0.7499061226844788, 0.7450072169303894, 0.7402100563049316, 0.7383033037185669, 0.7368093132972717, 0.7244653105735779, 0.7260995507240295, 0.7356911301612854, 0.7217759490013123, 0.7278296947479248, 0.72239089012146, 0.7180435657501221, 0.7160881757736206, 0.7079383134841919, 0.7079370021820068, 0.7058701515197754, 0.6990363001823425, 0.7008696794509888, 0.6969032287597656, 0.6975472569465637, 0.6920485496520996, 0.6930187940597534, 0.6819862127304077, 0.6838686466217041, 0.6772424578666687, 0.6833460330963135, 0.6811839938163757, 0.6740587949752808], 'accuracy': [0.6120689511299133, 0.6522090435028076, 0.654633641242981, 0.6632543206214905, 0.6643319129943848, 0.6551724076271057, 0.657597005367279, 0.665678858757019, 0.6570581793785095, 0.6662176847457886, 0.6724137663841248, 0.6710668206214905, 0.6659482717514038, 0.6724137663841248, 0.6761853694915771, 0.6721444129943848, 0.678340494632721, 0.6799569129943848, 0.6815732717514038, 0.6788793206214905, 0.6751077771186829, 0.6848060488700867, 0.6904633641242981, 0.6869612336158752, 0.6834590435028076, 0.6901939511299133, 0.6915409564971924, 0.693696141242981, 0.6931573152542114, 0.696659505367279, 0.6920797228813171, 0.7028555870056152, 0.6885775923728943, 0.6928879022598267, 0.7033944129943848, 0.7103987336158752, 0.703125, 0.7055495977401733, 0.703125, 0.7052801847457886, 0.7082435488700867, 0.7141702771186829, 0.7004310488700867, 0.7128232717514038, 0.704741358757019, 0.7192887663841248, 0.7246767282485962, 0.7176724076271057, 0.7230603694915771, 0.7244073152542114, 0.7262930870056152, 0.7179418206214905, 0.7238685488700867, 0.720366358757019, 0.7308728694915771, 0.720366358757019, 0.7306034564971924, 0.7271012663841248, 0.7324892282485962, 0.7332974076271057, 0.7297952771186829, 0.7354525923728943, 0.7311422228813171, 0.7349137663841248, 0.7389547228813171, 0.7351831793785095, 0.7454202771186829, 0.7322198152542114, 0.7432650923728943, 0.7510775923728943, 0.7429956793785095, 0.7397629022598267, 0.7443426847457886, 0.7456896305084229, 0.748383641242981, 0.748652994632721, 0.751616358757019, 0.7578125, 0.751616358757019, 0.7400323152542114, 0.7575430870056152, 0.7524245977401733, 0.7510775923728943, 0.7575430870056152, 0.7583512663841248, 0.7621228694915771, 0.7621228694915771, 0.7626616358757019, 0.759428858757019, 0.7615840435028076, 0.7661637663841248, 0.7632004022598267, 0.7650862336158752, 0.7632004022598267, 0.775053858757019, 0.7726293206214905, 0.7650862336158752, 0.7653555870056152, 0.7675107717514038, 0.7685883641242981], 'val_loss': [1.09894859790802, 1.09675931930542, 1.0927735567092896, 1.0895767211914062, 1.0832185745239258, 1.082417368888855, 1.0815337896347046, 1.072835087776184, 1.06155526638031, 1.0590989589691162, 1.0576629638671875, 1.0501047372817993, 1.034077763557434, 1.0275089740753174, 1.0251965522766113, 1.0188182592391968, 1.005276083946228, 0.9925497770309448, 0.9899916052818298, 0.9775372743606567, 0.9814198017120361, 0.9671880006790161, 0.9618639349937439, 0.9571417570114136, 0.9585170149803162, 0.950573742389679, 0.9480851292610168, 0.9450185298919678, 0.9426835775375366, 0.9448476433753967, 0.9388233423233032, 0.9372550845146179, 0.9350329041481018, 0.933742880821228, 0.9340554475784302, 0.930004894733429, 0.9269452691078186, 0.9268122911453247, 0.9226517081260681, 0.9211837649345398, 0.922247588634491, 0.9194100499153137, 0.9186920523643494, 0.9206736087799072, 0.9157266020774841, 0.9177629351615906, 0.9109255075454712, 0.913977324962616, 0.9093543291091919, 0.9223737120628357, 0.9111595153808594, 0.9105791449546814, 0.909513533115387, 0.910576343536377, 0.9099082946777344, 0.9037397503852844, 0.9031484723091125, 0.9007809162139893, 0.8997038006782532, 0.8983922600746155, 0.9016697406768799, 0.9005705118179321, 0.8999481201171875, 0.8989865779876709, 0.9151664972305298, 0.8954383134841919, 0.896973729133606, 0.8968417644500732, 0.8978946805000305, 0.8955731391906738, 0.9002404808998108, 0.9130071401596069, 0.8935035467147827, 0.8914883732795715, 0.8924405574798584, 0.8949476480484009, 0.8922743797302246, 0.8895592093467712, 0.905180037021637, 0.8907727003097534, 0.9019094109535217, 0.9108498692512512, 0.904712438583374, 0.8892015218734741, 0.8947494029998779, 0.8945437073707581, 0.8959574103355408, 0.8905264735221863, 0.9108022451400757, 0.8982270359992981, 0.8911183476448059, 0.8953724503517151, 0.8967009782791138, 0.9185239672660828, 0.8975986242294312, 0.9017690420150757, 0.8988478183746338, 0.9070921540260315, 0.9063389301300049, 0.8999300599098206], 'val_accuracy': [0.5161637663841248, 0.5161637663841248, 0.5183189511299133, 0.5183189511299133, 0.524784505367279, 0.5226293206214905, 0.5226293206214905, 0.5269396305084229, 0.5409482717514038, 0.5398706793785095, 0.5398706793785095, 0.548491358757019, 0.5786637663841248, 0.5883620977401733, 0.5829741358757019, 0.5851293206214905, 0.607758641242981, 0.6336206793785095, 0.6293103694915771, 0.6271551847457886, 0.6239224076271057, 0.6293103694915771, 0.6303879022598267, 0.6271551847457886, 0.6346982717514038, 0.6346982717514038, 0.6303879022598267, 0.6433189511299133, 0.6336206793785095, 0.6303879022598267, 0.6476293206214905, 0.642241358757019, 0.6303879022598267, 0.6336206793785095, 0.6282327771186829, 0.6357758641242981, 0.6336206793785095, 0.6346982717514038, 0.6357758641242981, 0.6336206793785095, 0.6346982717514038, 0.6336206793785095, 0.631465494632721, 0.6346982717514038, 0.6336206793785095, 0.6325430870056152, 0.6368534564971924, 0.6465517282485962, 0.6379310488700867, 0.639008641242981, 0.6433189511299133, 0.6411637663841248, 0.6260775923728943, 0.6336206793785095, 0.6368534564971924, 0.6260775923728943, 0.631465494632721, 0.6443965435028076, 0.631465494632721, 0.6368534564971924, 0.6282327771186829, 0.6400862336158752, 0.6336206793785095, 0.642241358757019, 0.6368534564971924, 0.6325430870056152, 0.6336206793785095, 0.6379310488700867, 0.6357758641242981, 0.6368534564971924, 0.6551724076271057, 0.6433189511299133, 0.6368534564971924, 0.6336206793785095, 0.6379310488700867, 0.6325430870056152, 0.6454741358757019, 0.6433189511299133, 0.6454741358757019, 0.639008641242981, 0.6487069129943848, 0.639008641242981, 0.642241358757019, 0.6400862336158752, 0.6487069129943848, 0.642241358757019, 0.6368534564971924, 0.6454741358757019, 0.6400862336158752, 0.6443965435028076, 0.6379310488700867, 0.6357758641242981, 0.642241358757019, 0.6465517282485962, 0.649784505367279, 0.6443965435028076, 0.6519396305084229, 0.6508620977401733, 0.6487069129943848, 0.6487069129943848]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 1.0640 - accuracy: 0.6013"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 64ms/step - loss: 1.0618 - accuracy: 0.6078 - val_loss: 1.1019 - val_accuracy: 0.5045\n","Epoch 2/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0389 - accuracy: 0.6508 - val_loss: 1.1008 - val_accuracy: 0.5045\n","Epoch 3/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0314 - accuracy: 0.6466 - val_loss: 1.0979 - val_accuracy: 0.5045\n","Epoch 4/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0269 - accuracy: 0.6537 - val_loss: 1.0951 - val_accuracy: 0.5045\n","Epoch 5/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0191 - accuracy: 0.6542 - val_loss: 1.0934 - val_accuracy: 0.5034\n","Epoch 6/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.0151 - accuracy: 0.6505 - val_loss: 1.0863 - val_accuracy: 0.5057\n","Epoch 7/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.0091 - accuracy: 0.6522 - val_loss: 1.0829 - val_accuracy: 0.5068\n","Epoch 8/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.0045 - accuracy: 0.6511 - val_loss: 1.0758 - val_accuracy: 0.5136\n","Epoch 9/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9991 - accuracy: 0.6534 - val_loss: 1.0694 - val_accuracy: 0.5170\n","Epoch 10/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9927 - accuracy: 0.6548 - val_loss: 1.0699 - val_accuracy: 0.5158\n","Epoch 11/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9876 - accuracy: 0.6627 - val_loss: 1.0619 - val_accuracy: 0.5317\n","Epoch 12/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.9840 - accuracy: 0.6551 - val_loss: 1.0555 - val_accuracy: 0.5385\n","Epoch 13/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.9782 - accuracy: 0.6667 - val_loss: 1.0482 - val_accuracy: 0.5577\n","Epoch 14/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.9768 - accuracy: 0.6576 - val_loss: 1.0371 - val_accuracy: 0.5769\n","Epoch 15/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9742 - accuracy: 0.6650 - val_loss: 1.0477 - val_accuracy: 0.5486\n","Epoch 16/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9634 - accuracy: 0.6678 - val_loss: 1.0282 - val_accuracy: 0.5769\n","Epoch 17/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.9565 - accuracy: 0.6752 - val_loss: 1.0249 - val_accuracy: 0.5837\n","Epoch 18/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.9527 - accuracy: 0.6740 - val_loss: 1.0146 - val_accuracy: 0.5962\n","Epoch 19/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9495 - accuracy: 0.6737 - val_loss: 1.0092 - val_accuracy: 0.5928\n","Epoch 20/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9455 - accuracy: 0.6783 - val_loss: 1.0073 - val_accuracy: 0.5905\n","Epoch 21/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.9417 - accuracy: 0.6743 - val_loss: 0.9978 - val_accuracy: 0.6143\n","Epoch 22/100\n","28/28 [==============================] - 1s 17ms/step - loss: 0.9369 - accuracy: 0.6808 - val_loss: 0.9962 - val_accuracy: 0.6052\n","Epoch 23/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9299 - accuracy: 0.6780 - val_loss: 0.9848 - val_accuracy: 0.6324\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9309 - accuracy: 0.6737 - val_loss: 0.9835 - val_accuracy: 0.6324\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9196 - accuracy: 0.6879 - val_loss: 0.9838 - val_accuracy: 0.6244\n","Epoch 26/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9190 - accuracy: 0.6885 - val_loss: 0.9735 - val_accuracy: 0.6312\n","Epoch 27/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.9125 - accuracy: 0.6887 - val_loss: 0.9758 - val_accuracy: 0.6346\n","Epoch 28/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9088 - accuracy: 0.6876 - val_loss: 0.9667 - val_accuracy: 0.6324\n","Epoch 29/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9016 - accuracy: 0.6947 - val_loss: 0.9668 - val_accuracy: 0.6335\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8985 - accuracy: 0.6967 - val_loss: 0.9650 - val_accuracy: 0.6290\n","Epoch 31/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.8966 - accuracy: 0.6876 - val_loss: 0.9589 - val_accuracy: 0.6391\n","Epoch 32/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8888 - accuracy: 0.6964 - val_loss: 0.9619 - val_accuracy: 0.6369\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8924 - accuracy: 0.6910 - val_loss: 0.9618 - val_accuracy: 0.6357\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8865 - accuracy: 0.6967 - val_loss: 0.9571 - val_accuracy: 0.6346\n","Epoch 35/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8818 - accuracy: 0.7018 - val_loss: 0.9548 - val_accuracy: 0.6403\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8727 - accuracy: 0.7057 - val_loss: 0.9635 - val_accuracy: 0.6380\n","Epoch 37/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.8691 - accuracy: 0.7023 - val_loss: 0.9542 - val_accuracy: 0.6437\n","Epoch 38/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.8688 - accuracy: 0.7049 - val_loss: 0.9521 - val_accuracy: 0.6459\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8621 - accuracy: 0.7125 - val_loss: 0.9508 - val_accuracy: 0.6369\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8626 - accuracy: 0.7068 - val_loss: 0.9576 - val_accuracy: 0.6324\n","Epoch 41/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8569 - accuracy: 0.7091 - val_loss: 0.9479 - val_accuracy: 0.6324\n","Epoch 42/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8535 - accuracy: 0.7108 - val_loss: 0.9508 - val_accuracy: 0.6290\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8467 - accuracy: 0.7066 - val_loss: 0.9496 - val_accuracy: 0.6278\n","Epoch 44/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8489 - accuracy: 0.7105 - val_loss: 0.9501 - val_accuracy: 0.6357\n","Epoch 45/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.8380 - accuracy: 0.7145 - val_loss: 0.9431 - val_accuracy: 0.6595\n","Epoch 46/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8335 - accuracy: 0.7176 - val_loss: 0.9481 - val_accuracy: 0.6380\n","Epoch 47/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8342 - accuracy: 0.7170 - val_loss: 0.9471 - val_accuracy: 0.6301\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8281 - accuracy: 0.7173 - val_loss: 0.9479 - val_accuracy: 0.6437\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8227 - accuracy: 0.7213 - val_loss: 0.9454 - val_accuracy: 0.6391\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8240 - accuracy: 0.7136 - val_loss: 0.9449 - val_accuracy: 0.6437\n","Epoch 51/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8223 - accuracy: 0.7193 - val_loss: 0.9451 - val_accuracy: 0.6335\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8170 - accuracy: 0.7179 - val_loss: 0.9408 - val_accuracy: 0.6403\n","Epoch 53/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8101 - accuracy: 0.7281 - val_loss: 0.9416 - val_accuracy: 0.6380\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8105 - accuracy: 0.7227 - val_loss: 0.9454 - val_accuracy: 0.6471\n","Epoch 55/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8075 - accuracy: 0.7284 - val_loss: 0.9396 - val_accuracy: 0.6391\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7968 - accuracy: 0.7261 - val_loss: 0.9423 - val_accuracy: 0.6437\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8005 - accuracy: 0.7250 - val_loss: 0.9394 - val_accuracy: 0.6369\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7956 - accuracy: 0.7284 - val_loss: 0.9444 - val_accuracy: 0.6425\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7970 - accuracy: 0.7213 - val_loss: 0.9521 - val_accuracy: 0.6324\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7965 - accuracy: 0.7216 - val_loss: 0.9377 - val_accuracy: 0.6301\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7875 - accuracy: 0.7275 - val_loss: 0.9454 - val_accuracy: 0.6267\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7901 - accuracy: 0.7281 - val_loss: 0.9383 - val_accuracy: 0.6403\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7806 - accuracy: 0.7346 - val_loss: 0.9322 - val_accuracy: 0.6527\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7743 - accuracy: 0.7419 - val_loss: 0.9412 - val_accuracy: 0.6369\n","Epoch 65/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7727 - accuracy: 0.7368 - val_loss: 0.9467 - val_accuracy: 0.6357\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7817 - accuracy: 0.7269 - val_loss: 0.9403 - val_accuracy: 0.6403\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7746 - accuracy: 0.7275 - val_loss: 0.9505 - val_accuracy: 0.6425\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7725 - accuracy: 0.7334 - val_loss: 0.9407 - val_accuracy: 0.6369\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7607 - accuracy: 0.7473 - val_loss: 0.9352 - val_accuracy: 0.6448\n","Epoch 70/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7559 - accuracy: 0.7450 - val_loss: 0.9324 - val_accuracy: 0.6448\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7546 - accuracy: 0.7428 - val_loss: 0.9348 - val_accuracy: 0.6357\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7544 - accuracy: 0.7431 - val_loss: 0.9370 - val_accuracy: 0.6437\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7508 - accuracy: 0.7456 - val_loss: 0.9369 - val_accuracy: 0.6425\n","Epoch 74/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7431 - accuracy: 0.7402 - val_loss: 0.9511 - val_accuracy: 0.6357\n","Epoch 75/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7444 - accuracy: 0.7459 - val_loss: 0.9380 - val_accuracy: 0.6369\n","Epoch 76/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7438 - accuracy: 0.7425 - val_loss: 0.9442 - val_accuracy: 0.6380\n","Epoch 77/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7400 - accuracy: 0.7456 - val_loss: 0.9332 - val_accuracy: 0.6391\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7337 - accuracy: 0.7470 - val_loss: 0.9349 - val_accuracy: 0.6414\n","Epoch 79/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7387 - accuracy: 0.7419 - val_loss: 0.9319 - val_accuracy: 0.6357\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7321 - accuracy: 0.7499 - val_loss: 0.9249 - val_accuracy: 0.6437\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7277 - accuracy: 0.7490 - val_loss: 0.9374 - val_accuracy: 0.6391\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7247 - accuracy: 0.7493 - val_loss: 0.9439 - val_accuracy: 0.6357\n","Epoch 83/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7234 - accuracy: 0.7544 - val_loss: 0.9419 - val_accuracy: 0.6448\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7245 - accuracy: 0.7564 - val_loss: 0.9344 - val_accuracy: 0.6448\n","Epoch 85/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7217 - accuracy: 0.7507 - val_loss: 0.9403 - val_accuracy: 0.6414\n","Epoch 86/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7176 - accuracy: 0.7564 - val_loss: 0.9344 - val_accuracy: 0.6391\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7119 - accuracy: 0.7603 - val_loss: 0.9372 - val_accuracy: 0.6437\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7063 - accuracy: 0.7632 - val_loss: 0.9446 - val_accuracy: 0.6425\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7033 - accuracy: 0.7547 - val_loss: 0.9467 - val_accuracy: 0.6369\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7010 - accuracy: 0.7600 - val_loss: 0.9386 - val_accuracy: 0.6357\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7059 - accuracy: 0.7533 - val_loss: 0.9579 - val_accuracy: 0.6380\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7065 - accuracy: 0.7547 - val_loss: 0.9660 - val_accuracy: 0.6357\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7004 - accuracy: 0.7623 - val_loss: 0.9322 - val_accuracy: 0.6482\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6917 - accuracy: 0.7632 - val_loss: 0.9421 - val_accuracy: 0.6437\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6923 - accuracy: 0.7620 - val_loss: 0.9429 - val_accuracy: 0.6414\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6859 - accuracy: 0.7733 - val_loss: 0.9489 - val_accuracy: 0.6448\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6798 - accuracy: 0.7697 - val_loss: 0.9530 - val_accuracy: 0.6414\n","Epoch 98/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6865 - accuracy: 0.7603 - val_loss: 0.9456 - val_accuracy: 0.6391\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6845 - accuracy: 0.7632 - val_loss: 0.9450 - val_accuracy: 0.6448\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6812 - accuracy: 0.7646 - val_loss: 0.9570 - val_accuracy: 0.6391\n","{'loss': [1.0617947578430176, 1.038874626159668, 1.0313531160354614, 1.026868462562561, 1.0190731287002563, 1.0151337385177612, 1.0091294050216675, 1.004493236541748, 0.9991449117660522, 0.9926624298095703, 0.9876222014427185, 0.984026312828064, 0.978162944316864, 0.9767888784408569, 0.9742141962051392, 0.9634188413619995, 0.9565104842185974, 0.9527366757392883, 0.9495427012443542, 0.9455146193504333, 0.9416652917861938, 0.9368590712547302, 0.9298837184906006, 0.9309409260749817, 0.9195594191551208, 0.9190275073051453, 0.9124706387519836, 0.908840537071228, 0.9016255140304565, 0.898514449596405, 0.8965663313865662, 0.8888348340988159, 0.8923736810684204, 0.8864684700965881, 0.8818499445915222, 0.8727164268493652, 0.8690935373306274, 0.8687809109687805, 0.8620967268943787, 0.8625665307044983, 0.8568531274795532, 0.8535221219062805, 0.8466740250587463, 0.8489101529121399, 0.8380202054977417, 0.8334697484970093, 0.8342264890670776, 0.828113853931427, 0.8227282166481018, 0.8239550590515137, 0.8223164081573486, 0.81703782081604, 0.8101338744163513, 0.8105330467224121, 0.8075414299964905, 0.7967581152915955, 0.8005487322807312, 0.795560359954834, 0.7969515919685364, 0.7965043187141418, 0.7875369191169739, 0.790050745010376, 0.7806277871131897, 0.7742522954940796, 0.7727341055870056, 0.781652569770813, 0.7745909094810486, 0.7725254893302917, 0.7606680393218994, 0.7559322714805603, 0.754593014717102, 0.754438042640686, 0.7508085370063782, 0.7431382536888123, 0.744442880153656, 0.7438095808029175, 0.7399954795837402, 0.7337450385093689, 0.7387226819992065, 0.7321233153343201, 0.7277336716651917, 0.72470623254776, 0.7233717441558838, 0.7245111465454102, 0.721726655960083, 0.7175601124763489, 0.7118797898292542, 0.7062987685203552, 0.7032697796821594, 0.7010097503662109, 0.7058901786804199, 0.7065448760986328, 0.7004100680351257, 0.6916957497596741, 0.6922876834869385, 0.6859135031700134, 0.679834246635437, 0.6865136027336121, 0.6845054030418396, 0.681169331073761], 'accuracy': [0.607809841632843, 0.6508206129074097, 0.6465761065483093, 0.6536502838134766, 0.6542161703109741, 0.6505376100540161, 0.6522354483604431, 0.6511035561561584, 0.653367280960083, 0.6547821164131165, 0.66270512342453, 0.6550650596618652, 0.6666666865348816, 0.6576117873191833, 0.6649688482284546, 0.6677985191345215, 0.6751556396484375, 0.6740237474441528, 0.673740804195404, 0.6782682538032532, 0.6743067502975464, 0.6808149218559265, 0.6779853105545044, 0.673740804195404, 0.6878890991210938, 0.6884549856185913, 0.6887379884719849, 0.6876060962677002, 0.6946802735328674, 0.6966609954833984, 0.6876060962677002, 0.6963780522346497, 0.6910017132759094, 0.6966609954833984, 0.7017543911933899, 0.7057158946990967, 0.7023203372955322, 0.7048670053482056, 0.7125070691108704, 0.7068477869033813, 0.7091115117073059, 0.7108092904090881, 0.7065647840499878, 0.7105262875556946, 0.7144878506660461, 0.7176004648208618, 0.7170345187187195, 0.7173174619674683, 0.7212790250778198, 0.713638961315155, 0.719298243522644, 0.7178834080696106, 0.7280701994895935, 0.7226938605308533, 0.7283531427383423, 0.7260894179344177, 0.7249575257301331, 0.7283531427383423, 0.7212790250778198, 0.7215619683265686, 0.7275042533874512, 0.7280701994895935, 0.7345783710479736, 0.7419354915618896, 0.7368420958518982, 0.7269383072853088, 0.7275042533874512, 0.7334465384483337, 0.7473118305206299, 0.7450481057167053, 0.7427843809127808, 0.7430673241615295, 0.7456140518188477, 0.7402377128601074, 0.7458969950675964, 0.742501437664032, 0.7456140518188477, 0.7470288872718811, 0.7419354915618896, 0.7498584985733032, 0.7490096092224121, 0.7492926120758057, 0.7543859481811523, 0.7563667297363281, 0.7507073879241943, 0.7563667297363281, 0.7603282332420349, 0.7631579041481018, 0.7546689510345459, 0.7600452899932861, 0.7532541155815125, 0.7546689510345459, 0.7623090147972107, 0.7631579041481018, 0.7620260119438171, 0.7733446359634399, 0.7696660757064819, 0.7603282332420349, 0.7631579041481018, 0.7645727396011353], 'val_loss': [1.1019004583358765, 1.1007730960845947, 1.0979424715042114, 1.09505295753479, 1.0934096574783325, 1.0863486528396606, 1.0828584432601929, 1.0757980346679688, 1.0693778991699219, 1.0699385404586792, 1.0619043111801147, 1.0554810762405396, 1.0481702089309692, 1.037105679512024, 1.0476744174957275, 1.0281620025634766, 1.0248603820800781, 1.0146292448043823, 1.009226679801941, 1.0073350667953491, 0.9978427290916443, 0.9961634874343872, 0.984763503074646, 0.9834964871406555, 0.9837606549263, 0.9734700918197632, 0.9757669568061829, 0.9666681289672852, 0.9668119549751282, 0.9650142788887024, 0.9589226245880127, 0.9619470834732056, 0.9618256092071533, 0.9570765495300293, 0.9547773003578186, 0.9635167717933655, 0.9541553258895874, 0.9521083831787109, 0.9508392214775085, 0.9575763940811157, 0.947949230670929, 0.9508053064346313, 0.9495905041694641, 0.9500786066055298, 0.9431388974189758, 0.9480534195899963, 0.947091281414032, 0.9478918313980103, 0.9454358816146851, 0.9449151754379272, 0.9451307654380798, 0.9407960176467896, 0.9416050314903259, 0.9454174637794495, 0.9396355152130127, 0.9422912001609802, 0.9393903613090515, 0.9443621635437012, 0.9521194100379944, 0.9377201199531555, 0.9454454183578491, 0.9382930397987366, 0.9322357177734375, 0.9411534070968628, 0.946712851524353, 0.9402902722358704, 0.9505074620246887, 0.9406603574752808, 0.935234785079956, 0.9323784112930298, 0.9348413348197937, 0.9369574785232544, 0.9368727803230286, 0.9510952830314636, 0.9379802942276001, 0.9441986083984375, 0.9332026243209839, 0.9348558783531189, 0.9318537712097168, 0.9248786568641663, 0.9373863339424133, 0.9439190626144409, 0.9419460296630859, 0.9344363808631897, 0.9402961134910583, 0.9344354271888733, 0.9371687173843384, 0.9446220397949219, 0.9466947913169861, 0.9385623335838318, 0.9578918814659119, 0.9660302996635437, 0.9322327971458435, 0.9421453475952148, 0.94294273853302, 0.9488823413848877, 0.9530407786369324, 0.9455693364143372, 0.9449517726898193, 0.9570457935333252], 'val_accuracy': [0.5045248866081238, 0.5045248866081238, 0.5045248866081238, 0.5045248866081238, 0.5033936500549316, 0.5056561231613159, 0.5067873597145081, 0.5135746598243713, 0.516968309879303, 0.5158371329307556, 0.5316742062568665, 0.5384615659713745, 0.557692289352417, 0.5769230723381042, 0.5486425161361694, 0.5769230723381042, 0.5837104320526123, 0.5961538553237915, 0.5927602052688599, 0.5904977321624756, 0.6142534017562866, 0.6052036285400391, 0.6323529481887817, 0.6323529481887817, 0.6244344115257263, 0.6312217116355896, 0.6346153616905212, 0.6323529481887817, 0.6334841847419739, 0.6289592981338501, 0.639140248298645, 0.6368778347969055, 0.6357465982437134, 0.6346153616905212, 0.6402714848518372, 0.6380090713500977, 0.6436651349067688, 0.6459276080131531, 0.6368778347969055, 0.6323529481887817, 0.6323529481887817, 0.6289592981338501, 0.627828061580658, 0.6357465982437134, 0.6595022678375244, 0.6380090713500977, 0.6300904750823975, 0.6436651349067688, 0.639140248298645, 0.6436651349067688, 0.6334841847419739, 0.6402714848518372, 0.6380090713500977, 0.6470588445663452, 0.639140248298645, 0.6436651349067688, 0.6368778347969055, 0.6425339579582214, 0.6323529481887817, 0.6300904750823975, 0.6266968250274658, 0.6402714848518372, 0.6527149081230164, 0.6368778347969055, 0.6357465982437134, 0.6402714848518372, 0.6425339579582214, 0.6368778347969055, 0.6447963714599609, 0.6447963714599609, 0.6357465982437134, 0.6436651349067688, 0.6425339579582214, 0.6357465982437134, 0.6368778347969055, 0.6380090713500977, 0.639140248298645, 0.6414027214050293, 0.6357465982437134, 0.6436651349067688, 0.639140248298645, 0.6357465982437134, 0.6447963714599609, 0.6447963714599609, 0.6414027214050293, 0.639140248298645, 0.6436651349067688, 0.6425339579582214, 0.6368778347969055, 0.6357465982437134, 0.6380090713500977, 0.6357465982437134, 0.6481900215148926, 0.6436651349067688, 0.6414027214050293, 0.6447963714599609, 0.6414027214050293, 0.639140248298645, 0.6447963714599609, 0.639140248298645]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 1.0665 - accuracy: 0.5948"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 8s 71ms/step - loss: 1.0659 - accuracy: 0.5956 - val_loss: 1.0981 - val_accuracy: 0.5145\n","Epoch 2/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.0440 - accuracy: 0.6357 - val_loss: 1.0972 - val_accuracy: 0.5145\n","Epoch 3/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0337 - accuracy: 0.6450 - val_loss: 1.0933 - val_accuracy: 0.5145\n","Epoch 4/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0280 - accuracy: 0.6488 - val_loss: 1.0888 - val_accuracy: 0.5155\n","Epoch 5/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.0217 - accuracy: 0.6450 - val_loss: 1.0821 - val_accuracy: 0.5217\n","Epoch 6/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0156 - accuracy: 0.6517 - val_loss: 1.0766 - val_accuracy: 0.5248\n","Epoch 7/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.0099 - accuracy: 0.6517 - val_loss: 1.0722 - val_accuracy: 0.5300\n","Epoch 8/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0019 - accuracy: 0.6641 - val_loss: 1.0680 - val_accuracy: 0.5300\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9993 - accuracy: 0.6535 - val_loss: 1.0616 - val_accuracy: 0.5372\n","Epoch 10/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9930 - accuracy: 0.6553 - val_loss: 1.0547 - val_accuracy: 0.5434\n","Epoch 11/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9868 - accuracy: 0.6584 - val_loss: 1.0448 - val_accuracy: 0.5640\n","Epoch 12/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9815 - accuracy: 0.6638 - val_loss: 1.0453 - val_accuracy: 0.5517\n","Epoch 13/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9742 - accuracy: 0.6643 - val_loss: 1.0309 - val_accuracy: 0.5930\n","Epoch 14/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9706 - accuracy: 0.6594 - val_loss: 1.0229 - val_accuracy: 0.5992\n","Epoch 15/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9660 - accuracy: 0.6633 - val_loss: 1.0146 - val_accuracy: 0.6136\n","Epoch 16/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9670 - accuracy: 0.6566 - val_loss: 1.0106 - val_accuracy: 0.6136\n","Epoch 17/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.9570 - accuracy: 0.6628 - val_loss: 1.0118 - val_accuracy: 0.5919\n","Epoch 18/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9577 - accuracy: 0.6672 - val_loss: 0.9981 - val_accuracy: 0.6219\n","Epoch 19/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.9455 - accuracy: 0.6721 - val_loss: 0.9932 - val_accuracy: 0.6250\n","Epoch 20/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9394 - accuracy: 0.6749 - val_loss: 0.9876 - val_accuracy: 0.6209\n","Epoch 21/100\n","31/31 [==============================] - 1s 35ms/step - loss: 0.9320 - accuracy: 0.6786 - val_loss: 0.9832 - val_accuracy: 0.6374\n","Epoch 22/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9300 - accuracy: 0.6798 - val_loss: 0.9814 - val_accuracy: 0.6260\n","Epoch 23/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9251 - accuracy: 0.6765 - val_loss: 0.9756 - val_accuracy: 0.6374\n","Epoch 24/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9212 - accuracy: 0.6770 - val_loss: 0.9746 - val_accuracy: 0.6364\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9156 - accuracy: 0.6775 - val_loss: 0.9743 - val_accuracy: 0.6322\n","Epoch 26/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9085 - accuracy: 0.6858 - val_loss: 0.9700 - val_accuracy: 0.6374\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9050 - accuracy: 0.6876 - val_loss: 0.9747 - val_accuracy: 0.6343\n","Epoch 28/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9014 - accuracy: 0.6891 - val_loss: 0.9662 - val_accuracy: 0.6415\n","Epoch 29/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8982 - accuracy: 0.6941 - val_loss: 0.9647 - val_accuracy: 0.6395\n","Epoch 30/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8919 - accuracy: 0.6904 - val_loss: 0.9658 - val_accuracy: 0.6415\n","Epoch 31/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8819 - accuracy: 0.6953 - val_loss: 0.9652 - val_accuracy: 0.6333\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8796 - accuracy: 0.6974 - val_loss: 0.9704 - val_accuracy: 0.6333\n","Epoch 33/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8738 - accuracy: 0.7010 - val_loss: 0.9617 - val_accuracy: 0.6384\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8751 - accuracy: 0.6964 - val_loss: 0.9626 - val_accuracy: 0.6395\n","Epoch 35/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8685 - accuracy: 0.7075 - val_loss: 0.9659 - val_accuracy: 0.6343\n","Epoch 36/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8650 - accuracy: 0.6997 - val_loss: 0.9608 - val_accuracy: 0.6302\n","Epoch 37/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8576 - accuracy: 0.7127 - val_loss: 0.9593 - val_accuracy: 0.6271\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8554 - accuracy: 0.7054 - val_loss: 0.9606 - val_accuracy: 0.6415\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8581 - accuracy: 0.6977 - val_loss: 0.9582 - val_accuracy: 0.6353\n","Epoch 40/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8513 - accuracy: 0.7008 - val_loss: 0.9631 - val_accuracy: 0.6302\n","Epoch 41/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8449 - accuracy: 0.7052 - val_loss: 0.9643 - val_accuracy: 0.6353\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8383 - accuracy: 0.7124 - val_loss: 0.9614 - val_accuracy: 0.6333\n","Epoch 43/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8367 - accuracy: 0.7072 - val_loss: 0.9540 - val_accuracy: 0.6322\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8337 - accuracy: 0.7137 - val_loss: 0.9569 - val_accuracy: 0.6343\n","Epoch 45/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8325 - accuracy: 0.7171 - val_loss: 0.9528 - val_accuracy: 0.6302\n","Epoch 46/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8231 - accuracy: 0.7111 - val_loss: 0.9517 - val_accuracy: 0.6229\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8169 - accuracy: 0.7243 - val_loss: 0.9583 - val_accuracy: 0.6291\n","Epoch 48/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.8159 - accuracy: 0.7168 - val_loss: 0.9543 - val_accuracy: 0.6333\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8145 - accuracy: 0.7132 - val_loss: 0.9564 - val_accuracy: 0.6209\n","Epoch 50/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8099 - accuracy: 0.7222 - val_loss: 0.9532 - val_accuracy: 0.6312\n","Epoch 51/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8055 - accuracy: 0.7204 - val_loss: 0.9542 - val_accuracy: 0.6260\n","Epoch 52/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8096 - accuracy: 0.7163 - val_loss: 0.9644 - val_accuracy: 0.6198\n","Epoch 53/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7974 - accuracy: 0.7305 - val_loss: 0.9668 - val_accuracy: 0.6054\n","Epoch 54/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8009 - accuracy: 0.7212 - val_loss: 0.9523 - val_accuracy: 0.6374\n","Epoch 55/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7895 - accuracy: 0.7328 - val_loss: 0.9524 - val_accuracy: 0.6260\n","Epoch 56/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7891 - accuracy: 0.7274 - val_loss: 0.9524 - val_accuracy: 0.6240\n","Epoch 57/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7867 - accuracy: 0.7302 - val_loss: 0.9456 - val_accuracy: 0.6240\n","Epoch 58/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7813 - accuracy: 0.7230 - val_loss: 0.9577 - val_accuracy: 0.6271\n","Epoch 59/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7745 - accuracy: 0.7344 - val_loss: 0.9496 - val_accuracy: 0.6281\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7732 - accuracy: 0.7289 - val_loss: 0.9541 - val_accuracy: 0.6229\n","Epoch 61/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7737 - accuracy: 0.7287 - val_loss: 0.9580 - val_accuracy: 0.6281\n","Epoch 62/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7679 - accuracy: 0.7359 - val_loss: 0.9583 - val_accuracy: 0.6229\n","Epoch 63/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7658 - accuracy: 0.7372 - val_loss: 0.9603 - val_accuracy: 0.6260\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7683 - accuracy: 0.7339 - val_loss: 0.9556 - val_accuracy: 0.6240\n","Epoch 65/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7620 - accuracy: 0.7377 - val_loss: 0.9559 - val_accuracy: 0.6260\n","Epoch 66/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7623 - accuracy: 0.7351 - val_loss: 0.9696 - val_accuracy: 0.6178\n","Epoch 67/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.7518 - accuracy: 0.7424 - val_loss: 0.9537 - val_accuracy: 0.6281\n","Epoch 68/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.7489 - accuracy: 0.7463 - val_loss: 0.9563 - val_accuracy: 0.6229\n","Epoch 69/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.7456 - accuracy: 0.7408 - val_loss: 0.9614 - val_accuracy: 0.6167\n","Epoch 70/100\n","31/31 [==============================] - 1s 39ms/step - loss: 0.7464 - accuracy: 0.7390 - val_loss: 0.9595 - val_accuracy: 0.6126\n","Epoch 71/100\n","31/31 [==============================] - 1s 40ms/step - loss: 0.7362 - accuracy: 0.7473 - val_loss: 0.9713 - val_accuracy: 0.6064\n","Epoch 72/100\n","31/31 [==============================] - 1s 31ms/step - loss: 0.7337 - accuracy: 0.7527 - val_loss: 0.9530 - val_accuracy: 0.6188\n","Epoch 73/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.7359 - accuracy: 0.7432 - val_loss: 0.9558 - val_accuracy: 0.6188\n","Epoch 74/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.7254 - accuracy: 0.7563 - val_loss: 0.9633 - val_accuracy: 0.6167\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7257 - accuracy: 0.7494 - val_loss: 0.9669 - val_accuracy: 0.6198\n","Epoch 76/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7256 - accuracy: 0.7527 - val_loss: 0.9669 - val_accuracy: 0.6167\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7272 - accuracy: 0.7460 - val_loss: 0.9613 - val_accuracy: 0.6188\n","Epoch 78/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7209 - accuracy: 0.7501 - val_loss: 0.9631 - val_accuracy: 0.6074\n","Epoch 79/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7210 - accuracy: 0.7517 - val_loss: 0.9618 - val_accuracy: 0.6126\n","Epoch 80/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7099 - accuracy: 0.7589 - val_loss: 0.9634 - val_accuracy: 0.6147\n","Epoch 81/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7096 - accuracy: 0.7602 - val_loss: 0.9666 - val_accuracy: 0.6157\n","Epoch 82/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7085 - accuracy: 0.7625 - val_loss: 0.9645 - val_accuracy: 0.6260\n","Epoch 83/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7068 - accuracy: 0.7612 - val_loss: 0.9597 - val_accuracy: 0.6219\n","Epoch 84/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7038 - accuracy: 0.7612 - val_loss: 0.9642 - val_accuracy: 0.6136\n","Epoch 85/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6970 - accuracy: 0.7669 - val_loss: 0.9607 - val_accuracy: 0.6178\n","Epoch 86/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7072 - accuracy: 0.7496 - val_loss: 0.9563 - val_accuracy: 0.6219\n","Epoch 87/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6960 - accuracy: 0.7654 - val_loss: 0.9618 - val_accuracy: 0.6291\n","Epoch 88/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6935 - accuracy: 0.7636 - val_loss: 0.9783 - val_accuracy: 0.6136\n","Epoch 89/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6833 - accuracy: 0.7755 - val_loss: 0.9769 - val_accuracy: 0.6126\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6903 - accuracy: 0.7602 - val_loss: 0.9816 - val_accuracy: 0.6105\n","Epoch 91/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6888 - accuracy: 0.7625 - val_loss: 0.9626 - val_accuracy: 0.6229\n","Epoch 92/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6807 - accuracy: 0.7705 - val_loss: 0.9827 - val_accuracy: 0.6116\n","Epoch 93/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6800 - accuracy: 0.7711 - val_loss: 0.9730 - val_accuracy: 0.6085\n","Epoch 94/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6681 - accuracy: 0.7817 - val_loss: 0.9824 - val_accuracy: 0.6198\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6758 - accuracy: 0.7731 - val_loss: 0.9709 - val_accuracy: 0.6198\n","Epoch 96/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6814 - accuracy: 0.7661 - val_loss: 0.9855 - val_accuracy: 0.6033\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6778 - accuracy: 0.7705 - val_loss: 0.9640 - val_accuracy: 0.6167\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6613 - accuracy: 0.7765 - val_loss: 0.9761 - val_accuracy: 0.6178\n","Epoch 99/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6703 - accuracy: 0.7713 - val_loss: 0.9692 - val_accuracy: 0.6209\n","Epoch 100/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6653 - accuracy: 0.7752 - val_loss: 0.9862 - val_accuracy: 0.6033\n","{'loss': [1.0658600330352783, 1.0440248250961304, 1.0336744785308838, 1.0280466079711914, 1.02165949344635, 1.015614628791809, 1.0098536014556885, 1.001914620399475, 0.9993453025817871, 0.9930452704429626, 0.9867854714393616, 0.9815121293067932, 0.9742228388786316, 0.9706451892852783, 0.9660348296165466, 0.9670057892799377, 0.9570245146751404, 0.9577161073684692, 0.945451021194458, 0.9394036531448364, 0.9320098161697388, 0.9299992918968201, 0.9251177310943604, 0.9212391972541809, 0.9155868291854858, 0.9085301756858826, 0.9049522280693054, 0.9014439582824707, 0.8981759548187256, 0.8919469714164734, 0.881893515586853, 0.8796365261077881, 0.8737931251525879, 0.8751193284988403, 0.8684869408607483, 0.8650045394897461, 0.8576304316520691, 0.8553851246833801, 0.8581048846244812, 0.8512728810310364, 0.8448769450187683, 0.8383364081382751, 0.8367423415184021, 0.8337152600288391, 0.8325392603874207, 0.8230808973312378, 0.816899836063385, 0.8159082531929016, 0.8144598007202148, 0.8099325299263, 0.8054757118225098, 0.8096441626548767, 0.7974371314048767, 0.8009086847305298, 0.7894731163978577, 0.789141833782196, 0.7867200374603271, 0.7813373804092407, 0.7745230793952942, 0.773188591003418, 0.7737420797348022, 0.7679409384727478, 0.7657504081726074, 0.7682564854621887, 0.7619556784629822, 0.762261152267456, 0.751770555973053, 0.7488760352134705, 0.7455958127975464, 0.7464417219161987, 0.7361932992935181, 0.7337108850479126, 0.7358855605125427, 0.7254249453544617, 0.7256850004196167, 0.7255501747131348, 0.7272243499755859, 0.7209290862083435, 0.7209638357162476, 0.7098853588104248, 0.7096334099769592, 0.7084982991218567, 0.7068414092063904, 0.7038413286209106, 0.697034478187561, 0.7071674466133118, 0.6959916353225708, 0.6934768557548523, 0.6833182573318481, 0.6902978420257568, 0.68881756067276, 0.6807379126548767, 0.6799911856651306, 0.66810142993927, 0.6757869124412537, 0.6813579201698303, 0.6777660250663757, 0.6613284349441528, 0.6703497171401978, 0.6653130054473877], 'accuracy': [0.5956072211265564, 0.6356589198112488, 0.6449612379074097, 0.6488372087478638, 0.6449612379074097, 0.6516795754432678, 0.6516795754432678, 0.6640827059745789, 0.6534883975982666, 0.6552971601486206, 0.658397912979126, 0.6638242602348328, 0.6643410921096802, 0.659431517124176, 0.6633074879646301, 0.656589150428772, 0.6627907156944275, 0.6671834588050842, 0.6720930337905884, 0.6749354004859924, 0.6785529851913452, 0.6798449754714966, 0.6764857769012451, 0.6770026087760925, 0.6775193810462952, 0.685788094997406, 0.6875969171524048, 0.6891472935676575, 0.6940568685531616, 0.6904392838478088, 0.695348858833313, 0.6974160075187683, 0.7010335922241211, 0.6963824033737183, 0.7074935436248779, 0.6997416019439697, 0.7126615047454834, 0.7054263353347778, 0.6976743936538696, 0.7007752060890198, 0.7051679491996765, 0.7124031186103821, 0.7072351574897766, 0.7136951088905334, 0.7170542478561401, 0.7111111283302307, 0.7242894172668457, 0.7167958617210388, 0.713178277015686, 0.7222222089767456, 0.7204134464263916, 0.7162790894508362, 0.7304909825325012, 0.7211886048316956, 0.7328165173530579, 0.7273901700973511, 0.7302325367927551, 0.7229974269866943, 0.7343669533729553, 0.7289405465126038, 0.7286821603775024, 0.735917329788208, 0.7372093200683594, 0.7338501214981079, 0.737726092338562, 0.7351421117782593, 0.7423772811889648, 0.746253252029419, 0.7408268451690674, 0.7390180826187134, 0.7472867965698242, 0.7527132034301758, 0.7431524395942688, 0.7563307285308838, 0.7493540048599243, 0.7527132034301758, 0.7459948062896729, 0.750129222869873, 0.7516795992851257, 0.7589147090911865, 0.7602066993713379, 0.7625322937965393, 0.7612403035163879, 0.7612403035163879, 0.766925036907196, 0.7496123909950256, 0.7653746604919434, 0.7635658979415894, 0.775452196598053, 0.7602066993713379, 0.7625322937965393, 0.7705426216125488, 0.7710594534873962, 0.7816537618637085, 0.7731266021728516, 0.7661498785018921, 0.7705426216125488, 0.776485800743103, 0.7713178396224976, 0.7751938104629517], 'val_loss': [1.098076343536377, 1.0971860885620117, 1.0933245420455933, 1.08883798122406, 1.0820603370666504, 1.076574683189392, 1.0722354650497437, 1.0679919719696045, 1.061635971069336, 1.0547126531600952, 1.044842004776001, 1.0452653169631958, 1.0308588743209839, 1.0229442119598389, 1.0145760774612427, 1.0105847120285034, 1.0118407011032104, 0.998104453086853, 0.9932189583778381, 0.987628698348999, 0.9832454323768616, 0.9814243316650391, 0.9756103754043579, 0.974640965461731, 0.9743012189865112, 0.970043420791626, 0.9746979475021362, 0.96622633934021, 0.964734673500061, 0.9657993912696838, 0.9651799201965332, 0.9703747630119324, 0.9617434144020081, 0.9626392722129822, 0.9659374356269836, 0.9607607126235962, 0.959277331829071, 0.9606233239173889, 0.9581825137138367, 0.9631060361862183, 0.9643212556838989, 0.9613749384880066, 0.9539521932601929, 0.9568578600883484, 0.9527527093887329, 0.9517130851745605, 0.9583039879798889, 0.9542649388313293, 0.956436038017273, 0.9532331824302673, 0.9542313814163208, 0.9643635749816895, 0.9667597413063049, 0.9522668719291687, 0.9524393677711487, 0.952374279499054, 0.9455991387367249, 0.9576901793479919, 0.9495652914047241, 0.9540815353393555, 0.9579877853393555, 0.958260715007782, 0.960293173789978, 0.9556498527526855, 0.9559139013290405, 0.9696441292762756, 0.9537129402160645, 0.9563369750976562, 0.9613701105117798, 0.9595231413841248, 0.9713435173034668, 0.9530278444290161, 0.9557756185531616, 0.9632836580276489, 0.9669340252876282, 0.9669238924980164, 0.9612915515899658, 0.9630970358848572, 0.9618151187896729, 0.9634178876876831, 0.9665544033050537, 0.9644875526428223, 0.959673285484314, 0.9642104506492615, 0.9606714844703674, 0.9562830924987793, 0.9618211984634399, 0.9783240556716919, 0.9768872261047363, 0.9815931916236877, 0.9626197218894958, 0.9827091097831726, 0.973031759262085, 0.9824351668357849, 0.9709312319755554, 0.9854874014854431, 0.9640451669692993, 0.9760674834251404, 0.9691862463951111, 0.9861665964126587], 'val_accuracy': [0.5144628286361694, 0.5144628286361694, 0.5144628286361694, 0.5154958963394165, 0.5216942429542542, 0.5247933864593506, 0.5299586653709412, 0.5299586653709412, 0.5371900796890259, 0.5433884263038635, 0.5640496015548706, 0.5516529083251953, 0.5929751992225647, 0.5991735458374023, 0.6136363744735718, 0.6136363744735718, 0.5919421315193176, 0.6219007968902588, 0.625, 0.6208677887916565, 0.6373966932296753, 0.6260330677032471, 0.6373966932296753, 0.6363636255264282, 0.6322314143180847, 0.6373966932296753, 0.6342975497245789, 0.6415289044380188, 0.6394628286361694, 0.6415289044380188, 0.6332644820213318, 0.6332644820213318, 0.6384297609329224, 0.6394628286361694, 0.6342975497245789, 0.6301652789115906, 0.6270661354064941, 0.6415289044380188, 0.6353305578231812, 0.6301652789115906, 0.6353305578231812, 0.6332644820213318, 0.6322314143180847, 0.6342975497245789, 0.6301652789115906, 0.6229338645935059, 0.6291322112083435, 0.6332644820213318, 0.6208677887916565, 0.6311983466148376, 0.6260330677032471, 0.6198347210884094, 0.60537189245224, 0.6373966932296753, 0.6260330677032471, 0.6239669322967529, 0.6239669322967529, 0.6270661354064941, 0.6280992031097412, 0.6229338645935059, 0.6280992031097412, 0.6229338645935059, 0.6260330677032471, 0.6239669322967529, 0.6260330677032471, 0.6177685856819153, 0.6280992031097412, 0.6229338645935059, 0.6167355179786682, 0.6126033067703247, 0.6064049601554871, 0.6188016533851624, 0.6188016533851624, 0.6167355179786682, 0.6198347210884094, 0.6167355179786682, 0.6188016533851624, 0.6074380278587341, 0.6126033067703247, 0.6146694421768188, 0.6157024502754211, 0.6260330677032471, 0.6219007968902588, 0.6136363744735718, 0.6177685856819153, 0.6219007968902588, 0.6291322112083435, 0.6136363744735718, 0.6126033067703247, 0.6105371713638306, 0.6229338645935059, 0.6115702390670776, 0.6084710955619812, 0.6198347210884094, 0.6198347210884094, 0.6033057570457458, 0.6167355179786682, 0.6177685856819153, 0.6208677887916565, 0.6033057570457458]}\n","32/32 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.7275 - accuracy: 0.7428"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 7s 56ms/step - loss: 0.7278 - accuracy: 0.7416 - val_loss: 0.9577 - val_accuracy: 0.5151\n","Epoch 2/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.7167 - accuracy: 0.7473 - val_loss: 0.9306 - val_accuracy: 0.5162\n","Epoch 3/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.7147 - accuracy: 0.7530 - val_loss: 0.9299 - val_accuracy: 0.5172\n","Epoch 4/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7058 - accuracy: 0.7597 - val_loss: 0.9213 - val_accuracy: 0.5172\n","Epoch 5/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.7063 - accuracy: 0.7478 - val_loss: 0.9287 - val_accuracy: 0.5183\n","Epoch 6/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.7008 - accuracy: 0.7573 - val_loss: 0.9097 - val_accuracy: 0.5226\n","Epoch 7/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.7014 - accuracy: 0.7460 - val_loss: 0.9149 - val_accuracy: 0.5237\n","Epoch 8/100\n","29/29 [==============================] - 1s 31ms/step - loss: 0.7012 - accuracy: 0.7581 - val_loss: 0.9168 - val_accuracy: 0.5248\n","Epoch 9/100\n","29/29 [==============================] - 1s 39ms/step - loss: 0.6900 - accuracy: 0.7645 - val_loss: 0.8975 - val_accuracy: 0.5312\n","Epoch 10/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6965 - accuracy: 0.7487 - val_loss: 0.8783 - val_accuracy: 0.5463\n","Epoch 11/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6875 - accuracy: 0.7605 - val_loss: 0.8686 - val_accuracy: 0.5560\n","Epoch 12/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6862 - accuracy: 0.7540 - val_loss: 0.8521 - val_accuracy: 0.5830\n","Epoch 13/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6860 - accuracy: 0.7581 - val_loss: 0.8688 - val_accuracy: 0.5603\n","Epoch 14/100\n","29/29 [==============================] - 1s 43ms/step - loss: 0.6794 - accuracy: 0.7567 - val_loss: 0.8411 - val_accuracy: 0.5991\n","Epoch 15/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.6746 - accuracy: 0.7656 - val_loss: 0.8686 - val_accuracy: 0.5700\n","Epoch 16/100\n","29/29 [==============================] - 1s 36ms/step - loss: 0.6776 - accuracy: 0.7659 - val_loss: 0.8543 - val_accuracy: 0.5841\n","Epoch 17/100\n","29/29 [==============================] - 1s 49ms/step - loss: 0.6679 - accuracy: 0.7710 - val_loss: 0.8029 - val_accuracy: 0.6649\n","Epoch 18/100\n","29/29 [==============================] - 2s 53ms/step - loss: 0.6689 - accuracy: 0.7686 - val_loss: 0.7884 - val_accuracy: 0.6681\n","Epoch 19/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.6748 - accuracy: 0.7680 - val_loss: 0.8005 - val_accuracy: 0.6530\n","Epoch 20/100\n","29/29 [==============================] - 2s 81ms/step - loss: 0.6761 - accuracy: 0.7586 - val_loss: 0.7829 - val_accuracy: 0.6692\n","Epoch 21/100\n","29/29 [==============================] - 2s 58ms/step - loss: 0.6605 - accuracy: 0.7740 - val_loss: 0.7753 - val_accuracy: 0.6972\n","Epoch 22/100\n","29/29 [==============================] - 1s 43ms/step - loss: 0.6566 - accuracy: 0.7737 - val_loss: 0.7726 - val_accuracy: 0.6940\n","Epoch 23/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.6598 - accuracy: 0.7710 - val_loss: 0.7735 - val_accuracy: 0.6724\n","Epoch 24/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.6563 - accuracy: 0.7729 - val_loss: 0.7710 - val_accuracy: 0.6746\n","Epoch 25/100\n","29/29 [==============================] - 1s 33ms/step - loss: 0.6571 - accuracy: 0.7740 - val_loss: 0.7724 - val_accuracy: 0.6929\n","Epoch 26/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.6487 - accuracy: 0.7810 - val_loss: 0.7715 - val_accuracy: 0.6897\n","Epoch 27/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.6480 - accuracy: 0.7716 - val_loss: 0.7765 - val_accuracy: 0.6983\n","Epoch 28/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6518 - accuracy: 0.7716 - val_loss: 0.7786 - val_accuracy: 0.6832\n","Epoch 29/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.6482 - accuracy: 0.7796 - val_loss: 0.7773 - val_accuracy: 0.6918\n","Epoch 30/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6416 - accuracy: 0.7834 - val_loss: 0.7829 - val_accuracy: 0.6897\n","Epoch 31/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6443 - accuracy: 0.7786 - val_loss: 0.7836 - val_accuracy: 0.6950\n","Epoch 32/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6405 - accuracy: 0.7769 - val_loss: 0.7890 - val_accuracy: 0.6832\n","Epoch 33/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6359 - accuracy: 0.7777 - val_loss: 0.8104 - val_accuracy: 0.6746\n","Epoch 34/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6405 - accuracy: 0.7823 - val_loss: 0.7890 - val_accuracy: 0.6886\n","Epoch 35/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6306 - accuracy: 0.7821 - val_loss: 0.7908 - val_accuracy: 0.6907\n","Epoch 36/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6270 - accuracy: 0.7918 - val_loss: 0.7910 - val_accuracy: 0.6853\n","Epoch 37/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.6297 - accuracy: 0.7831 - val_loss: 0.7913 - val_accuracy: 0.6886\n","Epoch 38/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6339 - accuracy: 0.7791 - val_loss: 0.8142 - val_accuracy: 0.6692\n","Epoch 39/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6241 - accuracy: 0.7815 - val_loss: 0.7890 - val_accuracy: 0.6918\n","Epoch 40/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6191 - accuracy: 0.7883 - val_loss: 0.7957 - val_accuracy: 0.6918\n","Epoch 41/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6251 - accuracy: 0.7856 - val_loss: 0.8057 - val_accuracy: 0.6929\n","Epoch 42/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6204 - accuracy: 0.7909 - val_loss: 0.7972 - val_accuracy: 0.6810\n","Epoch 43/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6233 - accuracy: 0.7804 - val_loss: 0.8512 - val_accuracy: 0.6422\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6188 - accuracy: 0.7904 - val_loss: 0.8167 - val_accuracy: 0.6703\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6162 - accuracy: 0.7885 - val_loss: 0.8491 - val_accuracy: 0.6487\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6065 - accuracy: 0.7945 - val_loss: 0.8111 - val_accuracy: 0.6670\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6116 - accuracy: 0.7928 - val_loss: 0.8056 - val_accuracy: 0.6864\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6287 - accuracy: 0.7807 - val_loss: 0.8420 - val_accuracy: 0.6681\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6136 - accuracy: 0.7920 - val_loss: 0.7952 - val_accuracy: 0.6940\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6016 - accuracy: 0.7950 - val_loss: 0.7929 - val_accuracy: 0.6821\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5959 - accuracy: 0.8017 - val_loss: 0.7965 - val_accuracy: 0.6853\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5918 - accuracy: 0.8050 - val_loss: 0.8203 - val_accuracy: 0.6756\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6070 - accuracy: 0.7958 - val_loss: 0.7992 - val_accuracy: 0.6983\n","Epoch 54/100\n","29/29 [==============================] - 2s 64ms/step - loss: 0.5912 - accuracy: 0.7974 - val_loss: 0.8078 - val_accuracy: 0.7026\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5923 - accuracy: 0.8017 - val_loss: 0.8008 - val_accuracy: 0.6940\n","Epoch 56/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5944 - accuracy: 0.8047 - val_loss: 0.8078 - val_accuracy: 0.7037\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5815 - accuracy: 0.7969 - val_loss: 0.8071 - val_accuracy: 0.6929\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5924 - accuracy: 0.8036 - val_loss: 0.8019 - val_accuracy: 0.7004\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5898 - accuracy: 0.8015 - val_loss: 0.8115 - val_accuracy: 0.6961\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5877 - accuracy: 0.8050 - val_loss: 0.8292 - val_accuracy: 0.6670\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5882 - accuracy: 0.8009 - val_loss: 0.8041 - val_accuracy: 0.6961\n","Epoch 62/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5822 - accuracy: 0.8047 - val_loss: 0.8058 - val_accuracy: 0.6907\n","Epoch 63/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5780 - accuracy: 0.8098 - val_loss: 0.8117 - val_accuracy: 0.6950\n","Epoch 64/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5854 - accuracy: 0.8060 - val_loss: 0.8392 - val_accuracy: 0.6681\n","Epoch 65/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5793 - accuracy: 0.8152 - val_loss: 0.8048 - val_accuracy: 0.6950\n","Epoch 66/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5860 - accuracy: 0.8012 - val_loss: 0.8077 - val_accuracy: 0.6810\n","Epoch 67/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5742 - accuracy: 0.8085 - val_loss: 0.8070 - val_accuracy: 0.6940\n","Epoch 68/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5723 - accuracy: 0.8120 - val_loss: 0.8131 - val_accuracy: 0.6929\n","Epoch 69/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5779 - accuracy: 0.8031 - val_loss: 0.8046 - val_accuracy: 0.6875\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5663 - accuracy: 0.8147 - val_loss: 0.8045 - val_accuracy: 0.6853\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5716 - accuracy: 0.8112 - val_loss: 0.8087 - val_accuracy: 0.6950\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5665 - accuracy: 0.8090 - val_loss: 0.8092 - val_accuracy: 0.6972\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5680 - accuracy: 0.8095 - val_loss: 0.8153 - val_accuracy: 0.6918\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5603 - accuracy: 0.8128 - val_loss: 0.8036 - val_accuracy: 0.6929\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5615 - accuracy: 0.8155 - val_loss: 0.8098 - val_accuracy: 0.6961\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5596 - accuracy: 0.8144 - val_loss: 0.8340 - val_accuracy: 0.6670\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5589 - accuracy: 0.8141 - val_loss: 0.8164 - val_accuracy: 0.6929\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5569 - accuracy: 0.8203 - val_loss: 0.8273 - val_accuracy: 0.6767\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5480 - accuracy: 0.8257 - val_loss: 0.8199 - val_accuracy: 0.6940\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5468 - accuracy: 0.8244 - val_loss: 0.8154 - val_accuracy: 0.6950\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5483 - accuracy: 0.8249 - val_loss: 0.8152 - val_accuracy: 0.6950\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5442 - accuracy: 0.8214 - val_loss: 0.8219 - val_accuracy: 0.6843\n","Epoch 83/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5449 - accuracy: 0.8211 - val_loss: 0.8206 - val_accuracy: 0.6918\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5411 - accuracy: 0.8249 - val_loss: 0.8266 - val_accuracy: 0.6886\n","Epoch 85/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5506 - accuracy: 0.8173 - val_loss: 0.8361 - val_accuracy: 0.6918\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5434 - accuracy: 0.8184 - val_loss: 0.9154 - val_accuracy: 0.6304\n","Epoch 87/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5408 - accuracy: 0.8292 - val_loss: 0.8334 - val_accuracy: 0.6810\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5347 - accuracy: 0.8292 - val_loss: 0.8226 - val_accuracy: 0.6940\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5353 - accuracy: 0.8252 - val_loss: 0.8189 - val_accuracy: 0.6994\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5358 - accuracy: 0.8254 - val_loss: 0.8195 - val_accuracy: 0.6864\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5413 - accuracy: 0.8235 - val_loss: 0.8569 - val_accuracy: 0.6703\n","Epoch 92/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5407 - accuracy: 0.8225 - val_loss: 0.8211 - val_accuracy: 0.6983\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5345 - accuracy: 0.8225 - val_loss: 0.8286 - val_accuracy: 0.6853\n","Epoch 94/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5266 - accuracy: 0.8305 - val_loss: 0.8191 - val_accuracy: 0.6832\n","Epoch 95/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5354 - accuracy: 0.8276 - val_loss: 0.8397 - val_accuracy: 0.6789\n","Epoch 96/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5312 - accuracy: 0.8227 - val_loss: 0.8253 - val_accuracy: 0.6972\n","Epoch 97/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5159 - accuracy: 0.8389 - val_loss: 0.8279 - val_accuracy: 0.6907\n","Epoch 98/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5213 - accuracy: 0.8319 - val_loss: 0.8226 - val_accuracy: 0.6907\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5163 - accuracy: 0.8394 - val_loss: 0.8761 - val_accuracy: 0.6681\n","Epoch 100/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5219 - accuracy: 0.8330 - val_loss: 0.8373 - val_accuracy: 0.6875\n","{'loss': [0.7277957201004028, 0.716658890247345, 0.714743435382843, 0.7058104872703552, 0.7062559723854065, 0.7008154392242432, 0.7013691663742065, 0.7011688351631165, 0.6899927258491516, 0.6965280771255493, 0.6874976754188538, 0.6861885786056519, 0.6859666705131531, 0.6794451475143433, 0.6745867729187012, 0.6775584816932678, 0.66788649559021, 0.6689397692680359, 0.6747831702232361, 0.6761298775672913, 0.6604897975921631, 0.6565905809402466, 0.6598201394081116, 0.6562536954879761, 0.6570954322814941, 0.648664653301239, 0.6480257511138916, 0.6518317461013794, 0.6482449769973755, 0.6415997743606567, 0.6442614197731018, 0.6404893398284912, 0.6359319090843201, 0.6405019164085388, 0.6306072473526001, 0.6269680261611938, 0.6296804547309875, 0.6338576078414917, 0.6241342425346375, 0.6190987825393677, 0.6251270771026611, 0.6203612685203552, 0.6233469247817993, 0.61883944272995, 0.6161670088768005, 0.6065439581871033, 0.6116322875022888, 0.6287199854850769, 0.6136454939842224, 0.6016291379928589, 0.5959423184394836, 0.5918057560920715, 0.6069808006286621, 0.5911884903907776, 0.592272937297821, 0.5943980813026428, 0.5815276503562927, 0.5923681855201721, 0.589783251285553, 0.5877177715301514, 0.5882082581520081, 0.5821607708930969, 0.5779723525047302, 0.5853559374809265, 0.5792909860610962, 0.5859515070915222, 0.5742278099060059, 0.5723282098770142, 0.5778940320014954, 0.5662912726402283, 0.5716202259063721, 0.5664657950401306, 0.5679930448532104, 0.5602966547012329, 0.5615323185920715, 0.5595895648002625, 0.5589385628700256, 0.556890606880188, 0.5479516386985779, 0.546820342540741, 0.5483459830284119, 0.5442119240760803, 0.5449358224868774, 0.5410608649253845, 0.5506049394607544, 0.5433621406555176, 0.540809690952301, 0.534664511680603, 0.5352762341499329, 0.535817563533783, 0.5413216948509216, 0.5407062768936157, 0.5345046520233154, 0.5266222953796387, 0.5353559851646423, 0.5312297344207764, 0.5158780813217163, 0.5212675333023071, 0.5162912607192993, 0.5219081044197083], 'accuracy': [0.7416487336158752, 0.7473060488700867, 0.7529633641242981, 0.7596982717514038, 0.7478448152542114, 0.7572737336158752, 0.7459590435028076, 0.7580819129943848, 0.7645474076271057, 0.748652994632721, 0.7605064511299133, 0.7540409564971924, 0.7580819129943848, 0.7567349076271057, 0.765625, 0.7658944129943848, 0.7710129022598267, 0.7685883641242981, 0.7680495977401733, 0.7586206793785095, 0.7739762663841248, 0.7737069129943848, 0.7710129022598267, 0.7728987336158752, 0.7739762663841248, 0.7809805870056152, 0.7715517282485962, 0.7715517282485962, 0.779633641242981, 0.7834051847457886, 0.7785560488700867, 0.7769396305084229, 0.7777478694915771, 0.7823275923728943, 0.7820581793785095, 0.7917564511299133, 0.7831357717514038, 0.7790948152542114, 0.7815194129943848, 0.7882543206214905, 0.7855603694915771, 0.7909482717514038, 0.7804418206214905, 0.790409505367279, 0.7885237336158752, 0.7944504022598267, 0.7928340435028076, 0.7807112336158752, 0.7920258641242981, 0.7949892282485962, 0.8017241358757019, 0.8049569129943848, 0.7957974076271057, 0.7974137663841248, 0.8017241358757019, 0.8046875, 0.796875, 0.8036099076271057, 0.8014547228813171, 0.8049569129943848, 0.8009159564971924, 0.8046875, 0.8098060488700867, 0.806034505367279, 0.8151939511299133, 0.8011853694915771, 0.8084590435028076, 0.8119612336158752, 0.803071141242981, 0.8146551847457886, 0.811152994632721, 0.8089978694915771, 0.8095366358757019, 0.8127694129943848, 0.8154633641242981, 0.8143857717514038, 0.814116358757019, 0.8203125, 0.8257004022598267, 0.8243534564971924, 0.8248922228813171, 0.8213900923728943, 0.8211206793785095, 0.8248922228813171, 0.8173491358757019, 0.8184267282485962, 0.8292025923728943, 0.8292025923728943, 0.8251616358757019, 0.8254310488700867, 0.8235452771186829, 0.8224676847457886, 0.8224676847457886, 0.8305495977401733, 0.8275862336158752, 0.8227370977401733, 0.8389008641242981, 0.8318965435028076, 0.8394396305084229, 0.8329741358757019], 'val_loss': [0.9577183723449707, 0.9305981397628784, 0.9299499988555908, 0.9212866425514221, 0.928717851638794, 0.9096990823745728, 0.9148789048194885, 0.9168331623077393, 0.8974891901016235, 0.8783031105995178, 0.8685864210128784, 0.8520939946174622, 0.868787944316864, 0.8410767912864685, 0.8686074018478394, 0.8543325662612915, 0.802875280380249, 0.7883948683738708, 0.8005428910255432, 0.7829316258430481, 0.7752517461776733, 0.7725850939750671, 0.773544430732727, 0.7710229158401489, 0.7724148035049438, 0.7715103626251221, 0.7764549851417542, 0.7786413431167603, 0.7773146629333496, 0.7828831076622009, 0.7836350202560425, 0.7890444993972778, 0.8103604316711426, 0.788959264755249, 0.7908264398574829, 0.7909805774688721, 0.7912550568580627, 0.8141600489616394, 0.7889730334281921, 0.7956541180610657, 0.805684506893158, 0.7972099781036377, 0.8511613011360168, 0.8166541457176208, 0.8491253852844238, 0.8111483454704285, 0.8056148886680603, 0.8419597744941711, 0.7952039837837219, 0.7929090261459351, 0.7964522242546082, 0.8203203678131104, 0.79923415184021, 0.8077549934387207, 0.8007948398590088, 0.8078153133392334, 0.807073712348938, 0.8018813729286194, 0.8114784955978394, 0.8291867971420288, 0.8041172623634338, 0.8057769536972046, 0.8117040395736694, 0.8391861319541931, 0.8047851324081421, 0.8076788783073425, 0.807007908821106, 0.8131223917007446, 0.8045748472213745, 0.8044734597206116, 0.8087010383605957, 0.8091731667518616, 0.8153184652328491, 0.8035616874694824, 0.8097854852676392, 0.8339563608169556, 0.8164492249488831, 0.8272521495819092, 0.8198613524436951, 0.8153707385063171, 0.8151702284812927, 0.8219020366668701, 0.8206192255020142, 0.8266236782073975, 0.8361049294471741, 0.915367066860199, 0.8334037065505981, 0.8226456642150879, 0.8189451098442078, 0.8195145130157471, 0.856897234916687, 0.8210941553115845, 0.8286075592041016, 0.8190565705299377, 0.8396993279457092, 0.8253433108329773, 0.8279128670692444, 0.8225739002227783, 0.8760631084442139, 0.8373422026634216], 'val_accuracy': [0.5150862336158752, 0.5161637663841248, 0.517241358757019, 0.517241358757019, 0.5183189511299133, 0.5226293206214905, 0.5237069129943848, 0.524784505367279, 0.53125, 0.5463362336158752, 0.556034505367279, 0.5829741358757019, 0.5603448152542114, 0.5991379022598267, 0.5700430870056152, 0.5840517282485962, 0.6648706793785095, 0.6681034564971924, 0.6530172228813171, 0.6691810488700867, 0.6971982717514038, 0.693965494632721, 0.6724137663841248, 0.6745689511299133, 0.6928879022598267, 0.6896551847457886, 0.6982758641242981, 0.6831896305084229, 0.6918103694915771, 0.6896551847457886, 0.6950430870056152, 0.6831896305084229, 0.6745689511299133, 0.6885775923728943, 0.6907327771186829, 0.6853448152542114, 0.6885775923728943, 0.6691810488700867, 0.6918103694915771, 0.6918103694915771, 0.6928879022598267, 0.681034505367279, 0.642241358757019, 0.670258641242981, 0.6487069129943848, 0.6670258641242981, 0.6864224076271057, 0.6681034564971924, 0.693965494632721, 0.6821120977401733, 0.6853448152542114, 0.6756465435028076, 0.6982758641242981, 0.7025862336158752, 0.693965494632721, 0.7036637663841248, 0.6928879022598267, 0.7004310488700867, 0.6961206793785095, 0.6670258641242981, 0.6961206793785095, 0.6907327771186829, 0.6950430870056152, 0.6681034564971924, 0.6950430870056152, 0.681034505367279, 0.693965494632721, 0.6928879022598267, 0.6875, 0.6853448152542114, 0.6950430870056152, 0.6971982717514038, 0.6918103694915771, 0.6928879022598267, 0.6961206793785095, 0.6670258641242981, 0.6928879022598267, 0.6767241358757019, 0.693965494632721, 0.6950430870056152, 0.6950430870056152, 0.6842672228813171, 0.6918103694915771, 0.6885775923728943, 0.6918103694915771, 0.6303879022598267, 0.681034505367279, 0.693965494632721, 0.6993534564971924, 0.6864224076271057, 0.670258641242981, 0.6982758641242981, 0.6853448152542114, 0.6831896305084229, 0.6788793206214905, 0.6971982717514038, 0.6907327771186829, 0.6907327771186829, 0.6681034564971924, 0.6875]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.7197 - accuracy: 0.7439"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 58ms/step - loss: 0.7197 - accuracy: 0.7439 - val_loss: 0.9636 - val_accuracy: 0.5045\n","Epoch 2/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7145 - accuracy: 0.7465 - val_loss: 0.9413 - val_accuracy: 0.5045\n","Epoch 3/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7140 - accuracy: 0.7431 - val_loss: 0.9365 - val_accuracy: 0.5045\n","Epoch 4/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7083 - accuracy: 0.7482 - val_loss: 0.9326 - val_accuracy: 0.5057\n","Epoch 5/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7101 - accuracy: 0.7374 - val_loss: 0.9431 - val_accuracy: 0.5057\n","Epoch 6/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7002 - accuracy: 0.7493 - val_loss: 0.9163 - val_accuracy: 0.5068\n","Epoch 7/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.7014 - accuracy: 0.7476 - val_loss: 0.9227 - val_accuracy: 0.5079\n","Epoch 8/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6916 - accuracy: 0.7603 - val_loss: 0.9091 - val_accuracy: 0.5113\n","Epoch 9/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6902 - accuracy: 0.7558 - val_loss: 0.9103 - val_accuracy: 0.5170\n","Epoch 10/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6904 - accuracy: 0.7592 - val_loss: 0.8952 - val_accuracy: 0.5249\n","Epoch 11/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6855 - accuracy: 0.7524 - val_loss: 0.8930 - val_accuracy: 0.5328\n","Epoch 12/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6794 - accuracy: 0.7683 - val_loss: 0.8734 - val_accuracy: 0.5645\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6770 - accuracy: 0.7640 - val_loss: 0.8734 - val_accuracy: 0.5622\n","Epoch 14/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6814 - accuracy: 0.7668 - val_loss: 0.8588 - val_accuracy: 0.5894\n","Epoch 15/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6733 - accuracy: 0.7677 - val_loss: 0.8687 - val_accuracy: 0.5735\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6811 - accuracy: 0.7558 - val_loss: 0.8670 - val_accuracy: 0.5781\n","Epoch 17/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.6656 - accuracy: 0.7708 - val_loss: 0.8329 - val_accuracy: 0.6199\n","Epoch 18/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.6730 - accuracy: 0.7600 - val_loss: 0.8210 - val_accuracy: 0.6482\n","Epoch 19/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6696 - accuracy: 0.7609 - val_loss: 0.8152 - val_accuracy: 0.6437\n","Epoch 20/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6722 - accuracy: 0.7569 - val_loss: 0.8235 - val_accuracy: 0.6369\n","Epoch 21/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6694 - accuracy: 0.7632 - val_loss: 0.8570 - val_accuracy: 0.6131\n","Epoch 22/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6628 - accuracy: 0.7716 - val_loss: 0.8121 - val_accuracy: 0.6855\n","Epoch 23/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6610 - accuracy: 0.7634 - val_loss: 0.8214 - val_accuracy: 0.6697\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6560 - accuracy: 0.7770 - val_loss: 0.8173 - val_accuracy: 0.6731\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6650 - accuracy: 0.7626 - val_loss: 0.8138 - val_accuracy: 0.6799\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6579 - accuracy: 0.7649 - val_loss: 0.8135 - val_accuracy: 0.6810\n","Epoch 27/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6532 - accuracy: 0.7629 - val_loss: 0.8085 - val_accuracy: 0.6878\n","Epoch 28/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6472 - accuracy: 0.7745 - val_loss: 0.8189 - val_accuracy: 0.6878\n","Epoch 29/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6545 - accuracy: 0.7671 - val_loss: 0.8182 - val_accuracy: 0.6844\n","Epoch 30/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6396 - accuracy: 0.7773 - val_loss: 0.8126 - val_accuracy: 0.6980\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6415 - accuracy: 0.7733 - val_loss: 0.8167 - val_accuracy: 0.6821\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6386 - accuracy: 0.7810 - val_loss: 0.8253 - val_accuracy: 0.6878\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6352 - accuracy: 0.7731 - val_loss: 0.8175 - val_accuracy: 0.6912\n","Epoch 34/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6340 - accuracy: 0.7753 - val_loss: 0.8255 - val_accuracy: 0.6878\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6323 - accuracy: 0.7779 - val_loss: 0.8311 - val_accuracy: 0.6980\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6364 - accuracy: 0.7756 - val_loss: 0.8514 - val_accuracy: 0.6731\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6316 - accuracy: 0.7810 - val_loss: 0.8294 - val_accuracy: 0.6923\n","Epoch 38/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6245 - accuracy: 0.7900 - val_loss: 0.8358 - val_accuracy: 0.6878\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6193 - accuracy: 0.7818 - val_loss: 0.8288 - val_accuracy: 0.6923\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6277 - accuracy: 0.7838 - val_loss: 0.8470 - val_accuracy: 0.6821\n","Epoch 41/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6216 - accuracy: 0.7816 - val_loss: 0.8698 - val_accuracy: 0.6640\n","Epoch 42/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6229 - accuracy: 0.7847 - val_loss: 0.8354 - val_accuracy: 0.6855\n","Epoch 43/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6182 - accuracy: 0.7855 - val_loss: 0.8345 - val_accuracy: 0.6889\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6125 - accuracy: 0.7895 - val_loss: 0.8441 - val_accuracy: 0.6934\n","Epoch 45/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6128 - accuracy: 0.7852 - val_loss: 0.8341 - val_accuracy: 0.6900\n","Epoch 46/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6117 - accuracy: 0.7866 - val_loss: 0.8560 - val_accuracy: 0.6776\n","Epoch 47/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6117 - accuracy: 0.7892 - val_loss: 0.8386 - val_accuracy: 0.6833\n","Epoch 48/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6080 - accuracy: 0.7917 - val_loss: 0.8696 - val_accuracy: 0.6459\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6114 - accuracy: 0.7883 - val_loss: 0.8489 - val_accuracy: 0.6867\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6060 - accuracy: 0.7906 - val_loss: 0.8411 - val_accuracy: 0.6833\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6037 - accuracy: 0.7889 - val_loss: 0.8511 - val_accuracy: 0.6878\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6010 - accuracy: 0.7937 - val_loss: 0.8630 - val_accuracy: 0.6776\n","Epoch 53/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5983 - accuracy: 0.7946 - val_loss: 0.8435 - val_accuracy: 0.6742\n","Epoch 54/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5992 - accuracy: 0.7886 - val_loss: 0.8476 - val_accuracy: 0.6855\n","Epoch 55/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5923 - accuracy: 0.7957 - val_loss: 0.8539 - val_accuracy: 0.6776\n","Epoch 56/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.6037 - accuracy: 0.7832 - val_loss: 0.8567 - val_accuracy: 0.6765\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5943 - accuracy: 0.7929 - val_loss: 0.8728 - val_accuracy: 0.6719\n","Epoch 58/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5876 - accuracy: 0.7971 - val_loss: 0.8640 - val_accuracy: 0.6753\n","Epoch 59/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5864 - accuracy: 0.7980 - val_loss: 0.8503 - val_accuracy: 0.6855\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5877 - accuracy: 0.8016 - val_loss: 0.8476 - val_accuracy: 0.6889\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5862 - accuracy: 0.7965 - val_loss: 0.8660 - val_accuracy: 0.6686\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5874 - accuracy: 0.7974 - val_loss: 0.8613 - val_accuracy: 0.6889\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5775 - accuracy: 0.8107 - val_loss: 0.8586 - val_accuracy: 0.6855\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5794 - accuracy: 0.8048 - val_loss: 0.8543 - val_accuracy: 0.6833\n","Epoch 65/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5763 - accuracy: 0.8048 - val_loss: 0.8668 - val_accuracy: 0.6946\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5801 - accuracy: 0.8059 - val_loss: 0.8845 - val_accuracy: 0.6810\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5690 - accuracy: 0.8107 - val_loss: 0.8748 - val_accuracy: 0.6810\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5651 - accuracy: 0.8084 - val_loss: 0.8561 - val_accuracy: 0.6878\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5754 - accuracy: 0.8033 - val_loss: 0.8640 - val_accuracy: 0.6799\n","Epoch 70/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5818 - accuracy: 0.8008 - val_loss: 0.8971 - val_accuracy: 0.6459\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5697 - accuracy: 0.8130 - val_loss: 0.8639 - val_accuracy: 0.6923\n","Epoch 72/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5609 - accuracy: 0.8087 - val_loss: 0.8970 - val_accuracy: 0.6731\n","Epoch 73/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5573 - accuracy: 0.8189 - val_loss: 0.9048 - val_accuracy: 0.6391\n","Epoch 74/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5641 - accuracy: 0.8081 - val_loss: 0.8879 - val_accuracy: 0.6833\n","Epoch 75/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5589 - accuracy: 0.8183 - val_loss: 0.9358 - val_accuracy: 0.6120\n","Epoch 76/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5607 - accuracy: 0.8031 - val_loss: 0.8769 - val_accuracy: 0.6776\n","Epoch 77/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5629 - accuracy: 0.8093 - val_loss: 0.8811 - val_accuracy: 0.6753\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5486 - accuracy: 0.8186 - val_loss: 0.8968 - val_accuracy: 0.6606\n","Epoch 79/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5431 - accuracy: 0.8152 - val_loss: 0.8720 - val_accuracy: 0.6787\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5491 - accuracy: 0.8087 - val_loss: 0.8945 - val_accuracy: 0.6697\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5493 - accuracy: 0.8186 - val_loss: 0.8823 - val_accuracy: 0.6878\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5486 - accuracy: 0.8161 - val_loss: 0.8964 - val_accuracy: 0.6697\n","Epoch 83/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5490 - accuracy: 0.8178 - val_loss: 0.8866 - val_accuracy: 0.6878\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5369 - accuracy: 0.8212 - val_loss: 0.9210 - val_accuracy: 0.6493\n","Epoch 85/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5444 - accuracy: 0.8164 - val_loss: 0.9036 - val_accuracy: 0.6697\n","Epoch 86/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5395 - accuracy: 0.8200 - val_loss: 0.9359 - val_accuracy: 0.6674\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5498 - accuracy: 0.8101 - val_loss: 0.9357 - val_accuracy: 0.6290\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5351 - accuracy: 0.8223 - val_loss: 0.9207 - val_accuracy: 0.6437\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5351 - accuracy: 0.8212 - val_loss: 0.8865 - val_accuracy: 0.6855\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5328 - accuracy: 0.8195 - val_loss: 0.9245 - val_accuracy: 0.6742\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5387 - accuracy: 0.8189 - val_loss: 0.9426 - val_accuracy: 0.6324\n","Epoch 92/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5279 - accuracy: 0.8243 - val_loss: 0.9108 - val_accuracy: 0.6776\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5306 - accuracy: 0.8231 - val_loss: 0.8920 - val_accuracy: 0.6776\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5471 - accuracy: 0.8115 - val_loss: 0.8937 - val_accuracy: 0.6799\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5288 - accuracy: 0.8172 - val_loss: 0.9037 - val_accuracy: 0.6753\n","Epoch 96/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5224 - accuracy: 0.8308 - val_loss: 0.9034 - val_accuracy: 0.6742\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5202 - accuracy: 0.8319 - val_loss: 0.9198 - val_accuracy: 0.6719\n","Epoch 98/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5231 - accuracy: 0.8234 - val_loss: 0.9013 - val_accuracy: 0.6799\n","Epoch 99/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5199 - accuracy: 0.8299 - val_loss: 0.9082 - val_accuracy: 0.6787\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5129 - accuracy: 0.8322 - val_loss: 0.9134 - val_accuracy: 0.6855\n","{'loss': [0.7197442650794983, 0.7145330309867859, 0.7140277624130249, 0.7083178758621216, 0.7101464867591858, 0.7001583576202393, 0.7013983726501465, 0.6915788650512695, 0.6901565194129944, 0.6904150247573853, 0.6855430006980896, 0.6794464588165283, 0.677044689655304, 0.6813649535179138, 0.6733365058898926, 0.6810541152954102, 0.6655942797660828, 0.6730289459228516, 0.6695809364318848, 0.6721569895744324, 0.6694444417953491, 0.6627658605575562, 0.6610223650932312, 0.6559684872627258, 0.664971113204956, 0.6579318642616272, 0.6531814336776733, 0.6472054719924927, 0.6545323729515076, 0.6396113634109497, 0.6414721012115479, 0.6385658383369446, 0.6352370977401733, 0.6340458989143372, 0.6323341727256775, 0.6364077925682068, 0.631605327129364, 0.6244714856147766, 0.6192570924758911, 0.6277450919151306, 0.6216235756874084, 0.6229304671287537, 0.6181740164756775, 0.6125438809394836, 0.6127954721450806, 0.611732006072998, 0.6117205023765564, 0.6080265045166016, 0.6114186644554138, 0.6060235500335693, 0.6036614775657654, 0.6009573340415955, 0.5983162522315979, 0.5991750955581665, 0.5922504663467407, 0.6036533117294312, 0.5942699313163757, 0.5876216292381287, 0.5863558650016785, 0.5876863598823547, 0.5861655473709106, 0.5874048471450806, 0.5775396823883057, 0.579400360584259, 0.5763205289840698, 0.5800989270210266, 0.568978488445282, 0.5650692582130432, 0.5753902196884155, 0.5818490982055664, 0.5696844458580017, 0.5608619451522827, 0.5573412775993347, 0.5640836954116821, 0.5588939785957336, 0.5607231855392456, 0.5629015564918518, 0.5485705137252808, 0.5430780649185181, 0.5490739345550537, 0.549331545829773, 0.548551082611084, 0.5490276217460632, 0.5368574261665344, 0.5443941354751587, 0.5395469665527344, 0.5497761368751526, 0.5350666046142578, 0.5351076722145081, 0.5327554941177368, 0.5387290716171265, 0.5279097557067871, 0.5306147336959839, 0.547114372253418, 0.5287553668022156, 0.5224459171295166, 0.5202410221099854, 0.5231410264968872, 0.5198928117752075, 0.5129101276397705], 'accuracy': [0.7439162135124207, 0.7464629411697388, 0.7430673241615295, 0.748160719871521, 0.7374080419540405, 0.7492926120758057, 0.7475947737693787, 0.7603282332420349, 0.7558007836341858, 0.759196400642395, 0.7524052262306213, 0.7682512998580933, 0.7640067934989929, 0.7668364644050598, 0.7676853537559509, 0.7558007836341858, 0.7707979679107666, 0.7600452899932861, 0.7608941793441772, 0.7569326758384705, 0.7631579041481018, 0.7716468572616577, 0.7634408473968506, 0.777023196220398, 0.7625919580459595, 0.764855682849884, 0.7628749012947083, 0.7744765281677246, 0.7671194076538086, 0.7773061394691467, 0.7733446359634399, 0.7809846997261047, 0.7730616927146912, 0.7753254175186157, 0.7778720855712891, 0.7756083607673645, 0.7809846997261047, 0.790039598941803, 0.7818335890769958, 0.7838143706321716, 0.7815506458282471, 0.7846632599830627, 0.7855121493339539, 0.7894737124443054, 0.7852292060852051, 0.7866440415382385, 0.7891907095909119, 0.79173743724823, 0.7883418202400208, 0.7906055450439453, 0.7889077663421631, 0.793718159198761, 0.7945670485496521, 0.7886247634887695, 0.7956989407539368, 0.7832484245300293, 0.7928692698478699, 0.7971137762069702, 0.7979626655578613, 0.8016412258148193, 0.7965478301048279, 0.797396719455719, 0.8106960654258728, 0.804753839969635, 0.804753839969635, 0.8058856725692749, 0.8106960654258728, 0.808432400226593, 0.8033390045166016, 0.8007922768592834, 0.8129597902297974, 0.8087153434753418, 0.8189020752906799, 0.8081493973731995, 0.8183361887931824, 0.803056001663208, 0.8092812895774841, 0.8186191320419312, 0.8152235150337219, 0.8087153434753418, 0.8186191320419312, 0.8160724639892578, 0.81777024269104, 0.8211658000946045, 0.8163554072380066, 0.8200339674949646, 0.8101301789283752, 0.8222976922988892, 0.8211658000946045, 0.8194680213928223, 0.8189020752906799, 0.8242784142494202, 0.8231465816497803, 0.8115450143814087, 0.8172042965888977, 0.8307866454124451, 0.831918478012085, 0.823429524898529, 0.829937756061554, 0.8322014808654785], 'val_loss': [0.9635595679283142, 0.9412714838981628, 0.936486542224884, 0.9325527548789978, 0.9431192278862, 0.9162971377372742, 0.9226938486099243, 0.9090563654899597, 0.9103299379348755, 0.8952431678771973, 0.8929997086524963, 0.8734340667724609, 0.873383104801178, 0.8587502241134644, 0.8686941862106323, 0.8670408725738525, 0.8329395055770874, 0.82098788022995, 0.8152096271514893, 0.8234797716140747, 0.8570131063461304, 0.8121333718299866, 0.8213557600975037, 0.8173092603683472, 0.8138248920440674, 0.8135431408882141, 0.8084921836853027, 0.8189349174499512, 0.8182399272918701, 0.8125976920127869, 0.8167285919189453, 0.8253486156463623, 0.8174945116043091, 0.8255327939987183, 0.8310737013816833, 0.8513919115066528, 0.8294155597686768, 0.8358020186424255, 0.8288208246231079, 0.8469656109809875, 0.8697909116744995, 0.8354082107543945, 0.834518313407898, 0.8440922498703003, 0.8341262340545654, 0.8559970259666443, 0.838629961013794, 0.869648814201355, 0.8488819003105164, 0.841110110282898, 0.8510714769363403, 0.8630269169807434, 0.8435177803039551, 0.847568690776825, 0.8539002537727356, 0.856721818447113, 0.8728097677230835, 0.8640446066856384, 0.8503249287605286, 0.8475633859634399, 0.8660091757774353, 0.8613442778587341, 0.8585587739944458, 0.8542710542678833, 0.8667618632316589, 0.8845311999320984, 0.874817430973053, 0.8561091423034668, 0.8640431761741638, 0.8970698118209839, 0.8639368414878845, 0.8969682455062866, 0.9048031568527222, 0.8878850340843201, 0.9357882738113403, 0.8768742680549622, 0.8810979127883911, 0.8968098759651184, 0.8720104694366455, 0.8945444822311401, 0.8823072910308838, 0.8964198231697083, 0.8866329193115234, 0.9209901690483093, 0.9035676717758179, 0.9358778595924377, 0.9357327818870544, 0.9207465648651123, 0.8865479230880737, 0.9244604110717773, 0.9426165223121643, 0.9107933044433594, 0.891995370388031, 0.8937040567398071, 0.9036762118339539, 0.9034278988838196, 0.9197984337806702, 0.9012539386749268, 0.9082337617874146, 0.9134150147438049], 'val_accuracy': [0.5045248866081238, 0.5045248866081238, 0.5045248866081238, 0.5056561231613159, 0.5056561231613159, 0.5067873597145081, 0.5079185366630554, 0.5113122463226318, 0.516968309879303, 0.5248869061470032, 0.5328054428100586, 0.564479649066925, 0.5622171759605408, 0.5893664956092834, 0.5735294222831726, 0.5780543088912964, 0.6199095249176025, 0.6481900215148926, 0.6436651349067688, 0.6368778347969055, 0.6131221652030945, 0.685520350933075, 0.6696832776069641, 0.6730769276618958, 0.679864227771759, 0.6809954643249512, 0.6877828240394592, 0.6877828240394592, 0.6843891143798828, 0.6979637742042542, 0.6821267008781433, 0.6877828240394592, 0.6911764740943909, 0.6877828240394592, 0.6979637742042542, 0.6730769276618958, 0.692307710647583, 0.6877828240394592, 0.692307710647583, 0.6821267008781433, 0.6640271544456482, 0.685520350933075, 0.6889140009880066, 0.6934388875961304, 0.6900452375411987, 0.6776018142700195, 0.6832579374313354, 0.6459276080131531, 0.6866515874862671, 0.6832579374313354, 0.6877828240394592, 0.6776018142700195, 0.6742081642150879, 0.685520350933075, 0.6776018142700195, 0.6764705777168274, 0.6719456911087036, 0.6753393411636353, 0.685520350933075, 0.6889140009880066, 0.668552041053772, 0.6889140009880066, 0.685520350933075, 0.6832579374313354, 0.6945701241493225, 0.6809954643249512, 0.6809954643249512, 0.6877828240394592, 0.679864227771759, 0.6459276080131531, 0.692307710647583, 0.6730769276618958, 0.639140248298645, 0.6832579374313354, 0.6119909286499023, 0.6776018142700195, 0.6753393411636353, 0.6606335043907166, 0.6787330508232117, 0.6696832776069641, 0.6877828240394592, 0.6696832776069641, 0.6877828240394592, 0.6493212580680847, 0.6696832776069641, 0.6674208045005798, 0.6289592981338501, 0.6436651349067688, 0.685520350933075, 0.6742081642150879, 0.6323529481887817, 0.6776018142700195, 0.6776018142700195, 0.679864227771759, 0.6753393411636353, 0.6742081642150879, 0.6719456911087036, 0.679864227771759, 0.6787330508232117, 0.685520350933075]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.7232 - accuracy: 0.7437"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 9s 60ms/step - loss: 0.7232 - accuracy: 0.7437 - val_loss: 0.9504 - val_accuracy: 0.5145\n","Epoch 2/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7177 - accuracy: 0.7426 - val_loss: 0.9358 - val_accuracy: 0.5145\n","Epoch 3/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7088 - accuracy: 0.7447 - val_loss: 0.9297 - val_accuracy: 0.5145\n","Epoch 4/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.7133 - accuracy: 0.7362 - val_loss: 0.9370 - val_accuracy: 0.5165\n","Epoch 5/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.7056 - accuracy: 0.7501 - val_loss: 0.9187 - val_accuracy: 0.5186\n","Epoch 6/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6988 - accuracy: 0.7525 - val_loss: 0.9151 - val_accuracy: 0.5186\n","Epoch 7/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6950 - accuracy: 0.7556 - val_loss: 0.8942 - val_accuracy: 0.5300\n","Epoch 8/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6945 - accuracy: 0.7548 - val_loss: 0.9031 - val_accuracy: 0.5248\n","Epoch 9/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6915 - accuracy: 0.7519 - val_loss: 0.8929 - val_accuracy: 0.5372\n","Epoch 10/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6907 - accuracy: 0.7556 - val_loss: 0.8716 - val_accuracy: 0.5630\n","Epoch 11/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6914 - accuracy: 0.7620 - val_loss: 0.8639 - val_accuracy: 0.5754\n","Epoch 12/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6832 - accuracy: 0.7610 - val_loss: 0.8643 - val_accuracy: 0.5754\n","Epoch 13/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6867 - accuracy: 0.7581 - val_loss: 0.8451 - val_accuracy: 0.6116\n","Epoch 14/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6800 - accuracy: 0.7597 - val_loss: 0.8508 - val_accuracy: 0.6023\n","Epoch 15/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6750 - accuracy: 0.7677 - val_loss: 0.8314 - val_accuracy: 0.6457\n","Epoch 16/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.6692 - accuracy: 0.7638 - val_loss: 0.8142 - val_accuracy: 0.6653\n","Epoch 17/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6778 - accuracy: 0.7620 - val_loss: 0.8203 - val_accuracy: 0.6581\n","Epoch 18/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6707 - accuracy: 0.7667 - val_loss: 0.8167 - val_accuracy: 0.6591\n","Epoch 19/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.6655 - accuracy: 0.7680 - val_loss: 0.8116 - val_accuracy: 0.6684\n","Epoch 20/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6603 - accuracy: 0.7747 - val_loss: 0.8167 - val_accuracy: 0.6581\n","Epoch 21/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6671 - accuracy: 0.7633 - val_loss: 0.8228 - val_accuracy: 0.6570\n","Epoch 22/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6629 - accuracy: 0.7667 - val_loss: 0.8330 - val_accuracy: 0.6581\n","Epoch 23/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6556 - accuracy: 0.7731 - val_loss: 0.8265 - val_accuracy: 0.6643\n","Epoch 24/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6599 - accuracy: 0.7630 - val_loss: 0.8279 - val_accuracy: 0.6653\n","Epoch 25/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6558 - accuracy: 0.7713 - val_loss: 0.8429 - val_accuracy: 0.6560\n","Epoch 26/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6499 - accuracy: 0.7713 - val_loss: 0.8564 - val_accuracy: 0.6498\n","Epoch 27/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6467 - accuracy: 0.7765 - val_loss: 0.8387 - val_accuracy: 0.6684\n","Epoch 28/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6438 - accuracy: 0.7773 - val_loss: 0.8410 - val_accuracy: 0.6684\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6377 - accuracy: 0.7775 - val_loss: 0.8549 - val_accuracy: 0.6663\n","Epoch 30/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6378 - accuracy: 0.7786 - val_loss: 0.8583 - val_accuracy: 0.6684\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6381 - accuracy: 0.7765 - val_loss: 0.8634 - val_accuracy: 0.6560\n","Epoch 32/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6320 - accuracy: 0.7780 - val_loss: 0.8523 - val_accuracy: 0.6632\n","Epoch 33/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6302 - accuracy: 0.7850 - val_loss: 0.8678 - val_accuracy: 0.6570\n","Epoch 34/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6246 - accuracy: 0.7845 - val_loss: 0.8634 - val_accuracy: 0.6612\n","Epoch 35/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6259 - accuracy: 0.7902 - val_loss: 0.8598 - val_accuracy: 0.6612\n","Epoch 36/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6323 - accuracy: 0.7739 - val_loss: 0.8649 - val_accuracy: 0.6601\n","Epoch 37/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6305 - accuracy: 0.7791 - val_loss: 0.8743 - val_accuracy: 0.6632\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6199 - accuracy: 0.7886 - val_loss: 0.8911 - val_accuracy: 0.6446\n","Epoch 39/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6238 - accuracy: 0.7886 - val_loss: 0.8996 - val_accuracy: 0.6488\n","Epoch 40/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6179 - accuracy: 0.7866 - val_loss: 0.8897 - val_accuracy: 0.6488\n","Epoch 41/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6186 - accuracy: 0.7855 - val_loss: 0.8664 - val_accuracy: 0.6622\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6153 - accuracy: 0.7858 - val_loss: 0.8681 - val_accuracy: 0.6653\n","Epoch 43/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6175 - accuracy: 0.7858 - val_loss: 0.9136 - val_accuracy: 0.6405\n","Epoch 44/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6171 - accuracy: 0.7829 - val_loss: 0.8634 - val_accuracy: 0.6632\n","Epoch 45/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6179 - accuracy: 0.7879 - val_loss: 0.8610 - val_accuracy: 0.6550\n","Epoch 46/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6050 - accuracy: 0.7935 - val_loss: 0.8845 - val_accuracy: 0.6498\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6051 - accuracy: 0.8036 - val_loss: 0.8783 - val_accuracy: 0.6622\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6047 - accuracy: 0.7917 - val_loss: 0.8829 - val_accuracy: 0.6374\n","Epoch 49/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6017 - accuracy: 0.7964 - val_loss: 0.8871 - val_accuracy: 0.6488\n","Epoch 50/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5910 - accuracy: 0.7961 - val_loss: 0.8713 - val_accuracy: 0.6612\n","Epoch 51/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6011 - accuracy: 0.7897 - val_loss: 0.8851 - val_accuracy: 0.6622\n","Epoch 52/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5975 - accuracy: 0.7961 - val_loss: 0.8795 - val_accuracy: 0.6612\n","Epoch 53/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5970 - accuracy: 0.7972 - val_loss: 0.8842 - val_accuracy: 0.6622\n","Epoch 54/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5902 - accuracy: 0.7992 - val_loss: 0.8824 - val_accuracy: 0.6539\n","Epoch 55/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5885 - accuracy: 0.7990 - val_loss: 0.9246 - val_accuracy: 0.6446\n","Epoch 56/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6087 - accuracy: 0.7902 - val_loss: 0.8979 - val_accuracy: 0.6643\n","Epoch 57/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6096 - accuracy: 0.7832 - val_loss: 0.8853 - val_accuracy: 0.6622\n","Epoch 58/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5862 - accuracy: 0.8005 - val_loss: 0.8867 - val_accuracy: 0.6550\n","Epoch 59/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5835 - accuracy: 0.8052 - val_loss: 0.8777 - val_accuracy: 0.6550\n","Epoch 60/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5854 - accuracy: 0.8054 - val_loss: 0.8887 - val_accuracy: 0.6539\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5804 - accuracy: 0.8067 - val_loss: 0.8863 - val_accuracy: 0.6529\n","Epoch 62/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5793 - accuracy: 0.8057 - val_loss: 0.8885 - val_accuracy: 0.6581\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5795 - accuracy: 0.7972 - val_loss: 0.8920 - val_accuracy: 0.6550\n","Epoch 64/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5757 - accuracy: 0.8088 - val_loss: 0.8955 - val_accuracy: 0.6601\n","Epoch 65/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5783 - accuracy: 0.7984 - val_loss: 0.8970 - val_accuracy: 0.6508\n","Epoch 66/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5763 - accuracy: 0.8021 - val_loss: 0.8912 - val_accuracy: 0.6519\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5782 - accuracy: 0.8026 - val_loss: 0.8947 - val_accuracy: 0.6550\n","Epoch 68/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5701 - accuracy: 0.8052 - val_loss: 0.8943 - val_accuracy: 0.6488\n","Epoch 69/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5626 - accuracy: 0.8080 - val_loss: 0.9005 - val_accuracy: 0.6539\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5617 - accuracy: 0.8096 - val_loss: 0.8997 - val_accuracy: 0.6539\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5742 - accuracy: 0.7984 - val_loss: 0.9311 - val_accuracy: 0.6457\n","Epoch 72/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5579 - accuracy: 0.8140 - val_loss: 0.8978 - val_accuracy: 0.6550\n","Epoch 73/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5598 - accuracy: 0.8155 - val_loss: 0.9011 - val_accuracy: 0.6488\n","Epoch 74/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5615 - accuracy: 0.8163 - val_loss: 0.8938 - val_accuracy: 0.6612\n","Epoch 75/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5583 - accuracy: 0.8186 - val_loss: 0.8987 - val_accuracy: 0.6519\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5600 - accuracy: 0.8145 - val_loss: 0.9164 - val_accuracy: 0.6550\n","Epoch 77/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5542 - accuracy: 0.8173 - val_loss: 0.9262 - val_accuracy: 0.6477\n","Epoch 78/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5591 - accuracy: 0.8129 - val_loss: 0.9055 - val_accuracy: 0.6560\n","Epoch 79/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5516 - accuracy: 0.8137 - val_loss: 0.9854 - val_accuracy: 0.6250\n","Epoch 80/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5647 - accuracy: 0.8070 - val_loss: 0.9233 - val_accuracy: 0.6395\n","Epoch 81/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5482 - accuracy: 0.8171 - val_loss: 0.9108 - val_accuracy: 0.6529\n","Epoch 82/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5443 - accuracy: 0.8238 - val_loss: 0.9352 - val_accuracy: 0.6395\n","Epoch 83/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5463 - accuracy: 0.8196 - val_loss: 0.9518 - val_accuracy: 0.6405\n","Epoch 84/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5411 - accuracy: 0.8202 - val_loss: 0.9415 - val_accuracy: 0.6384\n","Epoch 85/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5447 - accuracy: 0.8199 - val_loss: 0.9212 - val_accuracy: 0.6467\n","Epoch 86/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5434 - accuracy: 0.8168 - val_loss: 0.9246 - val_accuracy: 0.6529\n","Epoch 87/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5472 - accuracy: 0.8098 - val_loss: 0.9166 - val_accuracy: 0.6529\n","Epoch 88/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5428 - accuracy: 0.8230 - val_loss: 0.9478 - val_accuracy: 0.6436\n","Epoch 89/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5477 - accuracy: 0.8124 - val_loss: 0.9215 - val_accuracy: 0.6488\n","Epoch 90/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5362 - accuracy: 0.8274 - val_loss: 0.9172 - val_accuracy: 0.6477\n","Epoch 91/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5338 - accuracy: 0.8251 - val_loss: 0.9243 - val_accuracy: 0.6529\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5285 - accuracy: 0.8258 - val_loss: 0.9389 - val_accuracy: 0.6426\n","Epoch 93/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5360 - accuracy: 0.8245 - val_loss: 1.0030 - val_accuracy: 0.6198\n","Epoch 94/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5593 - accuracy: 0.8083 - val_loss: 1.0240 - val_accuracy: 0.6012\n","Epoch 95/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5344 - accuracy: 0.8178 - val_loss: 0.9625 - val_accuracy: 0.6384\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5288 - accuracy: 0.8233 - val_loss: 0.9258 - val_accuracy: 0.6498\n","Epoch 97/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5238 - accuracy: 0.8284 - val_loss: 0.9212 - val_accuracy: 0.6488\n","Epoch 98/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5216 - accuracy: 0.8344 - val_loss: 0.9444 - val_accuracy: 0.6477\n","Epoch 99/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5219 - accuracy: 0.8302 - val_loss: 0.9304 - val_accuracy: 0.6560\n","Epoch 100/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5147 - accuracy: 0.8377 - val_loss: 0.9429 - val_accuracy: 0.6508\n","{'loss': [0.7232447862625122, 0.7177293300628662, 0.708823025226593, 0.7133261561393738, 0.7055941224098206, 0.69883131980896, 0.6950387358665466, 0.6944773197174072, 0.6914819478988647, 0.6907228827476501, 0.6913623809814453, 0.6831820011138916, 0.6866639852523804, 0.6800296306610107, 0.6749686598777771, 0.6692022681236267, 0.6778218746185303, 0.6706814169883728, 0.6654908657073975, 0.6602938771247864, 0.6670562624931335, 0.6628618240356445, 0.6556115746498108, 0.6599066257476807, 0.6558299660682678, 0.6498779058456421, 0.6466923952102661, 0.6437682509422302, 0.6376527547836304, 0.6378040909767151, 0.6380512118339539, 0.6319628357887268, 0.6301960945129395, 0.6246286630630493, 0.6259056329727173, 0.6322944164276123, 0.6305471062660217, 0.6198546886444092, 0.6237735152244568, 0.6179259419441223, 0.6185576319694519, 0.6152838468551636, 0.6175122261047363, 0.6170836091041565, 0.6178665161132812, 0.6049797534942627, 0.6050660610198975, 0.6047472953796387, 0.6017151474952698, 0.5909575819969177, 0.6011205911636353, 0.5975214838981628, 0.5969705581665039, 0.5901662707328796, 0.5885339975357056, 0.6086983680725098, 0.6095686554908752, 0.5861748456954956, 0.5835368037223816, 0.5853621363639832, 0.5804481506347656, 0.5792996287345886, 0.5795185565948486, 0.575704038143158, 0.5782844424247742, 0.5762794613838196, 0.578202486038208, 0.5701489448547363, 0.5625882148742676, 0.5617403388023376, 0.5741851329803467, 0.5579171776771545, 0.5597966909408569, 0.5615246891975403, 0.5582621097564697, 0.5599757432937622, 0.5541786551475525, 0.5590612888336182, 0.5515934824943542, 0.5646785497665405, 0.5481612086296082, 0.5443328022956848, 0.546343207359314, 0.5410992503166199, 0.5447075366973877, 0.5434157848358154, 0.5472384691238403, 0.5427827835083008, 0.5476546287536621, 0.5362347960472107, 0.5338475704193115, 0.5285101532936096, 0.5360211133956909, 0.5593441128730774, 0.5344458222389221, 0.5287607312202454, 0.5238274335861206, 0.5215541124343872, 0.5219178199768066, 0.5147266983985901], 'accuracy': [0.7436692714691162, 0.7426356673240662, 0.7447028160095215, 0.7361757159233093, 0.750129222869873, 0.7524547576904297, 0.7555555701255798, 0.7547803521156311, 0.751937985420227, 0.7555555701255798, 0.7620155215263367, 0.7609819173812866, 0.7581395506858826, 0.7596899271011353, 0.7677002549171448, 0.7638242840766907, 0.7620155215263367, 0.7666666507720947, 0.7679586410522461, 0.7746769785881042, 0.763307511806488, 0.7666666507720947, 0.7731266021728516, 0.7630490660667419, 0.7713178396224976, 0.7713178396224976, 0.776485800743103, 0.777260959148407, 0.7775194048881531, 0.7785529494285583, 0.776485800743103, 0.7780361771583557, 0.7850129008293152, 0.7844961285591125, 0.7901808619499207, 0.7739018201828003, 0.7790697813034058, 0.788630485534668, 0.788630485534668, 0.7865633368492126, 0.7855297327041626, 0.7857881188392639, 0.7857881188392639, 0.7829457521438599, 0.7878552675247192, 0.7935400605201721, 0.8036175966262817, 0.7917312383651733, 0.7963824272155762, 0.7961240410804749, 0.789664089679718, 0.7961240410804749, 0.7971576452255249, 0.7992247939109802, 0.7989664077758789, 0.7901808619499207, 0.7832041382789612, 0.8005167841911316, 0.8051679730415344, 0.8054263591766357, 0.8067183494567871, 0.8056847453117371, 0.7971576452255249, 0.8087855577468872, 0.7984496355056763, 0.8020671606063843, 0.8025839924812317, 0.8051679730415344, 0.8080103397369385, 0.8095607161521912, 0.7984496355056763, 0.8139534592628479, 0.8155038952827454, 0.8162790536880493, 0.8186046481132507, 0.8144702911376953, 0.8173126578330994, 0.8129199147224426, 0.8136950731277466, 0.8069767355918884, 0.817054271697998, 0.8237726092338562, 0.8196382522583008, 0.8201550245285034, 0.8198966383934021, 0.8167958855628967, 0.8098191022872925, 0.8229973912239075, 0.8124030828475952, 0.827390193939209, 0.8250645995140076, 0.8258398175239563, 0.8245478272438049, 0.8082687258720398, 0.817829430103302, 0.8232558369636536, 0.828423798084259, 0.8343669176101685, 0.830232560634613, 0.8377261161804199], 'val_loss': [0.9504361152648926, 0.9358219504356384, 0.9296878576278687, 0.9370224475860596, 0.9187087416648865, 0.91511470079422, 0.894241213798523, 0.9031266570091248, 0.892933189868927, 0.8716210126876831, 0.8639307618141174, 0.8642908334732056, 0.8451176285743713, 0.8507555723190308, 0.8313859701156616, 0.8142179250717163, 0.8203417658805847, 0.8166887760162354, 0.8115947842597961, 0.8167393803596497, 0.8227928876876831, 0.8329822421073914, 0.8264738321304321, 0.827872097492218, 0.8429221510887146, 0.8563807010650635, 0.8387221097946167, 0.8410080075263977, 0.8549378514289856, 0.8582820296287537, 0.8633919954299927, 0.8523279428482056, 0.867847204208374, 0.863430917263031, 0.8597955107688904, 0.86492919921875, 0.8742578029632568, 0.8911129236221313, 0.8995782732963562, 0.8897424340248108, 0.8664082884788513, 0.8680656552314758, 0.9135782718658447, 0.8633832931518555, 0.8610184788703918, 0.8844766020774841, 0.8782786726951599, 0.8828771710395813, 0.8870654702186584, 0.8712853193283081, 0.8850964903831482, 0.8795145750045776, 0.8842105865478516, 0.8824000358581543, 0.9245639443397522, 0.8979196548461914, 0.8852596282958984, 0.8866838216781616, 0.8776879906654358, 0.8887187838554382, 0.886326014995575, 0.8884926438331604, 0.8920188546180725, 0.8954896926879883, 0.8970401883125305, 0.8911588788032532, 0.894686758518219, 0.8943285942077637, 0.9004902243614197, 0.8996964693069458, 0.9311246275901794, 0.8977537155151367, 0.9010536670684814, 0.8937981724739075, 0.8986740708351135, 0.916448175907135, 0.9262065291404724, 0.9055193066596985, 0.9854138493537903, 0.9233084321022034, 0.9107779264450073, 0.935178279876709, 0.9518257975578308, 0.9415193796157837, 0.9211628437042236, 0.9246283769607544, 0.916560709476471, 0.9478291869163513, 0.9215477108955383, 0.9171683192253113, 0.9242870211601257, 0.9388582706451416, 1.0029704570770264, 1.023989200592041, 0.9624978303909302, 0.9258294701576233, 0.921188235282898, 0.9444053769111633, 0.9304397702217102, 0.9428761005401611], 'val_accuracy': [0.5144628286361694, 0.5144628286361694, 0.5144628286361694, 0.5165289044380188, 0.5185950398445129, 0.5185950398445129, 0.5299586653709412, 0.5247933864593506, 0.5371900796890259, 0.5630165338516235, 0.5754132270812988, 0.5754132270812988, 0.6115702390670776, 0.6022727489471436, 0.6456611752510071, 0.6652892827987671, 0.6580578684806824, 0.6590909361839294, 0.6683884263038635, 0.6580578684806824, 0.6570248007774353, 0.6580578684806824, 0.66425621509552, 0.6652892827987671, 0.6559917330741882, 0.6497933864593506, 0.6683884263038635, 0.6683884263038635, 0.6663222908973694, 0.6683884263038635, 0.6559917330741882, 0.663223147392273, 0.6570248007774353, 0.6611570119857788, 0.6611570119857788, 0.6601239442825317, 0.663223147392273, 0.64462810754776, 0.6487603187561035, 0.6487603187561035, 0.6621900796890259, 0.6652892827987671, 0.6404958963394165, 0.663223147392273, 0.6549586653709412, 0.6497933864593506, 0.6621900796890259, 0.6373966932296753, 0.6487603187561035, 0.6611570119857788, 0.6621900796890259, 0.6611570119857788, 0.6621900796890259, 0.6539255976676941, 0.64462810754776, 0.66425621509552, 0.6621900796890259, 0.6549586653709412, 0.6549586653709412, 0.6539255976676941, 0.6528925895690918, 0.6580578684806824, 0.6549586653709412, 0.6601239442825317, 0.6508264541625977, 0.6518595218658447, 0.6549586653709412, 0.6487603187561035, 0.6539255976676941, 0.6539255976676941, 0.6456611752510071, 0.6549586653709412, 0.6487603187561035, 0.6611570119857788, 0.6518595218658447, 0.6549586653709412, 0.6477272510528564, 0.6559917330741882, 0.625, 0.6394628286361694, 0.6528925895690918, 0.6394628286361694, 0.6404958963394165, 0.6384297609329224, 0.6466942429542542, 0.6528925895690918, 0.6528925895690918, 0.6435950398445129, 0.6487603187561035, 0.6477272510528564, 0.6528925895690918, 0.6425619721412659, 0.6198347210884094, 0.6012396812438965, 0.6384297609329224, 0.6497933864593506, 0.6487603187561035, 0.6477272510528564, 0.6559917330741882, 0.6508264541625977]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.5869 - accuracy: 0.7994"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 7s 74ms/step - loss: 0.5876 - accuracy: 0.7993 - val_loss: 0.9106 - val_accuracy: 0.5172\n","Epoch 2/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5766 - accuracy: 0.8023 - val_loss: 0.8895 - val_accuracy: 0.5172\n","Epoch 3/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5679 - accuracy: 0.8087 - val_loss: 0.8892 - val_accuracy: 0.5172\n","Epoch 4/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.5641 - accuracy: 0.8039 - val_loss: 0.8564 - val_accuracy: 0.5216\n","Epoch 5/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5625 - accuracy: 0.8165 - val_loss: 0.8730 - val_accuracy: 0.5216\n","Epoch 6/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5581 - accuracy: 0.8128 - val_loss: 0.8836 - val_accuracy: 0.5205\n","Epoch 7/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5577 - accuracy: 0.8103 - val_loss: 0.8464 - val_accuracy: 0.5323\n","Epoch 8/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5626 - accuracy: 0.8058 - val_loss: 0.8289 - val_accuracy: 0.5496\n","Epoch 9/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5550 - accuracy: 0.8147 - val_loss: 0.8072 - val_accuracy: 0.5647\n","Epoch 10/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5502 - accuracy: 0.8122 - val_loss: 0.7937 - val_accuracy: 0.6627\n","Epoch 11/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5468 - accuracy: 0.8101 - val_loss: 0.7921 - val_accuracy: 0.6024\n","Epoch 12/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5515 - accuracy: 0.8138 - val_loss: 0.7708 - val_accuracy: 0.6649\n","Epoch 13/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.5455 - accuracy: 0.8141 - val_loss: 0.7627 - val_accuracy: 0.6875\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5381 - accuracy: 0.8273 - val_loss: 0.7622 - val_accuracy: 0.6735\n","Epoch 15/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5356 - accuracy: 0.8225 - val_loss: 0.7536 - val_accuracy: 0.6756\n","Epoch 16/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5332 - accuracy: 0.8268 - val_loss: 0.7426 - val_accuracy: 0.6789\n","Epoch 17/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5303 - accuracy: 0.8276 - val_loss: 0.7382 - val_accuracy: 0.6853\n","Epoch 18/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5300 - accuracy: 0.8262 - val_loss: 0.7218 - val_accuracy: 0.6961\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5344 - accuracy: 0.8203 - val_loss: 0.7153 - val_accuracy: 0.6961\n","Epoch 20/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5304 - accuracy: 0.8284 - val_loss: 0.7056 - val_accuracy: 0.7004\n","Epoch 21/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5254 - accuracy: 0.8327 - val_loss: 0.6936 - val_accuracy: 0.7317\n","Epoch 22/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5301 - accuracy: 0.8300 - val_loss: 0.7072 - val_accuracy: 0.7155\n","Epoch 23/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5247 - accuracy: 0.8260 - val_loss: 0.7093 - val_accuracy: 0.7004\n","Epoch 24/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.5157 - accuracy: 0.8305 - val_loss: 0.6885 - val_accuracy: 0.7371\n","Epoch 25/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5235 - accuracy: 0.8281 - val_loss: 0.6819 - val_accuracy: 0.7371\n","Epoch 26/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5169 - accuracy: 0.8319 - val_loss: 0.7110 - val_accuracy: 0.7091\n","Epoch 27/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5204 - accuracy: 0.8268 - val_loss: 0.7091 - val_accuracy: 0.7134\n","Epoch 28/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.5275 - accuracy: 0.8281 - val_loss: 0.7002 - val_accuracy: 0.7435\n","Epoch 29/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5188 - accuracy: 0.8351 - val_loss: 0.6973 - val_accuracy: 0.7414\n","Epoch 30/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.5121 - accuracy: 0.8357 - val_loss: 0.7015 - val_accuracy: 0.7468\n","Epoch 31/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5134 - accuracy: 0.8349 - val_loss: 0.7421 - val_accuracy: 0.7091\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5103 - accuracy: 0.8330 - val_loss: 0.7117 - val_accuracy: 0.7414\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5178 - accuracy: 0.8276 - val_loss: 0.7172 - val_accuracy: 0.7381\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5047 - accuracy: 0.8349 - val_loss: 0.7113 - val_accuracy: 0.7414\n","Epoch 35/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5033 - accuracy: 0.8397 - val_loss: 0.7105 - val_accuracy: 0.7360\n","Epoch 36/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5126 - accuracy: 0.8295 - val_loss: 0.7213 - val_accuracy: 0.7381\n","Epoch 37/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5007 - accuracy: 0.8400 - val_loss: 0.7207 - val_accuracy: 0.7457\n","Epoch 38/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5024 - accuracy: 0.8394 - val_loss: 0.7153 - val_accuracy: 0.7317\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5008 - accuracy: 0.8357 - val_loss: 0.7499 - val_accuracy: 0.7241\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4990 - accuracy: 0.8392 - val_loss: 0.7197 - val_accuracy: 0.7403\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4960 - accuracy: 0.8464 - val_loss: 0.7213 - val_accuracy: 0.7392\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4930 - accuracy: 0.8467 - val_loss: 0.7454 - val_accuracy: 0.7295\n","Epoch 43/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4963 - accuracy: 0.8402 - val_loss: 0.7978 - val_accuracy: 0.6875\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4882 - accuracy: 0.8505 - val_loss: 0.7287 - val_accuracy: 0.7360\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4925 - accuracy: 0.8432 - val_loss: 0.7279 - val_accuracy: 0.7241\n","Epoch 46/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4929 - accuracy: 0.8446 - val_loss: 0.7387 - val_accuracy: 0.7209\n","Epoch 47/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4862 - accuracy: 0.8502 - val_loss: 0.7297 - val_accuracy: 0.7414\n","Epoch 48/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4869 - accuracy: 0.8478 - val_loss: 0.7337 - val_accuracy: 0.7392\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4797 - accuracy: 0.8534 - val_loss: 0.7319 - val_accuracy: 0.7403\n","Epoch 50/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4876 - accuracy: 0.8421 - val_loss: 0.7410 - val_accuracy: 0.7328\n","Epoch 51/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4774 - accuracy: 0.8553 - val_loss: 0.7849 - val_accuracy: 0.7058\n","Epoch 52/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4741 - accuracy: 0.8575 - val_loss: 0.8452 - val_accuracy: 0.6627\n","Epoch 53/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4749 - accuracy: 0.8510 - val_loss: 0.7816 - val_accuracy: 0.7080\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4754 - accuracy: 0.8561 - val_loss: 0.7662 - val_accuracy: 0.7112\n","Epoch 55/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4816 - accuracy: 0.8483 - val_loss: 0.7569 - val_accuracy: 0.7263\n","Epoch 56/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4787 - accuracy: 0.8526 - val_loss: 0.7529 - val_accuracy: 0.7198\n","Epoch 57/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4669 - accuracy: 0.8586 - val_loss: 0.7605 - val_accuracy: 0.7134\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4748 - accuracy: 0.8521 - val_loss: 0.7418 - val_accuracy: 0.7328\n","Epoch 59/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4709 - accuracy: 0.8567 - val_loss: 0.7634 - val_accuracy: 0.7101\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4726 - accuracy: 0.8473 - val_loss: 0.7569 - val_accuracy: 0.7317\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4637 - accuracy: 0.8548 - val_loss: 0.7824 - val_accuracy: 0.7123\n","Epoch 62/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4630 - accuracy: 0.8556 - val_loss: 0.7700 - val_accuracy: 0.7284\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4626 - accuracy: 0.8524 - val_loss: 0.7712 - val_accuracy: 0.7231\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4628 - accuracy: 0.8607 - val_loss: 0.8432 - val_accuracy: 0.6907\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4688 - accuracy: 0.8521 - val_loss: 0.7578 - val_accuracy: 0.7306\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4577 - accuracy: 0.8653 - val_loss: 0.7601 - val_accuracy: 0.7306\n","Epoch 67/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4547 - accuracy: 0.8594 - val_loss: 0.7925 - val_accuracy: 0.7188\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4563 - accuracy: 0.8621 - val_loss: 0.7756 - val_accuracy: 0.7295\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4618 - accuracy: 0.8610 - val_loss: 0.7866 - val_accuracy: 0.7177\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4499 - accuracy: 0.8623 - val_loss: 0.8332 - val_accuracy: 0.6972\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4517 - accuracy: 0.8580 - val_loss: 0.7658 - val_accuracy: 0.7295\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4533 - accuracy: 0.8605 - val_loss: 0.7769 - val_accuracy: 0.7231\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4460 - accuracy: 0.8691 - val_loss: 0.7689 - val_accuracy: 0.7306\n","Epoch 74/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4441 - accuracy: 0.8685 - val_loss: 0.8104 - val_accuracy: 0.7144\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4423 - accuracy: 0.8688 - val_loss: 0.7706 - val_accuracy: 0.7241\n","Epoch 76/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4393 - accuracy: 0.8702 - val_loss: 0.7875 - val_accuracy: 0.7188\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4447 - accuracy: 0.8661 - val_loss: 0.8319 - val_accuracy: 0.7112\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4451 - accuracy: 0.8688 - val_loss: 0.7843 - val_accuracy: 0.7231\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4358 - accuracy: 0.8710 - val_loss: 0.7909 - val_accuracy: 0.7231\n","Epoch 80/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4345 - accuracy: 0.8693 - val_loss: 0.7782 - val_accuracy: 0.7252\n","Epoch 81/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4415 - accuracy: 0.8677 - val_loss: 0.8001 - val_accuracy: 0.7166\n","Epoch 82/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4336 - accuracy: 0.8699 - val_loss: 0.7759 - val_accuracy: 0.7263\n","Epoch 83/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4246 - accuracy: 0.8772 - val_loss: 0.7886 - val_accuracy: 0.7177\n","Epoch 84/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4371 - accuracy: 0.8707 - val_loss: 0.7988 - val_accuracy: 0.7177\n","Epoch 85/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4410 - accuracy: 0.8605 - val_loss: 0.7898 - val_accuracy: 0.7252\n","Epoch 86/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4359 - accuracy: 0.8666 - val_loss: 0.7845 - val_accuracy: 0.7263\n","Epoch 87/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4272 - accuracy: 0.8761 - val_loss: 0.8226 - val_accuracy: 0.7080\n","Epoch 88/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4248 - accuracy: 0.8780 - val_loss: 0.8053 - val_accuracy: 0.7252\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4401 - accuracy: 0.8650 - val_loss: 0.7967 - val_accuracy: 0.7166\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4248 - accuracy: 0.8742 - val_loss: 0.8157 - val_accuracy: 0.7241\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4177 - accuracy: 0.8796 - val_loss: 0.8699 - val_accuracy: 0.6875\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4291 - accuracy: 0.8731 - val_loss: 0.7919 - val_accuracy: 0.7209\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4199 - accuracy: 0.8758 - val_loss: 0.8350 - val_accuracy: 0.7058\n","Epoch 94/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4256 - accuracy: 0.8774 - val_loss: 0.8033 - val_accuracy: 0.7209\n","Epoch 95/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4156 - accuracy: 0.8807 - val_loss: 0.8018 - val_accuracy: 0.7144\n","Epoch 96/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4130 - accuracy: 0.8769 - val_loss: 0.8044 - val_accuracy: 0.7188\n","Epoch 97/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4168 - accuracy: 0.8807 - val_loss: 0.8381 - val_accuracy: 0.7220\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4240 - accuracy: 0.8702 - val_loss: 0.8195 - val_accuracy: 0.7252\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4175 - accuracy: 0.8737 - val_loss: 0.8265 - val_accuracy: 0.7188\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4252 - accuracy: 0.8772 - val_loss: 0.8628 - val_accuracy: 0.6994\n","{'loss': [0.5875796675682068, 0.5765901803970337, 0.5678916573524475, 0.564117968082428, 0.5624502301216125, 0.5580694675445557, 0.5577472448348999, 0.5626023411750793, 0.5550300478935242, 0.5501652956008911, 0.5467857718467712, 0.5514978766441345, 0.5454792380332947, 0.5381097197532654, 0.5355730652809143, 0.5331791043281555, 0.5303086042404175, 0.5300003290176392, 0.5344460010528564, 0.5303979516029358, 0.5254127383232117, 0.5301171541213989, 0.5247434377670288, 0.5156725645065308, 0.5234829783439636, 0.5169367790222168, 0.5204361081123352, 0.5274734497070312, 0.5188307762145996, 0.5120862126350403, 0.5133782625198364, 0.5103026628494263, 0.5178157687187195, 0.5047186017036438, 0.5032566785812378, 0.5126331448554993, 0.5006656050682068, 0.5024308562278748, 0.5008428692817688, 0.4990271329879761, 0.4960396885871887, 0.49295496940612793, 0.4962877631187439, 0.48822370171546936, 0.4924556612968445, 0.49288344383239746, 0.48615965247154236, 0.48690420389175415, 0.47965505719184875, 0.48757869005203247, 0.47738584876060486, 0.474136620759964, 0.47489482164382935, 0.47541865706443787, 0.48161113262176514, 0.4786930978298187, 0.4669113755226135, 0.4747712314128876, 0.47086644172668457, 0.47258707880973816, 0.4637131989002228, 0.4630053639411926, 0.4626013934612274, 0.46278443932533264, 0.46875348687171936, 0.45767742395401, 0.4547450840473175, 0.4562598168849945, 0.46179813146591187, 0.44992774724960327, 0.4517205059528351, 0.45328885316848755, 0.4460316300392151, 0.4441431164741516, 0.4422740042209625, 0.43932202458381653, 0.4447060227394104, 0.44514864683151245, 0.4357709586620331, 0.4344850778579712, 0.44153541326522827, 0.4336478114128113, 0.42458128929138184, 0.4371464252471924, 0.4410257637500763, 0.4359203279018402, 0.42717045545578003, 0.42476004362106323, 0.44008368253707886, 0.42480823397636414, 0.4176759421825409, 0.4291474521160126, 0.41986343264579773, 0.42563411593437195, 0.4155597388744354, 0.4130253493785858, 0.41682174801826477, 0.4239616394042969, 0.4175475239753723, 0.42515847086906433], 'accuracy': [0.7992995977401733, 0.8022629022598267, 0.8087284564971924, 0.8038793206214905, 0.8165409564971924, 0.8127694129943848, 0.8103448152542114, 0.8057650923728943, 0.8146551847457886, 0.8122305870056152, 0.8100754022598267, 0.813847005367279, 0.814116358757019, 0.8273168206214905, 0.8224676847457886, 0.826777994632721, 0.8275862336158752, 0.8262392282485962, 0.8203125, 0.8283944129943848, 0.8327047228813171, 0.8300107717514038, 0.8259698152542114, 0.8305495977401733, 0.828125, 0.8318965435028076, 0.826777994632721, 0.828125, 0.8351293206214905, 0.8356680870056152, 0.8348599076271057, 0.8329741358757019, 0.8275862336158752, 0.8348599076271057, 0.8397090435028076, 0.829472005367279, 0.8399784564971924, 0.8394396305084229, 0.8356680870056152, 0.8391702771186829, 0.8464439511299133, 0.8467133641242981, 0.8402478694915771, 0.8504849076271057, 0.8432112336158752, 0.8445581793785095, 0.850215494632721, 0.8477909564971924, 0.8534482717514038, 0.842133641242981, 0.8553340435028076, 0.8574892282485962, 0.8510237336158752, 0.8561422228813171, 0.8483297228813171, 0.8526400923728943, 0.8585668206214905, 0.8521012663841248, 0.8566810488700867, 0.8472521305084229, 0.8547952771186829, 0.8556034564971924, 0.8523706793785095, 0.860722005367279, 0.8521012663841248, 0.8653017282485962, 0.859375, 0.8620689511299133, 0.860991358757019, 0.8623383641242981, 0.858027994632721, 0.8604525923728943, 0.8690732717514038, 0.868534505367279, 0.868803858757019, 0.8701508641242981, 0.8661099076271057, 0.868803858757019, 0.8709590435028076, 0.8693426847457886, 0.8677262663841248, 0.8698814511299133, 0.8771551847457886, 0.8706896305084229, 0.8604525923728943, 0.8666487336158752, 0.8760775923728943, 0.8779633641242981, 0.8650323152542114, 0.8741918206214905, 0.8795797228813171, 0.8731142282485962, 0.8758081793785095, 0.8774245977401733, 0.8806573152542114, 0.8768857717514038, 0.8806573152542114, 0.8701508641242981, 0.873652994632721, 0.8771551847457886], 'val_loss': [0.910645604133606, 0.8895077705383301, 0.889174222946167, 0.8564390540122986, 0.8729953765869141, 0.8836261034011841, 0.8463853001594543, 0.8289436101913452, 0.8071575164794922, 0.7937114238739014, 0.7920814752578735, 0.7707909345626831, 0.7627056241035461, 0.7622076272964478, 0.7536422610282898, 0.7425955533981323, 0.7381600141525269, 0.7218101620674133, 0.71531081199646, 0.7055602669715881, 0.6935670971870422, 0.7071739435195923, 0.7093490958213806, 0.6885396838188171, 0.6818963289260864, 0.7109970450401306, 0.709079384803772, 0.7001908421516418, 0.6972581744194031, 0.7015356421470642, 0.742091715335846, 0.7116603851318359, 0.7172410488128662, 0.7113463282585144, 0.7104681730270386, 0.7213032245635986, 0.720733106136322, 0.7153093814849854, 0.7498995661735535, 0.7197257876396179, 0.7212554812431335, 0.7453833222389221, 0.7978392243385315, 0.7286596894264221, 0.7279306650161743, 0.7387273907661438, 0.7296539545059204, 0.7337291240692139, 0.731860339641571, 0.7409935593605042, 0.7848966121673584, 0.8452484011650085, 0.7816265225410461, 0.7661572694778442, 0.7568612098693848, 0.7529048323631287, 0.7604802250862122, 0.7417894601821899, 0.7634379267692566, 0.7569395899772644, 0.7824087738990784, 0.7700104713439941, 0.7711929082870483, 0.8432368040084839, 0.757767379283905, 0.7600887417793274, 0.7924695014953613, 0.7756113409996033, 0.7866395711898804, 0.8332070708274841, 0.7657695412635803, 0.7768560647964478, 0.7689223289489746, 0.8103940486907959, 0.7705802321434021, 0.7874595522880554, 0.8319413661956787, 0.7843289375305176, 0.7908718585968018, 0.7782013416290283, 0.800060510635376, 0.7759157419204712, 0.788585901260376, 0.7988151907920837, 0.7897535562515259, 0.7845277190208435, 0.8225805759429932, 0.8052768111228943, 0.7967231869697571, 0.815664529800415, 0.8699291944503784, 0.7918891906738281, 0.8349673748016357, 0.8033052086830139, 0.8017738461494446, 0.8044210076332092, 0.838072657585144, 0.8195011615753174, 0.826453685760498, 0.8628439903259277], 'val_accuracy': [0.517241358757019, 0.517241358757019, 0.517241358757019, 0.5215517282485962, 0.5215517282485962, 0.5204741358757019, 0.5323275923728943, 0.5495689511299133, 0.5646551847457886, 0.662715494632721, 0.6023706793785095, 0.6648706793785095, 0.6875, 0.673491358757019, 0.6756465435028076, 0.6788793206214905, 0.6853448152542114, 0.6961206793785095, 0.6961206793785095, 0.7004310488700867, 0.7316810488700867, 0.7155172228813171, 0.7004310488700867, 0.7370689511299133, 0.7370689511299133, 0.7090517282485962, 0.7133620977401733, 0.743534505367279, 0.7413793206214905, 0.7467672228813171, 0.7090517282485962, 0.7413793206214905, 0.7381465435028076, 0.7413793206214905, 0.735991358757019, 0.7381465435028076, 0.7456896305084229, 0.7316810488700867, 0.7241379022598267, 0.7403017282485962, 0.7392241358757019, 0.7295258641242981, 0.6875, 0.735991358757019, 0.7241379022598267, 0.7209051847457886, 0.7413793206214905, 0.7392241358757019, 0.7403017282485962, 0.732758641242981, 0.7058189511299133, 0.662715494632721, 0.7079741358757019, 0.7112069129943848, 0.7262930870056152, 0.7198275923728943, 0.7133620977401733, 0.732758641242981, 0.7101293206214905, 0.7316810488700867, 0.712284505367279, 0.7284482717514038, 0.7230603694915771, 0.6907327771186829, 0.7306034564971924, 0.7306034564971924, 0.71875, 0.7295258641242981, 0.7176724076271057, 0.6971982717514038, 0.7295258641242981, 0.7230603694915771, 0.7306034564971924, 0.7144396305084229, 0.7241379022598267, 0.71875, 0.7112069129943848, 0.7230603694915771, 0.7230603694915771, 0.725215494632721, 0.7165948152542114, 0.7262930870056152, 0.7176724076271057, 0.7176724076271057, 0.725215494632721, 0.7262930870056152, 0.7079741358757019, 0.725215494632721, 0.7165948152542114, 0.7241379022598267, 0.6875, 0.7209051847457886, 0.7058189511299133, 0.7209051847457886, 0.7144396305084229, 0.71875, 0.7219827771186829, 0.725215494632721, 0.71875, 0.6993534564971924]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.5751 - accuracy: 0.7934"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 9s 85ms/step - loss: 0.5751 - accuracy: 0.7934 - val_loss: 0.9392 - val_accuracy: 0.5045\n","Epoch 2/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5756 - accuracy: 0.8025 - val_loss: 0.9208 - val_accuracy: 0.5045\n","Epoch 3/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5629 - accuracy: 0.8065 - val_loss: 0.8842 - val_accuracy: 0.5068\n","Epoch 4/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5604 - accuracy: 0.8070 - val_loss: 0.9109 - val_accuracy: 0.5068\n","Epoch 5/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5654 - accuracy: 0.7991 - val_loss: 0.8798 - val_accuracy: 0.5079\n","Epoch 6/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5548 - accuracy: 0.8115 - val_loss: 0.8637 - val_accuracy: 0.5124\n","Epoch 7/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5562 - accuracy: 0.8073 - val_loss: 0.8323 - val_accuracy: 0.5509\n","Epoch 8/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5538 - accuracy: 0.8059 - val_loss: 0.8383 - val_accuracy: 0.5577\n","Epoch 9/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5437 - accuracy: 0.8175 - val_loss: 0.8475 - val_accuracy: 0.5339\n","Epoch 10/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.5443 - accuracy: 0.8090 - val_loss: 0.8291 - val_accuracy: 0.5713\n","Epoch 11/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.5459 - accuracy: 0.8110 - val_loss: 0.8132 - val_accuracy: 0.6097\n","Epoch 12/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5465 - accuracy: 0.8130 - val_loss: 0.8308 - val_accuracy: 0.5792\n","Epoch 13/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.5472 - accuracy: 0.8084 - val_loss: 0.7968 - val_accuracy: 0.6618\n","Epoch 14/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5387 - accuracy: 0.8212 - val_loss: 0.7894 - val_accuracy: 0.6267\n","Epoch 15/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5378 - accuracy: 0.8209 - val_loss: 0.7982 - val_accuracy: 0.6109\n","Epoch 16/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5303 - accuracy: 0.8214 - val_loss: 0.7714 - val_accuracy: 0.6844\n","Epoch 17/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5431 - accuracy: 0.8084 - val_loss: 0.7763 - val_accuracy: 0.6606\n","Epoch 18/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5410 - accuracy: 0.8158 - val_loss: 0.7512 - val_accuracy: 0.6538\n","Epoch 19/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5404 - accuracy: 0.8124 - val_loss: 0.7450 - val_accuracy: 0.6550\n","Epoch 20/100\n","28/28 [==============================] - 1s 39ms/step - loss: 0.5309 - accuracy: 0.8206 - val_loss: 0.7414 - val_accuracy: 0.6946\n","Epoch 21/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5244 - accuracy: 0.8243 - val_loss: 0.7353 - val_accuracy: 0.6946\n","Epoch 22/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5238 - accuracy: 0.8277 - val_loss: 0.7311 - val_accuracy: 0.7048\n","Epoch 23/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5251 - accuracy: 0.8271 - val_loss: 0.7360 - val_accuracy: 0.7149\n","Epoch 24/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5212 - accuracy: 0.8198 - val_loss: 0.7389 - val_accuracy: 0.7183\n","Epoch 25/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5201 - accuracy: 0.8229 - val_loss: 0.7503 - val_accuracy: 0.7025\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5161 - accuracy: 0.8336 - val_loss: 0.7609 - val_accuracy: 0.6934\n","Epoch 27/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5162 - accuracy: 0.8254 - val_loss: 0.7376 - val_accuracy: 0.7229\n","Epoch 28/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5168 - accuracy: 0.8277 - val_loss: 0.7530 - val_accuracy: 0.7217\n","Epoch 29/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5070 - accuracy: 0.8396 - val_loss: 0.7782 - val_accuracy: 0.6912\n","Epoch 30/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5115 - accuracy: 0.8314 - val_loss: 0.8133 - val_accuracy: 0.6719\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5113 - accuracy: 0.8328 - val_loss: 0.8286 - val_accuracy: 0.6595\n","Epoch 32/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5022 - accuracy: 0.8316 - val_loss: 0.7927 - val_accuracy: 0.7014\n","Epoch 33/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5113 - accuracy: 0.8311 - val_loss: 0.7951 - val_accuracy: 0.6946\n","Epoch 34/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5205 - accuracy: 0.8155 - val_loss: 0.8170 - val_accuracy: 0.6867\n","Epoch 35/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5066 - accuracy: 0.8367 - val_loss: 0.8259 - val_accuracy: 0.6686\n","Epoch 36/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5044 - accuracy: 0.8331 - val_loss: 0.7976 - val_accuracy: 0.6900\n","Epoch 37/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4985 - accuracy: 0.8331 - val_loss: 0.7922 - val_accuracy: 0.7229\n","Epoch 38/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5032 - accuracy: 0.8333 - val_loss: 0.7832 - val_accuracy: 0.7206\n","Epoch 39/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4971 - accuracy: 0.8325 - val_loss: 0.7871 - val_accuracy: 0.7161\n","Epoch 40/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5084 - accuracy: 0.8322 - val_loss: 0.8267 - val_accuracy: 0.6980\n","Epoch 41/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4970 - accuracy: 0.8347 - val_loss: 0.7905 - val_accuracy: 0.7149\n","Epoch 42/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5007 - accuracy: 0.8347 - val_loss: 0.8044 - val_accuracy: 0.7081\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4863 - accuracy: 0.8438 - val_loss: 0.8012 - val_accuracy: 0.7183\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4836 - accuracy: 0.8503 - val_loss: 0.7952 - val_accuracy: 0.7206\n","Epoch 45/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4941 - accuracy: 0.8376 - val_loss: 0.8237 - val_accuracy: 0.7025\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4958 - accuracy: 0.8359 - val_loss: 0.8011 - val_accuracy: 0.7195\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4943 - accuracy: 0.8339 - val_loss: 0.8308 - val_accuracy: 0.7104\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4897 - accuracy: 0.8430 - val_loss: 0.8088 - val_accuracy: 0.7195\n","Epoch 49/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4827 - accuracy: 0.8410 - val_loss: 0.8101 - val_accuracy: 0.7138\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4792 - accuracy: 0.8455 - val_loss: 0.8139 - val_accuracy: 0.7059\n","Epoch 51/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4763 - accuracy: 0.8489 - val_loss: 0.8025 - val_accuracy: 0.7115\n","Epoch 52/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4792 - accuracy: 0.8463 - val_loss: 0.8443 - val_accuracy: 0.7115\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4861 - accuracy: 0.8415 - val_loss: 0.8086 - val_accuracy: 0.7183\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4757 - accuracy: 0.8452 - val_loss: 0.8348 - val_accuracy: 0.6957\n","Epoch 55/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4717 - accuracy: 0.8444 - val_loss: 0.8373 - val_accuracy: 0.6889\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4689 - accuracy: 0.8548 - val_loss: 0.8224 - val_accuracy: 0.7081\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4681 - accuracy: 0.8497 - val_loss: 0.8497 - val_accuracy: 0.7025\n","Epoch 58/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4685 - accuracy: 0.8492 - val_loss: 0.8355 - val_accuracy: 0.7025\n","Epoch 59/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4738 - accuracy: 0.8455 - val_loss: 0.8324 - val_accuracy: 0.7149\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4736 - accuracy: 0.8452 - val_loss: 0.8481 - val_accuracy: 0.7104\n","Epoch 61/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4701 - accuracy: 0.8523 - val_loss: 0.8109 - val_accuracy: 0.7195\n","Epoch 62/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4637 - accuracy: 0.8486 - val_loss: 0.8560 - val_accuracy: 0.6957\n","Epoch 63/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4581 - accuracy: 0.8529 - val_loss: 0.8444 - val_accuracy: 0.7115\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4673 - accuracy: 0.8492 - val_loss: 0.8599 - val_accuracy: 0.7048\n","Epoch 65/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4597 - accuracy: 0.8577 - val_loss: 0.8378 - val_accuracy: 0.7093\n","Epoch 66/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4616 - accuracy: 0.8557 - val_loss: 0.9191 - val_accuracy: 0.6584\n","Epoch 67/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4624 - accuracy: 0.8463 - val_loss: 0.8353 - val_accuracy: 0.7138\n","Epoch 68/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4516 - accuracy: 0.8605 - val_loss: 0.8316 - val_accuracy: 0.7115\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4550 - accuracy: 0.8630 - val_loss: 0.8544 - val_accuracy: 0.7104\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4495 - accuracy: 0.8613 - val_loss: 0.8449 - val_accuracy: 0.7070\n","Epoch 71/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4503 - accuracy: 0.8577 - val_loss: 0.8638 - val_accuracy: 0.7036\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4507 - accuracy: 0.8616 - val_loss: 0.8519 - val_accuracy: 0.7127\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4544 - accuracy: 0.8591 - val_loss: 0.8584 - val_accuracy: 0.7093\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4624 - accuracy: 0.8580 - val_loss: 0.8498 - val_accuracy: 0.7104\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4609 - accuracy: 0.8534 - val_loss: 0.8450 - val_accuracy: 0.7025\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4478 - accuracy: 0.8582 - val_loss: 0.8571 - val_accuracy: 0.7104\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4418 - accuracy: 0.8645 - val_loss: 0.8761 - val_accuracy: 0.7104\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4521 - accuracy: 0.8582 - val_loss: 0.8896 - val_accuracy: 0.6900\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4461 - accuracy: 0.8548 - val_loss: 0.8594 - val_accuracy: 0.7002\n","Epoch 80/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4347 - accuracy: 0.8642 - val_loss: 0.8657 - val_accuracy: 0.7025\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4437 - accuracy: 0.8625 - val_loss: 0.8692 - val_accuracy: 0.7081\n","Epoch 82/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4410 - accuracy: 0.8650 - val_loss: 0.8697 - val_accuracy: 0.7070\n","Epoch 83/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4317 - accuracy: 0.8679 - val_loss: 0.8774 - val_accuracy: 0.6991\n","Epoch 84/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4422 - accuracy: 0.8599 - val_loss: 0.9052 - val_accuracy: 0.7014\n","Epoch 85/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4408 - accuracy: 0.8659 - val_loss: 1.0062 - val_accuracy: 0.6233\n","Epoch 86/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4295 - accuracy: 0.8713 - val_loss: 0.8583 - val_accuracy: 0.7059\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4254 - accuracy: 0.8763 - val_loss: 0.8754 - val_accuracy: 0.7070\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4269 - accuracy: 0.8684 - val_loss: 0.8750 - val_accuracy: 0.7059\n","Epoch 89/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4259 - accuracy: 0.8752 - val_loss: 0.8807 - val_accuracy: 0.7081\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4178 - accuracy: 0.8769 - val_loss: 0.8728 - val_accuracy: 0.7081\n","Epoch 91/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4196 - accuracy: 0.8721 - val_loss: 0.8805 - val_accuracy: 0.7081\n","Epoch 92/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4195 - accuracy: 0.8707 - val_loss: 0.8773 - val_accuracy: 0.7070\n","Epoch 93/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4219 - accuracy: 0.8684 - val_loss: 0.8895 - val_accuracy: 0.7014\n","Epoch 94/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4221 - accuracy: 0.8693 - val_loss: 0.9011 - val_accuracy: 0.6991\n","Epoch 95/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4264 - accuracy: 0.8752 - val_loss: 0.9030 - val_accuracy: 0.7025\n","Epoch 96/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4274 - accuracy: 0.8713 - val_loss: 0.9337 - val_accuracy: 0.6878\n","Epoch 97/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4108 - accuracy: 0.8786 - val_loss: 0.8934 - val_accuracy: 0.7036\n","Epoch 98/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4279 - accuracy: 0.8676 - val_loss: 0.9722 - val_accuracy: 0.6923\n","Epoch 99/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4352 - accuracy: 0.8659 - val_loss: 0.9004 - val_accuracy: 0.6991\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4233 - accuracy: 0.8673 - val_loss: 0.9134 - val_accuracy: 0.7002\n","{'loss': [0.5750793218612671, 0.5755689740180969, 0.5628694891929626, 0.5603766441345215, 0.5654259920120239, 0.5547828674316406, 0.5562198162078857, 0.5538352131843567, 0.5437172055244446, 0.5443360209465027, 0.5459111332893372, 0.5465373396873474, 0.5472238063812256, 0.5386621356010437, 0.537784993648529, 0.530255913734436, 0.5430622100830078, 0.5409988164901733, 0.5403793454170227, 0.5308833122253418, 0.5244421362876892, 0.5237670540809631, 0.5250952243804932, 0.5211523175239563, 0.5200802087783813, 0.51610267162323, 0.5161941051483154, 0.5167697072029114, 0.5069698095321655, 0.511535108089447, 0.5113023519515991, 0.5022363662719727, 0.5113184452056885, 0.5204524993896484, 0.5066288113594055, 0.5043929219245911, 0.49852314591407776, 0.5032219886779785, 0.4970817565917969, 0.5084300637245178, 0.4969859719276428, 0.5007264018058777, 0.486337274312973, 0.48357757925987244, 0.49413740634918213, 0.4957873225212097, 0.4942793846130371, 0.48967164754867554, 0.48270729184150696, 0.47915947437286377, 0.47633951902389526, 0.4792273938655853, 0.4860912263393402, 0.4756655991077423, 0.47166019678115845, 0.4688568711280823, 0.4681115746498108, 0.468536913394928, 0.4737561047077179, 0.4735904335975647, 0.4700671136379242, 0.46365565061569214, 0.45813944935798645, 0.4673038721084595, 0.4596601724624634, 0.4615522623062134, 0.4624156057834625, 0.45158717036247253, 0.4549872875213623, 0.44947779178619385, 0.4502623677253723, 0.4507083296775818, 0.4544459283351898, 0.4624492824077606, 0.46092092990875244, 0.44784125685691833, 0.4418390095233917, 0.4520944356918335, 0.4461275339126587, 0.4347105622291565, 0.4437337815761566, 0.4410170316696167, 0.43173372745513916, 0.44223859906196594, 0.4408092200756073, 0.42952394485473633, 0.4253922402858734, 0.42686381936073303, 0.42592155933380127, 0.4177853465080261, 0.41959208250045776, 0.4195064306259155, 0.42190197110176086, 0.42214885354042053, 0.426352858543396, 0.4273684024810791, 0.4107561409473419, 0.4278596341609955, 0.43523821234703064, 0.4233400225639343], 'accuracy': [0.7934352159500122, 0.8024901151657104, 0.8064516186714172, 0.8070175647735596, 0.7990944981575012, 0.8115450143814087, 0.8073005080223083, 0.8058856725692749, 0.8174872398376465, 0.8089982867240906, 0.8109790682792664, 0.8129597902297974, 0.808432400226593, 0.8211658000946045, 0.8208828568458557, 0.821448802947998, 0.808432400226593, 0.8157894611358643, 0.8123939037322998, 0.8205999135971069, 0.8242784142494202, 0.8276740312576294, 0.8271080851554871, 0.819750964641571, 0.8228636384010315, 0.833616316318512, 0.8254103064537048, 0.8276740312576294, 0.8395586013793945, 0.8313525915145874, 0.8327674269676208, 0.8316355347633362, 0.8310695886611938, 0.8155065178871155, 0.8367289304733276, 0.8330503702163696, 0.8330503702163696, 0.8333333134651184, 0.8324844241142273, 0.8322014808654785, 0.8347481489181519, 0.8347481489181519, 0.8438030481338501, 0.850311279296875, 0.8375778198242188, 0.8358800411224365, 0.8338992595672607, 0.842954158782959, 0.8409733772277832, 0.8455008268356323, 0.8488964438438416, 0.8463497161865234, 0.8415393233299255, 0.8452178835868835, 0.8443689942359924, 0.8548387289047241, 0.8497453331947327, 0.8491793870925903, 0.8455008268356323, 0.8452178835868835, 0.852292001247406, 0.848613440990448, 0.8528579473495483, 0.8491793870925903, 0.8576683402061462, 0.8556876182556152, 0.8463497161865234, 0.8604980111122131, 0.8630446791648865, 0.8613469004631042, 0.8576683402061462, 0.8616299033164978, 0.8590831756591797, 0.8579513430595398, 0.8534238934516907, 0.8582342863082886, 0.8644595146179199, 0.8582342863082886, 0.8548387289047241, 0.8641765713691711, 0.8624787926673889, 0.8650254607200623, 0.8678551316261292, 0.8599320650100708, 0.8658743500709534, 0.8712506890296936, 0.8763440847396851, 0.8684210777282715, 0.8752122521400452, 0.8769100308418274, 0.8720995783805847, 0.870684802532196, 0.8684210777282715, 0.8692699670791626, 0.8752122521400452, 0.8712506890296936, 0.8786078095436096, 0.8675721287727356, 0.8658743500709534, 0.8672891855239868], 'val_loss': [0.9391656517982483, 0.9207773208618164, 0.8841851949691772, 0.9109101295471191, 0.8797694444656372, 0.8636752963066101, 0.8323442339897156, 0.8382633924484253, 0.847452700138092, 0.8290950655937195, 0.8132120370864868, 0.830819308757782, 0.7967858910560608, 0.7894256711006165, 0.7981798052787781, 0.7713804841041565, 0.7762858271598816, 0.751245379447937, 0.7450410723686218, 0.7413559556007385, 0.735256552696228, 0.7311385273933411, 0.7360287308692932, 0.7388741970062256, 0.750296950340271, 0.760949432849884, 0.7375754117965698, 0.7530130743980408, 0.7782042622566223, 0.8133044242858887, 0.8286440968513489, 0.7927069067955017, 0.7950866222381592, 0.81704181432724, 0.8259485363960266, 0.7976464033126831, 0.7922192811965942, 0.7832134962081909, 0.7870674133300781, 0.8266767263412476, 0.7905266284942627, 0.8044458627700806, 0.8011791110038757, 0.7951865196228027, 0.8237107992172241, 0.8010545969009399, 0.8307967185974121, 0.808845579624176, 0.810114860534668, 0.8138580918312073, 0.8025384545326233, 0.8442610502243042, 0.8085781335830688, 0.8347843885421753, 0.83733069896698, 0.822413444519043, 0.8496727347373962, 0.8355460166931152, 0.8324097990989685, 0.8480552434921265, 0.8109184503555298, 0.8559679985046387, 0.8444295525550842, 0.859886646270752, 0.8378455638885498, 0.9190787672996521, 0.835337221622467, 0.8316373229026794, 0.8543563485145569, 0.8448596000671387, 0.8637873530387878, 0.8518765568733215, 0.8583688139915466, 0.8497829437255859, 0.8449662923812866, 0.85711669921875, 0.8760958909988403, 0.889593243598938, 0.8594098091125488, 0.8656793236732483, 0.8691999316215515, 0.8697070479393005, 0.8773588538169861, 0.9052376747131348, 1.0061980485916138, 0.8582813143730164, 0.875382661819458, 0.8750099539756775, 0.8807103037834167, 0.8728206753730774, 0.880538821220398, 0.8772698044776917, 0.8895081281661987, 0.9010958671569824, 0.9029892683029175, 0.9337331056594849, 0.8934386372566223, 0.9721683859825134, 0.9003658294677734, 0.9133613109588623], 'val_accuracy': [0.5045248866081238, 0.5045248866081238, 0.5067873597145081, 0.5067873597145081, 0.5079185366630554, 0.5124434232711792, 0.5509049892425537, 0.557692289352417, 0.5339366793632507, 0.5712669491767883, 0.6097285151481628, 0.5791855454444885, 0.6617646813392639, 0.6266968250274658, 0.610859751701355, 0.6843891143798828, 0.6606335043907166, 0.6538461446762085, 0.6549773812294006, 0.6945701241493225, 0.6945701241493225, 0.7047511339187622, 0.7149321436882019, 0.7183257937431335, 0.7024886608123779, 0.6934388875961304, 0.7228506803512573, 0.7217194437980652, 0.6911764740943909, 0.6719456911087036, 0.6595022678375244, 0.7013574838638306, 0.6945701241493225, 0.6866515874862671, 0.668552041053772, 0.6900452375411987, 0.7228506803512573, 0.720588207244873, 0.7160633206367493, 0.6979637742042542, 0.7149321436882019, 0.7081447839736938, 0.7183257937431335, 0.720588207244873, 0.7024886608123779, 0.7194570302963257, 0.7104072570800781, 0.7194570302963257, 0.7138009071350098, 0.7058823704719543, 0.7115384340286255, 0.7115384340286255, 0.7183257937431335, 0.6957013607025146, 0.6889140009880066, 0.7081447839736938, 0.7024886608123779, 0.7024886608123779, 0.7149321436882019, 0.7104072570800781, 0.7194570302963257, 0.6957013607025146, 0.7115384340286255, 0.7047511339187622, 0.709276020526886, 0.6583710312843323, 0.7138009071350098, 0.7115384340286255, 0.7104072570800781, 0.7070135474205017, 0.7036198973655701, 0.7126696705818176, 0.709276020526886, 0.7104072570800781, 0.7024886608123779, 0.7104072570800781, 0.7104072570800781, 0.6900452375411987, 0.7002262473106384, 0.7024886608123779, 0.7081447839736938, 0.7070135474205017, 0.6990950107574463, 0.7013574838638306, 0.6233031749725342, 0.7058823704719543, 0.7070135474205017, 0.7058823704719543, 0.7081447839736938, 0.7081447839736938, 0.7081447839736938, 0.7070135474205017, 0.7013574838638306, 0.6990950107574463, 0.7024886608123779, 0.6877828240394592, 0.7036198973655701, 0.692307710647583, 0.6990950107574463, 0.7002262473106384]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/31 [==========================>...] - ETA: 0s - loss: 0.5787 - accuracy: 0.7991"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 9s 55ms/step - loss: 0.5797 - accuracy: 0.7997 - val_loss: 0.9146 - val_accuracy: 0.5145\n","Epoch 2/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5751 - accuracy: 0.8008 - val_loss: 0.8703 - val_accuracy: 0.5176\n","Epoch 3/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5652 - accuracy: 0.8054 - val_loss: 0.8578 - val_accuracy: 0.5207\n","Epoch 4/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5813 - accuracy: 0.7951 - val_loss: 0.8317 - val_accuracy: 0.5362\n","Epoch 5/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5603 - accuracy: 0.8121 - val_loss: 0.8517 - val_accuracy: 0.5238\n","Epoch 6/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5577 - accuracy: 0.8121 - val_loss: 0.8404 - val_accuracy: 0.5351\n","Epoch 7/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5534 - accuracy: 0.8093 - val_loss: 0.8295 - val_accuracy: 0.5465\n","Epoch 8/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5565 - accuracy: 0.8096 - val_loss: 0.8131 - val_accuracy: 0.5919\n","Epoch 9/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5486 - accuracy: 0.8155 - val_loss: 0.8119 - val_accuracy: 0.5868\n","Epoch 10/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5444 - accuracy: 0.8168 - val_loss: 0.8135 - val_accuracy: 0.5723\n","Epoch 11/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5463 - accuracy: 0.8181 - val_loss: 0.7898 - val_accuracy: 0.6302\n","Epoch 12/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5467 - accuracy: 0.8147 - val_loss: 0.7849 - val_accuracy: 0.6529\n","Epoch 13/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.5393 - accuracy: 0.8194 - val_loss: 0.7747 - val_accuracy: 0.6705\n","Epoch 14/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5326 - accuracy: 0.8256 - val_loss: 0.7779 - val_accuracy: 0.6653\n","Epoch 15/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5408 - accuracy: 0.8217 - val_loss: 0.7481 - val_accuracy: 0.6818\n","Epoch 16/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5456 - accuracy: 0.8145 - val_loss: 0.7689 - val_accuracy: 0.6725\n","Epoch 17/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5378 - accuracy: 0.8173 - val_loss: 0.7518 - val_accuracy: 0.6860\n","Epoch 18/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5340 - accuracy: 0.8217 - val_loss: 0.7409 - val_accuracy: 0.6622\n","Epoch 19/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5392 - accuracy: 0.8207 - val_loss: 0.7435 - val_accuracy: 0.6849\n","Epoch 20/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5268 - accuracy: 0.8295 - val_loss: 0.7350 - val_accuracy: 0.6973\n","Epoch 21/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5284 - accuracy: 0.8207 - val_loss: 0.7461 - val_accuracy: 0.6736\n","Epoch 22/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5296 - accuracy: 0.8251 - val_loss: 0.7544 - val_accuracy: 0.6808\n","Epoch 23/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5249 - accuracy: 0.8279 - val_loss: 0.7505 - val_accuracy: 0.6880\n","Epoch 24/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.5205 - accuracy: 0.8240 - val_loss: 0.7568 - val_accuracy: 0.7056\n","Epoch 25/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5309 - accuracy: 0.8220 - val_loss: 0.7698 - val_accuracy: 0.7076\n","Epoch 26/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5261 - accuracy: 0.8225 - val_loss: 0.7669 - val_accuracy: 0.7076\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5216 - accuracy: 0.8274 - val_loss: 0.7893 - val_accuracy: 0.6973\n","Epoch 28/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5263 - accuracy: 0.8269 - val_loss: 0.7855 - val_accuracy: 0.6849\n","Epoch 29/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5202 - accuracy: 0.8307 - val_loss: 0.7794 - val_accuracy: 0.7076\n","Epoch 30/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5198 - accuracy: 0.8279 - val_loss: 0.7972 - val_accuracy: 0.6870\n","Epoch 31/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5273 - accuracy: 0.8196 - val_loss: 0.7909 - val_accuracy: 0.6921\n","Epoch 32/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5122 - accuracy: 0.8370 - val_loss: 0.8152 - val_accuracy: 0.6715\n","Epoch 33/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5099 - accuracy: 0.8323 - val_loss: 0.7876 - val_accuracy: 0.6952\n","Epoch 34/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5032 - accuracy: 0.8370 - val_loss: 0.8568 - val_accuracy: 0.6601\n","Epoch 35/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5104 - accuracy: 0.8416 - val_loss: 0.8174 - val_accuracy: 0.6756\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5169 - accuracy: 0.8212 - val_loss: 0.8042 - val_accuracy: 0.6952\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5059 - accuracy: 0.8367 - val_loss: 0.8319 - val_accuracy: 0.6684\n","Epoch 38/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5060 - accuracy: 0.8377 - val_loss: 0.8347 - val_accuracy: 0.6942\n","Epoch 39/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5119 - accuracy: 0.8318 - val_loss: 0.8174 - val_accuracy: 0.6736\n","Epoch 40/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5015 - accuracy: 0.8390 - val_loss: 0.8183 - val_accuracy: 0.6849\n","Epoch 41/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4955 - accuracy: 0.8377 - val_loss: 0.8195 - val_accuracy: 0.6829\n","Epoch 42/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5004 - accuracy: 0.8364 - val_loss: 0.8132 - val_accuracy: 0.6952\n","Epoch 43/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4940 - accuracy: 0.8444 - val_loss: 0.8129 - val_accuracy: 0.6952\n","Epoch 44/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4959 - accuracy: 0.8406 - val_loss: 0.8109 - val_accuracy: 0.6932\n","Epoch 45/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4986 - accuracy: 0.8385 - val_loss: 0.8595 - val_accuracy: 0.6818\n","Epoch 46/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4985 - accuracy: 0.8357 - val_loss: 0.8687 - val_accuracy: 0.6539\n","Epoch 47/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4943 - accuracy: 0.8406 - val_loss: 0.8409 - val_accuracy: 0.6736\n","Epoch 48/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4923 - accuracy: 0.8408 - val_loss: 0.8381 - val_accuracy: 0.6736\n","Epoch 49/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5040 - accuracy: 0.8341 - val_loss: 0.8638 - val_accuracy: 0.6581\n","Epoch 50/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4917 - accuracy: 0.8439 - val_loss: 0.8428 - val_accuracy: 0.6632\n","Epoch 51/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4896 - accuracy: 0.8442 - val_loss: 0.8272 - val_accuracy: 0.6767\n","Epoch 52/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4865 - accuracy: 0.8470 - val_loss: 0.8549 - val_accuracy: 0.6694\n","Epoch 53/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4868 - accuracy: 0.8457 - val_loss: 0.8787 - val_accuracy: 0.6591\n","Epoch 54/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4847 - accuracy: 0.8475 - val_loss: 0.8619 - val_accuracy: 0.6570\n","Epoch 55/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4840 - accuracy: 0.8470 - val_loss: 0.8287 - val_accuracy: 0.6901\n","Epoch 56/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4802 - accuracy: 0.8496 - val_loss: 0.9102 - val_accuracy: 0.6384\n","Epoch 57/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4816 - accuracy: 0.8494 - val_loss: 0.8406 - val_accuracy: 0.6818\n","Epoch 58/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4827 - accuracy: 0.8512 - val_loss: 0.8666 - val_accuracy: 0.6705\n","Epoch 59/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4745 - accuracy: 0.8499 - val_loss: 0.8418 - val_accuracy: 0.6901\n","Epoch 60/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4818 - accuracy: 0.8452 - val_loss: 0.8498 - val_accuracy: 0.6911\n","Epoch 61/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4733 - accuracy: 0.8512 - val_loss: 0.8525 - val_accuracy: 0.6880\n","Epoch 62/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4732 - accuracy: 0.8527 - val_loss: 0.8526 - val_accuracy: 0.6798\n","Epoch 63/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4755 - accuracy: 0.8530 - val_loss: 0.8595 - val_accuracy: 0.6746\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4723 - accuracy: 0.8548 - val_loss: 0.8509 - val_accuracy: 0.6756\n","Epoch 65/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4756 - accuracy: 0.8442 - val_loss: 0.8612 - val_accuracy: 0.6849\n","Epoch 66/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4689 - accuracy: 0.8561 - val_loss: 0.8660 - val_accuracy: 0.6880\n","Epoch 67/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4785 - accuracy: 0.8434 - val_loss: 0.8862 - val_accuracy: 0.6643\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4798 - accuracy: 0.8421 - val_loss: 0.8768 - val_accuracy: 0.6725\n","Epoch 69/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4736 - accuracy: 0.8429 - val_loss: 0.8451 - val_accuracy: 0.6818\n","Epoch 70/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4626 - accuracy: 0.8576 - val_loss: 0.8766 - val_accuracy: 0.6674\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4643 - accuracy: 0.8602 - val_loss: 0.8801 - val_accuracy: 0.6746\n","Epoch 72/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4706 - accuracy: 0.8537 - val_loss: 0.8694 - val_accuracy: 0.6622\n","Epoch 73/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4700 - accuracy: 0.8517 - val_loss: 0.9146 - val_accuracy: 0.6488\n","Epoch 74/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4758 - accuracy: 0.8514 - val_loss: 0.8645 - val_accuracy: 0.6849\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4677 - accuracy: 0.8488 - val_loss: 0.8764 - val_accuracy: 0.6849\n","Epoch 76/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4588 - accuracy: 0.8612 - val_loss: 0.8598 - val_accuracy: 0.6829\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4680 - accuracy: 0.8535 - val_loss: 0.8772 - val_accuracy: 0.6880\n","Epoch 78/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4837 - accuracy: 0.8450 - val_loss: 0.8748 - val_accuracy: 0.6839\n","Epoch 79/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4584 - accuracy: 0.8571 - val_loss: 0.8726 - val_accuracy: 0.6787\n","Epoch 80/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4510 - accuracy: 0.8659 - val_loss: 0.8749 - val_accuracy: 0.6849\n","Epoch 81/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4517 - accuracy: 0.8636 - val_loss: 0.8800 - val_accuracy: 0.6705\n","Epoch 82/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4481 - accuracy: 0.8654 - val_loss: 0.8739 - val_accuracy: 0.6777\n","Epoch 83/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4458 - accuracy: 0.8667 - val_loss: 0.8737 - val_accuracy: 0.6756\n","Epoch 84/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4434 - accuracy: 0.8654 - val_loss: 0.8982 - val_accuracy: 0.6798\n","Epoch 85/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4532 - accuracy: 0.8563 - val_loss: 0.8994 - val_accuracy: 0.6663\n","Epoch 86/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4367 - accuracy: 0.8718 - val_loss: 0.8892 - val_accuracy: 0.6767\n","Epoch 87/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4467 - accuracy: 0.8605 - val_loss: 0.9112 - val_accuracy: 0.6767\n","Epoch 88/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4673 - accuracy: 0.8504 - val_loss: 1.1599 - val_accuracy: 0.5961\n","Epoch 89/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4688 - accuracy: 0.8468 - val_loss: 0.9104 - val_accuracy: 0.6560\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4514 - accuracy: 0.8576 - val_loss: 0.9449 - val_accuracy: 0.6539\n","Epoch 91/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4382 - accuracy: 0.8649 - val_loss: 0.9216 - val_accuracy: 0.6612\n","Epoch 92/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4401 - accuracy: 0.8643 - val_loss: 0.9406 - val_accuracy: 0.6477\n","Epoch 93/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4337 - accuracy: 0.8724 - val_loss: 0.9016 - val_accuracy: 0.6746\n","Epoch 94/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4403 - accuracy: 0.8649 - val_loss: 0.8814 - val_accuracy: 0.6839\n","Epoch 95/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4263 - accuracy: 0.8749 - val_loss: 0.9406 - val_accuracy: 0.6426\n","Epoch 96/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4452 - accuracy: 0.8651 - val_loss: 0.9012 - val_accuracy: 0.6839\n","Epoch 97/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4262 - accuracy: 0.8721 - val_loss: 0.9014 - val_accuracy: 0.6746\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4226 - accuracy: 0.8747 - val_loss: 0.9028 - val_accuracy: 0.6849\n","Epoch 99/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4272 - accuracy: 0.8726 - val_loss: 0.9619 - val_accuracy: 0.6736\n","Epoch 100/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4231 - accuracy: 0.8773 - val_loss: 0.9068 - val_accuracy: 0.6839\n","{'loss': [0.5796815752983093, 0.5750848054885864, 0.5652350783348083, 0.5812500715255737, 0.5602787137031555, 0.5576732754707336, 0.5534272193908691, 0.5564591884613037, 0.5486071705818176, 0.5444106459617615, 0.5462973713874817, 0.546703577041626, 0.5393286347389221, 0.5325589179992676, 0.5408148169517517, 0.5456473231315613, 0.5377551913261414, 0.5339885354042053, 0.5392147302627563, 0.5267695188522339, 0.5284463763237, 0.5295587778091431, 0.5249295830726624, 0.5205333232879639, 0.5309290885925293, 0.5260581970214844, 0.5216254591941833, 0.5263258814811707, 0.5202193260192871, 0.5197550654411316, 0.5272667407989502, 0.5122114419937134, 0.5098508596420288, 0.5032104849815369, 0.5103816390037537, 0.5169346928596497, 0.5059471130371094, 0.505956768989563, 0.5119270086288452, 0.5014835596084595, 0.495454877614975, 0.5003964900970459, 0.49401476979255676, 0.4958884119987488, 0.4986136257648468, 0.4985324740409851, 0.4943135380744934, 0.4923291802406311, 0.5040081143379211, 0.49168121814727783, 0.4896112084388733, 0.4865313470363617, 0.48683348298072815, 0.48471006751060486, 0.48401936888694763, 0.4802139401435852, 0.4815538823604584, 0.482705295085907, 0.4745445251464844, 0.4817749261856079, 0.4733332097530365, 0.47315096855163574, 0.475485622882843, 0.47230276465415955, 0.4756496250629425, 0.4689292907714844, 0.4784756004810333, 0.479808509349823, 0.47357460856437683, 0.4625811278820038, 0.4643042981624603, 0.47056639194488525, 0.46995577216148376, 0.4758385717868805, 0.4676884412765503, 0.4587540626525879, 0.46801847219467163, 0.48372089862823486, 0.45835164189338684, 0.45102572441101074, 0.4516960382461548, 0.44814279675483704, 0.44580110907554626, 0.4434205889701843, 0.45323362946510315, 0.43674421310424805, 0.4466989040374756, 0.46731773018836975, 0.468847393989563, 0.4513549506664276, 0.43819305300712585, 0.4401082992553711, 0.43372559547424316, 0.4402852952480316, 0.42627090215682983, 0.44524481892585754, 0.4261564612388611, 0.42264583706855774, 0.42716196179389954, 0.42307049036026], 'accuracy': [0.7997416257858276, 0.8007751703262329, 0.8054263591766357, 0.7950904369354248, 0.8121446967124939, 0.8121446967124939, 0.8093023300170898, 0.8095607161521912, 0.8155038952827454, 0.8167958855628967, 0.8180878758430481, 0.8147286772727966, 0.8193798661231995, 0.8255813717842102, 0.8217054009437561, 0.8144702911376953, 0.8173126578330994, 0.8217054009437561, 0.8206718564033508, 0.8294573426246643, 0.8206718564033508, 0.8250645995140076, 0.8279069662094116, 0.8240309953689575, 0.8219638466835022, 0.8224806189537048, 0.827390193939209, 0.8268733620643616, 0.8307493329048157, 0.8279069662094116, 0.8196382522583008, 0.8369508981704712, 0.8322997689247131, 0.8369508981704712, 0.841602087020874, 0.8211886286735535, 0.8366925120353699, 0.8377261161804199, 0.8317829370498657, 0.8390181064605713, 0.8377261161804199, 0.8364341259002686, 0.8444444537162781, 0.840568482875824, 0.8385012745857239, 0.8356589078903198, 0.840568482875824, 0.8408268690109253, 0.8341085314750671, 0.8439276218414307, 0.8441860675811768, 0.8470284342765808, 0.8457364439964294, 0.8475452065467834, 0.8470284342765808, 0.8496124148368835, 0.8493540287017822, 0.8511627912521362, 0.8498708009719849, 0.845219612121582, 0.8511627912521362, 0.8527131676673889, 0.8529715538024902, 0.854780375957489, 0.8441860675811768, 0.8560723662376404, 0.843410849571228, 0.8421188592910767, 0.8428940773010254, 0.8576227426528931, 0.8602067232131958, 0.853746771812439, 0.8516795635223389, 0.8514211773872375, 0.8488371968269348, 0.8612403273582458, 0.8534883856773376, 0.8449612259864807, 0.8571059703826904, 0.8658914566040039, 0.8635658621788025, 0.8653746843338013, 0.8666666746139526, 0.8653746843338013, 0.8563307523727417, 0.8718346357345581, 0.8604651093482971, 0.8503875732421875, 0.8467700481414795, 0.8576227426528931, 0.8648578524589539, 0.8643410801887512, 0.8723514080047607, 0.8648578524589539, 0.8749353885650635, 0.8651162981987, 0.8720930218696594, 0.8746770024299622, 0.8726097941398621, 0.8772609829902649], 'val_loss': [0.9145512580871582, 0.8703092336654663, 0.8577731847763062, 0.8317312002182007, 0.8516684174537659, 0.8403725028038025, 0.8294946551322937, 0.813082218170166, 0.811935544013977, 0.8135082125663757, 0.789776086807251, 0.7848801612854004, 0.7747399806976318, 0.777912437915802, 0.7480940818786621, 0.7689438462257385, 0.7518465518951416, 0.7409331202507019, 0.743475615978241, 0.7349511384963989, 0.7461033463478088, 0.7544494271278381, 0.7504961490631104, 0.7568431496620178, 0.769829511642456, 0.7668689489364624, 0.7893276214599609, 0.7855466604232788, 0.7794315218925476, 0.797167956829071, 0.7908708453178406, 0.8152440190315247, 0.7876487374305725, 0.8567651510238647, 0.8173658847808838, 0.8042464256286621, 0.8318758010864258, 0.8347187042236328, 0.8174474239349365, 0.818255603313446, 0.8194859623908997, 0.8132258057594299, 0.8129220604896545, 0.8109337687492371, 0.8594871759414673, 0.8687248826026917, 0.8408741354942322, 0.8381351828575134, 0.8637846112251282, 0.8428347706794739, 0.8271949887275696, 0.8549432754516602, 0.8787221312522888, 0.8619397282600403, 0.8287433385848999, 0.9102371335029602, 0.8406022191047668, 0.8666301965713501, 0.8418412804603577, 0.8498186469078064, 0.8525305986404419, 0.8525813817977905, 0.8595272898674011, 0.8509438037872314, 0.8611840009689331, 0.8660283088684082, 0.8861969113349915, 0.8767536282539368, 0.8451075553894043, 0.8765788674354553, 0.8801349997520447, 0.8694108724594116, 0.9145618081092834, 0.8644896149635315, 0.8763921856880188, 0.8598378896713257, 0.8771622180938721, 0.8747955560684204, 0.8725704550743103, 0.8749056458473206, 0.8800328373908997, 0.873874306678772, 0.8736768364906311, 0.8981822729110718, 0.8994338512420654, 0.8892234563827515, 0.911164402961731, 1.1598621606826782, 0.9104203581809998, 0.9448904991149902, 0.9216412901878357, 0.9406020641326904, 0.901612401008606, 0.8814401626586914, 0.9405857920646667, 0.9012033939361572, 0.9013750553131104, 0.9028254151344299, 0.9619184136390686, 0.9067659974098206], 'val_accuracy': [0.5144628286361694, 0.5175619721412659, 0.5206611752510071, 0.5361570119857788, 0.5237603187561035, 0.5351239442825317, 0.5464876294136047, 0.5919421315193176, 0.586776852607727, 0.5723140239715576, 0.6301652789115906, 0.6528925895690918, 0.6704545617103577, 0.6652892827987671, 0.6818181872367859, 0.672520637512207, 0.6859503984451294, 0.6621900796890259, 0.6849173307418823, 0.6973140239715576, 0.6735537052154541, 0.6807851195335388, 0.6880165338516235, 0.7055785059928894, 0.7076446413993835, 0.7076446413993835, 0.6973140239715576, 0.6849173307418823, 0.7076446413993835, 0.6869834661483765, 0.692148745059967, 0.6714876294136047, 0.6952479481697083, 0.6601239442825317, 0.6756198406219482, 0.6952479481697083, 0.6683884263038635, 0.6942148804664612, 0.6735537052154541, 0.6849173307418823, 0.682851254940033, 0.6952479481697083, 0.6952479481697083, 0.6931818127632141, 0.6818181872367859, 0.6539255976676941, 0.6735537052154541, 0.6735537052154541, 0.6580578684806824, 0.663223147392273, 0.6766529083251953, 0.6694214940071106, 0.6590909361839294, 0.6570248007774353, 0.6900826692581177, 0.6384297609329224, 0.6818181872367859, 0.6704545617103577, 0.6900826692581177, 0.69111567735672, 0.6880165338516235, 0.6797520518302917, 0.6745867729187012, 0.6756198406219482, 0.6849173307418823, 0.6880165338516235, 0.66425621509552, 0.672520637512207, 0.6818181872367859, 0.6673553586006165, 0.6745867729187012, 0.6621900796890259, 0.6487603187561035, 0.6849173307418823, 0.6849173307418823, 0.682851254940033, 0.6880165338516235, 0.68388432264328, 0.6787189841270447, 0.6849173307418823, 0.6704545617103577, 0.6776859760284424, 0.6756198406219482, 0.6797520518302917, 0.6663222908973694, 0.6766529083251953, 0.6766529083251953, 0.5960744023323059, 0.6559917330741882, 0.6539255976676941, 0.6611570119857788, 0.6477272510528564, 0.6745867729187012, 0.68388432264328, 0.6425619721412659, 0.68388432264328, 0.6745867729187012, 0.6849173307418823, 0.6735537052154541, 0.68388432264328]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.4776 - accuracy: 0.8474"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 8s 56ms/step - loss: 0.4795 - accuracy: 0.8456 - val_loss: 0.9814 - val_accuracy: 0.5162\n","Epoch 2/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4795 - accuracy: 0.8473 - val_loss: 0.9086 - val_accuracy: 0.5172\n","Epoch 3/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4648 - accuracy: 0.8583 - val_loss: 0.8914 - val_accuracy: 0.5183\n","Epoch 4/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4605 - accuracy: 0.8578 - val_loss: 0.8113 - val_accuracy: 0.5496\n","Epoch 5/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4573 - accuracy: 0.8540 - val_loss: 0.8135 - val_accuracy: 0.5506\n","Epoch 6/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4520 - accuracy: 0.8580 - val_loss: 0.8394 - val_accuracy: 0.5345\n","Epoch 7/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4610 - accuracy: 0.8545 - val_loss: 0.7820 - val_accuracy: 0.6455\n","Epoch 8/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4463 - accuracy: 0.8596 - val_loss: 0.7980 - val_accuracy: 0.5647\n","Epoch 9/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4390 - accuracy: 0.8704 - val_loss: 0.8100 - val_accuracy: 0.5593\n","Epoch 10/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4566 - accuracy: 0.8578 - val_loss: 0.7744 - val_accuracy: 0.5873\n","Epoch 11/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4652 - accuracy: 0.8499 - val_loss: 0.7544 - val_accuracy: 0.6390\n","Epoch 12/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4355 - accuracy: 0.8688 - val_loss: 0.7452 - val_accuracy: 0.6616\n","Epoch 13/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4445 - accuracy: 0.8626 - val_loss: 0.7745 - val_accuracy: 0.6487\n","Epoch 14/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4419 - accuracy: 0.8685 - val_loss: 0.7590 - val_accuracy: 0.6250\n","Epoch 15/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4305 - accuracy: 0.8712 - val_loss: 0.6886 - val_accuracy: 0.7188\n","Epoch 16/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4341 - accuracy: 0.8710 - val_loss: 0.6824 - val_accuracy: 0.7015\n","Epoch 17/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.4253 - accuracy: 0.8755 - val_loss: 0.6721 - val_accuracy: 0.7414\n","Epoch 18/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4302 - accuracy: 0.8664 - val_loss: 0.6963 - val_accuracy: 0.6810\n","Epoch 19/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4274 - accuracy: 0.8718 - val_loss: 0.6738 - val_accuracy: 0.7015\n","Epoch 20/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4222 - accuracy: 0.8766 - val_loss: 0.6819 - val_accuracy: 0.7188\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4271 - accuracy: 0.8726 - val_loss: 0.6651 - val_accuracy: 0.7188\n","Epoch 22/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4161 - accuracy: 0.8780 - val_loss: 0.6291 - val_accuracy: 0.7597\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4106 - accuracy: 0.8825 - val_loss: 0.6537 - val_accuracy: 0.7489\n","Epoch 24/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4207 - accuracy: 0.8720 - val_loss: 0.6503 - val_accuracy: 0.7662\n","Epoch 25/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4187 - accuracy: 0.8723 - val_loss: 0.6579 - val_accuracy: 0.7640\n","Epoch 26/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4452 - accuracy: 0.8564 - val_loss: 0.8085 - val_accuracy: 0.6875\n","Epoch 27/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4239 - accuracy: 0.8696 - val_loss: 0.7295 - val_accuracy: 0.7306\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4214 - accuracy: 0.8750 - val_loss: 0.6665 - val_accuracy: 0.7640\n","Epoch 29/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4221 - accuracy: 0.8737 - val_loss: 0.6975 - val_accuracy: 0.7619\n","Epoch 30/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4150 - accuracy: 0.8742 - val_loss: 0.6898 - val_accuracy: 0.7543\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4104 - accuracy: 0.8796 - val_loss: 0.7090 - val_accuracy: 0.7457\n","Epoch 32/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4009 - accuracy: 0.8847 - val_loss: 0.7084 - val_accuracy: 0.7532\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4062 - accuracy: 0.8801 - val_loss: 0.7120 - val_accuracy: 0.7425\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4116 - accuracy: 0.8739 - val_loss: 0.6910 - val_accuracy: 0.7586\n","Epoch 35/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4120 - accuracy: 0.8807 - val_loss: 0.6881 - val_accuracy: 0.7726\n","Epoch 36/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4052 - accuracy: 0.8823 - val_loss: 0.6806 - val_accuracy: 0.7651\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3925 - accuracy: 0.8885 - val_loss: 0.6933 - val_accuracy: 0.7608\n","Epoch 38/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3928 - accuracy: 0.8906 - val_loss: 0.7082 - val_accuracy: 0.7597\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3936 - accuracy: 0.8909 - val_loss: 0.6970 - val_accuracy: 0.7575\n","Epoch 40/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3974 - accuracy: 0.8855 - val_loss: 0.7566 - val_accuracy: 0.7435\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3938 - accuracy: 0.8869 - val_loss: 0.7067 - val_accuracy: 0.7575\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3939 - accuracy: 0.8882 - val_loss: 0.6926 - val_accuracy: 0.7608\n","Epoch 43/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3953 - accuracy: 0.8860 - val_loss: 0.7349 - val_accuracy: 0.7554\n","Epoch 44/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3994 - accuracy: 0.8812 - val_loss: 0.7673 - val_accuracy: 0.7349\n","Epoch 45/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3918 - accuracy: 0.8879 - val_loss: 0.7110 - val_accuracy: 0.7586\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4040 - accuracy: 0.8839 - val_loss: 0.7124 - val_accuracy: 0.7565\n","Epoch 47/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3856 - accuracy: 0.8906 - val_loss: 0.7365 - val_accuracy: 0.7478\n","Epoch 48/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3902 - accuracy: 0.8839 - val_loss: 0.7004 - val_accuracy: 0.7543\n","Epoch 49/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3931 - accuracy: 0.8860 - val_loss: 0.7044 - val_accuracy: 0.7651\n","Epoch 50/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3831 - accuracy: 0.8976 - val_loss: 0.7368 - val_accuracy: 0.7381\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3806 - accuracy: 0.8960 - val_loss: 0.7343 - val_accuracy: 0.7457\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3756 - accuracy: 0.8930 - val_loss: 0.8035 - val_accuracy: 0.7101\n","Epoch 53/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3823 - accuracy: 0.8930 - val_loss: 0.7123 - val_accuracy: 0.7554\n","Epoch 54/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3734 - accuracy: 0.8952 - val_loss: 0.7428 - val_accuracy: 0.7522\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3869 - accuracy: 0.8933 - val_loss: 0.7885 - val_accuracy: 0.7392\n","Epoch 56/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3782 - accuracy: 0.8901 - val_loss: 0.7399 - val_accuracy: 0.7500\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3858 - accuracy: 0.8909 - val_loss: 0.7565 - val_accuracy: 0.7349\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3692 - accuracy: 0.9006 - val_loss: 0.7215 - val_accuracy: 0.7500\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3757 - accuracy: 0.8957 - val_loss: 0.7301 - val_accuracy: 0.7586\n","Epoch 60/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3705 - accuracy: 0.8955 - val_loss: 0.7500 - val_accuracy: 0.7511\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3660 - accuracy: 0.9006 - val_loss: 0.7793 - val_accuracy: 0.7425\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3830 - accuracy: 0.8936 - val_loss: 0.7792 - val_accuracy: 0.7392\n","Epoch 63/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3769 - accuracy: 0.8949 - val_loss: 0.8178 - val_accuracy: 0.7198\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3801 - accuracy: 0.8966 - val_loss: 0.7489 - val_accuracy: 0.7532\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3702 - accuracy: 0.8957 - val_loss: 0.7768 - val_accuracy: 0.7360\n","Epoch 66/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3724 - accuracy: 0.8928 - val_loss: 0.8223 - val_accuracy: 0.7101\n","Epoch 67/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3769 - accuracy: 0.8955 - val_loss: 0.8009 - val_accuracy: 0.7403\n","Epoch 68/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3745 - accuracy: 0.8925 - val_loss: 0.7443 - val_accuracy: 0.7522\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3652 - accuracy: 0.9001 - val_loss: 0.7648 - val_accuracy: 0.7425\n","Epoch 70/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3593 - accuracy: 0.9025 - val_loss: 0.8376 - val_accuracy: 0.7101\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3644 - accuracy: 0.8995 - val_loss: 0.7912 - val_accuracy: 0.7435\n","Epoch 72/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3769 - accuracy: 0.8941 - val_loss: 0.7829 - val_accuracy: 0.7478\n","Epoch 73/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3560 - accuracy: 0.9030 - val_loss: 0.8010 - val_accuracy: 0.7284\n","Epoch 74/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3571 - accuracy: 0.9022 - val_loss: 0.7554 - val_accuracy: 0.7446\n","Epoch 75/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3659 - accuracy: 0.8968 - val_loss: 0.8035 - val_accuracy: 0.7414\n","Epoch 76/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3532 - accuracy: 0.9046 - val_loss: 0.7957 - val_accuracy: 0.7392\n","Epoch 77/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3672 - accuracy: 0.8925 - val_loss: 0.7748 - val_accuracy: 0.7489\n","Epoch 78/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3512 - accuracy: 0.9081 - val_loss: 0.7710 - val_accuracy: 0.7511\n","Epoch 79/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3533 - accuracy: 0.9046 - val_loss: 0.7693 - val_accuracy: 0.7489\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3447 - accuracy: 0.9092 - val_loss: 0.7769 - val_accuracy: 0.7457\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3478 - accuracy: 0.9030 - val_loss: 0.7779 - val_accuracy: 0.7392\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3548 - accuracy: 0.9019 - val_loss: 0.8083 - val_accuracy: 0.7317\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3583 - accuracy: 0.9030 - val_loss: 0.8118 - val_accuracy: 0.7338\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3807 - accuracy: 0.8930 - val_loss: 0.7756 - val_accuracy: 0.7532\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3515 - accuracy: 0.9052 - val_loss: 0.7984 - val_accuracy: 0.7220\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3464 - accuracy: 0.9089 - val_loss: 0.8154 - val_accuracy: 0.7274\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3540 - accuracy: 0.8984 - val_loss: 0.7648 - val_accuracy: 0.7500\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3354 - accuracy: 0.9103 - val_loss: 0.8226 - val_accuracy: 0.7241\n","Epoch 89/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3383 - accuracy: 0.9111 - val_loss: 0.7723 - val_accuracy: 0.7586\n","Epoch 90/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3348 - accuracy: 0.9127 - val_loss: 0.7823 - val_accuracy: 0.7478\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3330 - accuracy: 0.9151 - val_loss: 0.8240 - val_accuracy: 0.7263\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3352 - accuracy: 0.9095 - val_loss: 0.8098 - val_accuracy: 0.7403\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3449 - accuracy: 0.9079 - val_loss: 0.8211 - val_accuracy: 0.7425\n","Epoch 94/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3460 - accuracy: 0.9065 - val_loss: 0.7996 - val_accuracy: 0.7500\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3257 - accuracy: 0.9165 - val_loss: 0.8007 - val_accuracy: 0.7403\n","Epoch 96/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3302 - accuracy: 0.9159 - val_loss: 0.7895 - val_accuracy: 0.7457\n","Epoch 97/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3317 - accuracy: 0.9157 - val_loss: 0.8305 - val_accuracy: 0.7403\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3373 - accuracy: 0.9133 - val_loss: 0.8308 - val_accuracy: 0.7468\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3352 - accuracy: 0.9116 - val_loss: 0.8531 - val_accuracy: 0.7241\n","Epoch 100/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3449 - accuracy: 0.9068 - val_loss: 0.8116 - val_accuracy: 0.7522\n","{'loss': [0.4795048236846924, 0.4794989824295044, 0.46479350328445435, 0.46045050024986267, 0.45733097195625305, 0.4519672691822052, 0.4609834849834442, 0.44633275270462036, 0.43898168206214905, 0.4565524458885193, 0.46517857909202576, 0.43552708625793457, 0.44445398449897766, 0.4418773949146271, 0.4305020570755005, 0.43412068486213684, 0.42531782388687134, 0.4302205741405487, 0.42743849754333496, 0.4221845865249634, 0.4270590543746948, 0.4160819947719574, 0.4105890095233917, 0.42070040106773376, 0.4186752438545227, 0.44524991512298584, 0.42390501499176025, 0.4214470088481903, 0.42214900255203247, 0.41498860716819763, 0.4104030132293701, 0.40094369649887085, 0.40619349479675293, 0.41155558824539185, 0.4120188057422638, 0.40515705943107605, 0.39252516627311707, 0.3928232789039612, 0.39355218410491943, 0.3974023461341858, 0.39380723237991333, 0.393912136554718, 0.395271360874176, 0.39937713742256165, 0.3917715847492218, 0.40396612882614136, 0.38556477427482605, 0.3902159035205841, 0.39306798577308655, 0.3831084966659546, 0.380623996257782, 0.37557724118232727, 0.382329523563385, 0.37337034940719604, 0.38691291213035583, 0.37816739082336426, 0.3858177363872528, 0.3692465126514435, 0.3757098615169525, 0.37045133113861084, 0.365979939699173, 0.38301336765289307, 0.37686213850975037, 0.3801402449607849, 0.37021100521087646, 0.3723706305027008, 0.3769172728061676, 0.37454870343208313, 0.3651576638221741, 0.35933876037597656, 0.36441776156425476, 0.37685319781303406, 0.3559838533401489, 0.3570517897605896, 0.3658856451511383, 0.35322338342666626, 0.3672294318675995, 0.35122641921043396, 0.35333889722824097, 0.34471505880355835, 0.34776097536087036, 0.35484230518341064, 0.3582771122455597, 0.38066861033439636, 0.351462185382843, 0.3463878333568573, 0.35398346185684204, 0.3354082405567169, 0.33828768134117126, 0.33477213978767395, 0.3329867422580719, 0.3352412283420563, 0.34494903683662415, 0.34595897793769836, 0.3256787657737732, 0.3301568627357483, 0.33165547251701355, 0.3373003304004669, 0.3351803719997406, 0.34493643045425415], 'accuracy': [0.8456357717514038, 0.8472521305084229, 0.8582974076271057, 0.857758641242981, 0.8539870977401733, 0.858027994632721, 0.8545258641242981, 0.8596444129943848, 0.8704202771186829, 0.857758641242981, 0.849946141242981, 0.868803858757019, 0.8626077771186829, 0.868534505367279, 0.8712284564971924, 0.8709590435028076, 0.8755387663841248, 0.8663793206214905, 0.8717672228813171, 0.876616358757019, 0.8725754022598267, 0.8779633641242981, 0.8825430870056152, 0.8720366358757019, 0.8723060488700867, 0.8564116358757019, 0.8696120977401733, 0.875, 0.873652994632721, 0.8741918206214905, 0.8795797228813171, 0.8846982717514038, 0.8801185488700867, 0.8739224076271057, 0.8806573152542114, 0.8822737336158752, 0.8884698152542114, 0.890625, 0.8908944129943848, 0.8855064511299133, 0.8868534564971924, 0.8882004022598267, 0.8860452771186829, 0.881196141242981, 0.8879310488700867, 0.8838900923728943, 0.890625, 0.8838900923728943, 0.8860452771186829, 0.8976293206214905, 0.8960129022598267, 0.8930495977401733, 0.8930495977401733, 0.8952047228813171, 0.8933189511299133, 0.8900862336158752, 0.8908944129943848, 0.9005926847457886, 0.8957435488700867, 0.8954741358757019, 0.9005926847457886, 0.8935883641242981, 0.8949353694915771, 0.8965517282485962, 0.8957435488700867, 0.8927801847457886, 0.8954741358757019, 0.8925107717514038, 0.900053858757019, 0.9024784564971924, 0.8995150923728943, 0.8941271305084229, 0.9030172228813171, 0.9022090435028076, 0.896821141242981, 0.904633641242981, 0.8925107717514038, 0.9081357717514038, 0.904633641242981, 0.9092133641242981, 0.9030172228813171, 0.9019396305084229, 0.9030172228813171, 0.8930495977401733, 0.9051724076271057, 0.9089439511299133, 0.8984375, 0.9102909564971924, 0.9110991358757019, 0.912715494632721, 0.9151400923728943, 0.9094827771186829, 0.907866358757019, 0.9065194129943848, 0.9164870977401733, 0.9159482717514038, 0.915678858757019, 0.9132543206214905, 0.9116379022598267, 0.9067887663841248], 'val_loss': [0.9813857674598694, 0.9086381793022156, 0.8913525938987732, 0.8113494515419006, 0.8134569525718689, 0.8394390344619751, 0.7819834351539612, 0.7979879975318909, 0.8099708557128906, 0.7743524312973022, 0.7544241547584534, 0.7452144026756287, 0.7745205163955688, 0.7589510083198547, 0.6885865926742554, 0.6823979020118713, 0.672137439250946, 0.6962844729423523, 0.6737769842147827, 0.6818781495094299, 0.6651325225830078, 0.6291192770004272, 0.6537057757377625, 0.6502823233604431, 0.6579073667526245, 0.8084759712219238, 0.7295466065406799, 0.6664554476737976, 0.6975448131561279, 0.689812421798706, 0.7090290784835815, 0.7084115147590637, 0.7120238542556763, 0.6909694671630859, 0.6880891919136047, 0.6806307435035706, 0.6932781934738159, 0.7081691026687622, 0.6969935297966003, 0.7566246390342712, 0.7066604495048523, 0.6925967931747437, 0.7348937392234802, 0.767328679561615, 0.7109679579734802, 0.7124294638633728, 0.7364614605903625, 0.70041424036026, 0.7043653726577759, 0.736807644367218, 0.7343092560768127, 0.8034870624542236, 0.7123286724090576, 0.7428019046783447, 0.7884520292282104, 0.739936888217926, 0.7564575672149658, 0.7214711904525757, 0.7300759553909302, 0.7500247955322266, 0.7792603969573975, 0.7792034149169922, 0.8177852034568787, 0.7489163875579834, 0.7768312692642212, 0.8222941160202026, 0.8009422421455383, 0.7443239688873291, 0.7647681832313538, 0.8375662565231323, 0.7912335991859436, 0.7829011082649231, 0.8009676933288574, 0.7553514242172241, 0.8034761548042297, 0.795706570148468, 0.7748408317565918, 0.771002471446991, 0.7693372368812561, 0.7769455313682556, 0.7778881788253784, 0.8082975149154663, 0.8118085265159607, 0.7755971550941467, 0.7984226942062378, 0.8153713345527649, 0.764840841293335, 0.8225905895233154, 0.7723284363746643, 0.7823233604431152, 0.8240259885787964, 0.8098033666610718, 0.8211473822593689, 0.7995929718017578, 0.8006789684295654, 0.7895395755767822, 0.8304721713066101, 0.8308144807815552, 0.8530735373497009, 0.8115595579147339], 'val_accuracy': [0.5161637663841248, 0.517241358757019, 0.5183189511299133, 0.5495689511299133, 0.5506465435028076, 0.5344827771186829, 0.6454741358757019, 0.5646551847457886, 0.5592672228813171, 0.587284505367279, 0.639008641242981, 0.6616379022598267, 0.6487069129943848, 0.625, 0.71875, 0.701508641242981, 0.7413793206214905, 0.681034505367279, 0.701508641242981, 0.71875, 0.71875, 0.7596982717514038, 0.7489224076271057, 0.7661637663841248, 0.764008641242981, 0.6875, 0.7306034564971924, 0.764008641242981, 0.7618534564971924, 0.7543103694915771, 0.7456896305084229, 0.7532327771186829, 0.7424569129943848, 0.7586206793785095, 0.7726293206214905, 0.7650862336158752, 0.7607758641242981, 0.7596982717514038, 0.7575430870056152, 0.743534505367279, 0.7575430870056152, 0.7607758641242981, 0.7553879022598267, 0.7349137663841248, 0.7586206793785095, 0.756465494632721, 0.7478448152542114, 0.7543103694915771, 0.7650862336158752, 0.7381465435028076, 0.7456896305084229, 0.7101293206214905, 0.7553879022598267, 0.7521551847457886, 0.7392241358757019, 0.75, 0.7349137663841248, 0.75, 0.7586206793785095, 0.7510775923728943, 0.7424569129943848, 0.7392241358757019, 0.7198275923728943, 0.7532327771186829, 0.735991358757019, 0.7101293206214905, 0.7403017282485962, 0.7521551847457886, 0.7424569129943848, 0.7101293206214905, 0.743534505367279, 0.7478448152542114, 0.7284482717514038, 0.7446120977401733, 0.7413793206214905, 0.7392241358757019, 0.7489224076271057, 0.7510775923728943, 0.7489224076271057, 0.7456896305084229, 0.7392241358757019, 0.7316810488700867, 0.7338362336158752, 0.7532327771186829, 0.7219827771186829, 0.7273706793785095, 0.75, 0.7241379022598267, 0.7586206793785095, 0.7478448152542114, 0.7262930870056152, 0.7403017282485962, 0.7424569129943848, 0.75, 0.7403017282485962, 0.7456896305084229, 0.7403017282485962, 0.7467672228813171, 0.7241379022598267, 0.7521551847457886]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 0.4633 - accuracy: 0.8462"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 7s 62ms/step - loss: 0.4635 - accuracy: 0.8466 - val_loss: 0.9425 - val_accuracy: 0.5057\n","Epoch 2/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.4658 - accuracy: 0.8475 - val_loss: 0.8955 - val_accuracy: 0.5068\n","Epoch 3/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.4599 - accuracy: 0.8529 - val_loss: 0.8592 - val_accuracy: 0.5102\n","Epoch 4/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.4497 - accuracy: 0.8554 - val_loss: 0.8505 - val_accuracy: 0.5158\n","Epoch 5/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.4455 - accuracy: 0.8594 - val_loss: 0.8438 - val_accuracy: 0.5249\n","Epoch 6/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4499 - accuracy: 0.8568 - val_loss: 0.9129 - val_accuracy: 0.5102\n","Epoch 7/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4557 - accuracy: 0.8526 - val_loss: 0.8186 - val_accuracy: 0.5962\n","Epoch 8/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4442 - accuracy: 0.8596 - val_loss: 0.8091 - val_accuracy: 0.5520\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4439 - accuracy: 0.8588 - val_loss: 0.8166 - val_accuracy: 0.5882\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4544 - accuracy: 0.8543 - val_loss: 0.7917 - val_accuracy: 0.5724\n","Epoch 11/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4415 - accuracy: 0.8653 - val_loss: 0.7981 - val_accuracy: 0.6097\n","Epoch 12/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.4431 - accuracy: 0.8613 - val_loss: 0.7753 - val_accuracy: 0.6493\n","Epoch 13/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4325 - accuracy: 0.8588 - val_loss: 0.7805 - val_accuracy: 0.5871\n","Epoch 14/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4313 - accuracy: 0.8625 - val_loss: 0.7680 - val_accuracy: 0.6018\n","Epoch 15/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4389 - accuracy: 0.8546 - val_loss: 0.7302 - val_accuracy: 0.6867\n","Epoch 16/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4544 - accuracy: 0.8497 - val_loss: 0.7867 - val_accuracy: 0.6380\n","Epoch 17/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4436 - accuracy: 0.8554 - val_loss: 0.7396 - val_accuracy: 0.6267\n","Epoch 18/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4352 - accuracy: 0.8659 - val_loss: 0.7537 - val_accuracy: 0.6357\n","Epoch 19/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4178 - accuracy: 0.8721 - val_loss: 0.7345 - val_accuracy: 0.6448\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4219 - accuracy: 0.8724 - val_loss: 0.7182 - val_accuracy: 0.6708\n","Epoch 21/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4231 - accuracy: 0.8670 - val_loss: 0.7065 - val_accuracy: 0.6878\n","Epoch 22/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4170 - accuracy: 0.8772 - val_loss: 0.6935 - val_accuracy: 0.7229\n","Epoch 23/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4228 - accuracy: 0.8713 - val_loss: 0.7285 - val_accuracy: 0.6799\n","Epoch 24/100\n","28/28 [==============================] - 1s 43ms/step - loss: 0.4202 - accuracy: 0.8761 - val_loss: 0.6965 - val_accuracy: 0.7443\n","Epoch 25/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4166 - accuracy: 0.8724 - val_loss: 0.7186 - val_accuracy: 0.7025\n","Epoch 26/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4138 - accuracy: 0.8766 - val_loss: 0.8415 - val_accuracy: 0.6425\n","Epoch 27/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.4179 - accuracy: 0.8687 - val_loss: 0.7075 - val_accuracy: 0.7455\n","Epoch 28/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4191 - accuracy: 0.8738 - val_loss: 0.7519 - val_accuracy: 0.7296\n","Epoch 29/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4226 - accuracy: 0.8690 - val_loss: 0.7372 - val_accuracy: 0.7376\n","Epoch 30/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4052 - accuracy: 0.8874 - val_loss: 0.7433 - val_accuracy: 0.7353\n","Epoch 31/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4030 - accuracy: 0.8766 - val_loss: 0.7416 - val_accuracy: 0.7410\n","Epoch 32/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4056 - accuracy: 0.8797 - val_loss: 0.7182 - val_accuracy: 0.7590\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4058 - accuracy: 0.8814 - val_loss: 0.7767 - val_accuracy: 0.7387\n","Epoch 34/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3994 - accuracy: 0.8829 - val_loss: 0.7491 - val_accuracy: 0.7455\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4031 - accuracy: 0.8763 - val_loss: 0.8107 - val_accuracy: 0.7353\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4116 - accuracy: 0.8780 - val_loss: 0.7568 - val_accuracy: 0.7534\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3990 - accuracy: 0.8829 - val_loss: 0.8700 - val_accuracy: 0.6810\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4016 - accuracy: 0.8769 - val_loss: 0.7781 - val_accuracy: 0.7206\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3909 - accuracy: 0.8840 - val_loss: 0.7569 - val_accuracy: 0.7489\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3919 - accuracy: 0.8942 - val_loss: 0.8000 - val_accuracy: 0.7217\n","Epoch 41/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3950 - accuracy: 0.8792 - val_loss: 0.7583 - val_accuracy: 0.7466\n","Epoch 42/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3909 - accuracy: 0.8854 - val_loss: 0.7589 - val_accuracy: 0.7443\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3921 - accuracy: 0.8928 - val_loss: 0.7590 - val_accuracy: 0.7398\n","Epoch 44/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3922 - accuracy: 0.8851 - val_loss: 0.8506 - val_accuracy: 0.6900\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3948 - accuracy: 0.8795 - val_loss: 0.7776 - val_accuracy: 0.7489\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3921 - accuracy: 0.8913 - val_loss: 0.7631 - val_accuracy: 0.7421\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3971 - accuracy: 0.8814 - val_loss: 0.8224 - val_accuracy: 0.7025\n","Epoch 48/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3852 - accuracy: 0.8860 - val_loss: 0.7877 - val_accuracy: 0.7421\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3841 - accuracy: 0.8896 - val_loss: 0.7621 - val_accuracy: 0.7511\n","Epoch 50/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3921 - accuracy: 0.8837 - val_loss: 0.8606 - val_accuracy: 0.6912\n","Epoch 51/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3781 - accuracy: 0.8899 - val_loss: 0.7875 - val_accuracy: 0.7489\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3787 - accuracy: 0.8891 - val_loss: 0.8326 - val_accuracy: 0.7172\n","Epoch 53/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3888 - accuracy: 0.8846 - val_loss: 0.7872 - val_accuracy: 0.7364\n","Epoch 54/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3856 - accuracy: 0.8877 - val_loss: 0.7696 - val_accuracy: 0.7511\n","Epoch 55/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3772 - accuracy: 0.8945 - val_loss: 0.7859 - val_accuracy: 0.7466\n","Epoch 56/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3839 - accuracy: 0.8840 - val_loss: 0.8022 - val_accuracy: 0.7477\n","Epoch 57/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3773 - accuracy: 0.8913 - val_loss: 0.7934 - val_accuracy: 0.7523\n","Epoch 58/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3825 - accuracy: 0.8899 - val_loss: 0.8121 - val_accuracy: 0.7330\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3697 - accuracy: 0.8939 - val_loss: 0.8049 - val_accuracy: 0.7489\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3701 - accuracy: 0.8956 - val_loss: 0.7845 - val_accuracy: 0.7511\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3733 - accuracy: 0.8995 - val_loss: 0.8528 - val_accuracy: 0.7127\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3680 - accuracy: 0.8947 - val_loss: 0.8139 - val_accuracy: 0.7364\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3669 - accuracy: 0.8953 - val_loss: 0.8104 - val_accuracy: 0.7432\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3721 - accuracy: 0.8947 - val_loss: 0.7972 - val_accuracy: 0.7500\n","Epoch 65/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3721 - accuracy: 0.8947 - val_loss: 0.7985 - val_accuracy: 0.7489\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3627 - accuracy: 0.8962 - val_loss: 0.8036 - val_accuracy: 0.7398\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3648 - accuracy: 0.8936 - val_loss: 0.8798 - val_accuracy: 0.7093\n","Epoch 68/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3750 - accuracy: 0.8967 - val_loss: 0.8245 - val_accuracy: 0.7489\n","Epoch 69/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3715 - accuracy: 0.8945 - val_loss: 0.8281 - val_accuracy: 0.7229\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3595 - accuracy: 0.9044 - val_loss: 0.8553 - val_accuracy: 0.7036\n","Epoch 71/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3517 - accuracy: 0.9055 - val_loss: 0.8686 - val_accuracy: 0.7206\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3813 - accuracy: 0.8865 - val_loss: 0.8164 - val_accuracy: 0.7364\n","Epoch 73/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3638 - accuracy: 0.9041 - val_loss: 0.8598 - val_accuracy: 0.7104\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3746 - accuracy: 0.8947 - val_loss: 0.8013 - val_accuracy: 0.7500\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3580 - accuracy: 0.9029 - val_loss: 0.8239 - val_accuracy: 0.7342\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3569 - accuracy: 0.8967 - val_loss: 0.8287 - val_accuracy: 0.7455\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3587 - accuracy: 0.9012 - val_loss: 0.8224 - val_accuracy: 0.7376\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3426 - accuracy: 0.9058 - val_loss: 0.8651 - val_accuracy: 0.7251\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3537 - accuracy: 0.9046 - val_loss: 0.9108 - val_accuracy: 0.6946\n","Epoch 80/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3581 - accuracy: 0.9038 - val_loss: 0.8603 - val_accuracy: 0.7330\n","Epoch 81/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3576 - accuracy: 0.9007 - val_loss: 0.9003 - val_accuracy: 0.7195\n","Epoch 82/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3540 - accuracy: 0.9049 - val_loss: 0.8580 - val_accuracy: 0.7285\n","Epoch 83/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3608 - accuracy: 0.8947 - val_loss: 0.8290 - val_accuracy: 0.7443\n","Epoch 84/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3530 - accuracy: 0.8956 - val_loss: 0.8269 - val_accuracy: 0.7296\n","Epoch 85/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3464 - accuracy: 0.9078 - val_loss: 0.8339 - val_accuracy: 0.7330\n","Epoch 86/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3443 - accuracy: 0.9106 - val_loss: 0.9005 - val_accuracy: 0.6821\n","Epoch 87/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3394 - accuracy: 0.9086 - val_loss: 0.8343 - val_accuracy: 0.7398\n","Epoch 88/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3421 - accuracy: 0.9111 - val_loss: 0.8704 - val_accuracy: 0.7466\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3393 - accuracy: 0.9089 - val_loss: 0.8565 - val_accuracy: 0.7296\n","Epoch 90/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3362 - accuracy: 0.9131 - val_loss: 0.8456 - val_accuracy: 0.7477\n","Epoch 91/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3446 - accuracy: 0.9032 - val_loss: 0.8588 - val_accuracy: 0.7330\n","Epoch 92/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3439 - accuracy: 0.9089 - val_loss: 0.8735 - val_accuracy: 0.7353\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3441 - accuracy: 0.9106 - val_loss: 0.8499 - val_accuracy: 0.7308\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3552 - accuracy: 0.8939 - val_loss: 0.8513 - val_accuracy: 0.7443\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3383 - accuracy: 0.9111 - val_loss: 0.8908 - val_accuracy: 0.7025\n","Epoch 96/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3338 - accuracy: 0.9114 - val_loss: 0.8709 - val_accuracy: 0.7432\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3317 - accuracy: 0.9145 - val_loss: 0.8778 - val_accuracy: 0.7229\n","Epoch 98/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3286 - accuracy: 0.9154 - val_loss: 0.8574 - val_accuracy: 0.7319\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3246 - accuracy: 0.9154 - val_loss: 0.8942 - val_accuracy: 0.7138\n","Epoch 100/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3392 - accuracy: 0.9038 - val_loss: 0.8576 - val_accuracy: 0.7296\n","{'loss': [0.46353283524513245, 0.46576735377311707, 0.4599110186100006, 0.44970446825027466, 0.4455002248287201, 0.44992852210998535, 0.4557369351387024, 0.4441799819469452, 0.4439387321472168, 0.4543808102607727, 0.4415009021759033, 0.44311290979385376, 0.43254587054252625, 0.4312639534473419, 0.4389427602291107, 0.4543980658054352, 0.443575918674469, 0.4351706802845001, 0.4177669882774353, 0.42187434434890747, 0.4230615496635437, 0.4170477092266083, 0.4228004813194275, 0.4201925992965698, 0.4166144132614136, 0.41382285952568054, 0.41794946789741516, 0.41906124353408813, 0.422619104385376, 0.40524327754974365, 0.402968168258667, 0.40562745928764343, 0.40578797459602356, 0.3993631899356842, 0.4030981957912445, 0.4116363525390625, 0.39901065826416016, 0.40161511301994324, 0.3909175395965576, 0.39189139008522034, 0.3950141370296478, 0.3908535838127136, 0.39205774664878845, 0.3921971321105957, 0.3948184847831726, 0.3920920491218567, 0.3970628082752228, 0.38518452644348145, 0.384105920791626, 0.39212265610694885, 0.378096342086792, 0.3787444531917572, 0.3888266682624817, 0.38555586338043213, 0.3772214651107788, 0.3838706612586975, 0.3772912621498108, 0.38250628113746643, 0.3696647882461548, 0.37014874815940857, 0.373298704624176, 0.36799055337905884, 0.36689847707748413, 0.37210533022880554, 0.3721056580543518, 0.3626910448074341, 0.36476829648017883, 0.3750409781932831, 0.3714579641819, 0.35946717858314514, 0.35171398520469666, 0.3813096880912781, 0.36380890011787415, 0.374642938375473, 0.35801181197166443, 0.35693490505218506, 0.3587491512298584, 0.34264102578163147, 0.35370856523513794, 0.3580873906612396, 0.3576413094997406, 0.35403162240982056, 0.36083635687828064, 0.3529692590236664, 0.3463914096355438, 0.3442787230014801, 0.3393549919128418, 0.3421499729156494, 0.3393016755580902, 0.3361546993255615, 0.3446294665336609, 0.3438916802406311, 0.3441081643104553, 0.3552135229110718, 0.33830761909484863, 0.333763062953949, 0.3317153751850128, 0.3286357820034027, 0.3246423602104187, 0.3392060399055481], 'accuracy': [0.846632719039917, 0.8474816083908081, 0.8528579473495483, 0.8554046154022217, 0.8593661785125732, 0.8568194508552551, 0.8525750041007996, 0.859649121761322, 0.8588002324104309, 0.8542727828025818, 0.865308403968811, 0.8613469004631042, 0.8588002324104309, 0.8624787926673889, 0.8545557260513306, 0.8497453331947327, 0.8554046154022217, 0.8658743500709534, 0.8720995783805847, 0.8723825812339783, 0.867006242275238, 0.8771929740905762, 0.8712506890296936, 0.8760611414909363, 0.8723825812339783, 0.8766270279884338, 0.8687040209770203, 0.8737974166870117, 0.868986964225769, 0.8873797655105591, 0.8766270279884338, 0.8797396421432495, 0.8814374804496765, 0.88285231590271, 0.8763440847396851, 0.8780418634414673, 0.88285231590271, 0.8769100308418274, 0.8839841485023499, 0.8941709399223328, 0.879173755645752, 0.8853989839553833, 0.8927561044692993, 0.8851160407066345, 0.8794566988945007, 0.8913412690162659, 0.8814374804496765, 0.8859649300575256, 0.8896434903144836, 0.8837012052536011, 0.8899264335632324, 0.8890775442123413, 0.8845500946044922, 0.8876627087593079, 0.8944538831710815, 0.8839841485023499, 0.8913412690162659, 0.8899264335632324, 0.8938879370689392, 0.8955857157707214, 0.899547278881073, 0.8947368264198303, 0.8953027725219727, 0.8947368264198303, 0.8947368264198303, 0.8961516618728638, 0.8936049938201904, 0.8967176079750061, 0.8944538831710815, 0.9043576717376709, 0.9054895043373108, 0.8865308165550232, 0.9040747284889221, 0.8947368264198303, 0.9029428362846375, 0.8967176079750061, 0.9012450575828552, 0.9057725071907043, 0.9046406149864197, 0.9037917256355286, 0.9006791114807129, 0.9049236178398132, 0.8947368264198303, 0.8955857157707214, 0.9077532291412354, 0.9105829000473022, 0.9086021780967712, 0.9111488461494446, 0.90888512134552, 0.9131296277046204, 0.9032257795333862, 0.90888512134552, 0.9105829000473022, 0.8938879370689392, 0.9111488461494446, 0.9114317893981934, 0.914544403553009, 0.9153932929039001, 0.9153932929039001, 0.9037917256355286], 'val_loss': [0.9424843788146973, 0.8954970836639404, 0.8592345118522644, 0.850530743598938, 0.8438276648521423, 0.9129423499107361, 0.8185599446296692, 0.8090505599975586, 0.8166239261627197, 0.7916906476020813, 0.7981423735618591, 0.7753403186798096, 0.7805207371711731, 0.767978847026825, 0.730158269405365, 0.7866939902305603, 0.7395848035812378, 0.7536526918411255, 0.7344804406166077, 0.7182273864746094, 0.7064527273178101, 0.6935329437255859, 0.7284731864929199, 0.6965205073356628, 0.7185899615287781, 0.8415026068687439, 0.7074639797210693, 0.7518776059150696, 0.7371865510940552, 0.7432898879051208, 0.7416278123855591, 0.7181934118270874, 0.7767467498779297, 0.7490547895431519, 0.8106786608695984, 0.7568186521530151, 0.8700248599052429, 0.7780760526657104, 0.7569125294685364, 0.7999963760375977, 0.7583427429199219, 0.7589325308799744, 0.7589971423149109, 0.8506482839584351, 0.777555525302887, 0.7631046772003174, 0.8223593831062317, 0.7877397537231445, 0.7620960474014282, 0.8605557084083557, 0.7875143885612488, 0.8326188921928406, 0.7871931195259094, 0.7695685625076294, 0.7859129905700684, 0.8021625280380249, 0.7933633327484131, 0.8120525479316711, 0.8049024343490601, 0.7845155000686646, 0.8527916669845581, 0.8138689398765564, 0.8103553056716919, 0.7972329258918762, 0.7984644174575806, 0.8036080598831177, 0.8797858953475952, 0.8245290517807007, 0.8280782103538513, 0.8553487658500671, 0.8686411380767822, 0.8163695335388184, 0.8598060011863708, 0.8012772798538208, 0.8239428400993347, 0.8287222385406494, 0.8224395513534546, 0.8650968670845032, 0.9108307361602783, 0.8603004813194275, 0.900277853012085, 0.8580487370491028, 0.8289940357208252, 0.8269029259681702, 0.8339248299598694, 0.9005491733551025, 0.8343044519424438, 0.8703900575637817, 0.856529951095581, 0.8456242084503174, 0.8587658405303955, 0.8735299706459045, 0.849868655204773, 0.8513318300247192, 0.8908133506774902, 0.8708635568618774, 0.8777692914009094, 0.8574464321136475, 0.8942403197288513, 0.8575975298881531], 'val_accuracy': [0.5056561231613159, 0.5067873597145081, 0.5101810097694397, 0.5158371329307556, 0.5248869061470032, 0.5101810097694397, 0.5961538553237915, 0.5520362257957458, 0.5882353186607361, 0.5723981857299805, 0.6097285151481628, 0.6493212580680847, 0.587104082107544, 0.6018099784851074, 0.6866515874862671, 0.6380090713500977, 0.6266968250274658, 0.6357465982437134, 0.6447963714599609, 0.6708144545555115, 0.6877828240394592, 0.7228506803512573, 0.679864227771759, 0.7443438768386841, 0.7024886608123779, 0.6425339579582214, 0.7454751133918762, 0.7296379804611206, 0.7375565767288208, 0.7352941036224365, 0.7409502267837524, 0.7590497732162476, 0.7386877536773682, 0.7454751133918762, 0.7352941036224365, 0.7533936500549316, 0.6809954643249512, 0.720588207244873, 0.7488687634468079, 0.7217194437980652, 0.7466063499450684, 0.7443438768386841, 0.7398189902305603, 0.6900452375411987, 0.7488687634468079, 0.7420814633369446, 0.7024886608123779, 0.7420814633369446, 0.7511312365531921, 0.6911764740943909, 0.7488687634468079, 0.7171945571899414, 0.7364253401756287, 0.7511312365531921, 0.7466063499450684, 0.7477375268936157, 0.7522624731063843, 0.733031690120697, 0.7488687634468079, 0.7511312365531921, 0.7126696705818176, 0.7364253401756287, 0.7432126402854919, 0.75, 0.7488687634468079, 0.7398189902305603, 0.709276020526886, 0.7488687634468079, 0.7228506803512573, 0.7036198973655701, 0.720588207244873, 0.7364253401756287, 0.7104072570800781, 0.75, 0.7341628670692444, 0.7454751133918762, 0.7375565767288208, 0.7251130938529968, 0.6945701241493225, 0.733031690120697, 0.7194570302963257, 0.7285068035125732, 0.7443438768386841, 0.7296379804611206, 0.733031690120697, 0.6821267008781433, 0.7398189902305603, 0.7466063499450684, 0.7296379804611206, 0.7477375268936157, 0.733031690120697, 0.7352941036224365, 0.7307692170143127, 0.7443438768386841, 0.7024886608123779, 0.7432126402854919, 0.7228506803512573, 0.7319004535675049, 0.7138009071350098, 0.7296379804611206]}\n","45/45 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," lstm (LSTM)                 (None, 3, 256)            1311744   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 3, 256)            525312    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4558401 (17.39 MB)\n","Trainable params: 4557889 (17.39 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.4941 - accuracy: 0.8341"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 8s 56ms/step - loss: 0.4952 - accuracy: 0.8336 - val_loss: 0.9005 - val_accuracy: 0.5155\n","Epoch 2/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4762 - accuracy: 0.8452 - val_loss: 0.8447 - val_accuracy: 0.5186\n","Epoch 3/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4657 - accuracy: 0.8535 - val_loss: 0.8695 - val_accuracy: 0.5186\n","Epoch 4/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4743 - accuracy: 0.8457 - val_loss: 0.8493 - val_accuracy: 0.5248\n","Epoch 5/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4684 - accuracy: 0.8481 - val_loss: 0.8083 - val_accuracy: 0.5558\n","Epoch 6/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4754 - accuracy: 0.8455 - val_loss: 0.8268 - val_accuracy: 0.5403\n","Epoch 7/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.4566 - accuracy: 0.8581 - val_loss: 0.7777 - val_accuracy: 0.6250\n","Epoch 8/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.4648 - accuracy: 0.8504 - val_loss: 0.7823 - val_accuracy: 0.6322\n","Epoch 9/100\n","31/31 [==============================] - 1s 33ms/step - loss: 0.4636 - accuracy: 0.8532 - val_loss: 0.7670 - val_accuracy: 0.6632\n","Epoch 10/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4639 - accuracy: 0.8540 - val_loss: 0.7752 - val_accuracy: 0.6074\n","Epoch 11/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4596 - accuracy: 0.8537 - val_loss: 0.7460 - val_accuracy: 0.6829\n","Epoch 12/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4581 - accuracy: 0.8514 - val_loss: 0.7624 - val_accuracy: 0.6674\n","Epoch 13/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4546 - accuracy: 0.8620 - val_loss: 0.7373 - val_accuracy: 0.6591\n","Epoch 14/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4431 - accuracy: 0.8667 - val_loss: 0.7279 - val_accuracy: 0.6963\n","Epoch 15/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4415 - accuracy: 0.8610 - val_loss: 0.7413 - val_accuracy: 0.6260\n","Epoch 16/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4396 - accuracy: 0.8664 - val_loss: 0.7072 - val_accuracy: 0.6674\n","Epoch 17/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4475 - accuracy: 0.8594 - val_loss: 0.7311 - val_accuracy: 0.6395\n","Epoch 18/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4397 - accuracy: 0.8597 - val_loss: 0.6968 - val_accuracy: 0.6818\n","Epoch 19/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4398 - accuracy: 0.8695 - val_loss: 0.7028 - val_accuracy: 0.6736\n","Epoch 20/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4411 - accuracy: 0.8646 - val_loss: 0.6880 - val_accuracy: 0.7066\n","Epoch 21/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4335 - accuracy: 0.8716 - val_loss: 0.7082 - val_accuracy: 0.7231\n","Epoch 22/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4317 - accuracy: 0.8693 - val_loss: 0.7514 - val_accuracy: 0.6674\n","Epoch 23/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4469 - accuracy: 0.8592 - val_loss: 0.7272 - val_accuracy: 0.7107\n","Epoch 24/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4366 - accuracy: 0.8672 - val_loss: 0.7112 - val_accuracy: 0.7345\n","Epoch 25/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4392 - accuracy: 0.8672 - val_loss: 0.7366 - val_accuracy: 0.7097\n","Epoch 26/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4293 - accuracy: 0.8700 - val_loss: 0.7238 - val_accuracy: 0.7366\n","Epoch 27/100\n","31/31 [==============================] - 1s 30ms/step - loss: 0.4340 - accuracy: 0.8734 - val_loss: 0.7180 - val_accuracy: 0.7397\n","Epoch 28/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4300 - accuracy: 0.8705 - val_loss: 0.7695 - val_accuracy: 0.7076\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4239 - accuracy: 0.8718 - val_loss: 0.7539 - val_accuracy: 0.7283\n","Epoch 30/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4270 - accuracy: 0.8718 - val_loss: 0.7558 - val_accuracy: 0.7242\n","Epoch 31/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4280 - accuracy: 0.8739 - val_loss: 0.8478 - val_accuracy: 0.6694\n","Epoch 32/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4281 - accuracy: 0.8685 - val_loss: 0.7547 - val_accuracy: 0.7366\n","Epoch 33/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4344 - accuracy: 0.8615 - val_loss: 0.8194 - val_accuracy: 0.6983\n","Epoch 34/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4182 - accuracy: 0.8773 - val_loss: 0.7809 - val_accuracy: 0.7376\n","Epoch 35/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4231 - accuracy: 0.8700 - val_loss: 0.8117 - val_accuracy: 0.6983\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4187 - accuracy: 0.8796 - val_loss: 0.8612 - val_accuracy: 0.6715\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4216 - accuracy: 0.8788 - val_loss: 0.9347 - val_accuracy: 0.6477\n","Epoch 38/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4225 - accuracy: 0.8708 - val_loss: 0.8127 - val_accuracy: 0.6983\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4157 - accuracy: 0.8770 - val_loss: 0.7790 - val_accuracy: 0.7304\n","Epoch 40/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4095 - accuracy: 0.8765 - val_loss: 0.8039 - val_accuracy: 0.7200\n","Epoch 41/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4151 - accuracy: 0.8793 - val_loss: 0.7848 - val_accuracy: 0.7355\n","Epoch 42/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4307 - accuracy: 0.8698 - val_loss: 0.7869 - val_accuracy: 0.7200\n","Epoch 43/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4146 - accuracy: 0.8744 - val_loss: 0.7924 - val_accuracy: 0.7262\n","Epoch 44/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4015 - accuracy: 0.8835 - val_loss: 0.7783 - val_accuracy: 0.7231\n","Epoch 45/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4075 - accuracy: 0.8804 - val_loss: 0.8234 - val_accuracy: 0.7035\n","Epoch 46/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4053 - accuracy: 0.8837 - val_loss: 0.7779 - val_accuracy: 0.7262\n","Epoch 47/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4163 - accuracy: 0.8708 - val_loss: 0.7958 - val_accuracy: 0.7242\n","Epoch 48/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4069 - accuracy: 0.8811 - val_loss: 1.0014 - val_accuracy: 0.6364\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3969 - accuracy: 0.8814 - val_loss: 0.8652 - val_accuracy: 0.6829\n","Epoch 50/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4092 - accuracy: 0.8767 - val_loss: 0.9360 - val_accuracy: 0.6539\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4065 - accuracy: 0.8814 - val_loss: 0.8234 - val_accuracy: 0.7045\n","Epoch 52/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4006 - accuracy: 0.8840 - val_loss: 0.8479 - val_accuracy: 0.6932\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3953 - accuracy: 0.8881 - val_loss: 0.9322 - val_accuracy: 0.6663\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4104 - accuracy: 0.8757 - val_loss: 0.8587 - val_accuracy: 0.6942\n","Epoch 55/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3907 - accuracy: 0.8902 - val_loss: 0.8171 - val_accuracy: 0.7273\n","Epoch 56/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3983 - accuracy: 0.8809 - val_loss: 0.8547 - val_accuracy: 0.6983\n","Epoch 57/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3995 - accuracy: 0.8840 - val_loss: 0.8413 - val_accuracy: 0.7231\n","Epoch 58/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3905 - accuracy: 0.8858 - val_loss: 0.8235 - val_accuracy: 0.7242\n","Epoch 59/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4035 - accuracy: 0.8796 - val_loss: 0.8871 - val_accuracy: 0.7190\n","Epoch 60/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3970 - accuracy: 0.8866 - val_loss: 0.9151 - val_accuracy: 0.6777\n","Epoch 61/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3912 - accuracy: 0.8866 - val_loss: 0.8470 - val_accuracy: 0.7097\n","Epoch 62/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3818 - accuracy: 0.8910 - val_loss: 0.8213 - val_accuracy: 0.7211\n","Epoch 63/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4012 - accuracy: 0.8873 - val_loss: 0.8517 - val_accuracy: 0.7211\n","Epoch 64/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3867 - accuracy: 0.8907 - val_loss: 0.9260 - val_accuracy: 0.7035\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3913 - accuracy: 0.8881 - val_loss: 0.8598 - val_accuracy: 0.7190\n","Epoch 66/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3784 - accuracy: 0.8974 - val_loss: 0.8338 - val_accuracy: 0.7211\n","Epoch 67/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3890 - accuracy: 0.8884 - val_loss: 0.9035 - val_accuracy: 0.6818\n","Epoch 68/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3861 - accuracy: 0.8876 - val_loss: 0.8724 - val_accuracy: 0.7097\n","Epoch 69/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3844 - accuracy: 0.8956 - val_loss: 0.8673 - val_accuracy: 0.7014\n","Epoch 70/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3891 - accuracy: 0.8829 - val_loss: 0.9366 - val_accuracy: 0.6653\n","Epoch 71/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3718 - accuracy: 0.8974 - val_loss: 0.8454 - val_accuracy: 0.7221\n","Epoch 72/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3710 - accuracy: 0.8987 - val_loss: 0.8691 - val_accuracy: 0.7200\n","Epoch 73/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3720 - accuracy: 0.8961 - val_loss: 0.9416 - val_accuracy: 0.7097\n","Epoch 74/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3746 - accuracy: 0.8972 - val_loss: 0.8741 - val_accuracy: 0.7097\n","Epoch 75/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3734 - accuracy: 0.8938 - val_loss: 1.0146 - val_accuracy: 0.6570\n","Epoch 76/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3844 - accuracy: 0.8850 - val_loss: 0.8897 - val_accuracy: 0.7118\n","Epoch 77/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3793 - accuracy: 0.8915 - val_loss: 0.9244 - val_accuracy: 0.6798\n","Epoch 78/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3702 - accuracy: 0.8969 - val_loss: 0.8808 - val_accuracy: 0.6994\n","Epoch 79/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3669 - accuracy: 0.9000 - val_loss: 0.8823 - val_accuracy: 0.7035\n","Epoch 80/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3633 - accuracy: 0.8979 - val_loss: 0.8692 - val_accuracy: 0.7149\n","Epoch 81/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3680 - accuracy: 0.8982 - val_loss: 0.9154 - val_accuracy: 0.6808\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3806 - accuracy: 0.8946 - val_loss: 0.9934 - val_accuracy: 0.6570\n","Epoch 83/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3682 - accuracy: 0.8995 - val_loss: 0.9095 - val_accuracy: 0.6880\n","Epoch 84/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3681 - accuracy: 0.8974 - val_loss: 0.9700 - val_accuracy: 0.6612\n","Epoch 85/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3663 - accuracy: 0.8984 - val_loss: 0.8938 - val_accuracy: 0.7138\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3703 - accuracy: 0.8925 - val_loss: 0.9454 - val_accuracy: 0.6746\n","Epoch 87/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3591 - accuracy: 0.9018 - val_loss: 0.9575 - val_accuracy: 0.6684\n","Epoch 88/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3588 - accuracy: 0.9003 - val_loss: 0.9690 - val_accuracy: 0.6663\n","Epoch 89/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3767 - accuracy: 0.8915 - val_loss: 0.9127 - val_accuracy: 0.7087\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3505 - accuracy: 0.9067 - val_loss: 0.9172 - val_accuracy: 0.6994\n","Epoch 91/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3427 - accuracy: 0.9111 - val_loss: 0.9378 - val_accuracy: 0.7231\n","Epoch 92/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3572 - accuracy: 0.8995 - val_loss: 1.0021 - val_accuracy: 0.6550\n","Epoch 93/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3559 - accuracy: 0.9062 - val_loss: 0.9347 - val_accuracy: 0.7169\n","Epoch 94/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3528 - accuracy: 0.9005 - val_loss: 0.9589 - val_accuracy: 0.6983\n","Epoch 95/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3570 - accuracy: 0.9026 - val_loss: 0.9070 - val_accuracy: 0.7087\n","Epoch 96/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3633 - accuracy: 0.8977 - val_loss: 0.9419 - val_accuracy: 0.6767\n","Epoch 97/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3539 - accuracy: 0.9049 - val_loss: 0.9497 - val_accuracy: 0.7128\n","Epoch 98/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3467 - accuracy: 0.9096 - val_loss: 0.9532 - val_accuracy: 0.6983\n","Epoch 99/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3506 - accuracy: 0.9026 - val_loss: 0.9024 - val_accuracy: 0.7159\n","Epoch 100/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3450 - accuracy: 0.9121 - val_loss: 0.9898 - val_accuracy: 0.7107\n","{'loss': [0.4951514005661011, 0.47615954279899597, 0.465653657913208, 0.4743002951145172, 0.4684177339076996, 0.4753839373588562, 0.456609308719635, 0.4647991359233856, 0.4636251926422119, 0.46386289596557617, 0.4596233665943146, 0.45813506841659546, 0.45464757084846497, 0.44305419921875, 0.441482275724411, 0.43960848450660706, 0.447480171918869, 0.4396694302558899, 0.4398458003997803, 0.44112056493759155, 0.43349453806877136, 0.4316972494125366, 0.4469220042228699, 0.43657153844833374, 0.4391511082649231, 0.4293025732040405, 0.43401968479156494, 0.430026113986969, 0.42389801144599915, 0.4270170032978058, 0.4279562830924988, 0.4281226694583893, 0.43443289399147034, 0.41818729043006897, 0.42310890555381775, 0.41866379976272583, 0.4215520918369293, 0.42254331707954407, 0.4156505763530731, 0.4094702899456024, 0.4151216149330139, 0.43074268102645874, 0.4145646095275879, 0.40148675441741943, 0.40748801827430725, 0.40534690022468567, 0.4162963628768921, 0.406854510307312, 0.3968926966190338, 0.4092015326023102, 0.40652936697006226, 0.4006098508834839, 0.3952663838863373, 0.4103817939758301, 0.3906737267971039, 0.3983251452445984, 0.39948374032974243, 0.3905038833618164, 0.4035446047782898, 0.3969677984714508, 0.3911513090133667, 0.3818480670452118, 0.4012340009212494, 0.3866807520389557, 0.39132779836654663, 0.3784055709838867, 0.3890073597431183, 0.38614580035209656, 0.3843582272529602, 0.3890557289123535, 0.37182480096817017, 0.37104037404060364, 0.3719888925552368, 0.3746495544910431, 0.3734428286552429, 0.3843565285205841, 0.3793184161186218, 0.37018534541130066, 0.36686772108078003, 0.3632933497428894, 0.36803382635116577, 0.38063058257102966, 0.3682459890842438, 0.3681386113166809, 0.36627253890037537, 0.37032803893089294, 0.3591189980506897, 0.3587881028652191, 0.3766564130783081, 0.3505452573299408, 0.34267693758010864, 0.35718515515327454, 0.35592296719551086, 0.35277605056762695, 0.3569900095462799, 0.36327606439590454, 0.35387372970581055, 0.34669947624206543, 0.3505876958370209, 0.34502044320106506], 'accuracy': [0.8335917592048645, 0.845219612121582, 0.8534883856773376, 0.8457364439964294, 0.8480620384216309, 0.8454780578613281, 0.8581395149230957, 0.8503875732421875, 0.8532299995422363, 0.8540051579475403, 0.853746771812439, 0.8514211773872375, 0.8620154857635498, 0.8666666746139526, 0.8609819412231445, 0.8664082884788513, 0.8594315052032471, 0.8596899509429932, 0.8695090413093567, 0.8645994663238525, 0.8715762495994568, 0.8692506551742554, 0.8591731190681458, 0.8671834468841553, 0.8671834468841553, 0.8700258135795593, 0.8733850121498108, 0.8705426454544067, 0.8718346357345581, 0.8718346357345581, 0.8739017844200134, 0.8684754371643066, 0.8614987134933472, 0.8772609829902649, 0.8700258135795593, 0.8795865774154663, 0.8788113594055176, 0.8708010315895081, 0.8770025968551636, 0.8764857649803162, 0.879328191280365, 0.869767427444458, 0.8744186162948608, 0.8834625482559204, 0.8803617358207703, 0.8837209343910217, 0.8708010315895081, 0.881136953830719, 0.8813953399658203, 0.8767442107200623, 0.8813953399658203, 0.883979320526123, 0.8881136775016785, 0.8757106065750122, 0.8901808857917786, 0.8808785676956177, 0.883979320526123, 0.8857881426811218, 0.8795865774154663, 0.8865633010864258, 0.8865633010864258, 0.8909560441970825, 0.8873385190963745, 0.8906976580619812, 0.8881136775016785, 0.8974159955978394, 0.8883720636367798, 0.8875969052314758, 0.8956072330474854, 0.882945716381073, 0.8974159955978394, 0.8987079858779907, 0.896124005317688, 0.897157609462738, 0.8937984704971313, 0.8850129246711731, 0.8914728760719299, 0.8968992233276367, 0.8999999761581421, 0.8979328274726868, 0.8981912136077881, 0.8945736289024353, 0.8994832038879395, 0.8974159955978394, 0.8984495997428894, 0.89250648021698, 0.9018087983131409, 0.9002584218978882, 0.8914728760719299, 0.906718373298645, 0.9111111164093018, 0.8994832038879395, 0.9062015414237976, 0.9005168080329895, 0.9025839567184448, 0.8976744413375854, 0.9049095511436462, 0.9095607399940491, 0.9025839567184448, 0.9121447205543518], 'val_loss': [0.9005222320556641, 0.8446894288063049, 0.8694503307342529, 0.8492780327796936, 0.8083449602127075, 0.8268109560012817, 0.7776520848274231, 0.7822759747505188, 0.7669857144355774, 0.7751819491386414, 0.7460011839866638, 0.7623757719993591, 0.7372871041297913, 0.7278863191604614, 0.741258978843689, 0.7071937918663025, 0.7311153411865234, 0.6967521905899048, 0.7028461694717407, 0.6880337595939636, 0.7081877589225769, 0.7513808012008667, 0.7272098064422607, 0.7112390995025635, 0.7365676164627075, 0.7237916588783264, 0.7180185914039612, 0.7694520354270935, 0.7539499402046204, 0.7558378577232361, 0.8477718830108643, 0.7547374963760376, 0.819392740726471, 0.7808901071548462, 0.811724066734314, 0.8612067103385925, 0.9347395300865173, 0.8127347826957703, 0.7790222764015198, 0.8039277195930481, 0.7848210334777832, 0.7869396209716797, 0.7924246191978455, 0.7782515287399292, 0.8233940005302429, 0.7778666615486145, 0.7957876920700073, 1.001444935798645, 0.8652042746543884, 0.9359802007675171, 0.8234267830848694, 0.847854733467102, 0.9321560263633728, 0.8586937785148621, 0.8171245455741882, 0.8546679019927979, 0.8412830233573914, 0.8235052824020386, 0.8871499300003052, 0.9150885939598083, 0.8469938635826111, 0.8213164210319519, 0.8517176508903503, 0.92596435546875, 0.8597739934921265, 0.8337917923927307, 0.9035474061965942, 0.8724269866943359, 0.867337167263031, 0.9366120100021362, 0.8454090356826782, 0.8691202998161316, 0.9416184425354004, 0.8741027116775513, 1.014574646949768, 0.8897183537483215, 0.924370288848877, 0.880833089351654, 0.8823429346084595, 0.869156002998352, 0.9154066443443298, 0.9934159517288208, 0.9095121622085571, 0.9700225591659546, 0.893789529800415, 0.9454348087310791, 0.9575031995773315, 0.9690296053886414, 0.9127272367477417, 0.9171603918075562, 0.937758207321167, 1.0021309852600098, 0.9346545338630676, 0.9588510990142822, 0.906973123550415, 0.9419111609458923, 0.9496820569038391, 0.9532374739646912, 0.9024229049682617, 0.9898467063903809], 'val_accuracy': [0.5154958963394165, 0.5185950398445129, 0.5185950398445129, 0.5247933864593506, 0.5557851195335388, 0.5402892827987671, 0.625, 0.6322314143180847, 0.663223147392273, 0.6074380278587341, 0.682851254940033, 0.6673553586006165, 0.6590909361839294, 0.6962810158729553, 0.6260330677032471, 0.6673553586006165, 0.6394628286361694, 0.6818181872367859, 0.6735537052154541, 0.7066115736961365, 0.7231404781341553, 0.6673553586006165, 0.71074378490448, 0.7345041036605835, 0.7097107172012329, 0.7365702390670776, 0.7396694421768188, 0.7076446413993835, 0.7283057570457458, 0.7241735458374023, 0.6694214940071106, 0.7365702390670776, 0.6983470916748047, 0.7376033067703247, 0.6983470916748047, 0.6714876294136047, 0.6477272510528564, 0.6983470916748047, 0.73037189245224, 0.7200413346290588, 0.7355371713638306, 0.7200413346290588, 0.7262396812438965, 0.7231404781341553, 0.7035123705863953, 0.7262396812438965, 0.7241735458374023, 0.6363636255264282, 0.682851254940033, 0.6539255976676941, 0.7045454382896423, 0.6931818127632141, 0.6663222908973694, 0.6942148804664612, 0.7272727489471436, 0.6983470916748047, 0.7231404781341553, 0.7241735458374023, 0.7190082669258118, 0.6776859760284424, 0.7097107172012329, 0.7210744023323059, 0.7210744023323059, 0.7035123705863953, 0.7190082669258118, 0.7210744023323059, 0.6818181872367859, 0.7097107172012329, 0.7014462947845459, 0.6652892827987671, 0.7221074104309082, 0.7200413346290588, 0.7097107172012329, 0.7097107172012329, 0.6570248007774353, 0.711776852607727, 0.6797520518302917, 0.6993801593780518, 0.7035123705863953, 0.7148760557174683, 0.6807851195335388, 0.6570248007774353, 0.6880165338516235, 0.6611570119857788, 0.7138429880142212, 0.6745867729187012, 0.6683884263038635, 0.6663222908973694, 0.7086777091026306, 0.6993801593780518, 0.7231404781341553, 0.6549586653709412, 0.7169421315193176, 0.6983470916748047, 0.7086777091026306, 0.6766529083251953, 0.7128099203109741, 0.6983470916748047, 0.7159090638160706, 0.71074378490448]}\n","32/32 [==============================] - 1s 5ms/step\n"]}],"source":["global_model, metrics_df = federated_learning(Theta_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1716904751041,"user":{"displayName":"Fazla Rabby Raihan","userId":"02045780865667266745"},"user_tz":-360},"id":"Ik5JoVP2NPvY","outputId":"0bf1e790-c69d-4369-e17f-e2ad32c55ad0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.617      0.634   0.554  0.592        0.554        0.680   \n","1        1     0.626      0.674   0.490  0.567        0.490        0.763   \n","2        2     0.642      0.634   0.671  0.652        0.671        0.612   \n","3        0     0.638      0.647   0.608  0.627        0.608        0.668   \n","4        1     0.654      0.688   0.564  0.620        0.564        0.744   \n","5        2     0.651      0.667   0.602  0.633        0.602        0.699   \n","6        0     0.665      0.668   0.655  0.662        0.655        0.675   \n","7        1     0.699      0.725   0.641  0.681        0.641        0.757   \n","8        2     0.673      0.692   0.622  0.655        0.622        0.723   \n","9        0     0.700      0.728   0.638  0.680        0.638        0.762   \n","10       1     0.736      0.773   0.668  0.717        0.668        0.804   \n","11       2     0.723      0.758   0.655  0.703        0.655        0.791   \n","12       0     0.719      0.757   0.647  0.697        0.647        0.792   \n","13       1     0.755      0.785   0.702  0.741        0.702        0.808   \n","14       2     0.731      0.733   0.727  0.730        0.727        0.735   \n","\n","    Kappa  \n","0   0.235  \n","1   0.253  \n","2   0.283  \n","3   0.276  \n","4   0.308  \n","5   0.301  \n","6   0.330  \n","7   0.398  \n","8   0.345  \n","9   0.400  \n","10  0.472  \n","11  0.446  \n","12  0.439  \n","13  0.510  \n","14  0.462  "],"text/html":["\n","  <div id=\"df-263b49ee-6b2c-41d0-b4de-ab9358b1436f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.617</td>\n","      <td>0.634</td>\n","      <td>0.554</td>\n","      <td>0.592</td>\n","      <td>0.554</td>\n","      <td>0.680</td>\n","      <td>0.235</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.626</td>\n","      <td>0.674</td>\n","      <td>0.490</td>\n","      <td>0.567</td>\n","      <td>0.490</td>\n","      <td>0.763</td>\n","      <td>0.253</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.642</td>\n","      <td>0.634</td>\n","      <td>0.671</td>\n","      <td>0.652</td>\n","      <td>0.671</td>\n","      <td>0.612</td>\n","      <td>0.283</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.638</td>\n","      <td>0.647</td>\n","      <td>0.608</td>\n","      <td>0.627</td>\n","      <td>0.608</td>\n","      <td>0.668</td>\n","      <td>0.276</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.654</td>\n","      <td>0.688</td>\n","      <td>0.564</td>\n","      <td>0.620</td>\n","      <td>0.564</td>\n","      <td>0.744</td>\n","      <td>0.308</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.651</td>\n","      <td>0.667</td>\n","      <td>0.602</td>\n","      <td>0.633</td>\n","      <td>0.602</td>\n","      <td>0.699</td>\n","      <td>0.301</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.665</td>\n","      <td>0.668</td>\n","      <td>0.655</td>\n","      <td>0.662</td>\n","      <td>0.655</td>\n","      <td>0.675</td>\n","      <td>0.330</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.699</td>\n","      <td>0.725</td>\n","      <td>0.641</td>\n","      <td>0.681</td>\n","      <td>0.641</td>\n","      <td>0.757</td>\n","      <td>0.398</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.673</td>\n","      <td>0.692</td>\n","      <td>0.622</td>\n","      <td>0.655</td>\n","      <td>0.622</td>\n","      <td>0.723</td>\n","      <td>0.345</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.700</td>\n","      <td>0.728</td>\n","      <td>0.638</td>\n","      <td>0.680</td>\n","      <td>0.638</td>\n","      <td>0.762</td>\n","      <td>0.400</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.736</td>\n","      <td>0.773</td>\n","      <td>0.668</td>\n","      <td>0.717</td>\n","      <td>0.668</td>\n","      <td>0.804</td>\n","      <td>0.472</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.723</td>\n","      <td>0.758</td>\n","      <td>0.655</td>\n","      <td>0.703</td>\n","      <td>0.655</td>\n","      <td>0.791</td>\n","      <td>0.446</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.719</td>\n","      <td>0.757</td>\n","      <td>0.647</td>\n","      <td>0.697</td>\n","      <td>0.647</td>\n","      <td>0.792</td>\n","      <td>0.439</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.755</td>\n","      <td>0.785</td>\n","      <td>0.702</td>\n","      <td>0.741</td>\n","      <td>0.702</td>\n","      <td>0.808</td>\n","      <td>0.510</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.731</td>\n","      <td>0.733</td>\n","      <td>0.727</td>\n","      <td>0.730</td>\n","      <td>0.727</td>\n","      <td>0.735</td>\n","      <td>0.462</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-263b49ee-6b2c-41d0-b4de-ab9358b1436f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-263b49ee-6b2c-41d0-b4de-ab9358b1436f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-263b49ee-6b2c-41d0-b4de-ab9358b1436f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5996739d-4b91-487e-ba1f-8d51570fa9f1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5996739d-4b91-487e-ba1f-8d51570fa9f1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5996739d-4b91-487e-ba1f-8d51570fa9f1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.044175731324962095,\n        \"min\": 0.617,\n        \"max\": 0.755,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7,\n          0.723,\n          0.617\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05065175219081764,\n        \"min\": 0.634,\n        \"max\": 0.785,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.773,\n          0.757,\n          0.634\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06006163500938015,\n        \"min\": 0.49,\n        \"max\": 0.727,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.638,\n          0.647,\n          0.554\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05023971110017027,\n        \"min\": 0.567,\n        \"max\": 0.741,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.68,\n          0.703,\n          0.592\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06006163500938015,\n        \"min\": 0.49,\n        \"max\": 0.727,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.638,\n          0.647,\n          0.554\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.057462037157463494,\n        \"min\": 0.612,\n        \"max\": 0.808,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.762,\n          0.791,\n          0.68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08834742026039395,\n        \"min\": 0.235,\n        \"max\": 0.51,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.4,\n          0.446,\n          0.235\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":13}],"source":["\n","metrics_df.round(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ncf_cMAQF6g4"},"outputs":[],"source":["metrics_df.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/TF Domain/CNN_LSTM/Theta_tf_CNN_LSTM.csv', index = False)"]},{"cell_type":"markdown","source":["# CNN"],"metadata":{"id":"QUuWzfMHSNmi"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    # model.add(Dropout(0.5))\n","    # model.add(LSTM(256, return_sequences=True))\n","    # model.add(LSTM(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time+Frequency/Theta/CNN/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time+Frequency/Theta/CNN/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n"],"metadata":{"id":"8xrx_fxBSWGd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717505603184,"user_tz":-360,"elapsed":635,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"outputId":"8fc32c8a-4eb4-4e84-898a-d0de9a898f85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["global_model_CNN, metrics_df_CNN = federated_learning(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1TaNdIbSfkq","outputId":"dc1600b6-ac4e-407d-84db-9d38e5275edc","executionInfo":{"status":"ok","timestamp":1717506679543,"user_tz":-360,"elapsed":1076361,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4640, 37, 29), Test shape: (1194, 37, 29)\n","Train shape: (4418, 37, 29), Test shape: (1416, 37, 29)\n","Train shape: (4838, 37, 29), Test shape: (996, 37, 29)\n","Train shape: (4640, 37, 29), Test shape: (1194, 37, 29)\n","Train shape: (4418, 37, 29), Test shape: (1416, 37, 29)\n","Train shape: (4838, 37, 29), Test shape: (996, 37, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 1.9596 - accuracy: 0.5159"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/29 [==============================] - 19s 97ms/step - loss: 1.9596 - accuracy: 0.5159 - val_loss: 1.9531 - val_accuracy: 0.5506\n","Epoch 2/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.9380 - accuracy: 0.5245 - val_loss: 1.9351 - val_accuracy: 0.5345\n","Epoch 3/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.9184 - accuracy: 0.5423 - val_loss: 1.9173 - val_accuracy: 0.5690\n","Epoch 4/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.8997 - accuracy: 0.5673 - val_loss: 1.8998 - val_accuracy: 0.5647\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.8814 - accuracy: 0.5676 - val_loss: 1.8825 - val_accuracy: 0.5571\n","Epoch 6/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.8632 - accuracy: 0.5749 - val_loss: 1.8656 - val_accuracy: 0.5528\n","Epoch 7/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.8453 - accuracy: 0.5808 - val_loss: 1.8487 - val_accuracy: 0.5528\n","Epoch 8/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.8275 - accuracy: 0.5830 - val_loss: 1.8323 - val_accuracy: 0.5506\n","Epoch 9/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.8100 - accuracy: 0.5876 - val_loss: 1.8160 - val_accuracy: 0.5485\n","Epoch 10/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.7927 - accuracy: 0.5884 - val_loss: 1.7997 - val_accuracy: 0.5582\n","Epoch 11/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.7755 - accuracy: 0.5886 - val_loss: 1.7841 - val_accuracy: 0.5603\n","Epoch 12/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.7589 - accuracy: 0.6010 - val_loss: 1.7682 - val_accuracy: 0.5625\n","Epoch 13/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.7417 - accuracy: 0.6010 - val_loss: 1.7526 - val_accuracy: 0.5625\n","Epoch 14/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.7250 - accuracy: 0.6034 - val_loss: 1.7375 - val_accuracy: 0.5614\n","Epoch 15/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.7085 - accuracy: 0.6072 - val_loss: 1.7205 - val_accuracy: 0.5851\n","Epoch 16/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.6929 - accuracy: 0.6118 - val_loss: 1.7058 - val_accuracy: 0.5787\n","Epoch 17/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.6766 - accuracy: 0.6129 - val_loss: 1.6910 - val_accuracy: 0.5776\n","Epoch 18/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.6615 - accuracy: 0.6202 - val_loss: 1.6751 - val_accuracy: 0.5744\n","Epoch 19/100\n","29/29 [==============================] - 1s 24ms/step - loss: 1.6460 - accuracy: 0.6148 - val_loss: 1.6599 - val_accuracy: 0.5690\n","Epoch 20/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.6317 - accuracy: 0.6121 - val_loss: 1.6473 - val_accuracy: 0.5711\n","Epoch 21/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.6167 - accuracy: 0.6145 - val_loss: 1.6317 - val_accuracy: 0.5733\n","Epoch 22/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.6024 - accuracy: 0.6220 - val_loss: 1.6175 - val_accuracy: 0.5819\n","Epoch 23/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.5885 - accuracy: 0.6202 - val_loss: 1.6040 - val_accuracy: 0.5841\n","Epoch 24/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.5753 - accuracy: 0.6234 - val_loss: 1.5910 - val_accuracy: 0.5905\n","Epoch 25/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.5626 - accuracy: 0.6234 - val_loss: 1.5789 - val_accuracy: 0.5894\n","Epoch 26/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.5495 - accuracy: 0.6253 - val_loss: 1.5677 - val_accuracy: 0.5905\n","Epoch 27/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5372 - accuracy: 0.6250 - val_loss: 1.5549 - val_accuracy: 0.5862\n","Epoch 28/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.5238 - accuracy: 0.6288 - val_loss: 1.5456 - val_accuracy: 0.5905\n","Epoch 29/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.5138 - accuracy: 0.6247 - val_loss: 1.5328 - val_accuracy: 0.5981\n","Epoch 30/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.5016 - accuracy: 0.6350 - val_loss: 1.5219 - val_accuracy: 0.5884\n","Epoch 31/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.4894 - accuracy: 0.6352 - val_loss: 1.5109 - val_accuracy: 0.5959\n","Epoch 32/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4775 - accuracy: 0.6328 - val_loss: 1.5009 - val_accuracy: 0.5938\n","Epoch 33/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4666 - accuracy: 0.6352 - val_loss: 1.4906 - val_accuracy: 0.5927\n","Epoch 34/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4558 - accuracy: 0.6398 - val_loss: 1.4828 - val_accuracy: 0.5938\n","Epoch 35/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4440 - accuracy: 0.6414 - val_loss: 1.4740 - val_accuracy: 0.5927\n","Epoch 36/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.4338 - accuracy: 0.6420 - val_loss: 1.4653 - val_accuracy: 0.5970\n","Epoch 37/100\n","29/29 [==============================] - 1s 32ms/step - loss: 1.4240 - accuracy: 0.6436 - val_loss: 1.4563 - val_accuracy: 0.6002\n","Epoch 38/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.4107 - accuracy: 0.6436 - val_loss: 1.4422 - val_accuracy: 0.5991\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.4030 - accuracy: 0.6479 - val_loss: 1.4337 - val_accuracy: 0.5991\n","Epoch 40/100\n","29/29 [==============================] - 1s 43ms/step - loss: 1.3908 - accuracy: 0.6468 - val_loss: 1.4255 - val_accuracy: 0.6034\n","Epoch 41/100\n","29/29 [==============================] - 1s 46ms/step - loss: 1.3805 - accuracy: 0.6560 - val_loss: 1.4168 - val_accuracy: 0.6045\n","Epoch 42/100\n","29/29 [==============================] - 1s 40ms/step - loss: 1.3700 - accuracy: 0.6490 - val_loss: 1.4093 - val_accuracy: 0.6078\n","Epoch 43/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.3611 - accuracy: 0.6554 - val_loss: 1.4023 - val_accuracy: 0.6056\n","Epoch 44/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.3506 - accuracy: 0.6530 - val_loss: 1.3910 - val_accuracy: 0.6078\n","Epoch 45/100\n","29/29 [==============================] - 1s 40ms/step - loss: 1.3408 - accuracy: 0.6581 - val_loss: 1.3859 - val_accuracy: 0.6088\n","Epoch 46/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.3317 - accuracy: 0.6584 - val_loss: 1.3746 - val_accuracy: 0.6088\n","Epoch 47/100\n","29/29 [==============================] - 1s 34ms/step - loss: 1.3211 - accuracy: 0.6624 - val_loss: 1.3664 - val_accuracy: 0.6142\n","Epoch 48/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.3117 - accuracy: 0.6643 - val_loss: 1.3607 - val_accuracy: 0.6045\n","Epoch 49/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.3017 - accuracy: 0.6681 - val_loss: 1.3525 - val_accuracy: 0.6121\n","Epoch 50/100\n","29/29 [==============================] - 1s 31ms/step - loss: 1.2933 - accuracy: 0.6657 - val_loss: 1.3435 - val_accuracy: 0.6196\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.2870 - accuracy: 0.6641 - val_loss: 1.3406 - val_accuracy: 0.6131\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2752 - accuracy: 0.6700 - val_loss: 1.3313 - val_accuracy: 0.6164\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2649 - accuracy: 0.6773 - val_loss: 1.3272 - val_accuracy: 0.6142\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.2558 - accuracy: 0.6746 - val_loss: 1.3191 - val_accuracy: 0.6175\n","Epoch 55/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2467 - accuracy: 0.6821 - val_loss: 1.3092 - val_accuracy: 0.6228\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2382 - accuracy: 0.6778 - val_loss: 1.3022 - val_accuracy: 0.6250\n","Epoch 57/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2293 - accuracy: 0.6808 - val_loss: 1.2998 - val_accuracy: 0.6131\n","Epoch 58/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2212 - accuracy: 0.6794 - val_loss: 1.2905 - val_accuracy: 0.6228\n","Epoch 59/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.2121 - accuracy: 0.6824 - val_loss: 1.2835 - val_accuracy: 0.6196\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.2016 - accuracy: 0.6883 - val_loss: 1.2780 - val_accuracy: 0.6218\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1934 - accuracy: 0.6880 - val_loss: 1.2724 - val_accuracy: 0.6218\n","Epoch 62/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1847 - accuracy: 0.6926 - val_loss: 1.2675 - val_accuracy: 0.6164\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1772 - accuracy: 0.6942 - val_loss: 1.2603 - val_accuracy: 0.6207\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1682 - accuracy: 0.6964 - val_loss: 1.2629 - val_accuracy: 0.6185\n","Epoch 65/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.1614 - accuracy: 0.6959 - val_loss: 1.2561 - val_accuracy: 0.6164\n","Epoch 66/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.1500 - accuracy: 0.7058 - val_loss: 1.2469 - val_accuracy: 0.6131\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.1427 - accuracy: 0.7107 - val_loss: 1.2420 - val_accuracy: 0.6228\n","Epoch 68/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1345 - accuracy: 0.7066 - val_loss: 1.2384 - val_accuracy: 0.6207\n","Epoch 69/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1273 - accuracy: 0.7042 - val_loss: 1.2340 - val_accuracy: 0.6164\n","Epoch 70/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1196 - accuracy: 0.7066 - val_loss: 1.2315 - val_accuracy: 0.6196\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1120 - accuracy: 0.7126 - val_loss: 1.2253 - val_accuracy: 0.6153\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1023 - accuracy: 0.7174 - val_loss: 1.2232 - val_accuracy: 0.6196\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0955 - accuracy: 0.7196 - val_loss: 1.2194 - val_accuracy: 0.6142\n","Epoch 74/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.0873 - accuracy: 0.7212 - val_loss: 1.2148 - val_accuracy: 0.6175\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0795 - accuracy: 0.7209 - val_loss: 1.2112 - val_accuracy: 0.6185\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.0717 - accuracy: 0.7193 - val_loss: 1.2070 - val_accuracy: 0.6153\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0628 - accuracy: 0.7290 - val_loss: 1.2059 - val_accuracy: 0.6153\n","Epoch 78/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0570 - accuracy: 0.7309 - val_loss: 1.2023 - val_accuracy: 0.6196\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0544 - accuracy: 0.7220 - val_loss: 1.2039 - val_accuracy: 0.6153\n","Epoch 80/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0408 - accuracy: 0.7325 - val_loss: 1.1994 - val_accuracy: 0.6099\n","Epoch 81/100\n","29/29 [==============================] - 0s 11ms/step - loss: 1.0340 - accuracy: 0.7411 - val_loss: 1.2071 - val_accuracy: 0.6078\n","Epoch 82/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0358 - accuracy: 0.7193 - val_loss: 1.1961 - val_accuracy: 0.6218\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0219 - accuracy: 0.7376 - val_loss: 1.1883 - val_accuracy: 0.6153\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 1.0153 - accuracy: 0.7387 - val_loss: 1.1872 - val_accuracy: 0.6131\n","Epoch 85/100\n","29/29 [==============================] - 0s 13ms/step - loss: 1.0058 - accuracy: 0.7430 - val_loss: 1.1895 - val_accuracy: 0.6153\n","Epoch 86/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9984 - accuracy: 0.7478 - val_loss: 1.1907 - val_accuracy: 0.6153\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9944 - accuracy: 0.7438 - val_loss: 1.1891 - val_accuracy: 0.6121\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9861 - accuracy: 0.7489 - val_loss: 1.1850 - val_accuracy: 0.6207\n","Epoch 89/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9788 - accuracy: 0.7513 - val_loss: 1.1794 - val_accuracy: 0.6153\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9700 - accuracy: 0.7554 - val_loss: 1.1815 - val_accuracy: 0.6142\n","Epoch 91/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9646 - accuracy: 0.7562 - val_loss: 1.1839 - val_accuracy: 0.6088\n","Epoch 92/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9569 - accuracy: 0.7586 - val_loss: 1.1826 - val_accuracy: 0.6045\n","Epoch 93/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9494 - accuracy: 0.7608 - val_loss: 1.1798 - val_accuracy: 0.6078\n","Epoch 94/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9445 - accuracy: 0.7637 - val_loss: 1.1894 - val_accuracy: 0.6121\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9385 - accuracy: 0.7624 - val_loss: 1.1797 - val_accuracy: 0.6142\n","Epoch 96/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9295 - accuracy: 0.7675 - val_loss: 1.1791 - val_accuracy: 0.6142\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9261 - accuracy: 0.7664 - val_loss: 1.1873 - val_accuracy: 0.6110\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9198 - accuracy: 0.7716 - val_loss: 1.1784 - val_accuracy: 0.6164\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.9101 - accuracy: 0.7710 - val_loss: 1.1847 - val_accuracy: 0.6110\n","Epoch 100/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.9079 - accuracy: 0.7691 - val_loss: 1.1838 - val_accuracy: 0.6185\n","{'loss': [1.9596478939056396, 1.937956690788269, 1.9183934926986694, 1.8997235298156738, 1.8814117908477783, 1.863207459449768, 1.8452521562576294, 1.8275421857833862, 1.8099642992019653, 1.792667269706726, 1.7754508256912231, 1.7588903903961182, 1.7417387962341309, 1.7249857187271118, 1.7084732055664062, 1.6929407119750977, 1.6766124963760376, 1.6615095138549805, 1.6460232734680176, 1.631666660308838, 1.6166672706604004, 1.6024075746536255, 1.5884971618652344, 1.5753209590911865, 1.562564492225647, 1.5495007038116455, 1.5372467041015625, 1.5237747430801392, 1.5138335227966309, 1.5016162395477295, 1.4893672466278076, 1.4774810075759888, 1.466579556465149, 1.4557626247406006, 1.4439585208892822, 1.4338059425354004, 1.424015998840332, 1.4106957912445068, 1.4030393362045288, 1.3907805681228638, 1.3804574012756348, 1.3700498342514038, 1.3610777854919434, 1.3506214618682861, 1.3407893180847168, 1.3316552639007568, 1.3210915327072144, 1.3116925954818726, 1.3016784191131592, 1.293267011642456, 1.2869898080825806, 1.2751859426498413, 1.2649000883102417, 1.2558250427246094, 1.2466604709625244, 1.2382135391235352, 1.229340672492981, 1.2212002277374268, 1.212082028388977, 1.2016291618347168, 1.193416714668274, 1.1847058534622192, 1.1771821975708008, 1.1682230234146118, 1.1614457368850708, 1.1500033140182495, 1.1427050828933716, 1.1344629526138306, 1.1273431777954102, 1.1195828914642334, 1.1119933128356934, 1.102280855178833, 1.09546959400177, 1.0873020887374878, 1.0794597864151, 1.0716898441314697, 1.062770128250122, 1.0569605827331543, 1.0543789863586426, 1.0408014059066772, 1.0339521169662476, 1.035824179649353, 1.0219422578811646, 1.0152919292449951, 1.0058019161224365, 0.9983967542648315, 0.9943661689758301, 0.9861096739768982, 0.9787625074386597, 0.9700387716293335, 0.9646405577659607, 0.9569174647331238, 0.9494298100471497, 0.9445052742958069, 0.9384853839874268, 0.9295211434364319, 0.9260915517807007, 0.9197709560394287, 0.9100857973098755, 0.907944917678833], 'accuracy': [0.5158944129943848, 0.5245150923728943, 0.5422952771186829, 0.5673491358757019, 0.5676185488700867, 0.5748922228813171, 0.5808189511299133, 0.5829741358757019, 0.587553858757019, 0.5883620977401733, 0.5886314511299133, 0.6010237336158752, 0.6010237336158752, 0.6034482717514038, 0.6072198152542114, 0.6117995977401733, 0.6128771305084229, 0.6201508641242981, 0.6147629022598267, 0.6120689511299133, 0.6144935488700867, 0.6220366358757019, 0.6201508641242981, 0.623383641242981, 0.623383641242981, 0.6252694129943848, 0.625, 0.6287715435028076, 0.6247305870056152, 0.6349676847457886, 0.6352370977401733, 0.6328125, 0.6352370977401733, 0.6398168206214905, 0.6414331793785095, 0.641972005367279, 0.6435883641242981, 0.6435883641242981, 0.6478987336158752, 0.646821141242981, 0.6559805870056152, 0.6489762663841248, 0.6554418206214905, 0.6530172228813171, 0.6581357717514038, 0.6584051847457886, 0.662446141242981, 0.6643319129943848, 0.6681034564971924, 0.665678858757019, 0.6640625, 0.6699892282485962, 0.6772629022598267, 0.6745689511299133, 0.6821120977401733, 0.6778017282485962, 0.6807650923728943, 0.6794180870056152, 0.6823814511299133, 0.6883081793785095, 0.6880387663841248, 0.6926185488700867, 0.6942349076271057, 0.6963900923728943, 0.6958512663841248, 0.7058189511299133, 0.7106680870056152, 0.7066271305084229, 0.7042025923728943, 0.7066271305084229, 0.712553858757019, 0.717402994632721, 0.7195581793785095, 0.7211745977401733, 0.7209051847457886, 0.7192887663841248, 0.7289870977401733, 0.7308728694915771, 0.7219827771186829, 0.7324892282485962, 0.7411099076271057, 0.7192887663841248, 0.7376077771186829, 0.7386853694915771, 0.7429956793785095, 0.7478448152542114, 0.743803858757019, 0.7489224076271057, 0.751347005367279, 0.7553879022598267, 0.756196141242981, 0.7586206793785095, 0.7607758641242981, 0.7637392282485962, 0.7623922228813171, 0.7675107717514038, 0.7664331793785095, 0.7715517282485962, 0.7710129022598267, 0.7691271305084229], 'val_loss': [1.9531022310256958, 1.9350868463516235, 1.9173072576522827, 1.8997763395309448, 1.8824794292449951, 1.865565538406372, 1.848707675933838, 1.8322640657424927, 1.815994381904602, 1.7997395992279053, 1.7840700149536133, 1.7682294845581055, 1.7525668144226074, 1.7374786138534546, 1.7205272912979126, 1.7058053016662598, 1.691042184829712, 1.6750816106796265, 1.6599258184432983, 1.6472922563552856, 1.631738305091858, 1.6174728870391846, 1.604047417640686, 1.5909708738327026, 1.5788748264312744, 1.567697286605835, 1.5548806190490723, 1.5455769300460815, 1.5327850580215454, 1.5219166278839111, 1.5109367370605469, 1.5009335279464722, 1.4905540943145752, 1.4827930927276611, 1.4739995002746582, 1.4652743339538574, 1.456257700920105, 1.442226767539978, 1.433671236038208, 1.4255061149597168, 1.4168081283569336, 1.4092715978622437, 1.402311086654663, 1.3910304307937622, 1.385923981666565, 1.374563455581665, 1.3664361238479614, 1.360694408416748, 1.3524929285049438, 1.3435276746749878, 1.3405877351760864, 1.3312857151031494, 1.3271700143814087, 1.3191184997558594, 1.309218168258667, 1.3022005558013916, 1.2997534275054932, 1.2904919385910034, 1.2835056781768799, 1.2780014276504517, 1.2723671197891235, 1.2675474882125854, 1.2603254318237305, 1.2629024982452393, 1.2560828924179077, 1.2469046115875244, 1.2420181035995483, 1.238409399986267, 1.2339695692062378, 1.2315236330032349, 1.2252562046051025, 1.2232218980789185, 1.219401240348816, 1.214819312095642, 1.211167812347412, 1.207029104232788, 1.2059025764465332, 1.202327013015747, 1.203940987586975, 1.1993823051452637, 1.20709228515625, 1.196141004562378, 1.18831467628479, 1.1872328519821167, 1.1894999742507935, 1.1907154321670532, 1.189125418663025, 1.1849629878997803, 1.1793733835220337, 1.1815390586853027, 1.183891773223877, 1.1825690269470215, 1.17978036403656, 1.1893908977508545, 1.179701566696167, 1.1791383028030396, 1.1872930526733398, 1.1783853769302368, 1.184650182723999, 1.1838444471359253], 'val_accuracy': [0.5506465435028076, 0.5344827771186829, 0.568965494632721, 0.5646551847457886, 0.5571120977401733, 0.5528017282485962, 0.5528017282485962, 0.5506465435028076, 0.548491358757019, 0.5581896305084229, 0.5603448152542114, 0.5625, 0.5625, 0.5614224076271057, 0.5851293206214905, 0.5786637663841248, 0.5775862336158752, 0.5743534564971924, 0.568965494632721, 0.5711206793785095, 0.5732758641242981, 0.5818965435028076, 0.5840517282485962, 0.5905172228813171, 0.5894396305084229, 0.5905172228813171, 0.5862069129943848, 0.5905172228813171, 0.5980603694915771, 0.5883620977401733, 0.5959051847457886, 0.59375, 0.5926724076271057, 0.59375, 0.5926724076271057, 0.5969827771186829, 0.600215494632721, 0.5991379022598267, 0.5991379022598267, 0.6034482717514038, 0.6045258641242981, 0.607758641242981, 0.6056034564971924, 0.607758641242981, 0.6088362336158752, 0.6088362336158752, 0.6142241358757019, 0.6045258641242981, 0.6120689511299133, 0.6196120977401733, 0.6131465435028076, 0.6163793206214905, 0.6142241358757019, 0.6174569129943848, 0.6228448152542114, 0.625, 0.6131465435028076, 0.6228448152542114, 0.6196120977401733, 0.6217672228813171, 0.6217672228813171, 0.6163793206214905, 0.6206896305084229, 0.618534505367279, 0.6163793206214905, 0.6131465435028076, 0.6228448152542114, 0.6206896305084229, 0.6163793206214905, 0.6196120977401733, 0.6153017282485962, 0.6196120977401733, 0.6142241358757019, 0.6174569129943848, 0.618534505367279, 0.6153017282485962, 0.6153017282485962, 0.6196120977401733, 0.6153017282485962, 0.6099137663841248, 0.607758641242981, 0.6217672228813171, 0.6153017282485962, 0.6131465435028076, 0.6153017282485962, 0.6153017282485962, 0.6120689511299133, 0.6206896305084229, 0.6153017282485962, 0.6142241358757019, 0.6088362336158752, 0.6045258641242981, 0.607758641242981, 0.6120689511299133, 0.6142241358757019, 0.6142241358757019, 0.610991358757019, 0.6163793206214905, 0.610991358757019, 0.618534505367279]}\n","38/38 [==============================] - 0s 8ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 59ms/step - loss: 1.9600 - accuracy: 0.5034 - val_loss: 1.9537 - val_accuracy: 0.5588\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 1.9550 - accuracy: 0.4297"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 1s 19ms/step - loss: 1.9394 - accuracy: 0.5164 - val_loss: 1.9361 - val_accuracy: 0.5781\n","Epoch 3/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.9206 - accuracy: 0.5280 - val_loss: 1.9189 - val_accuracy: 0.5475\n","Epoch 4/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.9026 - accuracy: 0.5498 - val_loss: 1.9018 - val_accuracy: 0.5464\n","Epoch 5/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.8847 - accuracy: 0.5608 - val_loss: 1.8850 - val_accuracy: 0.5475\n","Epoch 6/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.8673 - accuracy: 0.5645 - val_loss: 1.8686 - val_accuracy: 0.5362\n","Epoch 7/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.8499 - accuracy: 0.5676 - val_loss: 1.8523 - val_accuracy: 0.5339\n","Epoch 8/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.8327 - accuracy: 0.5665 - val_loss: 1.8362 - val_accuracy: 0.5441\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.8160 - accuracy: 0.5792 - val_loss: 1.8203 - val_accuracy: 0.5441\n","Epoch 10/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.7992 - accuracy: 0.5767 - val_loss: 1.8049 - val_accuracy: 0.5441\n","Epoch 11/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.7825 - accuracy: 0.5866 - val_loss: 1.7892 - val_accuracy: 0.5475\n","Epoch 12/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.7662 - accuracy: 0.5846 - val_loss: 1.7749 - val_accuracy: 0.5441\n","Epoch 13/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.7494 - accuracy: 0.5905 - val_loss: 1.7587 - val_accuracy: 0.5464\n","Epoch 14/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.7332 - accuracy: 0.5942 - val_loss: 1.7443 - val_accuracy: 0.5464\n","Epoch 15/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.7174 - accuracy: 0.6016 - val_loss: 1.7301 - val_accuracy: 0.5520\n","Epoch 16/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.7028 - accuracy: 0.5971 - val_loss: 1.7141 - val_accuracy: 0.5622\n","Epoch 17/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.6865 - accuracy: 0.6019 - val_loss: 1.7001 - val_accuracy: 0.5656\n","Epoch 18/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.6723 - accuracy: 0.5990 - val_loss: 1.6860 - val_accuracy: 0.5679\n","Epoch 19/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.6573 - accuracy: 0.5988 - val_loss: 1.6695 - val_accuracy: 0.5781\n","Epoch 20/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.6422 - accuracy: 0.6115 - val_loss: 1.6603 - val_accuracy: 0.5747\n","Epoch 21/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.6291 - accuracy: 0.6050 - val_loss: 1.6420 - val_accuracy: 0.5871\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.6159 - accuracy: 0.6084 - val_loss: 1.6294 - val_accuracy: 0.5792\n","Epoch 23/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.6020 - accuracy: 0.6087 - val_loss: 1.6155 - val_accuracy: 0.5871\n","Epoch 24/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.5882 - accuracy: 0.6186 - val_loss: 1.6054 - val_accuracy: 0.5803\n","Epoch 25/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5751 - accuracy: 0.6228 - val_loss: 1.5911 - val_accuracy: 0.5905\n","Epoch 26/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.5624 - accuracy: 0.6171 - val_loss: 1.5804 - val_accuracy: 0.5928\n","Epoch 27/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.5504 - accuracy: 0.6177 - val_loss: 1.5689 - val_accuracy: 0.5837\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.5387 - accuracy: 0.6222 - val_loss: 1.5600 - val_accuracy: 0.5803\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.5267 - accuracy: 0.6194 - val_loss: 1.5476 - val_accuracy: 0.5882\n","Epoch 30/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.5140 - accuracy: 0.6197 - val_loss: 1.5371 - val_accuracy: 0.5882\n","Epoch 31/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.5032 - accuracy: 0.6239 - val_loss: 1.5263 - val_accuracy: 0.5894\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.4921 - accuracy: 0.6245 - val_loss: 1.5170 - val_accuracy: 0.5916\n","Epoch 33/100\n","28/28 [==============================] - 0s 12ms/step - loss: 1.4807 - accuracy: 0.6248 - val_loss: 1.5074 - val_accuracy: 0.5916\n","Epoch 34/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4689 - accuracy: 0.6248 - val_loss: 1.4969 - val_accuracy: 0.5950\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.4597 - accuracy: 0.6214 - val_loss: 1.4919 - val_accuracy: 0.5916\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.4489 - accuracy: 0.6248 - val_loss: 1.4875 - val_accuracy: 0.5814\n","Epoch 37/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4382 - accuracy: 0.6234 - val_loss: 1.4739 - val_accuracy: 0.5973\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.4256 - accuracy: 0.6353 - val_loss: 1.4601 - val_accuracy: 0.5939\n","Epoch 39/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4159 - accuracy: 0.6353 - val_loss: 1.4522 - val_accuracy: 0.5950\n","Epoch 40/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.4049 - accuracy: 0.6375 - val_loss: 1.4475 - val_accuracy: 0.6029\n","Epoch 41/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.3957 - accuracy: 0.6409 - val_loss: 1.4362 - val_accuracy: 0.5939\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3847 - accuracy: 0.6364 - val_loss: 1.4261 - val_accuracy: 0.5950\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3745 - accuracy: 0.6423 - val_loss: 1.4184 - val_accuracy: 0.5916\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3657 - accuracy: 0.6392 - val_loss: 1.4106 - val_accuracy: 0.5916\n","Epoch 45/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3566 - accuracy: 0.6443 - val_loss: 1.4033 - val_accuracy: 0.5939\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3466 - accuracy: 0.6440 - val_loss: 1.3956 - val_accuracy: 0.5905\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.3371 - accuracy: 0.6449 - val_loss: 1.3895 - val_accuracy: 0.5928\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3269 - accuracy: 0.6466 - val_loss: 1.3793 - val_accuracy: 0.5916\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.3176 - accuracy: 0.6480 - val_loss: 1.3719 - val_accuracy: 0.5905\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3083 - accuracy: 0.6537 - val_loss: 1.3664 - val_accuracy: 0.5984\n","Epoch 51/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2983 - accuracy: 0.6505 - val_loss: 1.3583 - val_accuracy: 0.5916\n","Epoch 52/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2894 - accuracy: 0.6545 - val_loss: 1.3515 - val_accuracy: 0.5950\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2805 - accuracy: 0.6585 - val_loss: 1.3452 - val_accuracy: 0.5973\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2712 - accuracy: 0.6596 - val_loss: 1.3394 - val_accuracy: 0.6018\n","Epoch 55/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2618 - accuracy: 0.6590 - val_loss: 1.3370 - val_accuracy: 0.6063\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2536 - accuracy: 0.6604 - val_loss: 1.3255 - val_accuracy: 0.5973\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.2445 - accuracy: 0.6664 - val_loss: 1.3208 - val_accuracy: 0.6007\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2359 - accuracy: 0.6641 - val_loss: 1.3139 - val_accuracy: 0.6018\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2274 - accuracy: 0.6644 - val_loss: 1.3105 - val_accuracy: 0.6041\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.2176 - accuracy: 0.6737 - val_loss: 1.3040 - val_accuracy: 0.6041\n","Epoch 61/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.2107 - accuracy: 0.6760 - val_loss: 1.2975 - val_accuracy: 0.6097\n","Epoch 62/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2010 - accuracy: 0.6769 - val_loss: 1.2952 - val_accuracy: 0.6109\n","Epoch 63/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.1926 - accuracy: 0.6771 - val_loss: 1.2881 - val_accuracy: 0.6131\n","Epoch 64/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1843 - accuracy: 0.6834 - val_loss: 1.2839 - val_accuracy: 0.6154\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1768 - accuracy: 0.6851 - val_loss: 1.2768 - val_accuracy: 0.6029\n","Epoch 66/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1679 - accuracy: 0.6802 - val_loss: 1.2731 - val_accuracy: 0.6165\n","Epoch 67/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1581 - accuracy: 0.6947 - val_loss: 1.2786 - val_accuracy: 0.6188\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1516 - accuracy: 0.6870 - val_loss: 1.2640 - val_accuracy: 0.6097\n","Epoch 69/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1437 - accuracy: 0.6902 - val_loss: 1.2596 - val_accuracy: 0.5973\n","Epoch 70/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1369 - accuracy: 0.6921 - val_loss: 1.2614 - val_accuracy: 0.6154\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1260 - accuracy: 0.7006 - val_loss: 1.2491 - val_accuracy: 0.6097\n","Epoch 72/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.1201 - accuracy: 0.6989 - val_loss: 1.2517 - val_accuracy: 0.6244\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1116 - accuracy: 0.7009 - val_loss: 1.2417 - val_accuracy: 0.6063\n","Epoch 74/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.1047 - accuracy: 0.7023 - val_loss: 1.2384 - val_accuracy: 0.6075\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0988 - accuracy: 0.7063 - val_loss: 1.2361 - val_accuracy: 0.6143\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0883 - accuracy: 0.7134 - val_loss: 1.2319 - val_accuracy: 0.6131\n","Epoch 77/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0802 - accuracy: 0.7176 - val_loss: 1.2256 - val_accuracy: 0.6188\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0730 - accuracy: 0.7162 - val_loss: 1.2338 - val_accuracy: 0.6165\n","Epoch 79/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0667 - accuracy: 0.7176 - val_loss: 1.2232 - val_accuracy: 0.6131\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0583 - accuracy: 0.7221 - val_loss: 1.2172 - val_accuracy: 0.6131\n","Epoch 81/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0557 - accuracy: 0.7193 - val_loss: 1.2205 - val_accuracy: 0.6131\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0450 - accuracy: 0.7250 - val_loss: 1.2098 - val_accuracy: 0.6120\n","Epoch 83/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0359 - accuracy: 0.7298 - val_loss: 1.2100 - val_accuracy: 0.6222\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0277 - accuracy: 0.7337 - val_loss: 1.2079 - val_accuracy: 0.6131\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0217 - accuracy: 0.7360 - val_loss: 1.2074 - val_accuracy: 0.6176\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0198 - accuracy: 0.7292 - val_loss: 1.2063 - val_accuracy: 0.6165\n","Epoch 87/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0122 - accuracy: 0.7309 - val_loss: 1.1998 - val_accuracy: 0.6188\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9995 - accuracy: 0.7371 - val_loss: 1.1988 - val_accuracy: 0.6188\n","Epoch 89/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9930 - accuracy: 0.7434 - val_loss: 1.1961 - val_accuracy: 0.6210\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9869 - accuracy: 0.7453 - val_loss: 1.1970 - val_accuracy: 0.6154\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9805 - accuracy: 0.7456 - val_loss: 1.1982 - val_accuracy: 0.6154\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9752 - accuracy: 0.7538 - val_loss: 1.2020 - val_accuracy: 0.6154\n","Epoch 93/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9665 - accuracy: 0.7544 - val_loss: 1.1928 - val_accuracy: 0.6188\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9599 - accuracy: 0.7550 - val_loss: 1.1945 - val_accuracy: 0.6188\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9532 - accuracy: 0.7572 - val_loss: 1.1926 - val_accuracy: 0.6154\n","Epoch 96/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9462 - accuracy: 0.7600 - val_loss: 1.1917 - val_accuracy: 0.6176\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9433 - accuracy: 0.7606 - val_loss: 1.1925 - val_accuracy: 0.6120\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9349 - accuracy: 0.7615 - val_loss: 1.1960 - val_accuracy: 0.6176\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.9245 - accuracy: 0.7745 - val_loss: 1.1965 - val_accuracy: 0.6188\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9182 - accuracy: 0.7714 - val_loss: 1.1966 - val_accuracy: 0.6233\n","{'loss': [1.9599705934524536, 1.9394398927688599, 1.9205671548843384, 1.9025555849075317, 1.8847136497497559, 1.8672945499420166, 1.8499401807785034, 1.8327000141143799, 1.8159829378128052, 1.7991632223129272, 1.7824591398239136, 1.7662469148635864, 1.7494337558746338, 1.733234167098999, 1.7173579931259155, 1.7028441429138184, 1.686535358428955, 1.672330379486084, 1.6573458909988403, 1.6422072649002075, 1.6291450262069702, 1.6158617734909058, 1.601950764656067, 1.5881704092025757, 1.575053334236145, 1.5623834133148193, 1.5503607988357544, 1.5386672019958496, 1.5266801118850708, 1.5140258073806763, 1.5031554698944092, 1.4921129941940308, 1.480657935142517, 1.4688984155654907, 1.4596614837646484, 1.4488931894302368, 1.4382447004318237, 1.4256281852722168, 1.4159120321273804, 1.404888391494751, 1.395748496055603, 1.3847402334213257, 1.3744999170303345, 1.3657093048095703, 1.3566454648971558, 1.3465566635131836, 1.3370567560195923, 1.3269492387771606, 1.3176218271255493, 1.3082705736160278, 1.2982946634292603, 1.2893924713134766, 1.280450463294983, 1.271202564239502, 1.2617703676223755, 1.2536230087280273, 1.2444840669631958, 1.2358578443527222, 1.2273555994033813, 1.2175744771957397, 1.2107455730438232, 1.2010458707809448, 1.192581057548523, 1.1842775344848633, 1.17684006690979, 1.1678681373596191, 1.1581089496612549, 1.1516249179840088, 1.1437498331069946, 1.1369327306747437, 1.125970721244812, 1.1201050281524658, 1.1116138696670532, 1.1047449111938477, 1.0988032817840576, 1.0883386135101318, 1.080228567123413, 1.0729851722717285, 1.0667282342910767, 1.0582823753356934, 1.0557435750961304, 1.0450021028518677, 1.035893201828003, 1.0277025699615479, 1.0216814279556274, 1.0198445320129395, 1.0121955871582031, 0.9995469450950623, 0.9930444359779358, 0.9868518710136414, 0.9805074334144592, 0.9751701354980469, 0.9664671421051025, 0.9599084854125977, 0.9531813859939575, 0.9461924433708191, 0.9432529211044312, 0.9349313378334045, 0.9244997501373291, 0.9182332158088684], 'accuracy': [0.5033955574035645, 0.5164120197296143, 0.5280135869979858, 0.5498019456863403, 0.5608375668525696, 0.5645161271095276, 0.5676287412643433, 0.5664969086647034, 0.5792303085327148, 0.5766836404800415, 0.5865874290466309, 0.5846067070960999, 0.5905489325523376, 0.5942274928092957, 0.6015846133232117, 0.5970571637153625, 0.6018675565719604, 0.5990379452705383, 0.5987549424171448, 0.611488401889801, 0.6049801707267761, 0.6083757877349854, 0.6086587309837341, 0.6185625195503235, 0.6228070259094238, 0.61714768409729, 0.6177136301994324, 0.6222410798072815, 0.6194114089012146, 0.6196944117546082, 0.6239388585090637, 0.624504804611206, 0.6247877478599548, 0.6247877478599548, 0.6213921904563904, 0.6247877478599548, 0.6233729720115662, 0.6352574825286865, 0.6352574825286865, 0.6375212073326111, 0.6409168243408203, 0.6363893747329712, 0.6423316597938538, 0.6392189860343933, 0.6443123817443848, 0.644029438495636, 0.6448783278465271, 0.6465761065483093, 0.6479909420013428, 0.6536502838134766, 0.6505376100540161, 0.6544991731643677, 0.6584606766700745, 0.6595925092697144, 0.6590266227722168, 0.6604413986206055, 0.666383683681488, 0.6641199588775635, 0.664402961730957, 0.673740804195404, 0.6760045289993286, 0.6768534183502197, 0.6771363615989685, 0.6833616495132446, 0.6850594282150269, 0.680249035358429, 0.6946802735328674, 0.6870402097702026, 0.6901528239250183, 0.6921335458755493, 0.7006224989891052, 0.698924720287323, 0.7009055018424988, 0.7023203372955322, 0.706281840801239, 0.7133559584617615, 0.7176004648208618, 0.7161856293678284, 0.7176004648208618, 0.7221279144287109, 0.719298243522644, 0.7249575257301331, 0.7297679781913757, 0.7337294816970825, 0.7359932065010071, 0.7292020320892334, 0.7308998107910156, 0.7371250987052917, 0.7433503270149231, 0.7453310489654541, 0.7456140518188477, 0.7538200616836548, 0.7543859481811523, 0.7549518942832947, 0.7572156190872192, 0.7600452899932861, 0.7606111764907837, 0.7614601254463196, 0.7744765281677246, 0.7713639140129089], 'val_loss': [1.953696370124817, 1.936138391494751, 1.918886661529541, 1.9018449783325195, 1.8850374221801758, 1.8686094284057617, 1.8523263931274414, 1.8362077474594116, 1.8203332424163818, 1.8049148321151733, 1.7892298698425293, 1.7749321460723877, 1.7586668729782104, 1.7443315982818604, 1.730084776878357, 1.714065432548523, 1.700086236000061, 1.6859633922576904, 1.6694995164871216, 1.6602591276168823, 1.641974925994873, 1.6293680667877197, 1.6155468225479126, 1.6053786277770996, 1.5911208391189575, 1.580380916595459, 1.5689102411270142, 1.5600003004074097, 1.5475534200668335, 1.537099838256836, 1.526320219039917, 1.5170376300811768, 1.5073915719985962, 1.4969395399093628, 1.4918789863586426, 1.4875234365463257, 1.4738928079605103, 1.4600579738616943, 1.4521983861923218, 1.4475011825561523, 1.4361929893493652, 1.4260681867599487, 1.4184362888336182, 1.4106191396713257, 1.403275489807129, 1.3956334590911865, 1.3895175457000732, 1.3792787790298462, 1.3719426393508911, 1.3664288520812988, 1.3582981824874878, 1.3514890670776367, 1.3452342748641968, 1.339393973350525, 1.33696711063385, 1.3255023956298828, 1.3207521438598633, 1.3139419555664062, 1.3105204105377197, 1.303985834121704, 1.2975404262542725, 1.2951627969741821, 1.2881215810775757, 1.2838892936706543, 1.2767994403839111, 1.2730602025985718, 1.2786214351654053, 1.2640291452407837, 1.2595564126968384, 1.2614305019378662, 1.2490549087524414, 1.2516810894012451, 1.2417019605636597, 1.2384055852890015, 1.2361280918121338, 1.2319475412368774, 1.22556734085083, 1.2337913513183594, 1.2232166528701782, 1.217179298400879, 1.2204720973968506, 1.209794282913208, 1.2100144624710083, 1.207894206047058, 1.2073841094970703, 1.206296443939209, 1.1998274326324463, 1.198779582977295, 1.1960968971252441, 1.19704270362854, 1.19817054271698, 1.201974868774414, 1.192809820175171, 1.1945480108261108, 1.1925712823867798, 1.1917155981063843, 1.192453384399414, 1.195998191833496, 1.196513295173645, 1.1966133117675781], 'val_accuracy': [0.5588235259056091, 0.5780543088912964, 0.5475113391876221, 0.5463801026344299, 0.5475113391876221, 0.5361990928649902, 0.5339366793632507, 0.5441176295280457, 0.5441176295280457, 0.5441176295280457, 0.5475113391876221, 0.5441176295280457, 0.5463801026344299, 0.5463801026344299, 0.5520362257957458, 0.5622171759605408, 0.5656108856201172, 0.5678732991218567, 0.5780543088912964, 0.5746606588363647, 0.587104082107544, 0.5791855454444885, 0.587104082107544, 0.5803167223930359, 0.5904977321624756, 0.5927602052688599, 0.5837104320526123, 0.5803167223930359, 0.5882353186607361, 0.5882353186607361, 0.5893664956092834, 0.5916289687156677, 0.5916289687156677, 0.5950226187705994, 0.5916289687156677, 0.581447958946228, 0.5972850918769836, 0.5938913822174072, 0.5950226187705994, 0.6029411554336548, 0.5938913822174072, 0.5950226187705994, 0.5916289687156677, 0.5916289687156677, 0.5938913822174072, 0.5904977321624756, 0.5927602052688599, 0.5916289687156677, 0.5904977321624756, 0.598416268825531, 0.5916289687156677, 0.5950226187705994, 0.5972850918769836, 0.6018099784851074, 0.6063348650932312, 0.5972850918769836, 0.6006787419319153, 0.6018099784851074, 0.6040723919868469, 0.6040723919868469, 0.6097285151481628, 0.610859751701355, 0.6131221652030945, 0.6153846383094788, 0.6029411554336548, 0.6165158152580261, 0.6187782883644104, 0.6097285151481628, 0.5972850918769836, 0.6153846383094788, 0.6097285151481628, 0.6244344115257263, 0.6063348650932312, 0.6074660420417786, 0.6142534017562866, 0.6131221652030945, 0.6187782883644104, 0.6165158152580261, 0.6131221652030945, 0.6131221652030945, 0.6131221652030945, 0.6119909286499023, 0.622171938419342, 0.6131221652030945, 0.6176470518112183, 0.6165158152580261, 0.6187782883644104, 0.6187782883644104, 0.6210407018661499, 0.6153846383094788, 0.6153846383094788, 0.6153846383094788, 0.6187782883644104, 0.6187782883644104, 0.6153846383094788, 0.6176470518112183, 0.6119909286499023, 0.6176470518112183, 0.6187782883644104, 0.6233031749725342]}\n","45/45 [==============================] - 1s 8ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 5s 48ms/step - loss: 1.9587 - accuracy: 0.5134 - val_loss: 1.9519 - val_accuracy: 0.5661\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 20ms/step - loss: 1.9354 - accuracy: 0.5315 - val_loss: 1.9325 - val_accuracy: 0.5733\n","Epoch 3/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.9148 - accuracy: 0.5442 - val_loss: 1.9134 - val_accuracy: 0.5475\n","Epoch 4/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.8951 - accuracy: 0.5581 - val_loss: 1.8946 - val_accuracy: 0.5393\n","Epoch 5/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.8756 - accuracy: 0.5695 - val_loss: 1.8762 - val_accuracy: 0.5413\n","Epoch 6/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.8565 - accuracy: 0.5690 - val_loss: 1.8582 - val_accuracy: 0.5403\n","Epoch 7/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.8378 - accuracy: 0.5721 - val_loss: 1.8403 - val_accuracy: 0.5413\n","Epoch 8/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.8193 - accuracy: 0.5687 - val_loss: 1.8226 - val_accuracy: 0.5424\n","Epoch 9/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.8012 - accuracy: 0.5773 - val_loss: 1.8054 - val_accuracy: 0.5444\n","Epoch 10/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.7831 - accuracy: 0.5767 - val_loss: 1.7883 - val_accuracy: 0.5413\n","Epoch 11/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.7652 - accuracy: 0.5855 - val_loss: 1.7715 - val_accuracy: 0.5424\n","Epoch 12/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.7479 - accuracy: 0.5897 - val_loss: 1.7544 - val_accuracy: 0.5517\n","Epoch 13/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.7305 - accuracy: 0.5894 - val_loss: 1.7380 - val_accuracy: 0.5527\n","Epoch 14/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.7130 - accuracy: 0.5953 - val_loss: 1.7211 - val_accuracy: 0.5640\n","Epoch 15/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.6965 - accuracy: 0.5953 - val_loss: 1.7050 - val_accuracy: 0.5713\n","Epoch 16/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.6792 - accuracy: 0.6005 - val_loss: 1.6885 - val_accuracy: 0.5723\n","Epoch 17/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.6632 - accuracy: 0.6005 - val_loss: 1.6728 - val_accuracy: 0.5733\n","Epoch 18/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.6468 - accuracy: 0.6034 - val_loss: 1.6576 - val_accuracy: 0.5785\n","Epoch 19/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.6320 - accuracy: 0.6039 - val_loss: 1.6417 - val_accuracy: 0.5899\n","Epoch 20/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.6164 - accuracy: 0.6083 - val_loss: 1.6270 - val_accuracy: 0.5919\n","Epoch 21/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.6025 - accuracy: 0.6080 - val_loss: 1.6146 - val_accuracy: 0.5857\n","Epoch 22/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.5871 - accuracy: 0.6145 - val_loss: 1.5984 - val_accuracy: 0.5899\n","Epoch 23/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.5727 - accuracy: 0.6132 - val_loss: 1.5853 - val_accuracy: 0.5868\n","Epoch 24/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.5592 - accuracy: 0.6183 - val_loss: 1.5732 - val_accuracy: 0.5837\n","Epoch 25/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.5461 - accuracy: 0.6183 - val_loss: 1.5598 - val_accuracy: 0.5857\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.5321 - accuracy: 0.6207 - val_loss: 1.5485 - val_accuracy: 0.5919\n","Epoch 27/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.5194 - accuracy: 0.6178 - val_loss: 1.5384 - val_accuracy: 0.5981\n","Epoch 28/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.5069 - accuracy: 0.6199 - val_loss: 1.5270 - val_accuracy: 0.5992\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4943 - accuracy: 0.6238 - val_loss: 1.5119 - val_accuracy: 0.5899\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4828 - accuracy: 0.6189 - val_loss: 1.5070 - val_accuracy: 0.5930\n","Epoch 31/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.4692 - accuracy: 0.6274 - val_loss: 1.4916 - val_accuracy: 0.6002\n","Epoch 32/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.4573 - accuracy: 0.6266 - val_loss: 1.4807 - val_accuracy: 0.6023\n","Epoch 33/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.4459 - accuracy: 0.6256 - val_loss: 1.4705 - val_accuracy: 0.6074\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.4339 - accuracy: 0.6315 - val_loss: 1.4616 - val_accuracy: 0.6023\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4226 - accuracy: 0.6313 - val_loss: 1.4500 - val_accuracy: 0.6023\n","Epoch 36/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.4116 - accuracy: 0.6302 - val_loss: 1.4457 - val_accuracy: 0.6043\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4013 - accuracy: 0.6346 - val_loss: 1.4387 - val_accuracy: 0.6043\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3892 - accuracy: 0.6271 - val_loss: 1.4248 - val_accuracy: 0.6023\n","Epoch 39/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3786 - accuracy: 0.6398 - val_loss: 1.4127 - val_accuracy: 0.6033\n","Epoch 40/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3678 - accuracy: 0.6380 - val_loss: 1.4035 - val_accuracy: 0.5992\n","Epoch 41/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3569 - accuracy: 0.6393 - val_loss: 1.3956 - val_accuracy: 0.5981\n","Epoch 42/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3470 - accuracy: 0.6413 - val_loss: 1.3864 - val_accuracy: 0.5950\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3379 - accuracy: 0.6452 - val_loss: 1.3797 - val_accuracy: 0.5992\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3261 - accuracy: 0.6488 - val_loss: 1.3714 - val_accuracy: 0.6002\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.3169 - accuracy: 0.6473 - val_loss: 1.3633 - val_accuracy: 0.5868\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3056 - accuracy: 0.6532 - val_loss: 1.3563 - val_accuracy: 0.6012\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.2950 - accuracy: 0.6519 - val_loss: 1.3518 - val_accuracy: 0.6033\n","Epoch 48/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.2849 - accuracy: 0.6587 - val_loss: 1.3555 - val_accuracy: 0.6023\n","Epoch 49/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2777 - accuracy: 0.6514 - val_loss: 1.3339 - val_accuracy: 0.5899\n","Epoch 50/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.2665 - accuracy: 0.6605 - val_loss: 1.3339 - val_accuracy: 0.6043\n","Epoch 51/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2572 - accuracy: 0.6605 - val_loss: 1.3214 - val_accuracy: 0.5950\n","Epoch 52/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2476 - accuracy: 0.6643 - val_loss: 1.3166 - val_accuracy: 0.6002\n","Epoch 53/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.2369 - accuracy: 0.6687 - val_loss: 1.3111 - val_accuracy: 0.6023\n","Epoch 54/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.2290 - accuracy: 0.6713 - val_loss: 1.3028 - val_accuracy: 0.5940\n","Epoch 55/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2180 - accuracy: 0.6726 - val_loss: 1.2981 - val_accuracy: 0.5940\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.2084 - accuracy: 0.6752 - val_loss: 1.2936 - val_accuracy: 0.5981\n","Epoch 57/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.2027 - accuracy: 0.6729 - val_loss: 1.2896 - val_accuracy: 0.6054\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1920 - accuracy: 0.6783 - val_loss: 1.2816 - val_accuracy: 0.6033\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1821 - accuracy: 0.6755 - val_loss: 1.2765 - val_accuracy: 0.6064\n","Epoch 60/100\n","31/31 [==============================] - 0s 12ms/step - loss: 1.1732 - accuracy: 0.6804 - val_loss: 1.2731 - val_accuracy: 0.5992\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1679 - accuracy: 0.6809 - val_loss: 1.2740 - val_accuracy: 0.6012\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1568 - accuracy: 0.6876 - val_loss: 1.2704 - val_accuracy: 0.5930\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1481 - accuracy: 0.6806 - val_loss: 1.2587 - val_accuracy: 0.6054\n","Epoch 64/100\n","31/31 [==============================] - 2s 50ms/step - loss: 1.1407 - accuracy: 0.6920 - val_loss: 1.2549 - val_accuracy: 0.6095\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.1303 - accuracy: 0.6943 - val_loss: 1.2559 - val_accuracy: 0.6074\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1238 - accuracy: 0.6907 - val_loss: 1.2485 - val_accuracy: 0.5971\n","Epoch 67/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1150 - accuracy: 0.6933 - val_loss: 1.2456 - val_accuracy: 0.6136\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1057 - accuracy: 0.7016 - val_loss: 1.2434 - val_accuracy: 0.6095\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0967 - accuracy: 0.7044 - val_loss: 1.2369 - val_accuracy: 0.6033\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.0884 - accuracy: 0.7070 - val_loss: 1.2379 - val_accuracy: 0.6012\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0850 - accuracy: 0.7078 - val_loss: 1.2431 - val_accuracy: 0.5899\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0746 - accuracy: 0.7065 - val_loss: 1.2274 - val_accuracy: 0.6105\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0659 - accuracy: 0.7132 - val_loss: 1.2269 - val_accuracy: 0.6033\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0585 - accuracy: 0.7168 - val_loss: 1.2285 - val_accuracy: 0.6054\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 1.0506 - accuracy: 0.7173 - val_loss: 1.2195 - val_accuracy: 0.6064\n","Epoch 76/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0433 - accuracy: 0.7225 - val_loss: 1.2211 - val_accuracy: 0.6064\n","Epoch 77/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0360 - accuracy: 0.7243 - val_loss: 1.2252 - val_accuracy: 0.6002\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0311 - accuracy: 0.7186 - val_loss: 1.2200 - val_accuracy: 0.6095\n","Epoch 79/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0209 - accuracy: 0.7271 - val_loss: 1.2133 - val_accuracy: 0.6074\n","Epoch 80/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0135 - accuracy: 0.7295 - val_loss: 1.2111 - val_accuracy: 0.6043\n","Epoch 81/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0068 - accuracy: 0.7315 - val_loss: 1.2106 - val_accuracy: 0.6095\n","Epoch 82/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9992 - accuracy: 0.7326 - val_loss: 1.2092 - val_accuracy: 0.6043\n","Epoch 83/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9934 - accuracy: 0.7328 - val_loss: 1.2074 - val_accuracy: 0.6064\n","Epoch 84/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9907 - accuracy: 0.7313 - val_loss: 1.2054 - val_accuracy: 0.6043\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9809 - accuracy: 0.7408 - val_loss: 1.2166 - val_accuracy: 0.6085\n","Epoch 86/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.9731 - accuracy: 0.7406 - val_loss: 1.2085 - val_accuracy: 0.5961\n","Epoch 87/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9655 - accuracy: 0.7413 - val_loss: 1.2100 - val_accuracy: 0.6023\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9596 - accuracy: 0.7444 - val_loss: 1.2020 - val_accuracy: 0.5981\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9517 - accuracy: 0.7501 - val_loss: 1.2031 - val_accuracy: 0.6043\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9488 - accuracy: 0.7444 - val_loss: 1.2105 - val_accuracy: 0.6064\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9407 - accuracy: 0.7514 - val_loss: 1.1990 - val_accuracy: 0.5971\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9322 - accuracy: 0.7535 - val_loss: 1.2051 - val_accuracy: 0.6002\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9262 - accuracy: 0.7556 - val_loss: 1.2023 - val_accuracy: 0.6002\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9213 - accuracy: 0.7556 - val_loss: 1.1992 - val_accuracy: 0.6033\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9165 - accuracy: 0.7581 - val_loss: 1.2200 - val_accuracy: 0.6002\n","Epoch 96/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9222 - accuracy: 0.7514 - val_loss: 1.2232 - val_accuracy: 0.6033\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.9070 - accuracy: 0.7607 - val_loss: 1.2030 - val_accuracy: 0.5981\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8953 - accuracy: 0.7674 - val_loss: 1.2034 - val_accuracy: 0.5909\n","Epoch 99/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8898 - accuracy: 0.7669 - val_loss: 1.2044 - val_accuracy: 0.5940\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8865 - accuracy: 0.7718 - val_loss: 1.1984 - val_accuracy: 0.6023\n","{'loss': [1.9587222337722778, 1.9354336261749268, 1.914847731590271, 1.895058035850525, 1.8756452798843384, 1.8565446138381958, 1.8378440141677856, 1.8193026781082153, 1.8011960983276367, 1.7831274271011353, 1.7652307748794556, 1.747894287109375, 1.7304692268371582, 1.7130446434020996, 1.6964811086654663, 1.6791613101959229, 1.6632134914398193, 1.6468435525894165, 1.6320210695266724, 1.6164180040359497, 1.6024866104125977, 1.5870622396469116, 1.5727250576019287, 1.5591833591461182, 1.546147108078003, 1.5320500135421753, 1.5193758010864258, 1.506949543952942, 1.4943238496780396, 1.4827789068222046, 1.4691556692123413, 1.4572954177856445, 1.4458810091018677, 1.4338632822036743, 1.4225527048110962, 1.411645770072937, 1.4012813568115234, 1.3892072439193726, 1.3786393404006958, 1.367849349975586, 1.356857180595398, 1.3470187187194824, 1.3379080295562744, 1.3261438608169556, 1.316854476928711, 1.3056061267852783, 1.2950339317321777, 1.284886121749878, 1.2776572704315186, 1.2664921283721924, 1.2571676969528198, 1.2475814819335938, 1.236891269683838, 1.2289865016937256, 1.2179938554763794, 1.2084269523620605, 1.2026731967926025, 1.1919869184494019, 1.1820694208145142, 1.1731925010681152, 1.1679425239562988, 1.156773567199707, 1.1480646133422852, 1.1407277584075928, 1.1303189992904663, 1.1237947940826416, 1.115012526512146, 1.1057405471801758, 1.096714973449707, 1.088428258895874, 1.0850492715835571, 1.0745774507522583, 1.0658618211746216, 1.0584863424301147, 1.050635576248169, 1.0433193445205688, 1.035959005355835, 1.0311262607574463, 1.0209134817123413, 1.013476014137268, 1.0068283081054688, 0.9992303848266602, 0.9934282898902893, 0.9907463788986206, 0.9809131622314453, 0.9730808734893799, 0.9655490517616272, 0.959645688533783, 0.9516965746879578, 0.9487630724906921, 0.9406532645225525, 0.9321514964103699, 0.926205575466156, 0.9212977290153503, 0.9164705872535706, 0.9222097992897034, 0.9069957733154297, 0.8953275680541992, 0.8897976279258728, 0.8864884972572327], 'accuracy': [0.5134366750717163, 0.5315245389938354, 0.5441860556602478, 0.5581395626068115, 0.5695090293884277, 0.5689922571182251, 0.5720930099487305, 0.5687338709831238, 0.5772609710693359, 0.5767441987991333, 0.5855297446250916, 0.589664101600647, 0.5894056558609009, 0.5953488349914551, 0.5953488349914551, 0.6005167961120605, 0.6005167961120605, 0.6033591628074646, 0.603875994682312, 0.6082687377929688, 0.6080103516578674, 0.6144703030586243, 0.6131783127784729, 0.6183462738990784, 0.6183462738990784, 0.620671808719635, 0.617829442024231, 0.619896650314331, 0.6237726211547852, 0.618863046169281, 0.6273902058601379, 0.6266149878501892, 0.6255813837051392, 0.6315245628356934, 0.631266176700592, 0.630232572555542, 0.6346253156661987, 0.6271317601203918, 0.6397932767868042, 0.6379845142364502, 0.6392765045166016, 0.6413436532020569, 0.645219624042511, 0.6488372087478638, 0.6472868323326111, 0.6532299518585205, 0.6519379615783691, 0.6586563587188721, 0.6514211893081665, 0.6604651212692261, 0.6604651212692261, 0.6643410921096802, 0.6687338352203369, 0.6713178157806396, 0.672609806060791, 0.6751937866210938, 0.6728681921958923, 0.6782945990562439, 0.6754521727561951, 0.6803617477416992, 0.6808785796165466, 0.6875969171524048, 0.6806201338768005, 0.6919896602630615, 0.6943152546882629, 0.6906976699829102, 0.6932816505432129, 0.7015503644943237, 0.7043927907943726, 0.7069767713546753, 0.7077519297599792, 0.7064599394798279, 0.713178277015686, 0.7167958617210388, 0.7173126339912415, 0.7224805951118469, 0.7242894172668457, 0.7186046242713928, 0.7271317839622498, 0.7294573783874512, 0.7315245270729065, 0.7325581312179565, 0.7328165173530579, 0.7312661409378052, 0.7408268451690674, 0.7405684590339661, 0.7413436770439148, 0.7444444298744202, 0.750129222869873, 0.7444444298744202, 0.7514212131500244, 0.7534883618354797, 0.7555555701255798, 0.7555555701255798, 0.7581395506858826, 0.7514212131500244, 0.7607235312461853, 0.7674418687820435, 0.766925036907196, 0.7718346118927002], 'val_loss': [1.9518709182739258, 1.932455062866211, 1.9134243726730347, 1.8946274518966675, 1.8762092590332031, 1.8582022190093994, 1.8402647972106934, 1.822634220123291, 1.8053898811340332, 1.7882602214813232, 1.7714803218841553, 1.7544316053390503, 1.7380297183990479, 1.7210755348205566, 1.7050185203552246, 1.6884995698928833, 1.6728333234786987, 1.6576042175292969, 1.6416617631912231, 1.6270270347595215, 1.6146224737167358, 1.5983543395996094, 1.585317850112915, 1.573158860206604, 1.5598114728927612, 1.5485140085220337, 1.5384331941604614, 1.5270044803619385, 1.5118683576583862, 1.5070253610610962, 1.4916002750396729, 1.480700969696045, 1.4705252647399902, 1.4615851640701294, 1.4500352144241333, 1.4456738233566284, 1.438739538192749, 1.4247900247573853, 1.4127023220062256, 1.4034669399261475, 1.3956061601638794, 1.3864058256149292, 1.3797096014022827, 1.3713765144348145, 1.3633205890655518, 1.3563413619995117, 1.3517543077468872, 1.3555389642715454, 1.3338865041732788, 1.3339219093322754, 1.3214175701141357, 1.3165513277053833, 1.3111311197280884, 1.3027592897415161, 1.2980543375015259, 1.2936331033706665, 1.2895981073379517, 1.281614899635315, 1.2765363454818726, 1.2731362581253052, 1.273979902267456, 1.270393967628479, 1.2587323188781738, 1.2549177408218384, 1.2559274435043335, 1.2485263347625732, 1.245550274848938, 1.243368148803711, 1.2368618249893188, 1.2379236221313477, 1.243143081665039, 1.2273837327957153, 1.2269279956817627, 1.2285069227218628, 1.219478726387024, 1.2211430072784424, 1.2251546382904053, 1.220042109489441, 1.213315486907959, 1.2110888957977295, 1.2106049060821533, 1.2092477083206177, 1.207403540611267, 1.20537269115448, 1.2166274785995483, 1.208465814590454, 1.2099865674972534, 1.2020174264907837, 1.2031089067459106, 1.2104592323303223, 1.1989916563034058, 1.2050786018371582, 1.202345371246338, 1.1991554498672485, 1.220030426979065, 1.2231545448303223, 1.2030065059661865, 1.2034342288970947, 1.2044081687927246, 1.198425531387329], 'val_accuracy': [0.56611567735672, 0.5733470916748047, 0.547520637512207, 0.53925621509552, 0.5413222908973694, 0.5402892827987671, 0.5413222908973694, 0.5423553586006165, 0.5444214940071106, 0.5413222908973694, 0.5423553586006165, 0.5516529083251953, 0.5526859760284424, 0.5640496015548706, 0.5712810158729553, 0.5723140239715576, 0.5733470916748047, 0.5785123705863953, 0.5898760557174683, 0.5919421315193176, 0.58574378490448, 0.5898760557174683, 0.586776852607727, 0.5836777091026306, 0.58574378490448, 0.5919421315193176, 0.5981404781341553, 0.5991735458374023, 0.5898760557174683, 0.5929751992225647, 0.6002066135406494, 0.6022727489471436, 0.6074380278587341, 0.6022727489471436, 0.6022727489471436, 0.6043388247489929, 0.6043388247489929, 0.6022727489471436, 0.6033057570457458, 0.5991735458374023, 0.5981404781341553, 0.5950413346290588, 0.5991735458374023, 0.6002066135406494, 0.586776852607727, 0.6012396812438965, 0.6033057570457458, 0.6022727489471436, 0.5898760557174683, 0.6043388247489929, 0.5950413346290588, 0.6002066135406494, 0.6022727489471436, 0.5940082669258118, 0.5940082669258118, 0.5981404781341553, 0.60537189245224, 0.6033057570457458, 0.6064049601554871, 0.5991735458374023, 0.6012396812438965, 0.5929751992225647, 0.60537189245224, 0.6095041036605835, 0.6074380278587341, 0.5971074104309082, 0.6136363744735718, 0.6095041036605835, 0.6033057570457458, 0.6012396812438965, 0.5898760557174683, 0.6105371713638306, 0.6033057570457458, 0.60537189245224, 0.6064049601554871, 0.6064049601554871, 0.6002066135406494, 0.6095041036605835, 0.6074380278587341, 0.6043388247489929, 0.6095041036605835, 0.6043388247489929, 0.6064049601554871, 0.6043388247489929, 0.6084710955619812, 0.5960744023323059, 0.6022727489471436, 0.5981404781341553, 0.6043388247489929, 0.6064049601554871, 0.5971074104309082, 0.6002066135406494, 0.6002066135406494, 0.6033057570457458, 0.6002066135406494, 0.6033057570457458, 0.5981404781341553, 0.5909090638160706, 0.5940082669258118, 0.6022727489471436]}\n","32/32 [==============================] - 0s 9ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 32ms/step - loss: 0.9829 - accuracy: 0.7101 - val_loss: 1.1462 - val_accuracy: 0.5162\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.9223 - accuracy: 0.7891"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 1s 21ms/step - loss: 0.9674 - accuracy: 0.7239 - val_loss: 1.1312 - val_accuracy: 0.5172\n","Epoch 3/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.9583 - accuracy: 0.7276 - val_loss: 1.1271 - val_accuracy: 0.5183\n","Epoch 4/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9518 - accuracy: 0.7276 - val_loss: 1.1224 - val_accuracy: 0.5216\n","Epoch 5/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.9471 - accuracy: 0.7276 - val_loss: 1.1159 - val_accuracy: 0.5237\n","Epoch 6/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.9379 - accuracy: 0.7360 - val_loss: 1.1204 - val_accuracy: 0.5216\n","Epoch 7/100\n","29/29 [==============================] - 1s 30ms/step - loss: 0.9340 - accuracy: 0.7341 - val_loss: 1.0998 - val_accuracy: 0.5323\n","Epoch 8/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9272 - accuracy: 0.7398 - val_loss: 1.1008 - val_accuracy: 0.5312\n","Epoch 9/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9200 - accuracy: 0.7441 - val_loss: 1.0847 - val_accuracy: 0.5442\n","Epoch 10/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9147 - accuracy: 0.7427 - val_loss: 1.0761 - val_accuracy: 0.5550\n","Epoch 11/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.9081 - accuracy: 0.7500 - val_loss: 1.0781 - val_accuracy: 0.5517\n","Epoch 12/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.9030 - accuracy: 0.7449 - val_loss: 1.0649 - val_accuracy: 0.5647\n","Epoch 13/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8970 - accuracy: 0.7492 - val_loss: 1.0569 - val_accuracy: 0.5765\n","Epoch 14/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8910 - accuracy: 0.7508 - val_loss: 1.0390 - val_accuracy: 0.5905\n","Epoch 15/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8878 - accuracy: 0.7522 - val_loss: 1.0345 - val_accuracy: 0.5981\n","Epoch 16/100\n","29/29 [==============================] - 1s 34ms/step - loss: 0.8799 - accuracy: 0.7578 - val_loss: 1.0290 - val_accuracy: 0.6024\n","Epoch 17/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.8779 - accuracy: 0.7527 - val_loss: 1.0060 - val_accuracy: 0.6422\n","Epoch 18/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8730 - accuracy: 0.7513 - val_loss: 1.0069 - val_accuracy: 0.6369\n","Epoch 19/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8662 - accuracy: 0.7600 - val_loss: 1.0031 - val_accuracy: 0.6336\n","Epoch 20/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.8642 - accuracy: 0.7554 - val_loss: 0.9865 - val_accuracy: 0.6466\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8595 - accuracy: 0.7629 - val_loss: 0.9805 - val_accuracy: 0.6584\n","Epoch 22/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8540 - accuracy: 0.7645 - val_loss: 0.9759 - val_accuracy: 0.6670\n","Epoch 23/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8454 - accuracy: 0.7670 - val_loss: 0.9763 - val_accuracy: 0.6584\n","Epoch 24/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8398 - accuracy: 0.7643 - val_loss: 0.9765 - val_accuracy: 0.6562\n","Epoch 25/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8347 - accuracy: 0.7694 - val_loss: 0.9725 - val_accuracy: 0.6649\n","Epoch 26/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.8309 - accuracy: 0.7716 - val_loss: 0.9798 - val_accuracy: 0.6627\n","Epoch 27/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8241 - accuracy: 0.7753 - val_loss: 0.9734 - val_accuracy: 0.6735\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8204 - accuracy: 0.7756 - val_loss: 0.9742 - val_accuracy: 0.6724\n","Epoch 29/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8147 - accuracy: 0.7831 - val_loss: 0.9820 - val_accuracy: 0.6584\n","Epoch 30/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8150 - accuracy: 0.7753 - val_loss: 0.9758 - val_accuracy: 0.6616\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8106 - accuracy: 0.7796 - val_loss: 0.9787 - val_accuracy: 0.6638\n","Epoch 32/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8019 - accuracy: 0.7791 - val_loss: 0.9808 - val_accuracy: 0.6659\n","Epoch 33/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8003 - accuracy: 0.7818 - val_loss: 0.9855 - val_accuracy: 0.6562\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7939 - accuracy: 0.7885 - val_loss: 0.9806 - val_accuracy: 0.6638\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7881 - accuracy: 0.7923 - val_loss: 0.9834 - val_accuracy: 0.6670\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7844 - accuracy: 0.7923 - val_loss: 0.9893 - val_accuracy: 0.6659\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7821 - accuracy: 0.7918 - val_loss: 0.9842 - val_accuracy: 0.6552\n","Epoch 38/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7755 - accuracy: 0.7942 - val_loss: 0.9852 - val_accuracy: 0.6638\n","Epoch 39/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7694 - accuracy: 0.7945 - val_loss: 0.9887 - val_accuracy: 0.6616\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7650 - accuracy: 0.8015 - val_loss: 0.9869 - val_accuracy: 0.6627\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7614 - accuracy: 0.8004 - val_loss: 0.9893 - val_accuracy: 0.6638\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7595 - accuracy: 0.7955 - val_loss: 0.9931 - val_accuracy: 0.6627\n","Epoch 43/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7525 - accuracy: 0.8028 - val_loss: 0.9898 - val_accuracy: 0.6616\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7499 - accuracy: 0.8036 - val_loss: 1.0015 - val_accuracy: 0.6659\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7430 - accuracy: 0.8055 - val_loss: 0.9923 - val_accuracy: 0.6595\n","Epoch 46/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7382 - accuracy: 0.8117 - val_loss: 0.9970 - val_accuracy: 0.6692\n","Epoch 47/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7353 - accuracy: 0.8125 - val_loss: 1.0023 - val_accuracy: 0.6692\n","Epoch 48/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7309 - accuracy: 0.8155 - val_loss: 1.0056 - val_accuracy: 0.6562\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7281 - accuracy: 0.8149 - val_loss: 0.9988 - val_accuracy: 0.6659\n","Epoch 50/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7236 - accuracy: 0.8136 - val_loss: 1.0023 - val_accuracy: 0.6638\n","Epoch 51/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7190 - accuracy: 0.8227 - val_loss: 1.0029 - val_accuracy: 0.6573\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7216 - accuracy: 0.8136 - val_loss: 1.0073 - val_accuracy: 0.6670\n","Epoch 53/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7108 - accuracy: 0.8217 - val_loss: 1.0084 - val_accuracy: 0.6573\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7065 - accuracy: 0.8241 - val_loss: 1.0187 - val_accuracy: 0.6649\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.7030 - accuracy: 0.8284 - val_loss: 1.0027 - val_accuracy: 0.6616\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6989 - accuracy: 0.8279 - val_loss: 1.0203 - val_accuracy: 0.6616\n","Epoch 57/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6952 - accuracy: 0.8289 - val_loss: 1.0189 - val_accuracy: 0.6530\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6886 - accuracy: 0.8332 - val_loss: 1.0168 - val_accuracy: 0.6584\n","Epoch 59/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6861 - accuracy: 0.8316 - val_loss: 1.0167 - val_accuracy: 0.6498\n","Epoch 60/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6828 - accuracy: 0.8389 - val_loss: 1.0267 - val_accuracy: 0.6649\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6760 - accuracy: 0.8376 - val_loss: 1.0367 - val_accuracy: 0.6519\n","Epoch 62/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6771 - accuracy: 0.8373 - val_loss: 1.0359 - val_accuracy: 0.6627\n","Epoch 63/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6788 - accuracy: 0.8376 - val_loss: 1.0167 - val_accuracy: 0.6616\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6709 - accuracy: 0.8402 - val_loss: 1.0377 - val_accuracy: 0.6595\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6625 - accuracy: 0.8470 - val_loss: 1.0366 - val_accuracy: 0.6584\n","Epoch 66/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6606 - accuracy: 0.8438 - val_loss: 1.0433 - val_accuracy: 0.6638\n","Epoch 67/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6571 - accuracy: 0.8486 - val_loss: 1.0333 - val_accuracy: 0.6584\n","Epoch 68/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6525 - accuracy: 0.8513 - val_loss: 1.0563 - val_accuracy: 0.6552\n","Epoch 69/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6503 - accuracy: 0.8475 - val_loss: 1.0388 - val_accuracy: 0.6713\n","Epoch 70/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6442 - accuracy: 0.8534 - val_loss: 1.0611 - val_accuracy: 0.6530\n","Epoch 71/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6491 - accuracy: 0.8464 - val_loss: 1.0609 - val_accuracy: 0.6509\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6421 - accuracy: 0.8526 - val_loss: 1.0729 - val_accuracy: 0.6627\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6374 - accuracy: 0.8529 - val_loss: 1.0475 - val_accuracy: 0.6562\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6329 - accuracy: 0.8543 - val_loss: 1.0576 - val_accuracy: 0.6562\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6281 - accuracy: 0.8572 - val_loss: 1.0622 - val_accuracy: 0.6509\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6254 - accuracy: 0.8640 - val_loss: 1.0803 - val_accuracy: 0.6562\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6246 - accuracy: 0.8596 - val_loss: 1.0571 - val_accuracy: 0.6573\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6178 - accuracy: 0.8653 - val_loss: 1.0703 - val_accuracy: 0.6519\n","Epoch 79/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6154 - accuracy: 0.8672 - val_loss: 1.0875 - val_accuracy: 0.6552\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6110 - accuracy: 0.8664 - val_loss: 1.0650 - val_accuracy: 0.6562\n","Epoch 81/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6069 - accuracy: 0.8672 - val_loss: 1.0869 - val_accuracy: 0.6519\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.6043 - accuracy: 0.8715 - val_loss: 1.0760 - val_accuracy: 0.6573\n","Epoch 83/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6012 - accuracy: 0.8712 - val_loss: 1.0928 - val_accuracy: 0.6562\n","Epoch 84/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5994 - accuracy: 0.8761 - val_loss: 1.0973 - val_accuracy: 0.6541\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5963 - accuracy: 0.8723 - val_loss: 1.1026 - val_accuracy: 0.6476\n","Epoch 86/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5989 - accuracy: 0.8680 - val_loss: 1.0957 - val_accuracy: 0.6584\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5900 - accuracy: 0.8798 - val_loss: 1.0947 - val_accuracy: 0.6595\n","Epoch 88/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5879 - accuracy: 0.8793 - val_loss: 1.0982 - val_accuracy: 0.6552\n","Epoch 89/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5935 - accuracy: 0.8747 - val_loss: 1.1142 - val_accuracy: 0.6455\n","Epoch 90/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5963 - accuracy: 0.8631 - val_loss: 1.1159 - val_accuracy: 0.6562\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5809 - accuracy: 0.8763 - val_loss: 1.1114 - val_accuracy: 0.6541\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5802 - accuracy: 0.8836 - val_loss: 1.1244 - val_accuracy: 0.6552\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5848 - accuracy: 0.8693 - val_loss: 1.1046 - val_accuracy: 0.6552\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5733 - accuracy: 0.8812 - val_loss: 1.1292 - val_accuracy: 0.6541\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5709 - accuracy: 0.8815 - val_loss: 1.1257 - val_accuracy: 0.6573\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5631 - accuracy: 0.8901 - val_loss: 1.1265 - val_accuracy: 0.6412\n","Epoch 97/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5594 - accuracy: 0.8890 - val_loss: 1.1240 - val_accuracy: 0.6476\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5561 - accuracy: 0.8922 - val_loss: 1.1321 - val_accuracy: 0.6552\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5539 - accuracy: 0.8952 - val_loss: 1.1393 - val_accuracy: 0.6444\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5587 - accuracy: 0.8893 - val_loss: 1.1615 - val_accuracy: 0.6552\n","{'loss': [0.9829477071762085, 0.9673784971237183, 0.9582682847976685, 0.9518189430236816, 0.9470961093902588, 0.9379078149795532, 0.9339584708213806, 0.9272473454475403, 0.9199939370155334, 0.9146995544433594, 0.9080857634544373, 0.9029659628868103, 0.897045373916626, 0.8910263180732727, 0.8878288269042969, 0.8798968195915222, 0.877878725528717, 0.8729979991912842, 0.8661597967147827, 0.8641899824142456, 0.8594745993614197, 0.8540021181106567, 0.8454229235649109, 0.8397623896598816, 0.8347188234329224, 0.8309311270713806, 0.8240895867347717, 0.8203659057617188, 0.8147279024124146, 0.8150382041931152, 0.8105888366699219, 0.8019411563873291, 0.8003010749816895, 0.7939093112945557, 0.788054883480072, 0.7843945026397705, 0.7820631861686707, 0.7755324244499207, 0.7693589329719543, 0.764957845211029, 0.7613572478294373, 0.7595149874687195, 0.7524780631065369, 0.7498798966407776, 0.7430265545845032, 0.7382333278656006, 0.7352550625801086, 0.7309253811836243, 0.7280571460723877, 0.723553478717804, 0.7189505100250244, 0.7215752601623535, 0.7107641696929932, 0.7065234780311584, 0.7029517889022827, 0.6989373564720154, 0.6952204704284668, 0.6886443495750427, 0.6860966682434082, 0.6828047633171082, 0.675981879234314, 0.6771339774131775, 0.6787810921669006, 0.670866847038269, 0.6624779105186462, 0.6605616211891174, 0.6571453213691711, 0.6524772047996521, 0.6502957344055176, 0.6442030668258667, 0.6491143703460693, 0.6420766115188599, 0.6373655796051025, 0.6329261660575867, 0.6281431317329407, 0.6254092454910278, 0.6245837807655334, 0.6178196668624878, 0.6154180765151978, 0.6109878420829773, 0.6068682074546814, 0.6042501926422119, 0.6012110114097595, 0.5993978381156921, 0.5962837338447571, 0.598871111869812, 0.5899789333343506, 0.5878624320030212, 0.5935244560241699, 0.596257746219635, 0.580901026725769, 0.5801556706428528, 0.5848472714424133, 0.5732686519622803, 0.5709319114685059, 0.5630815625190735, 0.5594187378883362, 0.5561318397521973, 0.5538869500160217, 0.5586599111557007], 'accuracy': [0.7101293206214905, 0.7238685488700867, 0.7276400923728943, 0.7276400923728943, 0.7276400923728943, 0.735991358757019, 0.7341055870056152, 0.7397629022598267, 0.7440732717514038, 0.7427262663841248, 0.75, 0.7448814511299133, 0.7491918206214905, 0.7508081793785095, 0.7521551847457886, 0.7578125, 0.7526939511299133, 0.751347005367279, 0.7599676847457886, 0.7553879022598267, 0.7629310488700867, 0.7645474076271057, 0.766972005367279, 0.764277994632721, 0.7693965435028076, 0.7715517282485962, 0.7753232717514038, 0.7755926847457886, 0.7831357717514038, 0.7753232717514038, 0.779633641242981, 0.7790948152542114, 0.7817887663841248, 0.7885237336158752, 0.7922952771186829, 0.7922952771186829, 0.7917564511299133, 0.7941810488700867, 0.7944504022598267, 0.8014547228813171, 0.8003771305084229, 0.795527994632721, 0.8028017282485962, 0.8036099076271057, 0.8054956793785095, 0.8116918206214905, 0.8125, 0.8154633641242981, 0.8149245977401733, 0.8135775923728943, 0.8227370977401733, 0.8135775923728943, 0.821659505367279, 0.8240840435028076, 0.8283944129943848, 0.8278555870056152, 0.8289331793785095, 0.8332435488700867, 0.8316271305084229, 0.8389008641242981, 0.837553858757019, 0.837284505367279, 0.837553858757019, 0.8402478694915771, 0.8469827771186829, 0.84375, 0.8485991358757019, 0.8512930870056152, 0.8475215435028076, 0.8534482717514038, 0.8464439511299133, 0.8526400923728943, 0.852909505367279, 0.8542564511299133, 0.8572198152542114, 0.8639547228813171, 0.8596444129943848, 0.8653017282485962, 0.8671875, 0.8663793206214905, 0.8671875, 0.8714978694915771, 0.8712284564971924, 0.8760775923728943, 0.8723060488700867, 0.8679956793785095, 0.8798491358757019, 0.8793103694915771, 0.8747305870056152, 0.8631465435028076, 0.876347005367279, 0.8836206793785095, 0.8693426847457886, 0.881196141242981, 0.881465494632721, 0.8900862336158752, 0.889008641242981, 0.892241358757019, 0.8952047228813171, 0.889277994632721], 'val_loss': [1.1461690664291382, 1.1312062740325928, 1.1271030902862549, 1.1224173307418823, 1.1158736944198608, 1.1204211711883545, 1.0998435020446777, 1.1008059978485107, 1.0847275257110596, 1.0760647058486938, 1.0781208276748657, 1.0648517608642578, 1.056878924369812, 1.0390323400497437, 1.034512996673584, 1.0289677381515503, 1.0059510469436646, 1.0069339275360107, 1.0030564069747925, 0.9864648580551147, 0.9805346727371216, 0.9758974313735962, 0.9763348698616028, 0.9765172600746155, 0.9724898338317871, 0.9797531366348267, 0.9733951091766357, 0.9742386937141418, 0.9820272922515869, 0.9757992029190063, 0.9787288308143616, 0.9807747602462769, 0.9854557514190674, 0.9805675148963928, 0.9834228157997131, 0.9893429279327393, 0.9841791987419128, 0.9852174520492554, 0.9886748194694519, 0.9869424104690552, 0.9893265962600708, 0.9930755496025085, 0.9897980093955994, 1.0015499591827393, 0.9923475384712219, 0.9970192313194275, 1.0022529363632202, 1.0055660009384155, 0.9988229274749756, 1.0023183822631836, 1.0029469728469849, 1.0073262453079224, 1.00838041305542, 1.0187206268310547, 1.0026977062225342, 1.020268201828003, 1.018890619277954, 1.0168225765228271, 1.016740322113037, 1.0267127752304077, 1.0366798639297485, 1.0358539819717407, 1.0166975259780884, 1.0376827716827393, 1.036582350730896, 1.0433251857757568, 1.0333366394042969, 1.056254506111145, 1.038849949836731, 1.0610767602920532, 1.0609285831451416, 1.0729092359542847, 1.0475165843963623, 1.057583212852478, 1.06223464012146, 1.0802909135818481, 1.0570985078811646, 1.0703434944152832, 1.0875484943389893, 1.0650461912155151, 1.0868617296218872, 1.0759867429733276, 1.0927985906600952, 1.0973089933395386, 1.1026129722595215, 1.0956696271896362, 1.0946738719940186, 1.0982308387756348, 1.114245891571045, 1.1158584356307983, 1.1114376783370972, 1.1243693828582764, 1.1045784950256348, 1.129218578338623, 1.1257448196411133, 1.1265140771865845, 1.1240416765213013, 1.1320892572402954, 1.1393399238586426, 1.1615287065505981], 'val_accuracy': [0.5161637663841248, 0.517241358757019, 0.5183189511299133, 0.5215517282485962, 0.5237069129943848, 0.5215517282485962, 0.5323275923728943, 0.53125, 0.5441810488700867, 0.5549569129943848, 0.5517241358757019, 0.5646551847457886, 0.576508641242981, 0.5905172228813171, 0.5980603694915771, 0.6023706793785095, 0.642241358757019, 0.6368534564971924, 0.6336206793785095, 0.6465517282485962, 0.6584051847457886, 0.6670258641242981, 0.6584051847457886, 0.65625, 0.6648706793785095, 0.662715494632721, 0.673491358757019, 0.6724137663841248, 0.6584051847457886, 0.6616379022598267, 0.6637930870056152, 0.6659482717514038, 0.65625, 0.6637930870056152, 0.6670258641242981, 0.6659482717514038, 0.6551724076271057, 0.6637930870056152, 0.6616379022598267, 0.662715494632721, 0.6637930870056152, 0.662715494632721, 0.6616379022598267, 0.6659482717514038, 0.6594827771186829, 0.6691810488700867, 0.6691810488700867, 0.65625, 0.6659482717514038, 0.6637930870056152, 0.6573275923728943, 0.6670258641242981, 0.6573275923728943, 0.6648706793785095, 0.6616379022598267, 0.6616379022598267, 0.6530172228813171, 0.6584051847457886, 0.649784505367279, 0.6648706793785095, 0.6519396305084229, 0.662715494632721, 0.6616379022598267, 0.6594827771186829, 0.6584051847457886, 0.6637930870056152, 0.6584051847457886, 0.6551724076271057, 0.6713362336158752, 0.6530172228813171, 0.6508620977401733, 0.662715494632721, 0.65625, 0.65625, 0.6508620977401733, 0.65625, 0.6573275923728943, 0.6519396305084229, 0.6551724076271057, 0.65625, 0.6519396305084229, 0.6573275923728943, 0.65625, 0.6540948152542114, 0.6476293206214905, 0.6584051847457886, 0.6594827771186829, 0.6551724076271057, 0.6454741358757019, 0.65625, 0.6540948152542114, 0.6551724076271057, 0.6551724076271057, 0.6540948152542114, 0.6573275923728943, 0.6411637663841248, 0.6476293206214905, 0.6551724076271057, 0.6443965435028076, 0.6551724076271057]}\n","38/38 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 34ms/step - loss: 0.9856 - accuracy: 0.7080 - val_loss: 1.1488 - val_accuracy: 0.5057\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.9707 - accuracy: 0.7500"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 14ms/step - loss: 0.9719 - accuracy: 0.7204 - val_loss: 1.1328 - val_accuracy: 0.5045\n","Epoch 3/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9687 - accuracy: 0.7182 - val_loss: 1.1347 - val_accuracy: 0.5045\n","Epoch 4/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9580 - accuracy: 0.7244 - val_loss: 1.1218 - val_accuracy: 0.5057\n","Epoch 5/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9506 - accuracy: 0.7301 - val_loss: 1.1195 - val_accuracy: 0.5079\n","Epoch 6/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9460 - accuracy: 0.7329 - val_loss: 1.1090 - val_accuracy: 0.5158\n","Epoch 7/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.9415 - accuracy: 0.7298 - val_loss: 1.1093 - val_accuracy: 0.5158\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9316 - accuracy: 0.7366 - val_loss: 1.1020 - val_accuracy: 0.5181\n","Epoch 9/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.9267 - accuracy: 0.7388 - val_loss: 1.1027 - val_accuracy: 0.5215\n","Epoch 10/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9208 - accuracy: 0.7397 - val_loss: 1.0955 - val_accuracy: 0.5305\n","Epoch 11/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.9146 - accuracy: 0.7431 - val_loss: 1.0830 - val_accuracy: 0.5486\n","Epoch 12/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9125 - accuracy: 0.7411 - val_loss: 1.0831 - val_accuracy: 0.5475\n","Epoch 13/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.9068 - accuracy: 0.7431 - val_loss: 1.0713 - val_accuracy: 0.5543\n","Epoch 14/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.9012 - accuracy: 0.7453 - val_loss: 1.0552 - val_accuracy: 0.5803\n","Epoch 15/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.8926 - accuracy: 0.7496 - val_loss: 1.0481 - val_accuracy: 0.5916\n","Epoch 16/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.8876 - accuracy: 0.7530 - val_loss: 1.0452 - val_accuracy: 0.5984\n","Epoch 17/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.8819 - accuracy: 0.7566 - val_loss: 1.0247 - val_accuracy: 0.6165\n","Epoch 18/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.8818 - accuracy: 0.7535 - val_loss: 1.0147 - val_accuracy: 0.6369\n","Epoch 19/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8720 - accuracy: 0.7606 - val_loss: 1.0128 - val_accuracy: 0.6346\n","Epoch 20/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8659 - accuracy: 0.7578 - val_loss: 1.0210 - val_accuracy: 0.6267\n","Epoch 21/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8614 - accuracy: 0.7632 - val_loss: 1.0079 - val_accuracy: 0.6471\n","Epoch 22/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8564 - accuracy: 0.7649 - val_loss: 1.0070 - val_accuracy: 0.6437\n","Epoch 23/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8508 - accuracy: 0.7583 - val_loss: 0.9948 - val_accuracy: 0.6584\n","Epoch 24/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8475 - accuracy: 0.7680 - val_loss: 0.9944 - val_accuracy: 0.6572\n","Epoch 25/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8400 - accuracy: 0.7714 - val_loss: 0.9957 - val_accuracy: 0.6606\n","Epoch 26/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.8385 - accuracy: 0.7714 - val_loss: 0.9944 - val_accuracy: 0.6663\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8307 - accuracy: 0.7770 - val_loss: 0.9962 - val_accuracy: 0.6663\n","Epoch 28/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8265 - accuracy: 0.7719 - val_loss: 1.0012 - val_accuracy: 0.6538\n","Epoch 29/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8203 - accuracy: 0.7796 - val_loss: 1.0054 - val_accuracy: 0.6629\n","Epoch 30/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8165 - accuracy: 0.7816 - val_loss: 1.0063 - val_accuracy: 0.6674\n","Epoch 31/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8124 - accuracy: 0.7816 - val_loss: 1.0047 - val_accuracy: 0.6629\n","Epoch 32/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8058 - accuracy: 0.7849 - val_loss: 1.0077 - val_accuracy: 0.6686\n","Epoch 33/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8047 - accuracy: 0.7838 - val_loss: 1.0061 - val_accuracy: 0.6731\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7986 - accuracy: 0.7892 - val_loss: 1.0076 - val_accuracy: 0.6697\n","Epoch 35/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7921 - accuracy: 0.7878 - val_loss: 1.0094 - val_accuracy: 0.6652\n","Epoch 36/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7871 - accuracy: 0.7903 - val_loss: 1.0117 - val_accuracy: 0.6674\n","Epoch 37/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7830 - accuracy: 0.7920 - val_loss: 1.0129 - val_accuracy: 0.6686\n","Epoch 38/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7762 - accuracy: 0.8002 - val_loss: 1.0127 - val_accuracy: 0.6652\n","Epoch 39/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7740 - accuracy: 0.7985 - val_loss: 1.0169 - val_accuracy: 0.6595\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7685 - accuracy: 0.7977 - val_loss: 1.0163 - val_accuracy: 0.6674\n","Epoch 41/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7643 - accuracy: 0.8008 - val_loss: 1.0248 - val_accuracy: 0.6550\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7587 - accuracy: 0.8019 - val_loss: 1.0239 - val_accuracy: 0.6584\n","Epoch 43/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7624 - accuracy: 0.7971 - val_loss: 1.0270 - val_accuracy: 0.6640\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7545 - accuracy: 0.8073 - val_loss: 1.0232 - val_accuracy: 0.6674\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7491 - accuracy: 0.8104 - val_loss: 1.0235 - val_accuracy: 0.6584\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7485 - accuracy: 0.8059 - val_loss: 1.0219 - val_accuracy: 0.6561\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7381 - accuracy: 0.8147 - val_loss: 1.0353 - val_accuracy: 0.6595\n","Epoch 48/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7391 - accuracy: 0.8141 - val_loss: 1.0335 - val_accuracy: 0.6572\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7307 - accuracy: 0.8164 - val_loss: 1.0573 - val_accuracy: 0.6561\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7318 - accuracy: 0.8169 - val_loss: 1.0416 - val_accuracy: 0.6618\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7200 - accuracy: 0.8203 - val_loss: 1.0276 - val_accuracy: 0.6652\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7248 - accuracy: 0.8178 - val_loss: 1.0411 - val_accuracy: 0.6663\n","Epoch 53/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7124 - accuracy: 0.8308 - val_loss: 1.0372 - val_accuracy: 0.6686\n","Epoch 54/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7104 - accuracy: 0.8226 - val_loss: 1.0415 - val_accuracy: 0.6697\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7062 - accuracy: 0.8297 - val_loss: 1.0493 - val_accuracy: 0.6674\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7005 - accuracy: 0.8331 - val_loss: 1.0441 - val_accuracy: 0.6697\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7017 - accuracy: 0.8316 - val_loss: 1.0583 - val_accuracy: 0.6674\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6918 - accuracy: 0.8356 - val_loss: 1.0500 - val_accuracy: 0.6561\n","Epoch 59/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6920 - accuracy: 0.8353 - val_loss: 1.0481 - val_accuracy: 0.6674\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6873 - accuracy: 0.8404 - val_loss: 1.0430 - val_accuracy: 0.6731\n","Epoch 61/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6940 - accuracy: 0.8257 - val_loss: 1.0651 - val_accuracy: 0.6448\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6881 - accuracy: 0.8379 - val_loss: 1.0718 - val_accuracy: 0.6629\n","Epoch 63/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6782 - accuracy: 0.8452 - val_loss: 1.0756 - val_accuracy: 0.6719\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6830 - accuracy: 0.8376 - val_loss: 1.0596 - val_accuracy: 0.6674\n","Epoch 65/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6723 - accuracy: 0.8435 - val_loss: 1.0618 - val_accuracy: 0.6674\n","Epoch 66/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6650 - accuracy: 0.8452 - val_loss: 1.0584 - val_accuracy: 0.6686\n","Epoch 67/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6621 - accuracy: 0.8472 - val_loss: 1.0713 - val_accuracy: 0.6663\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6621 - accuracy: 0.8509 - val_loss: 1.0679 - val_accuracy: 0.6708\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6558 - accuracy: 0.8480 - val_loss: 1.0710 - val_accuracy: 0.6674\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6533 - accuracy: 0.8551 - val_loss: 1.0728 - val_accuracy: 0.6686\n","Epoch 71/100\n","28/28 [==============================] - 2s 60ms/step - loss: 0.6476 - accuracy: 0.8540 - val_loss: 1.0699 - val_accuracy: 0.6799\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6430 - accuracy: 0.8588 - val_loss: 1.0795 - val_accuracy: 0.6742\n","Epoch 73/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6396 - accuracy: 0.8571 - val_loss: 1.0805 - val_accuracy: 0.6561\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6383 - accuracy: 0.8582 - val_loss: 1.0939 - val_accuracy: 0.6572\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6380 - accuracy: 0.8546 - val_loss: 1.0954 - val_accuracy: 0.6437\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6295 - accuracy: 0.8596 - val_loss: 1.0844 - val_accuracy: 0.6742\n","Epoch 77/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6276 - accuracy: 0.8636 - val_loss: 1.0847 - val_accuracy: 0.6674\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6234 - accuracy: 0.8656 - val_loss: 1.0941 - val_accuracy: 0.6753\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6201 - accuracy: 0.8690 - val_loss: 1.0973 - val_accuracy: 0.6652\n","Epoch 80/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6154 - accuracy: 0.8701 - val_loss: 1.1061 - val_accuracy: 0.6561\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6155 - accuracy: 0.8693 - val_loss: 1.1262 - val_accuracy: 0.6618\n","Epoch 82/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6146 - accuracy: 0.8630 - val_loss: 1.1183 - val_accuracy: 0.6538\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6083 - accuracy: 0.8681 - val_loss: 1.1044 - val_accuracy: 0.6787\n","Epoch 84/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6082 - accuracy: 0.8701 - val_loss: 1.1161 - val_accuracy: 0.6663\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6056 - accuracy: 0.8684 - val_loss: 1.1119 - val_accuracy: 0.6618\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6007 - accuracy: 0.8744 - val_loss: 1.1212 - val_accuracy: 0.6572\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5994 - accuracy: 0.8741 - val_loss: 1.1064 - val_accuracy: 0.6799\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5944 - accuracy: 0.8763 - val_loss: 1.1407 - val_accuracy: 0.6618\n","Epoch 89/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5889 - accuracy: 0.8780 - val_loss: 1.1268 - val_accuracy: 0.6787\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5864 - accuracy: 0.8755 - val_loss: 1.1307 - val_accuracy: 0.6425\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5880 - accuracy: 0.8780 - val_loss: 1.1396 - val_accuracy: 0.6674\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5879 - accuracy: 0.8775 - val_loss: 1.1426 - val_accuracy: 0.6482\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5843 - accuracy: 0.8783 - val_loss: 1.1489 - val_accuracy: 0.6753\n","Epoch 94/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5924 - accuracy: 0.8744 - val_loss: 1.1511 - val_accuracy: 0.6708\n","Epoch 95/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5848 - accuracy: 0.8778 - val_loss: 1.1695 - val_accuracy: 0.6380\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5821 - accuracy: 0.8763 - val_loss: 1.1588 - val_accuracy: 0.6629\n","Epoch 97/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5663 - accuracy: 0.8891 - val_loss: 1.1394 - val_accuracy: 0.6742\n","Epoch 98/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5611 - accuracy: 0.8871 - val_loss: 1.1643 - val_accuracy: 0.6708\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5651 - accuracy: 0.8848 - val_loss: 1.1582 - val_accuracy: 0.6606\n","Epoch 100/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5591 - accuracy: 0.8905 - val_loss: 1.1494 - val_accuracy: 0.6674\n","{'loss': [0.9855830669403076, 0.9718844294548035, 0.9686721563339233, 0.9580398797988892, 0.9506118297576904, 0.946022629737854, 0.9414935111999512, 0.9315618872642517, 0.9266676306724548, 0.9208250045776367, 0.9146150946617126, 0.9124900102615356, 0.9067900776863098, 0.901198148727417, 0.8926436305046082, 0.887601912021637, 0.8819294571876526, 0.8818119764328003, 0.8720280528068542, 0.86589115858078, 0.8613989949226379, 0.8563868403434753, 0.8508416414260864, 0.8475203514099121, 0.8400055170059204, 0.8384756445884705, 0.8307072520256042, 0.8264986872673035, 0.8203428983688354, 0.8164787292480469, 0.8123893141746521, 0.8057754039764404, 0.8046725988388062, 0.7986054420471191, 0.7920584678649902, 0.7870720028877258, 0.7829643487930298, 0.7761647701263428, 0.7740055322647095, 0.7684747576713562, 0.7643280029296875, 0.7587028741836548, 0.7623782753944397, 0.7545431852340698, 0.7490862607955933, 0.7484702467918396, 0.7381288409233093, 0.7390806674957275, 0.7307451963424683, 0.7317808270454407, 0.7199505567550659, 0.7248260378837585, 0.7123553156852722, 0.710438072681427, 0.7061607837677002, 0.7004644870758057, 0.7017396688461304, 0.6917538046836853, 0.6920170187950134, 0.6872599124908447, 0.6940209269523621, 0.6880530118942261, 0.678230881690979, 0.6829659342765808, 0.6722841262817383, 0.6649627685546875, 0.6620834469795227, 0.662071943283081, 0.655798077583313, 0.6532783508300781, 0.6475774645805359, 0.6430252194404602, 0.6396347880363464, 0.6382861733436584, 0.6380289793014526, 0.629464864730835, 0.6276377439498901, 0.6234187483787537, 0.6200718283653259, 0.6153882145881653, 0.6154685616493225, 0.6145545840263367, 0.6082818508148193, 0.6082277894020081, 0.6055815815925598, 0.600701630115509, 0.5994090437889099, 0.5944003462791443, 0.5889427065849304, 0.5863561034202576, 0.5879756212234497, 0.5879372358322144, 0.5842670202255249, 0.5923864841461182, 0.584784209728241, 0.5820969343185425, 0.5663473010063171, 0.5611100196838379, 0.5650987029075623, 0.5590716004371643], 'accuracy': [0.7079796195030212, 0.7204301357269287, 0.7181664109230042, 0.7243916392326355, 0.7300509214401245, 0.7328805923461914, 0.7297679781913757, 0.7365591526031494, 0.738822877407074, 0.7396717667579651, 0.7430673241615295, 0.7410866022109985, 0.7430673241615295, 0.7453310489654541, 0.7495755553245544, 0.7529711127281189, 0.7566496729850769, 0.7535370588302612, 0.7606111764907837, 0.7577815651893616, 0.7631579041481018, 0.764855682849884, 0.7583475112915039, 0.7679682970046997, 0.7713639140129089, 0.7713639140129089, 0.777023196220398, 0.7719298005104065, 0.7795698642730713, 0.7815506458282471, 0.7815506458282471, 0.7849462628364563, 0.7838143706321716, 0.7891907095909119, 0.7877758741378784, 0.7903226017951965, 0.7920203804969788, 0.8002263903617859, 0.7985285520553589, 0.7976796627044678, 0.8007922768592834, 0.8019241690635681, 0.7971137762069702, 0.8073005080223083, 0.810413122177124, 0.8058856725692749, 0.8146576285362244, 0.814091682434082, 0.8163554072380066, 0.8169213533401489, 0.8203169107437134, 0.81777024269104, 0.8307866454124451, 0.8225806355476379, 0.8296547532081604, 0.8330503702163696, 0.8316355347633362, 0.835597038269043, 0.8353140950202942, 0.8404074907302856, 0.8256932497024536, 0.8378607630729675, 0.8452178835868835, 0.8375778198242188, 0.8435201048851013, 0.8452178835868835, 0.8471986651420593, 0.8508771657943726, 0.8480475544929504, 0.8551216721534729, 0.853989839553833, 0.8588002324104309, 0.8571024537086487, 0.8582342863082886, 0.8545557260513306, 0.859649121761322, 0.8636106252670288, 0.8655914068222046, 0.868986964225769, 0.8701188564300537, 0.8692699670791626, 0.8630446791648865, 0.8681380748748779, 0.8701188564300537, 0.8684210777282715, 0.8743633031845093, 0.8740803599357605, 0.8763440847396851, 0.8780418634414673, 0.875495195388794, 0.8780418634414673, 0.8774759769439697, 0.8783248662948608, 0.8743633031845093, 0.8777589201927185, 0.8763440847396851, 0.8890775442123413, 0.8870967626571655, 0.884833037853241, 0.8904923796653748], 'val_loss': [1.1488268375396729, 1.1327611207962036, 1.134742021560669, 1.1218197345733643, 1.1195402145385742, 1.1089956760406494, 1.1092631816864014, 1.101980447769165, 1.1026856899261475, 1.0955480337142944, 1.0829663276672363, 1.0831202268600464, 1.0713320970535278, 1.0551937818527222, 1.0481480360031128, 1.045193076133728, 1.0246573686599731, 1.014666199684143, 1.012826681137085, 1.0209996700286865, 1.0078679323196411, 1.0070122480392456, 0.9948168992996216, 0.9944043755531311, 0.9956721663475037, 0.9943765997886658, 0.9962169528007507, 1.0012117624282837, 1.0053702592849731, 1.0063464641571045, 1.0046509504318237, 1.0076518058776855, 1.0061423778533936, 1.0076370239257812, 1.0093977451324463, 1.0116522312164307, 1.0129280090332031, 1.0126755237579346, 1.0169463157653809, 1.0162779092788696, 1.0248209238052368, 1.0239439010620117, 1.026995062828064, 1.0231760740280151, 1.02346670627594, 1.0218675136566162, 1.035328984260559, 1.0334761142730713, 1.0572762489318848, 1.0415709018707275, 1.0275640487670898, 1.0410773754119873, 1.0371869802474976, 1.0415236949920654, 1.049255609512329, 1.0440614223480225, 1.0583479404449463, 1.049967885017395, 1.0480846166610718, 1.0429706573486328, 1.0650625228881836, 1.0717942714691162, 1.0755600929260254, 1.0596141815185547, 1.061810851097107, 1.0583537817001343, 1.0712807178497314, 1.0678818225860596, 1.071015477180481, 1.0727711915969849, 1.0698736906051636, 1.079499363899231, 1.0805349349975586, 1.0938700437545776, 1.0953978300094604, 1.0844395160675049, 1.0846673250198364, 1.0940622091293335, 1.0973176956176758, 1.106126070022583, 1.1261625289916992, 1.1182576417922974, 1.1043974161148071, 1.1160614490509033, 1.111881136894226, 1.1211581230163574, 1.106400489807129, 1.1406935453414917, 1.1267534494400024, 1.1306886672973633, 1.1395623683929443, 1.1426475048065186, 1.1489062309265137, 1.1510716676712036, 1.1694717407226562, 1.1587998867034912, 1.1393548250198364, 1.1643277406692505, 1.158224105834961, 1.1493618488311768], 'val_accuracy': [0.5056561231613159, 0.5045248866081238, 0.5045248866081238, 0.5056561231613159, 0.5079185366630554, 0.5158371329307556, 0.5158371329307556, 0.5180995464324951, 0.5214931964874268, 0.5305429697036743, 0.5486425161361694, 0.5475113391876221, 0.5542986392974854, 0.5803167223930359, 0.5916289687156677, 0.598416268825531, 0.6165158152580261, 0.6368778347969055, 0.6346153616905212, 0.6266968250274658, 0.6470588445663452, 0.6436651349067688, 0.6583710312843323, 0.6572397947311401, 0.6606335043907166, 0.6662895679473877, 0.6662895679473877, 0.6538461446762085, 0.662895917892456, 0.6674208045005798, 0.662895917892456, 0.668552041053772, 0.6730769276618958, 0.6696832776069641, 0.6651583909988403, 0.6674208045005798, 0.668552041053772, 0.6651583909988403, 0.6595022678375244, 0.6674208045005798, 0.6549773812294006, 0.6583710312843323, 0.6640271544456482, 0.6674208045005798, 0.6583710312843323, 0.6561086177825928, 0.6595022678375244, 0.6572397947311401, 0.6561086177825928, 0.6617646813392639, 0.6651583909988403, 0.6662895679473877, 0.668552041053772, 0.6696832776069641, 0.6674208045005798, 0.6696832776069641, 0.6674208045005798, 0.6561086177825928, 0.6674208045005798, 0.6730769276618958, 0.6447963714599609, 0.662895917892456, 0.6719456911087036, 0.6674208045005798, 0.6674208045005798, 0.668552041053772, 0.6662895679473877, 0.6708144545555115, 0.6674208045005798, 0.668552041053772, 0.679864227771759, 0.6742081642150879, 0.6561086177825928, 0.6572397947311401, 0.6436651349067688, 0.6742081642150879, 0.6674208045005798, 0.6753393411636353, 0.6651583909988403, 0.6561086177825928, 0.6617646813392639, 0.6538461446762085, 0.6787330508232117, 0.6662895679473877, 0.6617646813392639, 0.6572397947311401, 0.679864227771759, 0.6617646813392639, 0.6787330508232117, 0.6425339579582214, 0.6674208045005798, 0.6481900215148926, 0.6753393411636353, 0.6708144545555115, 0.6380090713500977, 0.662895917892456, 0.6742081642150879, 0.6708144545555115, 0.6606335043907166, 0.6674208045005798]}\n","45/45 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 5s 30ms/step - loss: 0.9927 - accuracy: 0.7034 - val_loss: 1.1333 - val_accuracy: 0.5165\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 1.0126 - accuracy: 0.7109"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 13ms/step - loss: 0.9792 - accuracy: 0.7111 - val_loss: 1.1355 - val_accuracy: 0.5145\n","Epoch 3/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9703 - accuracy: 0.7173 - val_loss: 1.1258 - val_accuracy: 0.5176\n","Epoch 4/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9629 - accuracy: 0.7158 - val_loss: 1.1207 - val_accuracy: 0.5176\n","Epoch 5/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9540 - accuracy: 0.7256 - val_loss: 1.1209 - val_accuracy: 0.5196\n","Epoch 6/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9480 - accuracy: 0.7264 - val_loss: 1.1063 - val_accuracy: 0.5310\n","Epoch 7/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9408 - accuracy: 0.7292 - val_loss: 1.0976 - val_accuracy: 0.5331\n","Epoch 8/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9342 - accuracy: 0.7346 - val_loss: 1.1010 - val_accuracy: 0.5331\n","Epoch 9/100\n","31/31 [==============================] - 1s 34ms/step - loss: 0.9293 - accuracy: 0.7282 - val_loss: 1.0930 - val_accuracy: 0.5341\n","Epoch 10/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.9216 - accuracy: 0.7349 - val_loss: 1.0741 - val_accuracy: 0.5589\n","Epoch 11/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9174 - accuracy: 0.7346 - val_loss: 1.0606 - val_accuracy: 0.5620\n","Epoch 12/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.9106 - accuracy: 0.7390 - val_loss: 1.0559 - val_accuracy: 0.5682\n","Epoch 13/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.9046 - accuracy: 0.7432 - val_loss: 1.0655 - val_accuracy: 0.5630\n","Epoch 14/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8989 - accuracy: 0.7437 - val_loss: 1.0549 - val_accuracy: 0.5692\n","Epoch 15/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.8926 - accuracy: 0.7432 - val_loss: 1.0328 - val_accuracy: 0.6002\n","Epoch 16/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8925 - accuracy: 0.7416 - val_loss: 1.0204 - val_accuracy: 0.6178\n","Epoch 17/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8834 - accuracy: 0.7465 - val_loss: 1.0184 - val_accuracy: 0.6105\n","Epoch 18/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8760 - accuracy: 0.7525 - val_loss: 1.0178 - val_accuracy: 0.6147\n","Epoch 19/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.8723 - accuracy: 0.7527 - val_loss: 1.0028 - val_accuracy: 0.6560\n","Epoch 20/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8663 - accuracy: 0.7540 - val_loss: 1.0012 - val_accuracy: 0.6488\n","Epoch 21/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8614 - accuracy: 0.7558 - val_loss: 1.0067 - val_accuracy: 0.6498\n","Epoch 22/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8563 - accuracy: 0.7587 - val_loss: 1.0013 - val_accuracy: 0.6457\n","Epoch 23/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8543 - accuracy: 0.7620 - val_loss: 0.9956 - val_accuracy: 0.6488\n","Epoch 24/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8458 - accuracy: 0.7641 - val_loss: 1.0020 - val_accuracy: 0.6477\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8424 - accuracy: 0.7633 - val_loss: 1.0097 - val_accuracy: 0.6477\n","Epoch 26/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8375 - accuracy: 0.7641 - val_loss: 1.0013 - val_accuracy: 0.6477\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8310 - accuracy: 0.7685 - val_loss: 1.0037 - val_accuracy: 0.6436\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8252 - accuracy: 0.7703 - val_loss: 0.9998 - val_accuracy: 0.6457\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8225 - accuracy: 0.7721 - val_loss: 1.0037 - val_accuracy: 0.6436\n","Epoch 30/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8209 - accuracy: 0.7685 - val_loss: 1.0014 - val_accuracy: 0.6446\n","Epoch 31/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.8197 - accuracy: 0.7667 - val_loss: 1.0120 - val_accuracy: 0.6467\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.8062 - accuracy: 0.7760 - val_loss: 1.0116 - val_accuracy: 0.6446\n","Epoch 33/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.8050 - accuracy: 0.7749 - val_loss: 1.0059 - val_accuracy: 0.6446\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7992 - accuracy: 0.7757 - val_loss: 1.0141 - val_accuracy: 0.6395\n","Epoch 35/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7942 - accuracy: 0.7881 - val_loss: 1.0056 - val_accuracy: 0.6415\n","Epoch 36/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7898 - accuracy: 0.7848 - val_loss: 1.0065 - val_accuracy: 0.6415\n","Epoch 37/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7829 - accuracy: 0.7873 - val_loss: 1.0291 - val_accuracy: 0.6405\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7874 - accuracy: 0.7824 - val_loss: 1.0115 - val_accuracy: 0.6426\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7785 - accuracy: 0.7863 - val_loss: 1.0284 - val_accuracy: 0.6488\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7718 - accuracy: 0.7860 - val_loss: 1.0125 - val_accuracy: 0.6374\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7666 - accuracy: 0.7928 - val_loss: 1.0233 - val_accuracy: 0.6374\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7647 - accuracy: 0.7925 - val_loss: 1.0185 - val_accuracy: 0.6415\n","Epoch 43/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7605 - accuracy: 0.7941 - val_loss: 1.0274 - val_accuracy: 0.6384\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7591 - accuracy: 0.7979 - val_loss: 1.0157 - val_accuracy: 0.6291\n","Epoch 45/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7529 - accuracy: 0.7984 - val_loss: 1.0187 - val_accuracy: 0.6333\n","Epoch 46/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.7464 - accuracy: 0.7995 - val_loss: 1.0238 - val_accuracy: 0.6281\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7434 - accuracy: 0.7977 - val_loss: 1.0456 - val_accuracy: 0.6415\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7407 - accuracy: 0.8049 - val_loss: 1.0266 - val_accuracy: 0.6364\n","Epoch 49/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7345 - accuracy: 0.8028 - val_loss: 1.0205 - val_accuracy: 0.6291\n","Epoch 50/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7319 - accuracy: 0.8080 - val_loss: 1.0285 - val_accuracy: 0.6353\n","Epoch 51/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7280 - accuracy: 0.8085 - val_loss: 1.0347 - val_accuracy: 0.6457\n","Epoch 52/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7234 - accuracy: 0.8085 - val_loss: 1.0341 - val_accuracy: 0.6353\n","Epoch 53/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7205 - accuracy: 0.8085 - val_loss: 1.0486 - val_accuracy: 0.6353\n","Epoch 54/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7161 - accuracy: 0.8189 - val_loss: 1.0333 - val_accuracy: 0.6353\n","Epoch 55/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7128 - accuracy: 0.8183 - val_loss: 1.0395 - val_accuracy: 0.6384\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7087 - accuracy: 0.8186 - val_loss: 1.0507 - val_accuracy: 0.6281\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.7052 - accuracy: 0.8176 - val_loss: 1.0418 - val_accuracy: 0.6415\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.7012 - accuracy: 0.8194 - val_loss: 1.0485 - val_accuracy: 0.6508\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6968 - accuracy: 0.8269 - val_loss: 1.0564 - val_accuracy: 0.6343\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6960 - accuracy: 0.8261 - val_loss: 1.0432 - val_accuracy: 0.6322\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6956 - accuracy: 0.8235 - val_loss: 1.0680 - val_accuracy: 0.6405\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6889 - accuracy: 0.8253 - val_loss: 1.0580 - val_accuracy: 0.6353\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6854 - accuracy: 0.8271 - val_loss: 1.0637 - val_accuracy: 0.6508\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6828 - accuracy: 0.8287 - val_loss: 1.0598 - val_accuracy: 0.6405\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6753 - accuracy: 0.8336 - val_loss: 1.0612 - val_accuracy: 0.6426\n","Epoch 66/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6747 - accuracy: 0.8333 - val_loss: 1.0573 - val_accuracy: 0.6384\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6698 - accuracy: 0.8336 - val_loss: 1.0651 - val_accuracy: 0.6384\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6643 - accuracy: 0.8395 - val_loss: 1.0635 - val_accuracy: 0.6426\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6610 - accuracy: 0.8388 - val_loss: 1.0697 - val_accuracy: 0.6395\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6583 - accuracy: 0.8424 - val_loss: 1.0719 - val_accuracy: 0.6312\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6568 - accuracy: 0.8393 - val_loss: 1.0789 - val_accuracy: 0.6426\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6534 - accuracy: 0.8457 - val_loss: 1.0790 - val_accuracy: 0.6405\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6483 - accuracy: 0.8403 - val_loss: 1.0748 - val_accuracy: 0.6333\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6461 - accuracy: 0.8447 - val_loss: 1.0819 - val_accuracy: 0.6333\n","Epoch 75/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6427 - accuracy: 0.8442 - val_loss: 1.0837 - val_accuracy: 0.6395\n","Epoch 76/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6370 - accuracy: 0.8486 - val_loss: 1.0911 - val_accuracy: 0.6395\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6352 - accuracy: 0.8501 - val_loss: 1.1204 - val_accuracy: 0.6436\n","Epoch 78/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6383 - accuracy: 0.8473 - val_loss: 1.1045 - val_accuracy: 0.6405\n","Epoch 79/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6364 - accuracy: 0.8475 - val_loss: 1.0919 - val_accuracy: 0.6436\n","Epoch 80/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6317 - accuracy: 0.8488 - val_loss: 1.1028 - val_accuracy: 0.6457\n","Epoch 81/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6281 - accuracy: 0.8532 - val_loss: 1.1168 - val_accuracy: 0.6498\n","Epoch 82/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6191 - accuracy: 0.8566 - val_loss: 1.0940 - val_accuracy: 0.6488\n","Epoch 83/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6219 - accuracy: 0.8545 - val_loss: 1.1234 - val_accuracy: 0.6343\n","Epoch 84/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6158 - accuracy: 0.8607 - val_loss: 1.1047 - val_accuracy: 0.6405\n","Epoch 85/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6138 - accuracy: 0.8587 - val_loss: 1.1054 - val_accuracy: 0.6457\n","Epoch 86/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6098 - accuracy: 0.8607 - val_loss: 1.1133 - val_accuracy: 0.6529\n","Epoch 87/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6128 - accuracy: 0.8597 - val_loss: 1.1231 - val_accuracy: 0.6333\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6010 - accuracy: 0.8667 - val_loss: 1.1248 - val_accuracy: 0.6415\n","Epoch 89/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5976 - accuracy: 0.8649 - val_loss: 1.1295 - val_accuracy: 0.6457\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5974 - accuracy: 0.8687 - val_loss: 1.1279 - val_accuracy: 0.6498\n","Epoch 91/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5956 - accuracy: 0.8661 - val_loss: 1.1477 - val_accuracy: 0.6426\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5892 - accuracy: 0.8724 - val_loss: 1.1238 - val_accuracy: 0.6539\n","Epoch 93/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5932 - accuracy: 0.8674 - val_loss: 1.1257 - val_accuracy: 0.6508\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5824 - accuracy: 0.8721 - val_loss: 1.1403 - val_accuracy: 0.6508\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5844 - accuracy: 0.8700 - val_loss: 1.1695 - val_accuracy: 0.6519\n","Epoch 96/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5839 - accuracy: 0.8669 - val_loss: 1.1444 - val_accuracy: 0.6519\n","Epoch 97/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6032 - accuracy: 0.8651 - val_loss: 1.1854 - val_accuracy: 0.6477\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5758 - accuracy: 0.8713 - val_loss: 1.1589 - val_accuracy: 0.6457\n","Epoch 99/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5716 - accuracy: 0.8786 - val_loss: 1.1464 - val_accuracy: 0.6508\n","Epoch 100/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.5675 - accuracy: 0.8780 - val_loss: 1.1619 - val_accuracy: 0.6457\n","{'loss': [0.992741584777832, 0.9792282581329346, 0.9702637195587158, 0.962895929813385, 0.9540322422981262, 0.948026180267334, 0.9408186078071594, 0.9342114925384521, 0.9292653203010559, 0.9216226935386658, 0.9174184799194336, 0.9105570912361145, 0.9046112298965454, 0.898884117603302, 0.892619788646698, 0.8925026059150696, 0.8834106922149658, 0.8760169744491577, 0.8722962141036987, 0.866283118724823, 0.8613897562026978, 0.8562734127044678, 0.8543074131011963, 0.8458001017570496, 0.8423885703086853, 0.8374913930892944, 0.8310128450393677, 0.825211226940155, 0.8224927186965942, 0.8208661675453186, 0.8197479248046875, 0.8061840534210205, 0.8050357103347778, 0.7992187142372131, 0.7941851019859314, 0.7898468971252441, 0.78293776512146, 0.7873880863189697, 0.7785243988037109, 0.7718172073364258, 0.7665547132492065, 0.7646623253822327, 0.7604889869689941, 0.7591463327407837, 0.7528946399688721, 0.746405839920044, 0.7433631420135498, 0.740721583366394, 0.7344980239868164, 0.7319361567497253, 0.7279983758926392, 0.7234411239624023, 0.720455527305603, 0.7160522937774658, 0.7127591371536255, 0.7086569666862488, 0.7052338123321533, 0.7011717557907104, 0.6967638731002808, 0.6959805488586426, 0.6956207156181335, 0.6889288425445557, 0.685410737991333, 0.6827630400657654, 0.6753442287445068, 0.674663245677948, 0.6698420643806458, 0.6642926931381226, 0.6609528660774231, 0.6583279371261597, 0.6568161249160767, 0.6534207463264465, 0.6482516527175903, 0.6461468935012817, 0.6426820755004883, 0.6370059847831726, 0.6352003216743469, 0.6382862329483032, 0.6363994479179382, 0.6316794157028198, 0.6280763149261475, 0.6190717220306396, 0.6218796968460083, 0.6157640814781189, 0.613787829875946, 0.609825849533081, 0.6127910017967224, 0.6009761095046997, 0.5976277589797974, 0.5973523259162903, 0.595645546913147, 0.5892224907875061, 0.5931548476219177, 0.5823522210121155, 0.5844239592552185, 0.583912193775177, 0.6031755805015564, 0.5757579803466797, 0.5716240406036377, 0.5675380229949951], 'accuracy': [0.7033591866493225, 0.7111111283302307, 0.7173126339912415, 0.7157622575759888, 0.7255814075469971, 0.726356565952301, 0.7291989922523499, 0.7346253395080566, 0.7281653881072998, 0.734883725643158, 0.7346253395080566, 0.7390180826187134, 0.7431524395942688, 0.7436692714691162, 0.7431524395942688, 0.7416020631790161, 0.7465116381645203, 0.7524547576904297, 0.7527132034301758, 0.7540051937103271, 0.7558139562606812, 0.7586563229560852, 0.7620155215263367, 0.764082670211792, 0.763307511806488, 0.764082670211792, 0.7684754729270935, 0.7702842354774475, 0.7720929980278015, 0.7684754729270935, 0.7666666507720947, 0.7759689688682556, 0.7749354243278503, 0.7757105827331543, 0.7881137132644653, 0.7847545146942139, 0.7873384952545166, 0.7824289202690125, 0.7863048911094666, 0.7860465049743652, 0.7927648425102234, 0.7925064563751221, 0.7940568327903748, 0.7979328036308289, 0.7984496355056763, 0.7994831800460815, 0.7976744174957275, 0.8049095869064331, 0.802842378616333, 0.8080103397369385, 0.8085271120071411, 0.8085271120071411, 0.8085271120071411, 0.818863034248352, 0.8183462619781494, 0.8186046481132507, 0.8175710439682007, 0.8193798661231995, 0.8268733620643616, 0.8260982036590576, 0.8235142230987549, 0.8253229856491089, 0.8271318078041077, 0.8286821842193604, 0.8335917592048645, 0.8333333134651184, 0.8335917592048645, 0.8395348787307739, 0.8387596607208252, 0.842377245426178, 0.8392764925956726, 0.8457364439964294, 0.8403100967407227, 0.8447028398513794, 0.8441860675811768, 0.8485788106918335, 0.8501291871070862, 0.8472868204116821, 0.8475452065467834, 0.8488371968269348, 0.8532299995422363, 0.856589138507843, 0.8545219898223877, 0.8607234954833984, 0.8586563467979431, 0.8607234954833984, 0.8596899509429932, 0.8666666746139526, 0.8648578524589539, 0.868733823299408, 0.8661498427391052, 0.8723514080047607, 0.8674418330192566, 0.8720930218696594, 0.8700258135795593, 0.866925060749054, 0.8651162981987, 0.8713178038597107, 0.8785529732704163, 0.8780362010002136], 'val_loss': [1.1333297491073608, 1.1355153322219849, 1.1257927417755127, 1.1206682920455933, 1.120872139930725, 1.106258749961853, 1.097567081451416, 1.10104238986969, 1.0929986238479614, 1.0740971565246582, 1.0606285333633423, 1.0558604001998901, 1.0655312538146973, 1.0549346208572388, 1.032792568206787, 1.020389199256897, 1.0184088945388794, 1.017822027206421, 1.0027529001235962, 1.0011711120605469, 1.0067416429519653, 1.0012787580490112, 0.9955624938011169, 1.002030849456787, 1.0096558332443237, 1.0013015270233154, 1.0036901235580444, 0.9998111724853516, 1.0037155151367188, 1.0014487504959106, 1.0119657516479492, 1.0115678310394287, 1.0059021711349487, 1.0141266584396362, 1.00563383102417, 1.0064839124679565, 1.029122233390808, 1.0115458965301514, 1.0283766984939575, 1.0124553442001343, 1.0233087539672852, 1.0185290575027466, 1.0273860692977905, 1.0157016515731812, 1.0186673402786255, 1.0238170623779297, 1.0455751419067383, 1.0266163349151611, 1.0205378532409668, 1.028451681137085, 1.034680962562561, 1.0341192483901978, 1.0486063957214355, 1.0333458185195923, 1.039452314376831, 1.0506837368011475, 1.0417863130569458, 1.0485303401947021, 1.0563524961471558, 1.0431641340255737, 1.0680092573165894, 1.058037281036377, 1.0636547803878784, 1.059835433959961, 1.0611836910247803, 1.0573196411132812, 1.06508469581604, 1.0635433197021484, 1.0697029829025269, 1.0719199180603027, 1.0788804292678833, 1.0790127515792847, 1.074826955795288, 1.0818599462509155, 1.0837265253067017, 1.0911387205123901, 1.1204487085342407, 1.1045371294021606, 1.0919365882873535, 1.1027578115463257, 1.116794228553772, 1.0939631462097168, 1.123443603515625, 1.104691743850708, 1.1053602695465088, 1.1132549047470093, 1.1230528354644775, 1.1248191595077515, 1.129549503326416, 1.1279078722000122, 1.1477036476135254, 1.123793363571167, 1.1257450580596924, 1.1403379440307617, 1.1694855690002441, 1.1443886756896973, 1.1854355335235596, 1.1589045524597168, 1.1463876962661743, 1.1618918180465698], 'val_accuracy': [0.5165289044380188, 0.5144628286361694, 0.5175619721412659, 0.5175619721412659, 0.51962810754776, 0.5309917330741882, 0.5330578684806824, 0.5330578684806824, 0.5340909361839294, 0.55888432264328, 0.5619834661483765, 0.5681818127632141, 0.5630165338516235, 0.5692148804664612, 0.6002066135406494, 0.6177685856819153, 0.6105371713638306, 0.6146694421768188, 0.6559917330741882, 0.6487603187561035, 0.6497933864593506, 0.6456611752510071, 0.6487603187561035, 0.6477272510528564, 0.6477272510528564, 0.6477272510528564, 0.6435950398445129, 0.6456611752510071, 0.6435950398445129, 0.64462810754776, 0.6466942429542542, 0.64462810754776, 0.64462810754776, 0.6394628286361694, 0.6415289044380188, 0.6415289044380188, 0.6404958963394165, 0.6425619721412659, 0.6487603187561035, 0.6373966932296753, 0.6373966932296753, 0.6415289044380188, 0.6384297609329224, 0.6291322112083435, 0.6332644820213318, 0.6280992031097412, 0.6415289044380188, 0.6363636255264282, 0.6291322112083435, 0.6353305578231812, 0.6456611752510071, 0.6353305578231812, 0.6353305578231812, 0.6353305578231812, 0.6384297609329224, 0.6280992031097412, 0.6415289044380188, 0.6508264541625977, 0.6342975497245789, 0.6322314143180847, 0.6404958963394165, 0.6353305578231812, 0.6508264541625977, 0.6404958963394165, 0.6425619721412659, 0.6384297609329224, 0.6384297609329224, 0.6425619721412659, 0.6394628286361694, 0.6311983466148376, 0.6425619721412659, 0.6404958963394165, 0.6332644820213318, 0.6332644820213318, 0.6394628286361694, 0.6394628286361694, 0.6435950398445129, 0.6404958963394165, 0.6435950398445129, 0.6456611752510071, 0.6497933864593506, 0.6487603187561035, 0.6342975497245789, 0.6404958963394165, 0.6456611752510071, 0.6528925895690918, 0.6332644820213318, 0.6415289044380188, 0.6456611752510071, 0.6497933864593506, 0.6425619721412659, 0.6539255976676941, 0.6508264541625977, 0.6508264541625977, 0.6518595218658447, 0.6518595218658447, 0.6477272510528564, 0.6456611752510071, 0.6508264541625977, 0.6456611752510071]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 5s 38ms/step - loss: 0.6568 - accuracy: 0.8324 - val_loss: 0.9846 - val_accuracy: 0.5269\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6390 - accuracy: 0.8389 - val_loss: 0.9636 - val_accuracy: 0.5442\n","Epoch 3/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6236 - accuracy: 0.8486 - val_loss: 0.9532 - val_accuracy: 0.5560\n","Epoch 4/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6152 - accuracy: 0.8478 - val_loss: 0.9526 - val_accuracy: 0.5603\n","Epoch 5/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6103 - accuracy: 0.8586 - val_loss: 0.9327 - val_accuracy: 0.6045\n","Epoch 6/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.6034 - accuracy: 0.8613 - val_loss: 0.9295 - val_accuracy: 0.6013\n","Epoch 7/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6036 - accuracy: 0.8561 - val_loss: 0.9204 - val_accuracy: 0.6110\n","Epoch 8/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5974 - accuracy: 0.8634 - val_loss: 0.9064 - val_accuracy: 0.6412\n","Epoch 9/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5938 - accuracy: 0.8648 - val_loss: 0.9238 - val_accuracy: 0.5970\n","Epoch 10/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6110 - accuracy: 0.8475 - val_loss: 0.8931 - val_accuracy: 0.6476\n","Epoch 11/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5998 - accuracy: 0.8586 - val_loss: 0.8811 - val_accuracy: 0.6713\n","Epoch 12/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5851 - accuracy: 0.8672 - val_loss: 0.8756 - val_accuracy: 0.6821\n","Epoch 13/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5799 - accuracy: 0.8707 - val_loss: 0.8915 - val_accuracy: 0.6336\n","Epoch 14/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.5765 - accuracy: 0.8728 - val_loss: 0.8709 - val_accuracy: 0.6756\n","Epoch 15/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5741 - accuracy: 0.8774 - val_loss: 0.8575 - val_accuracy: 0.6735\n","Epoch 16/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5726 - accuracy: 0.8712 - val_loss: 0.8482 - val_accuracy: 0.6983\n","Epoch 17/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5684 - accuracy: 0.8790 - val_loss: 0.8425 - val_accuracy: 0.7026\n","Epoch 18/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5651 - accuracy: 0.8809 - val_loss: 0.8353 - val_accuracy: 0.7069\n","Epoch 19/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5600 - accuracy: 0.8866 - val_loss: 0.8293 - val_accuracy: 0.7123\n","Epoch 20/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5581 - accuracy: 0.8820 - val_loss: 0.8308 - val_accuracy: 0.7112\n","Epoch 21/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5532 - accuracy: 0.8879 - val_loss: 0.8260 - val_accuracy: 0.7101\n","Epoch 22/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5527 - accuracy: 0.8879 - val_loss: 0.8360 - val_accuracy: 0.7123\n","Epoch 23/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.5470 - accuracy: 0.8909 - val_loss: 0.8397 - val_accuracy: 0.7274\n","Epoch 24/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5468 - accuracy: 0.8877 - val_loss: 0.8407 - val_accuracy: 0.7188\n","Epoch 25/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5431 - accuracy: 0.8936 - val_loss: 0.8573 - val_accuracy: 0.7198\n","Epoch 26/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5408 - accuracy: 0.8966 - val_loss: 0.8614 - val_accuracy: 0.7188\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5374 - accuracy: 0.8944 - val_loss: 0.8679 - val_accuracy: 0.7166\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5370 - accuracy: 0.8939 - val_loss: 0.8711 - val_accuracy: 0.7155\n","Epoch 29/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5348 - accuracy: 0.8914 - val_loss: 0.8815 - val_accuracy: 0.7220\n","Epoch 30/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5327 - accuracy: 0.8979 - val_loss: 0.8844 - val_accuracy: 0.7198\n","Epoch 31/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5273 - accuracy: 0.8957 - val_loss: 0.8979 - val_accuracy: 0.7284\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5251 - accuracy: 0.9009 - val_loss: 0.8954 - val_accuracy: 0.7144\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5220 - accuracy: 0.9001 - val_loss: 0.8980 - val_accuracy: 0.7284\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5207 - accuracy: 0.9044 - val_loss: 0.9032 - val_accuracy: 0.7252\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5152 - accuracy: 0.9019 - val_loss: 0.9051 - val_accuracy: 0.7155\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5148 - accuracy: 0.9060 - val_loss: 0.9065 - val_accuracy: 0.7198\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5120 - accuracy: 0.9052 - val_loss: 0.9279 - val_accuracy: 0.7101\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5150 - accuracy: 0.9030 - val_loss: 0.9428 - val_accuracy: 0.7263\n","Epoch 39/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5143 - accuracy: 0.8995 - val_loss: 0.9175 - val_accuracy: 0.7220\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5063 - accuracy: 0.9076 - val_loss: 0.9188 - val_accuracy: 0.7209\n","Epoch 41/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5001 - accuracy: 0.9146 - val_loss: 0.9162 - val_accuracy: 0.7209\n","Epoch 42/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4982 - accuracy: 0.9108 - val_loss: 0.9184 - val_accuracy: 0.7220\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4961 - accuracy: 0.9133 - val_loss: 0.9306 - val_accuracy: 0.7166\n","Epoch 44/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4940 - accuracy: 0.9154 - val_loss: 0.9282 - val_accuracy: 0.7220\n","Epoch 45/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4947 - accuracy: 0.9119 - val_loss: 0.9512 - val_accuracy: 0.7112\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4941 - accuracy: 0.9116 - val_loss: 0.9359 - val_accuracy: 0.7252\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4908 - accuracy: 0.9138 - val_loss: 1.0192 - val_accuracy: 0.7101\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5016 - accuracy: 0.9003 - val_loss: 1.0085 - val_accuracy: 0.6940\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.5176 - accuracy: 0.9038 - val_loss: 0.9902 - val_accuracy: 0.7037\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.5155 - accuracy: 0.8990 - val_loss: 0.9777 - val_accuracy: 0.7134\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4926 - accuracy: 0.9019 - val_loss: 0.9468 - val_accuracy: 0.7177\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4795 - accuracy: 0.9178 - val_loss: 0.9342 - val_accuracy: 0.7241\n","Epoch 53/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4742 - accuracy: 0.9205 - val_loss: 0.9490 - val_accuracy: 0.7166\n","Epoch 54/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4782 - accuracy: 0.9181 - val_loss: 0.9601 - val_accuracy: 0.7198\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4729 - accuracy: 0.9189 - val_loss: 0.9478 - val_accuracy: 0.7166\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4720 - accuracy: 0.9184 - val_loss: 0.9574 - val_accuracy: 0.7198\n","Epoch 57/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4672 - accuracy: 0.9189 - val_loss: 0.9605 - val_accuracy: 0.7112\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4667 - accuracy: 0.9235 - val_loss: 0.9665 - val_accuracy: 0.7134\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4602 - accuracy: 0.9251 - val_loss: 0.9727 - val_accuracy: 0.7112\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4591 - accuracy: 0.9259 - val_loss: 0.9585 - val_accuracy: 0.7198\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4593 - accuracy: 0.9238 - val_loss: 0.9680 - val_accuracy: 0.7123\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4564 - accuracy: 0.9273 - val_loss: 0.9711 - val_accuracy: 0.7188\n","Epoch 63/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4527 - accuracy: 0.9308 - val_loss: 0.9638 - val_accuracy: 0.7188\n","Epoch 64/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4540 - accuracy: 0.9251 - val_loss: 0.9778 - val_accuracy: 0.7177\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4537 - accuracy: 0.9270 - val_loss: 0.9749 - val_accuracy: 0.7101\n","Epoch 66/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4475 - accuracy: 0.9310 - val_loss: 0.9869 - val_accuracy: 0.7198\n","Epoch 67/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4471 - accuracy: 0.9310 - val_loss: 0.9903 - val_accuracy: 0.7188\n","Epoch 68/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4464 - accuracy: 0.9256 - val_loss: 0.9926 - val_accuracy: 0.7166\n","Epoch 69/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4464 - accuracy: 0.9262 - val_loss: 0.9806 - val_accuracy: 0.7155\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4456 - accuracy: 0.9286 - val_loss: 1.0178 - val_accuracy: 0.7123\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4487 - accuracy: 0.9300 - val_loss: 0.9861 - val_accuracy: 0.7231\n","Epoch 72/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4426 - accuracy: 0.9302 - val_loss: 1.0111 - val_accuracy: 0.7112\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4405 - accuracy: 0.9343 - val_loss: 1.0313 - val_accuracy: 0.7166\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4514 - accuracy: 0.9270 - val_loss: 1.0635 - val_accuracy: 0.6918\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4568 - accuracy: 0.9248 - val_loss: 1.0354 - val_accuracy: 0.7047\n","Epoch 76/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.4451 - accuracy: 0.9335 - val_loss: 1.0189 - val_accuracy: 0.7004\n","Epoch 77/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4392 - accuracy: 0.9297 - val_loss: 1.0132 - val_accuracy: 0.7112\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4294 - accuracy: 0.9391 - val_loss: 1.0254 - val_accuracy: 0.7037\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4290 - accuracy: 0.9359 - val_loss: 1.0251 - val_accuracy: 0.7198\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4263 - accuracy: 0.9337 - val_loss: 1.0249 - val_accuracy: 0.7112\n","Epoch 81/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4226 - accuracy: 0.9397 - val_loss: 1.0192 - val_accuracy: 0.7134\n","Epoch 82/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4208 - accuracy: 0.9391 - val_loss: 1.0327 - val_accuracy: 0.7123\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4199 - accuracy: 0.9397 - val_loss: 1.0422 - val_accuracy: 0.6972\n","Epoch 84/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4214 - accuracy: 0.9356 - val_loss: 1.0677 - val_accuracy: 0.7026\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4179 - accuracy: 0.9397 - val_loss: 1.0391 - val_accuracy: 0.7231\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4155 - accuracy: 0.9397 - val_loss: 1.0252 - val_accuracy: 0.7134\n","Epoch 87/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4338 - accuracy: 0.9310 - val_loss: 1.1124 - val_accuracy: 0.6810\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4282 - accuracy: 0.9397 - val_loss: 1.0445 - val_accuracy: 0.7177\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4181 - accuracy: 0.9394 - val_loss: 1.0501 - val_accuracy: 0.7047\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4195 - accuracy: 0.9386 - val_loss: 1.0513 - val_accuracy: 0.7037\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4119 - accuracy: 0.9399 - val_loss: 1.0462 - val_accuracy: 0.7134\n","Epoch 92/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4092 - accuracy: 0.9418 - val_loss: 1.0422 - val_accuracy: 0.7101\n","Epoch 93/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4065 - accuracy: 0.9405 - val_loss: 1.0547 - val_accuracy: 0.7080\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4026 - accuracy: 0.9475 - val_loss: 1.0519 - val_accuracy: 0.7091\n","Epoch 95/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4026 - accuracy: 0.9426 - val_loss: 1.0529 - val_accuracy: 0.7166\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3999 - accuracy: 0.9456 - val_loss: 1.0586 - val_accuracy: 0.7037\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4018 - accuracy: 0.9410 - val_loss: 1.0635 - val_accuracy: 0.7166\n","Epoch 98/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3991 - accuracy: 0.9491 - val_loss: 1.0730 - val_accuracy: 0.7069\n","Epoch 99/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3981 - accuracy: 0.9472 - val_loss: 1.0745 - val_accuracy: 0.7069\n","Epoch 100/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3963 - accuracy: 0.9480 - val_loss: 1.0704 - val_accuracy: 0.7058\n","{'loss': [0.6567581295967102, 0.6390380859375, 0.6236019134521484, 0.6152413487434387, 0.6103199124336243, 0.6033954620361328, 0.6035518646240234, 0.5974358916282654, 0.5938280820846558, 0.6110249757766724, 0.5998343825340271, 0.5851439833641052, 0.5798563957214355, 0.5765330195426941, 0.5740824341773987, 0.5725674629211426, 0.5683742761611938, 0.5650514364242554, 0.5599805116653442, 0.5580543875694275, 0.5531585216522217, 0.5526779294013977, 0.5470004677772522, 0.54676753282547, 0.5431085228919983, 0.5407621264457703, 0.5373891592025757, 0.536983072757721, 0.5348317623138428, 0.532696008682251, 0.5273152589797974, 0.5251180529594421, 0.5219622254371643, 0.5206829309463501, 0.5152023434638977, 0.514773964881897, 0.5119947195053101, 0.5149773955345154, 0.5142560601234436, 0.5063377022743225, 0.5001440048217773, 0.4981711506843567, 0.4960671365261078, 0.49397727847099304, 0.4946582317352295, 0.49414488673210144, 0.49076902866363525, 0.5015673041343689, 0.5175548195838928, 0.5155050754547119, 0.4926097095012665, 0.4795048236846924, 0.47420573234558105, 0.4782164692878723, 0.47289979457855225, 0.47196128964424133, 0.46716544032096863, 0.4666694104671478, 0.46024075150489807, 0.45908164978027344, 0.45933425426483154, 0.4564436972141266, 0.45265907049179077, 0.4539945423603058, 0.45371854305267334, 0.44750168919563293, 0.44714105129241943, 0.4463794231414795, 0.4464321732521057, 0.44563454389572144, 0.4486997127532959, 0.4425942301750183, 0.4405209422111511, 0.4513763189315796, 0.45681414008140564, 0.44513633847236633, 0.43917182087898254, 0.4293748736381531, 0.4290418028831482, 0.4262745678424835, 0.42255181074142456, 0.4207928478717804, 0.4199410676956177, 0.42140451073646545, 0.4179302752017975, 0.41545358300209045, 0.43384212255477905, 0.42824608087539673, 0.41809868812561035, 0.4195448160171509, 0.41192910075187683, 0.40915751457214355, 0.40647003054618835, 0.4026009440422058, 0.40258967876434326, 0.3998728394508362, 0.4017578959465027, 0.39906659722328186, 0.39806345105171204, 0.3962610363960266], 'accuracy': [0.8324353694915771, 0.8389008641242981, 0.8485991358757019, 0.8477909564971924, 0.8585668206214905, 0.8612607717514038, 0.8561422228813171, 0.8634159564971924, 0.8647629022598267, 0.8475215435028076, 0.8585668206214905, 0.8671875, 0.8706896305084229, 0.8728448152542114, 0.8774245977401733, 0.8712284564971924, 0.8790409564971924, 0.8809267282485962, 0.8865840435028076, 0.8820043206214905, 0.8879310488700867, 0.8879310488700867, 0.8908944129943848, 0.8876616358757019, 0.8935883641242981, 0.8965517282485962, 0.8943965435028076, 0.8938577771186829, 0.8914331793785095, 0.8978987336158752, 0.8957435488700867, 0.9008620977401733, 0.900053858757019, 0.9043642282485962, 0.9019396305084229, 0.9059805870056152, 0.9051724076271057, 0.9030172228813171, 0.8995150923728943, 0.907597005367279, 0.9146012663841248, 0.9108297228813171, 0.9132543206214905, 0.915409505367279, 0.9119073152542114, 0.9116379022598267, 0.9137930870056152, 0.9003232717514038, 0.9038254022598267, 0.8989762663841248, 0.9019396305084229, 0.9178340435028076, 0.920527994632721, 0.9181034564971924, 0.9189116358757019, 0.9183728694915771, 0.9189116358757019, 0.923491358757019, 0.9251077771186829, 0.9259159564971924, 0.9237607717514038, 0.9272629022598267, 0.9307650923728943, 0.9251077771186829, 0.9269935488700867, 0.931034505367279, 0.931034505367279, 0.9256465435028076, 0.9261853694915771, 0.9286099076271057, 0.9299569129943848, 0.9302262663841248, 0.9342672228813171, 0.9269935488700867, 0.9248383641242981, 0.9334590435028076, 0.9296875, 0.939116358757019, 0.935883641242981, 0.9337284564971924, 0.9396551847457886, 0.939116358757019, 0.9396551847457886, 0.9356142282485962, 0.9396551847457886, 0.9396551847457886, 0.931034505367279, 0.9396551847457886, 0.9393857717514038, 0.9385775923728943, 0.9399245977401733, 0.9418103694915771, 0.9404633641242981, 0.9474676847457886, 0.9426185488700867, 0.9455819129943848, 0.9410021305084229, 0.9490840435028076, 0.9471982717514038, 0.9480064511299133], 'val_loss': [0.9846450686454773, 0.9636400938034058, 0.9531899690628052, 0.9526419043540955, 0.9326701760292053, 0.9294642806053162, 0.9204047918319702, 0.9064475297927856, 0.9238186478614807, 0.8931291699409485, 0.8810750842094421, 0.8755946755409241, 0.8915237188339233, 0.8709168434143066, 0.8575456142425537, 0.8481627106666565, 0.8425151109695435, 0.8353431224822998, 0.8292895555496216, 0.83078533411026, 0.8259872198104858, 0.835965633392334, 0.8396729230880737, 0.8406803607940674, 0.8573246002197266, 0.8613889813423157, 0.8679456114768982, 0.8711342811584473, 0.8814614415168762, 0.8844006657600403, 0.8979130387306213, 0.8954373002052307, 0.8980039358139038, 0.9032217860221863, 0.9050778746604919, 0.9065134525299072, 0.92788165807724, 0.9428013563156128, 0.9174953699111938, 0.9187659025192261, 0.9161571860313416, 0.918415904045105, 0.9305625557899475, 0.9281530976295471, 0.9511764645576477, 0.9358620047569275, 1.0191715955734253, 1.0085053443908691, 0.9902034997940063, 0.9776885509490967, 0.946812093257904, 0.9341744780540466, 0.9490084648132324, 0.9601359963417053, 0.9478101134300232, 0.9573891758918762, 0.9605273604393005, 0.9664581418037415, 0.9727064967155457, 0.9585196375846863, 0.9679524898529053, 0.9711456894874573, 0.96384197473526, 0.977774441242218, 0.9749284386634827, 0.9868724942207336, 0.9903356432914734, 0.9926090836524963, 0.9805545806884766, 1.0178290605545044, 0.9860635995864868, 1.0110827684402466, 1.0313440561294556, 1.063480019569397, 1.0354334115982056, 1.0188945531845093, 1.0132046937942505, 1.0254390239715576, 1.0250972509384155, 1.0248867273330688, 1.0191948413848877, 1.0326822996139526, 1.042177438735962, 1.0677300691604614, 1.0391184091567993, 1.0251625776290894, 1.112358808517456, 1.0444657802581787, 1.050135850906372, 1.0513006448745728, 1.0461878776550293, 1.042203664779663, 1.05466628074646, 1.0519038438796997, 1.0528932809829712, 1.0586308240890503, 1.0634574890136719, 1.072993278503418, 1.074460744857788, 1.0704412460327148], 'val_accuracy': [0.5269396305084229, 0.5441810488700867, 0.556034505367279, 0.5603448152542114, 0.6045258641242981, 0.6012930870056152, 0.610991358757019, 0.6411637663841248, 0.5969827771186829, 0.6476293206214905, 0.6713362336158752, 0.6821120977401733, 0.6336206793785095, 0.6756465435028076, 0.673491358757019, 0.6982758641242981, 0.7025862336158752, 0.7068965435028076, 0.712284505367279, 0.7112069129943848, 0.7101293206214905, 0.712284505367279, 0.7273706793785095, 0.71875, 0.7198275923728943, 0.71875, 0.7165948152542114, 0.7155172228813171, 0.7219827771186829, 0.7198275923728943, 0.7284482717514038, 0.7144396305084229, 0.7284482717514038, 0.725215494632721, 0.7155172228813171, 0.7198275923728943, 0.7101293206214905, 0.7262930870056152, 0.7219827771186829, 0.7209051847457886, 0.7209051847457886, 0.7219827771186829, 0.7165948152542114, 0.7219827771186829, 0.7112069129943848, 0.725215494632721, 0.7101293206214905, 0.693965494632721, 0.7036637663841248, 0.7133620977401733, 0.7176724076271057, 0.7241379022598267, 0.7165948152542114, 0.7198275923728943, 0.7165948152542114, 0.7198275923728943, 0.7112069129943848, 0.7133620977401733, 0.7112069129943848, 0.7198275923728943, 0.712284505367279, 0.71875, 0.71875, 0.7176724076271057, 0.7101293206214905, 0.7198275923728943, 0.71875, 0.7165948152542114, 0.7155172228813171, 0.712284505367279, 0.7230603694915771, 0.7112069129943848, 0.7165948152542114, 0.6918103694915771, 0.704741358757019, 0.7004310488700867, 0.7112069129943848, 0.7036637663841248, 0.7198275923728943, 0.7112069129943848, 0.7133620977401733, 0.712284505367279, 0.6971982717514038, 0.7025862336158752, 0.7230603694915771, 0.7133620977401733, 0.681034505367279, 0.7176724076271057, 0.704741358757019, 0.7036637663841248, 0.7133620977401733, 0.7101293206214905, 0.7079741358757019, 0.7090517282485962, 0.7165948152542114, 0.7036637663841248, 0.7165948152542114, 0.7068965435028076, 0.7068965435028076, 0.7058189511299133]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 4s 33ms/step - loss: 0.6541 - accuracy: 0.8308 - val_loss: 0.9773 - val_accuracy: 0.5305\n","Epoch 2/100\n"," 1/28 [>.............................] - ETA: 0s - loss: 0.6947 - accuracy: 0.8203"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 13ms/step - loss: 0.6293 - accuracy: 0.8461 - val_loss: 0.9858 - val_accuracy: 0.5260\n","Epoch 3/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6209 - accuracy: 0.8461 - val_loss: 0.9669 - val_accuracy: 0.5452\n","Epoch 4/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.6211 - accuracy: 0.8458 - val_loss: 0.9709 - val_accuracy: 0.5430\n","Epoch 5/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6118 - accuracy: 0.8492 - val_loss: 0.9674 - val_accuracy: 0.5554\n","Epoch 6/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6056 - accuracy: 0.8585 - val_loss: 0.9457 - val_accuracy: 0.5826\n","Epoch 7/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5998 - accuracy: 0.8608 - val_loss: 0.9421 - val_accuracy: 0.5871\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6006 - accuracy: 0.8591 - val_loss: 0.9321 - val_accuracy: 0.5995\n","Epoch 9/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5937 - accuracy: 0.8642 - val_loss: 0.9239 - val_accuracy: 0.6109\n","Epoch 10/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5889 - accuracy: 0.8696 - val_loss: 0.9272 - val_accuracy: 0.6018\n","Epoch 11/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5880 - accuracy: 0.8630 - val_loss: 0.9075 - val_accuracy: 0.6561\n","Epoch 12/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5839 - accuracy: 0.8676 - val_loss: 0.8959 - val_accuracy: 0.6493\n","Epoch 13/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5834 - accuracy: 0.8659 - val_loss: 0.8947 - val_accuracy: 0.6708\n","Epoch 14/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5857 - accuracy: 0.8656 - val_loss: 0.8969 - val_accuracy: 0.6629\n","Epoch 15/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5862 - accuracy: 0.8673 - val_loss: 0.8789 - val_accuracy: 0.7002\n","Epoch 16/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5766 - accuracy: 0.8687 - val_loss: 0.8896 - val_accuracy: 0.6448\n","Epoch 17/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5726 - accuracy: 0.8741 - val_loss: 0.8702 - val_accuracy: 0.6855\n","Epoch 18/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5695 - accuracy: 0.8755 - val_loss: 0.8612 - val_accuracy: 0.7149\n","Epoch 19/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5630 - accuracy: 0.8803 - val_loss: 0.8699 - val_accuracy: 0.7104\n","Epoch 20/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5604 - accuracy: 0.8800 - val_loss: 0.8661 - val_accuracy: 0.6900\n","Epoch 21/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5609 - accuracy: 0.8763 - val_loss: 0.8638 - val_accuracy: 0.7172\n","Epoch 22/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5552 - accuracy: 0.8809 - val_loss: 0.8680 - val_accuracy: 0.7364\n","Epoch 23/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5525 - accuracy: 0.8854 - val_loss: 0.8627 - val_accuracy: 0.7364\n","Epoch 24/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5505 - accuracy: 0.8834 - val_loss: 0.8773 - val_accuracy: 0.7308\n","Epoch 25/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5462 - accuracy: 0.8894 - val_loss: 0.8948 - val_accuracy: 0.7138\n","Epoch 26/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5462 - accuracy: 0.8851 - val_loss: 0.9082 - val_accuracy: 0.7070\n","Epoch 27/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5413 - accuracy: 0.8919 - val_loss: 0.8961 - val_accuracy: 0.7296\n","Epoch 28/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5378 - accuracy: 0.8928 - val_loss: 0.9261 - val_accuracy: 0.7376\n","Epoch 29/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5378 - accuracy: 0.8862 - val_loss: 0.9068 - val_accuracy: 0.7353\n","Epoch 30/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5554 - accuracy: 0.8843 - val_loss: 0.9288 - val_accuracy: 0.7296\n","Epoch 31/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5430 - accuracy: 0.8854 - val_loss: 0.9200 - val_accuracy: 0.7330\n","Epoch 32/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5355 - accuracy: 0.8930 - val_loss: 0.9481 - val_accuracy: 0.7308\n","Epoch 33/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5285 - accuracy: 0.8953 - val_loss: 0.9319 - val_accuracy: 0.7319\n","Epoch 34/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5268 - accuracy: 0.8942 - val_loss: 0.9378 - val_accuracy: 0.7398\n","Epoch 35/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5208 - accuracy: 0.9004 - val_loss: 0.9360 - val_accuracy: 0.7410\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5185 - accuracy: 0.8984 - val_loss: 0.9356 - val_accuracy: 0.7308\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5164 - accuracy: 0.8967 - val_loss: 0.9504 - val_accuracy: 0.7319\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5137 - accuracy: 0.9063 - val_loss: 0.9455 - val_accuracy: 0.7376\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5093 - accuracy: 0.9032 - val_loss: 0.9565 - val_accuracy: 0.7172\n","Epoch 40/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5093 - accuracy: 0.9015 - val_loss: 0.9564 - val_accuracy: 0.7342\n","Epoch 41/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5050 - accuracy: 0.9109 - val_loss: 0.9593 - val_accuracy: 0.7274\n","Epoch 42/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5032 - accuracy: 0.9086 - val_loss: 0.9570 - val_accuracy: 0.7364\n","Epoch 43/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5038 - accuracy: 0.9046 - val_loss: 0.9551 - val_accuracy: 0.7342\n","Epoch 44/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5012 - accuracy: 0.9044 - val_loss: 0.9585 - val_accuracy: 0.7285\n","Epoch 45/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5033 - accuracy: 0.9055 - val_loss: 0.9593 - val_accuracy: 0.7353\n","Epoch 46/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4973 - accuracy: 0.9103 - val_loss: 0.9821 - val_accuracy: 0.7059\n","Epoch 47/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5045 - accuracy: 0.9114 - val_loss: 0.9843 - val_accuracy: 0.7330\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.5001 - accuracy: 0.9049 - val_loss: 0.9674 - val_accuracy: 0.7330\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4863 - accuracy: 0.9123 - val_loss: 0.9807 - val_accuracy: 0.7262\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4879 - accuracy: 0.9148 - val_loss: 0.9809 - val_accuracy: 0.7342\n","Epoch 51/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4811 - accuracy: 0.9148 - val_loss: 0.9872 - val_accuracy: 0.7240\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4827 - accuracy: 0.9137 - val_loss: 0.9807 - val_accuracy: 0.7285\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4823 - accuracy: 0.9157 - val_loss: 0.9825 - val_accuracy: 0.7172\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4765 - accuracy: 0.9148 - val_loss: 0.9821 - val_accuracy: 0.7364\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4735 - accuracy: 0.9208 - val_loss: 0.9945 - val_accuracy: 0.7262\n","Epoch 56/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4724 - accuracy: 0.9196 - val_loss: 1.0002 - val_accuracy: 0.7251\n","Epoch 57/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4694 - accuracy: 0.9228 - val_loss: 1.0001 - val_accuracy: 0.7330\n","Epoch 58/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4685 - accuracy: 0.9259 - val_loss: 1.0044 - val_accuracy: 0.7262\n","Epoch 59/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4673 - accuracy: 0.9250 - val_loss: 1.0084 - val_accuracy: 0.7308\n","Epoch 60/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4644 - accuracy: 0.9236 - val_loss: 0.9895 - val_accuracy: 0.7319\n","Epoch 61/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4642 - accuracy: 0.9253 - val_loss: 1.0154 - val_accuracy: 0.7285\n","Epoch 62/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4600 - accuracy: 0.9276 - val_loss: 1.0199 - val_accuracy: 0.7296\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4565 - accuracy: 0.9278 - val_loss: 1.0217 - val_accuracy: 0.7195\n","Epoch 64/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4564 - accuracy: 0.9276 - val_loss: 1.0325 - val_accuracy: 0.7138\n","Epoch 65/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4561 - accuracy: 0.9290 - val_loss: 1.0211 - val_accuracy: 0.7274\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4550 - accuracy: 0.9281 - val_loss: 1.0469 - val_accuracy: 0.7274\n","Epoch 67/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4528 - accuracy: 0.9284 - val_loss: 1.0263 - val_accuracy: 0.7229\n","Epoch 68/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4509 - accuracy: 0.9310 - val_loss: 1.0340 - val_accuracy: 0.7195\n","Epoch 69/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4645 - accuracy: 0.9185 - val_loss: 1.0444 - val_accuracy: 0.7048\n","Epoch 70/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4863 - accuracy: 0.9063 - val_loss: 1.0929 - val_accuracy: 0.6923\n","Epoch 71/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4633 - accuracy: 0.9213 - val_loss: 1.0646 - val_accuracy: 0.7172\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4705 - accuracy: 0.9179 - val_loss: 1.0885 - val_accuracy: 0.7161\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4684 - accuracy: 0.9126 - val_loss: 1.0931 - val_accuracy: 0.7172\n","Epoch 74/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4509 - accuracy: 0.9250 - val_loss: 1.0413 - val_accuracy: 0.7093\n","Epoch 75/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4393 - accuracy: 0.9349 - val_loss: 1.0424 - val_accuracy: 0.7206\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4388 - accuracy: 0.9349 - val_loss: 1.0388 - val_accuracy: 0.7262\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4423 - accuracy: 0.9335 - val_loss: 1.0498 - val_accuracy: 0.7138\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4348 - accuracy: 0.9329 - val_loss: 1.0726 - val_accuracy: 0.7172\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4354 - accuracy: 0.9321 - val_loss: 1.0841 - val_accuracy: 0.7274\n","Epoch 80/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4310 - accuracy: 0.9386 - val_loss: 1.0612 - val_accuracy: 0.7172\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4276 - accuracy: 0.9394 - val_loss: 1.0574 - val_accuracy: 0.7296\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4249 - accuracy: 0.9428 - val_loss: 1.0585 - val_accuracy: 0.7274\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4242 - accuracy: 0.9403 - val_loss: 1.0876 - val_accuracy: 0.7161\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4264 - accuracy: 0.9420 - val_loss: 1.0707 - val_accuracy: 0.7229\n","Epoch 85/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4225 - accuracy: 0.9392 - val_loss: 1.0735 - val_accuracy: 0.7229\n","Epoch 86/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4196 - accuracy: 0.9417 - val_loss: 1.0738 - val_accuracy: 0.7229\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4167 - accuracy: 0.9454 - val_loss: 1.0906 - val_accuracy: 0.7036\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4216 - accuracy: 0.9417 - val_loss: 1.0850 - val_accuracy: 0.7172\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4167 - accuracy: 0.9377 - val_loss: 1.1049 - val_accuracy: 0.7229\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4265 - accuracy: 0.9392 - val_loss: 1.1258 - val_accuracy: 0.6946\n","Epoch 91/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4340 - accuracy: 0.9324 - val_loss: 1.0975 - val_accuracy: 0.7172\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4299 - accuracy: 0.9298 - val_loss: 1.1331 - val_accuracy: 0.6833\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4384 - accuracy: 0.9264 - val_loss: 1.0932 - val_accuracy: 0.7127\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4185 - accuracy: 0.9420 - val_loss: 1.1432 - val_accuracy: 0.7127\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4294 - accuracy: 0.9360 - val_loss: 1.1152 - val_accuracy: 0.7172\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4181 - accuracy: 0.9414 - val_loss: 1.1123 - val_accuracy: 0.7183\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4039 - accuracy: 0.9485 - val_loss: 1.0965 - val_accuracy: 0.7262\n","Epoch 98/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4018 - accuracy: 0.9525 - val_loss: 1.1281 - val_accuracy: 0.7048\n","Epoch 99/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4022 - accuracy: 0.9491 - val_loss: 1.1071 - val_accuracy: 0.7183\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4013 - accuracy: 0.9491 - val_loss: 1.1235 - val_accuracy: 0.7161\n","{'loss': [0.6540980935096741, 0.6293202042579651, 0.6208553314208984, 0.6210769414901733, 0.611831784248352, 0.6056020855903625, 0.5998147130012512, 0.6005502939224243, 0.5937427878379822, 0.5889207720756531, 0.5880241394042969, 0.5838644504547119, 0.5833877921104431, 0.5856717824935913, 0.5862077474594116, 0.5765935778617859, 0.5725724697113037, 0.5694589018821716, 0.5629788041114807, 0.560427725315094, 0.5608986020088196, 0.555179238319397, 0.552535891532898, 0.5505142211914062, 0.5461594462394714, 0.5461858510971069, 0.5413294434547424, 0.5378129482269287, 0.5377869009971619, 0.5554357767105103, 0.5429983139038086, 0.5355132818222046, 0.5285058617591858, 0.5268028378486633, 0.5207542777061462, 0.5184866786003113, 0.5164279341697693, 0.5137065052986145, 0.5092785358428955, 0.5093108415603638, 0.5049858689308167, 0.5032190680503845, 0.5037662386894226, 0.5012189745903015, 0.5032899379730225, 0.4973369836807251, 0.5044946074485779, 0.5000523328781128, 0.4862881600856781, 0.48794543743133545, 0.48112887144088745, 0.48267272114753723, 0.48228785395622253, 0.47652551531791687, 0.4734571576118469, 0.4723844826221466, 0.46936899423599243, 0.4684823453426361, 0.4672737121582031, 0.46440571546554565, 0.46422773599624634, 0.460044264793396, 0.456498384475708, 0.456398069858551, 0.45613721013069153, 0.45500636100769043, 0.45280545949935913, 0.4508853852748871, 0.4645254909992218, 0.48628905415534973, 0.46327856183052063, 0.4705469310283661, 0.4684206247329712, 0.45086437463760376, 0.43927258253097534, 0.43882691860198975, 0.4423260986804962, 0.4348059594631195, 0.4353817403316498, 0.4310136139392853, 0.42756345868110657, 0.4249250292778015, 0.42424824833869934, 0.42636311054229736, 0.4225122630596161, 0.4196098744869232, 0.41668128967285156, 0.4215935468673706, 0.41669681668281555, 0.42650189995765686, 0.43398621678352356, 0.42986711859703064, 0.43837830424308777, 0.41851866245269775, 0.4293619692325592, 0.41809728741645813, 0.4039435386657715, 0.401820570230484, 0.4021562933921814, 0.401317298412323], 'accuracy': [0.8307866454124451, 0.8460667729377747, 0.8460667729377747, 0.8457838296890259, 0.8491793870925903, 0.8585172891616821, 0.8607810139656067, 0.8590831756591797, 0.8641765713691711, 0.8695529103279114, 0.8630446791648865, 0.8675721287727356, 0.8658743500709534, 0.8655914068222046, 0.8672891855239868, 0.8687040209770203, 0.8740803599357605, 0.875495195388794, 0.8803055882453918, 0.8800226449966431, 0.8763440847396851, 0.8808715343475342, 0.8853989839553833, 0.8834182024002075, 0.8893604874610901, 0.8851160407066345, 0.8919072151184082, 0.8927561044692993, 0.8862478733062744, 0.8842670917510986, 0.8853989839553833, 0.8930390477180481, 0.8953027725219727, 0.8941709399223328, 0.9003961682319641, 0.8984153866767883, 0.8967176079750061, 0.9063384532928467, 0.9032257795333862, 0.901528000831604, 0.9108659029006958, 0.9086021780967712, 0.9046406149864197, 0.9043576717376709, 0.9054895043373108, 0.9102999567985535, 0.9114317893981934, 0.9049236178398132, 0.9122806787490845, 0.9148274064064026, 0.9148274064064026, 0.9136955142021179, 0.9156762957572937, 0.9148274064064026, 0.9207696914672852, 0.9196377992630005, 0.9227504134178162, 0.9258630275726318, 0.9250141382217407, 0.9235993027687073, 0.9252971410751343, 0.9275608658790588, 0.9278438091278076, 0.9275608658790588, 0.9289756417274475, 0.9281267523765564, 0.92840975522995, 0.9309564232826233, 0.9185059666633606, 0.9063384532928467, 0.9213355779647827, 0.9179400205612183, 0.912563681602478, 0.9250141382217407, 0.9349179267883301, 0.9349179267883301, 0.9335030913352966, 0.9329372048377991, 0.9320882558822632, 0.9385964870452881, 0.9394453763961792, 0.9428409934043884, 0.9402942657470703, 0.9419921040534973, 0.9391624331474304, 0.9417091012001038, 0.9453876614570618, 0.9417091012001038, 0.937747597694397, 0.9391624331474304, 0.9323712587356567, 0.9298245906829834, 0.9264289736747742, 0.9419921040534973, 0.9360498189926147, 0.941426157951355, 0.9485002756118774, 0.9524617791175842, 0.9490662217140198, 0.9490662217140198], 'val_loss': [0.9772918820381165, 0.9858338832855225, 0.9668669700622559, 0.9709380269050598, 0.9674334526062012, 0.9457406997680664, 0.942081868648529, 0.9320561289787292, 0.9238852262496948, 0.9271794557571411, 0.907520055770874, 0.8958899974822998, 0.8947442770004272, 0.8969070911407471, 0.8789423704147339, 0.8895619511604309, 0.8702256679534912, 0.8611878156661987, 0.8699371814727783, 0.8660570979118347, 0.8638302087783813, 0.868018388748169, 0.8626790642738342, 0.8773292899131775, 0.8947829604148865, 0.9082401394844055, 0.8960802555084229, 0.9261244535446167, 0.9067670702934265, 0.9287712574005127, 0.9200169444084167, 0.9481288194656372, 0.9319283962249756, 0.9377624988555908, 0.9359805583953857, 0.9355894327163696, 0.9503742456436157, 0.945526659488678, 0.9564687013626099, 0.9564192295074463, 0.959289014339447, 0.9570493102073669, 0.9551160931587219, 0.9585432410240173, 0.9593439698219299, 0.982082188129425, 0.9843337535858154, 0.9674363136291504, 0.9806841611862183, 0.9809409976005554, 0.9871576428413391, 0.9807283282279968, 0.9824516773223877, 0.9821065068244934, 0.9945483803749084, 1.0001914501190186, 1.000095009803772, 1.0044426918029785, 1.0083966255187988, 0.9895147681236267, 1.0154041051864624, 1.0199278593063354, 1.0217375755310059, 1.0324516296386719, 1.0211385488510132, 1.0469214916229248, 1.0263289213180542, 1.0339903831481934, 1.0444416999816895, 1.092897891998291, 1.0646202564239502, 1.088496446609497, 1.0931103229522705, 1.041269063949585, 1.0423667430877686, 1.0388076305389404, 1.0498284101486206, 1.0725544691085815, 1.084069848060608, 1.061231255531311, 1.0573878288269043, 1.0585353374481201, 1.0875879526138306, 1.0707051753997803, 1.0734883546829224, 1.073760747909546, 1.0906398296356201, 1.0850260257720947, 1.1048613786697388, 1.1258127689361572, 1.0975123643875122, 1.1331470012664795, 1.0932210683822632, 1.1431634426116943, 1.1151784658432007, 1.1123452186584473, 1.0965040922164917, 1.12809157371521, 1.1071257591247559, 1.12352454662323], 'val_accuracy': [0.5305429697036743, 0.5260180830955505, 0.5452488660812378, 0.5429864525794983, 0.5554298758506775, 0.5825791954994202, 0.587104082107544, 0.5995475053787231, 0.610859751701355, 0.6018099784851074, 0.6561086177825928, 0.6493212580680847, 0.6708144545555115, 0.662895917892456, 0.7002262473106384, 0.6447963714599609, 0.685520350933075, 0.7149321436882019, 0.7104072570800781, 0.6900452375411987, 0.7171945571899414, 0.7364253401756287, 0.7364253401756287, 0.7307692170143127, 0.7138009071350098, 0.7070135474205017, 0.7296379804611206, 0.7375565767288208, 0.7352941036224365, 0.7296379804611206, 0.733031690120697, 0.7307692170143127, 0.7319004535675049, 0.7398189902305603, 0.7409502267837524, 0.7307692170143127, 0.7319004535675049, 0.7375565767288208, 0.7171945571899414, 0.7341628670692444, 0.7273755669593811, 0.7364253401756287, 0.7341628670692444, 0.7285068035125732, 0.7352941036224365, 0.7058823704719543, 0.733031690120697, 0.733031690120697, 0.726244330406189, 0.7341628670692444, 0.7239819169044495, 0.7285068035125732, 0.7171945571899414, 0.7364253401756287, 0.726244330406189, 0.7251130938529968, 0.733031690120697, 0.726244330406189, 0.7307692170143127, 0.7319004535675049, 0.7285068035125732, 0.7296379804611206, 0.7194570302963257, 0.7138009071350098, 0.7273755669593811, 0.7273755669593811, 0.7228506803512573, 0.7194570302963257, 0.7047511339187622, 0.692307710647583, 0.7171945571899414, 0.7160633206367493, 0.7171945571899414, 0.709276020526886, 0.720588207244873, 0.726244330406189, 0.7138009071350098, 0.7171945571899414, 0.7273755669593811, 0.7171945571899414, 0.7296379804611206, 0.7273755669593811, 0.7160633206367493, 0.7228506803512573, 0.7228506803512573, 0.7228506803512573, 0.7036198973655701, 0.7171945571899414, 0.7228506803512573, 0.6945701241493225, 0.7171945571899414, 0.6832579374313354, 0.7126696705818176, 0.7126696705818176, 0.7171945571899414, 0.7183257937431335, 0.726244330406189, 0.7047511339187622, 0.7183257937431335, 0.7160633206367493]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 5s 32ms/step - loss: 0.6624 - accuracy: 0.8264 - val_loss: 0.9712 - val_accuracy: 0.5362\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.6388 - accuracy: 0.8516"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 19ms/step - loss: 0.6458 - accuracy: 0.8354 - val_loss: 0.9679 - val_accuracy: 0.5434\n","Epoch 3/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6459 - accuracy: 0.8380 - val_loss: 0.9603 - val_accuracy: 0.5486\n","Epoch 4/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.6344 - accuracy: 0.8380 - val_loss: 0.9712 - val_accuracy: 0.5424\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6265 - accuracy: 0.8437 - val_loss: 0.9643 - val_accuracy: 0.5455\n","Epoch 6/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6219 - accuracy: 0.8481 - val_loss: 0.9517 - val_accuracy: 0.5599\n","Epoch 7/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6169 - accuracy: 0.8478 - val_loss: 0.9300 - val_accuracy: 0.5857\n","Epoch 8/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6209 - accuracy: 0.8426 - val_loss: 0.9194 - val_accuracy: 0.6126\n","Epoch 9/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6195 - accuracy: 0.8442 - val_loss: 0.9165 - val_accuracy: 0.6095\n","Epoch 10/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6079 - accuracy: 0.8530 - val_loss: 0.9091 - val_accuracy: 0.6281\n","Epoch 11/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6039 - accuracy: 0.8548 - val_loss: 0.9014 - val_accuracy: 0.6364\n","Epoch 12/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6035 - accuracy: 0.8566 - val_loss: 0.9000 - val_accuracy: 0.6612\n","Epoch 13/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5955 - accuracy: 0.8597 - val_loss: 0.8850 - val_accuracy: 0.6870\n","Epoch 14/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5934 - accuracy: 0.8633 - val_loss: 0.8738 - val_accuracy: 0.6911\n","Epoch 15/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5937 - accuracy: 0.8607 - val_loss: 0.8836 - val_accuracy: 0.6787\n","Epoch 16/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5960 - accuracy: 0.8584 - val_loss: 0.8686 - val_accuracy: 0.6973\n","Epoch 17/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.6072 - accuracy: 0.8576 - val_loss: 0.8721 - val_accuracy: 0.6973\n","Epoch 18/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5818 - accuracy: 0.8649 - val_loss: 0.8664 - val_accuracy: 0.7097\n","Epoch 19/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5797 - accuracy: 0.8685 - val_loss: 0.8620 - val_accuracy: 0.7118\n","Epoch 20/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5751 - accuracy: 0.8685 - val_loss: 0.8757 - val_accuracy: 0.7025\n","Epoch 21/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5757 - accuracy: 0.8661 - val_loss: 0.8756 - val_accuracy: 0.7076\n","Epoch 22/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5711 - accuracy: 0.8708 - val_loss: 0.8877 - val_accuracy: 0.7076\n","Epoch 23/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5683 - accuracy: 0.8734 - val_loss: 0.8902 - val_accuracy: 0.7128\n","Epoch 24/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5646 - accuracy: 0.8819 - val_loss: 0.8993 - val_accuracy: 0.7066\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5633 - accuracy: 0.8775 - val_loss: 0.9091 - val_accuracy: 0.7056\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5608 - accuracy: 0.8809 - val_loss: 0.9185 - val_accuracy: 0.7118\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5587 - accuracy: 0.8780 - val_loss: 0.9352 - val_accuracy: 0.7004\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5569 - accuracy: 0.8824 - val_loss: 0.9451 - val_accuracy: 0.7014\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5535 - accuracy: 0.8827 - val_loss: 0.9388 - val_accuracy: 0.7097\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5545 - accuracy: 0.8796 - val_loss: 0.9469 - val_accuracy: 0.7118\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5482 - accuracy: 0.8791 - val_loss: 0.9455 - val_accuracy: 0.7097\n","Epoch 32/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5546 - accuracy: 0.8778 - val_loss: 0.9514 - val_accuracy: 0.7138\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5454 - accuracy: 0.8832 - val_loss: 0.9494 - val_accuracy: 0.7118\n","Epoch 34/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5430 - accuracy: 0.8853 - val_loss: 0.9609 - val_accuracy: 0.7097\n","Epoch 35/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5372 - accuracy: 0.8928 - val_loss: 0.9539 - val_accuracy: 0.7200\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5321 - accuracy: 0.8930 - val_loss: 0.9795 - val_accuracy: 0.7045\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5378 - accuracy: 0.8873 - val_loss: 0.9800 - val_accuracy: 0.7087\n","Epoch 38/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5317 - accuracy: 0.8930 - val_loss: 1.0235 - val_accuracy: 0.7035\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5342 - accuracy: 0.8884 - val_loss: 0.9727 - val_accuracy: 0.7190\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5265 - accuracy: 0.8959 - val_loss: 0.9646 - val_accuracy: 0.7128\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5222 - accuracy: 0.8948 - val_loss: 0.9736 - val_accuracy: 0.7066\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5201 - accuracy: 0.8984 - val_loss: 0.9838 - val_accuracy: 0.7107\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5194 - accuracy: 0.9003 - val_loss: 0.9812 - val_accuracy: 0.7128\n","Epoch 44/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5170 - accuracy: 0.9005 - val_loss: 1.0059 - val_accuracy: 0.7118\n","Epoch 45/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5164 - accuracy: 0.8997 - val_loss: 0.9959 - val_accuracy: 0.7004\n","Epoch 46/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.5119 - accuracy: 0.9047 - val_loss: 1.0014 - val_accuracy: 0.7097\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5089 - accuracy: 0.9031 - val_loss: 1.0095 - val_accuracy: 0.7097\n","Epoch 48/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5104 - accuracy: 0.9003 - val_loss: 1.0064 - val_accuracy: 0.7066\n","Epoch 49/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5043 - accuracy: 0.9059 - val_loss: 1.0104 - val_accuracy: 0.7076\n","Epoch 50/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5028 - accuracy: 0.9088 - val_loss: 0.9972 - val_accuracy: 0.7138\n","Epoch 51/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4971 - accuracy: 0.9093 - val_loss: 1.0099 - val_accuracy: 0.7056\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4962 - accuracy: 0.9088 - val_loss: 1.0026 - val_accuracy: 0.7066\n","Epoch 53/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5004 - accuracy: 0.9054 - val_loss: 1.0283 - val_accuracy: 0.7056\n","Epoch 54/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5117 - accuracy: 0.9005 - val_loss: 1.0434 - val_accuracy: 0.7035\n","Epoch 55/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5002 - accuracy: 0.9083 - val_loss: 1.0262 - val_accuracy: 0.6994\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4898 - accuracy: 0.9137 - val_loss: 1.0216 - val_accuracy: 0.7066\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4906 - accuracy: 0.9129 - val_loss: 1.0439 - val_accuracy: 0.7014\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5013 - accuracy: 0.9005 - val_loss: 1.1002 - val_accuracy: 0.6921\n","Epoch 59/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.5037 - accuracy: 0.9070 - val_loss: 1.0307 - val_accuracy: 0.6983\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4866 - accuracy: 0.9111 - val_loss: 1.0365 - val_accuracy: 0.7118\n","Epoch 61/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4896 - accuracy: 0.9078 - val_loss: 1.1002 - val_accuracy: 0.6725\n","Epoch 62/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4926 - accuracy: 0.9142 - val_loss: 1.0613 - val_accuracy: 0.7066\n","Epoch 63/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4789 - accuracy: 0.9134 - val_loss: 1.0374 - val_accuracy: 0.7056\n","Epoch 64/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4883 - accuracy: 0.9106 - val_loss: 1.0521 - val_accuracy: 0.7004\n","Epoch 65/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4780 - accuracy: 0.9160 - val_loss: 1.0466 - val_accuracy: 0.7004\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4712 - accuracy: 0.9176 - val_loss: 1.0484 - val_accuracy: 0.7056\n","Epoch 67/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4662 - accuracy: 0.9207 - val_loss: 1.0445 - val_accuracy: 0.7035\n","Epoch 68/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4648 - accuracy: 0.9240 - val_loss: 1.0575 - val_accuracy: 0.7035\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4626 - accuracy: 0.9225 - val_loss: 1.0397 - val_accuracy: 0.7107\n","Epoch 70/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4620 - accuracy: 0.9251 - val_loss: 1.0611 - val_accuracy: 0.7025\n","Epoch 71/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4632 - accuracy: 0.9230 - val_loss: 1.0582 - val_accuracy: 0.6994\n","Epoch 72/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4583 - accuracy: 0.9261 - val_loss: 1.0627 - val_accuracy: 0.7045\n","Epoch 73/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4631 - accuracy: 0.9225 - val_loss: 1.1106 - val_accuracy: 0.6963\n","Epoch 74/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4710 - accuracy: 0.9137 - val_loss: 1.0930 - val_accuracy: 0.6890\n","Epoch 75/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4734 - accuracy: 0.9168 - val_loss: 1.0820 - val_accuracy: 0.7056\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4551 - accuracy: 0.9214 - val_loss: 1.0854 - val_accuracy: 0.7045\n","Epoch 77/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4493 - accuracy: 0.9282 - val_loss: 1.1086 - val_accuracy: 0.6839\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4546 - accuracy: 0.9194 - val_loss: 1.0845 - val_accuracy: 0.7097\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4493 - accuracy: 0.9261 - val_loss: 1.0781 - val_accuracy: 0.6994\n","Epoch 80/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4433 - accuracy: 0.9300 - val_loss: 1.0811 - val_accuracy: 0.7056\n","Epoch 81/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4411 - accuracy: 0.9326 - val_loss: 1.1002 - val_accuracy: 0.7014\n","Epoch 82/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4434 - accuracy: 0.9276 - val_loss: 1.0973 - val_accuracy: 0.7056\n","Epoch 83/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4372 - accuracy: 0.9302 - val_loss: 1.0906 - val_accuracy: 0.7076\n","Epoch 84/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4397 - accuracy: 0.9287 - val_loss: 1.1175 - val_accuracy: 0.6952\n","Epoch 85/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4362 - accuracy: 0.9292 - val_loss: 1.0992 - val_accuracy: 0.7035\n","Epoch 86/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4344 - accuracy: 0.9351 - val_loss: 1.1136 - val_accuracy: 0.6983\n","Epoch 87/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4407 - accuracy: 0.9313 - val_loss: 1.1380 - val_accuracy: 0.6921\n","Epoch 88/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4327 - accuracy: 0.9331 - val_loss: 1.1100 - val_accuracy: 0.7014\n","Epoch 89/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4297 - accuracy: 0.9336 - val_loss: 1.1177 - val_accuracy: 0.6983\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4307 - accuracy: 0.9346 - val_loss: 1.1336 - val_accuracy: 0.6963\n","Epoch 91/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4317 - accuracy: 0.9318 - val_loss: 1.1196 - val_accuracy: 0.6983\n","Epoch 92/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4362 - accuracy: 0.9289 - val_loss: 1.1143 - val_accuracy: 0.6932\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4514 - accuracy: 0.9140 - val_loss: 1.1601 - val_accuracy: 0.6921\n","Epoch 94/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4372 - accuracy: 0.9279 - val_loss: 1.1728 - val_accuracy: 0.6921\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4259 - accuracy: 0.9331 - val_loss: 1.1274 - val_accuracy: 0.7056\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4195 - accuracy: 0.9393 - val_loss: 1.1420 - val_accuracy: 0.6994\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4187 - accuracy: 0.9439 - val_loss: 1.1354 - val_accuracy: 0.6973\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4189 - accuracy: 0.9385 - val_loss: 1.1446 - val_accuracy: 0.6963\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4208 - accuracy: 0.9328 - val_loss: 1.2105 - val_accuracy: 0.6839\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4216 - accuracy: 0.9323 - val_loss: 1.1484 - val_accuracy: 0.6983\n","{'loss': [0.6624010801315308, 0.6458471417427063, 0.645857036113739, 0.6343569159507751, 0.6264587640762329, 0.6219475865364075, 0.616856575012207, 0.6208884716033936, 0.6195021271705627, 0.6079325079917908, 0.60394686460495, 0.6035346388816833, 0.5955101847648621, 0.5933871865272522, 0.5937082767486572, 0.5960336327552795, 0.6072298288345337, 0.5817940831184387, 0.5796823501586914, 0.5751263499259949, 0.5756759643554688, 0.571086585521698, 0.5682646632194519, 0.5645977854728699, 0.5633167624473572, 0.5608255863189697, 0.558677613735199, 0.5569233894348145, 0.5535151362419128, 0.5544905066490173, 0.5481890439987183, 0.5546131134033203, 0.5453919172286987, 0.5429892539978027, 0.5372082591056824, 0.5321095585823059, 0.5378291010856628, 0.5316611528396606, 0.5342013835906982, 0.5264930129051208, 0.5222342014312744, 0.5200746059417725, 0.5193535089492798, 0.5169663429260254, 0.5163789391517639, 0.511850118637085, 0.508882462978363, 0.5104278922080994, 0.5043174624443054, 0.5027538537979126, 0.4971410632133484, 0.4961671829223633, 0.5004162192344666, 0.5117250680923462, 0.5001748204231262, 0.4897722005844116, 0.49060747027397156, 0.501311719417572, 0.503736138343811, 0.48658087849617004, 0.48964381217956543, 0.49260735511779785, 0.47885388135910034, 0.48828330636024475, 0.47795993089675903, 0.47121304273605347, 0.46620675921440125, 0.464767187833786, 0.4625545144081116, 0.4620380997657776, 0.4631759226322174, 0.45832884311676025, 0.46314284205436707, 0.4709787368774414, 0.4734276533126831, 0.45514655113220215, 0.4492921233177185, 0.45459917187690735, 0.44931545853614807, 0.4432780146598816, 0.441058874130249, 0.44344595074653625, 0.43720147013664246, 0.43969833850860596, 0.4362122416496277, 0.43439415097236633, 0.4407441318035126, 0.4327045679092407, 0.42965877056121826, 0.4307202994823456, 0.43171370029449463, 0.4361579418182373, 0.4513893723487854, 0.4371638000011444, 0.4258977472782135, 0.41946396231651306, 0.41867509484291077, 0.41885021328926086, 0.4207897484302521, 0.421581894159317], 'accuracy': [0.8263565897941589, 0.8354005217552185, 0.8379845023155212, 0.8379845023155212, 0.8436692357063293, 0.8480620384216309, 0.8478035926818848, 0.8426356315612793, 0.8441860675811768, 0.8529715538024902, 0.854780375957489, 0.856589138507843, 0.8596899509429932, 0.8633074760437012, 0.8607234954833984, 0.8583979606628418, 0.8576227426528931, 0.8648578524589539, 0.8684754371643066, 0.8684754371643066, 0.8661498427391052, 0.8708010315895081, 0.8733850121498108, 0.8819121718406677, 0.8775193691253662, 0.8808785676956177, 0.8780362010002136, 0.8824289441108704, 0.8826873302459717, 0.8795865774154663, 0.8790697455406189, 0.8777777552604675, 0.8832041621208191, 0.8852713108062744, 0.8927648663520813, 0.8930232524871826, 0.8873385190963745, 0.8930232524871826, 0.8883720636367798, 0.8958656191825867, 0.8948320150375366, 0.8984495997428894, 0.9002584218978882, 0.9005168080329895, 0.8997415900230408, 0.9046511650085449, 0.9031007885932922, 0.9002584218978882, 0.9059431552886963, 0.9087855219841003, 0.9093023538589478, 0.9087855219841003, 0.9054263830184937, 0.9005168080329895, 0.9082687497138977, 0.9136950969696045, 0.9129198789596558, 0.9005168080329895, 0.9069767594337463, 0.9111111164093018, 0.9077519178390503, 0.9142118692398071, 0.9134367108345032, 0.9105943441390991, 0.9160206913948059, 0.9175710678100586, 0.920671820640564, 0.9240310192108154, 0.9224806427955627, 0.9250646233558655, 0.9229974150657654, 0.9260981678962708, 0.9224806427955627, 0.9136950969696045, 0.9167958498001099, 0.9214470386505127, 0.9281653761863708, 0.9193798303604126, 0.9260981678962708, 0.9299741387367249, 0.9325581192970276, 0.9276486039161682, 0.930232584476471, 0.9286821484565735, 0.9291989803314209, 0.9351420998573303, 0.9312661290168762, 0.933074951171875, 0.9335917234420776, 0.9346253275871277, 0.9317829608917236, 0.9289405941963196, 0.9139534831047058, 0.9279069900512695, 0.933074951171875, 0.9392764568328857, 0.9439276456832886, 0.9385012984275818, 0.9328165650367737, 0.9322997331619263], 'val_loss': [0.9711818099021912, 0.9679218530654907, 0.9602948427200317, 0.9712085127830505, 0.9642995595932007, 0.9517402052879333, 0.9299949407577515, 0.9193769097328186, 0.9165302515029907, 0.9090713262557983, 0.9014085531234741, 0.9000197649002075, 0.8849969506263733, 0.8738093376159668, 0.8836047053337097, 0.8685899972915649, 0.8720962405204773, 0.8663896322250366, 0.8620069026947021, 0.8756640553474426, 0.8756066560745239, 0.8876731991767883, 0.8902078866958618, 0.8992630243301392, 0.9090588092803955, 0.9184673428535461, 0.9352294206619263, 0.9450703859329224, 0.9388480186462402, 0.9468635320663452, 0.9455023407936096, 0.9513949155807495, 0.9494290947914124, 0.9608976244926453, 0.9538717269897461, 0.9795480370521545, 0.9800111651420593, 1.0234888792037964, 0.9727239012718201, 0.964584231376648, 0.9736486673355103, 0.9837708473205566, 0.9811617732048035, 1.0059009790420532, 0.9959486722946167, 1.0014010667800903, 1.0094857215881348, 1.0064153671264648, 1.0104091167449951, 0.9972392916679382, 1.00987708568573, 1.0026134252548218, 1.0283262729644775, 1.0433790683746338, 1.0262240171432495, 1.0215845108032227, 1.043874740600586, 1.1002346277236938, 1.030747652053833, 1.0365312099456787, 1.1001787185668945, 1.06134831905365, 1.0373525619506836, 1.0521013736724854, 1.0465666055679321, 1.0483832359313965, 1.044469952583313, 1.0574508905410767, 1.039738655090332, 1.0610824823379517, 1.0581992864608765, 1.062710165977478, 1.1105931997299194, 1.0929596424102783, 1.0820469856262207, 1.0853767395019531, 1.108573079109192, 1.0845125913619995, 1.0780752897262573, 1.0810538530349731, 1.1001882553100586, 1.0973427295684814, 1.0906407833099365, 1.1174757480621338, 1.0992443561553955, 1.1136244535446167, 1.138046145439148, 1.1100114583969116, 1.1177287101745605, 1.133641242980957, 1.119592308998108, 1.1143097877502441, 1.1600685119628906, 1.17279851436615, 1.1274117231369019, 1.1419899463653564, 1.135391116142273, 1.1445614099502563, 1.21051025390625, 1.1484264135360718], 'val_accuracy': [0.5361570119857788, 0.5433884263038635, 0.5485537052154541, 0.5423553586006165, 0.5454545617103577, 0.5599173307418823, 0.58574378490448, 0.6126033067703247, 0.6095041036605835, 0.6280992031097412, 0.6363636255264282, 0.6611570119857788, 0.6869834661483765, 0.69111567735672, 0.6787189841270447, 0.6973140239715576, 0.6973140239715576, 0.7097107172012329, 0.711776852607727, 0.702479362487793, 0.7076446413993835, 0.7076446413993835, 0.7128099203109741, 0.7066115736961365, 0.7055785059928894, 0.711776852607727, 0.7004132270812988, 0.7014462947845459, 0.7097107172012329, 0.711776852607727, 0.7097107172012329, 0.7138429880142212, 0.711776852607727, 0.7097107172012329, 0.7200413346290588, 0.7045454382896423, 0.7086777091026306, 0.7035123705863953, 0.7190082669258118, 0.7128099203109741, 0.7066115736961365, 0.71074378490448, 0.7128099203109741, 0.711776852607727, 0.7004132270812988, 0.7097107172012329, 0.7097107172012329, 0.7066115736961365, 0.7076446413993835, 0.7138429880142212, 0.7055785059928894, 0.7066115736961365, 0.7055785059928894, 0.7035123705863953, 0.6993801593780518, 0.7066115736961365, 0.7014462947845459, 0.692148745059967, 0.6983470916748047, 0.711776852607727, 0.672520637512207, 0.7066115736961365, 0.7055785059928894, 0.7004132270812988, 0.7004132270812988, 0.7055785059928894, 0.7035123705863953, 0.7035123705863953, 0.71074378490448, 0.702479362487793, 0.6993801593780518, 0.7045454382896423, 0.6962810158729553, 0.6890496015548706, 0.7055785059928894, 0.7045454382896423, 0.68388432264328, 0.7097107172012329, 0.6993801593780518, 0.7055785059928894, 0.7014462947845459, 0.7055785059928894, 0.7076446413993835, 0.6952479481697083, 0.7035123705863953, 0.6983470916748047, 0.692148745059967, 0.7014462947845459, 0.6983470916748047, 0.6962810158729553, 0.6983470916748047, 0.6931818127632141, 0.692148745059967, 0.692148745059967, 0.7055785059928894, 0.6993801593780518, 0.6973140239715576, 0.6962810158729553, 0.68388432264328, 0.6983470916748047]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 31ms/step - loss: 0.4807 - accuracy: 0.9073 - val_loss: 0.8958 - val_accuracy: 0.6649\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.4356 - accuracy: 0.9375"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 13ms/step - loss: 0.4592 - accuracy: 0.9154 - val_loss: 0.8949 - val_accuracy: 0.6088\n","Epoch 3/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4546 - accuracy: 0.9178 - val_loss: 0.8847 - val_accuracy: 0.6315\n","Epoch 4/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4458 - accuracy: 0.9286 - val_loss: 0.8765 - val_accuracy: 0.6530\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4407 - accuracy: 0.9248 - val_loss: 0.8777 - val_accuracy: 0.6250\n","Epoch 6/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4360 - accuracy: 0.9302 - val_loss: 0.8599 - val_accuracy: 0.6961\n","Epoch 7/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4315 - accuracy: 0.9313 - val_loss: 0.8610 - val_accuracy: 0.6562\n","Epoch 8/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4272 - accuracy: 0.9340 - val_loss: 0.8636 - val_accuracy: 0.6336\n","Epoch 9/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4265 - accuracy: 0.9329 - val_loss: 0.8538 - val_accuracy: 0.6552\n","Epoch 10/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.4255 - accuracy: 0.9343 - val_loss: 0.8313 - val_accuracy: 0.7026\n","Epoch 11/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4257 - accuracy: 0.9321 - val_loss: 0.8537 - val_accuracy: 0.6422\n","Epoch 12/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4352 - accuracy: 0.9275 - val_loss: 0.8257 - val_accuracy: 0.6929\n","Epoch 13/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4329 - accuracy: 0.9327 - val_loss: 0.8326 - val_accuracy: 0.6703\n","Epoch 14/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4312 - accuracy: 0.9305 - val_loss: 0.8394 - val_accuracy: 0.6670\n","Epoch 15/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4151 - accuracy: 0.9423 - val_loss: 0.8008 - val_accuracy: 0.7241\n","Epoch 16/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4141 - accuracy: 0.9383 - val_loss: 0.8039 - val_accuracy: 0.7091\n","Epoch 17/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4102 - accuracy: 0.9402 - val_loss: 0.7892 - val_accuracy: 0.7338\n","Epoch 18/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4069 - accuracy: 0.9413 - val_loss: 0.7944 - val_accuracy: 0.7295\n","Epoch 19/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4064 - accuracy: 0.9437 - val_loss: 0.7799 - val_accuracy: 0.7543\n","Epoch 20/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4018 - accuracy: 0.9456 - val_loss: 0.7986 - val_accuracy: 0.7414\n","Epoch 21/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4020 - accuracy: 0.9423 - val_loss: 0.7837 - val_accuracy: 0.7737\n","Epoch 22/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4041 - accuracy: 0.9415 - val_loss: 0.8182 - val_accuracy: 0.7381\n","Epoch 23/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4000 - accuracy: 0.9464 - val_loss: 0.7942 - val_accuracy: 0.7705\n","Epoch 24/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3942 - accuracy: 0.9475 - val_loss: 0.7983 - val_accuracy: 0.7716\n","Epoch 25/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3942 - accuracy: 0.9488 - val_loss: 0.8111 - val_accuracy: 0.7834\n","Epoch 26/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3912 - accuracy: 0.9502 - val_loss: 0.8187 - val_accuracy: 0.7705\n","Epoch 27/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3909 - accuracy: 0.9515 - val_loss: 0.8234 - val_accuracy: 0.7759\n","Epoch 28/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3871 - accuracy: 0.9496 - val_loss: 0.8270 - val_accuracy: 0.7812\n","Epoch 29/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3867 - accuracy: 0.9472 - val_loss: 0.8549 - val_accuracy: 0.7812\n","Epoch 30/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3838 - accuracy: 0.9534 - val_loss: 0.8516 - val_accuracy: 0.7877\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3864 - accuracy: 0.9472 - val_loss: 0.8580 - val_accuracy: 0.7812\n","Epoch 32/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3823 - accuracy: 0.9499 - val_loss: 0.8900 - val_accuracy: 0.7500\n","Epoch 33/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3947 - accuracy: 0.9407 - val_loss: 0.9266 - val_accuracy: 0.7694\n","Epoch 34/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3908 - accuracy: 0.9472 - val_loss: 0.9476 - val_accuracy: 0.7629\n","Epoch 35/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3884 - accuracy: 0.9469 - val_loss: 0.9233 - val_accuracy: 0.7737\n","Epoch 36/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4563 - accuracy: 0.9197 - val_loss: 0.9871 - val_accuracy: 0.7575\n","Epoch 37/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4329 - accuracy: 0.9275 - val_loss: 0.9134 - val_accuracy: 0.7489\n","Epoch 38/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3859 - accuracy: 0.9475 - val_loss: 0.9051 - val_accuracy: 0.7478\n","Epoch 39/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3834 - accuracy: 0.9480 - val_loss: 0.9100 - val_accuracy: 0.7478\n","Epoch 40/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3837 - accuracy: 0.9496 - val_loss: 0.9065 - val_accuracy: 0.7705\n","Epoch 41/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3765 - accuracy: 0.9529 - val_loss: 0.9047 - val_accuracy: 0.7500\n","Epoch 42/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3720 - accuracy: 0.9526 - val_loss: 0.8939 - val_accuracy: 0.7651\n","Epoch 43/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3691 - accuracy: 0.9523 - val_loss: 0.9005 - val_accuracy: 0.7769\n","Epoch 44/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3683 - accuracy: 0.9542 - val_loss: 0.9062 - val_accuracy: 0.7769\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3678 - accuracy: 0.9547 - val_loss: 0.8940 - val_accuracy: 0.7705\n","Epoch 46/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3643 - accuracy: 0.9599 - val_loss: 0.9079 - val_accuracy: 0.7608\n","Epoch 47/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3647 - accuracy: 0.9561 - val_loss: 0.9184 - val_accuracy: 0.7532\n","Epoch 48/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3651 - accuracy: 0.9593 - val_loss: 0.9058 - val_accuracy: 0.7748\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3635 - accuracy: 0.9577 - val_loss: 0.9121 - val_accuracy: 0.7791\n","Epoch 50/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3595 - accuracy: 0.9585 - val_loss: 0.9258 - val_accuracy: 0.7619\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3614 - accuracy: 0.9572 - val_loss: 0.9201 - val_accuracy: 0.7726\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3576 - accuracy: 0.9580 - val_loss: 0.9111 - val_accuracy: 0.7737\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3571 - accuracy: 0.9596 - val_loss: 0.9158 - val_accuracy: 0.7619\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3556 - accuracy: 0.9599 - val_loss: 0.9226 - val_accuracy: 0.7662\n","Epoch 55/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3566 - accuracy: 0.9539 - val_loss: 0.9240 - val_accuracy: 0.7759\n","Epoch 56/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3552 - accuracy: 0.9599 - val_loss: 0.9226 - val_accuracy: 0.7748\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3530 - accuracy: 0.9615 - val_loss: 0.9272 - val_accuracy: 0.7683\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3514 - accuracy: 0.9593 - val_loss: 0.9272 - val_accuracy: 0.7716\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3522 - accuracy: 0.9612 - val_loss: 0.9569 - val_accuracy: 0.7726\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3515 - accuracy: 0.9601 - val_loss: 0.9422 - val_accuracy: 0.7575\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3491 - accuracy: 0.9620 - val_loss: 0.9475 - val_accuracy: 0.7468\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3488 - accuracy: 0.9631 - val_loss: 0.9540 - val_accuracy: 0.7597\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3480 - accuracy: 0.9626 - val_loss: 0.9424 - val_accuracy: 0.7619\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3466 - accuracy: 0.9642 - val_loss: 0.9561 - val_accuracy: 0.7629\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3437 - accuracy: 0.9634 - val_loss: 0.9473 - val_accuracy: 0.7651\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3437 - accuracy: 0.9655 - val_loss: 0.9737 - val_accuracy: 0.7543\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3469 - accuracy: 0.9604 - val_loss: 0.9584 - val_accuracy: 0.7705\n","Epoch 68/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3484 - accuracy: 0.9580 - val_loss: 0.9540 - val_accuracy: 0.7586\n","Epoch 69/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3418 - accuracy: 0.9634 - val_loss: 0.9557 - val_accuracy: 0.7511\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3405 - accuracy: 0.9636 - val_loss: 0.9618 - val_accuracy: 0.7554\n","Epoch 71/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3390 - accuracy: 0.9642 - val_loss: 0.9915 - val_accuracy: 0.7392\n","Epoch 72/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3429 - accuracy: 0.9647 - val_loss: 0.9896 - val_accuracy: 0.7457\n","Epoch 73/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3415 - accuracy: 0.9636 - val_loss: 0.9804 - val_accuracy: 0.7672\n","Epoch 74/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3344 - accuracy: 0.9666 - val_loss: 0.9893 - val_accuracy: 0.7435\n","Epoch 75/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3381 - accuracy: 0.9642 - val_loss: 1.0001 - val_accuracy: 0.7349\n","Epoch 76/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3431 - accuracy: 0.9609 - val_loss: 0.9916 - val_accuracy: 0.7554\n","Epoch 77/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3351 - accuracy: 0.9663 - val_loss: 0.9935 - val_accuracy: 0.7629\n","Epoch 78/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3340 - accuracy: 0.9679 - val_loss: 0.9788 - val_accuracy: 0.7651\n","Epoch 79/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3337 - accuracy: 0.9644 - val_loss: 0.9896 - val_accuracy: 0.7575\n","Epoch 80/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3296 - accuracy: 0.9677 - val_loss: 0.9789 - val_accuracy: 0.7683\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3299 - accuracy: 0.9677 - val_loss: 1.0074 - val_accuracy: 0.7522\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3278 - accuracy: 0.9704 - val_loss: 0.9901 - val_accuracy: 0.7500\n","Epoch 83/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3281 - accuracy: 0.9714 - val_loss: 0.9899 - val_accuracy: 0.7575\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3292 - accuracy: 0.9663 - val_loss: 1.0150 - val_accuracy: 0.7532\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3263 - accuracy: 0.9688 - val_loss: 1.0510 - val_accuracy: 0.7575\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3263 - accuracy: 0.9671 - val_loss: 1.0278 - val_accuracy: 0.7619\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3276 - accuracy: 0.9644 - val_loss: 1.0539 - val_accuracy: 0.7338\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3247 - accuracy: 0.9714 - val_loss: 1.0292 - val_accuracy: 0.7468\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3771 - accuracy: 0.9566 - val_loss: 1.2864 - val_accuracy: 0.7015\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4639 - accuracy: 0.9356 - val_loss: 1.1342 - val_accuracy: 0.7360\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4123 - accuracy: 0.9383 - val_loss: 1.1531 - val_accuracy: 0.7177\n","Epoch 92/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3572 - accuracy: 0.9609 - val_loss: 1.1775 - val_accuracy: 0.7037\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3307 - accuracy: 0.9661 - val_loss: 1.0658 - val_accuracy: 0.7349\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3290 - accuracy: 0.9701 - val_loss: 1.0536 - val_accuracy: 0.7511\n","Epoch 95/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3342 - accuracy: 0.9652 - val_loss: 1.0422 - val_accuracy: 0.7403\n","Epoch 96/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3212 - accuracy: 0.9709 - val_loss: 1.0400 - val_accuracy: 0.7457\n","Epoch 97/100\n","29/29 [==============================] - 0s 11ms/step - loss: 0.3196 - accuracy: 0.9720 - val_loss: 1.0454 - val_accuracy: 0.7554\n","Epoch 98/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3192 - accuracy: 0.9701 - val_loss: 1.0370 - val_accuracy: 0.7500\n","Epoch 99/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3166 - accuracy: 0.9733 - val_loss: 1.0418 - val_accuracy: 0.7446\n","Epoch 100/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3157 - accuracy: 0.9723 - val_loss: 1.0494 - val_accuracy: 0.7425\n","{'loss': [0.48073673248291016, 0.4592057466506958, 0.4545951187610626, 0.4457680881023407, 0.44066664576530457, 0.43595385551452637, 0.43146950006484985, 0.42723533511161804, 0.42646631598472595, 0.4255096912384033, 0.42568403482437134, 0.43519678711891174, 0.43293389678001404, 0.43121618032455444, 0.4151413142681122, 0.4140660762786865, 0.4102484881877899, 0.4068641662597656, 0.406436949968338, 0.40178152918815613, 0.4019906520843506, 0.40414154529571533, 0.39997178316116333, 0.39423370361328125, 0.3942309617996216, 0.3911762535572052, 0.39090874791145325, 0.3871285617351532, 0.3866952955722809, 0.3837810456752777, 0.38639241456985474, 0.3823111653327942, 0.39468616247177124, 0.3908361792564392, 0.3884074091911316, 0.45626598596572876, 0.4329341948032379, 0.38592711091041565, 0.38343092799186707, 0.3836885690689087, 0.3765086531639099, 0.3720395863056183, 0.3690580427646637, 0.368257075548172, 0.3678480386734009, 0.36429402232170105, 0.36472809314727783, 0.36513954401016235, 0.36347097158432007, 0.35954880714416504, 0.3614467978477478, 0.3576069474220276, 0.35714495182037354, 0.35556575655937195, 0.3565894067287445, 0.35518717765808105, 0.35297152400016785, 0.3514344394207001, 0.3521546721458435, 0.3514707684516907, 0.3490772247314453, 0.3488462567329407, 0.3479677438735962, 0.3466041386127472, 0.34373700618743896, 0.3437204360961914, 0.3469265103340149, 0.34844693541526794, 0.34176963567733765, 0.3405300974845886, 0.33899521827697754, 0.3429486155509949, 0.341467022895813, 0.3343895673751831, 0.33806344866752625, 0.3431427478790283, 0.33505189418792725, 0.3340403139591217, 0.3336886763572693, 0.32959944009780884, 0.32991263270378113, 0.32780054211616516, 0.32810667157173157, 0.3292020261287689, 0.32626810669898987, 0.32632794976234436, 0.32763954997062683, 0.32474905252456665, 0.3770805895328522, 0.46391913294792175, 0.412312388420105, 0.35716018080711365, 0.3307362496852875, 0.3289540112018585, 0.33421170711517334, 0.3211662769317627, 0.3195725083351135, 0.3192169964313507, 0.31663423776626587, 0.3157026171684265], 'accuracy': [0.9073275923728943, 0.915409505367279, 0.9178340435028076, 0.9286099076271057, 0.9248383641242981, 0.9302262663841248, 0.931303858757019, 0.9339978694915771, 0.9329202771186829, 0.9342672228813171, 0.9321120977401733, 0.9275323152542114, 0.9326508641242981, 0.9304956793785095, 0.9423491358757019, 0.9383081793785095, 0.9401939511299133, 0.9412715435028076, 0.943696141242981, 0.9455819129943848, 0.9423491358757019, 0.9415409564971924, 0.9463900923728943, 0.9474676847457886, 0.9488146305084229, 0.9501616358757019, 0.951508641242981, 0.9496228694915771, 0.9471982717514038, 0.9533944129943848, 0.9471982717514038, 0.9498922228813171, 0.9407327771186829, 0.9471982717514038, 0.946928858757019, 0.9197198152542114, 0.9275323152542114, 0.9474676847457886, 0.9480064511299133, 0.9496228694915771, 0.9528555870056152, 0.9525862336158752, 0.9523168206214905, 0.9542025923728943, 0.954741358757019, 0.9598599076271057, 0.9560883641242981, 0.959321141242981, 0.9577047228813171, 0.9585129022598267, 0.9571659564971924, 0.9579741358757019, 0.959590494632721, 0.9598599076271057, 0.9539331793785095, 0.9598599076271057, 0.9614762663841248, 0.959321141242981, 0.9612069129943848, 0.9601293206214905, 0.9620150923728943, 0.9630926847457886, 0.962553858757019, 0.9641702771186829, 0.9633620977401733, 0.9655172228813171, 0.9603987336158752, 0.9579741358757019, 0.9633620977401733, 0.9636314511299133, 0.9641702771186829, 0.9647090435028076, 0.9636314511299133, 0.9665948152542114, 0.9641702771186829, 0.9609375, 0.9663254022598267, 0.9679418206214905, 0.9644396305084229, 0.9676724076271057, 0.9676724076271057, 0.970366358757019, 0.9714439511299133, 0.9663254022598267, 0.96875, 0.967133641242981, 0.9644396305084229, 0.9714439511299133, 0.9566271305084229, 0.9356142282485962, 0.9383081793785095, 0.9609375, 0.9660560488700867, 0.970097005367279, 0.9652478694915771, 0.9709051847457886, 0.9719827771186829, 0.970097005367279, 0.9733297228813171, 0.9722521305084229], 'val_loss': [0.8957871198654175, 0.8949365019798279, 0.8847104907035828, 0.8764544725418091, 0.8777076601982117, 0.8598577976226807, 0.8609816431999207, 0.8635588884353638, 0.8537614345550537, 0.8312699794769287, 0.8536815047264099, 0.8257423043251038, 0.832586944103241, 0.8393725752830505, 0.8007875084877014, 0.8038531541824341, 0.7892488241195679, 0.7944023013114929, 0.77987140417099, 0.7986176609992981, 0.7836989164352417, 0.818230926990509, 0.7942258715629578, 0.7983085513114929, 0.8110896348953247, 0.8187209367752075, 0.8233734369277954, 0.8270055651664734, 0.8549444675445557, 0.8516444563865662, 0.8579646348953247, 0.8899852633476257, 0.9266420602798462, 0.9476388096809387, 0.9233126640319824, 0.9870798587799072, 0.9134180545806885, 0.9051341414451599, 0.9099806547164917, 0.9065312743186951, 0.9047377109527588, 0.8938711881637573, 0.9005452990531921, 0.9061808586120605, 0.893986165523529, 0.9078746438026428, 0.9183533787727356, 0.9058067798614502, 0.9121041893959045, 0.9257868528366089, 0.9200654625892639, 0.9110734462738037, 0.9158329963684082, 0.9225935935974121, 0.9240206480026245, 0.9226269125938416, 0.9272288680076599, 0.9272448420524597, 0.956871509552002, 0.9422441720962524, 0.947548508644104, 0.9539725184440613, 0.9424254298210144, 0.9560505151748657, 0.9472777843475342, 0.9736891388893127, 0.9584277868270874, 0.9539954662322998, 0.9556764960289001, 0.961751401424408, 0.9915245771408081, 0.989574670791626, 0.9803890585899353, 0.98930823802948, 1.0001192092895508, 0.9916438460350037, 0.9934894442558289, 0.9788056015968323, 0.9895503520965576, 0.978895902633667, 1.0074206590652466, 0.9901478886604309, 0.9898635149002075, 1.0150169134140015, 1.0509660243988037, 1.0277574062347412, 1.053874135017395, 1.0291848182678223, 1.2864305973052979, 1.134202480316162, 1.1530821323394775, 1.1775091886520386, 1.065808653831482, 1.0536208152770996, 1.042189598083496, 1.039982557296753, 1.0454068183898926, 1.0370166301727295, 1.04176926612854, 1.0494086742401123], 'val_accuracy': [0.6648706793785095, 0.6088362336158752, 0.631465494632721, 0.6530172228813171, 0.625, 0.6961206793785095, 0.65625, 0.6336206793785095, 0.6551724076271057, 0.7025862336158752, 0.642241358757019, 0.6928879022598267, 0.670258641242981, 0.6670258641242981, 0.7241379022598267, 0.7090517282485962, 0.7338362336158752, 0.7295258641242981, 0.7543103694915771, 0.7413793206214905, 0.7737069129943848, 0.7381465435028076, 0.7704741358757019, 0.7715517282485962, 0.7834051847457886, 0.7704741358757019, 0.7758620977401733, 0.78125, 0.78125, 0.787715494632721, 0.78125, 0.75, 0.7693965435028076, 0.7629310488700867, 0.7737069129943848, 0.7575430870056152, 0.7489224076271057, 0.7478448152542114, 0.7478448152542114, 0.7704741358757019, 0.75, 0.7650862336158752, 0.7769396305084229, 0.7769396305084229, 0.7704741358757019, 0.7607758641242981, 0.7532327771186829, 0.774784505367279, 0.7790948152542114, 0.7618534564971924, 0.7726293206214905, 0.7737069129943848, 0.7618534564971924, 0.7661637663841248, 0.7758620977401733, 0.774784505367279, 0.7683189511299133, 0.7715517282485962, 0.7726293206214905, 0.7575430870056152, 0.7467672228813171, 0.7596982717514038, 0.7618534564971924, 0.7629310488700867, 0.7650862336158752, 0.7543103694915771, 0.7704741358757019, 0.7586206793785095, 0.7510775923728943, 0.7553879022598267, 0.7392241358757019, 0.7456896305084229, 0.767241358757019, 0.743534505367279, 0.7349137663841248, 0.7553879022598267, 0.7629310488700867, 0.7650862336158752, 0.7575430870056152, 0.7683189511299133, 0.7521551847457886, 0.75, 0.7575430870056152, 0.7532327771186829, 0.7575430870056152, 0.7618534564971924, 0.7338362336158752, 0.7467672228813171, 0.701508641242981, 0.735991358757019, 0.7176724076271057, 0.7036637663841248, 0.7349137663841248, 0.7510775923728943, 0.7403017282485962, 0.7456896305084229, 0.7553879022598267, 0.75, 0.7446120977401733, 0.7424569129943848]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","25/28 [=========================>....] - ETA: 0s - loss: 0.4911 - accuracy: 0.8956"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 4s 38ms/step - loss: 0.4886 - accuracy: 0.8976 - val_loss: 0.9142 - val_accuracy: 0.5939\n","Epoch 2/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4661 - accuracy: 0.9100 - val_loss: 0.9119 - val_accuracy: 0.5554\n","Epoch 3/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4640 - accuracy: 0.9111 - val_loss: 0.9047 - val_accuracy: 0.5724\n","Epoch 4/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4470 - accuracy: 0.9259 - val_loss: 0.9029 - val_accuracy: 0.5690\n","Epoch 5/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4428 - accuracy: 0.9242 - val_loss: 0.9022 - val_accuracy: 0.5588\n","Epoch 6/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4471 - accuracy: 0.9228 - val_loss: 0.8832 - val_accuracy: 0.6256\n","Epoch 7/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4517 - accuracy: 0.9171 - val_loss: 0.8818 - val_accuracy: 0.6097\n","Epoch 8/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4385 - accuracy: 0.9270 - val_loss: 0.8987 - val_accuracy: 0.5645\n","Epoch 9/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.4520 - accuracy: 0.9219 - val_loss: 0.8679 - val_accuracy: 0.6482\n","Epoch 10/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4638 - accuracy: 0.9080 - val_loss: 0.8898 - val_accuracy: 0.5871\n","Epoch 11/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4416 - accuracy: 0.9219 - val_loss: 0.8872 - val_accuracy: 0.5905\n","Epoch 12/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4274 - accuracy: 0.9349 - val_loss: 0.8568 - val_accuracy: 0.6448\n","Epoch 13/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4213 - accuracy: 0.9360 - val_loss: 0.8627 - val_accuracy: 0.6222\n","Epoch 14/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4216 - accuracy: 0.9346 - val_loss: 0.8758 - val_accuracy: 0.6131\n","Epoch 15/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4187 - accuracy: 0.9380 - val_loss: 0.8626 - val_accuracy: 0.6244\n","Epoch 16/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4180 - accuracy: 0.9383 - val_loss: 0.8278 - val_accuracy: 0.6776\n","Epoch 17/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4166 - accuracy: 0.9400 - val_loss: 0.8073 - val_accuracy: 0.7229\n","Epoch 18/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4133 - accuracy: 0.9386 - val_loss: 0.8112 - val_accuracy: 0.7206\n","Epoch 19/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4110 - accuracy: 0.9400 - val_loss: 0.7951 - val_accuracy: 0.7364\n","Epoch 20/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4096 - accuracy: 0.9437 - val_loss: 0.8006 - val_accuracy: 0.7319\n","Epoch 21/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4102 - accuracy: 0.9423 - val_loss: 0.8069 - val_accuracy: 0.7138\n","Epoch 22/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4099 - accuracy: 0.9403 - val_loss: 0.8018 - val_accuracy: 0.7421\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4044 - accuracy: 0.9451 - val_loss: 0.8179 - val_accuracy: 0.7217\n","Epoch 24/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4055 - accuracy: 0.9426 - val_loss: 0.8000 - val_accuracy: 0.7568\n","Epoch 25/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.4016 - accuracy: 0.9454 - val_loss: 0.7948 - val_accuracy: 0.7805\n","Epoch 26/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4025 - accuracy: 0.9454 - val_loss: 0.8361 - val_accuracy: 0.7760\n","Epoch 27/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4002 - accuracy: 0.9457 - val_loss: 0.7975 - val_accuracy: 0.7828\n","Epoch 28/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4016 - accuracy: 0.9397 - val_loss: 0.8046 - val_accuracy: 0.7839\n","Epoch 29/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3965 - accuracy: 0.9496 - val_loss: 0.8276 - val_accuracy: 0.7805\n","Epoch 30/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3969 - accuracy: 0.9485 - val_loss: 0.8168 - val_accuracy: 0.7783\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3965 - accuracy: 0.9474 - val_loss: 0.8865 - val_accuracy: 0.7681\n","Epoch 32/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3976 - accuracy: 0.9434 - val_loss: 0.8292 - val_accuracy: 0.7760\n","Epoch 33/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3985 - accuracy: 0.9411 - val_loss: 0.8502 - val_accuracy: 0.7749\n","Epoch 34/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3922 - accuracy: 0.9482 - val_loss: 0.8632 - val_accuracy: 0.7613\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3868 - accuracy: 0.9510 - val_loss: 0.8738 - val_accuracy: 0.7670\n","Epoch 36/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3891 - accuracy: 0.9525 - val_loss: 0.8727 - val_accuracy: 0.7704\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3882 - accuracy: 0.9496 - val_loss: 0.8504 - val_accuracy: 0.7715\n","Epoch 38/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3857 - accuracy: 0.9502 - val_loss: 0.8671 - val_accuracy: 0.7681\n","Epoch 39/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3833 - accuracy: 0.9533 - val_loss: 0.8615 - val_accuracy: 0.7726\n","Epoch 40/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3851 - accuracy: 0.9502 - val_loss: 0.8638 - val_accuracy: 0.7568\n","Epoch 41/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3906 - accuracy: 0.9474 - val_loss: 0.9040 - val_accuracy: 0.7692\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.4082 - accuracy: 0.9389 - val_loss: 0.9509 - val_accuracy: 0.7624\n","Epoch 43/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4061 - accuracy: 0.9360 - val_loss: 0.9311 - val_accuracy: 0.7534\n","Epoch 44/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3918 - accuracy: 0.9485 - val_loss: 0.9910 - val_accuracy: 0.7410\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3968 - accuracy: 0.9372 - val_loss: 0.8714 - val_accuracy: 0.7726\n","Epoch 46/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3762 - accuracy: 0.9550 - val_loss: 0.8861 - val_accuracy: 0.7681\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3730 - accuracy: 0.9576 - val_loss: 0.8770 - val_accuracy: 0.7771\n","Epoch 48/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3707 - accuracy: 0.9573 - val_loss: 0.8762 - val_accuracy: 0.7647\n","Epoch 49/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3691 - accuracy: 0.9564 - val_loss: 0.8998 - val_accuracy: 0.7681\n","Epoch 50/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3700 - accuracy: 0.9573 - val_loss: 0.9020 - val_accuracy: 0.7681\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3681 - accuracy: 0.9550 - val_loss: 0.8954 - val_accuracy: 0.7670\n","Epoch 52/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3737 - accuracy: 0.9510 - val_loss: 0.9313 - val_accuracy: 0.7771\n","Epoch 53/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3671 - accuracy: 0.9587 - val_loss: 0.8979 - val_accuracy: 0.7692\n","Epoch 54/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3741 - accuracy: 0.9533 - val_loss: 0.9254 - val_accuracy: 0.7726\n","Epoch 55/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3676 - accuracy: 0.9581 - val_loss: 0.9352 - val_accuracy: 0.7681\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3648 - accuracy: 0.9567 - val_loss: 0.8977 - val_accuracy: 0.7692\n","Epoch 57/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3595 - accuracy: 0.9629 - val_loss: 0.9049 - val_accuracy: 0.7602\n","Epoch 58/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3606 - accuracy: 0.9601 - val_loss: 0.9571 - val_accuracy: 0.7681\n","Epoch 59/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3597 - accuracy: 0.9598 - val_loss: 0.9690 - val_accuracy: 0.7749\n","Epoch 60/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3621 - accuracy: 0.9584 - val_loss: 0.9039 - val_accuracy: 0.7624\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3591 - accuracy: 0.9598 - val_loss: 0.9328 - val_accuracy: 0.7704\n","Epoch 62/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3622 - accuracy: 0.9559 - val_loss: 0.9225 - val_accuracy: 0.7704\n","Epoch 63/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3582 - accuracy: 0.9624 - val_loss: 0.9383 - val_accuracy: 0.7738\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3713 - accuracy: 0.9573 - val_loss: 0.9795 - val_accuracy: 0.7443\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3642 - accuracy: 0.9593 - val_loss: 0.9606 - val_accuracy: 0.7477\n","Epoch 66/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3556 - accuracy: 0.9593 - val_loss: 0.9499 - val_accuracy: 0.7647\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3546 - accuracy: 0.9573 - val_loss: 0.9343 - val_accuracy: 0.7568\n","Epoch 68/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3610 - accuracy: 0.9578 - val_loss: 0.9717 - val_accuracy: 0.7557\n","Epoch 69/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3966 - accuracy: 0.9423 - val_loss: 0.9885 - val_accuracy: 0.7511\n","Epoch 70/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3534 - accuracy: 0.9593 - val_loss: 0.9441 - val_accuracy: 0.7613\n","Epoch 71/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3509 - accuracy: 0.9663 - val_loss: 0.9700 - val_accuracy: 0.7545\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3499 - accuracy: 0.9595 - val_loss: 0.9359 - val_accuracy: 0.7602\n","Epoch 73/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.3470 - accuracy: 0.9638 - val_loss: 0.9539 - val_accuracy: 0.7602\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3483 - accuracy: 0.9669 - val_loss: 0.9526 - val_accuracy: 0.7602\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3475 - accuracy: 0.9607 - val_loss: 0.9716 - val_accuracy: 0.7534\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3431 - accuracy: 0.9675 - val_loss: 0.9531 - val_accuracy: 0.7579\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3409 - accuracy: 0.9658 - val_loss: 0.9507 - val_accuracy: 0.7579\n","Epoch 78/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3431 - accuracy: 0.9624 - val_loss: 0.9729 - val_accuracy: 0.7590\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3411 - accuracy: 0.9675 - val_loss: 0.9702 - val_accuracy: 0.7647\n","Epoch 80/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3398 - accuracy: 0.9672 - val_loss: 0.9672 - val_accuracy: 0.7602\n","Epoch 81/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3408 - accuracy: 0.9632 - val_loss: 0.9797 - val_accuracy: 0.7613\n","Epoch 82/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3373 - accuracy: 0.9666 - val_loss: 0.9766 - val_accuracy: 0.7602\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3362 - accuracy: 0.9697 - val_loss: 0.9854 - val_accuracy: 0.7613\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3379 - accuracy: 0.9666 - val_loss: 0.9846 - val_accuracy: 0.7534\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3361 - accuracy: 0.9675 - val_loss: 1.0348 - val_accuracy: 0.7590\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3357 - accuracy: 0.9649 - val_loss: 1.0026 - val_accuracy: 0.7376\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3536 - accuracy: 0.9570 - val_loss: 1.2116 - val_accuracy: 0.7398\n","Epoch 88/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4037 - accuracy: 0.9409 - val_loss: 1.1059 - val_accuracy: 0.7557\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3527 - accuracy: 0.9584 - val_loss: 1.0042 - val_accuracy: 0.7477\n","Epoch 90/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3389 - accuracy: 0.9675 - val_loss: 1.0059 - val_accuracy: 0.7568\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3336 - accuracy: 0.9680 - val_loss: 1.0071 - val_accuracy: 0.7590\n","Epoch 92/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3345 - accuracy: 0.9663 - val_loss: 1.0027 - val_accuracy: 0.7523\n","Epoch 93/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3304 - accuracy: 0.9677 - val_loss: 1.0124 - val_accuracy: 0.7602\n","Epoch 94/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3282 - accuracy: 0.9717 - val_loss: 0.9932 - val_accuracy: 0.7534\n","Epoch 95/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3280 - accuracy: 0.9717 - val_loss: 0.9816 - val_accuracy: 0.7523\n","Epoch 96/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3256 - accuracy: 0.9706 - val_loss: 0.9993 - val_accuracy: 0.7590\n","Epoch 97/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3263 - accuracy: 0.9703 - val_loss: 1.0053 - val_accuracy: 0.7534\n","Epoch 98/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3257 - accuracy: 0.9703 - val_loss: 1.0087 - val_accuracy: 0.7568\n","Epoch 99/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3247 - accuracy: 0.9728 - val_loss: 1.0087 - val_accuracy: 0.7602\n","Epoch 100/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3245 - accuracy: 0.9728 - val_loss: 1.0273 - val_accuracy: 0.7568\n","{'loss': [0.4886489808559418, 0.4660608172416687, 0.46395203471183777, 0.4470219314098358, 0.4427776634693146, 0.44705671072006226, 0.4516896605491638, 0.43848374485969543, 0.45202502608299255, 0.46383389830589294, 0.44163569808006287, 0.4274103343486786, 0.4212700426578522, 0.4215892255306244, 0.4186892509460449, 0.4180018901824951, 0.41657063364982605, 0.41325414180755615, 0.4109928607940674, 0.40959087014198303, 0.410209059715271, 0.40993732213974, 0.40440115332603455, 0.40552619099617004, 0.4015958607196808, 0.4025202691555023, 0.4001760184764862, 0.4016300141811371, 0.3965446650981903, 0.39692604541778564, 0.3965446650981903, 0.3976122736930847, 0.39854127168655396, 0.392169713973999, 0.38682910799980164, 0.389058917760849, 0.38819149136543274, 0.38568177819252014, 0.3832659423351288, 0.3851207494735718, 0.3906101584434509, 0.4082305133342743, 0.406074583530426, 0.3918129801750183, 0.3968327045440674, 0.3762098550796509, 0.37301191687583923, 0.3707437813282013, 0.3691030740737915, 0.3700163662433624, 0.3680570125579834, 0.3736652433872223, 0.3671242296695709, 0.37410515546798706, 0.3676146864891052, 0.3647921681404114, 0.3594881594181061, 0.36055225133895874, 0.3597140908241272, 0.3621046245098114, 0.35912543535232544, 0.36224207282066345, 0.35819247364997864, 0.37130317091941833, 0.36420938372612, 0.3555883765220642, 0.3546203672885895, 0.36101147532463074, 0.39660120010375977, 0.35336771607398987, 0.35087358951568604, 0.34988269209861755, 0.34698486328125, 0.34833911061286926, 0.347464382648468, 0.3430849015712738, 0.3409413695335388, 0.34311309456825256, 0.34109559655189514, 0.3398227095603943, 0.3408266007900238, 0.3372511863708496, 0.33624133467674255, 0.33785656094551086, 0.33613789081573486, 0.3356912434101105, 0.3535587787628174, 0.4036701023578644, 0.35267195105552673, 0.33888569474220276, 0.33361753821372986, 0.3344604969024658, 0.3304298222064972, 0.3282195031642914, 0.328041136264801, 0.3255811035633087, 0.32627010345458984, 0.325675904750824, 0.32471394538879395, 0.3244929313659668], 'accuracy': [0.8975664973258972, 0.9100169539451599, 0.9111488461494446, 0.9258630275726318, 0.9241652488708496, 0.9227504134178162, 0.9170911312103271, 0.9269949197769165, 0.921901524066925, 0.9080362319946289, 0.921901524066925, 0.9349179267883301, 0.9360498189926147, 0.9346349835395813, 0.9380305409431458, 0.9383135437965393, 0.9400113224983215, 0.9385964870452881, 0.9400113224983215, 0.9436898827552795, 0.9422750473022461, 0.9402942657470703, 0.945104718208313, 0.9425579905509949, 0.9453876614570618, 0.9453876614570618, 0.9456706047058105, 0.9397283792495728, 0.9496321678161621, 0.9485002756118774, 0.9473684430122375, 0.943406879901886, 0.9411431550979614, 0.9482173323631287, 0.9510469436645508, 0.9524617791175842, 0.9496321678161621, 0.9501980543136597, 0.9533106684684753, 0.9501980543136597, 0.9473684430122375, 0.9388794302940369, 0.9360498189926147, 0.9485002756118774, 0.9371816515922546, 0.9550085067749023, 0.9575551748275757, 0.9572722315788269, 0.9564233422279358, 0.9572722315788269, 0.9550085067749023, 0.9510469436645508, 0.9586870670318604, 0.9533106684684753, 0.958121120929718, 0.9567062854766846, 0.9629315137863159, 0.960101842880249, 0.9598188996315002, 0.9584040641784668, 0.9598188996315002, 0.9558573961257935, 0.9623655676841736, 0.9572722315788269, 0.9592529535293579, 0.9592529535293579, 0.9572722315788269, 0.9578381180763245, 0.9422750473022461, 0.9592529535293579, 0.9663271307945251, 0.9595359563827515, 0.963780403137207, 0.9668930172920227, 0.9606677889823914, 0.967458963394165, 0.9657611846923828, 0.9623655676841736, 0.967458963394165, 0.9671760201454163, 0.9632145166397095, 0.9666100740432739, 0.9697226881980896, 0.9666100740432739, 0.967458963394165, 0.9649122953414917, 0.9569892287254333, 0.9408602118492126, 0.9584040641784668, 0.967458963394165, 0.9680249094963074, 0.9663271307945251, 0.9677419066429138, 0.9717034697532654, 0.9717034697532654, 0.9705715775489807, 0.9702886343002319, 0.9702886343002319, 0.9728353023529053, 0.9728353023529053], 'val_loss': [0.9141632318496704, 0.9119488596916199, 0.9046879410743713, 0.9028992652893066, 0.9022480249404907, 0.8832332491874695, 0.8818128705024719, 0.8986928462982178, 0.867895781993866, 0.8897840976715088, 0.8872148990631104, 0.8567504286766052, 0.8627021908760071, 0.8758347034454346, 0.8626015782356262, 0.8277586102485657, 0.8073291778564453, 0.8112270832061768, 0.7950916290283203, 0.8005760908126831, 0.8069446682929993, 0.801847517490387, 0.8178589344024658, 0.7999711036682129, 0.7948097586631775, 0.8361045122146606, 0.7975139617919922, 0.8045527935028076, 0.8276063203811646, 0.8167573809623718, 0.8864893317222595, 0.8291882276535034, 0.8502025604248047, 0.8632200956344604, 0.8738018870353699, 0.8727263808250427, 0.8504185080528259, 0.8671219348907471, 0.8615138530731201, 0.8637653589248657, 0.9039852619171143, 0.9509376883506775, 0.9310593008995056, 0.9910141825675964, 0.8714156150817871, 0.8861085176467896, 0.8770041465759277, 0.8761811256408691, 0.8997629880905151, 0.9020091891288757, 0.895407497882843, 0.9313184022903442, 0.8978742361068726, 0.9254055619239807, 0.9351652264595032, 0.8976539373397827, 0.9049189686775208, 0.9570591449737549, 0.9689648151397705, 0.9038733839988708, 0.9328405857086182, 0.9225330352783203, 0.9383482933044434, 0.9795442223548889, 0.9605939388275146, 0.9498549103736877, 0.934313178062439, 0.9716625213623047, 0.9884803891181946, 0.9441350698471069, 0.9700492024421692, 0.9359056353569031, 0.9538851976394653, 0.9526206851005554, 0.9715854525566101, 0.9530795812606812, 0.950709879398346, 0.9728520512580872, 0.9701755046844482, 0.9671807885169983, 0.9797084927558899, 0.9765747785568237, 0.9854161143302917, 0.9845908880233765, 1.03480064868927, 1.0026167631149292, 1.211629033088684, 1.1058579683303833, 1.0041950941085815, 1.005907654762268, 1.0070511102676392, 1.0026941299438477, 1.0124188661575317, 0.9932336807250977, 0.9815923571586609, 0.9992976188659668, 1.0053311586380005, 1.008698582649231, 1.0087016820907593, 1.0273162126541138], 'val_accuracy': [0.5938913822174072, 0.5554298758506775, 0.5723981857299805, 0.5690045356750488, 0.5588235259056091, 0.6255655884742737, 0.6097285151481628, 0.564479649066925, 0.6481900215148926, 0.587104082107544, 0.5904977321624756, 0.6447963714599609, 0.622171938419342, 0.6131221652030945, 0.6244344115257263, 0.6776018142700195, 0.7228506803512573, 0.720588207244873, 0.7364253401756287, 0.7319004535675049, 0.7138009071350098, 0.7420814633369446, 0.7217194437980652, 0.7567873597145081, 0.7805429697036743, 0.7760180830955505, 0.7828054428100586, 0.7839366793632507, 0.7805429697036743, 0.7782805562019348, 0.7680995464324951, 0.7760180830955505, 0.7748869061470032, 0.7613122463226318, 0.766968309879303, 0.7703620195388794, 0.7714931964874268, 0.7680995464324951, 0.7726244330406189, 0.7567873597145081, 0.7692307829856873, 0.7624434232711792, 0.7533936500549316, 0.7409502267837524, 0.7726244330406189, 0.7680995464324951, 0.7771493196487427, 0.7647058963775635, 0.7680995464324951, 0.7680995464324951, 0.766968309879303, 0.7771493196487427, 0.7692307829856873, 0.7726244330406189, 0.7680995464324951, 0.7692307829856873, 0.7601810097694397, 0.7680995464324951, 0.7748869061470032, 0.7624434232711792, 0.7703620195388794, 0.7703620195388794, 0.773755669593811, 0.7443438768386841, 0.7477375268936157, 0.7647058963775635, 0.7567873597145081, 0.7556561231613159, 0.7511312365531921, 0.7613122463226318, 0.7545248866081238, 0.7601810097694397, 0.7601810097694397, 0.7601810097694397, 0.7533936500549316, 0.7579185366630554, 0.7579185366630554, 0.7590497732162476, 0.7647058963775635, 0.7601810097694397, 0.7613122463226318, 0.7601810097694397, 0.7613122463226318, 0.7533936500549316, 0.7590497732162476, 0.7375565767288208, 0.7398189902305603, 0.7556561231613159, 0.7477375268936157, 0.7567873597145081, 0.7590497732162476, 0.7522624731063843, 0.7601810097694397, 0.7533936500549316, 0.7522624731063843, 0.7590497732162476, 0.7533936500549316, 0.7567873597145081, 0.7601810097694397, 0.7567873597145081]}\n","45/45 [==============================] - 0s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 5s 34ms/step - loss: 0.5034 - accuracy: 0.8938 - val_loss: 0.9149 - val_accuracy: 0.5764\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.4944 - accuracy: 0.8672"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 19ms/step - loss: 0.5027 - accuracy: 0.8935 - val_loss: 0.9033 - val_accuracy: 0.6188\n","Epoch 3/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4777 - accuracy: 0.9090 - val_loss: 0.8974 - val_accuracy: 0.6498\n","Epoch 4/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4727 - accuracy: 0.9088 - val_loss: 0.8939 - val_accuracy: 0.6240\n","Epoch 5/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4662 - accuracy: 0.9106 - val_loss: 0.8847 - val_accuracy: 0.6860\n","Epoch 6/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4693 - accuracy: 0.9096 - val_loss: 0.8917 - val_accuracy: 0.5971\n","Epoch 7/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4609 - accuracy: 0.9129 - val_loss: 0.8693 - val_accuracy: 0.6808\n","Epoch 8/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4552 - accuracy: 0.9191 - val_loss: 0.8666 - val_accuracy: 0.6839\n","Epoch 9/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4515 - accuracy: 0.9191 - val_loss: 0.8645 - val_accuracy: 0.6384\n","Epoch 10/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4509 - accuracy: 0.9238 - val_loss: 0.8506 - val_accuracy: 0.7014\n","Epoch 11/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4493 - accuracy: 0.9222 - val_loss: 0.8426 - val_accuracy: 0.6932\n","Epoch 12/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4521 - accuracy: 0.9202 - val_loss: 0.8325 - val_accuracy: 0.7087\n","Epoch 13/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4476 - accuracy: 0.9222 - val_loss: 0.8214 - val_accuracy: 0.7190\n","Epoch 14/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4371 - accuracy: 0.9292 - val_loss: 0.8234 - val_accuracy: 0.7190\n","Epoch 15/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.4364 - accuracy: 0.9313 - val_loss: 0.8123 - val_accuracy: 0.7242\n","Epoch 16/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4361 - accuracy: 0.9292 - val_loss: 0.8242 - val_accuracy: 0.7128\n","Epoch 17/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4348 - accuracy: 0.9287 - val_loss: 0.8156 - val_accuracy: 0.7459\n","Epoch 18/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4366 - accuracy: 0.9248 - val_loss: 0.8337 - val_accuracy: 0.7262\n","Epoch 19/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4298 - accuracy: 0.9315 - val_loss: 0.8280 - val_accuracy: 0.7510\n","Epoch 20/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4282 - accuracy: 0.9357 - val_loss: 0.8226 - val_accuracy: 0.7531\n","Epoch 21/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4335 - accuracy: 0.9256 - val_loss: 0.8455 - val_accuracy: 0.7541\n","Epoch 22/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4325 - accuracy: 0.9284 - val_loss: 0.8558 - val_accuracy: 0.7541\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4519 - accuracy: 0.9274 - val_loss: 0.8696 - val_accuracy: 0.7562\n","Epoch 24/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4248 - accuracy: 0.9323 - val_loss: 0.8835 - val_accuracy: 0.7572\n","Epoch 25/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4297 - accuracy: 0.9307 - val_loss: 0.8993 - val_accuracy: 0.7438\n","Epoch 26/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4277 - accuracy: 0.9359 - val_loss: 0.9153 - val_accuracy: 0.7459\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4214 - accuracy: 0.9344 - val_loss: 0.9348 - val_accuracy: 0.7572\n","Epoch 28/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4127 - accuracy: 0.9380 - val_loss: 0.9269 - val_accuracy: 0.7531\n","Epoch 29/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4134 - accuracy: 0.9388 - val_loss: 0.9343 - val_accuracy: 0.7583\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4129 - accuracy: 0.9367 - val_loss: 0.9341 - val_accuracy: 0.7541\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4129 - accuracy: 0.9390 - val_loss: 1.0120 - val_accuracy: 0.7428\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4150 - accuracy: 0.9336 - val_loss: 0.9538 - val_accuracy: 0.7500\n","Epoch 33/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4095 - accuracy: 0.9388 - val_loss: 0.9549 - val_accuracy: 0.7583\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4131 - accuracy: 0.9380 - val_loss: 0.9599 - val_accuracy: 0.7521\n","Epoch 35/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4035 - accuracy: 0.9424 - val_loss: 0.9820 - val_accuracy: 0.7541\n","Epoch 36/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4086 - accuracy: 0.9385 - val_loss: 0.9522 - val_accuracy: 0.7541\n","Epoch 37/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4141 - accuracy: 0.9349 - val_loss: 1.0400 - val_accuracy: 0.7386\n","Epoch 38/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4312 - accuracy: 0.9238 - val_loss: 1.0549 - val_accuracy: 0.7500\n","Epoch 39/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4086 - accuracy: 0.9382 - val_loss: 0.9854 - val_accuracy: 0.7490\n","Epoch 40/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4066 - accuracy: 0.9388 - val_loss: 0.9842 - val_accuracy: 0.7335\n","Epoch 41/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3991 - accuracy: 0.9442 - val_loss: 0.9891 - val_accuracy: 0.7479\n","Epoch 42/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3941 - accuracy: 0.9457 - val_loss: 0.9732 - val_accuracy: 0.7469\n","Epoch 43/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3910 - accuracy: 0.9491 - val_loss: 0.9877 - val_accuracy: 0.7438\n","Epoch 44/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3917 - accuracy: 0.9473 - val_loss: 0.9967 - val_accuracy: 0.7469\n","Epoch 45/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3895 - accuracy: 0.9504 - val_loss: 0.9840 - val_accuracy: 0.7500\n","Epoch 46/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3881 - accuracy: 0.9452 - val_loss: 0.9996 - val_accuracy: 0.7417\n","Epoch 47/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3914 - accuracy: 0.9444 - val_loss: 1.0149 - val_accuracy: 0.7459\n","Epoch 48/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3885 - accuracy: 0.9455 - val_loss: 1.0128 - val_accuracy: 0.7438\n","Epoch 49/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3870 - accuracy: 0.9457 - val_loss: 1.0074 - val_accuracy: 0.7428\n","Epoch 50/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3871 - accuracy: 0.9444 - val_loss: 1.0156 - val_accuracy: 0.7479\n","Epoch 51/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3857 - accuracy: 0.9468 - val_loss: 1.0776 - val_accuracy: 0.7479\n","Epoch 52/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3852 - accuracy: 0.9468 - val_loss: 1.0200 - val_accuracy: 0.7438\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3824 - accuracy: 0.9522 - val_loss: 1.0191 - val_accuracy: 0.7448\n","Epoch 54/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3991 - accuracy: 0.9426 - val_loss: 1.0420 - val_accuracy: 0.7376\n","Epoch 55/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3928 - accuracy: 0.9439 - val_loss: 1.0240 - val_accuracy: 0.7345\n","Epoch 56/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3787 - accuracy: 0.9501 - val_loss: 1.0284 - val_accuracy: 0.7397\n","Epoch 57/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3791 - accuracy: 0.9519 - val_loss: 1.0934 - val_accuracy: 0.7469\n","Epoch 58/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3890 - accuracy: 0.9426 - val_loss: 1.0485 - val_accuracy: 0.7428\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3891 - accuracy: 0.9413 - val_loss: 1.0396 - val_accuracy: 0.7490\n","Epoch 60/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3777 - accuracy: 0.9504 - val_loss: 1.0629 - val_accuracy: 0.7407\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3749 - accuracy: 0.9525 - val_loss: 1.0229 - val_accuracy: 0.7428\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3719 - accuracy: 0.9488 - val_loss: 1.1054 - val_accuracy: 0.7355\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3741 - accuracy: 0.9519 - val_loss: 1.0403 - val_accuracy: 0.7386\n","Epoch 64/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3811 - accuracy: 0.9439 - val_loss: 1.0940 - val_accuracy: 0.7407\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3904 - accuracy: 0.9478 - val_loss: 1.1863 - val_accuracy: 0.7149\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4438 - accuracy: 0.9163 - val_loss: 1.2138 - val_accuracy: 0.7180\n","Epoch 67/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.4228 - accuracy: 0.9313 - val_loss: 1.0560 - val_accuracy: 0.7397\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.4017 - accuracy: 0.9370 - val_loss: 1.0963 - val_accuracy: 0.7345\n","Epoch 69/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3885 - accuracy: 0.9455 - val_loss: 1.0641 - val_accuracy: 0.7376\n","Epoch 70/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3713 - accuracy: 0.9501 - val_loss: 1.0591 - val_accuracy: 0.7355\n","Epoch 71/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3645 - accuracy: 0.9579 - val_loss: 1.0296 - val_accuracy: 0.7428\n","Epoch 72/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3661 - accuracy: 0.9530 - val_loss: 1.0359 - val_accuracy: 0.7469\n","Epoch 73/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3614 - accuracy: 0.9579 - val_loss: 1.0528 - val_accuracy: 0.7417\n","Epoch 74/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3618 - accuracy: 0.9574 - val_loss: 1.0421 - val_accuracy: 0.7417\n","Epoch 75/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3588 - accuracy: 0.9568 - val_loss: 1.0530 - val_accuracy: 0.7386\n","Epoch 76/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3594 - accuracy: 0.9556 - val_loss: 1.0522 - val_accuracy: 0.7417\n","Epoch 77/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3564 - accuracy: 0.9579 - val_loss: 1.0571 - val_accuracy: 0.7366\n","Epoch 78/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3550 - accuracy: 0.9620 - val_loss: 1.0652 - val_accuracy: 0.7428\n","Epoch 79/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3561 - accuracy: 0.9599 - val_loss: 1.0739 - val_accuracy: 0.7324\n","Epoch 80/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3553 - accuracy: 0.9589 - val_loss: 1.0647 - val_accuracy: 0.7314\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3545 - accuracy: 0.9574 - val_loss: 1.0723 - val_accuracy: 0.7335\n","Epoch 82/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3506 - accuracy: 0.9618 - val_loss: 1.0651 - val_accuracy: 0.7417\n","Epoch 83/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3502 - accuracy: 0.9605 - val_loss: 1.0750 - val_accuracy: 0.7448\n","Epoch 84/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3502 - accuracy: 0.9587 - val_loss: 1.0723 - val_accuracy: 0.7324\n","Epoch 85/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3511 - accuracy: 0.9602 - val_loss: 1.0803 - val_accuracy: 0.7428\n","Epoch 86/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3507 - accuracy: 0.9594 - val_loss: 1.0900 - val_accuracy: 0.7469\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3517 - accuracy: 0.9587 - val_loss: 1.1256 - val_accuracy: 0.7283\n","Epoch 88/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3480 - accuracy: 0.9574 - val_loss: 1.0938 - val_accuracy: 0.7355\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3494 - accuracy: 0.9630 - val_loss: 1.1022 - val_accuracy: 0.7448\n","Epoch 90/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3449 - accuracy: 0.9649 - val_loss: 1.1219 - val_accuracy: 0.7448\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3475 - accuracy: 0.9605 - val_loss: 1.1470 - val_accuracy: 0.7211\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3449 - accuracy: 0.9646 - val_loss: 1.1043 - val_accuracy: 0.7355\n","Epoch 93/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3428 - accuracy: 0.9659 - val_loss: 1.1100 - val_accuracy: 0.7397\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3488 - accuracy: 0.9566 - val_loss: 1.0983 - val_accuracy: 0.7366\n","Epoch 95/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3409 - accuracy: 0.9610 - val_loss: 1.1092 - val_accuracy: 0.7417\n","Epoch 96/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3413 - accuracy: 0.9620 - val_loss: 1.1119 - val_accuracy: 0.7407\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3407 - accuracy: 0.9633 - val_loss: 1.1312 - val_accuracy: 0.7407\n","Epoch 98/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3379 - accuracy: 0.9672 - val_loss: 1.1179 - val_accuracy: 0.7417\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3374 - accuracy: 0.9646 - val_loss: 1.1331 - val_accuracy: 0.7355\n","Epoch 100/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3431 - accuracy: 0.9630 - val_loss: 1.1405 - val_accuracy: 0.7345\n","{'loss': [0.5033930540084839, 0.5026816725730896, 0.47774210572242737, 0.47266292572021484, 0.4662434756755829, 0.46932005882263184, 0.4608796238899231, 0.45516932010650635, 0.4515228271484375, 0.45092740654945374, 0.4492698609828949, 0.45213571190834045, 0.4476092457771301, 0.43709781765937805, 0.43636226654052734, 0.43611598014831543, 0.434763640165329, 0.4366496801376343, 0.4298154413700104, 0.42818546295166016, 0.43353480100631714, 0.4325298070907593, 0.45194050669670105, 0.4248347282409668, 0.42970412969589233, 0.42766350507736206, 0.4213850200176239, 0.4127412736415863, 0.4133799076080322, 0.412900447845459, 0.4128901958465576, 0.4150086045265198, 0.40952232480049133, 0.41305094957351685, 0.4034673571586609, 0.4086146354675293, 0.414071261882782, 0.43119242787361145, 0.40861839056015015, 0.40664035081863403, 0.39907562732696533, 0.39406439661979675, 0.390990674495697, 0.39166510105133057, 0.38949379324913025, 0.3880663514137268, 0.39135465025901794, 0.388508141040802, 0.38699617981910706, 0.38706323504447937, 0.38570600748062134, 0.38524186611175537, 0.3824050724506378, 0.39914846420288086, 0.39279478788375854, 0.3787291944026947, 0.37908175587654114, 0.38895630836486816, 0.3891279697418213, 0.3776596784591675, 0.37489786744117737, 0.37192222476005554, 0.3741479218006134, 0.38108041882514954, 0.39044642448425293, 0.44377708435058594, 0.42278915643692017, 0.4016587734222412, 0.3885497450828552, 0.3713476061820984, 0.3644822835922241, 0.36608341336250305, 0.36143171787261963, 0.3617525100708008, 0.35876694321632385, 0.3594054877758026, 0.3564215898513794, 0.35499441623687744, 0.35614654421806335, 0.3553369343280792, 0.35454344749450684, 0.35057368874549866, 0.35023823380470276, 0.3501754105091095, 0.3511015474796295, 0.35073113441467285, 0.3517337739467621, 0.347981333732605, 0.3493531346321106, 0.34491461515426636, 0.3474772870540619, 0.3449336290359497, 0.3427582383155823, 0.34877973794937134, 0.34088653326034546, 0.3413345515727997, 0.3406693935394287, 0.33790263533592224, 0.3373737335205078, 0.3430931568145752], 'accuracy': [0.8937984704971313, 0.8935400247573853, 0.9090439081192017, 0.9087855219841003, 0.9105943441390991, 0.9095607399940491, 0.9129198789596558, 0.9191214442253113, 0.9191214442253113, 0.9237726330757141, 0.9222221970558167, 0.9201550483703613, 0.9222221970558167, 0.9291989803314209, 0.9312661290168762, 0.9291989803314209, 0.9286821484565735, 0.9248061776161194, 0.9315245747566223, 0.9356589317321777, 0.9255813956260681, 0.9284237623214722, 0.9273901581764221, 0.9322997331619263, 0.9307493567466736, 0.935917317867279, 0.9343669414520264, 0.9379844665527344, 0.9387596845626831, 0.9366925358772278, 0.9390180706977844, 0.9335917234420776, 0.9387596845626831, 0.9379844665527344, 0.9423772692680359, 0.9385012984275818, 0.934883713722229, 0.9237726330757141, 0.9382429122924805, 0.9387596845626831, 0.9441860318183899, 0.9457364082336426, 0.949095606803894, 0.94728684425354, 0.9503875970840454, 0.9452196359634399, 0.9444444179534912, 0.9454780220985413, 0.9457364082336426, 0.9444444179534912, 0.9467700123786926, 0.9467700123786926, 0.9521963596343994, 0.9426356554031372, 0.9439276456832886, 0.9501292109489441, 0.9519379734992981, 0.9426356554031372, 0.9413436651229858, 0.9503875970840454, 0.9524548053741455, 0.9488372206687927, 0.9519379734992981, 0.9439276456832886, 0.9478036165237427, 0.9162790775299072, 0.9312661290168762, 0.9369509220123291, 0.9454780220985413, 0.9501292109489441, 0.9578811526298523, 0.9529715776443481, 0.9578811526298523, 0.9573643207550049, 0.9568475484848022, 0.9555555582046509, 0.9578811526298523, 0.9620155096054077, 0.9599483013153076, 0.9589147567749023, 0.9573643207550049, 0.9617571234703064, 0.960465133190155, 0.9586563110351562, 0.9602067470550537, 0.959431529045105, 0.9586563110351562, 0.9573643207550049, 0.9630491137504578, 0.9648578763008118, 0.960465133190155, 0.9645994901657104, 0.9658914804458618, 0.9565891623497009, 0.9609819054603577, 0.9620155096054077, 0.9633074998855591, 0.9671834707260132, 0.9645994901657104, 0.9630491137504578], 'val_loss': [0.9148752689361572, 0.903272271156311, 0.8974444270133972, 0.8938906192779541, 0.8846748471260071, 0.8917117118835449, 0.8692950010299683, 0.8666433691978455, 0.8645462989807129, 0.8505772948265076, 0.8426420092582703, 0.8324885368347168, 0.821355938911438, 0.8234068751335144, 0.8122588992118835, 0.8242167234420776, 0.8156135082244873, 0.8336831331253052, 0.8280413746833801, 0.8226016163825989, 0.845486581325531, 0.8558343648910522, 0.8695597648620605, 0.8834619522094727, 0.8992601633071899, 0.9153417944908142, 0.9348109364509583, 0.9268887042999268, 0.9342721104621887, 0.9340522885322571, 1.0119906663894653, 0.9537568688392639, 0.9549046158790588, 0.9599338173866272, 0.9820354580879211, 0.9522320032119751, 1.0400416851043701, 1.0549012422561646, 0.9853554964065552, 0.9841610193252563, 0.9890987873077393, 0.973211944103241, 0.9876742362976074, 0.9967288374900818, 0.9839910268783569, 0.9996010661125183, 1.0148937702178955, 1.012773871421814, 1.0074374675750732, 1.0155500173568726, 1.077552318572998, 1.0199886560440063, 1.019108772277832, 1.0419646501541138, 1.0239932537078857, 1.028403878211975, 1.0933659076690674, 1.048510193824768, 1.0396367311477661, 1.0629103183746338, 1.022940993309021, 1.105369210243225, 1.040252923965454, 1.0940202474594116, 1.1862658262252808, 1.213803768157959, 1.0560147762298584, 1.0962798595428467, 1.0641134977340698, 1.0591295957565308, 1.0296235084533691, 1.0358859300613403, 1.0527976751327515, 1.0421258211135864, 1.053032398223877, 1.0521636009216309, 1.0571315288543701, 1.0651888847351074, 1.0739158391952515, 1.0647311210632324, 1.0722870826721191, 1.0650519132614136, 1.0750470161437988, 1.072317361831665, 1.0803065299987793, 1.0900167226791382, 1.1255754232406616, 1.0938445329666138, 1.1021642684936523, 1.1219456195831299, 1.147009253501892, 1.1043288707733154, 1.1100467443466187, 1.0983150005340576, 1.1092246770858765, 1.1119369268417358, 1.13119637966156, 1.1178712844848633, 1.1331485509872437, 1.1404826641082764], 'val_accuracy': [0.5764462947845459, 0.6188016533851624, 0.6497933864593506, 0.6239669322967529, 0.6859503984451294, 0.5971074104309082, 0.6807851195335388, 0.68388432264328, 0.6384297609329224, 0.7014462947845459, 0.6931818127632141, 0.7086777091026306, 0.7190082669258118, 0.7190082669258118, 0.7241735458374023, 0.7128099203109741, 0.7458677887916565, 0.7262396812438965, 0.7510330677032471, 0.7530992031097412, 0.7541322112083435, 0.7541322112083435, 0.7561983466148376, 0.7572314143180847, 0.7438016533851624, 0.7458677887916565, 0.7572314143180847, 0.7530992031097412, 0.7582644820213318, 0.7541322112083435, 0.7427685856819153, 0.75, 0.7582644820213318, 0.7520661354064941, 0.7541322112083435, 0.7541322112083435, 0.7386363744735718, 0.75, 0.7489669322967529, 0.7334710955619812, 0.7479338645935059, 0.7469007968902588, 0.7438016533851624, 0.7469007968902588, 0.75, 0.7417355179786682, 0.7458677887916565, 0.7438016533851624, 0.7427685856819153, 0.7479338645935059, 0.7479338645935059, 0.7438016533851624, 0.7448347210884094, 0.7376033067703247, 0.7345041036605835, 0.7396694421768188, 0.7469007968902588, 0.7427685856819153, 0.7489669322967529, 0.7407024502754211, 0.7427685856819153, 0.7355371713638306, 0.7386363744735718, 0.7407024502754211, 0.7148760557174683, 0.7179751992225647, 0.7396694421768188, 0.7345041036605835, 0.7376033067703247, 0.7355371713638306, 0.7427685856819153, 0.7469007968902588, 0.7417355179786682, 0.7417355179786682, 0.7386363744735718, 0.7417355179786682, 0.7365702390670776, 0.7427685856819153, 0.7324380278587341, 0.7314049601554871, 0.7334710955619812, 0.7417355179786682, 0.7448347210884094, 0.7324380278587341, 0.7427685856819153, 0.7469007968902588, 0.7283057570457458, 0.7355371713638306, 0.7448347210884094, 0.7448347210884094, 0.7210744023323059, 0.7355371713638306, 0.7396694421768188, 0.7365702390670776, 0.7417355179786682, 0.7407024502754211, 0.7407024502754211, 0.7417355179786682, 0.7355371713638306, 0.7345041036605835]}\n","32/32 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - 3s 31ms/step - loss: 0.3923 - accuracy: 0.9359 - val_loss: 0.8659 - val_accuracy: 0.6519\n","Epoch 2/100\n"," 1/29 [>.............................] - ETA: 0s - loss: 0.3371 - accuracy: 0.9609"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 0s 11ms/step - loss: 0.3778 - accuracy: 0.9469 - val_loss: 0.8617 - val_accuracy: 0.6228\n","Epoch 3/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3643 - accuracy: 0.9485 - val_loss: 0.8824 - val_accuracy: 0.5657\n","Epoch 4/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3536 - accuracy: 0.9561 - val_loss: 0.8690 - val_accuracy: 0.5905\n","Epoch 5/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3464 - accuracy: 0.9582 - val_loss: 0.8983 - val_accuracy: 0.5636\n","Epoch 6/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3510 - accuracy: 0.9542 - val_loss: 0.8497 - val_accuracy: 0.6347\n","Epoch 7/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3505 - accuracy: 0.9550 - val_loss: 0.8349 - val_accuracy: 0.6606\n","Epoch 8/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3433 - accuracy: 0.9591 - val_loss: 0.8379 - val_accuracy: 0.6433\n","Epoch 9/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3428 - accuracy: 0.9607 - val_loss: 0.8557 - val_accuracy: 0.6401\n","Epoch 10/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3388 - accuracy: 0.9626 - val_loss: 0.8904 - val_accuracy: 0.6142\n","Epoch 11/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3356 - accuracy: 0.9652 - val_loss: 0.8416 - val_accuracy: 0.6487\n","Epoch 12/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3364 - accuracy: 0.9631 - val_loss: 0.9006 - val_accuracy: 0.6315\n","Epoch 13/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3373 - accuracy: 0.9612 - val_loss: 0.8191 - val_accuracy: 0.6864\n","Epoch 14/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3423 - accuracy: 0.9604 - val_loss: 0.8453 - val_accuracy: 0.6659\n","Epoch 15/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3434 - accuracy: 0.9623 - val_loss: 0.8563 - val_accuracy: 0.6918\n","Epoch 16/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3825 - accuracy: 0.9405 - val_loss: 0.9607 - val_accuracy: 0.6304\n","Epoch 17/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3559 - accuracy: 0.9547 - val_loss: 0.7698 - val_accuracy: 0.7403\n","Epoch 18/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3327 - accuracy: 0.9650 - val_loss: 0.7981 - val_accuracy: 0.7241\n","Epoch 19/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3350 - accuracy: 0.9626 - val_loss: 0.8092 - val_accuracy: 0.7317\n","Epoch 20/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3344 - accuracy: 0.9634 - val_loss: 0.7472 - val_accuracy: 0.7845\n","Epoch 21/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3355 - accuracy: 0.9626 - val_loss: 0.7804 - val_accuracy: 0.7619\n","Epoch 22/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3251 - accuracy: 0.9671 - val_loss: 0.7516 - val_accuracy: 0.8028\n","Epoch 23/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3258 - accuracy: 0.9663 - val_loss: 0.7536 - val_accuracy: 0.8114\n","Epoch 24/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3237 - accuracy: 0.9712 - val_loss: 0.8112 - val_accuracy: 0.7629\n","Epoch 25/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3265 - accuracy: 0.9620 - val_loss: 0.7847 - val_accuracy: 0.8125\n","Epoch 26/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3234 - accuracy: 0.9685 - val_loss: 0.7989 - val_accuracy: 0.7985\n","Epoch 27/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3192 - accuracy: 0.9717 - val_loss: 0.7865 - val_accuracy: 0.8050\n","Epoch 28/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3199 - accuracy: 0.9704 - val_loss: 0.8058 - val_accuracy: 0.7899\n","Epoch 29/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3203 - accuracy: 0.9704 - val_loss: 0.8113 - val_accuracy: 0.8060\n","Epoch 30/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3152 - accuracy: 0.9723 - val_loss: 0.8222 - val_accuracy: 0.8136\n","Epoch 31/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3158 - accuracy: 0.9693 - val_loss: 0.8174 - val_accuracy: 0.8060\n","Epoch 32/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3151 - accuracy: 0.9744 - val_loss: 0.8349 - val_accuracy: 0.7909\n","Epoch 33/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3151 - accuracy: 0.9720 - val_loss: 0.8308 - val_accuracy: 0.7974\n","Epoch 34/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3147 - accuracy: 0.9731 - val_loss: 0.8361 - val_accuracy: 0.8071\n","Epoch 35/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3139 - accuracy: 0.9706 - val_loss: 0.8426 - val_accuracy: 0.7974\n","Epoch 36/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3142 - accuracy: 0.9731 - val_loss: 0.8468 - val_accuracy: 0.8093\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3113 - accuracy: 0.9744 - val_loss: 0.8463 - val_accuracy: 0.8006\n","Epoch 38/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3089 - accuracy: 0.9739 - val_loss: 0.8454 - val_accuracy: 0.8082\n","Epoch 39/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3119 - accuracy: 0.9720 - val_loss: 0.8549 - val_accuracy: 0.8039\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3110 - accuracy: 0.9712 - val_loss: 0.8623 - val_accuracy: 0.7931\n","Epoch 41/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3072 - accuracy: 0.9763 - val_loss: 0.8686 - val_accuracy: 0.8125\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3082 - accuracy: 0.9766 - val_loss: 0.8672 - val_accuracy: 0.7920\n","Epoch 43/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3092 - accuracy: 0.9739 - val_loss: 0.8552 - val_accuracy: 0.8060\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3055 - accuracy: 0.9749 - val_loss: 0.8823 - val_accuracy: 0.7780\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3080 - accuracy: 0.9717 - val_loss: 0.8709 - val_accuracy: 0.8136\n","Epoch 46/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3021 - accuracy: 0.9768 - val_loss: 0.8737 - val_accuracy: 0.8071\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3027 - accuracy: 0.9752 - val_loss: 0.8728 - val_accuracy: 0.7996\n","Epoch 48/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3026 - accuracy: 0.9779 - val_loss: 0.8740 - val_accuracy: 0.8039\n","Epoch 49/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3076 - accuracy: 0.9731 - val_loss: 0.8860 - val_accuracy: 0.8082\n","Epoch 50/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3020 - accuracy: 0.9779 - val_loss: 0.9055 - val_accuracy: 0.8125\n","Epoch 51/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3011 - accuracy: 0.9760 - val_loss: 0.8984 - val_accuracy: 0.7909\n","Epoch 52/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.3002 - accuracy: 0.9731 - val_loss: 0.8836 - val_accuracy: 0.8017\n","Epoch 53/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2989 - accuracy: 0.9774 - val_loss: 0.8866 - val_accuracy: 0.7899\n","Epoch 54/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2979 - accuracy: 0.9782 - val_loss: 0.8907 - val_accuracy: 0.7996\n","Epoch 55/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2963 - accuracy: 0.9787 - val_loss: 0.8995 - val_accuracy: 0.8028\n","Epoch 56/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2968 - accuracy: 0.9776 - val_loss: 0.8896 - val_accuracy: 0.8028\n","Epoch 57/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2942 - accuracy: 0.9771 - val_loss: 0.8925 - val_accuracy: 0.7996\n","Epoch 58/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2941 - accuracy: 0.9803 - val_loss: 0.9052 - val_accuracy: 0.7856\n","Epoch 59/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2939 - accuracy: 0.9787 - val_loss: 0.8967 - val_accuracy: 0.8006\n","Epoch 60/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2946 - accuracy: 0.9766 - val_loss: 0.8982 - val_accuracy: 0.7985\n","Epoch 61/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2963 - accuracy: 0.9755 - val_loss: 0.9281 - val_accuracy: 0.7953\n","Epoch 62/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3064 - accuracy: 0.9709 - val_loss: 0.9862 - val_accuracy: 0.7823\n","Epoch 63/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.4119 - accuracy: 0.9461 - val_loss: 1.0262 - val_accuracy: 0.7726\n","Epoch 64/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.4071 - accuracy: 0.9459 - val_loss: 1.1337 - val_accuracy: 0.7446\n","Epoch 65/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.3208 - accuracy: 0.9666 - val_loss: 0.9477 - val_accuracy: 0.8028\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2978 - accuracy: 0.9739 - val_loss: 0.9957 - val_accuracy: 0.7899\n","Epoch 67/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2928 - accuracy: 0.9787 - val_loss: 0.9483 - val_accuracy: 0.7985\n","Epoch 68/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2900 - accuracy: 0.9798 - val_loss: 0.9539 - val_accuracy: 0.7931\n","Epoch 69/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2892 - accuracy: 0.9809 - val_loss: 0.9628 - val_accuracy: 0.7877\n","Epoch 70/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2894 - accuracy: 0.9820 - val_loss: 0.9561 - val_accuracy: 0.8028\n","Epoch 71/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2905 - accuracy: 0.9784 - val_loss: 0.9533 - val_accuracy: 0.7953\n","Epoch 72/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2899 - accuracy: 0.9790 - val_loss: 0.9639 - val_accuracy: 0.7726\n","Epoch 73/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2873 - accuracy: 0.9801 - val_loss: 0.9693 - val_accuracy: 0.7780\n","Epoch 74/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2884 - accuracy: 0.9811 - val_loss: 0.9784 - val_accuracy: 0.7866\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2851 - accuracy: 0.9814 - val_loss: 0.9710 - val_accuracy: 0.7812\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2853 - accuracy: 0.9809 - val_loss: 0.9598 - val_accuracy: 0.7931\n","Epoch 77/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2843 - accuracy: 0.9817 - val_loss: 0.9662 - val_accuracy: 0.7985\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2836 - accuracy: 0.9806 - val_loss: 0.9629 - val_accuracy: 0.7942\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2855 - accuracy: 0.9793 - val_loss: 0.9685 - val_accuracy: 0.7931\n","Epoch 80/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2876 - accuracy: 0.9779 - val_loss: 0.9716 - val_accuracy: 0.7909\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2834 - accuracy: 0.9806 - val_loss: 0.9807 - val_accuracy: 0.7823\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2833 - accuracy: 0.9801 - val_loss: 0.9736 - val_accuracy: 0.7877\n","Epoch 83/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2805 - accuracy: 0.9836 - val_loss: 0.9751 - val_accuracy: 0.7985\n","Epoch 84/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2809 - accuracy: 0.9817 - val_loss: 0.9807 - val_accuracy: 0.7942\n","Epoch 85/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2818 - accuracy: 0.9822 - val_loss: 0.9838 - val_accuracy: 0.7985\n","Epoch 86/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2799 - accuracy: 0.9833 - val_loss: 0.9868 - val_accuracy: 0.7909\n","Epoch 87/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2818 - accuracy: 0.9811 - val_loss: 0.9951 - val_accuracy: 0.7705\n","Epoch 88/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2800 - accuracy: 0.9828 - val_loss: 0.9938 - val_accuracy: 0.8006\n","Epoch 89/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2787 - accuracy: 0.9822 - val_loss: 0.9862 - val_accuracy: 0.7963\n","Epoch 90/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2786 - accuracy: 0.9838 - val_loss: 0.9916 - val_accuracy: 0.7866\n","Epoch 91/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2797 - accuracy: 0.9825 - val_loss: 0.9850 - val_accuracy: 0.7985\n","Epoch 92/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2774 - accuracy: 0.9841 - val_loss: 0.9878 - val_accuracy: 0.7920\n","Epoch 93/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2765 - accuracy: 0.9849 - val_loss: 1.0025 - val_accuracy: 0.7985\n","Epoch 94/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2784 - accuracy: 0.9811 - val_loss: 1.0140 - val_accuracy: 0.7802\n","Epoch 95/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2782 - accuracy: 0.9801 - val_loss: 0.9986 - val_accuracy: 0.7888\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2765 - accuracy: 0.9841 - val_loss: 1.0448 - val_accuracy: 0.7565\n","Epoch 97/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2788 - accuracy: 0.9790 - val_loss: 1.0090 - val_accuracy: 0.8006\n","Epoch 98/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2740 - accuracy: 0.9844 - val_loss: 1.0035 - val_accuracy: 0.7942\n","Epoch 99/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.2770 - accuracy: 0.9828 - val_loss: 1.0060 - val_accuracy: 0.7963\n","Epoch 100/100\n","29/29 [==============================] - 0s 12ms/step - loss: 0.2752 - accuracy: 0.9849 - val_loss: 1.0168 - val_accuracy: 0.7909\n","{'loss': [0.392318993806839, 0.3778225779533386, 0.3643449544906616, 0.3535746932029724, 0.34641221165657043, 0.35099345445632935, 0.350518137216568, 0.3432995080947876, 0.3427692949771881, 0.33884647488594055, 0.3356066644191742, 0.33642005920410156, 0.33733728528022766, 0.34233224391937256, 0.3434429466724396, 0.38245415687561035, 0.3559119403362274, 0.3326692581176758, 0.33501023054122925, 0.3343693017959595, 0.3354938328266144, 0.325099378824234, 0.32580703496932983, 0.32365453243255615, 0.32652223110198975, 0.3234320878982544, 0.3192349076271057, 0.3199273943901062, 0.32031434774398804, 0.31518271565437317, 0.3157701790332794, 0.31514763832092285, 0.3151257038116455, 0.31468892097473145, 0.31390392780303955, 0.3141571879386902, 0.3113357424736023, 0.3088732659816742, 0.3119322657585144, 0.3110153377056122, 0.3071991503238678, 0.30821800231933594, 0.30924883484840393, 0.30551740527153015, 0.30795156955718994, 0.3020855486392975, 0.3027448058128357, 0.30260875821113586, 0.3075680136680603, 0.30196669697761536, 0.3011453449726105, 0.300218790769577, 0.2988668978214264, 0.2978658676147461, 0.2962639629840851, 0.2968232035636902, 0.29422831535339355, 0.2941375970840454, 0.2939257323741913, 0.2945851683616638, 0.2962877154350281, 0.30642226338386536, 0.41187041997909546, 0.40706658363342285, 0.3207777142524719, 0.2978205382823944, 0.2928158938884735, 0.28998497128486633, 0.28922393918037415, 0.2893683910369873, 0.29051196575164795, 0.289941668510437, 0.2872937321662903, 0.2883972227573395, 0.28514617681503296, 0.2852565050125122, 0.2843305468559265, 0.28358566761016846, 0.28554049134254456, 0.28758201003074646, 0.2834244966506958, 0.28329184651374817, 0.2804793119430542, 0.2808927297592163, 0.28177547454833984, 0.2799041271209717, 0.2818107008934021, 0.27999749779701233, 0.2787359356880188, 0.27855628728866577, 0.2796635031700134, 0.2774496376514435, 0.27651268243789673, 0.27844586968421936, 0.27823713421821594, 0.2765251100063324, 0.27880120277404785, 0.27396437525749207, 0.2769690155982971, 0.27524274587631226], 'accuracy': [0.935883641242981, 0.946928858757019, 0.9485452771186829, 0.9560883641242981, 0.9582435488700867, 0.9542025923728943, 0.9550107717514038, 0.9590517282485962, 0.9606680870056152, 0.962553858757019, 0.9652478694915771, 0.9630926847457886, 0.9612069129943848, 0.9603987336158752, 0.962284505367279, 0.9404633641242981, 0.954741358757019, 0.9649784564971924, 0.962553858757019, 0.9633620977401733, 0.962553858757019, 0.967133641242981, 0.9663254022598267, 0.9711745977401733, 0.9620150923728943, 0.9684805870056152, 0.9717133641242981, 0.970366358757019, 0.970366358757019, 0.9722521305084229, 0.9692887663841248, 0.9744073152542114, 0.9719827771186829, 0.9730603694915771, 0.9706357717514038, 0.9730603694915771, 0.9744073152542114, 0.9738685488700867, 0.9719827771186829, 0.9711745977401733, 0.9762930870056152, 0.9765625, 0.9738685488700867, 0.974946141242981, 0.9717133641242981, 0.9768319129943848, 0.975215494632721, 0.977909505367279, 0.9730603694915771, 0.977909505367279, 0.9760237336158752, 0.9730603694915771, 0.9773706793785095, 0.978178858757019, 0.9787176847457886, 0.9776400923728943, 0.9771012663841248, 0.9803340435028076, 0.9787176847457886, 0.9765625, 0.9754849076271057, 0.9709051847457886, 0.9461206793785095, 0.9458512663841248, 0.9665948152542114, 0.9738685488700867, 0.9787176847457886, 0.9797952771186829, 0.9808728694915771, 0.9819504022598267, 0.9784482717514038, 0.9789870977401733, 0.9800646305084229, 0.9811422228813171, 0.9814116358757019, 0.9808728694915771, 0.9816810488700867, 0.9806034564971924, 0.9792564511299133, 0.977909505367279, 0.9806034564971924, 0.9800646305084229, 0.9835668206214905, 0.9816810488700867, 0.9822198152542114, 0.9832974076271057, 0.9811422228813171, 0.982758641242981, 0.9822198152542114, 0.9838362336158752, 0.9824892282485962, 0.9841055870056152, 0.9849137663841248, 0.9811422228813171, 0.9800646305084229, 0.9841055870056152, 0.9789870977401733, 0.984375, 0.982758641242981, 0.9849137663841248], 'val_loss': [0.8659053444862366, 0.8617064952850342, 0.8823705911636353, 0.8690319657325745, 0.8982517719268799, 0.8497435450553894, 0.8349180817604065, 0.8379204869270325, 0.85566246509552, 0.8904350399971008, 0.841616690158844, 0.9006072282791138, 0.8190638422966003, 0.8453043103218079, 0.8563111424446106, 0.9606993198394775, 0.769849419593811, 0.7980781197547913, 0.8092402815818787, 0.7472350001335144, 0.7804112434387207, 0.7516146898269653, 0.7535601258277893, 0.8111951947212219, 0.7847278714179993, 0.7989004850387573, 0.7864740490913391, 0.8057589530944824, 0.811262309551239, 0.8222400546073914, 0.8173775672912598, 0.8349034786224365, 0.8308084607124329, 0.8361048698425293, 0.8426300287246704, 0.8468193411827087, 0.8463205695152283, 0.8454375863075256, 0.8549079298973083, 0.862306535243988, 0.8685908317565918, 0.8672094941139221, 0.8551770448684692, 0.8822532296180725, 0.8709318041801453, 0.8737316131591797, 0.872797429561615, 0.874007523059845, 0.8860103487968445, 0.905489444732666, 0.8984268307685852, 0.8836436867713928, 0.8866410255432129, 0.890730082988739, 0.8994733095169067, 0.8895876407623291, 0.8925206661224365, 0.9052351117134094, 0.8966847658157349, 0.898150622844696, 0.9280544519424438, 0.9862492680549622, 1.0261986255645752, 1.1337392330169678, 0.947670578956604, 0.9956505298614502, 0.9483377933502197, 0.9539344310760498, 0.9628247618675232, 0.9560791254043579, 0.9532802104949951, 0.9638550281524658, 0.9693313241004944, 0.9783621430397034, 0.9710032343864441, 0.9597687721252441, 0.9661728143692017, 0.9629064202308655, 0.9684786796569824, 0.9715768694877625, 0.9806585907936096, 0.9735963940620422, 0.9751107692718506, 0.980711042881012, 0.9837695360183716, 0.9868323802947998, 0.9951040148735046, 0.993834912776947, 0.986151933670044, 0.9915874004364014, 0.9849868416786194, 0.9878172874450684, 1.0025118589401245, 1.01396644115448, 0.9986065030097961, 1.0447769165039062, 1.0089631080627441, 1.003525972366333, 1.0059925317764282, 1.0168473720550537], 'val_accuracy': [0.6519396305084229, 0.6228448152542114, 0.5657327771186829, 0.5905172228813171, 0.5635775923728943, 0.6346982717514038, 0.6605603694915771, 0.6433189511299133, 0.6400862336158752, 0.6142241358757019, 0.6487069129943848, 0.631465494632721, 0.6864224076271057, 0.6659482717514038, 0.6918103694915771, 0.6303879022598267, 0.7403017282485962, 0.7241379022598267, 0.7316810488700867, 0.7844827771186829, 0.7618534564971924, 0.8028017282485962, 0.8114224076271057, 0.7629310488700867, 0.8125, 0.798491358757019, 0.8049569129943848, 0.7898706793785095, 0.806034505367279, 0.8135775923728943, 0.806034505367279, 0.7909482717514038, 0.7974137663841248, 0.8071120977401733, 0.7974137663841248, 0.8092672228813171, 0.8006465435028076, 0.8081896305084229, 0.8038793206214905, 0.7931034564971924, 0.8125, 0.7920258641242981, 0.806034505367279, 0.7780172228813171, 0.8135775923728943, 0.8071120977401733, 0.7995689511299133, 0.8038793206214905, 0.8081896305084229, 0.8125, 0.7909482717514038, 0.8017241358757019, 0.7898706793785095, 0.7995689511299133, 0.8028017282485962, 0.8028017282485962, 0.7995689511299133, 0.7855603694915771, 0.8006465435028076, 0.798491358757019, 0.795258641242981, 0.7823275923728943, 0.7726293206214905, 0.7446120977401733, 0.8028017282485962, 0.7898706793785095, 0.798491358757019, 0.7931034564971924, 0.787715494632721, 0.8028017282485962, 0.795258641242981, 0.7726293206214905, 0.7780172228813171, 0.7866379022598267, 0.78125, 0.7931034564971924, 0.798491358757019, 0.7941810488700867, 0.7931034564971924, 0.7909482717514038, 0.7823275923728943, 0.787715494632721, 0.798491358757019, 0.7941810488700867, 0.798491358757019, 0.7909482717514038, 0.7704741358757019, 0.8006465435028076, 0.7963362336158752, 0.7866379022598267, 0.798491358757019, 0.7920258641242981, 0.798491358757019, 0.7801724076271057, 0.7887930870056152, 0.756465494632721, 0.8006465435028076, 0.7941810488700867, 0.7963362336158752, 0.7909482717514038]}\n","38/38 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 5s 41ms/step - loss: 0.4109 - accuracy: 0.9304 - val_loss: 0.9083 - val_accuracy: 0.5419\n","Epoch 2/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 1s 19ms/step - loss: 0.3858 - accuracy: 0.9437 - val_loss: 0.8832 - val_accuracy: 0.5814\n","Epoch 3/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3726 - accuracy: 0.9485 - val_loss: 0.9453 - val_accuracy: 0.5271\n","Epoch 4/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3695 - accuracy: 0.9465 - val_loss: 0.9018 - val_accuracy: 0.5509\n","Epoch 5/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3556 - accuracy: 0.9539 - val_loss: 0.9001 - val_accuracy: 0.5543\n","Epoch 6/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3543 - accuracy: 0.9564 - val_loss: 0.8696 - val_accuracy: 0.5792\n","Epoch 7/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3556 - accuracy: 0.9561 - val_loss: 0.9001 - val_accuracy: 0.5622\n","Epoch 8/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3567 - accuracy: 0.9590 - val_loss: 0.9255 - val_accuracy: 0.5543\n","Epoch 9/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3484 - accuracy: 0.9590 - val_loss: 0.9846 - val_accuracy: 0.5452\n","Epoch 10/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3514 - accuracy: 0.9576 - val_loss: 0.9691 - val_accuracy: 0.5532\n","Epoch 11/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3443 - accuracy: 0.9610 - val_loss: 0.9652 - val_accuracy: 0.5656\n","Epoch 12/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3466 - accuracy: 0.9584 - val_loss: 0.9259 - val_accuracy: 0.5939\n","Epoch 13/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3435 - accuracy: 0.9576 - val_loss: 0.8512 - val_accuracy: 0.6403\n","Epoch 14/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3389 - accuracy: 0.9621 - val_loss: 0.9546 - val_accuracy: 0.5995\n","Epoch 15/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3423 - accuracy: 0.9641 - val_loss: 0.8264 - val_accuracy: 0.6652\n","Epoch 16/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3414 - accuracy: 0.9610 - val_loss: 0.8070 - val_accuracy: 0.6855\n","Epoch 17/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3355 - accuracy: 0.9658 - val_loss: 0.8361 - val_accuracy: 0.6663\n","Epoch 18/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3339 - accuracy: 0.9649 - val_loss: 0.7824 - val_accuracy: 0.7115\n","Epoch 19/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3324 - accuracy: 0.9652 - val_loss: 0.7615 - val_accuracy: 0.7364\n","Epoch 20/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3401 - accuracy: 0.9604 - val_loss: 0.8137 - val_accuracy: 0.7081\n","Epoch 21/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3314 - accuracy: 0.9677 - val_loss: 0.7437 - val_accuracy: 0.7738\n","Epoch 22/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3586 - accuracy: 0.9550 - val_loss: 0.8302 - val_accuracy: 0.7726\n","Epoch 23/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3456 - accuracy: 0.9578 - val_loss: 0.8163 - val_accuracy: 0.7308\n","Epoch 24/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3421 - accuracy: 0.9610 - val_loss: 0.7578 - val_accuracy: 0.7941\n","Epoch 25/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3483 - accuracy: 0.9612 - val_loss: 0.7498 - val_accuracy: 0.8224\n","Epoch 26/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3293 - accuracy: 0.9669 - val_loss: 0.7940 - val_accuracy: 0.7760\n","Epoch 27/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3255 - accuracy: 0.9697 - val_loss: 0.7457 - val_accuracy: 0.8179\n","Epoch 28/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3221 - accuracy: 0.9703 - val_loss: 0.7602 - val_accuracy: 0.8201\n","Epoch 29/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3260 - accuracy: 0.9675 - val_loss: 0.7837 - val_accuracy: 0.8224\n","Epoch 30/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3219 - accuracy: 0.9726 - val_loss: 0.7581 - val_accuracy: 0.8235\n","Epoch 31/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3201 - accuracy: 0.9706 - val_loss: 0.7613 - val_accuracy: 0.8258\n","Epoch 32/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3204 - accuracy: 0.9709 - val_loss: 0.7679 - val_accuracy: 0.8247\n","Epoch 33/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3189 - accuracy: 0.9726 - val_loss: 0.7801 - val_accuracy: 0.8190\n","Epoch 34/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3198 - accuracy: 0.9711 - val_loss: 0.7969 - val_accuracy: 0.8145\n","Epoch 35/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3159 - accuracy: 0.9751 - val_loss: 0.7918 - val_accuracy: 0.8167\n","Epoch 36/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3156 - accuracy: 0.9754 - val_loss: 0.7633 - val_accuracy: 0.8213\n","Epoch 37/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3180 - accuracy: 0.9731 - val_loss: 0.7816 - val_accuracy: 0.8133\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3159 - accuracy: 0.9737 - val_loss: 0.7769 - val_accuracy: 0.8145\n","Epoch 39/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3139 - accuracy: 0.9731 - val_loss: 0.7952 - val_accuracy: 0.8235\n","Epoch 40/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3129 - accuracy: 0.9740 - val_loss: 0.7918 - val_accuracy: 0.8088\n","Epoch 41/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3116 - accuracy: 0.9740 - val_loss: 0.7872 - val_accuracy: 0.8156\n","Epoch 42/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3135 - accuracy: 0.9731 - val_loss: 0.8117 - val_accuracy: 0.8066\n","Epoch 43/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3114 - accuracy: 0.9728 - val_loss: 0.7913 - val_accuracy: 0.8190\n","Epoch 44/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3088 - accuracy: 0.9737 - val_loss: 0.7881 - val_accuracy: 0.8190\n","Epoch 45/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3077 - accuracy: 0.9768 - val_loss: 0.8123 - val_accuracy: 0.8100\n","Epoch 46/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3115 - accuracy: 0.9680 - val_loss: 0.7952 - val_accuracy: 0.8156\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3093 - accuracy: 0.9745 - val_loss: 0.8355 - val_accuracy: 0.8201\n","Epoch 48/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3066 - accuracy: 0.9751 - val_loss: 0.8701 - val_accuracy: 0.8100\n","Epoch 49/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3158 - accuracy: 0.9646 - val_loss: 0.8255 - val_accuracy: 0.8043\n","Epoch 50/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3174 - accuracy: 0.9683 - val_loss: 0.9289 - val_accuracy: 0.8145\n","Epoch 51/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3627 - accuracy: 0.9570 - val_loss: 1.1119 - val_accuracy: 0.7296\n","Epoch 52/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3510 - accuracy: 0.9615 - val_loss: 1.0830 - val_accuracy: 0.7296\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3831 - accuracy: 0.9462 - val_loss: 0.9068 - val_accuracy: 0.7975\n","Epoch 54/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.3491 - accuracy: 0.9578 - val_loss: 0.8970 - val_accuracy: 0.7952\n","Epoch 55/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.3258 - accuracy: 0.9672 - val_loss: 0.8893 - val_accuracy: 0.7998\n","Epoch 56/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.3040 - accuracy: 0.9765 - val_loss: 0.9582 - val_accuracy: 0.7907\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3009 - accuracy: 0.9788 - val_loss: 0.8763 - val_accuracy: 0.8111\n","Epoch 58/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3008 - accuracy: 0.9768 - val_loss: 0.8544 - val_accuracy: 0.8122\n","Epoch 59/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2981 - accuracy: 0.9788 - val_loss: 0.8546 - val_accuracy: 0.8043\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2979 - accuracy: 0.9796 - val_loss: 0.8539 - val_accuracy: 0.8088\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2976 - accuracy: 0.9793 - val_loss: 0.8872 - val_accuracy: 0.8100\n","Epoch 62/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2967 - accuracy: 0.9799 - val_loss: 0.8616 - val_accuracy: 0.8032\n","Epoch 63/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3004 - accuracy: 0.9745 - val_loss: 0.8711 - val_accuracy: 0.8032\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3000 - accuracy: 0.9745 - val_loss: 0.8857 - val_accuracy: 0.8077\n","Epoch 65/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2968 - accuracy: 0.9779 - val_loss: 0.8770 - val_accuracy: 0.8054\n","Epoch 66/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2945 - accuracy: 0.9802 - val_loss: 0.8691 - val_accuracy: 0.8088\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2964 - accuracy: 0.9788 - val_loss: 0.8767 - val_accuracy: 0.8043\n","Epoch 68/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2930 - accuracy: 0.9799 - val_loss: 0.8868 - val_accuracy: 0.7839\n","Epoch 69/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2937 - accuracy: 0.9785 - val_loss: 0.8795 - val_accuracy: 0.8100\n","Epoch 70/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2937 - accuracy: 0.9768 - val_loss: 0.8832 - val_accuracy: 0.8088\n","Epoch 71/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2916 - accuracy: 0.9808 - val_loss: 0.8795 - val_accuracy: 0.8054\n","Epoch 72/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2909 - accuracy: 0.9830 - val_loss: 0.8722 - val_accuracy: 0.8054\n","Epoch 73/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2907 - accuracy: 0.9799 - val_loss: 0.8983 - val_accuracy: 0.8020\n","Epoch 74/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2915 - accuracy: 0.9793 - val_loss: 0.9087 - val_accuracy: 0.8043\n","Epoch 75/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2904 - accuracy: 0.9825 - val_loss: 0.8906 - val_accuracy: 0.7986\n","Epoch 76/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2890 - accuracy: 0.9822 - val_loss: 0.9107 - val_accuracy: 0.7998\n","Epoch 77/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2899 - accuracy: 0.9788 - val_loss: 0.8841 - val_accuracy: 0.8054\n","Epoch 78/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2890 - accuracy: 0.9805 - val_loss: 0.8979 - val_accuracy: 0.7930\n","Epoch 79/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2885 - accuracy: 0.9819 - val_loss: 0.8836 - val_accuracy: 0.8054\n","Epoch 80/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2878 - accuracy: 0.9808 - val_loss: 0.9195 - val_accuracy: 0.7817\n","Epoch 81/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2963 - accuracy: 0.9723 - val_loss: 0.9385 - val_accuracy: 0.8054\n","Epoch 82/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2922 - accuracy: 0.9774 - val_loss: 0.9076 - val_accuracy: 0.7998\n","Epoch 83/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2857 - accuracy: 0.9813 - val_loss: 0.9247 - val_accuracy: 0.7941\n","Epoch 84/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2844 - accuracy: 0.9810 - val_loss: 0.9116 - val_accuracy: 0.8145\n","Epoch 85/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2842 - accuracy: 0.9810 - val_loss: 0.9260 - val_accuracy: 0.7964\n","Epoch 86/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2866 - accuracy: 0.9785 - val_loss: 0.9437 - val_accuracy: 0.7896\n","Epoch 87/100\n","28/28 [==============================] - 0s 13ms/step - loss: 0.2842 - accuracy: 0.9836 - val_loss: 0.9133 - val_accuracy: 0.8032\n","Epoch 88/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2830 - accuracy: 0.9816 - val_loss: 0.9171 - val_accuracy: 0.8054\n","Epoch 89/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2799 - accuracy: 0.9850 - val_loss: 0.9306 - val_accuracy: 0.8032\n","Epoch 90/100\n","28/28 [==============================] - 0s 12ms/step - loss: 0.2818 - accuracy: 0.9827 - val_loss: 0.9081 - val_accuracy: 0.8009\n","Epoch 91/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2804 - accuracy: 0.9847 - val_loss: 0.9106 - val_accuracy: 0.8043\n","Epoch 92/100\n","28/28 [==============================] - 0s 14ms/step - loss: 0.2831 - accuracy: 0.9816 - val_loss: 1.0086 - val_accuracy: 0.7839\n","Epoch 93/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.2906 - accuracy: 0.9757 - val_loss: 0.9304 - val_accuracy: 0.8009\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.2841 - accuracy: 0.9788 - val_loss: 0.9553 - val_accuracy: 0.7930\n","Epoch 95/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3050 - accuracy: 0.9728 - val_loss: 0.9748 - val_accuracy: 0.7919\n","Epoch 96/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3326 - accuracy: 0.9689 - val_loss: 1.0754 - val_accuracy: 0.7511\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4082 - accuracy: 0.9448 - val_loss: 1.0584 - val_accuracy: 0.7828\n","Epoch 98/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3198 - accuracy: 0.9720 - val_loss: 0.9094 - val_accuracy: 0.7896\n","Epoch 99/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3085 - accuracy: 0.9734 - val_loss: 0.9892 - val_accuracy: 0.7726\n","Epoch 100/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3193 - accuracy: 0.9711 - val_loss: 0.9548 - val_accuracy: 0.7930\n","{'loss': [0.4109284281730652, 0.38576817512512207, 0.37257668375968933, 0.36951860785484314, 0.3556237518787384, 0.3543257713317871, 0.3556220233440399, 0.3567180931568146, 0.3484061062335968, 0.35141637921333313, 0.34429967403411865, 0.34663838148117065, 0.3434540331363678, 0.3388666808605194, 0.3423418402671814, 0.3414175808429718, 0.3355054557323456, 0.3339017927646637, 0.3324238955974579, 0.34011077880859375, 0.3313876688480377, 0.35864901542663574, 0.34557396173477173, 0.3421096205711365, 0.34831443428993225, 0.32925403118133545, 0.3254659175872803, 0.32214030623435974, 0.32597658038139343, 0.3218994736671448, 0.3201204240322113, 0.32038605213165283, 0.3189283013343811, 0.3197903335094452, 0.3158664405345917, 0.3155527114868164, 0.3179692327976227, 0.31590551137924194, 0.3139089345932007, 0.31292006373405457, 0.3116433322429657, 0.313511461019516, 0.3113819658756256, 0.30883628129959106, 0.30773380398750305, 0.31149494647979736, 0.30927062034606934, 0.3066191077232361, 0.31575214862823486, 0.31740519404411316, 0.36273372173309326, 0.3510242998600006, 0.38310253620147705, 0.34914591908454895, 0.32575178146362305, 0.30401870608329773, 0.30089542269706726, 0.3007875382900238, 0.29811614751815796, 0.2978809177875519, 0.29755091667175293, 0.2967086434364319, 0.30038198828697205, 0.30004510283470154, 0.2967786192893982, 0.29451149702072144, 0.2963789701461792, 0.2930101752281189, 0.2937154173851013, 0.2937459945678711, 0.29156196117401123, 0.29094523191452026, 0.29074153304100037, 0.2914813756942749, 0.2903805077075958, 0.2890026569366455, 0.2898949980735779, 0.2889633774757385, 0.2885143458843231, 0.2877804636955261, 0.29627525806427, 0.2922365665435791, 0.28569844365119934, 0.28435730934143066, 0.2841697037220001, 0.28658610582351685, 0.2842225432395935, 0.28297916054725647, 0.2799094617366791, 0.28175899386405945, 0.280415415763855, 0.2831106185913086, 0.29061776399612427, 0.28413620591163635, 0.30500465631484985, 0.33257409930229187, 0.40822917222976685, 0.31981420516967773, 0.3084903657436371, 0.3192855417728424], 'accuracy': [0.930390477180481, 0.9436898827552795, 0.9485002756118774, 0.9465195536613464, 0.9538766145706177, 0.9564233422279358, 0.9561403393745422, 0.9589700102806091, 0.9589700102806091, 0.9575551748275757, 0.9609507918357849, 0.9584040641784668, 0.9575551748275757, 0.9620826244354248, 0.9640634059906006, 0.9609507918357849, 0.9657611846923828, 0.9649122953414917, 0.9651952385902405, 0.9603848457336426, 0.9677419066429138, 0.9550085067749023, 0.9578381180763245, 0.9609507918357849, 0.9612337350845337, 0.9668930172920227, 0.9697226881980896, 0.9702886343002319, 0.967458963394165, 0.9725523591041565, 0.9705715775489807, 0.9708545804023743, 0.9725523591041565, 0.971137523651123, 0.9750990271568298, 0.9753820300102234, 0.9731183052062988, 0.9736841917037964, 0.9731183052062988, 0.9739671945571899, 0.9739671945571899, 0.9731183052062988, 0.9728353023529053, 0.9736841917037964, 0.9767968058586121, 0.9680249094963074, 0.9745330810546875, 0.9750990271568298, 0.9646292924880981, 0.9683078527450562, 0.9569892287254333, 0.9615166783332825, 0.9462365508079529, 0.9578381180763245, 0.9671760201454163, 0.9765138626098633, 0.9787775874137878, 0.9767968058586121, 0.9787775874137878, 0.979626476764679, 0.9793435335159302, 0.9799094796180725, 0.9745330810546875, 0.9745330810546875, 0.9779286980628967, 0.9801924228668213, 0.9787775874137878, 0.9799094796180725, 0.9784946441650391, 0.9767968058586121, 0.9807583689689636, 0.9830220937728882, 0.9799094796180725, 0.9793435335159302, 0.9824561476707458, 0.9821732044219971, 0.9787775874137878, 0.9804753661155701, 0.9818902015686035, 0.9807583689689636, 0.9722693562507629, 0.9773627519607544, 0.9813242554664612, 0.9810413122177124, 0.9810413122177124, 0.9784946441650391, 0.9835879802703857, 0.9816072583198547, 0.9850028157234192, 0.9827390909194946, 0.9847198724746704, 0.9816072583198547, 0.9756649732589722, 0.9787775874137878, 0.9728353023529053, 0.9688737988471985, 0.9448217153549194, 0.9719864130020142, 0.9734012484550476, 0.971137523651123], 'val_loss': [0.9082723259925842, 0.8831691741943359, 0.9452924728393555, 0.901832640171051, 0.9001370668411255, 0.8696026802062988, 0.9000528454780579, 0.9255347847938538, 0.9846246838569641, 0.9690666198730469, 0.9651576280593872, 0.9258677363395691, 0.8511541485786438, 0.9546207785606384, 0.8263845443725586, 0.8069568276405334, 0.8360522985458374, 0.7824419736862183, 0.7615064382553101, 0.8136694431304932, 0.7436640858650208, 0.8302424550056458, 0.816300630569458, 0.7577582597732544, 0.7498332858085632, 0.7939706444740295, 0.7457084655761719, 0.7601837515830994, 0.7837085723876953, 0.75812166929245, 0.7613460421562195, 0.7679181098937988, 0.7800830602645874, 0.7969471216201782, 0.7918067574501038, 0.7633100152015686, 0.7815962433815002, 0.7769204378128052, 0.7951729893684387, 0.7918356657028198, 0.7872008085250854, 0.8117251992225647, 0.7912707328796387, 0.7881237864494324, 0.8123236894607544, 0.7951540946960449, 0.8355252146720886, 0.8700739741325378, 0.8254978656768799, 0.9289093613624573, 1.1119303703308105, 1.0830094814300537, 0.9067614674568176, 0.8970462679862976, 0.8893149495124817, 0.9582250714302063, 0.876344621181488, 0.8543733358383179, 0.8545882701873779, 0.8538941740989685, 0.8871976137161255, 0.861609935760498, 0.8711296319961548, 0.8857322335243225, 0.8770391345024109, 0.8690783381462097, 0.8766855597496033, 0.8868395090103149, 0.8795138597488403, 0.8832002282142639, 0.8794786334037781, 0.872229278087616, 0.8982749581336975, 0.9086578488349915, 0.8905935287475586, 0.9106889963150024, 0.8841174840927124, 0.8979396224021912, 0.8835985660552979, 0.919507622718811, 0.938529908657074, 0.9075762629508972, 0.9247034192085266, 0.9116414189338684, 0.9260437488555908, 0.9437109231948853, 0.9133242964744568, 0.9170708060264587, 0.9306405782699585, 0.908149003982544, 0.910645067691803, 1.0085612535476685, 0.9304110407829285, 0.9552757143974304, 0.974769651889801, 1.0753998756408691, 1.0583908557891846, 0.9093751311302185, 0.989173948764801, 0.9548235535621643], 'val_accuracy': [0.5418552160263062, 0.581447958946228, 0.5271493196487427, 0.5509049892425537, 0.5542986392974854, 0.5791855454444885, 0.5622171759605408, 0.5542986392974854, 0.5452488660812378, 0.5531674027442932, 0.5656108856201172, 0.5938913822174072, 0.6402714848518372, 0.5995475053787231, 0.6651583909988403, 0.685520350933075, 0.6662895679473877, 0.7115384340286255, 0.7364253401756287, 0.7081447839736938, 0.773755669593811, 0.7726244330406189, 0.7307692170143127, 0.7941176295280457, 0.8223981857299805, 0.7760180830955505, 0.8178732991218567, 0.820135772228241, 0.8223981857299805, 0.8235294222831726, 0.8257918357849121, 0.8246606588363647, 0.8190045356750488, 0.814479649066925, 0.8167420625686646, 0.8212669491767883, 0.8133484125137329, 0.814479649066925, 0.8235294222831726, 0.8088235259056091, 0.8156108856201172, 0.8065611124038696, 0.8190045356750488, 0.8190045356750488, 0.8099547624588013, 0.8156108856201172, 0.820135772228241, 0.8099547624588013, 0.8042986392974854, 0.814479649066925, 0.7296379804611206, 0.7296379804611206, 0.7975113391876221, 0.7952488660812378, 0.7997737526893616, 0.790723979473114, 0.8110859990119934, 0.8122171759605408, 0.8042986392974854, 0.8088235259056091, 0.8099547624588013, 0.8031674027442932, 0.8031674027442932, 0.807692289352417, 0.8054298758506775, 0.8088235259056091, 0.8042986392974854, 0.7839366793632507, 0.8099547624588013, 0.8088235259056091, 0.8054298758506775, 0.8054298758506775, 0.8020362257957458, 0.8042986392974854, 0.7986425161361694, 0.7997737526893616, 0.8054298758506775, 0.7929864525794983, 0.8054298758506775, 0.7816742062568665, 0.8054298758506775, 0.7997737526893616, 0.7941176295280457, 0.814479649066925, 0.7963801026344299, 0.7895927429199219, 0.8031674027442932, 0.8054298758506775, 0.8031674027442932, 0.8009049892425537, 0.8042986392974854, 0.7839366793632507, 0.8009049892425537, 0.7929864525794983, 0.7918552160263062, 0.7511312365531921, 0.7828054428100586, 0.7895927429199219, 0.7726244330406189, 0.7929864525794983]}\n","45/45 [==============================] - 0s 3ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1573376   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3900993 (14.88 MB)\n","Trainable params: 3900481 (14.88 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 3s 30ms/step - loss: 0.4328 - accuracy: 0.9202 - val_loss: 0.8930 - val_accuracy: 0.5713\n","Epoch 2/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.3660 - accuracy: 0.9609"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 1s 20ms/step - loss: 0.3973 - accuracy: 0.9326 - val_loss: 0.8870 - val_accuracy: 0.5826\n","Epoch 3/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3924 - accuracy: 0.9385 - val_loss: 0.8870 - val_accuracy: 0.5682\n","Epoch 4/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3977 - accuracy: 0.9341 - val_loss: 0.9170 - val_accuracy: 0.5475\n","Epoch 5/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3874 - accuracy: 0.9364 - val_loss: 0.9236 - val_accuracy: 0.5403\n","Epoch 6/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3778 - accuracy: 0.9447 - val_loss: 0.9208 - val_accuracy: 0.5568\n","Epoch 7/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3687 - accuracy: 0.9491 - val_loss: 0.8767 - val_accuracy: 0.5961\n","Epoch 8/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3712 - accuracy: 0.9488 - val_loss: 0.9097 - val_accuracy: 0.5795\n","Epoch 9/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.3725 - accuracy: 0.9419 - val_loss: 0.8435 - val_accuracy: 0.6539\n","Epoch 10/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3627 - accuracy: 0.9522 - val_loss: 0.8755 - val_accuracy: 0.6136\n","Epoch 11/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3647 - accuracy: 0.9509 - val_loss: 0.8151 - val_accuracy: 0.7149\n","Epoch 12/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3635 - accuracy: 0.9504 - val_loss: 0.8629 - val_accuracy: 0.6333\n","Epoch 13/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3580 - accuracy: 0.9530 - val_loss: 0.8124 - val_accuracy: 0.7045\n","Epoch 14/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3620 - accuracy: 0.9553 - val_loss: 0.8336 - val_accuracy: 0.6983\n","Epoch 15/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3586 - accuracy: 0.9540 - val_loss: 0.8061 - val_accuracy: 0.7056\n","Epoch 16/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3710 - accuracy: 0.9494 - val_loss: 0.8096 - val_accuracy: 0.7479\n","Epoch 17/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3830 - accuracy: 0.9442 - val_loss: 0.7889 - val_accuracy: 0.7583\n","Epoch 18/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.3579 - accuracy: 0.9571 - val_loss: 0.7918 - val_accuracy: 0.7727\n","Epoch 19/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3602 - accuracy: 0.9543 - val_loss: 0.8064 - val_accuracy: 0.7758\n","Epoch 20/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3541 - accuracy: 0.9561 - val_loss: 0.8122 - val_accuracy: 0.7882\n","Epoch 21/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3500 - accuracy: 0.9571 - val_loss: 0.8201 - val_accuracy: 0.7769\n","Epoch 22/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3470 - accuracy: 0.9594 - val_loss: 0.8260 - val_accuracy: 0.7882\n","Epoch 23/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.3440 - accuracy: 0.9625 - val_loss: 0.8342 - val_accuracy: 0.7913\n","Epoch 24/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3467 - accuracy: 0.9558 - val_loss: 0.8402 - val_accuracy: 0.7934\n","Epoch 25/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3424 - accuracy: 0.9597 - val_loss: 0.8682 - val_accuracy: 0.7862\n","Epoch 26/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3439 - accuracy: 0.9599 - val_loss: 0.8609 - val_accuracy: 0.7944\n","Epoch 27/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3420 - accuracy: 0.9628 - val_loss: 0.8791 - val_accuracy: 0.7903\n","Epoch 28/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3387 - accuracy: 0.9630 - val_loss: 0.8909 - val_accuracy: 0.7913\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3470 - accuracy: 0.9553 - val_loss: 0.9057 - val_accuracy: 0.7851\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3374 - accuracy: 0.9643 - val_loss: 0.8905 - val_accuracy: 0.7924\n","Epoch 31/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3409 - accuracy: 0.9607 - val_loss: 0.9044 - val_accuracy: 0.7944\n","Epoch 32/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3361 - accuracy: 0.9643 - val_loss: 0.9128 - val_accuracy: 0.7841\n","Epoch 33/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3340 - accuracy: 0.9646 - val_loss: 0.9002 - val_accuracy: 0.7882\n","Epoch 34/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3345 - accuracy: 0.9651 - val_loss: 0.9084 - val_accuracy: 0.7913\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3338 - accuracy: 0.9625 - val_loss: 0.9452 - val_accuracy: 0.7820\n","Epoch 36/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3342 - accuracy: 0.9651 - val_loss: 0.9285 - val_accuracy: 0.7903\n","Epoch 37/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3355 - accuracy: 0.9641 - val_loss: 0.9471 - val_accuracy: 0.7872\n","Epoch 38/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3350 - accuracy: 0.9612 - val_loss: 0.9761 - val_accuracy: 0.7686\n","Epoch 39/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3537 - accuracy: 0.9553 - val_loss: 0.9832 - val_accuracy: 0.7758\n","Epoch 40/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4691 - accuracy: 0.9271 - val_loss: 1.0671 - val_accuracy: 0.7552\n","Epoch 41/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3544 - accuracy: 0.9563 - val_loss: 0.9262 - val_accuracy: 0.7779\n","Epoch 42/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3372 - accuracy: 0.9610 - val_loss: 0.9328 - val_accuracy: 0.7769\n","Epoch 43/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3331 - accuracy: 0.9651 - val_loss: 0.9473 - val_accuracy: 0.7841\n","Epoch 44/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3318 - accuracy: 0.9636 - val_loss: 0.9281 - val_accuracy: 0.7789\n","Epoch 45/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3287 - accuracy: 0.9667 - val_loss: 0.9484 - val_accuracy: 0.7841\n","Epoch 46/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3308 - accuracy: 0.9659 - val_loss: 0.9748 - val_accuracy: 0.7676\n","Epoch 47/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3287 - accuracy: 0.9690 - val_loss: 0.9504 - val_accuracy: 0.7789\n","Epoch 48/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3259 - accuracy: 0.9667 - val_loss: 0.9386 - val_accuracy: 0.7872\n","Epoch 49/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3247 - accuracy: 0.9664 - val_loss: 0.9429 - val_accuracy: 0.7841\n","Epoch 50/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3221 - accuracy: 0.9680 - val_loss: 0.9739 - val_accuracy: 0.7686\n","Epoch 51/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3263 - accuracy: 0.9661 - val_loss: 0.9528 - val_accuracy: 0.7800\n","Epoch 52/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3273 - accuracy: 0.9646 - val_loss: 0.9921 - val_accuracy: 0.7779\n","Epoch 53/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3252 - accuracy: 0.9698 - val_loss: 0.9832 - val_accuracy: 0.7810\n","Epoch 54/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3205 - accuracy: 0.9685 - val_loss: 0.9476 - val_accuracy: 0.7862\n","Epoch 55/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3206 - accuracy: 0.9695 - val_loss: 0.9534 - val_accuracy: 0.7851\n","Epoch 56/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3205 - accuracy: 0.9690 - val_loss: 0.9614 - val_accuracy: 0.7851\n","Epoch 57/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3187 - accuracy: 0.9711 - val_loss: 0.9758 - val_accuracy: 0.7769\n","Epoch 58/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3176 - accuracy: 0.9718 - val_loss: 0.9643 - val_accuracy: 0.7758\n","Epoch 59/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3160 - accuracy: 0.9703 - val_loss: 0.9639 - val_accuracy: 0.7800\n","Epoch 60/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3161 - accuracy: 0.9698 - val_loss: 1.0273 - val_accuracy: 0.7562\n","Epoch 61/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3182 - accuracy: 0.9664 - val_loss: 0.9767 - val_accuracy: 0.7738\n","Epoch 62/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3133 - accuracy: 0.9698 - val_loss: 0.9767 - val_accuracy: 0.7831\n","Epoch 63/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3156 - accuracy: 0.9677 - val_loss: 0.9891 - val_accuracy: 0.7789\n","Epoch 64/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3120 - accuracy: 0.9695 - val_loss: 0.9965 - val_accuracy: 0.7665\n","Epoch 65/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3111 - accuracy: 0.9695 - val_loss: 1.0322 - val_accuracy: 0.7707\n","Epoch 66/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3147 - accuracy: 0.9674 - val_loss: 1.0096 - val_accuracy: 0.7769\n","Epoch 67/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3105 - accuracy: 0.9742 - val_loss: 0.9981 - val_accuracy: 0.7779\n","Epoch 68/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3099 - accuracy: 0.9718 - val_loss: 1.0087 - val_accuracy: 0.7758\n","Epoch 69/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3119 - accuracy: 0.9667 - val_loss: 1.0082 - val_accuracy: 0.7769\n","Epoch 70/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3086 - accuracy: 0.9711 - val_loss: 1.0103 - val_accuracy: 0.7779\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3082 - accuracy: 0.9698 - val_loss: 1.0079 - val_accuracy: 0.7738\n","Epoch 72/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3049 - accuracy: 0.9726 - val_loss: 1.0131 - val_accuracy: 0.7727\n","Epoch 73/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3061 - accuracy: 0.9731 - val_loss: 1.0235 - val_accuracy: 0.7696\n","Epoch 74/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3089 - accuracy: 0.9713 - val_loss: 1.0300 - val_accuracy: 0.7717\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3099 - accuracy: 0.9726 - val_loss: 1.0208 - val_accuracy: 0.7738\n","Epoch 76/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3037 - accuracy: 0.9749 - val_loss: 1.0278 - val_accuracy: 0.7665\n","Epoch 77/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3037 - accuracy: 0.9731 - val_loss: 1.0351 - val_accuracy: 0.7748\n","Epoch 78/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3039 - accuracy: 0.9749 - val_loss: 1.0297 - val_accuracy: 0.7769\n","Epoch 79/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3044 - accuracy: 0.9711 - val_loss: 1.0459 - val_accuracy: 0.7696\n","Epoch 80/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3031 - accuracy: 0.9742 - val_loss: 1.0320 - val_accuracy: 0.7738\n","Epoch 81/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2988 - accuracy: 0.9773 - val_loss: 1.0359 - val_accuracy: 0.7758\n","Epoch 82/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2990 - accuracy: 0.9749 - val_loss: 1.0473 - val_accuracy: 0.7707\n","Epoch 83/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3024 - accuracy: 0.9711 - val_loss: 1.0425 - val_accuracy: 0.7748\n","Epoch 84/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2985 - accuracy: 0.9747 - val_loss: 1.0496 - val_accuracy: 0.7769\n","Epoch 85/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3038 - accuracy: 0.9731 - val_loss: 1.0717 - val_accuracy: 0.7634\n","Epoch 86/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3043 - accuracy: 0.9739 - val_loss: 1.1261 - val_accuracy: 0.7696\n","Epoch 87/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3140 - accuracy: 0.9669 - val_loss: 1.1433 - val_accuracy: 0.7645\n","Epoch 88/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3222 - accuracy: 0.9693 - val_loss: 1.0638 - val_accuracy: 0.7655\n","Epoch 89/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3041 - accuracy: 0.9726 - val_loss: 1.1405 - val_accuracy: 0.7645\n","Epoch 90/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.3616 - accuracy: 0.9501 - val_loss: 1.6300 - val_accuracy: 0.6860\n","Epoch 91/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.4302 - accuracy: 0.9238 - val_loss: 1.1134 - val_accuracy: 0.7531\n","Epoch 92/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3221 - accuracy: 0.9630 - val_loss: 1.0953 - val_accuracy: 0.7521\n","Epoch 93/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3198 - accuracy: 0.9695 - val_loss: 1.1324 - val_accuracy: 0.7397\n","Epoch 94/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3310 - accuracy: 0.9576 - val_loss: 1.1210 - val_accuracy: 0.7634\n","Epoch 95/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3241 - accuracy: 0.9698 - val_loss: 1.0987 - val_accuracy: 0.7676\n","Epoch 96/100\n","31/31 [==============================] - 0s 12ms/step - loss: 0.3360 - accuracy: 0.9615 - val_loss: 1.0907 - val_accuracy: 0.7645\n","Epoch 97/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3274 - accuracy: 0.9597 - val_loss: 1.1647 - val_accuracy: 0.7634\n","Epoch 98/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.3081 - accuracy: 0.9711 - val_loss: 1.0889 - val_accuracy: 0.7707\n","Epoch 99/100\n","31/31 [==============================] - 0s 13ms/step - loss: 0.2988 - accuracy: 0.9711 - val_loss: 1.1010 - val_accuracy: 0.7531\n","Epoch 100/100\n","31/31 [==============================] - 0s 14ms/step - loss: 0.2943 - accuracy: 0.9760 - val_loss: 1.0864 - val_accuracy: 0.7655\n","{'loss': [0.4327605664730072, 0.3973080813884735, 0.39240410923957825, 0.3976576030254364, 0.38741952180862427, 0.3777564764022827, 0.3686710000038147, 0.3711605966091156, 0.3725242018699646, 0.36269813776016235, 0.36465683579444885, 0.3634966015815735, 0.358036607503891, 0.36195802688598633, 0.35857611894607544, 0.3709809482097626, 0.3829728662967682, 0.3578643202781677, 0.3602484464645386, 0.3541227877140045, 0.3500223755836487, 0.3470414876937866, 0.3440166413784027, 0.34670940041542053, 0.3424016535282135, 0.3438637852668762, 0.34200966358184814, 0.33867087960243225, 0.34703683853149414, 0.337404727935791, 0.3408758044242859, 0.336139440536499, 0.3340166509151459, 0.3344677984714508, 0.3337906002998352, 0.33420681953430176, 0.3355196714401245, 0.3350088596343994, 0.353689968585968, 0.46906036138534546, 0.35440173745155334, 0.3372293710708618, 0.3331316411495209, 0.3317989706993103, 0.3287068009376526, 0.33082902431488037, 0.3286741077899933, 0.32594189047813416, 0.32474222779273987, 0.3220937252044678, 0.3263278305530548, 0.3273458182811737, 0.3251609206199646, 0.32052332162857056, 0.32056930661201477, 0.3204725980758667, 0.3186928927898407, 0.31760701537132263, 0.3160070478916168, 0.31608903408050537, 0.3182260990142822, 0.3133106231689453, 0.31562185287475586, 0.3120422065258026, 0.3110778033733368, 0.3147031366825104, 0.3104994297027588, 0.30985045433044434, 0.31190457940101624, 0.30862852931022644, 0.3081851899623871, 0.30489298701286316, 0.3061215579509735, 0.3089439570903778, 0.30986738204956055, 0.30373167991638184, 0.30374911427497864, 0.3038720190525055, 0.3043724298477173, 0.30310124158859253, 0.2988481819629669, 0.2990141212940216, 0.30237066745758057, 0.2984859049320221, 0.30381298065185547, 0.304292768239975, 0.3140123188495636, 0.3222319483757019, 0.3040848970413208, 0.36162835359573364, 0.4302067458629608, 0.3220917582511902, 0.3197934627532959, 0.3310002088546753, 0.3241048753261566, 0.33597224950790405, 0.327380895614624, 0.30813634395599365, 0.29880592226982117, 0.29432621598243713], 'accuracy': [0.9201550483703613, 0.9325581192970276, 0.9385012984275818, 0.934108555316925, 0.9364340901374817, 0.9447028636932373, 0.949095606803894, 0.9488372206687927, 0.9418604373931885, 0.9521963596343994, 0.950904369354248, 0.9503875970840454, 0.9529715776443481, 0.9552971720695496, 0.9540051817893982, 0.9493539929389954, 0.9441860318183899, 0.9571059346199036, 0.9542635679244995, 0.9560723304748535, 0.9571059346199036, 0.959431529045105, 0.9625322818756104, 0.9558139443397522, 0.9596899151802063, 0.9599483013153076, 0.9627906680107117, 0.9630491137504578, 0.9552971720695496, 0.9643411040306091, 0.9607235193252563, 0.9643411040306091, 0.9645994901657104, 0.9651162624359131, 0.9625322818756104, 0.9651162624359131, 0.964082658290863, 0.961240291595459, 0.9552971720695496, 0.9271317720413208, 0.9563307762145996, 0.9609819054603577, 0.9651162624359131, 0.9635658860206604, 0.9666666388511658, 0.9658914804458618, 0.9689922332763672, 0.9666666388511658, 0.9664082527160645, 0.9679586291313171, 0.9661498665809631, 0.9645994901657104, 0.9697674512863159, 0.9684754610061646, 0.9695090651512146, 0.9689922332763672, 0.9710594415664673, 0.9718345999717712, 0.9702842235565186, 0.9697674512863159, 0.9664082527160645, 0.9697674512863159, 0.9677002429962158, 0.9695090651512146, 0.9695090651512146, 0.9674418568611145, 0.9741601943969727, 0.9718345999717712, 0.9666666388511658, 0.9710594415664673, 0.9697674512863159, 0.97260981798172, 0.9731265902519226, 0.9713178277015686, 0.97260981798172, 0.9749354124069214, 0.9731265902519226, 0.9749354124069214, 0.9710594415664673, 0.9741601943969727, 0.9772610068321228, 0.9749354124069214, 0.9710594415664673, 0.9746770262718201, 0.9731265902519226, 0.9739018082618713, 0.9669250845909119, 0.9692506194114685, 0.97260981798172, 0.9501292109489441, 0.9237726330757141, 0.9630491137504578, 0.9695090651512146, 0.957622766494751, 0.9697674512863159, 0.9614987373352051, 0.9596899151802063, 0.9710594415664673, 0.9710594415664673, 0.9759690165519714], 'val_loss': [0.8930362462997437, 0.886959433555603, 0.8869692087173462, 0.9169684052467346, 0.9235953688621521, 0.9208232164382935, 0.8767259120941162, 0.9096862077713013, 0.843461811542511, 0.8754602670669556, 0.8150724768638611, 0.8628526926040649, 0.8124028444290161, 0.8336231112480164, 0.8061347007751465, 0.8096484541893005, 0.7889248132705688, 0.791819155216217, 0.8064153790473938, 0.8121767640113831, 0.8200874924659729, 0.8259602785110474, 0.8342119455337524, 0.8401505947113037, 0.8682088851928711, 0.8609310388565063, 0.8790915608406067, 0.8909300565719604, 0.9056762456893921, 0.890477180480957, 0.9043750762939453, 0.9127854108810425, 0.9002235531806946, 0.9084097146987915, 0.9451537132263184, 0.9285183548927307, 0.9471424221992493, 0.9760576486587524, 0.9832375049591064, 1.0670701265335083, 0.9261921644210815, 0.9327689409255981, 0.9472766518592834, 0.928076446056366, 0.9484103918075562, 0.974798858165741, 0.9503645896911621, 0.9385907053947449, 0.9429157972335815, 0.9739009737968445, 0.9527751207351685, 0.9921098351478577, 0.9831500053405762, 0.9475511312484741, 0.9533856511116028, 0.9613667726516724, 0.9758227467536926, 0.9643020629882812, 0.9638844728469849, 1.0272865295410156, 0.9767488241195679, 0.976669192314148, 0.9891088604927063, 0.9965015649795532, 1.0321773290634155, 1.0096046924591064, 0.9981110692024231, 1.008738398551941, 1.0082305669784546, 1.0102862119674683, 1.0078682899475098, 1.0131301879882812, 1.0235176086425781, 1.0299726724624634, 1.0208312273025513, 1.027833342552185, 1.03513503074646, 1.0296941995620728, 1.0459023714065552, 1.0320006608963013, 1.0358710289001465, 1.0473278760910034, 1.0424578189849854, 1.0495892763137817, 1.0716646909713745, 1.126135230064392, 1.143328070640564, 1.0638219118118286, 1.1404722929000854, 1.6299923658370972, 1.1134485006332397, 1.0953289270401, 1.132393717765808, 1.1209646463394165, 1.0986987352371216, 1.090695858001709, 1.1647305488586426, 1.088945746421814, 1.101008415222168, 1.0863674879074097], 'val_accuracy': [0.5712810158729553, 0.5826446413993835, 0.5681818127632141, 0.547520637512207, 0.5402892827987671, 0.5568181872367859, 0.5960744023323059, 0.5795454382896423, 0.6539255976676941, 0.6136363744735718, 0.7148760557174683, 0.6332644820213318, 0.7045454382896423, 0.6983470916748047, 0.7055785059928894, 0.7479338645935059, 0.7582644820213318, 0.7727272510528564, 0.7758264541625977, 0.788223147392273, 0.7768595218658447, 0.788223147392273, 0.7913222908973694, 0.7933884263038635, 0.7861570119857788, 0.7944214940071106, 0.7902892827987671, 0.7913222908973694, 0.7851239442825317, 0.7923553586006165, 0.7944214940071106, 0.7840909361839294, 0.788223147392273, 0.7913222908973694, 0.7820248007774353, 0.7902892827987671, 0.7871900796890259, 0.7685950398445129, 0.7758264541625977, 0.7551652789115906, 0.7778925895690918, 0.7768595218658447, 0.7840909361839294, 0.7789255976676941, 0.7840909361839294, 0.7675619721412659, 0.7789255976676941, 0.7871900796890259, 0.7840909361839294, 0.7685950398445129, 0.7799586653709412, 0.7778925895690918, 0.7809917330741882, 0.7861570119857788, 0.7851239442825317, 0.7851239442825317, 0.7768595218658447, 0.7758264541625977, 0.7799586653709412, 0.7561983466148376, 0.7737603187561035, 0.7830578684806824, 0.7789255976676941, 0.7665289044380188, 0.7706611752510071, 0.7768595218658447, 0.7778925895690918, 0.7758264541625977, 0.7768595218658447, 0.7778925895690918, 0.7737603187561035, 0.7727272510528564, 0.76962810754776, 0.7716942429542542, 0.7737603187561035, 0.7665289044380188, 0.7747933864593506, 0.7768595218658447, 0.76962810754776, 0.7737603187561035, 0.7758264541625977, 0.7706611752510071, 0.7747933864593506, 0.7768595218658447, 0.7634297609329224, 0.76962810754776, 0.7644628286361694, 0.7654958963394165, 0.7644628286361694, 0.6859503984451294, 0.7530992031097412, 0.7520661354064941, 0.7396694421768188, 0.7634297609329224, 0.7675619721412659, 0.7644628286361694, 0.7634297609329224, 0.7706611752510071, 0.7530992031097412, 0.7654958963394165]}\n","32/32 [==============================] - 0s 4ms/step\n"]}]},{"cell_type":"code","source":["metrics_df_CNN.round(3)"],"metadata":{"id":"y3RXIk-qZ7ts","colab":{"base_uri":"https://localhost:8080/","height":519},"executionInfo":{"status":"ok","timestamp":1717506679544,"user_tz":-360,"elapsed":15,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"outputId":"ff004016-7605-4e30-d981-0a826b62ba7d","collapsed":true},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Client  Accuracy  Precision  Recall     F1  Sensitivity  Specificity  \\\n","0        0     0.599      0.635   0.464  0.536        0.464        0.734   \n","1        1     0.633      0.696   0.475  0.564        0.475        0.792   \n","2        2     0.613      0.615   0.606  0.611        0.606        0.620   \n","3        0     0.643      0.678   0.544  0.604        0.544        0.742   \n","4        1     0.676      0.694   0.630  0.660        0.630        0.722   \n","5        2     0.677      0.742   0.542  0.626        0.542        0.811   \n","6        0     0.689      0.736   0.590  0.655        0.590        0.789   \n","7        1     0.724      0.763   0.650  0.702        0.650        0.798   \n","8        2     0.714      0.702   0.743  0.722        0.743        0.685   \n","9        0     0.729      0.761   0.668  0.712        0.668        0.791   \n","10       1     0.758      0.776   0.726  0.750        0.726        0.791   \n","11       2     0.764      0.772   0.749  0.760        0.749        0.779   \n","12       0     0.760      0.783   0.719  0.749        0.719        0.801   \n","13       1     0.794      0.793   0.795  0.794        0.795        0.792   \n","14       2     0.801      0.758   0.886  0.817        0.886        0.717   \n","\n","    Kappa  \n","0   0.198  \n","1   0.267  \n","2   0.227  \n","3   0.286  \n","4   0.352  \n","5   0.353  \n","6   0.379  \n","7   0.448  \n","8   0.428  \n","9   0.459  \n","10  0.517  \n","11  0.528  \n","12  0.519  \n","13  0.588  \n","14  0.602  "],"text/html":["\n","  <div id=\"df-80bc42e7-e1bd-41d2-84a7-65bc5c959511\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Client</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>Kappa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.599</td>\n","      <td>0.635</td>\n","      <td>0.464</td>\n","      <td>0.536</td>\n","      <td>0.464</td>\n","      <td>0.734</td>\n","      <td>0.198</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.633</td>\n","      <td>0.696</td>\n","      <td>0.475</td>\n","      <td>0.564</td>\n","      <td>0.475</td>\n","      <td>0.792</td>\n","      <td>0.267</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.613</td>\n","      <td>0.615</td>\n","      <td>0.606</td>\n","      <td>0.611</td>\n","      <td>0.606</td>\n","      <td>0.620</td>\n","      <td>0.227</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.643</td>\n","      <td>0.678</td>\n","      <td>0.544</td>\n","      <td>0.604</td>\n","      <td>0.544</td>\n","      <td>0.742</td>\n","      <td>0.286</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.676</td>\n","      <td>0.694</td>\n","      <td>0.630</td>\n","      <td>0.660</td>\n","      <td>0.630</td>\n","      <td>0.722</td>\n","      <td>0.352</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>0.677</td>\n","      <td>0.742</td>\n","      <td>0.542</td>\n","      <td>0.626</td>\n","      <td>0.542</td>\n","      <td>0.811</td>\n","      <td>0.353</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0.689</td>\n","      <td>0.736</td>\n","      <td>0.590</td>\n","      <td>0.655</td>\n","      <td>0.590</td>\n","      <td>0.789</td>\n","      <td>0.379</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0.724</td>\n","      <td>0.763</td>\n","      <td>0.650</td>\n","      <td>0.702</td>\n","      <td>0.650</td>\n","      <td>0.798</td>\n","      <td>0.448</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.714</td>\n","      <td>0.702</td>\n","      <td>0.743</td>\n","      <td>0.722</td>\n","      <td>0.743</td>\n","      <td>0.685</td>\n","      <td>0.428</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.729</td>\n","      <td>0.761</td>\n","      <td>0.668</td>\n","      <td>0.712</td>\n","      <td>0.668</td>\n","      <td>0.791</td>\n","      <td>0.459</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>0.758</td>\n","      <td>0.776</td>\n","      <td>0.726</td>\n","      <td>0.750</td>\n","      <td>0.726</td>\n","      <td>0.791</td>\n","      <td>0.517</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>0.764</td>\n","      <td>0.772</td>\n","      <td>0.749</td>\n","      <td>0.760</td>\n","      <td>0.749</td>\n","      <td>0.779</td>\n","      <td>0.528</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.760</td>\n","      <td>0.783</td>\n","      <td>0.719</td>\n","      <td>0.749</td>\n","      <td>0.719</td>\n","      <td>0.801</td>\n","      <td>0.519</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>0.794</td>\n","      <td>0.793</td>\n","      <td>0.795</td>\n","      <td>0.794</td>\n","      <td>0.795</td>\n","      <td>0.792</td>\n","      <td>0.588</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2</td>\n","      <td>0.801</td>\n","      <td>0.758</td>\n","      <td>0.886</td>\n","      <td>0.817</td>\n","      <td>0.886</td>\n","      <td>0.717</td>\n","      <td>0.602</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80bc42e7-e1bd-41d2-84a7-65bc5c959511')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-80bc42e7-e1bd-41d2-84a7-65bc5c959511 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-80bc42e7-e1bd-41d2-84a7-65bc5c959511');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-538020e2-8123-4c03-9409-2d7035df7eba\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-538020e2-8123-4c03-9409-2d7035df7eba')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-538020e2-8123-4c03-9409-2d7035df7eba button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"metrics_df_CNN\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Client\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06440881335729792,\n        \"min\": 0.599,\n        \"max\": 0.801,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.729,\n          0.764,\n          0.599\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.054589986871830885,\n        \"min\": 0.615,\n        \"max\": 0.793,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.761,\n          0.772,\n          0.635\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1195221836353084,\n        \"min\": 0.464,\n        \"max\": 0.886,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.668,\n          0.749,\n          0.464\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08430884267015502,\n        \"min\": 0.536,\n        \"max\": 0.817,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.712,\n          0.76,\n          0.536\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1195221836353084,\n        \"min\": 0.464,\n        \"max\": 0.886,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.668,\n          0.749,\n          0.464\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05367201984540657,\n        \"min\": 0.62,\n        \"max\": 0.811,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.801,\n          0.791,\n          0.734\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12867537596973394,\n        \"min\": 0.198,\n        \"max\": 0.602,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.459,\n          0.528,\n          0.198\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["metrics_df_CNN.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/TF Domain/CNN/Theta_tf_CNN.csv', index = False)"],"metadata":{"id":"_iOLsKpkfzdG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# GRU"],"metadata":{"id":"GPlWZUcV48bB"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, LSTM, Dropout, GRU\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","import tensorflow_addons as tfa\n","\n","class FederatedData:\n","    def __init__(self, data_path, num_clients, scaler_type='MinMax', test_size=0.2):\n","        self.data_path = data_path\n","        self.num_clients = num_clients\n","        self.scaler_type = scaler_type\n","        self.test_size = test_size\n","        self.partitions = []  # Initialize partitions attribute\n","        self.load_data()\n","        self.scale_data()\n","        self.create_partitions()\n","\n","    def load_data(self):\n","        try:\n","            data = np.load(self.data_path, allow_pickle=True)\n","            self.X = np.moveaxis(data['X'], 1, 2)  # Move axis here\n","            self.Y = data['Y']\n","            self.groups = data['Group']  # Assuming 'Group' contains group identifiers\n","        except KeyError as e:\n","            raise ValueError(f\"Missing expected data field: {e}\")\n","        except FileNotFoundError as e:\n","            raise ValueError(f\"Data file not found: {e}\")\n","\n","    def scale_data(self):\n","        # Reshape data to 2D array for scaling\n","        X_reshaped = self.X.reshape(-1, self.X.shape[-1])\n","\n","        # Select scaler based on input\n","        if self.scaler_type == 'Standard':\n","            scaler = StandardScaler()\n","        elif self.scaler_type == 'MinMax':\n","            scaler = MinMaxScaler(feature_range=(0, 1))\n","        else:\n","            raise ValueError(\"Unsupported scaler type. Choose either 'Standard' or 'MinMax'.\")\n","\n","        # Fit and transform the data\n","        scaled_data_reshaped = scaler.fit_transform(X_reshaped)\n","\n","        # Reshape back to original shape\n","        self.X = scaled_data_reshaped.reshape(self.X.shape)\n","\n","    def create_partitions(self):\n","        gss = GroupShuffleSplit(n_splits=self.num_clients, test_size=self.test_size, random_state=42)\n","        for train_index, test_index in gss.split(self.X, self.Y, self.groups):\n","            X_train, X_test = self.X[train_index], self.X[test_index]\n","            Y_train, Y_test = self.Y[train_index], self.Y[test_index]\n","            self.partitions.append((X_train, Y_train, X_test, Y_test))\n","            print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n","\n","    def get_training_and_validation_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        partition_X_train, partition_Y_train, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        X_train, X_val, Y_train, Y_val = train_test_split(partition_X_train, partition_Y_train, test_size=0.2, random_state=42)\n","        return X_train, X_val, Y_train, Y_val, partition_X_test, partition_Y_test\n","\n","    def get_testing_data(self, client_idx):\n","        if client_idx < 0 or client_idx >= len(self.partitions):\n","            raise ValueError(f\"Invalid client index. Must be between 0 and {len(self.partitions) - 1}.\")\n","\n","        _, _, partition_X_test, partition_Y_test = self.partitions[client_idx]\n","        return partition_X_test, partition_Y_test\n","\n","def build_sequential_model_gru(input_shape):\n","    clear_session()\n","    model = Sequential()\n","\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\", input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(256, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(512, 3, strides=1, activation='relu', padding=\"same\"))\n","    model.add(MaxPooling1D(2, padding=\"same\"))\n","    model.add(Conv1D(filters=1024, kernel_size=3, strides=1, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(GRU(256, return_sequences=True))\n","    model.add(GRU(256, return_sequences=True))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(32, activation='relu',kernel_regularizer=l2(0.001)))\n","    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n","\n","    # opt = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt = tfa.optimizers.RectifiedAdam(learning_rate=0.00009)\n","    opt = tfa.optimizers.SWA(opt)\n","    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model\n","\n","def compute_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    kappa = cohen_kappa_score(y_true, y_pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    specificity = tn / (tn + fp)\n","    sensitivity = recall\n","\n","    return accuracy, precision, recall, f1, sensitivity, specificity, kappa\n","\n","def federated_learning_gru(data_path):\n","    federated_data = FederatedData(data_path, num_clients=3, scaler_type='MinMax')\n","    federated_data.create_partitions()\n","\n","    # Get the input shape from the data\n","    input_shape = federated_data.X.shape[1:]\n","    global_model = build_sequential_model_gru(input_shape)\n","\n","    num_clients = 3\n","    local_epochs = 5\n","    global_optimizer = Adam(learning_rate=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # Initialize m and v for Adam optimizer\n","    m = [np.zeros_like(w) for w in global_model.get_weights()]\n","    v = [np.zeros_like(w) for w in global_model.get_weights()]\n","    beta1 = 0.9\n","    beta2 = 0.999\n","    epsilon = 1e-7\n","    t = 0\n","\n","    client_data = []\n","    for client_idx in range(num_clients):\n","        x_train, x_val, y_train, y_val, x_test, y_test = federated_data.get_training_and_validation_data(client_idx)\n","        client_data.append((x_train, x_val, y_train, y_val, x_test, y_test))\n","\n","    metrics_list = []\n","\n","    for epoch in range(local_epochs):\n","        client_models = []\n","\n","        for client in range(num_clients):\n","            x_train, x_val, y_train, y_val, x_test, y_test = client_data[client]\n","            client_model = build_sequential_model_gru(input_shape)\n","            client_model.set_weights(global_model.get_weights())  # Initialize with global weights\n","            opt = Adam(learning_rate=0.000009, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","            client_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","            # Set up callbacks\n","            run_name = f\"epoch_{epoch}_client_{client}\"\n","            checkpoint_filepath = f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time+Frequency/Theta/CNN_GRU/best_model_{run_name}.h5'\n","            checkpoint_callback = ModelCheckpoint(\n","                checkpoint_filepath,\n","                monitor='val_accuracy',\n","                save_best_only=True,\n","                mode='max'\n","            )\n","            csv_logger = CSVLogger(f'/content/drive/MyDrive/EEG Signal /Epileptic seizure/Saved model/Time+Frequency/Theta/CNN_GRU/training_log_{run_name}.csv', append=True, separator=';')\n","\n","            history = client_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val, y_val), callbacks=[checkpoint_callback, csv_logger])\n","            client_models.append(client_model)\n","\n","            print(history.history)\n","\n","            # Load the best model before evaluation\n","            best_model = load_model(checkpoint_filepath)\n","\n","            # Evaluate client model\n","            y_pred = (best_model.predict(x_test) > 0.5).astype(\"int32\")\n","            accuracy, precision, recall, f1, sensitivity, specificity, kappa = compute_metrics(y_test, y_pred)\n","            metrics_list.append({\n","                'Client': client,\n","                'Accuracy': accuracy,\n","                'Precision': precision,\n","                'Recall': recall,\n","                'F1': f1,\n","                'Sensitivity': sensitivity,\n","                'Specificity': specificity,\n","                'Kappa': kappa\n","            })\n","\n","        global_weights = global_model.get_weights()\n","        layer_start_idx = 0\n","        for layer in global_model.layers:\n","            layer_weights = []\n","            layer_biases = []\n","            num_params = len(layer.get_weights())\n","            for i in range(num_clients):\n","                layer_params = client_models[i].get_weights()[layer_start_idx:layer_start_idx + num_params]\n","                if num_params > 0:\n","                    layer_weights.append(layer_params[0])\n","                if num_params > 1:\n","                    layer_biases.append(layer_params[1])\n","\n","            if len(layer_weights) > 0:\n","                averaged_layer_weights = np.mean(layer_weights, axis=0)\n","                if averaged_layer_weights.shape == global_weights[layer_start_idx].shape:\n","                    global_weights[layer_start_idx] = averaged_layer_weights\n","                else:\n","                    print(f\"Warning: Shape mismatch for weights at layer {layer.name}, expected {global_weights[layer_start_idx].shape} but got {averaged_layer_weights.shape}\")\n","            if len(layer_biases) > 0:\n","                averaged_layer_biases = np.mean(layer_biases, axis=0)\n","                if averaged_layer_biases.shape == global_weights[layer_start_idx + 1].shape:\n","                    global_weights[layer_start_idx + 1] = averaged_layer_biases\n","                else:\n","                    print(f\"Warning: Shape mismatch for biases at layer {layer.name}, expected {global_weights[layer_start_idx + 1].shape} but got {averaged_layer_biases.shape}\")\n","\n","            layer_start_idx += num_params\n","\n","        # Apply FedOpt (Adam) update to global weights\n","        t += 1\n","        for i in range(len(global_weights)):\n","            g_t = global_weights[i] - global_model.get_weights()[i]  # Gradient\n","            m[i] = beta1 * m[i] + (1 - beta1) * g_t\n","            v[i] = beta2 * v[i] + (1 - beta2) * (g_t ** 2)\n","            m_hat = m[i] / (1 - beta1 ** t)\n","            v_hat = v[i] / (1 - beta2 ** t)\n","            global_weights[i] -= global_optimizer.learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n","\n","        global_model.set_weights(global_weights)\n","\n","    metrics_df = pd.DataFrame(metrics_list)\n","    return global_model, metrics_df\n","\n","# Example usage\n","# data_path = 'path/to/your/data.npz'\n","# global_model, metrics_df = federated_learning(data_path)\n","# print(metrics_df)\n","\n"],"metadata":{"id":"ieXSN-9PI4Dx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["global_model_gru, metrics_df_gru = federated_learning_gru(Theta_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"lD5S-Pvy5B-r","outputId":"8977832b-07a8-4d53-ca01-16c389e6d21b"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train shape: (4640, 37, 29), Test shape: (1194, 37, 29)\n","Train shape: (4418, 37, 29), Test shape: (1416, 37, 29)\n","Train shape: (4838, 37, 29), Test shape: (996, 37, 29)\n","Train shape: (4640, 37, 29), Test shape: (1194, 37, 29)\n","Train shape: (4418, 37, 29), Test shape: (1416, 37, 29)\n","Train shape: (4838, 37, 29), Test shape: (996, 37, 29)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 1.7020 - accuracy: 0.5379"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 8s 72ms/step - loss: 1.7018 - accuracy: 0.5374 - val_loss: 1.6971 - val_accuracy: 0.5647\n","Epoch 2/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.6906 - accuracy: 0.5458 - val_loss: 1.6871 - val_accuracy: 0.5474\n","Epoch 3/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.6793 - accuracy: 0.5620 - val_loss: 1.6772 - val_accuracy: 0.5442\n","Epoch 4/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.6679 - accuracy: 0.5690 - val_loss: 1.6674 - val_accuracy: 0.5420\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.6567 - accuracy: 0.5657 - val_loss: 1.6575 - val_accuracy: 0.5539\n","Epoch 6/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.6457 - accuracy: 0.5700 - val_loss: 1.6478 - val_accuracy: 0.5560\n","Epoch 7/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.6351 - accuracy: 0.5760 - val_loss: 1.6382 - val_accuracy: 0.5550\n","Epoch 8/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.6251 - accuracy: 0.5773 - val_loss: 1.6285 - val_accuracy: 0.5550\n","Epoch 9/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.6153 - accuracy: 0.5768 - val_loss: 1.6189 - val_accuracy: 0.5571\n","Epoch 10/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.6057 - accuracy: 0.5779 - val_loss: 1.6094 - val_accuracy: 0.5550\n","Epoch 11/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.5960 - accuracy: 0.5862 - val_loss: 1.6000 - val_accuracy: 0.5560\n","Epoch 12/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.5862 - accuracy: 0.5838 - val_loss: 1.5901 - val_accuracy: 0.5700\n","Epoch 13/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5765 - accuracy: 0.5816 - val_loss: 1.5805 - val_accuracy: 0.5679\n","Epoch 14/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.5669 - accuracy: 0.5881 - val_loss: 1.5712 - val_accuracy: 0.5668\n","Epoch 15/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.5573 - accuracy: 0.5905 - val_loss: 1.5616 - val_accuracy: 0.5657\n","Epoch 16/100\n","29/29 [==============================] - 1s 34ms/step - loss: 1.5477 - accuracy: 0.5897 - val_loss: 1.5524 - val_accuracy: 0.5711\n","Epoch 17/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.5380 - accuracy: 0.5892 - val_loss: 1.5425 - val_accuracy: 0.5819\n","Epoch 18/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.5285 - accuracy: 0.5921 - val_loss: 1.5327 - val_accuracy: 0.5830\n","Epoch 19/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.5183 - accuracy: 0.5997 - val_loss: 1.5230 - val_accuracy: 0.5754\n","Epoch 20/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.5081 - accuracy: 0.5991 - val_loss: 1.5132 - val_accuracy: 0.5700\n","Epoch 21/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.4983 - accuracy: 0.5991 - val_loss: 1.5040 - val_accuracy: 0.5722\n","Epoch 22/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.4879 - accuracy: 0.6059 - val_loss: 1.4940 - val_accuracy: 0.5819\n","Epoch 23/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4776 - accuracy: 0.6094 - val_loss: 1.4849 - val_accuracy: 0.5819\n","Epoch 24/100\n","29/29 [==============================] - 1s 21ms/step - loss: 1.4686 - accuracy: 0.6161 - val_loss: 1.4760 - val_accuracy: 0.5938\n","Epoch 25/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.4593 - accuracy: 0.6126 - val_loss: 1.4676 - val_accuracy: 0.5938\n","Epoch 26/100\n","29/29 [==============================] - 1s 23ms/step - loss: 1.4495 - accuracy: 0.6228 - val_loss: 1.4590 - val_accuracy: 0.5991\n","Epoch 27/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.4420 - accuracy: 0.6193 - val_loss: 1.4520 - val_accuracy: 0.5894\n","Epoch 28/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.4338 - accuracy: 0.6196 - val_loss: 1.4434 - val_accuracy: 0.6034\n","Epoch 29/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.4249 - accuracy: 0.6242 - val_loss: 1.4383 - val_accuracy: 0.6002\n","Epoch 30/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.4167 - accuracy: 0.6220 - val_loss: 1.4313 - val_accuracy: 0.5991\n","Epoch 31/100\n","29/29 [==============================] - 1s 27ms/step - loss: 1.4102 - accuracy: 0.6242 - val_loss: 1.4247 - val_accuracy: 0.6078\n","Epoch 32/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.4019 - accuracy: 0.6307 - val_loss: 1.4178 - val_accuracy: 0.6067\n","Epoch 33/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.3946 - accuracy: 0.6282 - val_loss: 1.4118 - val_accuracy: 0.6067\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3875 - accuracy: 0.6352 - val_loss: 1.4034 - val_accuracy: 0.6024\n","Epoch 35/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.3803 - accuracy: 0.6288 - val_loss: 1.4000 - val_accuracy: 0.6110\n","Epoch 36/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.3722 - accuracy: 0.6393 - val_loss: 1.3939 - val_accuracy: 0.6121\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3671 - accuracy: 0.6360 - val_loss: 1.3846 - val_accuracy: 0.6045\n","Epoch 38/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3593 - accuracy: 0.6312 - val_loss: 1.3778 - val_accuracy: 0.5959\n","Epoch 39/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.3515 - accuracy: 0.6331 - val_loss: 1.3712 - val_accuracy: 0.5970\n","Epoch 40/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3451 - accuracy: 0.6350 - val_loss: 1.3670 - val_accuracy: 0.6067\n","Epoch 41/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.3396 - accuracy: 0.6342 - val_loss: 1.3594 - val_accuracy: 0.6056\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3348 - accuracy: 0.6317 - val_loss: 1.3525 - val_accuracy: 0.6013\n","Epoch 43/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.3281 - accuracy: 0.6358 - val_loss: 1.3472 - val_accuracy: 0.6024\n","Epoch 44/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.3183 - accuracy: 0.6398 - val_loss: 1.3426 - val_accuracy: 0.6142\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.3131 - accuracy: 0.6428 - val_loss: 1.3366 - val_accuracy: 0.6131\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.3061 - accuracy: 0.6409 - val_loss: 1.3322 - val_accuracy: 0.6110\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.2996 - accuracy: 0.6433 - val_loss: 1.3282 - val_accuracy: 0.6078\n","Epoch 48/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.2922 - accuracy: 0.6503 - val_loss: 1.3249 - val_accuracy: 0.6034\n","Epoch 49/100\n","29/29 [==============================] - 1s 22ms/step - loss: 1.2883 - accuracy: 0.6406 - val_loss: 1.3134 - val_accuracy: 0.6196\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2805 - accuracy: 0.6447 - val_loss: 1.3126 - val_accuracy: 0.6056\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2739 - accuracy: 0.6436 - val_loss: 1.3025 - val_accuracy: 0.6099\n","Epoch 52/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.2643 - accuracy: 0.6525 - val_loss: 1.2977 - val_accuracy: 0.6196\n","Epoch 53/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2604 - accuracy: 0.6490 - val_loss: 1.2933 - val_accuracy: 0.6153\n","Epoch 54/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2538 - accuracy: 0.6468 - val_loss: 1.2862 - val_accuracy: 0.6196\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2491 - accuracy: 0.6455 - val_loss: 1.2854 - val_accuracy: 0.6099\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2429 - accuracy: 0.6511 - val_loss: 1.2760 - val_accuracy: 0.6196\n","Epoch 57/100\n","29/29 [==============================] - 1s 26ms/step - loss: 1.2356 - accuracy: 0.6536 - val_loss: 1.2705 - val_accuracy: 0.6261\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2287 - accuracy: 0.6581 - val_loss: 1.2699 - val_accuracy: 0.6099\n","Epoch 59/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2243 - accuracy: 0.6576 - val_loss: 1.2646 - val_accuracy: 0.6110\n","Epoch 60/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.2170 - accuracy: 0.6624 - val_loss: 1.2587 - val_accuracy: 0.6153\n","Epoch 61/100\n","29/29 [==============================] - 1s 19ms/step - loss: 1.2112 - accuracy: 0.6544 - val_loss: 1.2541 - val_accuracy: 0.6164\n","Epoch 62/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.2039 - accuracy: 0.6614 - val_loss: 1.2560 - val_accuracy: 0.6056\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.2021 - accuracy: 0.6571 - val_loss: 1.2423 - val_accuracy: 0.6196\n","Epoch 64/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1911 - accuracy: 0.6651 - val_loss: 1.2434 - val_accuracy: 0.6078\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1871 - accuracy: 0.6646 - val_loss: 1.2386 - val_accuracy: 0.6099\n","Epoch 66/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1776 - accuracy: 0.6719 - val_loss: 1.2288 - val_accuracy: 0.6121\n","Epoch 67/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1724 - accuracy: 0.6724 - val_loss: 1.2250 - val_accuracy: 0.6207\n","Epoch 68/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1697 - accuracy: 0.6686 - val_loss: 1.2222 - val_accuracy: 0.6142\n","Epoch 69/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1638 - accuracy: 0.6657 - val_loss: 1.2194 - val_accuracy: 0.6121\n","Epoch 70/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1556 - accuracy: 0.6732 - val_loss: 1.2127 - val_accuracy: 0.6131\n","Epoch 71/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1509 - accuracy: 0.6703 - val_loss: 1.2081 - val_accuracy: 0.6153\n","Epoch 72/100\n","29/29 [==============================] - 0s 16ms/step - loss: 1.1414 - accuracy: 0.6783 - val_loss: 1.2068 - val_accuracy: 0.6164\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1357 - accuracy: 0.6840 - val_loss: 1.2006 - val_accuracy: 0.6056\n","Epoch 74/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1316 - accuracy: 0.6821 - val_loss: 1.2020 - val_accuracy: 0.6207\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1234 - accuracy: 0.6918 - val_loss: 1.1929 - val_accuracy: 0.6142\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1198 - accuracy: 0.6837 - val_loss: 1.1932 - val_accuracy: 0.6153\n","Epoch 77/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.1122 - accuracy: 0.6899 - val_loss: 1.1864 - val_accuracy: 0.6142\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.1074 - accuracy: 0.6897 - val_loss: 1.1866 - val_accuracy: 0.6110\n","Epoch 79/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0995 - accuracy: 0.6918 - val_loss: 1.1810 - val_accuracy: 0.6067\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0929 - accuracy: 0.6983 - val_loss: 1.1776 - val_accuracy: 0.6164\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0876 - accuracy: 0.6991 - val_loss: 1.1735 - val_accuracy: 0.6078\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0811 - accuracy: 0.6975 - val_loss: 1.1747 - val_accuracy: 0.6067\n","Epoch 83/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0736 - accuracy: 0.6977 - val_loss: 1.1704 - val_accuracy: 0.6067\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 1.0670 - accuracy: 0.7015 - val_loss: 1.1677 - val_accuracy: 0.6067\n","Epoch 85/100\n","29/29 [==============================] - 0s 14ms/step - loss: 1.0601 - accuracy: 0.7104 - val_loss: 1.1611 - val_accuracy: 0.6142\n","Epoch 86/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0587 - accuracy: 0.7004 - val_loss: 1.1636 - val_accuracy: 0.6175\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0478 - accuracy: 0.7058 - val_loss: 1.1575 - val_accuracy: 0.6056\n","Epoch 88/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0431 - accuracy: 0.7150 - val_loss: 1.1550 - val_accuracy: 0.6099\n","Epoch 89/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0382 - accuracy: 0.7074 - val_loss: 1.1517 - val_accuracy: 0.5991\n","Epoch 90/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0338 - accuracy: 0.7096 - val_loss: 1.1519 - val_accuracy: 0.6110\n","Epoch 91/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0268 - accuracy: 0.7085 - val_loss: 1.1510 - val_accuracy: 0.6142\n","Epoch 92/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.0184 - accuracy: 0.7223 - val_loss: 1.1452 - val_accuracy: 0.6110\n","Epoch 93/100\n","29/29 [==============================] - 1s 17ms/step - loss: 1.0168 - accuracy: 0.7115 - val_loss: 1.1447 - val_accuracy: 0.6013\n","Epoch 94/100\n","29/29 [==============================] - 0s 17ms/step - loss: 1.0132 - accuracy: 0.7109 - val_loss: 1.1392 - val_accuracy: 0.6110\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9984 - accuracy: 0.7271 - val_loss: 1.1384 - val_accuracy: 0.6067\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9989 - accuracy: 0.7220 - val_loss: 1.1394 - val_accuracy: 0.6045\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9877 - accuracy: 0.7244 - val_loss: 1.1423 - val_accuracy: 0.6078\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9834 - accuracy: 0.7260 - val_loss: 1.1346 - val_accuracy: 0.6099\n","Epoch 99/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9761 - accuracy: 0.7349 - val_loss: 1.1343 - val_accuracy: 0.6164\n","Epoch 100/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9718 - accuracy: 0.7276 - val_loss: 1.1321 - val_accuracy: 0.6078\n","{'loss': [1.7018307447433472, 1.6906040906906128, 1.6793420314788818, 1.6678740978240967, 1.6567128896713257, 1.6457172632217407, 1.6350891590118408, 1.6251099109649658, 1.6153231859207153, 1.605680227279663, 1.596037745475769, 1.5862125158309937, 1.5765197277069092, 1.5669406652450562, 1.5572690963745117, 1.5477241277694702, 1.5379582643508911, 1.528501272201538, 1.5183043479919434, 1.5081490278244019, 1.4982874393463135, 1.4879052639007568, 1.4775612354278564, 1.4685542583465576, 1.4593409299850464, 1.4494726657867432, 1.4419792890548706, 1.4337944984436035, 1.4249097108840942, 1.4167293310165405, 1.4102226495742798, 1.4018946886062622, 1.3946326971054077, 1.3875219821929932, 1.3802810907363892, 1.3721944093704224, 1.3670786619186401, 1.3593021631240845, 1.3514517545700073, 1.3451120853424072, 1.3395678997039795, 1.3347569704055786, 1.3281080722808838, 1.3182729482650757, 1.3131107091903687, 1.3060740232467651, 1.2996472120285034, 1.2922199964523315, 1.2882509231567383, 1.2804871797561646, 1.2739216089248657, 1.264313817024231, 1.2604053020477295, 1.2537921667099, 1.249135136604309, 1.2428661584854126, 1.235551118850708, 1.22874116897583, 1.2243080139160156, 1.2169649600982666, 1.2112047672271729, 1.203911542892456, 1.2021379470825195, 1.1910709142684937, 1.187100887298584, 1.177635908126831, 1.1723698377609253, 1.1697083711624146, 1.1637587547302246, 1.1555744409561157, 1.1508933305740356, 1.1414313316345215, 1.135705828666687, 1.131604790687561, 1.1234384775161743, 1.1197551488876343, 1.1122268438339233, 1.1074191331863403, 1.09952712059021, 1.092867374420166, 1.087552785873413, 1.0810757875442505, 1.0735887289047241, 1.0670411586761475, 1.0601123571395874, 1.058740496635437, 1.0478360652923584, 1.0430954694747925, 1.0382169485092163, 1.0338211059570312, 1.0268083810806274, 1.018379807472229, 1.016831874847412, 1.0132362842559814, 0.9984060525894165, 0.9988695979118347, 0.9877430200576782, 0.9834074378013611, 0.9761337637901306, 0.9717761278152466], 'accuracy': [0.537446141242981, 0.5457974076271057, 0.5619612336158752, 0.568965494632721, 0.5657327771186829, 0.5700430870056152, 0.5759698152542114, 0.5773168206214905, 0.576777994632721, 0.5778555870056152, 0.5862069129943848, 0.5837823152542114, 0.5816271305084229, 0.5880926847457886, 0.5905172228813171, 0.5897090435028076, 0.5891702771186829, 0.592133641242981, 0.5996767282485962, 0.5991379022598267, 0.5991379022598267, 0.6058728694915771, 0.609375, 0.6161099076271057, 0.6126077771186829, 0.6228448152542114, 0.6193426847457886, 0.6196120977401733, 0.6241918206214905, 0.6220366358757019, 0.6241918206214905, 0.6306573152542114, 0.6282327771186829, 0.6352370977401733, 0.6287715435028076, 0.639277994632721, 0.6360452771186829, 0.631196141242981, 0.6330819129943848, 0.6349676847457886, 0.634159505367279, 0.6317349076271057, 0.6357758641242981, 0.6398168206214905, 0.6427801847457886, 0.6408944129943848, 0.6433189511299133, 0.6503232717514038, 0.640625, 0.6446659564971924, 0.6435883641242981, 0.6524784564971924, 0.6489762663841248, 0.646821141242981, 0.6454741358757019, 0.6511314511299133, 0.6535560488700867, 0.6581357717514038, 0.657597005367279, 0.662446141242981, 0.6543642282485962, 0.6613685488700867, 0.6570581793785095, 0.6651400923728943, 0.6646012663841248, 0.671875, 0.6724137663841248, 0.6686422228813171, 0.665678858757019, 0.673222005367279, 0.670258641242981, 0.678340494632721, 0.6839978694915771, 0.6821120977401733, 0.6918103694915771, 0.6837284564971924, 0.6899245977401733, 0.6896551847457886, 0.6918103694915771, 0.6982758641242981, 0.6990840435028076, 0.6974676847457886, 0.6977370977401733, 0.701508641242981, 0.7103987336158752, 0.7004310488700867, 0.7058189511299133, 0.7149784564971924, 0.7074353694915771, 0.709590494632721, 0.7085129022598267, 0.7222521305084229, 0.7114762663841248, 0.7109375, 0.7271012663841248, 0.7219827771186829, 0.7244073152542114, 0.7260237336158752, 0.7349137663841248, 0.7276400923728943], 'val_loss': [1.6971194744110107, 1.6871145963668823, 1.6772102117538452, 1.667373538017273, 1.6575459241867065, 1.6478041410446167, 1.6381884813308716, 1.6285208463668823, 1.6188760995864868, 1.6093523502349854, 1.5999925136566162, 1.5901422500610352, 1.5805444717407227, 1.5711642503738403, 1.5616480112075806, 1.552362084388733, 1.5424692630767822, 1.532737374305725, 1.522964358329773, 1.5131570100784302, 1.504002332687378, 1.4939996004104614, 1.4848567247390747, 1.475994348526001, 1.4675624370574951, 1.4589698314666748, 1.4519753456115723, 1.4433887004852295, 1.4383001327514648, 1.4313483238220215, 1.424669623374939, 1.4177625179290771, 1.4118497371673584, 1.403358817100525, 1.4000427722930908, 1.3938992023468018, 1.384610652923584, 1.3778116703033447, 1.371228575706482, 1.36697256565094, 1.359377145767212, 1.3525474071502686, 1.3472310304641724, 1.3425654172897339, 1.3365960121154785, 1.3322046995162964, 1.328249454498291, 1.324914813041687, 1.3134396076202393, 1.3126018047332764, 1.302458643913269, 1.2977029085159302, 1.2932653427124023, 1.2861545085906982, 1.2854291200637817, 1.2760207653045654, 1.2704904079437256, 1.2698818445205688, 1.2645559310913086, 1.2587403059005737, 1.2541399002075195, 1.2560006380081177, 1.2423007488250732, 1.2434284687042236, 1.2385518550872803, 1.2288132905960083, 1.2250405550003052, 1.2222023010253906, 1.219415545463562, 1.2126753330230713, 1.2081223726272583, 1.2068065404891968, 1.2006064653396606, 1.2019847631454468, 1.1928566694259644, 1.1931735277175903, 1.1863963603973389, 1.1866490840911865, 1.1810201406478882, 1.1776041984558105, 1.1734611988067627, 1.1746628284454346, 1.1704224348068237, 1.1677145957946777, 1.1611484289169312, 1.1635792255401611, 1.1575486660003662, 1.1550365686416626, 1.1517210006713867, 1.1519256830215454, 1.1510462760925293, 1.1452323198318481, 1.1446890830993652, 1.1391761302947998, 1.13844895362854, 1.13944411277771, 1.1422524452209473, 1.1346349716186523, 1.1342555284500122, 1.1321452856063843], 'val_accuracy': [0.5646551847457886, 0.5474137663841248, 0.5441810488700867, 0.5420258641242981, 0.5538793206214905, 0.556034505367279, 0.5549569129943848, 0.5549569129943848, 0.5571120977401733, 0.5549569129943848, 0.556034505367279, 0.5700430870056152, 0.5678879022598267, 0.5668103694915771, 0.5657327771186829, 0.5711206793785095, 0.5818965435028076, 0.5829741358757019, 0.5754310488700867, 0.5700430870056152, 0.5721982717514038, 0.5818965435028076, 0.5818965435028076, 0.59375, 0.59375, 0.5991379022598267, 0.5894396305084229, 0.6034482717514038, 0.600215494632721, 0.5991379022598267, 0.607758641242981, 0.6066810488700867, 0.6066810488700867, 0.6023706793785095, 0.610991358757019, 0.6120689511299133, 0.6045258641242981, 0.5959051847457886, 0.5969827771186829, 0.6066810488700867, 0.6056034564971924, 0.6012930870056152, 0.6023706793785095, 0.6142241358757019, 0.6131465435028076, 0.610991358757019, 0.607758641242981, 0.6034482717514038, 0.6196120977401733, 0.6056034564971924, 0.6099137663841248, 0.6196120977401733, 0.6153017282485962, 0.6196120977401733, 0.6099137663841248, 0.6196120977401733, 0.6260775923728943, 0.6099137663841248, 0.610991358757019, 0.6153017282485962, 0.6163793206214905, 0.6056034564971924, 0.6196120977401733, 0.607758641242981, 0.6099137663841248, 0.6120689511299133, 0.6206896305084229, 0.6142241358757019, 0.6120689511299133, 0.6131465435028076, 0.6153017282485962, 0.6163793206214905, 0.6056034564971924, 0.6206896305084229, 0.6142241358757019, 0.6153017282485962, 0.6142241358757019, 0.610991358757019, 0.6066810488700867, 0.6163793206214905, 0.607758641242981, 0.6066810488700867, 0.6066810488700867, 0.6066810488700867, 0.6142241358757019, 0.6174569129943848, 0.6056034564971924, 0.6099137663841248, 0.5991379022598267, 0.610991358757019, 0.6142241358757019, 0.610991358757019, 0.6012930870056152, 0.610991358757019, 0.6066810488700867, 0.6045258641242981, 0.607758641242981, 0.6099137663841248, 0.6163793206214905, 0.607758641242981]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - 8s 54ms/step - loss: 1.7021 - accuracy: 0.5311 - val_loss: 1.6974 - val_accuracy: 0.5475\n","Epoch 2/100\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 0s 16ms/step - loss: 1.6915 - accuracy: 0.5450 - val_loss: 1.6878 - val_accuracy: 0.5351\n","Epoch 3/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.6808 - accuracy: 0.5410 - val_loss: 1.6782 - val_accuracy: 0.5362\n","Epoch 4/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6698 - accuracy: 0.5557 - val_loss: 1.6688 - val_accuracy: 0.5305\n","Epoch 5/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6590 - accuracy: 0.5591 - val_loss: 1.6594 - val_accuracy: 0.5305\n","Epoch 6/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.6486 - accuracy: 0.5600 - val_loss: 1.6500 - val_accuracy: 0.5396\n","Epoch 7/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6383 - accuracy: 0.5625 - val_loss: 1.6408 - val_accuracy: 0.5385\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6286 - accuracy: 0.5665 - val_loss: 1.6314 - val_accuracy: 0.5419\n","Epoch 9/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6192 - accuracy: 0.5640 - val_loss: 1.6225 - val_accuracy: 0.5407\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.6098 - accuracy: 0.5651 - val_loss: 1.6132 - val_accuracy: 0.5452\n","Epoch 11/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.6005 - accuracy: 0.5671 - val_loss: 1.6046 - val_accuracy: 0.5385\n","Epoch 12/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.5912 - accuracy: 0.5713 - val_loss: 1.5955 - val_accuracy: 0.5430\n","Epoch 13/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.5817 - accuracy: 0.5747 - val_loss: 1.5864 - val_accuracy: 0.5464\n","Epoch 14/100\n","28/28 [==============================] - 1s 27ms/step - loss: 1.5727 - accuracy: 0.5758 - val_loss: 1.5773 - val_accuracy: 0.5509\n","Epoch 15/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.5635 - accuracy: 0.5764 - val_loss: 1.5684 - val_accuracy: 0.5475\n","Epoch 16/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.5544 - accuracy: 0.5798 - val_loss: 1.5591 - val_accuracy: 0.5509\n","Epoch 17/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.5446 - accuracy: 0.5838 - val_loss: 1.5507 - val_accuracy: 0.5509\n","Epoch 18/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.5355 - accuracy: 0.5829 - val_loss: 1.5415 - val_accuracy: 0.5633\n","Epoch 19/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.5257 - accuracy: 0.5883 - val_loss: 1.5320 - val_accuracy: 0.5781\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.5165 - accuracy: 0.5897 - val_loss: 1.5225 - val_accuracy: 0.5667\n","Epoch 21/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.5069 - accuracy: 0.5917 - val_loss: 1.5144 - val_accuracy: 0.5690\n","Epoch 22/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4967 - accuracy: 0.5973 - val_loss: 1.5058 - val_accuracy: 0.5690\n","Epoch 23/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4875 - accuracy: 0.6007 - val_loss: 1.4962 - val_accuracy: 0.5747\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4785 - accuracy: 0.6010 - val_loss: 1.4890 - val_accuracy: 0.5713\n","Epoch 25/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4698 - accuracy: 0.6024 - val_loss: 1.4808 - val_accuracy: 0.5735\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4601 - accuracy: 0.6047 - val_loss: 1.4753 - val_accuracy: 0.5713\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4528 - accuracy: 0.6038 - val_loss: 1.4681 - val_accuracy: 0.5724\n","Epoch 28/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4438 - accuracy: 0.6115 - val_loss: 1.4658 - val_accuracy: 0.5656\n","Epoch 29/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4381 - accuracy: 0.6109 - val_loss: 1.4554 - val_accuracy: 0.5701\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4306 - accuracy: 0.6036 - val_loss: 1.4487 - val_accuracy: 0.5747\n","Epoch 31/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.4229 - accuracy: 0.6098 - val_loss: 1.4425 - val_accuracy: 0.5814\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4141 - accuracy: 0.6152 - val_loss: 1.4364 - val_accuracy: 0.5724\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.4060 - accuracy: 0.6152 - val_loss: 1.4314 - val_accuracy: 0.5701\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.4013 - accuracy: 0.6140 - val_loss: 1.4269 - val_accuracy: 0.5679\n","Epoch 35/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3929 - accuracy: 0.6225 - val_loss: 1.4203 - val_accuracy: 0.5724\n","Epoch 36/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.3858 - accuracy: 0.6177 - val_loss: 1.4128 - val_accuracy: 0.5837\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3795 - accuracy: 0.6225 - val_loss: 1.4102 - val_accuracy: 0.5724\n","Epoch 38/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.3734 - accuracy: 0.6143 - val_loss: 1.4014 - val_accuracy: 0.5814\n","Epoch 39/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3658 - accuracy: 0.6183 - val_loss: 1.3955 - val_accuracy: 0.5826\n","Epoch 40/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.3588 - accuracy: 0.6191 - val_loss: 1.3895 - val_accuracy: 0.5882\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3523 - accuracy: 0.6228 - val_loss: 1.3874 - val_accuracy: 0.5769\n","Epoch 42/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.3462 - accuracy: 0.6225 - val_loss: 1.3786 - val_accuracy: 0.5882\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3403 - accuracy: 0.6256 - val_loss: 1.3729 - val_accuracy: 0.5848\n","Epoch 44/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.3310 - accuracy: 0.6251 - val_loss: 1.3678 - val_accuracy: 0.5905\n","Epoch 45/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.3264 - accuracy: 0.6293 - val_loss: 1.3639 - val_accuracy: 0.5826\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.3196 - accuracy: 0.6271 - val_loss: 1.3583 - val_accuracy: 0.5837\n","Epoch 47/100\n","28/28 [==============================] - 0s 18ms/step - loss: 1.3147 - accuracy: 0.6222 - val_loss: 1.3528 - val_accuracy: 0.5814\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.3082 - accuracy: 0.6256 - val_loss: 1.3476 - val_accuracy: 0.5826\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3015 - accuracy: 0.6299 - val_loss: 1.3408 - val_accuracy: 0.5837\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2945 - accuracy: 0.6310 - val_loss: 1.3360 - val_accuracy: 0.5826\n","Epoch 51/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2895 - accuracy: 0.6350 - val_loss: 1.3313 - val_accuracy: 0.5837\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2830 - accuracy: 0.6293 - val_loss: 1.3278 - val_accuracy: 0.5826\n","Epoch 53/100\n","28/28 [==============================] - 1s 22ms/step - loss: 1.2760 - accuracy: 0.6387 - val_loss: 1.3214 - val_accuracy: 0.5916\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2712 - accuracy: 0.6355 - val_loss: 1.3168 - val_accuracy: 0.5882\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2652 - accuracy: 0.6367 - val_loss: 1.3181 - val_accuracy: 0.5871\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2610 - accuracy: 0.6361 - val_loss: 1.3053 - val_accuracy: 0.5894\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2512 - accuracy: 0.6432 - val_loss: 1.3021 - val_accuracy: 0.5871\n","Epoch 58/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.2468 - accuracy: 0.6423 - val_loss: 1.2981 - val_accuracy: 0.5837\n","Epoch 59/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2420 - accuracy: 0.6392 - val_loss: 1.2934 - val_accuracy: 0.5860\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2366 - accuracy: 0.6443 - val_loss: 1.2891 - val_accuracy: 0.5860\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2293 - accuracy: 0.6420 - val_loss: 1.2844 - val_accuracy: 0.5882\n","Epoch 62/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.2239 - accuracy: 0.6409 - val_loss: 1.2786 - val_accuracy: 0.5939\n","Epoch 63/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2168 - accuracy: 0.6497 - val_loss: 1.2734 - val_accuracy: 0.5882\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2128 - accuracy: 0.6457 - val_loss: 1.2689 - val_accuracy: 0.5928\n","Epoch 65/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.2063 - accuracy: 0.6551 - val_loss: 1.2658 - val_accuracy: 0.5984\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.2006 - accuracy: 0.6531 - val_loss: 1.2609 - val_accuracy: 0.5905\n","Epoch 67/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1981 - accuracy: 0.6517 - val_loss: 1.2572 - val_accuracy: 0.5905\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1897 - accuracy: 0.6522 - val_loss: 1.2545 - val_accuracy: 0.5973\n","Epoch 69/100\n","28/28 [==============================] - 1s 29ms/step - loss: 1.1837 - accuracy: 0.6570 - val_loss: 1.2472 - val_accuracy: 0.6007\n","Epoch 70/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1786 - accuracy: 0.6559 - val_loss: 1.2449 - val_accuracy: 0.5995\n","Epoch 71/100\n","28/28 [==============================] - 1s 30ms/step - loss: 1.1709 - accuracy: 0.6596 - val_loss: 1.2413 - val_accuracy: 0.6029\n","Epoch 72/100\n","28/28 [==============================] - 1s 21ms/step - loss: 1.1665 - accuracy: 0.6587 - val_loss: 1.2390 - val_accuracy: 0.5939\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1616 - accuracy: 0.6616 - val_loss: 1.2393 - val_accuracy: 0.5871\n","Epoch 74/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1547 - accuracy: 0.6610 - val_loss: 1.2268 - val_accuracy: 0.6007\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1500 - accuracy: 0.6585 - val_loss: 1.2283 - val_accuracy: 0.6029\n","Epoch 76/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1459 - accuracy: 0.6647 - val_loss: 1.2181 - val_accuracy: 0.6029\n","Epoch 77/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1380 - accuracy: 0.6664 - val_loss: 1.2158 - val_accuracy: 0.6029\n","Epoch 78/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1347 - accuracy: 0.6743 - val_loss: 1.2137 - val_accuracy: 0.6007\n","Epoch 79/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.1300 - accuracy: 0.6703 - val_loss: 1.2134 - val_accuracy: 0.6018\n","Epoch 80/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1228 - accuracy: 0.6703 - val_loss: 1.2081 - val_accuracy: 0.5950\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1147 - accuracy: 0.6774 - val_loss: 1.2037 - val_accuracy: 0.5995\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1099 - accuracy: 0.6729 - val_loss: 1.2105 - val_accuracy: 0.5803\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.1063 - accuracy: 0.6802 - val_loss: 1.1956 - val_accuracy: 0.6007\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0980 - accuracy: 0.6811 - val_loss: 1.1932 - val_accuracy: 0.5962\n","Epoch 85/100\n","28/28 [==============================] - 1s 24ms/step - loss: 1.0920 - accuracy: 0.6802 - val_loss: 1.1878 - val_accuracy: 0.6041\n","Epoch 86/100\n","28/28 [==============================] - 1s 25ms/step - loss: 1.0890 - accuracy: 0.6718 - val_loss: 1.1848 - val_accuracy: 0.6075\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 1.0840 - accuracy: 0.6802 - val_loss: 1.1817 - val_accuracy: 0.6041\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0722 - accuracy: 0.6848 - val_loss: 1.1849 - val_accuracy: 0.6041\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0711 - accuracy: 0.6876 - val_loss: 1.1787 - val_accuracy: 0.5916\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0612 - accuracy: 0.6919 - val_loss: 1.1740 - val_accuracy: 0.5995\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0581 - accuracy: 0.6887 - val_loss: 1.1730 - val_accuracy: 0.6018\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0520 - accuracy: 0.6955 - val_loss: 1.1700 - val_accuracy: 0.5973\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0423 - accuracy: 0.6947 - val_loss: 1.1683 - val_accuracy: 0.6029\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0411 - accuracy: 0.6944 - val_loss: 1.1695 - val_accuracy: 0.5905\n","Epoch 95/100\n","28/28 [==============================] - 0s 17ms/step - loss: 1.0320 - accuracy: 0.7003 - val_loss: 1.1629 - val_accuracy: 0.6018\n","Epoch 96/100\n","28/28 [==============================] - 1s 28ms/step - loss: 1.0263 - accuracy: 0.7006 - val_loss: 1.1612 - val_accuracy: 0.6131\n","Epoch 97/100\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0175 - accuracy: 0.7080 - val_loss: 1.1616 - val_accuracy: 0.6007\n","Epoch 98/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0129 - accuracy: 0.7102 - val_loss: 1.1572 - val_accuracy: 0.6131\n","Epoch 99/100\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0125 - accuracy: 0.7060 - val_loss: 1.1585 - val_accuracy: 0.6131\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0079 - accuracy: 0.7032 - val_loss: 1.1705 - val_accuracy: 0.5905\n","{'loss': [1.702110767364502, 1.6915340423583984, 1.680806040763855, 1.669825792312622, 1.6589876413345337, 1.648593544960022, 1.6383488178253174, 1.6286462545394897, 1.6192028522491455, 1.6097509860992432, 1.60045325756073, 1.5912339687347412, 1.581748127937317, 1.5726583003997803, 1.5634889602661133, 1.554442286491394, 1.5445935726165771, 1.5355404615402222, 1.5256919860839844, 1.5164722204208374, 1.5069118738174438, 1.4966950416564941, 1.4875168800354004, 1.4785140752792358, 1.4697623252868652, 1.4600530862808228, 1.45279061794281, 1.443758249282837, 1.438065528869629, 1.430588722229004, 1.4229182004928589, 1.4140657186508179, 1.4059640169143677, 1.4013104438781738, 1.3928828239440918, 1.385785698890686, 1.3795479536056519, 1.3733562231063843, 1.3658146858215332, 1.358810544013977, 1.3523244857788086, 1.3461766242980957, 1.3403483629226685, 1.3310089111328125, 1.326385259628296, 1.3196228742599487, 1.314666748046875, 1.3082026243209839, 1.3014894723892212, 1.2944624423980713, 1.289515733718872, 1.2830440998077393, 1.2759814262390137, 1.2712199687957764, 1.2651807069778442, 1.2610048055648804, 1.251172661781311, 1.2468338012695312, 1.2420003414154053, 1.2366167306900024, 1.2292581796646118, 1.223936676979065, 1.2167695760726929, 1.2128351926803589, 1.2062898874282837, 1.2005605697631836, 1.1981056928634644, 1.1896547079086304, 1.1836721897125244, 1.1786285638809204, 1.170912504196167, 1.1665316820144653, 1.161592721939087, 1.1547400951385498, 1.150047779083252, 1.1459389925003052, 1.1379644870758057, 1.1347419023513794, 1.1300312280654907, 1.1228028535842896, 1.1147468090057373, 1.1098746061325073, 1.1063369512557983, 1.0980201959609985, 1.0919634103775024, 1.0890281200408936, 1.0839509963989258, 1.0722451210021973, 1.0711015462875366, 1.0612285137176514, 1.0580809116363525, 1.051994800567627, 1.0423439741134644, 1.0411063432693481, 1.03202223777771, 1.0263339281082153, 1.0175089836120605, 1.0129497051239014, 1.0124551057815552, 1.0079232454299927], 'accuracy': [0.5311262011528015, 0.5449914932250977, 0.5410299897193909, 0.5557441711425781, 0.5591397881507874, 0.5599886775016785, 0.5625353455543518, 0.5664969086647034, 0.5639501810073853, 0.5650820732116699, 0.5670627951622009, 0.5713073015213013, 0.5747028589248657, 0.5758347511291504, 0.5764006972312927, 0.5797962546348572, 0.583757758140564, 0.5829088687896729, 0.5882852077484131, 0.5897000432014465, 0.5916808247566223, 0.5973401069641113, 0.6007357239723206, 0.6010186672210693, 0.6024335026741028, 0.6046972274780273, 0.6038483381271362, 0.611488401889801, 0.6109224557876587, 0.6035653352737427, 0.6097906231880188, 0.615166962146759, 0.615166962146759, 0.6140350699424744, 0.6225240230560303, 0.6177136301994324, 0.6225240230560303, 0.6143180727958679, 0.6182795763015747, 0.6191284656524658, 0.6228070259094238, 0.6225240230560303, 0.6256366968154907, 0.6250707507133484, 0.629315197467804, 0.6270514726638794, 0.6222410798072815, 0.6256366968154907, 0.6298811435699463, 0.631013035774231, 0.6349745392799377, 0.629315197467804, 0.6386530995368958, 0.6355404853820801, 0.63667231798172, 0.6361063718795776, 0.6431805491447449, 0.6423316597938538, 0.6392189860343933, 0.6443123817443848, 0.6420486569404602, 0.6409168243408203, 0.649688720703125, 0.6457272171974182, 0.6550650596618652, 0.6530843377113342, 0.6516695022583008, 0.6522354483604431, 0.657045841217041, 0.6559139490127563, 0.6595925092697144, 0.6587436199188232, 0.6615732908248901, 0.6610073447227478, 0.6584606766700745, 0.6646859049797058, 0.666383683681488, 0.6743067502975464, 0.6703452467918396, 0.6703452467918396, 0.6774193644523621, 0.6728919148445129, 0.680249035358429, 0.6810979247093201, 0.680249035358429, 0.6717600226402283, 0.680249035358429, 0.6847764849662781, 0.6876060962677002, 0.6918506026268005, 0.6887379884719849, 0.6955291628837585, 0.6946802735328674, 0.6943972706794739, 0.7003395557403564, 0.7006224989891052, 0.7079796195030212, 0.7102433443069458, 0.7059988975524902, 0.7031692266464233], 'val_loss': [1.6974472999572754, 1.6877915859222412, 1.678235411643982, 1.668776035308838, 1.659382939338684, 1.6499589681625366, 1.6407864093780518, 1.6314406394958496, 1.6224664449691772, 1.6132076978683472, 1.604583978652954, 1.59548020362854, 1.5864211320877075, 1.5772716999053955, 1.5683863162994385, 1.5590897798538208, 1.5506658554077148, 1.5414806604385376, 1.5320417881011963, 1.5224682092666626, 1.5144243240356445, 1.5057880878448486, 1.4961751699447632, 1.4889912605285645, 1.4807852506637573, 1.4753116369247437, 1.4681459665298462, 1.4658093452453613, 1.4554400444030762, 1.4486610889434814, 1.4425182342529297, 1.436374306678772, 1.4314305782318115, 1.4268923997879028, 1.4202741384506226, 1.41278874874115, 1.4101520776748657, 1.401440978050232, 1.3954848051071167, 1.3895180225372314, 1.3873628377914429, 1.3785626888275146, 1.3728761672973633, 1.3677537441253662, 1.3639088869094849, 1.358261227607727, 1.352765679359436, 1.3476067781448364, 1.3408204317092896, 1.3359923362731934, 1.331292986869812, 1.3278056383132935, 1.3213951587677002, 1.3168299198150635, 1.3180885314941406, 1.3053468465805054, 1.3021103143692017, 1.2981404066085815, 1.2934163808822632, 1.2890665531158447, 1.2843821048736572, 1.2786437273025513, 1.2733889818191528, 1.2689197063446045, 1.2657654285430908, 1.2608544826507568, 1.2571507692337036, 1.254477620124817, 1.2472138404846191, 1.2448784112930298, 1.2412832975387573, 1.2390332221984863, 1.2393285036087036, 1.2267557382583618, 1.228323221206665, 1.2181434631347656, 1.2157917022705078, 1.2137348651885986, 1.2133737802505493, 1.2081456184387207, 1.2036936283111572, 1.210479736328125, 1.1955629587173462, 1.193179726600647, 1.1877721548080444, 1.184794545173645, 1.1817288398742676, 1.1848546266555786, 1.1787117719650269, 1.1740413904190063, 1.1729942560195923, 1.170025110244751, 1.1682792901992798, 1.1695283651351929, 1.1628636121749878, 1.161242127418518, 1.1616075038909912, 1.1572048664093018, 1.1584646701812744, 1.1704649925231934], 'val_accuracy': [0.5475113391876221, 0.5350678563117981, 0.5361990928649902, 0.5305429697036743, 0.5305429697036743, 0.5395927429199219, 0.5384615659713745, 0.5418552160263062, 0.540723979473114, 0.5452488660812378, 0.5384615659713745, 0.5429864525794983, 0.5463801026344299, 0.5509049892425537, 0.5475113391876221, 0.5509049892425537, 0.5509049892425537, 0.5633484125137329, 0.5780543088912964, 0.5667420625686646, 0.5690045356750488, 0.5690045356750488, 0.5746606588363647, 0.5712669491767883, 0.5735294222831726, 0.5712669491767883, 0.5723981857299805, 0.5656108856201172, 0.570135772228241, 0.5746606588363647, 0.581447958946228, 0.5723981857299805, 0.570135772228241, 0.5678732991218567, 0.5723981857299805, 0.5837104320526123, 0.5723981857299805, 0.581447958946228, 0.5825791954994202, 0.5882353186607361, 0.5769230723381042, 0.5882353186607361, 0.5848416090011597, 0.5904977321624756, 0.5825791954994202, 0.5837104320526123, 0.581447958946228, 0.5825791954994202, 0.5837104320526123, 0.5825791954994202, 0.5837104320526123, 0.5825791954994202, 0.5916289687156677, 0.5882353186607361, 0.587104082107544, 0.5893664956092834, 0.587104082107544, 0.5837104320526123, 0.5859728455543518, 0.5859728455543518, 0.5882353186607361, 0.5938913822174072, 0.5882353186607361, 0.5927602052688599, 0.598416268825531, 0.5904977321624756, 0.5904977321624756, 0.5972850918769836, 0.6006787419319153, 0.5995475053787231, 0.6029411554336548, 0.5938913822174072, 0.587104082107544, 0.6006787419319153, 0.6029411554336548, 0.6029411554336548, 0.6029411554336548, 0.6006787419319153, 0.6018099784851074, 0.5950226187705994, 0.5995475053787231, 0.5803167223930359, 0.6006787419319153, 0.5961538553237915, 0.6040723919868469, 0.6074660420417786, 0.6040723919868469, 0.6040723919868469, 0.5916289687156677, 0.5995475053787231, 0.6018099784851074, 0.5972850918769836, 0.6029411554336548, 0.5904977321624756, 0.6018099784851074, 0.6131221652030945, 0.6006787419319153, 0.6131221652030945, 0.6131221652030945, 0.5904977321624756]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 8s 50ms/step - loss: 1.7014 - accuracy: 0.5289 - val_loss: 1.6964 - val_accuracy: 0.5671\n","Epoch 2/100\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 0s 16ms/step - loss: 1.6894 - accuracy: 0.5478 - val_loss: 1.6857 - val_accuracy: 0.5393\n","Epoch 3/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.6773 - accuracy: 0.5661 - val_loss: 1.6752 - val_accuracy: 0.5372\n","Epoch 4/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.6652 - accuracy: 0.5587 - val_loss: 1.6648 - val_accuracy: 0.5403\n","Epoch 5/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.6532 - accuracy: 0.5674 - val_loss: 1.6545 - val_accuracy: 0.5413\n","Epoch 6/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.6418 - accuracy: 0.5664 - val_loss: 1.6442 - val_accuracy: 0.5393\n","Epoch 7/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.6308 - accuracy: 0.5731 - val_loss: 1.6341 - val_accuracy: 0.5393\n","Epoch 8/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.6204 - accuracy: 0.5713 - val_loss: 1.6241 - val_accuracy: 0.5393\n","Epoch 9/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.6097 - accuracy: 0.5718 - val_loss: 1.6141 - val_accuracy: 0.5413\n","Epoch 10/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.5996 - accuracy: 0.5680 - val_loss: 1.6041 - val_accuracy: 0.5393\n","Epoch 11/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5894 - accuracy: 0.5713 - val_loss: 1.5942 - val_accuracy: 0.5424\n","Epoch 12/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5797 - accuracy: 0.5757 - val_loss: 1.5843 - val_accuracy: 0.5496\n","Epoch 13/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5697 - accuracy: 0.5747 - val_loss: 1.5744 - val_accuracy: 0.5599\n","Epoch 14/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.5597 - accuracy: 0.5765 - val_loss: 1.5650 - val_accuracy: 0.5496\n","Epoch 15/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.5501 - accuracy: 0.5822 - val_loss: 1.5550 - val_accuracy: 0.5702\n","Epoch 16/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.5405 - accuracy: 0.5829 - val_loss: 1.5454 - val_accuracy: 0.5682\n","Epoch 17/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.5306 - accuracy: 0.5902 - val_loss: 1.5352 - val_accuracy: 0.5651\n","Epoch 18/100\n","31/31 [==============================] - 1s 29ms/step - loss: 1.5201 - accuracy: 0.5881 - val_loss: 1.5257 - val_accuracy: 0.5713\n","Epoch 19/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.5107 - accuracy: 0.5863 - val_loss: 1.5158 - val_accuracy: 0.5692\n","Epoch 20/100\n","31/31 [==============================] - 1s 27ms/step - loss: 1.5005 - accuracy: 0.5866 - val_loss: 1.5060 - val_accuracy: 0.5878\n","Epoch 21/100\n","31/31 [==============================] - 1s 28ms/step - loss: 1.4909 - accuracy: 0.5922 - val_loss: 1.4966 - val_accuracy: 0.5919\n","Epoch 22/100\n","31/31 [==============================] - 1s 20ms/step - loss: 1.4810 - accuracy: 0.5972 - val_loss: 1.4869 - val_accuracy: 0.5878\n","Epoch 23/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.4706 - accuracy: 0.6016 - val_loss: 1.4775 - val_accuracy: 0.5930\n","Epoch 24/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.4617 - accuracy: 0.5966 - val_loss: 1.4682 - val_accuracy: 0.5909\n","Epoch 25/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4528 - accuracy: 0.6034 - val_loss: 1.4591 - val_accuracy: 0.5888\n","Epoch 26/100\n","31/31 [==============================] - 1s 23ms/step - loss: 1.4434 - accuracy: 0.6109 - val_loss: 1.4548 - val_accuracy: 0.5992\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.4349 - accuracy: 0.6085 - val_loss: 1.4433 - val_accuracy: 0.5837\n","Epoch 28/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.4269 - accuracy: 0.6109 - val_loss: 1.4390 - val_accuracy: 0.6074\n","Epoch 29/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4172 - accuracy: 0.6127 - val_loss: 1.4269 - val_accuracy: 0.5826\n","Epoch 30/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.4107 - accuracy: 0.6129 - val_loss: 1.4241 - val_accuracy: 0.6002\n","Epoch 31/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.4028 - accuracy: 0.6090 - val_loss: 1.4165 - val_accuracy: 0.6033\n","Epoch 32/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3955 - accuracy: 0.6145 - val_loss: 1.4045 - val_accuracy: 0.5806\n","Epoch 33/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3871 - accuracy: 0.6140 - val_loss: 1.4014 - val_accuracy: 0.6002\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3802 - accuracy: 0.6152 - val_loss: 1.3974 - val_accuracy: 0.6064\n","Epoch 35/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.3734 - accuracy: 0.6134 - val_loss: 1.3879 - val_accuracy: 0.6023\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3642 - accuracy: 0.6196 - val_loss: 1.3803 - val_accuracy: 0.5971\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3590 - accuracy: 0.6171 - val_loss: 1.3716 - val_accuracy: 0.5878\n","Epoch 38/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3498 - accuracy: 0.6212 - val_loss: 1.3686 - val_accuracy: 0.6043\n","Epoch 39/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3433 - accuracy: 0.6264 - val_loss: 1.3584 - val_accuracy: 0.5909\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.3362 - accuracy: 0.6253 - val_loss: 1.3562 - val_accuracy: 0.6064\n","Epoch 41/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3310 - accuracy: 0.6235 - val_loss: 1.3480 - val_accuracy: 0.6043\n","Epoch 42/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.3230 - accuracy: 0.6238 - val_loss: 1.3430 - val_accuracy: 0.5971\n","Epoch 43/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.3150 - accuracy: 0.6279 - val_loss: 1.3371 - val_accuracy: 0.6043\n","Epoch 44/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3088 - accuracy: 0.6207 - val_loss: 1.3323 - val_accuracy: 0.6064\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.3024 - accuracy: 0.6287 - val_loss: 1.3235 - val_accuracy: 0.6012\n","Epoch 46/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.2971 - accuracy: 0.6302 - val_loss: 1.3189 - val_accuracy: 0.6095\n","Epoch 47/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2892 - accuracy: 0.6326 - val_loss: 1.3156 - val_accuracy: 0.6095\n","Epoch 48/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2830 - accuracy: 0.6336 - val_loss: 1.3053 - val_accuracy: 0.5961\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.2777 - accuracy: 0.6282 - val_loss: 1.3036 - val_accuracy: 0.6064\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.2678 - accuracy: 0.6388 - val_loss: 1.2930 - val_accuracy: 0.5930\n","Epoch 51/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2645 - accuracy: 0.6341 - val_loss: 1.2950 - val_accuracy: 0.6074\n","Epoch 52/100\n","31/31 [==============================] - 1s 22ms/step - loss: 1.2570 - accuracy: 0.6349 - val_loss: 1.2876 - val_accuracy: 0.6126\n","Epoch 53/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2511 - accuracy: 0.6426 - val_loss: 1.2822 - val_accuracy: 0.6054\n","Epoch 54/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2431 - accuracy: 0.6380 - val_loss: 1.2735 - val_accuracy: 0.5878\n","Epoch 55/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2392 - accuracy: 0.6354 - val_loss: 1.2677 - val_accuracy: 0.5992\n","Epoch 56/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2316 - accuracy: 0.6388 - val_loss: 1.2632 - val_accuracy: 0.5878\n","Epoch 57/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2243 - accuracy: 0.6419 - val_loss: 1.2599 - val_accuracy: 0.6064\n","Epoch 58/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2178 - accuracy: 0.6468 - val_loss: 1.2531 - val_accuracy: 0.5930\n","Epoch 59/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.2129 - accuracy: 0.6393 - val_loss: 1.2534 - val_accuracy: 0.6054\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.2072 - accuracy: 0.6468 - val_loss: 1.2446 - val_accuracy: 0.6012\n","Epoch 61/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1995 - accuracy: 0.6442 - val_loss: 1.2406 - val_accuracy: 0.6002\n","Epoch 62/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1952 - accuracy: 0.6460 - val_loss: 1.2457 - val_accuracy: 0.6002\n","Epoch 63/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1867 - accuracy: 0.6530 - val_loss: 1.2332 - val_accuracy: 0.6064\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1835 - accuracy: 0.6473 - val_loss: 1.2319 - val_accuracy: 0.6064\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1759 - accuracy: 0.6545 - val_loss: 1.2245 - val_accuracy: 0.5981\n","Epoch 66/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1709 - accuracy: 0.6545 - val_loss: 1.2198 - val_accuracy: 0.6043\n","Epoch 67/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1620 - accuracy: 0.6568 - val_loss: 1.2150 - val_accuracy: 0.6023\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.1576 - accuracy: 0.6602 - val_loss: 1.2134 - val_accuracy: 0.6012\n","Epoch 69/100\n","31/31 [==============================] - 0s 14ms/step - loss: 1.1483 - accuracy: 0.6633 - val_loss: 1.2083 - val_accuracy: 0.5961\n","Epoch 70/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1424 - accuracy: 0.6659 - val_loss: 1.2042 - val_accuracy: 0.6054\n","Epoch 71/100\n","31/31 [==============================] - 1s 17ms/step - loss: 1.1351 - accuracy: 0.6615 - val_loss: 1.2023 - val_accuracy: 0.5899\n","Epoch 72/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1303 - accuracy: 0.6695 - val_loss: 1.1965 - val_accuracy: 0.6054\n","Epoch 73/100\n","31/31 [==============================] - 2s 55ms/step - loss: 1.1260 - accuracy: 0.6628 - val_loss: 1.1908 - val_accuracy: 0.6229\n","Epoch 74/100\n","31/31 [==============================] - 1s 19ms/step - loss: 1.1155 - accuracy: 0.6718 - val_loss: 1.1959 - val_accuracy: 0.5826\n","Epoch 75/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.1121 - accuracy: 0.6742 - val_loss: 1.1896 - val_accuracy: 0.6085\n","Epoch 76/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.1018 - accuracy: 0.6755 - val_loss: 1.1836 - val_accuracy: 0.6136\n","Epoch 77/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0949 - accuracy: 0.6840 - val_loss: 1.1806 - val_accuracy: 0.5940\n","Epoch 78/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0939 - accuracy: 0.6832 - val_loss: 1.1800 - val_accuracy: 0.6116\n","Epoch 79/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0856 - accuracy: 0.6824 - val_loss: 1.1821 - val_accuracy: 0.5950\n","Epoch 80/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0791 - accuracy: 0.6819 - val_loss: 1.1729 - val_accuracy: 0.6064\n","Epoch 81/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0727 - accuracy: 0.6881 - val_loss: 1.1701 - val_accuracy: 0.6147\n","Epoch 82/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0670 - accuracy: 0.6783 - val_loss: 1.1718 - val_accuracy: 0.6074\n","Epoch 83/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0643 - accuracy: 0.6879 - val_loss: 1.1777 - val_accuracy: 0.5919\n","Epoch 84/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0545 - accuracy: 0.6922 - val_loss: 1.1600 - val_accuracy: 0.6178\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0428 - accuracy: 0.6982 - val_loss: 1.1734 - val_accuracy: 0.6012\n","Epoch 86/100\n","31/31 [==============================] - 1s 16ms/step - loss: 1.0437 - accuracy: 0.6974 - val_loss: 1.1672 - val_accuracy: 0.5930\n","Epoch 87/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0330 - accuracy: 0.7036 - val_loss: 1.1565 - val_accuracy: 0.6033\n","Epoch 88/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0294 - accuracy: 0.7039 - val_loss: 1.1609 - val_accuracy: 0.6043\n","Epoch 89/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0197 - accuracy: 0.7142 - val_loss: 1.1578 - val_accuracy: 0.6064\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0195 - accuracy: 0.7010 - val_loss: 1.1532 - val_accuracy: 0.6012\n","Epoch 91/100\n","31/31 [==============================] - 0s 16ms/step - loss: 1.0117 - accuracy: 0.7080 - val_loss: 1.1510 - val_accuracy: 0.6064\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0017 - accuracy: 0.7173 - val_loss: 1.1551 - val_accuracy: 0.6085\n","Epoch 93/100\n","31/31 [==============================] - 0s 15ms/step - loss: 1.0014 - accuracy: 0.7047 - val_loss: 1.1505 - val_accuracy: 0.6012\n","Epoch 94/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9923 - accuracy: 0.7129 - val_loss: 1.1475 - val_accuracy: 0.6054\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9848 - accuracy: 0.7214 - val_loss: 1.1480 - val_accuracy: 0.6064\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9793 - accuracy: 0.7238 - val_loss: 1.1473 - val_accuracy: 0.5992\n","Epoch 97/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9770 - accuracy: 0.7155 - val_loss: 1.1444 - val_accuracy: 0.6085\n","Epoch 98/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9712 - accuracy: 0.7165 - val_loss: 1.1471 - val_accuracy: 0.6116\n","Epoch 99/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9609 - accuracy: 0.7212 - val_loss: 1.1397 - val_accuracy: 0.6136\n","Epoch 100/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.9547 - accuracy: 0.7323 - val_loss: 1.1358 - val_accuracy: 0.6064\n","{'loss': [1.7014482021331787, 1.6894371509552002, 1.6772878170013428, 1.6651774644851685, 1.653194546699524, 1.6417871713638306, 1.6307625770568848, 1.6203720569610596, 1.6097341775894165, 1.5996348857879639, 1.5894156694412231, 1.5796904563903809, 1.569731593132019, 1.5597423315048218, 1.550077199935913, 1.5404961109161377, 1.530571460723877, 1.5201208591461182, 1.5106974840164185, 1.5004891157150269, 1.490886926651001, 1.4810255765914917, 1.470552682876587, 1.4617078304290771, 1.4528251886367798, 1.4434367418289185, 1.434934139251709, 1.4268600940704346, 1.4172027111053467, 1.4106647968292236, 1.4028137922286987, 1.3954578638076782, 1.3870878219604492, 1.380161166191101, 1.3734118938446045, 1.3641592264175415, 1.3589750528335571, 1.3497583866119385, 1.343336582183838, 1.336194396018982, 1.3309842348098755, 1.3230323791503906, 1.3150256872177124, 1.3088181018829346, 1.3024269342422485, 1.29708731174469, 1.2892005443572998, 1.282982587814331, 1.2777409553527832, 1.2678428888320923, 1.2645434141159058, 1.2570407390594482, 1.2511088848114014, 1.2431412935256958, 1.2392425537109375, 1.2316312789916992, 1.2242567539215088, 1.2177951335906982, 1.2129266262054443, 1.2071775197982788, 1.199546456336975, 1.1951733827590942, 1.186689019203186, 1.1834981441497803, 1.175866723060608, 1.1709270477294922, 1.1620161533355713, 1.1576483249664307, 1.148314118385315, 1.1423834562301636, 1.1351349353790283, 1.1303441524505615, 1.1259872913360596, 1.1154574155807495, 1.1120786666870117, 1.1017969846725464, 1.0948872566223145, 1.0939350128173828, 1.0856343507766724, 1.0790786743164062, 1.0726730823516846, 1.0669697523117065, 1.064343810081482, 1.0544853210449219, 1.0427968502044678, 1.0436561107635498, 1.0330232381820679, 1.029400110244751, 1.0196971893310547, 1.0194916725158691, 1.0116595029830933, 1.0016999244689941, 1.0013573169708252, 0.9923201203346252, 0.9847875833511353, 0.9793034195899963, 0.9770413041114807, 0.9712157845497131, 0.9608843922615051, 0.9547170400619507], 'accuracy': [0.5289405584335327, 0.5478036403656006, 0.566149890422821, 0.5586563348770142, 0.5674418807029724, 0.5664082765579224, 0.5731266140937805, 0.5713178515434265, 0.5718346238136292, 0.567958652973175, 0.5713178515434265, 0.5757105946540833, 0.5746769905090332, 0.576485812664032, 0.5821705460548401, 0.5829457640647888, 0.5901808738708496, 0.5881136655807495, 0.5863049030303955, 0.5865632891654968, 0.5922480821609497, 0.5971575975418091, 0.6015504002571106, 0.5966408252716064, 0.6033591628074646, 0.6108527183532715, 0.6085271239280701, 0.6108527183532715, 0.6126614809036255, 0.6129198670387268, 0.6090439558029175, 0.6144703030586243, 0.6139534711837769, 0.6152454614639282, 0.6134366989135742, 0.6196382641792297, 0.617054283618927, 0.6211886405944824, 0.6263566017150879, 0.6253229975700378, 0.6235142350196838, 0.6237726211547852, 0.6279069781303406, 0.620671808719635, 0.6286821961402893, 0.630232572555542, 0.6325581669807434, 0.6335917115211487, 0.6281653642654419, 0.6387596726417542, 0.6341085433959961, 0.6348837018013, 0.6426356434822083, 0.6379845142364502, 0.6354005336761475, 0.6387596726417542, 0.6418604850769043, 0.6467700004577637, 0.6392765045166016, 0.6467700004577637, 0.6441860198974609, 0.6459948420524597, 0.6529715657234192, 0.6472868323326111, 0.6545219421386719, 0.6545219421386719, 0.6568475365638733, 0.6602067351341248, 0.6633074879646301, 0.6658914685249329, 0.6614987254142761, 0.6695090532302856, 0.6627907156944275, 0.6718346476554871, 0.6741601824760437, 0.6754521727561951, 0.683979332447052, 0.6832041144371033, 0.6824289560317993, 0.6819121241569519, 0.6881136894226074, 0.6782945990562439, 0.6878553032875061, 0.6922480463981628, 0.698191225528717, 0.6974160075187683, 0.7036175727844238, 0.7038759589195251, 0.7142118811607361, 0.7010335922241211, 0.7080103158950806, 0.7173126339912415, 0.7046511769294739, 0.7129198908805847, 0.7214470505714417, 0.7237725853919983, 0.7155038714408875, 0.7165374755859375, 0.7211886048316956, 0.7322997450828552], 'val_loss': [1.6963950395584106, 1.685727834701538, 1.675201416015625, 1.6647918224334717, 1.6544901132583618, 1.6442320346832275, 1.6340975761413574, 1.6240748167037964, 1.6141208410263062, 1.60409677028656, 1.5942113399505615, 1.5843101739883423, 1.5743573904037476, 1.5650181770324707, 1.5549652576446533, 1.545351266860962, 1.5352152585983276, 1.5257108211517334, 1.515846848487854, 1.50596022605896, 1.496563196182251, 1.4868967533111572, 1.4774589538574219, 1.468223214149475, 1.4591234922409058, 1.4547853469848633, 1.4432611465454102, 1.438975214958191, 1.4269109964370728, 1.4241331815719604, 1.416473388671875, 1.4044665098190308, 1.4014033079147339, 1.3974355459213257, 1.3878775835037231, 1.3802698850631714, 1.3715828657150269, 1.3686182498931885, 1.3584413528442383, 1.3561960458755493, 1.3479859828948975, 1.3429601192474365, 1.3370981216430664, 1.3322935104370117, 1.323546051979065, 1.3188942670822144, 1.3156343698501587, 1.3053427934646606, 1.303645372390747, 1.2929778099060059, 1.2949501276016235, 1.2875754833221436, 1.2821637392044067, 1.2735068798065186, 1.2676637172698975, 1.2631891965866089, 1.259868860244751, 1.253099799156189, 1.2533915042877197, 1.244603157043457, 1.240570068359375, 1.2456560134887695, 1.233170747756958, 1.231893539428711, 1.224503755569458, 1.2198020219802856, 1.2149814367294312, 1.2134103775024414, 1.2082961797714233, 1.2042346000671387, 1.2022640705108643, 1.1965359449386597, 1.1907873153686523, 1.1959177255630493, 1.1896382570266724, 1.183551549911499, 1.180587649345398, 1.1800384521484375, 1.1821054220199585, 1.1729496717453003, 1.1700941324234009, 1.1717967987060547, 1.177662968635559, 1.160033941268921, 1.1734362840652466, 1.1671918630599976, 1.1565492153167725, 1.1609101295471191, 1.1578068733215332, 1.153207778930664, 1.150995135307312, 1.1551222801208496, 1.1505117416381836, 1.147521734237671, 1.1480110883712769, 1.147274136543274, 1.1444412469863892, 1.1471055746078491, 1.1397335529327393, 1.135825753211975], 'val_accuracy': [0.567148745059967, 0.53925621509552, 0.5371900796890259, 0.5402892827987671, 0.5413222908973694, 0.53925621509552, 0.53925621509552, 0.53925621509552, 0.5413222908973694, 0.53925621509552, 0.5423553586006165, 0.5495867729187012, 0.5599173307418823, 0.5495867729187012, 0.5702479481697083, 0.5681818127632141, 0.5650826692581177, 0.5712810158729553, 0.5692148804664612, 0.5878099203109741, 0.5919421315193176, 0.5878099203109741, 0.5929751992225647, 0.5909090638160706, 0.5888429880142212, 0.5991735458374023, 0.5836777091026306, 0.6074380278587341, 0.5826446413993835, 0.6002066135406494, 0.6033057570457458, 0.5805785059928894, 0.6002066135406494, 0.6064049601554871, 0.6022727489471436, 0.5971074104309082, 0.5878099203109741, 0.6043388247489929, 0.5909090638160706, 0.6064049601554871, 0.6043388247489929, 0.5971074104309082, 0.6043388247489929, 0.6064049601554871, 0.6012396812438965, 0.6095041036605835, 0.6095041036605835, 0.5960744023323059, 0.6064049601554871, 0.5929751992225647, 0.6074380278587341, 0.6126033067703247, 0.60537189245224, 0.5878099203109741, 0.5991735458374023, 0.5878099203109741, 0.6064049601554871, 0.5929751992225647, 0.60537189245224, 0.6012396812438965, 0.6002066135406494, 0.6002066135406494, 0.6064049601554871, 0.6064049601554871, 0.5981404781341553, 0.6043388247489929, 0.6022727489471436, 0.6012396812438965, 0.5960744023323059, 0.60537189245224, 0.5898760557174683, 0.60537189245224, 0.6229338645935059, 0.5826446413993835, 0.6084710955619812, 0.6136363744735718, 0.5940082669258118, 0.6115702390670776, 0.5950413346290588, 0.6064049601554871, 0.6146694421768188, 0.6074380278587341, 0.5919421315193176, 0.6177685856819153, 0.6012396812438965, 0.5929751992225647, 0.6033057570457458, 0.6043388247489929, 0.6064049601554871, 0.6012396812438965, 0.6064049601554871, 0.6084710955619812, 0.6012396812438965, 0.60537189245224, 0.6064049601554871, 0.5991735458374023, 0.6084710955619812, 0.6115702390670776, 0.6136363744735718, 0.6064049601554871]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 1.0443 - accuracy: 0.6638"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 8s 97ms/step - loss: 1.0444 - accuracy: 0.6627 - val_loss: 1.1384 - val_accuracy: 0.5172\n","Epoch 2/100\n","29/29 [==============================] - 1s 20ms/step - loss: 1.0315 - accuracy: 0.6821 - val_loss: 1.1389 - val_accuracy: 0.5162\n","Epoch 3/100\n","29/29 [==============================] - 1s 28ms/step - loss: 1.0169 - accuracy: 0.6910 - val_loss: 1.1322 - val_accuracy: 0.5183\n","Epoch 4/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0111 - accuracy: 0.6945 - val_loss: 1.1336 - val_accuracy: 0.5172\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 1.0022 - accuracy: 0.7020 - val_loss: 1.1322 - val_accuracy: 0.5183\n","Epoch 6/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.9999 - accuracy: 0.6985 - val_loss: 1.1283 - val_accuracy: 0.5183\n","Epoch 7/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.9949 - accuracy: 0.6953 - val_loss: 1.1286 - val_accuracy: 0.5205\n","Epoch 8/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.9867 - accuracy: 0.6910 - val_loss: 1.1191 - val_accuracy: 0.5259\n","Epoch 9/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9784 - accuracy: 0.7085 - val_loss: 1.1232 - val_accuracy: 0.5216\n","Epoch 10/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.9732 - accuracy: 0.7069 - val_loss: 1.1061 - val_accuracy: 0.5291\n","Epoch 11/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.9680 - accuracy: 0.7053 - val_loss: 1.0995 - val_accuracy: 0.5334\n","Epoch 12/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.9612 - accuracy: 0.7064 - val_loss: 1.1095 - val_accuracy: 0.5302\n","Epoch 13/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.9593 - accuracy: 0.7128 - val_loss: 1.0911 - val_accuracy: 0.5409\n","Epoch 14/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.9531 - accuracy: 0.7088 - val_loss: 1.0714 - val_accuracy: 0.5603\n","Epoch 15/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.9445 - accuracy: 0.7109 - val_loss: 1.0526 - val_accuracy: 0.5819\n","Epoch 16/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.9424 - accuracy: 0.7074 - val_loss: 1.0481 - val_accuracy: 0.5851\n","Epoch 17/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.9388 - accuracy: 0.7088 - val_loss: 1.0553 - val_accuracy: 0.5797\n","Epoch 18/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.9300 - accuracy: 0.7142 - val_loss: 1.0460 - val_accuracy: 0.5884\n","Epoch 19/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.9264 - accuracy: 0.7166 - val_loss: 1.0197 - val_accuracy: 0.6185\n","Epoch 20/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9154 - accuracy: 0.7258 - val_loss: 1.0266 - val_accuracy: 0.6164\n","Epoch 21/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.9124 - accuracy: 0.7239 - val_loss: 0.9983 - val_accuracy: 0.6444\n","Epoch 22/100\n","29/29 [==============================] - 1s 40ms/step - loss: 0.9092 - accuracy: 0.7260 - val_loss: 0.9889 - val_accuracy: 0.6476\n","Epoch 23/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.9058 - accuracy: 0.7233 - val_loss: 0.9906 - val_accuracy: 0.6466\n","Epoch 24/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.9000 - accuracy: 0.7274 - val_loss: 0.9866 - val_accuracy: 0.6433\n","Epoch 25/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8906 - accuracy: 0.7368 - val_loss: 0.9886 - val_accuracy: 0.6455\n","Epoch 26/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8885 - accuracy: 0.7322 - val_loss: 0.9858 - val_accuracy: 0.6466\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8877 - accuracy: 0.7338 - val_loss: 0.9927 - val_accuracy: 0.6444\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8818 - accuracy: 0.7271 - val_loss: 0.9993 - val_accuracy: 0.6444\n","Epoch 29/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8788 - accuracy: 0.7338 - val_loss: 0.9875 - val_accuracy: 0.6519\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8744 - accuracy: 0.7303 - val_loss: 0.9988 - val_accuracy: 0.6433\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8714 - accuracy: 0.7284 - val_loss: 0.9809 - val_accuracy: 0.6412\n","Epoch 32/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8603 - accuracy: 0.7411 - val_loss: 0.9847 - val_accuracy: 0.6444\n","Epoch 33/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8592 - accuracy: 0.7384 - val_loss: 0.9938 - val_accuracy: 0.6487\n","Epoch 34/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8550 - accuracy: 0.7346 - val_loss: 0.9865 - val_accuracy: 0.6422\n","Epoch 35/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8461 - accuracy: 0.7452 - val_loss: 0.9756 - val_accuracy: 0.6422\n","Epoch 36/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8427 - accuracy: 0.7457 - val_loss: 0.9780 - val_accuracy: 0.6444\n","Epoch 37/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8362 - accuracy: 0.7511 - val_loss: 0.9736 - val_accuracy: 0.6401\n","Epoch 38/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8329 - accuracy: 0.7470 - val_loss: 0.9986 - val_accuracy: 0.6498\n","Epoch 39/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8417 - accuracy: 0.7470 - val_loss: 0.9946 - val_accuracy: 0.6433\n","Epoch 40/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8286 - accuracy: 0.7495 - val_loss: 0.9703 - val_accuracy: 0.6498\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.8196 - accuracy: 0.7516 - val_loss: 0.9791 - val_accuracy: 0.6455\n","Epoch 42/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8193 - accuracy: 0.7495 - val_loss: 0.9728 - val_accuracy: 0.6466\n","Epoch 43/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.8200 - accuracy: 0.7524 - val_loss: 0.9693 - val_accuracy: 0.6616\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8212 - accuracy: 0.7500 - val_loss: 0.9771 - val_accuracy: 0.6595\n","Epoch 45/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.8098 - accuracy: 0.7637 - val_loss: 0.9661 - val_accuracy: 0.6606\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.8007 - accuracy: 0.7602 - val_loss: 0.9812 - val_accuracy: 0.6509\n","Epoch 47/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.7979 - accuracy: 0.7570 - val_loss: 0.9710 - val_accuracy: 0.6649\n","Epoch 48/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7951 - accuracy: 0.7594 - val_loss: 0.9697 - val_accuracy: 0.6573\n","Epoch 49/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7980 - accuracy: 0.7559 - val_loss: 0.9654 - val_accuracy: 0.6509\n","Epoch 50/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.8055 - accuracy: 0.7452 - val_loss: 0.9800 - val_accuracy: 0.6433\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.7916 - accuracy: 0.7570 - val_loss: 0.9794 - val_accuracy: 0.6390\n","Epoch 52/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7800 - accuracy: 0.7699 - val_loss: 0.9832 - val_accuracy: 0.6595\n","Epoch 53/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.7736 - accuracy: 0.7726 - val_loss: 0.9683 - val_accuracy: 0.6476\n","Epoch 54/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.7707 - accuracy: 0.7670 - val_loss: 0.9956 - val_accuracy: 0.6455\n","Epoch 55/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.7718 - accuracy: 0.7581 - val_loss: 0.9761 - val_accuracy: 0.6530\n","Epoch 56/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7635 - accuracy: 0.7654 - val_loss: 0.9672 - val_accuracy: 0.6562\n","Epoch 57/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7562 - accuracy: 0.7753 - val_loss: 0.9704 - val_accuracy: 0.6649\n","Epoch 58/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.7566 - accuracy: 0.7732 - val_loss: 0.9647 - val_accuracy: 0.6659\n","Epoch 59/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7547 - accuracy: 0.7777 - val_loss: 0.9660 - val_accuracy: 0.6541\n","Epoch 60/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7459 - accuracy: 0.7780 - val_loss: 0.9674 - val_accuracy: 0.6616\n","Epoch 61/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7317 - accuracy: 0.7936 - val_loss: 0.9726 - val_accuracy: 0.6573\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7461 - accuracy: 0.7767 - val_loss: 0.9872 - val_accuracy: 0.6466\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7408 - accuracy: 0.7713 - val_loss: 0.9775 - val_accuracy: 0.6562\n","Epoch 64/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.7353 - accuracy: 0.7753 - val_loss: 0.9675 - val_accuracy: 0.6724\n","Epoch 65/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7277 - accuracy: 0.7826 - val_loss: 0.9952 - val_accuracy: 0.6444\n","Epoch 66/100\n","29/29 [==============================] - 0s 13ms/step - loss: 0.7302 - accuracy: 0.7858 - val_loss: 0.9655 - val_accuracy: 0.6659\n","Epoch 67/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7325 - accuracy: 0.7796 - val_loss: 0.9838 - val_accuracy: 0.6412\n","Epoch 68/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7201 - accuracy: 0.7920 - val_loss: 0.9797 - val_accuracy: 0.6638\n","Epoch 69/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7204 - accuracy: 0.7853 - val_loss: 0.9775 - val_accuracy: 0.6412\n","Epoch 70/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7122 - accuracy: 0.7928 - val_loss: 0.9710 - val_accuracy: 0.6595\n","Epoch 71/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7183 - accuracy: 0.7872 - val_loss: 0.9742 - val_accuracy: 0.6692\n","Epoch 72/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.7041 - accuracy: 0.8004 - val_loss: 0.9737 - val_accuracy: 0.6616\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6977 - accuracy: 0.7990 - val_loss: 0.9709 - val_accuracy: 0.6649\n","Epoch 74/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6998 - accuracy: 0.7936 - val_loss: 0.9831 - val_accuracy: 0.6433\n","Epoch 75/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.7069 - accuracy: 0.7888 - val_loss: 0.9815 - val_accuracy: 0.6584\n","Epoch 76/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6956 - accuracy: 0.7945 - val_loss: 0.9827 - val_accuracy: 0.6541\n","Epoch 77/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6960 - accuracy: 0.7915 - val_loss: 0.9897 - val_accuracy: 0.6659\n","Epoch 78/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6925 - accuracy: 0.7928 - val_loss: 0.9777 - val_accuracy: 0.6692\n","Epoch 79/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6853 - accuracy: 0.8047 - val_loss: 0.9789 - val_accuracy: 0.6509\n","Epoch 80/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.6814 - accuracy: 0.8025 - val_loss: 0.9789 - val_accuracy: 0.6670\n","Epoch 81/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6776 - accuracy: 0.8033 - val_loss: 0.9992 - val_accuracy: 0.6649\n","Epoch 82/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.6796 - accuracy: 0.8033 - val_loss: 0.9876 - val_accuracy: 0.6627\n","Epoch 83/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.6701 - accuracy: 0.8015 - val_loss: 1.0161 - val_accuracy: 0.6487\n","Epoch 84/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.6677 - accuracy: 0.8090 - val_loss: 0.9950 - val_accuracy: 0.6455\n","Epoch 85/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.6575 - accuracy: 0.8168 - val_loss: 0.9925 - val_accuracy: 0.6530\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.6673 - accuracy: 0.7996 - val_loss: 0.9960 - val_accuracy: 0.6649\n","Epoch 87/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6587 - accuracy: 0.8171 - val_loss: 1.0072 - val_accuracy: 0.6358\n","Epoch 88/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6667 - accuracy: 0.8087 - val_loss: 1.0020 - val_accuracy: 0.6627\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6583 - accuracy: 0.8090 - val_loss: 0.9941 - val_accuracy: 0.6573\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6536 - accuracy: 0.8082 - val_loss: 0.9972 - val_accuracy: 0.6444\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6485 - accuracy: 0.8147 - val_loss: 0.9965 - val_accuracy: 0.6552\n","Epoch 92/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6472 - accuracy: 0.8138 - val_loss: 1.0288 - val_accuracy: 0.6519\n","Epoch 93/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6458 - accuracy: 0.8187 - val_loss: 1.0243 - val_accuracy: 0.6552\n","Epoch 94/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6445 - accuracy: 0.8165 - val_loss: 1.0144 - val_accuracy: 0.6638\n","Epoch 95/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6365 - accuracy: 0.8163 - val_loss: 1.0021 - val_accuracy: 0.6476\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6396 - accuracy: 0.8184 - val_loss: 0.9994 - val_accuracy: 0.6476\n","Epoch 97/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6355 - accuracy: 0.8179 - val_loss: 1.0027 - val_accuracy: 0.6476\n","Epoch 98/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6387 - accuracy: 0.8214 - val_loss: 1.0021 - val_accuracy: 0.6595\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6301 - accuracy: 0.8198 - val_loss: 1.0410 - val_accuracy: 0.6175\n","Epoch 100/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6228 - accuracy: 0.8227 - val_loss: 1.0655 - val_accuracy: 0.5981\n","{'loss': [1.0443631410598755, 1.0314902067184448, 1.0168633460998535, 1.0111479759216309, 1.0022194385528564, 0.9998974800109863, 0.9949257969856262, 0.9866950511932373, 0.97843998670578, 0.9732292294502258, 0.9680231809616089, 0.9612318873405457, 0.9592728614807129, 0.9530986547470093, 0.9445302486419678, 0.9423528909683228, 0.9388148784637451, 0.9300450682640076, 0.9263945817947388, 0.9153813719749451, 0.9124086499214172, 0.9092304706573486, 0.9058012366294861, 0.899954617023468, 0.8906497955322266, 0.8885368704795837, 0.8877294659614563, 0.8818091154098511, 0.8788345456123352, 0.8744373917579651, 0.871401309967041, 0.8603121638298035, 0.8592472672462463, 0.8550072908401489, 0.8460968732833862, 0.8427125215530396, 0.836165726184845, 0.8329482674598694, 0.8416720628738403, 0.8285580277442932, 0.8196216225624084, 0.8192903995513916, 0.8200036287307739, 0.8212066888809204, 0.8098435997962952, 0.8006872534751892, 0.7979442477226257, 0.7950891852378845, 0.7979564666748047, 0.805517852306366, 0.791623055934906, 0.780026376247406, 0.7735849618911743, 0.7707038521766663, 0.7717947959899902, 0.7634570598602295, 0.7562123537063599, 0.7565734386444092, 0.7546670436859131, 0.7458922863006592, 0.7317136526107788, 0.7460684776306152, 0.7408422827720642, 0.7353224754333496, 0.7277240753173828, 0.7301563620567322, 0.7325467467308044, 0.7201151251792908, 0.7203993797302246, 0.712246298789978, 0.7183297276496887, 0.7040607929229736, 0.6977226734161377, 0.6998286247253418, 0.706892728805542, 0.6956250667572021, 0.695978581905365, 0.692474901676178, 0.685329020023346, 0.6813598871231079, 0.6776074171066284, 0.679632842540741, 0.670072615146637, 0.6676511168479919, 0.6574651002883911, 0.6673297882080078, 0.6587042808532715, 0.6667073965072632, 0.6583468317985535, 0.653621256351471, 0.6484599709510803, 0.6472027897834778, 0.6458337903022766, 0.6444684863090515, 0.6364887356758118, 0.639566957950592, 0.6354919672012329, 0.6387001276016235, 0.6300532221794128, 0.6228229403495789], 'accuracy': [0.662715494632721, 0.6821120977401733, 0.6910021305084229, 0.6945043206214905, 0.7020474076271057, 0.6985452771186829, 0.6953125, 0.6910021305084229, 0.7085129022598267, 0.7068965435028076, 0.7052801847457886, 0.7063577771186829, 0.7128232717514038, 0.7087823152542114, 0.7109375, 0.7074353694915771, 0.7087823152542114, 0.7141702771186829, 0.7165948152542114, 0.7257543206214905, 0.7238685488700867, 0.7260237336158752, 0.7233297228813171, 0.7273706793785095, 0.7367995977401733, 0.7322198152542114, 0.7338362336158752, 0.7271012663841248, 0.7338362336158752, 0.7303340435028076, 0.7284482717514038, 0.7411099076271057, 0.7384159564971924, 0.7346444129943848, 0.7451508641242981, 0.7456896305084229, 0.7510775923728943, 0.7470366358757019, 0.7470366358757019, 0.7494612336158752, 0.751616358757019, 0.7494612336158752, 0.7524245977401733, 0.75, 0.7637392282485962, 0.7602370977401733, 0.7570043206214905, 0.759428858757019, 0.7559267282485962, 0.7451508641242981, 0.7570043206214905, 0.7699353694915771, 0.7726293206214905, 0.766972005367279, 0.7580819129943848, 0.7653555870056152, 0.7753232717514038, 0.7731680870056152, 0.7777478694915771, 0.7780172228813171, 0.7936422228813171, 0.7766702771186829, 0.7712823152542114, 0.7753232717514038, 0.782597005367279, 0.7858297228813171, 0.779633641242981, 0.7920258641242981, 0.7852909564971924, 0.7928340435028076, 0.7871767282485962, 0.8003771305084229, 0.7990301847457886, 0.7936422228813171, 0.7887930870056152, 0.7944504022598267, 0.7914870977401733, 0.7928340435028076, 0.8046875, 0.8025323152542114, 0.803340494632721, 0.803340494632721, 0.8014547228813171, 0.8089978694915771, 0.8168103694915771, 0.7995689511299133, 0.8170797228813171, 0.8087284564971924, 0.8089978694915771, 0.8081896305084229, 0.8146551847457886, 0.813847005367279, 0.818696141242981, 0.8165409564971924, 0.8162715435028076, 0.8184267282485962, 0.8178879022598267, 0.8213900923728943, 0.8197737336158752, 0.8227370977401733], 'val_loss': [1.1384315490722656, 1.138939380645752, 1.1321771144866943, 1.133643388748169, 1.1321958303451538, 1.1283096075057983, 1.1286062002182007, 1.1191151142120361, 1.1232123374938965, 1.1060700416564941, 1.0994895696640015, 1.1094642877578735, 1.091102957725525, 1.0714105367660522, 1.0526046752929688, 1.0481146574020386, 1.0552656650543213, 1.0459859371185303, 1.0197395086288452, 1.026605486869812, 0.9983397126197815, 0.988937497138977, 0.9906007051467896, 0.9865753054618835, 0.9886038303375244, 0.9858107566833496, 0.9927323460578918, 0.9993110299110413, 0.9874688982963562, 0.9987936615943909, 0.9809063076972961, 0.984709620475769, 0.9938063025474548, 0.9865336418151855, 0.9756337404251099, 0.9779590368270874, 0.9735967516899109, 0.9985947608947754, 0.9945532083511353, 0.9702678918838501, 0.979095995426178, 0.9728227257728577, 0.9692643284797668, 0.977095901966095, 0.9661131501197815, 0.9812384843826294, 0.9710277915000916, 0.969663679599762, 0.9653926491737366, 0.9800334572792053, 0.9794361591339111, 0.9832004904747009, 0.9683067798614502, 0.995588481426239, 0.9760870337486267, 0.9671726226806641, 0.9704087376594543, 0.9647224545478821, 0.9660449624061584, 0.9674434065818787, 0.9726342558860779, 0.9872359037399292, 0.9774596095085144, 0.9675164818763733, 0.9952314496040344, 0.9655061364173889, 0.9837532639503479, 0.9796885848045349, 0.9775492548942566, 0.9710240364074707, 0.9741547703742981, 0.9737286567687988, 0.9708526730537415, 0.9831416606903076, 0.9814943075180054, 0.9827253222465515, 0.9896762371063232, 0.9776636958122253, 0.9789462685585022, 0.9789214134216309, 0.999177873134613, 0.9875925183296204, 1.0161092281341553, 0.9949640035629272, 0.992544412612915, 0.9960441589355469, 1.0071769952774048, 1.0020415782928467, 0.9940879344940186, 0.9971839785575867, 0.9965171813964844, 1.0287925004959106, 1.024324655532837, 1.0143859386444092, 1.0020657777786255, 0.9993879199028015, 1.0027276277542114, 1.0020544528961182, 1.0410312414169312, 1.065462350845337], 'val_accuracy': [0.517241358757019, 0.5161637663841248, 0.5183189511299133, 0.517241358757019, 0.5183189511299133, 0.5183189511299133, 0.5204741358757019, 0.5258620977401733, 0.5215517282485962, 0.5290948152542114, 0.5334051847457886, 0.5301724076271057, 0.5409482717514038, 0.5603448152542114, 0.5818965435028076, 0.5851293206214905, 0.579741358757019, 0.5883620977401733, 0.618534505367279, 0.6163793206214905, 0.6443965435028076, 0.6476293206214905, 0.6465517282485962, 0.6433189511299133, 0.6454741358757019, 0.6465517282485962, 0.6443965435028076, 0.6443965435028076, 0.6519396305084229, 0.6433189511299133, 0.6411637663841248, 0.6443965435028076, 0.6487069129943848, 0.642241358757019, 0.642241358757019, 0.6443965435028076, 0.6400862336158752, 0.649784505367279, 0.6433189511299133, 0.649784505367279, 0.6454741358757019, 0.6465517282485962, 0.6616379022598267, 0.6594827771186829, 0.6605603694915771, 0.6508620977401733, 0.6648706793785095, 0.6573275923728943, 0.6508620977401733, 0.6433189511299133, 0.639008641242981, 0.6594827771186829, 0.6476293206214905, 0.6454741358757019, 0.6530172228813171, 0.65625, 0.6648706793785095, 0.6659482717514038, 0.6540948152542114, 0.6616379022598267, 0.6573275923728943, 0.6465517282485962, 0.65625, 0.6724137663841248, 0.6443965435028076, 0.6659482717514038, 0.6411637663841248, 0.6637930870056152, 0.6411637663841248, 0.6594827771186829, 0.6691810488700867, 0.6616379022598267, 0.6648706793785095, 0.6433189511299133, 0.6584051847457886, 0.6540948152542114, 0.6659482717514038, 0.6691810488700867, 0.6508620977401733, 0.6670258641242981, 0.6648706793785095, 0.662715494632721, 0.6487069129943848, 0.6454741358757019, 0.6530172228813171, 0.6648706793785095, 0.6357758641242981, 0.662715494632721, 0.6573275923728943, 0.6443965435028076, 0.6551724076271057, 0.6519396305084229, 0.6551724076271057, 0.6637930870056152, 0.6476293206214905, 0.6476293206214905, 0.6476293206214905, 0.6594827771186829, 0.6174569129943848, 0.5980603694915771]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/28 [==========================>...] - ETA: 0s - loss: 1.0524 - accuracy: 0.6541"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 57ms/step - loss: 1.0498 - accuracy: 0.6596 - val_loss: 1.1426 - val_accuracy: 0.5045\n","Epoch 2/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0307 - accuracy: 0.6808 - val_loss: 1.1430 - val_accuracy: 0.5045\n","Epoch 3/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0212 - accuracy: 0.6851 - val_loss: 1.1457 - val_accuracy: 0.5045\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 1.0187 - accuracy: 0.6870 - val_loss: 1.1400 - val_accuracy: 0.5057\n","Epoch 5/100\n","28/28 [==============================] - 0s 15ms/step - loss: 1.0115 - accuracy: 0.6836 - val_loss: 1.1363 - val_accuracy: 0.5057\n","Epoch 6/100\n","28/28 [==============================] - 0s 14ms/step - loss: 1.0061 - accuracy: 0.6859 - val_loss: 1.1391 - val_accuracy: 0.5057\n","Epoch 7/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9992 - accuracy: 0.6851 - val_loss: 1.1396 - val_accuracy: 0.5057\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9959 - accuracy: 0.6975 - val_loss: 1.1275 - val_accuracy: 0.5057\n","Epoch 9/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9867 - accuracy: 0.6873 - val_loss: 1.1257 - val_accuracy: 0.5057\n","Epoch 10/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9821 - accuracy: 0.7032 - val_loss: 1.1130 - val_accuracy: 0.5124\n","Epoch 11/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9868 - accuracy: 0.6851 - val_loss: 1.1032 - val_accuracy: 0.5204\n","Epoch 12/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9738 - accuracy: 0.6944 - val_loss: 1.1122 - val_accuracy: 0.5147\n","Epoch 13/100\n","28/28 [==============================] - 1s 39ms/step - loss: 0.9717 - accuracy: 0.6935 - val_loss: 1.1064 - val_accuracy: 0.5249\n","Epoch 14/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.9625 - accuracy: 0.7054 - val_loss: 1.0823 - val_accuracy: 0.5554\n","Epoch 15/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.9561 - accuracy: 0.7043 - val_loss: 1.0832 - val_accuracy: 0.5566\n","Epoch 16/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.9495 - accuracy: 0.7142 - val_loss: 1.0729 - val_accuracy: 0.5656\n","Epoch 17/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.9441 - accuracy: 0.7145 - val_loss: 1.0510 - val_accuracy: 0.5905\n","Epoch 18/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9445 - accuracy: 0.7071 - val_loss: 1.0503 - val_accuracy: 0.5905\n","Epoch 19/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.9329 - accuracy: 0.7207 - val_loss: 1.0356 - val_accuracy: 0.6041\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9318 - accuracy: 0.7108 - val_loss: 1.0437 - val_accuracy: 0.5950\n","Epoch 21/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9256 - accuracy: 0.7119 - val_loss: 1.0220 - val_accuracy: 0.6199\n","Epoch 22/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.9240 - accuracy: 0.7128 - val_loss: 1.0242 - val_accuracy: 0.6176\n","Epoch 23/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.9143 - accuracy: 0.7187 - val_loss: 1.0012 - val_accuracy: 0.6425\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9197 - accuracy: 0.7097 - val_loss: 1.0244 - val_accuracy: 0.6165\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9080 - accuracy: 0.7207 - val_loss: 1.0009 - val_accuracy: 0.6414\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9047 - accuracy: 0.7162 - val_loss: 1.0124 - val_accuracy: 0.6380\n","Epoch 27/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.8997 - accuracy: 0.7286 - val_loss: 1.0012 - val_accuracy: 0.6482\n","Epoch 28/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.8950 - accuracy: 0.7264 - val_loss: 0.9938 - val_accuracy: 0.6538\n","Epoch 29/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.8935 - accuracy: 0.7221 - val_loss: 0.9936 - val_accuracy: 0.6550\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8925 - accuracy: 0.7244 - val_loss: 0.9961 - val_accuracy: 0.6527\n","Epoch 31/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8843 - accuracy: 0.7272 - val_loss: 0.9953 - val_accuracy: 0.6493\n","Epoch 32/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8755 - accuracy: 0.7309 - val_loss: 1.0054 - val_accuracy: 0.6335\n","Epoch 33/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8698 - accuracy: 0.7306 - val_loss: 0.9949 - val_accuracy: 0.6584\n","Epoch 34/100\n","28/28 [==============================] - 1s 27ms/step - loss: 0.8744 - accuracy: 0.7281 - val_loss: 0.9967 - val_accuracy: 0.6595\n","Epoch 35/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8660 - accuracy: 0.7309 - val_loss: 0.9925 - val_accuracy: 0.6561\n","Epoch 36/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8626 - accuracy: 0.7332 - val_loss: 0.9890 - val_accuracy: 0.6550\n","Epoch 37/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8494 - accuracy: 0.7411 - val_loss: 0.9876 - val_accuracy: 0.6527\n","Epoch 38/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8547 - accuracy: 0.7405 - val_loss: 0.9900 - val_accuracy: 0.6550\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8575 - accuracy: 0.7315 - val_loss: 0.9917 - val_accuracy: 0.6516\n","Epoch 40/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8412 - accuracy: 0.7419 - val_loss: 0.9922 - val_accuracy: 0.6527\n","Epoch 41/100\n","28/28 [==============================] - 1s 32ms/step - loss: 0.8366 - accuracy: 0.7402 - val_loss: 0.9926 - val_accuracy: 0.6629\n","Epoch 42/100\n","28/28 [==============================] - 1s 29ms/step - loss: 0.8336 - accuracy: 0.7450 - val_loss: 0.9886 - val_accuracy: 0.6640\n","Epoch 43/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.8302 - accuracy: 0.7428 - val_loss: 0.9880 - val_accuracy: 0.6674\n","Epoch 44/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8259 - accuracy: 0.7388 - val_loss: 0.9960 - val_accuracy: 0.6618\n","Epoch 45/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8248 - accuracy: 0.7507 - val_loss: 0.9870 - val_accuracy: 0.6584\n","Epoch 46/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8146 - accuracy: 0.7555 - val_loss: 0.9884 - val_accuracy: 0.6595\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8185 - accuracy: 0.7453 - val_loss: 0.9862 - val_accuracy: 0.6652\n","Epoch 48/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8109 - accuracy: 0.7501 - val_loss: 0.9818 - val_accuracy: 0.6697\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8100 - accuracy: 0.7561 - val_loss: 0.9934 - val_accuracy: 0.6414\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.8045 - accuracy: 0.7598 - val_loss: 0.9779 - val_accuracy: 0.6674\n","Epoch 51/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7955 - accuracy: 0.7615 - val_loss: 0.9868 - val_accuracy: 0.6629\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7987 - accuracy: 0.7482 - val_loss: 0.9831 - val_accuracy: 0.6640\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7939 - accuracy: 0.7583 - val_loss: 0.9849 - val_accuracy: 0.6584\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7910 - accuracy: 0.7561 - val_loss: 0.9792 - val_accuracy: 0.6697\n","Epoch 55/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7929 - accuracy: 0.7448 - val_loss: 0.9747 - val_accuracy: 0.6629\n","Epoch 56/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7771 - accuracy: 0.7620 - val_loss: 0.9836 - val_accuracy: 0.6516\n","Epoch 57/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7768 - accuracy: 0.7592 - val_loss: 0.9756 - val_accuracy: 0.6584\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7701 - accuracy: 0.7739 - val_loss: 0.9887 - val_accuracy: 0.6652\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7672 - accuracy: 0.7680 - val_loss: 0.9819 - val_accuracy: 0.6652\n","Epoch 60/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7705 - accuracy: 0.7640 - val_loss: 0.9759 - val_accuracy: 0.6674\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7568 - accuracy: 0.7666 - val_loss: 0.9814 - val_accuracy: 0.6697\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7591 - accuracy: 0.7708 - val_loss: 0.9800 - val_accuracy: 0.6686\n","Epoch 63/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.7558 - accuracy: 0.7626 - val_loss: 0.9910 - val_accuracy: 0.6369\n","Epoch 64/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7592 - accuracy: 0.7685 - val_loss: 0.9943 - val_accuracy: 0.6663\n","Epoch 65/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7535 - accuracy: 0.7688 - val_loss: 0.9834 - val_accuracy: 0.6538\n","Epoch 66/100\n","28/28 [==============================] - 1s 33ms/step - loss: 0.7481 - accuracy: 0.7649 - val_loss: 0.9868 - val_accuracy: 0.6708\n","Epoch 67/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7408 - accuracy: 0.7753 - val_loss: 0.9875 - val_accuracy: 0.6708\n","Epoch 68/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7444 - accuracy: 0.7702 - val_loss: 0.9925 - val_accuracy: 0.6505\n","Epoch 69/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7373 - accuracy: 0.7782 - val_loss: 0.9892 - val_accuracy: 0.6561\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7377 - accuracy: 0.7767 - val_loss: 0.9814 - val_accuracy: 0.6538\n","Epoch 71/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.7304 - accuracy: 0.7787 - val_loss: 1.0061 - val_accuracy: 0.6493\n","Epoch 72/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7266 - accuracy: 0.7813 - val_loss: 1.0133 - val_accuracy: 0.6063\n","Epoch 73/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7202 - accuracy: 0.7866 - val_loss: 0.9829 - val_accuracy: 0.6640\n","Epoch 74/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7215 - accuracy: 0.7821 - val_loss: 0.9793 - val_accuracy: 0.6686\n","Epoch 75/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7169 - accuracy: 0.7855 - val_loss: 0.9926 - val_accuracy: 0.6731\n","Epoch 76/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7125 - accuracy: 0.7869 - val_loss: 0.9907 - val_accuracy: 0.6380\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7077 - accuracy: 0.7923 - val_loss: 0.9823 - val_accuracy: 0.6686\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7007 - accuracy: 0.7909 - val_loss: 0.9982 - val_accuracy: 0.6561\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7029 - accuracy: 0.7906 - val_loss: 0.9969 - val_accuracy: 0.6640\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6985 - accuracy: 0.7917 - val_loss: 0.9951 - val_accuracy: 0.6448\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6964 - accuracy: 0.7960 - val_loss: 0.9992 - val_accuracy: 0.6391\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7019 - accuracy: 0.7793 - val_loss: 1.0155 - val_accuracy: 0.6493\n","Epoch 83/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7003 - accuracy: 0.7875 - val_loss: 0.9897 - val_accuracy: 0.6640\n","Epoch 84/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6898 - accuracy: 0.7977 - val_loss: 0.9932 - val_accuracy: 0.6505\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6804 - accuracy: 0.7954 - val_loss: 1.0118 - val_accuracy: 0.6527\n","Epoch 86/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6777 - accuracy: 0.7980 - val_loss: 1.0032 - val_accuracy: 0.6561\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6762 - accuracy: 0.8042 - val_loss: 0.9932 - val_accuracy: 0.6459\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6712 - accuracy: 0.8005 - val_loss: 0.9968 - val_accuracy: 0.6629\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6647 - accuracy: 0.7999 - val_loss: 1.0019 - val_accuracy: 0.6437\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6682 - accuracy: 0.8053 - val_loss: 1.0268 - val_accuracy: 0.6210\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6630 - accuracy: 0.8011 - val_loss: 0.9878 - val_accuracy: 0.6595\n","Epoch 92/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6595 - accuracy: 0.8104 - val_loss: 0.9956 - val_accuracy: 0.6482\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6668 - accuracy: 0.8045 - val_loss: 1.0101 - val_accuracy: 0.6357\n","Epoch 94/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6643 - accuracy: 0.8022 - val_loss: 1.0185 - val_accuracy: 0.6267\n","Epoch 95/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6622 - accuracy: 0.8025 - val_loss: 1.0112 - val_accuracy: 0.6437\n","Epoch 96/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6532 - accuracy: 0.8098 - val_loss: 1.0109 - val_accuracy: 0.6595\n","Epoch 97/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6560 - accuracy: 0.8084 - val_loss: 1.0256 - val_accuracy: 0.6595\n","Epoch 98/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6597 - accuracy: 0.8011 - val_loss: 0.9936 - val_accuracy: 0.6516\n","Epoch 99/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6436 - accuracy: 0.8084 - val_loss: 1.0132 - val_accuracy: 0.6663\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.6361 - accuracy: 0.8147 - val_loss: 1.0416 - val_accuracy: 0.6584\n","{'loss': [1.049826741218567, 1.0307235717773438, 1.0211683511734009, 1.0187362432479858, 1.0114554166793823, 1.0061198472976685, 0.9992307424545288, 0.9958704710006714, 0.9866943955421448, 0.9820735454559326, 0.9868195652961731, 0.9737593531608582, 0.9717350006103516, 0.9624588489532471, 0.9560682773590088, 0.9495159387588501, 0.9440979361534119, 0.9444945454597473, 0.9328895211219788, 0.9318286180496216, 0.9255969524383545, 0.9240192174911499, 0.9142871499061584, 0.9197456240653992, 0.90799880027771, 0.9046509265899658, 0.8996692299842834, 0.8950223922729492, 0.8934502601623535, 0.8924518823623657, 0.88428795337677, 0.8754773736000061, 0.8697702288627625, 0.8744286298751831, 0.8660181760787964, 0.8626474142074585, 0.8493923544883728, 0.8547384738922119, 0.857524037361145, 0.8412036299705505, 0.836590588092804, 0.8335703611373901, 0.8302285671234131, 0.8259391188621521, 0.8247843384742737, 0.8146247863769531, 0.8184987902641296, 0.8109303116798401, 0.8099574446678162, 0.8044536709785461, 0.7955265045166016, 0.7987358570098877, 0.7939265370368958, 0.7910059094429016, 0.7928986549377441, 0.7770882248878479, 0.776839554309845, 0.7701175808906555, 0.7672093510627747, 0.7705219984054565, 0.7567949891090393, 0.7590819597244263, 0.755780816078186, 0.7592414617538452, 0.7534766793251038, 0.7480559349060059, 0.7407642006874084, 0.74439537525177, 0.7372578382492065, 0.7377405166625977, 0.7303618788719177, 0.7266483902931213, 0.7202282547950745, 0.721476674079895, 0.7168604731559753, 0.7124572396278381, 0.7077264189720154, 0.700741708278656, 0.7029290795326233, 0.6985369920730591, 0.6964313983917236, 0.7019014358520508, 0.7002676725387573, 0.6898496150970459, 0.6804056763648987, 0.6776713132858276, 0.676152765750885, 0.6712355613708496, 0.6646889448165894, 0.6681591868400574, 0.6630237102508545, 0.6595093011856079, 0.666815459728241, 0.6643362641334534, 0.6621741652488708, 0.6532347798347473, 0.6559785008430481, 0.6597051620483398, 0.6436473727226257, 0.6360523700714111], 'accuracy': [0.6595925092697144, 0.6808149218559265, 0.6850594282150269, 0.6870402097702026, 0.6836445927619934, 0.685908317565918, 0.6850594282150269, 0.6975098848342896, 0.6873231530189514, 0.7031692266464233, 0.6850594282150269, 0.6943972706794739, 0.6935483813285828, 0.7054329514503479, 0.7043010592460632, 0.7142048478126526, 0.7144878506660461, 0.7071307301521301, 0.7207130789756775, 0.7108092904090881, 0.711941123008728, 0.7127900123596191, 0.7187322974205017, 0.7096773982048035, 0.7207130789756775, 0.7161856293678284, 0.7286360859870911, 0.7263723611831665, 0.7221279144287109, 0.7243916392326355, 0.7272212505340576, 0.7308998107910156, 0.7306168675422668, 0.7280701994895935, 0.7308998107910156, 0.7331635355949402, 0.7410866022109985, 0.7405206561088562, 0.731465756893158, 0.7419354915618896, 0.7402377128601074, 0.7450481057167053, 0.7427843809127808, 0.738822877407074, 0.7507073879241943, 0.755517840385437, 0.7453310489654541, 0.7501415014266968, 0.7560837864875793, 0.7597622871398926, 0.7614601254463196, 0.748160719871521, 0.7583475112915039, 0.7560837864875793, 0.7447651624679565, 0.7620260119438171, 0.759196400642395, 0.7739105820655823, 0.7679682970046997, 0.7640067934989929, 0.7665534615516663, 0.7707979679107666, 0.7625919580459595, 0.768534243106842, 0.7688171863555908, 0.764855682849884, 0.7753254175186157, 0.7702320218086243, 0.7781550884246826, 0.7767402529716492, 0.7787209749221802, 0.7812677025794983, 0.7866440415382385, 0.7821165919303894, 0.7855121493339539, 0.7869269847869873, 0.7923033237457275, 0.7908884882926941, 0.7906055450439453, 0.79173743724823, 0.7959818840026855, 0.7792869210243225, 0.7874929308891296, 0.7976796627044678, 0.7954159379005432, 0.7979626655578613, 0.8041878938674927, 0.8005093336105347, 0.7999433875083923, 0.8053197264671326, 0.801075279712677, 0.810413122177124, 0.8044708371162415, 0.8022071123123169, 0.8024901151657104, 0.8098471760749817, 0.808432400226593, 0.801075279712677, 0.808432400226593, 0.8146576285362244], 'val_loss': [1.1425601243972778, 1.143014669418335, 1.1456762552261353, 1.140048861503601, 1.1363379955291748, 1.139088749885559, 1.1396335363388062, 1.1275347471237183, 1.1256904602050781, 1.113014578819275, 1.1032294034957886, 1.1122055053710938, 1.106410026550293, 1.0822542905807495, 1.0832295417785645, 1.0728703737258911, 1.0509675741195679, 1.0502852201461792, 1.0356241464614868, 1.0437077283859253, 1.0220311880111694, 1.024160623550415, 1.0011507272720337, 1.0244181156158447, 1.0008717775344849, 1.0123631954193115, 1.001236081123352, 0.9937865734100342, 0.9935934543609619, 0.9961028099060059, 0.9952595829963684, 1.0054051876068115, 0.9949274659156799, 0.996730387210846, 0.9924649596214294, 0.9890161752700806, 0.9875862002372742, 0.9899683594703674, 0.9916760921478271, 0.9922342300415039, 0.9926244020462036, 0.9886029362678528, 0.9880409836769104, 0.9959692358970642, 0.9870095252990723, 0.9883996844291687, 0.9861624240875244, 0.9817788004875183, 0.9933881163597107, 0.9778897166252136, 0.9868394136428833, 0.9830811023712158, 0.9849273562431335, 0.979169487953186, 0.9746999740600586, 0.9836412668228149, 0.9756317138671875, 0.9887294769287109, 0.981930136680603, 0.9758867025375366, 0.9813819527626038, 0.980013906955719, 0.9910321235656738, 0.9942987561225891, 0.9834398031234741, 0.9868307709693909, 0.987510621547699, 0.9924694895744324, 0.9892284274101257, 0.9814175963401794, 1.0061404705047607, 1.0133305788040161, 0.9828941226005554, 0.9793384671211243, 0.9925804734230042, 0.9907432794570923, 0.9823055863380432, 0.9982379078865051, 0.996922492980957, 0.9950648546218872, 0.9992363452911377, 1.015476942062378, 0.9896613359451294, 0.9931958913803101, 1.0117647647857666, 1.0032408237457275, 0.9931979179382324, 0.996757984161377, 1.0018752813339233, 1.026770830154419, 0.9877874255180359, 0.9956225752830505, 1.0100535154342651, 1.0184516906738281, 1.0111706256866455, 1.0108782052993774, 1.0255515575408936, 0.9936463832855225, 1.0131555795669556, 1.041582703590393], 'val_accuracy': [0.5045248866081238, 0.5045248866081238, 0.5045248866081238, 0.5056561231613159, 0.5056561231613159, 0.5056561231613159, 0.5056561231613159, 0.5056561231613159, 0.5056561231613159, 0.5124434232711792, 0.5203620195388794, 0.5147058963775635, 0.5248869061470032, 0.5554298758506775, 0.5565611124038696, 0.5656108856201172, 0.5904977321624756, 0.5904977321624756, 0.6040723919868469, 0.5950226187705994, 0.6199095249176025, 0.6176470518112183, 0.6425339579582214, 0.6165158152580261, 0.6414027214050293, 0.6380090713500977, 0.6481900215148926, 0.6538461446762085, 0.6549773812294006, 0.6527149081230164, 0.6493212580680847, 0.6334841847419739, 0.6583710312843323, 0.6595022678375244, 0.6561086177825928, 0.6549773812294006, 0.6527149081230164, 0.6549773812294006, 0.651583731174469, 0.6527149081230164, 0.662895917892456, 0.6640271544456482, 0.6674208045005798, 0.6617646813392639, 0.6583710312843323, 0.6595022678375244, 0.6651583909988403, 0.6696832776069641, 0.6414027214050293, 0.6674208045005798, 0.662895917892456, 0.6640271544456482, 0.6583710312843323, 0.6696832776069641, 0.662895917892456, 0.651583731174469, 0.6583710312843323, 0.6651583909988403, 0.6651583909988403, 0.6674208045005798, 0.6696832776069641, 0.668552041053772, 0.6368778347969055, 0.6662895679473877, 0.6538461446762085, 0.6708144545555115, 0.6708144545555115, 0.6504524946212769, 0.6561086177825928, 0.6538461446762085, 0.6493212580680847, 0.6063348650932312, 0.6640271544456482, 0.668552041053772, 0.6730769276618958, 0.6380090713500977, 0.668552041053772, 0.6561086177825928, 0.6640271544456482, 0.6447963714599609, 0.639140248298645, 0.6493212580680847, 0.6640271544456482, 0.6504524946212769, 0.6527149081230164, 0.6561086177825928, 0.6459276080131531, 0.662895917892456, 0.6436651349067688, 0.6210407018661499, 0.6595022678375244, 0.6481900215148926, 0.6357465982437134, 0.6266968250274658, 0.6436651349067688, 0.6595022678375244, 0.6595022678375244, 0.651583731174469, 0.6662895679473877, 0.6583710312843323]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/31 [===========================>..] - ETA: 0s - loss: 1.0565 - accuracy: 0.6530"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 7s 66ms/step - loss: 1.0573 - accuracy: 0.6548 - val_loss: 1.1412 - val_accuracy: 0.5145\n","Epoch 2/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0321 - accuracy: 0.6767 - val_loss: 1.1363 - val_accuracy: 0.5145\n","Epoch 3/100\n","31/31 [==============================] - 1s 21ms/step - loss: 1.0232 - accuracy: 0.6850 - val_loss: 1.1395 - val_accuracy: 0.5145\n","Epoch 4/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0217 - accuracy: 0.6752 - val_loss: 1.1275 - val_accuracy: 0.5145\n","Epoch 5/100\n","31/31 [==============================] - 1s 18ms/step - loss: 1.0119 - accuracy: 0.6886 - val_loss: 1.1269 - val_accuracy: 0.5145\n","Epoch 6/100\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0078 - accuracy: 0.6809 - val_loss: 1.1171 - val_accuracy: 0.5238\n","Epoch 7/100\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0006 - accuracy: 0.6930 - val_loss: 1.1114 - val_accuracy: 0.5269\n","Epoch 8/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9932 - accuracy: 0.6953 - val_loss: 1.1047 - val_accuracy: 0.5300\n","Epoch 9/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9853 - accuracy: 0.6930 - val_loss: 1.0924 - val_accuracy: 0.5403\n","Epoch 10/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9769 - accuracy: 0.6979 - val_loss: 1.0960 - val_accuracy: 0.5393\n","Epoch 11/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9772 - accuracy: 0.6946 - val_loss: 1.0813 - val_accuracy: 0.5496\n","Epoch 12/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9692 - accuracy: 0.6951 - val_loss: 1.0757 - val_accuracy: 0.5506\n","Epoch 13/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.9636 - accuracy: 0.6992 - val_loss: 1.0779 - val_accuracy: 0.5506\n","Epoch 14/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9591 - accuracy: 0.7000 - val_loss: 1.0584 - val_accuracy: 0.5764\n","Epoch 15/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9506 - accuracy: 0.7088 - val_loss: 1.0548 - val_accuracy: 0.5785\n","Epoch 16/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.9421 - accuracy: 0.7127 - val_loss: 1.0651 - val_accuracy: 0.5723\n","Epoch 17/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9467 - accuracy: 0.6964 - val_loss: 1.0383 - val_accuracy: 0.5940\n","Epoch 18/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.9331 - accuracy: 0.7119 - val_loss: 1.0222 - val_accuracy: 0.6116\n","Epoch 19/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9264 - accuracy: 0.7189 - val_loss: 1.0151 - val_accuracy: 0.6291\n","Epoch 20/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.9198 - accuracy: 0.7165 - val_loss: 1.0058 - val_accuracy: 0.6457\n","Epoch 21/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9192 - accuracy: 0.7158 - val_loss: 1.0064 - val_accuracy: 0.6529\n","Epoch 22/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9128 - accuracy: 0.7220 - val_loss: 1.0063 - val_accuracy: 0.6395\n","Epoch 23/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.9074 - accuracy: 0.7256 - val_loss: 1.0051 - val_accuracy: 0.6426\n","Epoch 24/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.9040 - accuracy: 0.7212 - val_loss: 1.0017 - val_accuracy: 0.6488\n","Epoch 25/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8977 - accuracy: 0.7251 - val_loss: 0.9956 - val_accuracy: 0.6436\n","Epoch 26/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8925 - accuracy: 0.7230 - val_loss: 0.9955 - val_accuracy: 0.6519\n","Epoch 27/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8881 - accuracy: 0.7310 - val_loss: 0.9987 - val_accuracy: 0.6395\n","Epoch 28/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.8846 - accuracy: 0.7238 - val_loss: 1.0054 - val_accuracy: 0.6446\n","Epoch 29/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8773 - accuracy: 0.7282 - val_loss: 1.0083 - val_accuracy: 0.6446\n","Epoch 30/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8832 - accuracy: 0.7227 - val_loss: 1.0023 - val_accuracy: 0.6446\n","Epoch 31/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8653 - accuracy: 0.7411 - val_loss: 1.0026 - val_accuracy: 0.6312\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8658 - accuracy: 0.7388 - val_loss: 0.9962 - val_accuracy: 0.6467\n","Epoch 33/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8545 - accuracy: 0.7390 - val_loss: 0.9971 - val_accuracy: 0.6488\n","Epoch 34/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.8517 - accuracy: 0.7390 - val_loss: 0.9981 - val_accuracy: 0.6446\n","Epoch 35/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8561 - accuracy: 0.7367 - val_loss: 1.0018 - val_accuracy: 0.6446\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8506 - accuracy: 0.7375 - val_loss: 0.9957 - val_accuracy: 0.6415\n","Epoch 37/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8405 - accuracy: 0.7372 - val_loss: 1.0104 - val_accuracy: 0.6240\n","Epoch 38/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8273 - accuracy: 0.7540 - val_loss: 0.9941 - val_accuracy: 0.6488\n","Epoch 39/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8301 - accuracy: 0.7517 - val_loss: 1.0065 - val_accuracy: 0.6343\n","Epoch 40/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.8277 - accuracy: 0.7537 - val_loss: 1.0009 - val_accuracy: 0.6405\n","Epoch 41/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8242 - accuracy: 0.7530 - val_loss: 1.0063 - val_accuracy: 0.6395\n","Epoch 42/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8221 - accuracy: 0.7463 - val_loss: 1.0139 - val_accuracy: 0.6405\n","Epoch 43/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8218 - accuracy: 0.7460 - val_loss: 1.0024 - val_accuracy: 0.6384\n","Epoch 44/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.8160 - accuracy: 0.7527 - val_loss: 1.0110 - val_accuracy: 0.6229\n","Epoch 45/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.8057 - accuracy: 0.7514 - val_loss: 1.0049 - val_accuracy: 0.6281\n","Epoch 46/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7987 - accuracy: 0.7587 - val_loss: 1.0012 - val_accuracy: 0.6405\n","Epoch 47/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7993 - accuracy: 0.7512 - val_loss: 1.0000 - val_accuracy: 0.6333\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7916 - accuracy: 0.7610 - val_loss: 1.0015 - val_accuracy: 0.6322\n","Epoch 49/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.8020 - accuracy: 0.7558 - val_loss: 1.0181 - val_accuracy: 0.6219\n","Epoch 50/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7831 - accuracy: 0.7711 - val_loss: 1.0062 - val_accuracy: 0.6229\n","Epoch 51/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7874 - accuracy: 0.7636 - val_loss: 1.0072 - val_accuracy: 0.6374\n","Epoch 52/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7864 - accuracy: 0.7654 - val_loss: 1.0022 - val_accuracy: 0.6322\n","Epoch 53/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.7859 - accuracy: 0.7581 - val_loss: 1.0018 - val_accuracy: 0.6333\n","Epoch 54/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7727 - accuracy: 0.7752 - val_loss: 1.0031 - val_accuracy: 0.6364\n","Epoch 55/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.7726 - accuracy: 0.7682 - val_loss: 1.0033 - val_accuracy: 0.6271\n","Epoch 56/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.7611 - accuracy: 0.7739 - val_loss: 1.0139 - val_accuracy: 0.6240\n","Epoch 57/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7626 - accuracy: 0.7744 - val_loss: 1.0143 - val_accuracy: 0.6395\n","Epoch 58/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7531 - accuracy: 0.7757 - val_loss: 1.0141 - val_accuracy: 0.6302\n","Epoch 59/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.7571 - accuracy: 0.7682 - val_loss: 1.0274 - val_accuracy: 0.6343\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7693 - accuracy: 0.7625 - val_loss: 1.0028 - val_accuracy: 0.6281\n","Epoch 61/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7433 - accuracy: 0.7804 - val_loss: 1.0176 - val_accuracy: 0.6147\n","Epoch 62/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7389 - accuracy: 0.7798 - val_loss: 1.0052 - val_accuracy: 0.6219\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7344 - accuracy: 0.7780 - val_loss: 1.0161 - val_accuracy: 0.6281\n","Epoch 64/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7371 - accuracy: 0.7765 - val_loss: 1.0145 - val_accuracy: 0.6250\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7331 - accuracy: 0.7822 - val_loss: 1.0276 - val_accuracy: 0.6302\n","Epoch 66/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7263 - accuracy: 0.7853 - val_loss: 1.0255 - val_accuracy: 0.6271\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7276 - accuracy: 0.7804 - val_loss: 1.0202 - val_accuracy: 0.6167\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7226 - accuracy: 0.7806 - val_loss: 1.0149 - val_accuracy: 0.6271\n","Epoch 69/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7205 - accuracy: 0.7767 - val_loss: 1.0163 - val_accuracy: 0.6229\n","Epoch 70/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7139 - accuracy: 0.7891 - val_loss: 1.0209 - val_accuracy: 0.6188\n","Epoch 71/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7106 - accuracy: 0.7897 - val_loss: 1.0195 - val_accuracy: 0.6291\n","Epoch 72/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7097 - accuracy: 0.7897 - val_loss: 1.0225 - val_accuracy: 0.6343\n","Epoch 73/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7067 - accuracy: 0.7884 - val_loss: 1.0459 - val_accuracy: 0.6415\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.7133 - accuracy: 0.7827 - val_loss: 1.0245 - val_accuracy: 0.6250\n","Epoch 75/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.7010 - accuracy: 0.7884 - val_loss: 1.0437 - val_accuracy: 0.6271\n","Epoch 76/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6975 - accuracy: 0.7912 - val_loss: 1.0435 - val_accuracy: 0.6209\n","Epoch 77/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.7007 - accuracy: 0.7961 - val_loss: 1.0423 - val_accuracy: 0.6188\n","Epoch 78/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6909 - accuracy: 0.7946 - val_loss: 1.0327 - val_accuracy: 0.6198\n","Epoch 79/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6917 - accuracy: 0.7933 - val_loss: 1.0263 - val_accuracy: 0.6240\n","Epoch 80/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6870 - accuracy: 0.7933 - val_loss: 1.0371 - val_accuracy: 0.6271\n","Epoch 81/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6845 - accuracy: 0.8003 - val_loss: 1.0270 - val_accuracy: 0.6312\n","Epoch 82/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6797 - accuracy: 0.8023 - val_loss: 1.0334 - val_accuracy: 0.6229\n","Epoch 83/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6948 - accuracy: 0.7866 - val_loss: 1.0312 - val_accuracy: 0.6229\n","Epoch 84/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6826 - accuracy: 0.7956 - val_loss: 1.0469 - val_accuracy: 0.6116\n","Epoch 85/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6744 - accuracy: 0.8049 - val_loss: 1.0512 - val_accuracy: 0.6302\n","Epoch 86/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6694 - accuracy: 0.8026 - val_loss: 1.0390 - val_accuracy: 0.6250\n","Epoch 87/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6732 - accuracy: 0.7951 - val_loss: 1.0378 - val_accuracy: 0.6229\n","Epoch 88/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6624 - accuracy: 0.8026 - val_loss: 1.0472 - val_accuracy: 0.6219\n","Epoch 89/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6602 - accuracy: 0.8090 - val_loss: 1.0488 - val_accuracy: 0.6188\n","Epoch 90/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6620 - accuracy: 0.8044 - val_loss: 1.0394 - val_accuracy: 0.6271\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6640 - accuracy: 0.8034 - val_loss: 1.0920 - val_accuracy: 0.6012\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6633 - accuracy: 0.8005 - val_loss: 1.0339 - val_accuracy: 0.6209\n","Epoch 93/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6649 - accuracy: 0.7982 - val_loss: 1.0810 - val_accuracy: 0.6064\n","Epoch 94/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6556 - accuracy: 0.8067 - val_loss: 1.0725 - val_accuracy: 0.6054\n","Epoch 95/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6424 - accuracy: 0.8127 - val_loss: 1.0558 - val_accuracy: 0.6353\n","Epoch 96/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6465 - accuracy: 0.8106 - val_loss: 1.0418 - val_accuracy: 0.6250\n","Epoch 97/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6421 - accuracy: 0.8116 - val_loss: 1.0582 - val_accuracy: 0.6250\n","Epoch 98/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6362 - accuracy: 0.8140 - val_loss: 1.0745 - val_accuracy: 0.6064\n","Epoch 99/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6470 - accuracy: 0.8075 - val_loss: 1.0621 - val_accuracy: 0.6198\n","Epoch 100/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6340 - accuracy: 0.8171 - val_loss: 1.0530 - val_accuracy: 0.6240\n","{'loss': [1.0573220252990723, 1.0320754051208496, 1.0232374668121338, 1.0216525793075562, 1.0118945837020874, 1.0077935457229614, 1.0006496906280518, 0.9931723475456238, 0.9852654337882996, 0.9769337773323059, 0.9772425889968872, 0.969229519367218, 0.9635571241378784, 0.9591407179832458, 0.9506285786628723, 0.94211345911026, 0.9466530084609985, 0.9330894947052002, 0.9263870120048523, 0.9197646379470825, 0.9192394614219666, 0.9127618670463562, 0.9074433445930481, 0.9039790630340576, 0.8976545929908752, 0.892460286617279, 0.8881482481956482, 0.884647011756897, 0.8772587776184082, 0.8831512331962585, 0.8653319478034973, 0.8657506108283997, 0.8544644117355347, 0.8516538143157959, 0.8561434149742126, 0.8505967855453491, 0.8404736518859863, 0.8273279070854187, 0.8301330208778381, 0.8276932835578918, 0.8241910338401794, 0.8220504522323608, 0.8218371868133545, 0.8160406351089478, 0.8057005405426025, 0.7986850738525391, 0.7993318438529968, 0.7915700078010559, 0.8019574880599976, 0.7831358313560486, 0.7873623371124268, 0.7864135503768921, 0.785929262638092, 0.7726706862449646, 0.7725570201873779, 0.7610987424850464, 0.7625821828842163, 0.7531483769416809, 0.757129967212677, 0.7692805528640747, 0.7433088421821594, 0.7388597726821899, 0.734449565410614, 0.7371418476104736, 0.7330612540245056, 0.7262933254241943, 0.7275656461715698, 0.722646176815033, 0.7204855680465698, 0.7139399647712708, 0.7106068730354309, 0.7096583843231201, 0.7066944241523743, 0.7132676839828491, 0.7009907364845276, 0.6975278258323669, 0.7006964683532715, 0.690887987613678, 0.6917243003845215, 0.6869892477989197, 0.6845332980155945, 0.67970871925354, 0.6948332786560059, 0.6825762987136841, 0.6743557453155518, 0.669383704662323, 0.6731838583946228, 0.6624165177345276, 0.6602058410644531, 0.6619619727134705, 0.6640061140060425, 0.6632734537124634, 0.6648631691932678, 0.6555701494216919, 0.6423611044883728, 0.6464940905570984, 0.6421478986740112, 0.6362247467041016, 0.646971583366394, 0.6339653134346008], 'accuracy': [0.654780387878418, 0.6767441630363464, 0.685012936592102, 0.6751937866210938, 0.6886304616928101, 0.6808785796165466, 0.6930232644081116, 0.695348858833313, 0.6930232644081116, 0.6979328393936157, 0.6945736408233643, 0.6950904130935669, 0.6992248296737671, 0.699999988079071, 0.7087855339050293, 0.7126615047454834, 0.6963824033737183, 0.7118862867355347, 0.7188630700111389, 0.7165374755859375, 0.7157622575759888, 0.7219638228416443, 0.7255814075469971, 0.7211886048316956, 0.7250645756721497, 0.7229974269866943, 0.7310077548027039, 0.7237725853919983, 0.7281653881072998, 0.722739040851593, 0.7410852909088135, 0.7387596964836121, 0.7390180826187134, 0.7390180826187134, 0.736692488193512, 0.7374677062034607, 0.7372093200683594, 0.7540051937103271, 0.7516795992851257, 0.753746747970581, 0.7529715895652771, 0.746253252029419, 0.7459948062896729, 0.7527132034301758, 0.7514212131500244, 0.7586563229560852, 0.7511627674102783, 0.7609819173812866, 0.7558139562606812, 0.7710594534873962, 0.7635658979415894, 0.7653746604919434, 0.7581395506858826, 0.7751938104629517, 0.7682170271873474, 0.7739018201828003, 0.7744185924530029, 0.7757105827331543, 0.7682170271873474, 0.7625322937965393, 0.7803617715835571, 0.7798449397087097, 0.7780361771583557, 0.776485800743103, 0.7821705341339111, 0.7852713465690613, 0.7803617715835571, 0.7806201577186584, 0.7767441868782043, 0.7891472578048706, 0.789664089679718, 0.789664089679718, 0.7883720993995667, 0.7826873660087585, 0.7883720993995667, 0.7912144660949707, 0.7961240410804749, 0.7945736646652222, 0.7932816743850708, 0.7932816743850708, 0.8002583980560303, 0.8023256063461304, 0.7865633368492126, 0.7956072092056274, 0.8049095869064331, 0.8025839924812317, 0.7950904369354248, 0.8025839924812317, 0.8090439438819885, 0.8043927550315857, 0.8033591508865356, 0.8005167841911316, 0.7981911897659302, 0.8067183494567871, 0.8126614689826965, 0.8105943202972412, 0.8116279244422913, 0.8139534592628479, 0.8074935674667358, 0.817054271697998], 'val_loss': [1.1412384510040283, 1.136250615119934, 1.139534831047058, 1.127502202987671, 1.1268864870071411, 1.1171226501464844, 1.1114331483840942, 1.104653239250183, 1.0923537015914917, 1.0959676504135132, 1.0812515020370483, 1.0756827592849731, 1.077876091003418, 1.058445930480957, 1.0548391342163086, 1.0651322603225708, 1.038336992263794, 1.0222104787826538, 1.0150550603866577, 1.0057501792907715, 1.0064059495925903, 1.0062782764434814, 1.0050581693649292, 1.0016950368881226, 0.9956327080726624, 0.9955418109893799, 0.9986640810966492, 1.005378007888794, 1.0083047151565552, 1.0023491382598877, 1.0025556087493896, 0.9962225556373596, 0.997147262096405, 0.9980732202529907, 1.001841425895691, 0.995725154876709, 1.0104161500930786, 0.9941421747207642, 1.0065430402755737, 1.000892162322998, 1.0062646865844727, 1.0139474868774414, 1.002415418624878, 1.0110162496566772, 1.0048878192901611, 1.0012236833572388, 0.9999701380729675, 1.0014500617980957, 1.0180954933166504, 1.0062448978424072, 1.0072054862976074, 1.0022401809692383, 1.0018293857574463, 1.003103494644165, 1.003272294998169, 1.0138521194458008, 1.0142830610275269, 1.0140513181686401, 1.0274436473846436, 1.0027589797973633, 1.0175968408584595, 1.0051734447479248, 1.0160669088363647, 1.0144577026367188, 1.0275907516479492, 1.0255038738250732, 1.0202281475067139, 1.0149264335632324, 1.0163346529006958, 1.0208886861801147, 1.019459843635559, 1.0225257873535156, 1.0459153652191162, 1.0244861841201782, 1.0437264442443848, 1.0434659719467163, 1.0422542095184326, 1.0326581001281738, 1.0263499021530151, 1.0370590686798096, 1.0269596576690674, 1.033375859260559, 1.031227946281433, 1.046931505203247, 1.0511797666549683, 1.0389841794967651, 1.037757396697998, 1.0471739768981934, 1.0488300323486328, 1.039413332939148, 1.0920207500457764, 1.0339359045028687, 1.080987811088562, 1.0724951028823853, 1.0558136701583862, 1.0418014526367188, 1.0581691265106201, 1.0744576454162598, 1.0621472597122192, 1.0529794692993164], 'val_accuracy': [0.5144628286361694, 0.5144628286361694, 0.5144628286361694, 0.5144628286361694, 0.5144628286361694, 0.5237603187561035, 0.5268595218658447, 0.5299586653709412, 0.5402892827987671, 0.53925621509552, 0.5495867729187012, 0.5506198406219482, 0.5506198406219482, 0.5764462947845459, 0.5785123705863953, 0.5723140239715576, 0.5940082669258118, 0.6115702390670776, 0.6291322112083435, 0.6456611752510071, 0.6528925895690918, 0.6394628286361694, 0.6425619721412659, 0.6487603187561035, 0.6435950398445129, 0.6518595218658447, 0.6394628286361694, 0.64462810754776, 0.64462810754776, 0.64462810754776, 0.6311983466148376, 0.6466942429542542, 0.6487603187561035, 0.64462810754776, 0.64462810754776, 0.6415289044380188, 0.6239669322967529, 0.6487603187561035, 0.6342975497245789, 0.6404958963394165, 0.6394628286361694, 0.6404958963394165, 0.6384297609329224, 0.6229338645935059, 0.6280992031097412, 0.6404958963394165, 0.6332644820213318, 0.6322314143180847, 0.6219007968902588, 0.6229338645935059, 0.6373966932296753, 0.6322314143180847, 0.6332644820213318, 0.6363636255264282, 0.6270661354064941, 0.6239669322967529, 0.6394628286361694, 0.6301652789115906, 0.6342975497245789, 0.6280992031097412, 0.6146694421768188, 0.6219007968902588, 0.6280992031097412, 0.625, 0.6301652789115906, 0.6270661354064941, 0.6167355179786682, 0.6270661354064941, 0.6229338645935059, 0.6188016533851624, 0.6291322112083435, 0.6342975497245789, 0.6415289044380188, 0.625, 0.6270661354064941, 0.6208677887916565, 0.6188016533851624, 0.6198347210884094, 0.6239669322967529, 0.6270661354064941, 0.6311983466148376, 0.6229338645935059, 0.6229338645935059, 0.6115702390670776, 0.6301652789115906, 0.625, 0.6229338645935059, 0.6219007968902588, 0.6188016533851624, 0.6270661354064941, 0.6012396812438965, 0.6208677887916565, 0.6064049601554871, 0.60537189245224, 0.6353305578231812, 0.625, 0.625, 0.6064049601554871, 0.6198347210884094, 0.6239669322967529]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","26/29 [=========================>....] - ETA: 0s - loss: 0.6954 - accuracy: 0.7785"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 6s 54ms/step - loss: 0.6908 - accuracy: 0.7802 - val_loss: 1.0218 - val_accuracy: 0.5162\n","Epoch 2/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6782 - accuracy: 0.7934 - val_loss: 0.9965 - val_accuracy: 0.5172\n","Epoch 3/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6814 - accuracy: 0.7853 - val_loss: 0.9608 - val_accuracy: 0.5194\n","Epoch 4/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6720 - accuracy: 0.7931 - val_loss: 0.9446 - val_accuracy: 0.5248\n","Epoch 5/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6666 - accuracy: 0.7907 - val_loss: 0.9486 - val_accuracy: 0.5248\n","Epoch 6/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.6558 - accuracy: 0.8020 - val_loss: 0.9456 - val_accuracy: 0.5269\n","Epoch 7/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6631 - accuracy: 0.7953 - val_loss: 0.9138 - val_accuracy: 0.5453\n","Epoch 8/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.6619 - accuracy: 0.8017 - val_loss: 0.9037 - val_accuracy: 0.5539\n","Epoch 9/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.6581 - accuracy: 0.8017 - val_loss: 0.8974 - val_accuracy: 0.5625\n","Epoch 10/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.6510 - accuracy: 0.7977 - val_loss: 0.8900 - val_accuracy: 0.5711\n","Epoch 11/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.6438 - accuracy: 0.8052 - val_loss: 0.8677 - val_accuracy: 0.6185\n","Epoch 12/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6416 - accuracy: 0.8074 - val_loss: 0.8934 - val_accuracy: 0.5733\n","Epoch 13/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6425 - accuracy: 0.8079 - val_loss: 0.8784 - val_accuracy: 0.5948\n","Epoch 14/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6340 - accuracy: 0.8085 - val_loss: 0.8516 - val_accuracy: 0.6358\n","Epoch 15/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.6349 - accuracy: 0.8103 - val_loss: 0.8415 - val_accuracy: 0.6498\n","Epoch 16/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6281 - accuracy: 0.8093 - val_loss: 0.8243 - val_accuracy: 0.6735\n","Epoch 17/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6273 - accuracy: 0.8103 - val_loss: 0.8690 - val_accuracy: 0.6315\n","Epoch 18/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.6301 - accuracy: 0.8095 - val_loss: 0.8240 - val_accuracy: 0.6875\n","Epoch 19/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6198 - accuracy: 0.8200 - val_loss: 0.8218 - val_accuracy: 0.6864\n","Epoch 20/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.6183 - accuracy: 0.8125 - val_loss: 0.7988 - val_accuracy: 0.7188\n","Epoch 21/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6158 - accuracy: 0.8112 - val_loss: 0.8075 - val_accuracy: 0.7080\n","Epoch 22/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.6022 - accuracy: 0.8217 - val_loss: 0.8250 - val_accuracy: 0.6789\n","Epoch 23/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6100 - accuracy: 0.8176 - val_loss: 0.8397 - val_accuracy: 0.6843\n","Epoch 24/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5971 - accuracy: 0.8268 - val_loss: 0.8088 - val_accuracy: 0.7155\n","Epoch 25/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5998 - accuracy: 0.8254 - val_loss: 0.8518 - val_accuracy: 0.6789\n","Epoch 26/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6063 - accuracy: 0.8203 - val_loss: 0.8363 - val_accuracy: 0.6994\n","Epoch 27/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.6022 - accuracy: 0.8254 - val_loss: 0.8332 - val_accuracy: 0.7037\n","Epoch 28/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5949 - accuracy: 0.8308 - val_loss: 0.8318 - val_accuracy: 0.7101\n","Epoch 29/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5976 - accuracy: 0.8238 - val_loss: 0.8663 - val_accuracy: 0.6659\n","Epoch 30/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5974 - accuracy: 0.8182 - val_loss: 0.8300 - val_accuracy: 0.7091\n","Epoch 31/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5817 - accuracy: 0.8341 - val_loss: 0.8751 - val_accuracy: 0.6994\n","Epoch 32/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5765 - accuracy: 0.8362 - val_loss: 0.8821 - val_accuracy: 0.6746\n","Epoch 33/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5954 - accuracy: 0.8157 - val_loss: 0.8542 - val_accuracy: 0.6929\n","Epoch 34/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5921 - accuracy: 0.8206 - val_loss: 0.8808 - val_accuracy: 0.6713\n","Epoch 35/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5828 - accuracy: 0.8324 - val_loss: 0.8964 - val_accuracy: 0.6627\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5924 - accuracy: 0.8246 - val_loss: 0.8487 - val_accuracy: 0.7037\n","Epoch 37/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5702 - accuracy: 0.8370 - val_loss: 0.8603 - val_accuracy: 0.6940\n","Epoch 38/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5708 - accuracy: 0.8367 - val_loss: 0.8597 - val_accuracy: 0.7101\n","Epoch 39/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5696 - accuracy: 0.8402 - val_loss: 0.8965 - val_accuracy: 0.6994\n","Epoch 40/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5683 - accuracy: 0.8421 - val_loss: 0.9027 - val_accuracy: 0.6649\n","Epoch 41/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5666 - accuracy: 0.8335 - val_loss: 0.8996 - val_accuracy: 0.6659\n","Epoch 42/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5690 - accuracy: 0.8289 - val_loss: 0.8831 - val_accuracy: 0.6950\n","Epoch 43/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5542 - accuracy: 0.8446 - val_loss: 0.8885 - val_accuracy: 0.7058\n","Epoch 44/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5568 - accuracy: 0.8402 - val_loss: 0.8596 - val_accuracy: 0.7015\n","Epoch 45/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5559 - accuracy: 0.8435 - val_loss: 0.8743 - val_accuracy: 0.6961\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5531 - accuracy: 0.8424 - val_loss: 0.8720 - val_accuracy: 0.7004\n","Epoch 47/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5477 - accuracy: 0.8451 - val_loss: 0.9074 - val_accuracy: 0.6972\n","Epoch 48/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5499 - accuracy: 0.8473 - val_loss: 0.8794 - val_accuracy: 0.6983\n","Epoch 49/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5487 - accuracy: 0.8462 - val_loss: 0.8997 - val_accuracy: 0.6789\n","Epoch 50/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5413 - accuracy: 0.8456 - val_loss: 0.8870 - val_accuracy: 0.7004\n","Epoch 51/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5415 - accuracy: 0.8521 - val_loss: 0.9022 - val_accuracy: 0.6994\n","Epoch 52/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5346 - accuracy: 0.8553 - val_loss: 0.9149 - val_accuracy: 0.6627\n","Epoch 53/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5360 - accuracy: 0.8508 - val_loss: 0.8858 - val_accuracy: 0.6961\n","Epoch 54/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5337 - accuracy: 0.8491 - val_loss: 0.8890 - val_accuracy: 0.7080\n","Epoch 55/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5368 - accuracy: 0.8524 - val_loss: 0.9097 - val_accuracy: 0.6778\n","Epoch 56/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5423 - accuracy: 0.8424 - val_loss: 0.8883 - val_accuracy: 0.6940\n","Epoch 57/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5292 - accuracy: 0.8588 - val_loss: 0.9103 - val_accuracy: 0.6918\n","Epoch 58/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5257 - accuracy: 0.8532 - val_loss: 0.8934 - val_accuracy: 0.7015\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5292 - accuracy: 0.8521 - val_loss: 0.8923 - val_accuracy: 0.6950\n","Epoch 60/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5234 - accuracy: 0.8607 - val_loss: 0.9061 - val_accuracy: 0.6961\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5283 - accuracy: 0.8526 - val_loss: 0.9026 - val_accuracy: 0.6886\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.5101 - accuracy: 0.8594 - val_loss: 0.9141 - val_accuracy: 0.6994\n","Epoch 63/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.5172 - accuracy: 0.8567 - val_loss: 0.9071 - val_accuracy: 0.6940\n","Epoch 64/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5120 - accuracy: 0.8623 - val_loss: 0.9111 - val_accuracy: 0.6886\n","Epoch 65/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5103 - accuracy: 0.8610 - val_loss: 0.9181 - val_accuracy: 0.6875\n","Epoch 66/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.5117 - accuracy: 0.8605 - val_loss: 0.9129 - val_accuracy: 0.6940\n","Epoch 67/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.5121 - accuracy: 0.8583 - val_loss: 0.9148 - val_accuracy: 0.6821\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.5126 - accuracy: 0.8586 - val_loss: 0.9367 - val_accuracy: 0.7015\n","Epoch 69/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.5055 - accuracy: 0.8637 - val_loss: 0.9262 - val_accuracy: 0.6950\n","Epoch 70/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5000 - accuracy: 0.8688 - val_loss: 0.9510 - val_accuracy: 0.6918\n","Epoch 71/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4936 - accuracy: 0.8680 - val_loss: 0.9329 - val_accuracy: 0.6907\n","Epoch 72/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.5015 - accuracy: 0.8683 - val_loss: 0.9327 - val_accuracy: 0.6983\n","Epoch 73/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.4990 - accuracy: 0.8650 - val_loss: 0.9453 - val_accuracy: 0.6961\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4967 - accuracy: 0.8707 - val_loss: 0.9729 - val_accuracy: 0.6616\n","Epoch 75/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4942 - accuracy: 0.8683 - val_loss: 0.9427 - val_accuracy: 0.6907\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4840 - accuracy: 0.8728 - val_loss: 0.9416 - val_accuracy: 0.6875\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4808 - accuracy: 0.8755 - val_loss: 0.9444 - val_accuracy: 0.6843\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4913 - accuracy: 0.8666 - val_loss: 0.9612 - val_accuracy: 0.6735\n","Epoch 79/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4849 - accuracy: 0.8753 - val_loss: 0.9528 - val_accuracy: 0.6897\n","Epoch 80/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4789 - accuracy: 0.8672 - val_loss: 0.9439 - val_accuracy: 0.6950\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4800 - accuracy: 0.8728 - val_loss: 0.9526 - val_accuracy: 0.6918\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4869 - accuracy: 0.8650 - val_loss: 0.9270 - val_accuracy: 0.6983\n","Epoch 83/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4877 - accuracy: 0.8675 - val_loss: 0.9526 - val_accuracy: 0.6897\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4721 - accuracy: 0.8796 - val_loss: 0.9403 - val_accuracy: 0.6918\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4837 - accuracy: 0.8699 - val_loss: 0.9517 - val_accuracy: 0.6907\n","Epoch 86/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4638 - accuracy: 0.8798 - val_loss: 0.9822 - val_accuracy: 0.7004\n","Epoch 87/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4816 - accuracy: 0.8715 - val_loss: 0.9539 - val_accuracy: 0.6929\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4890 - accuracy: 0.8685 - val_loss: 0.9699 - val_accuracy: 0.6918\n","Epoch 89/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4857 - accuracy: 0.8731 - val_loss: 0.9683 - val_accuracy: 0.6800\n","Epoch 90/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4633 - accuracy: 0.8796 - val_loss: 0.9745 - val_accuracy: 0.6972\n","Epoch 91/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4677 - accuracy: 0.8731 - val_loss: 0.9488 - val_accuracy: 0.6961\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4644 - accuracy: 0.8780 - val_loss: 0.9681 - val_accuracy: 0.7004\n","Epoch 93/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4570 - accuracy: 0.8855 - val_loss: 0.9577 - val_accuracy: 0.6972\n","Epoch 94/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4595 - accuracy: 0.8785 - val_loss: 0.9784 - val_accuracy: 0.6961\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4525 - accuracy: 0.8898 - val_loss: 0.9687 - val_accuracy: 0.6983\n","Epoch 96/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4518 - accuracy: 0.8828 - val_loss: 0.9720 - val_accuracy: 0.6961\n","Epoch 97/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4520 - accuracy: 0.8874 - val_loss: 0.9764 - val_accuracy: 0.6875\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4493 - accuracy: 0.8850 - val_loss: 0.9961 - val_accuracy: 0.6810\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4440 - accuracy: 0.8895 - val_loss: 0.9848 - val_accuracy: 0.6950\n","Epoch 100/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4419 - accuracy: 0.8933 - val_loss: 0.9813 - val_accuracy: 0.7004\n","{'loss': [0.6908481121063232, 0.678182065486908, 0.6813657879829407, 0.6720241904258728, 0.6665538549423218, 0.6557714343070984, 0.6631178259849548, 0.6618601083755493, 0.6580736637115479, 0.6509969234466553, 0.643782913684845, 0.6416499018669128, 0.6424975991249084, 0.6339669823646545, 0.6349390149116516, 0.6281483769416809, 0.6273135542869568, 0.630057156085968, 0.6198295950889587, 0.6183329224586487, 0.6157909035682678, 0.6021838188171387, 0.6100046038627625, 0.5970780849456787, 0.5997681021690369, 0.6062710285186768, 0.6022433638572693, 0.5949234962463379, 0.5976423025131226, 0.5973960161209106, 0.5817466378211975, 0.5765442252159119, 0.5954492092132568, 0.5921355485916138, 0.5828312635421753, 0.5924314260482788, 0.5702401399612427, 0.5708410739898682, 0.569628894329071, 0.5682670474052429, 0.5666200518608093, 0.5690346360206604, 0.5542057156562805, 0.5567541718482971, 0.5559453368186951, 0.5531035661697388, 0.5476892590522766, 0.5499168634414673, 0.5486834049224854, 0.5412936210632324, 0.541520893573761, 0.5345884561538696, 0.5360069274902344, 0.5337285399436951, 0.5368126034736633, 0.5422589778900146, 0.5292185544967651, 0.5257296562194824, 0.5292198657989502, 0.5234253406524658, 0.5282752513885498, 0.5101085305213928, 0.5172012448310852, 0.5119665861129761, 0.5102971792221069, 0.5117312073707581, 0.5120904445648193, 0.5126054883003235, 0.5054510831832886, 0.4999959170818329, 0.49358272552490234, 0.5014793872833252, 0.4990069568157196, 0.4966854155063629, 0.4941914975643158, 0.48403769731521606, 0.4808366298675537, 0.4913075268268585, 0.4849017560482025, 0.47890394926071167, 0.4799700379371643, 0.4868764579296112, 0.4877198040485382, 0.47212305665016174, 0.4836634695529938, 0.463763028383255, 0.48155906796455383, 0.48896223306655884, 0.48573145270347595, 0.4632743299007416, 0.4676598608493805, 0.46437907218933105, 0.45697885751724243, 0.4595131576061249, 0.4524615406990051, 0.4517558217048645, 0.45201683044433594, 0.4493449628353119, 0.4440240263938904, 0.44190356135368347], 'accuracy': [0.7801724076271057, 0.7933728694915771, 0.7852909564971924, 0.7931034564971924, 0.790678858757019, 0.8019935488700867, 0.795258641242981, 0.8017241358757019, 0.8017241358757019, 0.7976831793785095, 0.8052262663841248, 0.8073814511299133, 0.8079202771186829, 0.8084590435028076, 0.8103448152542114, 0.8092672228813171, 0.8103448152542114, 0.8095366358757019, 0.8200430870056152, 0.8125, 0.811152994632721, 0.821659505367279, 0.8176185488700867, 0.826777994632721, 0.8254310488700867, 0.8203125, 0.8254310488700867, 0.8308189511299133, 0.8238146305084229, 0.8181573152542114, 0.8340517282485962, 0.8362069129943848, 0.8157327771186829, 0.8205819129943848, 0.8324353694915771, 0.8246228694915771, 0.8370150923728943, 0.8367456793785095, 0.8402478694915771, 0.842133641242981, 0.8335129022598267, 0.8289331793785095, 0.8445581793785095, 0.8402478694915771, 0.8434805870056152, 0.842402994632721, 0.845097005367279, 0.8472521305084229, 0.8461745977401733, 0.8456357717514038, 0.8521012663841248, 0.8553340435028076, 0.8507543206214905, 0.8491379022598267, 0.8523706793785095, 0.842402994632721, 0.8588362336158752, 0.853178858757019, 0.8521012663841248, 0.860722005367279, 0.8526400923728943, 0.859375, 0.8566810488700867, 0.8623383641242981, 0.860991358757019, 0.8604525923728943, 0.8582974076271057, 0.8585668206214905, 0.8636853694915771, 0.868803858757019, 0.8679956793785095, 0.8682650923728943, 0.8650323152542114, 0.8706896305084229, 0.8682650923728943, 0.8728448152542114, 0.8755387663841248, 0.8666487336158752, 0.8752694129943848, 0.8671875, 0.8728448152542114, 0.8650323152542114, 0.8674569129943848, 0.8795797228813171, 0.8698814511299133, 0.8798491358757019, 0.8714978694915771, 0.868534505367279, 0.8731142282485962, 0.8795797228813171, 0.8731142282485962, 0.8779633641242981, 0.8855064511299133, 0.8785021305084229, 0.8898168206214905, 0.8828125, 0.8873922228813171, 0.8849676847457886, 0.8895474076271057, 0.8933189511299133], 'val_loss': [1.0217612981796265, 0.9964650273323059, 0.9607610106468201, 0.9446010589599609, 0.9485666751861572, 0.9455825090408325, 0.9138005375862122, 0.9037064909934998, 0.8973903059959412, 0.8899556398391724, 0.8677111268043518, 0.8933669328689575, 0.8784286379814148, 0.8515596985816956, 0.8415118455886841, 0.8243155479431152, 0.8690466284751892, 0.8240039348602295, 0.8217798471450806, 0.7988163232803345, 0.8074679374694824, 0.8249558806419373, 0.8397378325462341, 0.8087875247001648, 0.8517946004867554, 0.8362969160079956, 0.8332470059394836, 0.8317691087722778, 0.8663272857666016, 0.8299742341041565, 0.8750572800636292, 0.8820925951004028, 0.8542361259460449, 0.8808449506759644, 0.8963642716407776, 0.8486701846122742, 0.8603029847145081, 0.8597389459609985, 0.8964744806289673, 0.9026986360549927, 0.8996478319168091, 0.8831068277359009, 0.8884737491607666, 0.8596094846725464, 0.8742756843566895, 0.8720488548278809, 0.9073745608329773, 0.8793962001800537, 0.8996709585189819, 0.8870087265968323, 0.9022224545478821, 0.9148877859115601, 0.8858418464660645, 0.8890451192855835, 0.9097056984901428, 0.8882776498794556, 0.910335898399353, 0.8934356570243835, 0.8923130631446838, 0.9061135649681091, 0.9026419520378113, 0.9140651822090149, 0.9071468710899353, 0.9110836386680603, 0.9181129336357117, 0.9129315614700317, 0.9148306846618652, 0.9367136359214783, 0.9262491464614868, 0.9510356187820435, 0.9329465627670288, 0.9327015280723572, 0.9452742338180542, 0.9729307293891907, 0.9427116513252258, 0.9415838122367859, 0.9443777799606323, 0.9611574411392212, 0.9528335332870483, 0.9438957571983337, 0.9526152014732361, 0.9270043969154358, 0.952643632888794, 0.9403471946716309, 0.9516929984092712, 0.9821510910987854, 0.953893780708313, 0.9698784351348877, 0.9682627320289612, 0.9745100736618042, 0.9488325715065002, 0.9680652618408203, 0.9577383995056152, 0.9784281253814697, 0.9686728119850159, 0.9720106720924377, 0.9764302372932434, 0.9960651397705078, 0.9847666025161743, 0.9812948703765869], 'val_accuracy': [0.5161637663841248, 0.517241358757019, 0.5193965435028076, 0.524784505367279, 0.524784505367279, 0.5269396305084229, 0.545258641242981, 0.5538793206214905, 0.5625, 0.5711206793785095, 0.618534505367279, 0.5732758641242981, 0.5948275923728943, 0.6357758641242981, 0.649784505367279, 0.673491358757019, 0.631465494632721, 0.6875, 0.6864224076271057, 0.71875, 0.7079741358757019, 0.6788793206214905, 0.6842672228813171, 0.7155172228813171, 0.6788793206214905, 0.6993534564971924, 0.7036637663841248, 0.7101293206214905, 0.6659482717514038, 0.7090517282485962, 0.6993534564971924, 0.6745689511299133, 0.6928879022598267, 0.6713362336158752, 0.662715494632721, 0.7036637663841248, 0.693965494632721, 0.7101293206214905, 0.6993534564971924, 0.6648706793785095, 0.6659482717514038, 0.6950430870056152, 0.7058189511299133, 0.701508641242981, 0.6961206793785095, 0.7004310488700867, 0.6971982717514038, 0.6982758641242981, 0.6788793206214905, 0.7004310488700867, 0.6993534564971924, 0.662715494632721, 0.6961206793785095, 0.7079741358757019, 0.6778017282485962, 0.693965494632721, 0.6918103694915771, 0.701508641242981, 0.6950430870056152, 0.6961206793785095, 0.6885775923728943, 0.6993534564971924, 0.693965494632721, 0.6885775923728943, 0.6875, 0.693965494632721, 0.6821120977401733, 0.701508641242981, 0.6950430870056152, 0.6918103694915771, 0.6907327771186829, 0.6982758641242981, 0.6961206793785095, 0.6616379022598267, 0.6907327771186829, 0.6875, 0.6842672228813171, 0.673491358757019, 0.6896551847457886, 0.6950430870056152, 0.6918103694915771, 0.6982758641242981, 0.6896551847457886, 0.6918103694915771, 0.6907327771186829, 0.7004310488700867, 0.6928879022598267, 0.6918103694915771, 0.6799569129943848, 0.6971982717514038, 0.6961206793785095, 0.7004310488700867, 0.6971982717514038, 0.6961206793785095, 0.6982758641242981, 0.6961206793785095, 0.6875, 0.681034505367279, 0.6950430870056152, 0.7004310488700867]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.7039 - accuracy: 0.7708"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 8s 55ms/step - loss: 0.7040 - accuracy: 0.7702 - val_loss: 1.0467 - val_accuracy: 0.5045\n","Epoch 2/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6970 - accuracy: 0.7790 - val_loss: 0.9764 - val_accuracy: 0.5057\n","Epoch 3/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6921 - accuracy: 0.7765 - val_loss: 0.9593 - val_accuracy: 0.5079\n","Epoch 4/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7037 - accuracy: 0.7688 - val_loss: 0.9870 - val_accuracy: 0.5057\n","Epoch 5/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6824 - accuracy: 0.7886 - val_loss: 0.9856 - val_accuracy: 0.5068\n","Epoch 6/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6820 - accuracy: 0.7821 - val_loss: 0.9346 - val_accuracy: 0.5204\n","Epoch 7/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6719 - accuracy: 0.7892 - val_loss: 0.9494 - val_accuracy: 0.5170\n","Epoch 8/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6733 - accuracy: 0.7929 - val_loss: 0.9224 - val_accuracy: 0.5385\n","Epoch 9/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.6627 - accuracy: 0.7951 - val_loss: 0.9074 - val_accuracy: 0.5532\n","Epoch 10/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.6662 - accuracy: 0.7895 - val_loss: 0.9145 - val_accuracy: 0.5498\n","Epoch 11/100\n","28/28 [==============================] - 1s 34ms/step - loss: 0.6645 - accuracy: 0.7997 - val_loss: 0.9005 - val_accuracy: 0.5622\n","Epoch 12/100\n","28/28 [==============================] - 1s 37ms/step - loss: 0.6557 - accuracy: 0.7977 - val_loss: 0.9031 - val_accuracy: 0.5633\n","Epoch 13/100\n","28/28 [==============================] - 1s 37ms/step - loss: 0.6498 - accuracy: 0.8022 - val_loss: 0.8887 - val_accuracy: 0.5826\n","Epoch 14/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.6561 - accuracy: 0.7934 - val_loss: 0.8719 - val_accuracy: 0.6041\n","Epoch 15/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.6565 - accuracy: 0.7965 - val_loss: 0.8580 - val_accuracy: 0.6256\n","Epoch 16/100\n","28/28 [==============================] - 1s 36ms/step - loss: 0.6494 - accuracy: 0.7954 - val_loss: 0.8450 - val_accuracy: 0.6561\n","Epoch 17/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6470 - accuracy: 0.7999 - val_loss: 0.8253 - val_accuracy: 0.6855\n","Epoch 18/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6345 - accuracy: 0.8033 - val_loss: 0.8172 - val_accuracy: 0.6912\n","Epoch 19/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6308 - accuracy: 0.8081 - val_loss: 0.8261 - val_accuracy: 0.6742\n","Epoch 20/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6343 - accuracy: 0.8022 - val_loss: 0.8070 - val_accuracy: 0.6980\n","Epoch 21/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6302 - accuracy: 0.8130 - val_loss: 0.8083 - val_accuracy: 0.6946\n","Epoch 22/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6314 - accuracy: 0.8016 - val_loss: 0.8006 - val_accuracy: 0.7002\n","Epoch 23/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6229 - accuracy: 0.8081 - val_loss: 0.8049 - val_accuracy: 0.7149\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6256 - accuracy: 0.8073 - val_loss: 0.8049 - val_accuracy: 0.7127\n","Epoch 25/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6280 - accuracy: 0.8039 - val_loss: 0.8198 - val_accuracy: 0.6946\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6244 - accuracy: 0.8028 - val_loss: 0.8281 - val_accuracy: 0.7070\n","Epoch 27/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6193 - accuracy: 0.8090 - val_loss: 0.8369 - val_accuracy: 0.7093\n","Epoch 28/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6122 - accuracy: 0.8144 - val_loss: 0.8193 - val_accuracy: 0.7115\n","Epoch 29/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6162 - accuracy: 0.8155 - val_loss: 0.8317 - val_accuracy: 0.7014\n","Epoch 30/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6107 - accuracy: 0.8149 - val_loss: 0.8195 - val_accuracy: 0.7081\n","Epoch 31/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6029 - accuracy: 0.8169 - val_loss: 0.8369 - val_accuracy: 0.7036\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6006 - accuracy: 0.8209 - val_loss: 0.8292 - val_accuracy: 0.7115\n","Epoch 33/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6083 - accuracy: 0.8178 - val_loss: 0.8475 - val_accuracy: 0.7093\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6054 - accuracy: 0.8149 - val_loss: 0.8806 - val_accuracy: 0.6923\n","Epoch 35/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.6106 - accuracy: 0.8147 - val_loss: 0.8403 - val_accuracy: 0.7070\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6010 - accuracy: 0.8234 - val_loss: 0.8466 - val_accuracy: 0.7014\n","Epoch 37/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5891 - accuracy: 0.8220 - val_loss: 0.8398 - val_accuracy: 0.7093\n","Epoch 38/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5908 - accuracy: 0.8234 - val_loss: 0.8597 - val_accuracy: 0.6912\n","Epoch 39/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5935 - accuracy: 0.8107 - val_loss: 0.8498 - val_accuracy: 0.7036\n","Epoch 40/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.5829 - accuracy: 0.8311 - val_loss: 0.8396 - val_accuracy: 0.7195\n","Epoch 41/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5870 - accuracy: 0.8280 - val_loss: 0.8671 - val_accuracy: 0.6787\n","Epoch 42/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5826 - accuracy: 0.8299 - val_loss: 0.8367 - val_accuracy: 0.7093\n","Epoch 43/100\n","28/28 [==============================] - 1s 31ms/step - loss: 0.5779 - accuracy: 0.8373 - val_loss: 0.8470 - val_accuracy: 0.7217\n","Epoch 44/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5714 - accuracy: 0.8333 - val_loss: 0.8466 - val_accuracy: 0.7217\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5755 - accuracy: 0.8376 - val_loss: 0.8506 - val_accuracy: 0.7195\n","Epoch 46/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5665 - accuracy: 0.8350 - val_loss: 0.8477 - val_accuracy: 0.7093\n","Epoch 47/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5670 - accuracy: 0.8381 - val_loss: 0.8624 - val_accuracy: 0.7104\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5694 - accuracy: 0.8413 - val_loss: 0.8489 - val_accuracy: 0.7183\n","Epoch 49/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5664 - accuracy: 0.8305 - val_loss: 0.8693 - val_accuracy: 0.7206\n","Epoch 50/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5682 - accuracy: 0.8288 - val_loss: 0.8656 - val_accuracy: 0.6946\n","Epoch 51/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5876 - accuracy: 0.8175 - val_loss: 0.8785 - val_accuracy: 0.6799\n","Epoch 52/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5636 - accuracy: 0.8274 - val_loss: 0.8544 - val_accuracy: 0.7172\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5532 - accuracy: 0.8413 - val_loss: 0.8562 - val_accuracy: 0.7183\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5607 - accuracy: 0.8359 - val_loss: 0.8727 - val_accuracy: 0.7195\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5526 - accuracy: 0.8381 - val_loss: 0.8555 - val_accuracy: 0.7115\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5443 - accuracy: 0.8438 - val_loss: 0.8650 - val_accuracy: 0.7217\n","Epoch 57/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5447 - accuracy: 0.8449 - val_loss: 0.8794 - val_accuracy: 0.7081\n","Epoch 58/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5535 - accuracy: 0.8345 - val_loss: 0.8676 - val_accuracy: 0.7093\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5454 - accuracy: 0.8373 - val_loss: 0.8681 - val_accuracy: 0.6946\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5478 - accuracy: 0.8455 - val_loss: 0.8719 - val_accuracy: 0.7115\n","Epoch 61/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5480 - accuracy: 0.8390 - val_loss: 0.8635 - val_accuracy: 0.7014\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5440 - accuracy: 0.8480 - val_loss: 0.8605 - val_accuracy: 0.7138\n","Epoch 63/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5281 - accuracy: 0.8495 - val_loss: 0.8774 - val_accuracy: 0.7070\n","Epoch 64/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5359 - accuracy: 0.8401 - val_loss: 0.8772 - val_accuracy: 0.7070\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5368 - accuracy: 0.8449 - val_loss: 0.8897 - val_accuracy: 0.7014\n","Epoch 66/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5600 - accuracy: 0.8263 - val_loss: 0.8804 - val_accuracy: 0.7025\n","Epoch 67/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5465 - accuracy: 0.8432 - val_loss: 0.8713 - val_accuracy: 0.6991\n","Epoch 68/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.5391 - accuracy: 0.8497 - val_loss: 0.8826 - val_accuracy: 0.7104\n","Epoch 69/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.5226 - accuracy: 0.8523 - val_loss: 0.8984 - val_accuracy: 0.6787\n","Epoch 70/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5280 - accuracy: 0.8455 - val_loss: 0.8942 - val_accuracy: 0.7081\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5244 - accuracy: 0.8537 - val_loss: 0.8752 - val_accuracy: 0.7014\n","Epoch 72/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5178 - accuracy: 0.8591 - val_loss: 0.8686 - val_accuracy: 0.7036\n","Epoch 73/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5160 - accuracy: 0.8520 - val_loss: 0.8727 - val_accuracy: 0.7081\n","Epoch 74/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.5124 - accuracy: 0.8580 - val_loss: 0.8984 - val_accuracy: 0.7059\n","Epoch 75/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5261 - accuracy: 0.8483 - val_loss: 0.9081 - val_accuracy: 0.6980\n","Epoch 76/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5176 - accuracy: 0.8483 - val_loss: 0.8740 - val_accuracy: 0.7161\n","Epoch 77/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.5162 - accuracy: 0.8546 - val_loss: 0.8850 - val_accuracy: 0.7036\n","Epoch 78/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5197 - accuracy: 0.8588 - val_loss: 0.8982 - val_accuracy: 0.7093\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5052 - accuracy: 0.8599 - val_loss: 0.8816 - val_accuracy: 0.7183\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5034 - accuracy: 0.8565 - val_loss: 0.8952 - val_accuracy: 0.7093\n","Epoch 81/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5147 - accuracy: 0.8585 - val_loss: 0.8903 - val_accuracy: 0.7014\n","Epoch 82/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5068 - accuracy: 0.8608 - val_loss: 0.8889 - val_accuracy: 0.6934\n","Epoch 83/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4992 - accuracy: 0.8639 - val_loss: 0.8928 - val_accuracy: 0.7036\n","Epoch 84/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5010 - accuracy: 0.8642 - val_loss: 0.8955 - val_accuracy: 0.6934\n","Epoch 85/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4979 - accuracy: 0.8596 - val_loss: 0.9035 - val_accuracy: 0.7115\n","Epoch 86/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5028 - accuracy: 0.8602 - val_loss: 0.9020 - val_accuracy: 0.6991\n","Epoch 87/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4992 - accuracy: 0.8565 - val_loss: 0.8909 - val_accuracy: 0.7149\n","Epoch 88/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4944 - accuracy: 0.8667 - val_loss: 0.8919 - val_accuracy: 0.7081\n","Epoch 89/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4845 - accuracy: 0.8664 - val_loss: 0.8853 - val_accuracy: 0.7172\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4875 - accuracy: 0.8713 - val_loss: 0.9027 - val_accuracy: 0.6867\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4923 - accuracy: 0.8596 - val_loss: 0.9440 - val_accuracy: 0.6572\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4896 - accuracy: 0.8656 - val_loss: 0.9155 - val_accuracy: 0.7002\n","Epoch 93/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4863 - accuracy: 0.8713 - val_loss: 0.9021 - val_accuracy: 0.7048\n","Epoch 94/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4835 - accuracy: 0.8710 - val_loss: 0.9090 - val_accuracy: 0.7036\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4887 - accuracy: 0.8664 - val_loss: 0.9369 - val_accuracy: 0.7036\n","Epoch 96/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4794 - accuracy: 0.8676 - val_loss: 0.9118 - val_accuracy: 0.7025\n","Epoch 97/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4849 - accuracy: 0.8704 - val_loss: 0.9476 - val_accuracy: 0.6833\n","Epoch 98/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4831 - accuracy: 0.8715 - val_loss: 0.9072 - val_accuracy: 0.6980\n","Epoch 99/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4725 - accuracy: 0.8727 - val_loss: 0.9357 - val_accuracy: 0.7025\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4751 - accuracy: 0.8715 - val_loss: 0.9115 - val_accuracy: 0.7115\n","{'loss': [0.7040380835533142, 0.6969954371452332, 0.6921100616455078, 0.7036624550819397, 0.6823940277099609, 0.6819724440574646, 0.6719382405281067, 0.6732529997825623, 0.6627088189125061, 0.6661655306816101, 0.6644841432571411, 0.6556979417800903, 0.6498190760612488, 0.6561399102210999, 0.656527042388916, 0.6493632197380066, 0.6469529867172241, 0.634472668170929, 0.6307712197303772, 0.6342566609382629, 0.6302043795585632, 0.6313679814338684, 0.6228823065757751, 0.6256204843521118, 0.6279925107955933, 0.6244136095046997, 0.6192730665206909, 0.6122221350669861, 0.6162447333335876, 0.6106753349304199, 0.6029448509216309, 0.6005991101264954, 0.6083390116691589, 0.6054484844207764, 0.610625147819519, 0.6010143160820007, 0.5890902280807495, 0.5908188819885254, 0.593488872051239, 0.5829197764396667, 0.5870005488395691, 0.582566499710083, 0.5779120326042175, 0.5714088678359985, 0.5754527449607849, 0.5664589405059814, 0.5670416951179504, 0.569377064704895, 0.5663658976554871, 0.5682090520858765, 0.5875638127326965, 0.5636240839958191, 0.5532355308532715, 0.5606997609138489, 0.5525542497634888, 0.5442636609077454, 0.5446527004241943, 0.553507924079895, 0.5453870296478271, 0.5477622747421265, 0.5479581356048584, 0.5440030097961426, 0.5280975103378296, 0.5359365344047546, 0.5367680788040161, 0.5599602460861206, 0.5465044975280762, 0.5391266942024231, 0.5226284265518188, 0.5280020236968994, 0.5244459509849548, 0.5177695155143738, 0.5160364508628845, 0.5123707056045532, 0.5261255502700806, 0.5175859332084656, 0.5161796808242798, 0.5196768045425415, 0.5052464008331299, 0.503355085849762, 0.5146923661231995, 0.5067574977874756, 0.499203085899353, 0.5009884834289551, 0.4979488253593445, 0.5027933716773987, 0.4991866946220398, 0.49440672993659973, 0.4845310151576996, 0.4874873161315918, 0.4923165440559387, 0.4895961284637451, 0.48630133271217346, 0.48350510001182556, 0.4887394905090332, 0.4793766438961029, 0.4848869740962982, 0.48314711451530457, 0.47249022126197815, 0.47512638568878174], 'accuracy': [0.7702320218086243, 0.7790039777755737, 0.7764572501182556, 0.7688171863555908, 0.7886247634887695, 0.7821165919303894, 0.7891907095909119, 0.7928692698478699, 0.7951329946517944, 0.7894737124443054, 0.7996604442596436, 0.7976796627044678, 0.8022071123123169, 0.7934352159500122, 0.7965478301048279, 0.7954159379005432, 0.7999433875083923, 0.8033390045166016, 0.8081493973731995, 0.8022071123123169, 0.8129597902297974, 0.8016412258148193, 0.8081493973731995, 0.8073005080223083, 0.8039049506187439, 0.8027730584144592, 0.8089982867240906, 0.8143746256828308, 0.8155065178871155, 0.8149405717849731, 0.8169213533401489, 0.8208828568458557, 0.81777024269104, 0.8149405717849731, 0.8146576285362244, 0.823429524898529, 0.8220146894454956, 0.823429524898529, 0.8106960654258728, 0.8310695886611938, 0.8279569745063782, 0.829937756061554, 0.83729487657547, 0.8333333134651184, 0.8375778198242188, 0.8350311517715454, 0.8381437659263611, 0.8412563800811768, 0.8305037021636963, 0.8288058638572693, 0.8174872398376465, 0.8273910880088806, 0.8412563800811768, 0.8358800411224365, 0.8381437659263611, 0.8438030481338501, 0.8449349403381348, 0.8344652056694031, 0.83729487657547, 0.8455008268356323, 0.8389926552772522, 0.8480475544929504, 0.8494623899459839, 0.8401244878768921, 0.8449349403381348, 0.826259195804596, 0.8432371020317078, 0.8497453331947327, 0.852292001247406, 0.8455008268356323, 0.8537068367004395, 0.8590831756591797, 0.8520090579986572, 0.8579513430595398, 0.8483304977416992, 0.8483304977416992, 0.8545557260513306, 0.8588002324104309, 0.8599320650100708, 0.8565365076065063, 0.8585172891616821, 0.8607810139656067, 0.8638936281204224, 0.8641765713691711, 0.859649121761322, 0.8602150678634644, 0.8565365076065063, 0.8667232394218445, 0.8664402961730957, 0.8712506890296936, 0.859649121761322, 0.8655914068222046, 0.8712506890296936, 0.8709677457809448, 0.8664402961730957, 0.8675721287727356, 0.8704017996788025, 0.8715336918830872, 0.872665524482727, 0.8715336918830872], 'val_loss': [1.0467135906219482, 0.9764239192008972, 0.9593119025230408, 0.9870119690895081, 0.9855830073356628, 0.9346401691436768, 0.9494087100028992, 0.9224196076393127, 0.9074380397796631, 0.9145349264144897, 0.9005235433578491, 0.9031001329421997, 0.8887110352516174, 0.871868371963501, 0.858039379119873, 0.8449576497077942, 0.8252947926521301, 0.817151665687561, 0.8261358141899109, 0.807010293006897, 0.8082529306411743, 0.8005709648132324, 0.8049160242080688, 0.8048686981201172, 0.8198114037513733, 0.8281163573265076, 0.8368752002716064, 0.8192582130432129, 0.8316607475280762, 0.8195271492004395, 0.8368952870368958, 0.8291980624198914, 0.8475403785705566, 0.8805961608886719, 0.8402574062347412, 0.8465714454650879, 0.8398166298866272, 0.8597233295440674, 0.8497873544692993, 0.8395794630050659, 0.8671116828918457, 0.8366590738296509, 0.8469849824905396, 0.8465959429740906, 0.8505997061729431, 0.8476582765579224, 0.8623906373977661, 0.8488704562187195, 0.8692604303359985, 0.8656020164489746, 0.8785012364387512, 0.8543559908866882, 0.8561896681785583, 0.8727168440818787, 0.8555175065994263, 0.8649713397026062, 0.8793845772743225, 0.8676400780677795, 0.8681098222732544, 0.8718969821929932, 0.863501250743866, 0.8605052828788757, 0.8774434328079224, 0.8772209882736206, 0.8896566033363342, 0.880391001701355, 0.871347188949585, 0.882577657699585, 0.898436963558197, 0.8941611051559448, 0.8751578330993652, 0.8686419129371643, 0.8727374076843262, 0.8983502984046936, 0.9081071615219116, 0.8740416765213013, 0.8850494623184204, 0.8981558084487915, 0.8816000819206238, 0.8951888084411621, 0.8902771472930908, 0.8889495134353638, 0.8927614092826843, 0.8955432772636414, 0.9034937620162964, 0.9020037651062012, 0.8908546566963196, 0.8919231295585632, 0.8852770328521729, 0.90269935131073, 0.9439910650253296, 0.9155097603797913, 0.9021408557891846, 0.9089516401290894, 0.9368832111358643, 0.91181480884552, 0.9476475715637207, 0.9072443842887878, 0.9356864094734192, 0.9115201234817505], 'val_accuracy': [0.5045248866081238, 0.5056561231613159, 0.5079185366630554, 0.5056561231613159, 0.5067873597145081, 0.5203620195388794, 0.516968309879303, 0.5384615659713745, 0.5531674027442932, 0.5497737526893616, 0.5622171759605408, 0.5633484125137329, 0.5825791954994202, 0.6040723919868469, 0.6255655884742737, 0.6561086177825928, 0.685520350933075, 0.6911764740943909, 0.6742081642150879, 0.6979637742042542, 0.6945701241493225, 0.7002262473106384, 0.7149321436882019, 0.7126696705818176, 0.6945701241493225, 0.7070135474205017, 0.709276020526886, 0.7115384340286255, 0.7013574838638306, 0.7081447839736938, 0.7036198973655701, 0.7115384340286255, 0.709276020526886, 0.692307710647583, 0.7070135474205017, 0.7013574838638306, 0.709276020526886, 0.6911764740943909, 0.7036198973655701, 0.7194570302963257, 0.6787330508232117, 0.709276020526886, 0.7217194437980652, 0.7217194437980652, 0.7194570302963257, 0.709276020526886, 0.7104072570800781, 0.7183257937431335, 0.720588207244873, 0.6945701241493225, 0.679864227771759, 0.7171945571899414, 0.7183257937431335, 0.7194570302963257, 0.7115384340286255, 0.7217194437980652, 0.7081447839736938, 0.709276020526886, 0.6945701241493225, 0.7115384340286255, 0.7013574838638306, 0.7138009071350098, 0.7070135474205017, 0.7070135474205017, 0.7013574838638306, 0.7024886608123779, 0.6990950107574463, 0.7104072570800781, 0.6787330508232117, 0.7081447839736938, 0.7013574838638306, 0.7036198973655701, 0.7081447839736938, 0.7058823704719543, 0.6979637742042542, 0.7160633206367493, 0.7036198973655701, 0.709276020526886, 0.7183257937431335, 0.709276020526886, 0.7013574838638306, 0.6934388875961304, 0.7036198973655701, 0.6934388875961304, 0.7115384340286255, 0.6990950107574463, 0.7149321436882019, 0.7081447839736938, 0.7171945571899414, 0.6866515874862671, 0.6572397947311401, 0.7002262473106384, 0.7047511339187622, 0.7036198973655701, 0.7036198973655701, 0.7024886608123779, 0.6832579374313354, 0.6979637742042542, 0.7024886608123779, 0.7115384340286255]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - ETA: 0s - loss: 0.6986 - accuracy: 0.7806"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 7s 67ms/step - loss: 0.6986 - accuracy: 0.7806 - val_loss: 0.9765 - val_accuracy: 0.5155\n","Epoch 2/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6893 - accuracy: 0.7871 - val_loss: 0.9497 - val_accuracy: 0.5196\n","Epoch 3/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6845 - accuracy: 0.7860 - val_loss: 0.9847 - val_accuracy: 0.5176\n","Epoch 4/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6881 - accuracy: 0.7798 - val_loss: 0.9438 - val_accuracy: 0.5269\n","Epoch 5/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.6897 - accuracy: 0.7762 - val_loss: 0.9245 - val_accuracy: 0.5393\n","Epoch 6/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6725 - accuracy: 0.7953 - val_loss: 0.9115 - val_accuracy: 0.5506\n","Epoch 7/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.6728 - accuracy: 0.7858 - val_loss: 0.9250 - val_accuracy: 0.5444\n","Epoch 8/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6708 - accuracy: 0.7915 - val_loss: 0.9112 - val_accuracy: 0.5558\n","Epoch 9/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6561 - accuracy: 0.8010 - val_loss: 0.8972 - val_accuracy: 0.5692\n","Epoch 10/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6674 - accuracy: 0.7920 - val_loss: 0.8775 - val_accuracy: 0.6023\n","Epoch 11/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6597 - accuracy: 0.7935 - val_loss: 0.8616 - val_accuracy: 0.6550\n","Epoch 12/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6652 - accuracy: 0.7917 - val_loss: 0.8692 - val_accuracy: 0.6033\n","Epoch 13/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6468 - accuracy: 0.8031 - val_loss: 0.8650 - val_accuracy: 0.6436\n","Epoch 14/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6507 - accuracy: 0.8013 - val_loss: 0.8492 - val_accuracy: 0.6581\n","Epoch 15/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.6454 - accuracy: 0.8044 - val_loss: 0.8415 - val_accuracy: 0.6622\n","Epoch 16/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.6384 - accuracy: 0.8059 - val_loss: 0.8277 - val_accuracy: 0.6798\n","Epoch 17/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6531 - accuracy: 0.7938 - val_loss: 0.8259 - val_accuracy: 0.6725\n","Epoch 18/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.6410 - accuracy: 0.8039 - val_loss: 0.8307 - val_accuracy: 0.6808\n","Epoch 19/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6395 - accuracy: 0.7995 - val_loss: 0.8305 - val_accuracy: 0.6777\n","Epoch 20/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6373 - accuracy: 0.8057 - val_loss: 0.8580 - val_accuracy: 0.6653\n","Epoch 21/100\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6264 - accuracy: 0.8103 - val_loss: 0.8343 - val_accuracy: 0.6829\n","Epoch 22/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6243 - accuracy: 0.8147 - val_loss: 0.8381 - val_accuracy: 0.6736\n","Epoch 23/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6304 - accuracy: 0.8090 - val_loss: 0.8494 - val_accuracy: 0.6746\n","Epoch 24/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.6258 - accuracy: 0.8150 - val_loss: 0.8474 - val_accuracy: 0.6808\n","Epoch 25/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.6170 - accuracy: 0.8119 - val_loss: 0.8614 - val_accuracy: 0.6808\n","Epoch 26/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.6134 - accuracy: 0.8196 - val_loss: 0.8635 - val_accuracy: 0.6756\n","Epoch 27/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.6129 - accuracy: 0.8186 - val_loss: 0.8739 - val_accuracy: 0.6839\n","Epoch 28/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.6098 - accuracy: 0.8155 - val_loss: 0.8730 - val_accuracy: 0.6736\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6061 - accuracy: 0.8158 - val_loss: 0.8888 - val_accuracy: 0.6839\n","Epoch 30/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.6068 - accuracy: 0.8207 - val_loss: 0.9187 - val_accuracy: 0.6529\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.6083 - accuracy: 0.8121 - val_loss: 0.8909 - val_accuracy: 0.6777\n","Epoch 32/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5999 - accuracy: 0.8222 - val_loss: 0.9194 - val_accuracy: 0.6653\n","Epoch 33/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.6032 - accuracy: 0.8145 - val_loss: 0.8927 - val_accuracy: 0.6860\n","Epoch 34/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5927 - accuracy: 0.8238 - val_loss: 0.8967 - val_accuracy: 0.6818\n","Epoch 35/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5961 - accuracy: 0.8248 - val_loss: 0.9076 - val_accuracy: 0.6818\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5912 - accuracy: 0.8295 - val_loss: 0.9132 - val_accuracy: 0.6725\n","Epoch 37/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5975 - accuracy: 0.8176 - val_loss: 0.9063 - val_accuracy: 0.6870\n","Epoch 38/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5938 - accuracy: 0.8230 - val_loss: 0.9121 - val_accuracy: 0.6787\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5919 - accuracy: 0.8225 - val_loss: 0.9032 - val_accuracy: 0.6756\n","Epoch 40/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5933 - accuracy: 0.8199 - val_loss: 0.9120 - val_accuracy: 0.6756\n","Epoch 41/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5876 - accuracy: 0.8207 - val_loss: 0.9203 - val_accuracy: 0.6767\n","Epoch 42/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5744 - accuracy: 0.8300 - val_loss: 0.9165 - val_accuracy: 0.6674\n","Epoch 43/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5719 - accuracy: 0.8333 - val_loss: 0.9335 - val_accuracy: 0.6777\n","Epoch 44/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5756 - accuracy: 0.8279 - val_loss: 0.9518 - val_accuracy: 0.6798\n","Epoch 45/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5677 - accuracy: 0.8375 - val_loss: 0.9182 - val_accuracy: 0.6818\n","Epoch 46/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5748 - accuracy: 0.8258 - val_loss: 0.9246 - val_accuracy: 0.6777\n","Epoch 47/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5721 - accuracy: 0.8302 - val_loss: 0.9216 - val_accuracy: 0.6746\n","Epoch 48/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5646 - accuracy: 0.8375 - val_loss: 0.9378 - val_accuracy: 0.6653\n","Epoch 49/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5669 - accuracy: 0.8320 - val_loss: 0.9224 - val_accuracy: 0.6674\n","Epoch 50/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5675 - accuracy: 0.8382 - val_loss: 0.9225 - val_accuracy: 0.6777\n","Epoch 51/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.5861 - accuracy: 0.8261 - val_loss: 1.0876 - val_accuracy: 0.5971\n","Epoch 52/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5815 - accuracy: 0.8220 - val_loss: 0.9366 - val_accuracy: 0.6787\n","Epoch 53/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5650 - accuracy: 0.8326 - val_loss: 0.9331 - val_accuracy: 0.6798\n","Epoch 54/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5545 - accuracy: 0.8401 - val_loss: 0.9669 - val_accuracy: 0.6684\n","Epoch 55/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5594 - accuracy: 0.8362 - val_loss: 0.9313 - val_accuracy: 0.6736\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5491 - accuracy: 0.8426 - val_loss: 0.9398 - val_accuracy: 0.6798\n","Epoch 57/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5646 - accuracy: 0.8297 - val_loss: 0.9387 - val_accuracy: 0.6746\n","Epoch 58/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5888 - accuracy: 0.8140 - val_loss: 0.9476 - val_accuracy: 0.6519\n","Epoch 59/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5704 - accuracy: 0.8266 - val_loss: 1.0186 - val_accuracy: 0.6612\n","Epoch 60/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5665 - accuracy: 0.8276 - val_loss: 0.9464 - val_accuracy: 0.6787\n","Epoch 61/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5439 - accuracy: 0.8367 - val_loss: 0.9220 - val_accuracy: 0.6777\n","Epoch 62/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5402 - accuracy: 0.8491 - val_loss: 0.9379 - val_accuracy: 0.6715\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5474 - accuracy: 0.8375 - val_loss: 0.9407 - val_accuracy: 0.6705\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5461 - accuracy: 0.8307 - val_loss: 0.9520 - val_accuracy: 0.6694\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5374 - accuracy: 0.8465 - val_loss: 0.9561 - val_accuracy: 0.6653\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5340 - accuracy: 0.8540 - val_loss: 0.9551 - val_accuracy: 0.6601\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5311 - accuracy: 0.8501 - val_loss: 0.9397 - val_accuracy: 0.6622\n","Epoch 68/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5225 - accuracy: 0.8563 - val_loss: 0.9445 - val_accuracy: 0.6653\n","Epoch 69/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5220 - accuracy: 0.8535 - val_loss: 0.9497 - val_accuracy: 0.6818\n","Epoch 70/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5295 - accuracy: 0.8483 - val_loss: 0.9653 - val_accuracy: 0.6694\n","Epoch 71/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5305 - accuracy: 0.8439 - val_loss: 0.9711 - val_accuracy: 0.6705\n","Epoch 72/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5231 - accuracy: 0.8499 - val_loss: 0.9556 - val_accuracy: 0.6756\n","Epoch 73/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5265 - accuracy: 0.8566 - val_loss: 0.9827 - val_accuracy: 0.6570\n","Epoch 74/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5128 - accuracy: 0.8605 - val_loss: 0.9784 - val_accuracy: 0.6736\n","Epoch 75/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5124 - accuracy: 0.8605 - val_loss: 0.9780 - val_accuracy: 0.6653\n","Epoch 76/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5203 - accuracy: 0.8491 - val_loss: 1.0000 - val_accuracy: 0.6663\n","Epoch 77/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5146 - accuracy: 0.8506 - val_loss: 0.9876 - val_accuracy: 0.6756\n","Epoch 78/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5068 - accuracy: 0.8612 - val_loss: 0.9946 - val_accuracy: 0.6694\n","Epoch 79/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5037 - accuracy: 0.8623 - val_loss: 0.9918 - val_accuracy: 0.6591\n","Epoch 80/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5124 - accuracy: 0.8506 - val_loss: 1.0678 - val_accuracy: 0.6643\n","Epoch 81/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.5189 - accuracy: 0.8519 - val_loss: 0.9729 - val_accuracy: 0.6663\n","Epoch 82/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.5063 - accuracy: 0.8525 - val_loss: 1.0193 - val_accuracy: 0.6508\n","Epoch 83/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5048 - accuracy: 0.8576 - val_loss: 0.9849 - val_accuracy: 0.6736\n","Epoch 84/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4982 - accuracy: 0.8649 - val_loss: 0.9972 - val_accuracy: 0.6643\n","Epoch 85/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4991 - accuracy: 0.8602 - val_loss: 0.9811 - val_accuracy: 0.6622\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4946 - accuracy: 0.8623 - val_loss: 0.9871 - val_accuracy: 0.6756\n","Epoch 87/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4860 - accuracy: 0.8677 - val_loss: 0.9929 - val_accuracy: 0.6767\n","Epoch 88/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4929 - accuracy: 0.8612 - val_loss: 0.9872 - val_accuracy: 0.6632\n","Epoch 89/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5049 - accuracy: 0.8561 - val_loss: 0.9957 - val_accuracy: 0.6684\n","Epoch 90/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4953 - accuracy: 0.8641 - val_loss: 1.0106 - val_accuracy: 0.6787\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4813 - accuracy: 0.8680 - val_loss: 1.0477 - val_accuracy: 0.6467\n","Epoch 92/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4899 - accuracy: 0.8659 - val_loss: 1.0126 - val_accuracy: 0.6612\n","Epoch 93/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4852 - accuracy: 0.8690 - val_loss: 1.0231 - val_accuracy: 0.6684\n","Epoch 94/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5010 - accuracy: 0.8540 - val_loss: 1.0496 - val_accuracy: 0.6643\n","Epoch 95/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4907 - accuracy: 0.8672 - val_loss: 1.0431 - val_accuracy: 0.6663\n","Epoch 96/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4823 - accuracy: 0.8711 - val_loss: 1.0129 - val_accuracy: 0.6643\n","Epoch 97/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4786 - accuracy: 0.8705 - val_loss: 1.0169 - val_accuracy: 0.6591\n","Epoch 98/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4746 - accuracy: 0.8687 - val_loss: 1.0344 - val_accuracy: 0.6663\n","Epoch 99/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4800 - accuracy: 0.8646 - val_loss: 1.0453 - val_accuracy: 0.6477\n","Epoch 100/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4824 - accuracy: 0.8656 - val_loss: 1.0107 - val_accuracy: 0.6715\n","{'loss': [0.698566198348999, 0.6893441677093506, 0.6844528317451477, 0.6880724430084229, 0.6896995902061462, 0.6724719405174255, 0.672785222530365, 0.6707989573478699, 0.6561103463172913, 0.6673761010169983, 0.659696638584137, 0.6652214527130127, 0.6467524170875549, 0.6506980061531067, 0.6453759670257568, 0.638441801071167, 0.653093159198761, 0.6409772038459778, 0.6395168900489807, 0.6372655630111694, 0.6264047026634216, 0.624302327632904, 0.6304369568824768, 0.6258075833320618, 0.6169517040252686, 0.6134462356567383, 0.6129410862922668, 0.6097624897956848, 0.6061078906059265, 0.606760561466217, 0.6083362698554993, 0.5998548865318298, 0.6031600832939148, 0.5927131772041321, 0.5961045622825623, 0.5912443995475769, 0.5974687337875366, 0.5938146114349365, 0.591869056224823, 0.5932736396789551, 0.5876049995422363, 0.5744273662567139, 0.5719226002693176, 0.5756011605262756, 0.5676607489585876, 0.5747683048248291, 0.5720525979995728, 0.5646194815635681, 0.5669108629226685, 0.5675490498542786, 0.586145281791687, 0.5815045833587646, 0.565005898475647, 0.5545116662979126, 0.5594320297241211, 0.5491098165512085, 0.5645878314971924, 0.5888403058052063, 0.5704460740089417, 0.5665178894996643, 0.5438568592071533, 0.5401654839515686, 0.5473799109458923, 0.5460655689239502, 0.5374417304992676, 0.533984899520874, 0.5310731530189514, 0.5225209593772888, 0.5219631791114807, 0.5294889807701111, 0.5304902791976929, 0.5230952501296997, 0.5264727473258972, 0.5127913951873779, 0.5123544335365295, 0.520256757736206, 0.514588475227356, 0.5067794919013977, 0.5037150979042053, 0.5123738646507263, 0.5189158320426941, 0.506252110004425, 0.5048234462738037, 0.4982472062110901, 0.49912452697753906, 0.4946443736553192, 0.48604923486709595, 0.49294769763946533, 0.5048716068267822, 0.49531248211860657, 0.4812731444835663, 0.4899151921272278, 0.48517996072769165, 0.501021146774292, 0.4907204806804657, 0.4822865426540375, 0.4786262810230255, 0.47459492087364197, 0.479992538690567, 0.4823807179927826], 'accuracy': [0.7806201577186584, 0.7870801091194153, 0.7860465049743652, 0.7798449397087097, 0.7762274146080017, 0.7953488230705261, 0.7857881188392639, 0.791472852230072, 0.801033616065979, 0.7919896841049194, 0.7935400605201721, 0.7917312383651733, 0.8031007647514343, 0.8012920022010803, 0.8043927550315857, 0.8059431314468384, 0.7937984466552734, 0.8038759827613831, 0.7994831800460815, 0.8056847453117371, 0.8103359341621399, 0.8147286772727966, 0.8090439438819885, 0.814987063407898, 0.8118863105773926, 0.8196382522583008, 0.8186046481132507, 0.8155038952827454, 0.8157622814178467, 0.8206718564033508, 0.8121446967124939, 0.8222222328186035, 0.8144702911376953, 0.8237726092338562, 0.8248062133789062, 0.8294573426246643, 0.8175710439682007, 0.8229973912239075, 0.8224806189537048, 0.8198966383934021, 0.8206718564033508, 0.8299741744995117, 0.8333333134651184, 0.8279069662094116, 0.8374677300453186, 0.8258398175239563, 0.830232560634613, 0.8374677300453186, 0.832041323184967, 0.8382428884506226, 0.8260982036590576, 0.8219638466835022, 0.8325581550598145, 0.8400516510009766, 0.8361757397651672, 0.8426356315612793, 0.8297157883644104, 0.8139534592628479, 0.8266149759292603, 0.8276485800743103, 0.8366925120353699, 0.8490955829620361, 0.8374677300453186, 0.8307493329048157, 0.8465116024017334, 0.8540051579475403, 0.8501291871070862, 0.8563307523727417, 0.8534883856773376, 0.8483204245567322, 0.8439276218414307, 0.8498708009719849, 0.856589138507843, 0.8604651093482971, 0.8604651093482971, 0.8490955829620361, 0.8506460189819336, 0.8612403273582458, 0.8622739315032959, 0.8506460189819336, 0.851938009262085, 0.8524547815322876, 0.8576227426528931, 0.8648578524589539, 0.8602067232131958, 0.8622739315032959, 0.8677002787590027, 0.8612403273582458, 0.8560723662376404, 0.8640826940536499, 0.867958664894104, 0.8658914566040039, 0.868992269039154, 0.8540051579475403, 0.8671834468841553, 0.8710594177246094, 0.8705426454544067, 0.868733823299408, 0.8645994663238525, 0.8656330704689026], 'val_loss': [0.9765089750289917, 0.949656069278717, 0.9846898913383484, 0.9437540173530579, 0.9245054125785828, 0.9115225672721863, 0.9249528050422668, 0.9111807346343994, 0.897242546081543, 0.877510130405426, 0.8616499900817871, 0.8692136406898499, 0.8650484681129456, 0.8492381572723389, 0.8414536118507385, 0.8276963233947754, 0.8258706331253052, 0.8306750655174255, 0.8304599523544312, 0.8579632043838501, 0.8342673182487488, 0.8380936980247498, 0.8494442105293274, 0.8473749160766602, 0.8613909482955933, 0.8634874224662781, 0.8738734722137451, 0.8730287551879883, 0.8888136148452759, 0.918658435344696, 0.8908575773239136, 0.9194149971008301, 0.8926715850830078, 0.8966562747955322, 0.9076327681541443, 0.9132258296012878, 0.9062966704368591, 0.9120966196060181, 0.9032251834869385, 0.9119817018508911, 0.9202532172203064, 0.9165107011795044, 0.9334856867790222, 0.9517553448677063, 0.9181605577468872, 0.92457115650177, 0.9216164946556091, 0.9377561807632446, 0.922406017780304, 0.922497034072876, 1.0875879526138306, 0.9365731477737427, 0.9331262111663818, 0.9668683409690857, 0.9313386082649231, 0.9397556185722351, 0.9386709928512573, 0.9475933909416199, 1.018560767173767, 0.946362316608429, 0.9220055341720581, 0.9378949403762817, 0.9407389163970947, 0.9520272612571716, 0.956079363822937, 0.955081582069397, 0.9396615624427795, 0.9444776177406311, 0.9497346878051758, 0.965335488319397, 0.9710822701454163, 0.9555855393409729, 0.9827167391777039, 0.9783802032470703, 0.977995753288269, 1.0000159740447998, 0.9876188635826111, 0.9946271181106567, 0.9917501211166382, 1.0678268671035767, 0.9728778600692749, 1.0192720890045166, 0.9848514199256897, 0.9972304701805115, 0.9811401963233948, 0.9871121048927307, 0.9928773045539856, 0.9872211813926697, 0.9956526160240173, 1.0106428861618042, 1.0476539134979248, 1.0126280784606934, 1.0230501890182495, 1.0496360063552856, 1.0431492328643799, 1.0128785371780396, 1.0169456005096436, 1.034395694732666, 1.0452858209609985, 1.0107234716415405], 'val_accuracy': [0.5154958963394165, 0.51962810754776, 0.5175619721412659, 0.5268595218658447, 0.53925621509552, 0.5506198406219482, 0.5444214940071106, 0.5557851195335388, 0.5692148804664612, 0.6022727489471436, 0.6549586653709412, 0.6033057570457458, 0.6435950398445129, 0.6580578684806824, 0.6621900796890259, 0.6797520518302917, 0.672520637512207, 0.6807851195335388, 0.6776859760284424, 0.6652892827987671, 0.682851254940033, 0.6735537052154541, 0.6745867729187012, 0.6807851195335388, 0.6807851195335388, 0.6756198406219482, 0.68388432264328, 0.6735537052154541, 0.68388432264328, 0.6528925895690918, 0.6776859760284424, 0.6652892827987671, 0.6859503984451294, 0.6818181872367859, 0.6818181872367859, 0.672520637512207, 0.6869834661483765, 0.6787189841270447, 0.6756198406219482, 0.6756198406219482, 0.6766529083251953, 0.6673553586006165, 0.6776859760284424, 0.6797520518302917, 0.6818181872367859, 0.6776859760284424, 0.6745867729187012, 0.6652892827987671, 0.6673553586006165, 0.6776859760284424, 0.5971074104309082, 0.6787189841270447, 0.6797520518302917, 0.6683884263038635, 0.6735537052154541, 0.6797520518302917, 0.6745867729187012, 0.6518595218658447, 0.6611570119857788, 0.6787189841270447, 0.6776859760284424, 0.6714876294136047, 0.6704545617103577, 0.6694214940071106, 0.6652892827987671, 0.6601239442825317, 0.6621900796890259, 0.6652892827987671, 0.6818181872367859, 0.6694214940071106, 0.6704545617103577, 0.6756198406219482, 0.6570248007774353, 0.6735537052154541, 0.6652892827987671, 0.6663222908973694, 0.6756198406219482, 0.6694214940071106, 0.6590909361839294, 0.66425621509552, 0.6663222908973694, 0.6508264541625977, 0.6735537052154541, 0.66425621509552, 0.6621900796890259, 0.6756198406219482, 0.6766529083251953, 0.663223147392273, 0.6683884263038635, 0.6787189841270447, 0.6466942429542542, 0.6611570119857788, 0.6683884263038635, 0.66425621509552, 0.6663222908973694, 0.66425621509552, 0.6590909361839294, 0.6663222908973694, 0.6477272510528564, 0.6714876294136047]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","29/29 [==============================] - ETA: 0s - loss: 0.5425 - accuracy: 0.8400"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 6s 53ms/step - loss: 0.5425 - accuracy: 0.8400 - val_loss: 0.9099 - val_accuracy: 0.5194\n","Epoch 2/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.5183 - accuracy: 0.8532 - val_loss: 0.8885 - val_accuracy: 0.5259\n","Epoch 3/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.5117 - accuracy: 0.8516 - val_loss: 0.8916 - val_accuracy: 0.5269\n","Epoch 4/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.5079 - accuracy: 0.8532 - val_loss: 0.8990 - val_accuracy: 0.5269\n","Epoch 5/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.5032 - accuracy: 0.8572 - val_loss: 0.9119 - val_accuracy: 0.5312\n","Epoch 6/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.5069 - accuracy: 0.8524 - val_loss: 0.8508 - val_accuracy: 0.5603\n","Epoch 7/100\n","29/29 [==============================] - 1s 26ms/step - loss: 0.5009 - accuracy: 0.8540 - val_loss: 0.8338 - val_accuracy: 0.6067\n","Epoch 8/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4976 - accuracy: 0.8610 - val_loss: 0.8462 - val_accuracy: 0.5711\n","Epoch 9/100\n","29/29 [==============================] - 1s 28ms/step - loss: 0.4951 - accuracy: 0.8586 - val_loss: 0.8174 - val_accuracy: 0.6519\n","Epoch 10/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4928 - accuracy: 0.8602 - val_loss: 0.8063 - val_accuracy: 0.6659\n","Epoch 11/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4873 - accuracy: 0.8618 - val_loss: 0.8058 - val_accuracy: 0.6272\n","Epoch 12/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4805 - accuracy: 0.8693 - val_loss: 0.8039 - val_accuracy: 0.6175\n","Epoch 13/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4938 - accuracy: 0.8607 - val_loss: 0.8300 - val_accuracy: 0.6045\n","Epoch 14/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4706 - accuracy: 0.8720 - val_loss: 0.7711 - val_accuracy: 0.6886\n","Epoch 15/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.4767 - accuracy: 0.8723 - val_loss: 0.7499 - val_accuracy: 0.6961\n","Epoch 16/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4727 - accuracy: 0.8742 - val_loss: 0.8026 - val_accuracy: 0.6519\n","Epoch 17/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4843 - accuracy: 0.8637 - val_loss: 0.7486 - val_accuracy: 0.7198\n","Epoch 18/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4712 - accuracy: 0.8742 - val_loss: 0.7528 - val_accuracy: 0.7069\n","Epoch 19/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.4703 - accuracy: 0.8734 - val_loss: 0.7210 - val_accuracy: 0.7446\n","Epoch 20/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4568 - accuracy: 0.8777 - val_loss: 0.7757 - val_accuracy: 0.6907\n","Epoch 21/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4691 - accuracy: 0.8747 - val_loss: 0.7176 - val_accuracy: 0.7468\n","Epoch 22/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4626 - accuracy: 0.8807 - val_loss: 0.7588 - val_accuracy: 0.7231\n","Epoch 23/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4704 - accuracy: 0.8645 - val_loss: 0.7413 - val_accuracy: 0.7554\n","Epoch 24/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4697 - accuracy: 0.8758 - val_loss: 0.7689 - val_accuracy: 0.7349\n","Epoch 25/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4669 - accuracy: 0.8699 - val_loss: 0.7537 - val_accuracy: 0.7522\n","Epoch 26/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4590 - accuracy: 0.8772 - val_loss: 0.7505 - val_accuracy: 0.7489\n","Epoch 27/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4612 - accuracy: 0.8755 - val_loss: 0.8310 - val_accuracy: 0.7209\n","Epoch 28/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4611 - accuracy: 0.8731 - val_loss: 0.8482 - val_accuracy: 0.7198\n","Epoch 29/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4512 - accuracy: 0.8817 - val_loss: 0.8344 - val_accuracy: 0.7188\n","Epoch 30/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4681 - accuracy: 0.8653 - val_loss: 0.7859 - val_accuracy: 0.7532\n","Epoch 31/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4560 - accuracy: 0.8720 - val_loss: 0.8474 - val_accuracy: 0.7220\n","Epoch 32/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4490 - accuracy: 0.8780 - val_loss: 0.8286 - val_accuracy: 0.7295\n","Epoch 33/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4483 - accuracy: 0.8836 - val_loss: 0.7954 - val_accuracy: 0.7511\n","Epoch 34/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4457 - accuracy: 0.8836 - val_loss: 0.8026 - val_accuracy: 0.7478\n","Epoch 35/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4348 - accuracy: 0.8863 - val_loss: 0.7924 - val_accuracy: 0.7511\n","Epoch 36/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4429 - accuracy: 0.8844 - val_loss: 0.8294 - val_accuracy: 0.7425\n","Epoch 37/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.4336 - accuracy: 0.8922 - val_loss: 0.8245 - val_accuracy: 0.7500\n","Epoch 38/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.4583 - accuracy: 0.8763 - val_loss: 0.9503 - val_accuracy: 0.7047\n","Epoch 39/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4424 - accuracy: 0.8866 - val_loss: 0.8643 - val_accuracy: 0.7338\n","Epoch 40/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4330 - accuracy: 0.8869 - val_loss: 0.8385 - val_accuracy: 0.7392\n","Epoch 41/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4351 - accuracy: 0.8895 - val_loss: 0.8352 - val_accuracy: 0.7392\n","Epoch 42/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4256 - accuracy: 0.8898 - val_loss: 0.8353 - val_accuracy: 0.7284\n","Epoch 43/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4304 - accuracy: 0.8866 - val_loss: 0.8369 - val_accuracy: 0.7425\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4238 - accuracy: 0.8939 - val_loss: 0.8562 - val_accuracy: 0.7446\n","Epoch 45/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4357 - accuracy: 0.8957 - val_loss: 0.8370 - val_accuracy: 0.7446\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4269 - accuracy: 0.8887 - val_loss: 0.9162 - val_accuracy: 0.7209\n","Epoch 47/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4154 - accuracy: 0.8992 - val_loss: 0.8833 - val_accuracy: 0.7004\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4214 - accuracy: 0.8904 - val_loss: 0.8547 - val_accuracy: 0.7317\n","Epoch 49/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4190 - accuracy: 0.8920 - val_loss: 0.8597 - val_accuracy: 0.7425\n","Epoch 50/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4144 - accuracy: 0.8979 - val_loss: 0.8593 - val_accuracy: 0.7435\n","Epoch 51/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4238 - accuracy: 0.8979 - val_loss: 0.8427 - val_accuracy: 0.7500\n","Epoch 52/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4244 - accuracy: 0.8933 - val_loss: 0.8790 - val_accuracy: 0.7468\n","Epoch 53/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4186 - accuracy: 0.8968 - val_loss: 0.8508 - val_accuracy: 0.7543\n","Epoch 54/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4133 - accuracy: 0.8933 - val_loss: 0.8507 - val_accuracy: 0.7435\n","Epoch 55/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4061 - accuracy: 0.8992 - val_loss: 0.8500 - val_accuracy: 0.7457\n","Epoch 56/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4093 - accuracy: 0.8990 - val_loss: 0.9027 - val_accuracy: 0.7220\n","Epoch 57/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4135 - accuracy: 0.8974 - val_loss: 0.8906 - val_accuracy: 0.7198\n","Epoch 58/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4129 - accuracy: 0.8947 - val_loss: 0.9662 - val_accuracy: 0.7069\n","Epoch 59/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4011 - accuracy: 0.9027 - val_loss: 0.8603 - val_accuracy: 0.7500\n","Epoch 60/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4007 - accuracy: 0.9052 - val_loss: 0.8706 - val_accuracy: 0.7425\n","Epoch 61/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.4049 - accuracy: 0.9009 - val_loss: 0.8903 - val_accuracy: 0.7198\n","Epoch 62/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3993 - accuracy: 0.9030 - val_loss: 0.8765 - val_accuracy: 0.7371\n","Epoch 63/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4028 - accuracy: 0.8992 - val_loss: 0.8736 - val_accuracy: 0.7414\n","Epoch 64/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.4014 - accuracy: 0.9065 - val_loss: 0.9037 - val_accuracy: 0.7446\n","Epoch 65/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.4043 - accuracy: 0.9044 - val_loss: 0.9257 - val_accuracy: 0.7295\n","Epoch 66/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3954 - accuracy: 0.9057 - val_loss: 0.8860 - val_accuracy: 0.7381\n","Epoch 67/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3914 - accuracy: 0.9065 - val_loss: 0.9576 - val_accuracy: 0.7155\n","Epoch 68/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3955 - accuracy: 0.8984 - val_loss: 0.8725 - val_accuracy: 0.7435\n","Epoch 69/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3842 - accuracy: 0.9060 - val_loss: 0.8819 - val_accuracy: 0.7414\n","Epoch 70/100\n","29/29 [==============================] - 1s 20ms/step - loss: 0.3876 - accuracy: 0.9068 - val_loss: 0.8787 - val_accuracy: 0.7468\n","Epoch 71/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3802 - accuracy: 0.9162 - val_loss: 0.9075 - val_accuracy: 0.7403\n","Epoch 72/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3807 - accuracy: 0.9098 - val_loss: 0.8842 - val_accuracy: 0.7446\n","Epoch 73/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3878 - accuracy: 0.9116 - val_loss: 0.8913 - val_accuracy: 0.7457\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3763 - accuracy: 0.9127 - val_loss: 0.9075 - val_accuracy: 0.7338\n","Epoch 75/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3824 - accuracy: 0.9116 - val_loss: 0.9152 - val_accuracy: 0.7435\n","Epoch 76/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3754 - accuracy: 0.9165 - val_loss: 0.9214 - val_accuracy: 0.7446\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3910 - accuracy: 0.9033 - val_loss: 0.9229 - val_accuracy: 0.7338\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3873 - accuracy: 0.9103 - val_loss: 0.9201 - val_accuracy: 0.7435\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3805 - accuracy: 0.9111 - val_loss: 0.9643 - val_accuracy: 0.7317\n","Epoch 80/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.4042 - accuracy: 0.8963 - val_loss: 1.1975 - val_accuracy: 0.6412\n","Epoch 81/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3839 - accuracy: 0.9092 - val_loss: 0.9062 - val_accuracy: 0.7435\n","Epoch 82/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3866 - accuracy: 0.9108 - val_loss: 0.9166 - val_accuracy: 0.7446\n","Epoch 83/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3844 - accuracy: 0.9068 - val_loss: 0.9958 - val_accuracy: 0.7198\n","Epoch 84/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3830 - accuracy: 0.9038 - val_loss: 0.9062 - val_accuracy: 0.7392\n","Epoch 85/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3953 - accuracy: 0.9006 - val_loss: 0.9547 - val_accuracy: 0.7403\n","Epoch 86/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3777 - accuracy: 0.9108 - val_loss: 0.9363 - val_accuracy: 0.7435\n","Epoch 87/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3679 - accuracy: 0.9151 - val_loss: 0.9436 - val_accuracy: 0.7435\n","Epoch 88/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3696 - accuracy: 0.9143 - val_loss: 0.9228 - val_accuracy: 0.7425\n","Epoch 89/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3570 - accuracy: 0.9205 - val_loss: 0.9186 - val_accuracy: 0.7446\n","Epoch 90/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3598 - accuracy: 0.9213 - val_loss: 0.9328 - val_accuracy: 0.7274\n","Epoch 91/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3613 - accuracy: 0.9195 - val_loss: 1.0323 - val_accuracy: 0.7177\n","Epoch 92/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3657 - accuracy: 0.9165 - val_loss: 0.9401 - val_accuracy: 0.7381\n","Epoch 93/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3592 - accuracy: 0.9170 - val_loss: 0.9359 - val_accuracy: 0.7489\n","Epoch 94/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3606 - accuracy: 0.9159 - val_loss: 0.9691 - val_accuracy: 0.7328\n","Epoch 95/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3570 - accuracy: 0.9170 - val_loss: 0.9763 - val_accuracy: 0.7414\n","Epoch 96/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3602 - accuracy: 0.9213 - val_loss: 0.9743 - val_accuracy: 0.7134\n","Epoch 97/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3549 - accuracy: 0.9235 - val_loss: 1.0096 - val_accuracy: 0.7371\n","Epoch 98/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3566 - accuracy: 0.9203 - val_loss: 0.9556 - val_accuracy: 0.7468\n","Epoch 99/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3477 - accuracy: 0.9270 - val_loss: 0.9999 - val_accuracy: 0.7241\n","Epoch 100/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3551 - accuracy: 0.9240 - val_loss: 1.0596 - val_accuracy: 0.7058\n","{'loss': [0.5425313711166382, 0.5182780027389526, 0.5116515159606934, 0.5079079270362854, 0.5032275915145874, 0.5068731904029846, 0.5009496212005615, 0.49761784076690674, 0.4950658082962036, 0.49275365471839905, 0.48727068305015564, 0.4805110991001129, 0.49378445744514465, 0.4705584943294525, 0.4767439067363739, 0.4727495014667511, 0.4843282997608185, 0.4712035059928894, 0.47026315331459045, 0.45678794384002686, 0.46908119320869446, 0.4625526964664459, 0.47039857506752014, 0.469684362411499, 0.46691644191741943, 0.4589698314666748, 0.4611952304840088, 0.461143434047699, 0.45121708512306213, 0.4681428074836731, 0.4560304880142212, 0.4489503800868988, 0.4482565224170685, 0.4457058310508728, 0.4348379075527191, 0.4429428279399872, 0.4335938096046448, 0.45826107263565063, 0.4423564672470093, 0.4329802989959717, 0.43511372804641724, 0.4255826771259308, 0.43037012219429016, 0.423846572637558, 0.435729444026947, 0.4268602132797241, 0.415424644947052, 0.4214090406894684, 0.4189866781234741, 0.4144468605518341, 0.4238017797470093, 0.42437979578971863, 0.4185855984687805, 0.4132560193538666, 0.4060783088207245, 0.4092937111854553, 0.41353729367256165, 0.41289404034614563, 0.40112626552581787, 0.4007180631160736, 0.40491703152656555, 0.39931195974349976, 0.4028129577636719, 0.40139397978782654, 0.4042830169200897, 0.3954068422317505, 0.3913765847682953, 0.39551231265068054, 0.3842140734195709, 0.38760673999786377, 0.3802380859851837, 0.3807165324687958, 0.38779112696647644, 0.37629932165145874, 0.38235726952552795, 0.37542861700057983, 0.3910241425037384, 0.38732948899269104, 0.3805381953716278, 0.40417996048927307, 0.3839164972305298, 0.3866414725780487, 0.3844214677810669, 0.38295942544937134, 0.3953067660331726, 0.37767159938812256, 0.367876797914505, 0.3695518970489502, 0.35702672600746155, 0.35977861285209656, 0.361345112323761, 0.3656808137893677, 0.3592035174369812, 0.36059892177581787, 0.35698992013931274, 0.3601633310317993, 0.3548735976219177, 0.3566432595252991, 0.34772273898124695, 0.35514265298843384], 'accuracy': [0.8399784564971924, 0.853178858757019, 0.8515625, 0.853178858757019, 0.8572198152542114, 0.8523706793785095, 0.8539870977401733, 0.860991358757019, 0.8585668206214905, 0.8601831793785095, 0.8617995977401733, 0.8693426847457886, 0.860722005367279, 0.8720366358757019, 0.8723060488700867, 0.8741918206214905, 0.8636853694915771, 0.8741918206214905, 0.873383641242981, 0.8776939511299133, 0.8747305870056152, 0.8806573152542114, 0.8644935488700867, 0.8758081793785095, 0.8698814511299133, 0.8771551847457886, 0.8755387663841248, 0.8731142282485962, 0.8817349076271057, 0.8653017282485962, 0.8720366358757019, 0.8779633641242981, 0.8836206793785095, 0.8836206793785095, 0.8863146305084229, 0.884428858757019, 0.892241358757019, 0.876347005367279, 0.8865840435028076, 0.8868534564971924, 0.8895474076271057, 0.8898168206214905, 0.8865840435028076, 0.8938577771186829, 0.8957435488700867, 0.8887392282485962, 0.8992456793785095, 0.8903555870056152, 0.891972005367279, 0.8978987336158752, 0.8978987336158752, 0.8933189511299133, 0.896821141242981, 0.8933189511299133, 0.8992456793785095, 0.8989762663841248, 0.8973599076271057, 0.8946659564971924, 0.9027478694915771, 0.9051724076271057, 0.9008620977401733, 0.9030172228813171, 0.8992456793785095, 0.9065194129943848, 0.9043642282485962, 0.9057112336158752, 0.9065194129943848, 0.8984375, 0.9059805870056152, 0.9067887663841248, 0.9162176847457886, 0.9097521305084229, 0.9116379022598267, 0.912715494632721, 0.9116379022598267, 0.9164870977401733, 0.9032866358757019, 0.9102909564971924, 0.9110991358757019, 0.8962823152542114, 0.9092133641242981, 0.9108297228813171, 0.9067887663841248, 0.9038254022598267, 0.9005926847457886, 0.9108297228813171, 0.9151400923728943, 0.9143319129943848, 0.920527994632721, 0.9213362336158752, 0.9194504022598267, 0.9164870977401733, 0.9170258641242981, 0.9159482717514038, 0.9170258641242981, 0.9213362336158752, 0.923491358757019, 0.920258641242981, 0.9269935488700867, 0.9240301847457886], 'val_loss': [0.9098541736602783, 0.8885035514831543, 0.8916319012641907, 0.8990310430526733, 0.9118603467941284, 0.8507862687110901, 0.8337719440460205, 0.8462477326393127, 0.8174064755439758, 0.8062611222267151, 0.8058413863182068, 0.8039208650588989, 0.8300431966781616, 0.7711055874824524, 0.7499304413795471, 0.8025822043418884, 0.7486171722412109, 0.7527897953987122, 0.7210403084754944, 0.775672197341919, 0.7176177501678467, 0.7587766051292419, 0.7413001656532288, 0.7688742280006409, 0.7536981701850891, 0.750461220741272, 0.8310283422470093, 0.848168134689331, 0.8343542814254761, 0.7859236001968384, 0.8473765850067139, 0.8285754919052124, 0.795393168926239, 0.8025698661804199, 0.7923554182052612, 0.8294402360916138, 0.8245024681091309, 0.9503482580184937, 0.8643259406089783, 0.8384814858436584, 0.835247278213501, 0.8353288173675537, 0.8369435667991638, 0.8561904430389404, 0.8369998931884766, 0.9162405729293823, 0.8833295702934265, 0.8546997308731079, 0.8597421050071716, 0.859329104423523, 0.8426814675331116, 0.8789807558059692, 0.8507994413375854, 0.8507251739501953, 0.8499942421913147, 0.9026668071746826, 0.8905751705169678, 0.9662305116653442, 0.8602582812309265, 0.8705598711967468, 0.8903346657752991, 0.8764803409576416, 0.8735835552215576, 0.9036897420883179, 0.9256654381752014, 0.8860021829605103, 0.9576403498649597, 0.8725079894065857, 0.8819140195846558, 0.8786588311195374, 0.90754234790802, 0.8842138051986694, 0.8913245797157288, 0.9075177311897278, 0.9151567816734314, 0.9214341640472412, 0.9228764772415161, 0.9200982451438904, 0.964311420917511, 1.1975359916687012, 0.9061650633811951, 0.9166299104690552, 0.9958243370056152, 0.9062221646308899, 0.9546928405761719, 0.9362911581993103, 0.9436319470405579, 0.9227502942085266, 0.9186155200004578, 0.9328190088272095, 1.0323349237442017, 0.9400612115859985, 0.9358827471733093, 0.9691352248191833, 0.9763107895851135, 0.9742720127105713, 1.009604573249817, 0.9555990099906921, 0.9999197721481323, 1.0596215724945068], 'val_accuracy': [0.5193965435028076, 0.5258620977401733, 0.5269396305084229, 0.5269396305084229, 0.53125, 0.5603448152542114, 0.6066810488700867, 0.5711206793785095, 0.6519396305084229, 0.6659482717514038, 0.6271551847457886, 0.6174569129943848, 0.6045258641242981, 0.6885775923728943, 0.6961206793785095, 0.6519396305084229, 0.7198275923728943, 0.7068965435028076, 0.7446120977401733, 0.6907327771186829, 0.7467672228813171, 0.7230603694915771, 0.7553879022598267, 0.7349137663841248, 0.7521551847457886, 0.7489224076271057, 0.7209051847457886, 0.7198275923728943, 0.71875, 0.7532327771186829, 0.7219827771186829, 0.7295258641242981, 0.7510775923728943, 0.7478448152542114, 0.7510775923728943, 0.7424569129943848, 0.75, 0.704741358757019, 0.7338362336158752, 0.7392241358757019, 0.7392241358757019, 0.7284482717514038, 0.7424569129943848, 0.7446120977401733, 0.7446120977401733, 0.7209051847457886, 0.7004310488700867, 0.7316810488700867, 0.7424569129943848, 0.743534505367279, 0.75, 0.7467672228813171, 0.7543103694915771, 0.743534505367279, 0.7456896305084229, 0.7219827771186829, 0.7198275923728943, 0.7068965435028076, 0.75, 0.7424569129943848, 0.7198275923728943, 0.7370689511299133, 0.7413793206214905, 0.7446120977401733, 0.7295258641242981, 0.7381465435028076, 0.7155172228813171, 0.743534505367279, 0.7413793206214905, 0.7467672228813171, 0.7403017282485962, 0.7446120977401733, 0.7456896305084229, 0.7338362336158752, 0.743534505367279, 0.7446120977401733, 0.7338362336158752, 0.743534505367279, 0.7316810488700867, 0.6411637663841248, 0.743534505367279, 0.7446120977401733, 0.7198275923728943, 0.7392241358757019, 0.7403017282485962, 0.743534505367279, 0.743534505367279, 0.7424569129943848, 0.7446120977401733, 0.7273706793785095, 0.7176724076271057, 0.7381465435028076, 0.7489224076271057, 0.732758641242981, 0.7413793206214905, 0.7133620977401733, 0.7370689511299133, 0.7467672228813171, 0.7241379022598267, 0.7058189511299133]}\n","38/38 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","27/28 [===========================>..] - ETA: 0s - loss: 0.5454 - accuracy: 0.8290"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 9s 55ms/step - loss: 0.5440 - accuracy: 0.8302 - val_loss: 0.9181 - val_accuracy: 0.5068\n","Epoch 2/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5265 - accuracy: 0.8415 - val_loss: 0.8964 - val_accuracy: 0.5113\n","Epoch 3/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5314 - accuracy: 0.8376 - val_loss: 0.8710 - val_accuracy: 0.5294\n","Epoch 4/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5218 - accuracy: 0.8401 - val_loss: 0.8715 - val_accuracy: 0.5294\n","Epoch 5/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5123 - accuracy: 0.8565 - val_loss: 0.8771 - val_accuracy: 0.5305\n","Epoch 6/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5219 - accuracy: 0.8407 - val_loss: 0.8463 - val_accuracy: 0.5667\n","Epoch 7/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5117 - accuracy: 0.8529 - val_loss: 0.8770 - val_accuracy: 0.5385\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4967 - accuracy: 0.8582 - val_loss: 0.8548 - val_accuracy: 0.5611\n","Epoch 9/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.5046 - accuracy: 0.8534 - val_loss: 0.8171 - val_accuracy: 0.6425\n","Epoch 10/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.4986 - accuracy: 0.8571 - val_loss: 0.8075 - val_accuracy: 0.6719\n","Epoch 11/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4938 - accuracy: 0.8568 - val_loss: 0.8109 - val_accuracy: 0.6471\n","Epoch 12/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.4991 - accuracy: 0.8492 - val_loss: 0.7954 - val_accuracy: 0.6810\n","Epoch 13/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4963 - accuracy: 0.8613 - val_loss: 0.8031 - val_accuracy: 0.6437\n","Epoch 14/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5011 - accuracy: 0.8551 - val_loss: 0.7920 - val_accuracy: 0.6719\n","Epoch 15/100\n","28/28 [==============================] - 1s 30ms/step - loss: 0.5055 - accuracy: 0.8475 - val_loss: 0.7306 - val_accuracy: 0.7319\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4892 - accuracy: 0.8594 - val_loss: 0.7396 - val_accuracy: 0.7036\n","Epoch 17/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4889 - accuracy: 0.8647 - val_loss: 0.7275 - val_accuracy: 0.7285\n","Epoch 18/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4877 - accuracy: 0.8588 - val_loss: 0.7369 - val_accuracy: 0.7251\n","Epoch 19/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4852 - accuracy: 0.8639 - val_loss: 0.7123 - val_accuracy: 0.7364\n","Epoch 20/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4776 - accuracy: 0.8659 - val_loss: 0.7609 - val_accuracy: 0.6968\n","Epoch 21/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4841 - accuracy: 0.8594 - val_loss: 0.7089 - val_accuracy: 0.7296\n","Epoch 22/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4916 - accuracy: 0.8580 - val_loss: 0.7198 - val_accuracy: 0.7048\n","Epoch 23/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4813 - accuracy: 0.8656 - val_loss: 0.6922 - val_accuracy: 0.7568\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4745 - accuracy: 0.8645 - val_loss: 0.7057 - val_accuracy: 0.7376\n","Epoch 25/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4707 - accuracy: 0.8687 - val_loss: 0.6935 - val_accuracy: 0.7466\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4744 - accuracy: 0.8670 - val_loss: 0.7104 - val_accuracy: 0.7477\n","Epoch 27/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4733 - accuracy: 0.8594 - val_loss: 0.7101 - val_accuracy: 0.7466\n","Epoch 28/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4673 - accuracy: 0.8738 - val_loss: 0.7177 - val_accuracy: 0.7534\n","Epoch 29/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4628 - accuracy: 0.8735 - val_loss: 0.7387 - val_accuracy: 0.7274\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4618 - accuracy: 0.8752 - val_loss: 0.7590 - val_accuracy: 0.7183\n","Epoch 31/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4629 - accuracy: 0.8738 - val_loss: 0.7812 - val_accuracy: 0.7070\n","Epoch 32/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4685 - accuracy: 0.8693 - val_loss: 0.7353 - val_accuracy: 0.7443\n","Epoch 33/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4680 - accuracy: 0.8749 - val_loss: 0.7318 - val_accuracy: 0.7421\n","Epoch 34/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4565 - accuracy: 0.8746 - val_loss: 0.7467 - val_accuracy: 0.7534\n","Epoch 35/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4440 - accuracy: 0.8829 - val_loss: 0.7338 - val_accuracy: 0.7421\n","Epoch 36/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4578 - accuracy: 0.8729 - val_loss: 0.8123 - val_accuracy: 0.7093\n","Epoch 37/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4488 - accuracy: 0.8778 - val_loss: 0.7719 - val_accuracy: 0.7534\n","Epoch 38/100\n","28/28 [==============================] - 1s 22ms/step - loss: 0.4476 - accuracy: 0.8840 - val_loss: 0.7493 - val_accuracy: 0.7511\n","Epoch 39/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4446 - accuracy: 0.8789 - val_loss: 0.7568 - val_accuracy: 0.7489\n","Epoch 40/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4451 - accuracy: 0.8803 - val_loss: 0.7505 - val_accuracy: 0.7443\n","Epoch 41/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4553 - accuracy: 0.8718 - val_loss: 0.7589 - val_accuracy: 0.7500\n","Epoch 42/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.4480 - accuracy: 0.8795 - val_loss: 0.7598 - val_accuracy: 0.7455\n","Epoch 43/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4337 - accuracy: 0.8831 - val_loss: 0.7792 - val_accuracy: 0.7568\n","Epoch 44/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4395 - accuracy: 0.8820 - val_loss: 0.7948 - val_accuracy: 0.7308\n","Epoch 45/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4375 - accuracy: 0.8851 - val_loss: 0.7812 - val_accuracy: 0.7285\n","Epoch 46/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4372 - accuracy: 0.8834 - val_loss: 0.8337 - val_accuracy: 0.6934\n","Epoch 47/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4354 - accuracy: 0.8862 - val_loss: 0.7708 - val_accuracy: 0.7274\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4394 - accuracy: 0.8812 - val_loss: 0.7674 - val_accuracy: 0.7511\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4460 - accuracy: 0.8761 - val_loss: 0.7841 - val_accuracy: 0.7330\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4391 - accuracy: 0.8891 - val_loss: 0.7918 - val_accuracy: 0.7500\n","Epoch 51/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4489 - accuracy: 0.8843 - val_loss: 0.7842 - val_accuracy: 0.7342\n","Epoch 52/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4280 - accuracy: 0.8885 - val_loss: 0.7838 - val_accuracy: 0.7534\n","Epoch 53/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4269 - accuracy: 0.8857 - val_loss: 0.7862 - val_accuracy: 0.7432\n","Epoch 54/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4271 - accuracy: 0.8795 - val_loss: 0.7788 - val_accuracy: 0.7443\n","Epoch 55/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4299 - accuracy: 0.8885 - val_loss: 0.7676 - val_accuracy: 0.7443\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4222 - accuracy: 0.8837 - val_loss: 0.7765 - val_accuracy: 0.7398\n","Epoch 57/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4171 - accuracy: 0.8905 - val_loss: 0.7760 - val_accuracy: 0.7545\n","Epoch 58/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4142 - accuracy: 0.8945 - val_loss: 0.8205 - val_accuracy: 0.7455\n","Epoch 59/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4153 - accuracy: 0.8950 - val_loss: 0.7881 - val_accuracy: 0.7376\n","Epoch 60/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4291 - accuracy: 0.8913 - val_loss: 0.7818 - val_accuracy: 0.7489\n","Epoch 61/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4379 - accuracy: 0.8763 - val_loss: 0.7940 - val_accuracy: 0.7398\n","Epoch 62/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4159 - accuracy: 0.8945 - val_loss: 0.8108 - val_accuracy: 0.7229\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4264 - accuracy: 0.8857 - val_loss: 0.8077 - val_accuracy: 0.7534\n","Epoch 64/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4155 - accuracy: 0.8902 - val_loss: 0.7932 - val_accuracy: 0.7251\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4130 - accuracy: 0.8911 - val_loss: 0.7716 - val_accuracy: 0.7455\n","Epoch 66/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4015 - accuracy: 0.9032 - val_loss: 0.7919 - val_accuracy: 0.7376\n","Epoch 67/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4042 - accuracy: 0.9004 - val_loss: 0.8072 - val_accuracy: 0.7477\n","Epoch 68/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4068 - accuracy: 0.8942 - val_loss: 0.8067 - val_accuracy: 0.7262\n","Epoch 69/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4013 - accuracy: 0.9018 - val_loss: 0.8054 - val_accuracy: 0.7308\n","Epoch 70/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4019 - accuracy: 0.8987 - val_loss: 0.8077 - val_accuracy: 0.7330\n","Epoch 71/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4056 - accuracy: 0.8993 - val_loss: 0.9514 - val_accuracy: 0.7149\n","Epoch 72/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.4072 - accuracy: 0.8987 - val_loss: 0.8449 - val_accuracy: 0.7240\n","Epoch 73/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4007 - accuracy: 0.8953 - val_loss: 0.8350 - val_accuracy: 0.7398\n","Epoch 74/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.4000 - accuracy: 0.9052 - val_loss: 0.8801 - val_accuracy: 0.7070\n","Epoch 75/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3905 - accuracy: 0.9032 - val_loss: 0.8848 - val_accuracy: 0.7025\n","Epoch 76/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3937 - accuracy: 0.9038 - val_loss: 0.9118 - val_accuracy: 0.6912\n","Epoch 77/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3942 - accuracy: 0.8967 - val_loss: 0.8349 - val_accuracy: 0.7251\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3859 - accuracy: 0.9032 - val_loss: 0.8459 - val_accuracy: 0.7489\n","Epoch 79/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3950 - accuracy: 0.9032 - val_loss: 0.8321 - val_accuracy: 0.7342\n","Epoch 80/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3953 - accuracy: 0.8993 - val_loss: 0.8775 - val_accuracy: 0.7070\n","Epoch 81/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3897 - accuracy: 0.9035 - val_loss: 0.8445 - val_accuracy: 0.7432\n","Epoch 82/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3998 - accuracy: 0.8973 - val_loss: 0.9295 - val_accuracy: 0.6923\n","Epoch 83/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3871 - accuracy: 0.9027 - val_loss: 0.8399 - val_accuracy: 0.7319\n","Epoch 84/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3839 - accuracy: 0.9058 - val_loss: 0.8481 - val_accuracy: 0.7319\n","Epoch 85/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3891 - accuracy: 0.9012 - val_loss: 0.8735 - val_accuracy: 0.7093\n","Epoch 86/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3735 - accuracy: 0.9095 - val_loss: 0.8486 - val_accuracy: 0.7319\n","Epoch 87/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3868 - accuracy: 0.9010 - val_loss: 0.8544 - val_accuracy: 0.7443\n","Epoch 88/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3789 - accuracy: 0.9063 - val_loss: 0.8681 - val_accuracy: 0.7523\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3828 - accuracy: 0.9027 - val_loss: 0.8438 - val_accuracy: 0.7387\n","Epoch 90/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3688 - accuracy: 0.9126 - val_loss: 0.8404 - val_accuracy: 0.7364\n","Epoch 91/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3724 - accuracy: 0.9114 - val_loss: 0.8310 - val_accuracy: 0.7342\n","Epoch 92/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3684 - accuracy: 0.9089 - val_loss: 0.8611 - val_accuracy: 0.7195\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3661 - accuracy: 0.9174 - val_loss: 0.8675 - val_accuracy: 0.7466\n","Epoch 94/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3788 - accuracy: 0.9063 - val_loss: 0.8872 - val_accuracy: 0.7240\n","Epoch 95/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3678 - accuracy: 0.9160 - val_loss: 0.8586 - val_accuracy: 0.7240\n","Epoch 96/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3717 - accuracy: 0.9103 - val_loss: 0.9258 - val_accuracy: 0.7410\n","Epoch 97/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3807 - accuracy: 0.9046 - val_loss: 0.8704 - val_accuracy: 0.7432\n","Epoch 98/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3833 - accuracy: 0.9041 - val_loss: 0.8519 - val_accuracy: 0.7477\n","Epoch 99/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3721 - accuracy: 0.9035 - val_loss: 0.8830 - val_accuracy: 0.7229\n","Epoch 100/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3747 - accuracy: 0.9134 - val_loss: 0.9360 - val_accuracy: 0.7183\n","{'loss': [0.5440039038658142, 0.5265031456947327, 0.5313908457756042, 0.5217577815055847, 0.5123380422592163, 0.521897554397583, 0.5116956233978271, 0.4966762661933899, 0.5046279430389404, 0.49859169125556946, 0.4938165545463562, 0.4991256594657898, 0.49631211161613464, 0.5011394023895264, 0.505530059337616, 0.489177942276001, 0.48890045285224915, 0.4876508414745331, 0.4851507842540741, 0.47757747769355774, 0.4841286242008209, 0.49162623286247253, 0.4812753200531006, 0.4745054841041565, 0.4707320034503937, 0.47440099716186523, 0.47330838441848755, 0.46728381514549255, 0.4628298878669739, 0.46180322766304016, 0.46291643381118774, 0.468456506729126, 0.46795329451560974, 0.4564715325832367, 0.44399622082710266, 0.45783093571662903, 0.44878947734832764, 0.44760018587112427, 0.44459953904151917, 0.4450725317001343, 0.45534950494766235, 0.44797107577323914, 0.43371453881263733, 0.43945568799972534, 0.4374982714653015, 0.43719810247421265, 0.4353904724121094, 0.43939054012298584, 0.4459993243217468, 0.43911370635032654, 0.44891610741615295, 0.42798203229904175, 0.4268943965435028, 0.4271428883075714, 0.4299367666244507, 0.4222041368484497, 0.4170658588409424, 0.41416922211647034, 0.41525131464004517, 0.42907553911209106, 0.43789660930633545, 0.41592568159103394, 0.4263589382171631, 0.4155474901199341, 0.41295352578163147, 0.40148505568504333, 0.40421760082244873, 0.4068368971347809, 0.4012790322303772, 0.4019222855567932, 0.40560343861579895, 0.4071796238422394, 0.40071630477905273, 0.4000113904476166, 0.3905443251132965, 0.3936845362186432, 0.39417755603790283, 0.38594815135002136, 0.39500826597213745, 0.39532971382141113, 0.3897199332714081, 0.3997684717178345, 0.3870828151702881, 0.38390353322029114, 0.38907918334007263, 0.37350502610206604, 0.386761337518692, 0.3788623511791229, 0.3828451633453369, 0.36880457401275635, 0.37235748767852783, 0.3684197962284088, 0.3661316931247711, 0.37882521748542786, 0.3677918016910553, 0.37165123224258423, 0.380689799785614, 0.3833073377609253, 0.3720989227294922, 0.3747287690639496], 'accuracy': [0.8302206993103027, 0.8415393233299255, 0.8375778198242188, 0.8401244878768921, 0.8565365076065063, 0.8406904339790344, 0.8528579473495483, 0.8582342863082886, 0.8534238934516907, 0.8571024537086487, 0.8568194508552551, 0.8491793870925903, 0.8613469004631042, 0.8551216721534729, 0.8474816083908081, 0.8593661785125732, 0.8647425174713135, 0.8588002324104309, 0.8638936281204224, 0.8658743500709534, 0.8593661785125732, 0.8579513430595398, 0.8655914068222046, 0.8644595146179199, 0.8687040209770203, 0.867006242275238, 0.8593661785125732, 0.8737974166870117, 0.8735144138336182, 0.8752122521400452, 0.8737974166870117, 0.8692699670791626, 0.8749292492866516, 0.8746463060379028, 0.88285231590271, 0.8729485273361206, 0.8777589201927185, 0.8839841485023499, 0.8788907527923584, 0.8803055882453918, 0.8718166351318359, 0.8794566988945007, 0.8831352591514587, 0.8820033669471741, 0.8851160407066345, 0.8834182024002075, 0.8862478733062744, 0.881154477596283, 0.8760611414909363, 0.8890775442123413, 0.8842670917510986, 0.888511598110199, 0.8856819272041321, 0.8794566988945007, 0.888511598110199, 0.8837012052536011, 0.8904923796653748, 0.8944538831710815, 0.8950198292732239, 0.8913412690162659, 0.8763440847396851, 0.8944538831710815, 0.8856819272041321, 0.8902093768119812, 0.8910582661628723, 0.9032257795333862, 0.9003961682319641, 0.8941709399223328, 0.9018110036849976, 0.8986983299255371, 0.8992642760276794, 0.8986983299255371, 0.8953027725219727, 0.905206561088562, 0.9032257795333862, 0.9037917256355286, 0.8967176079750061, 0.9032257795333862, 0.9032257795333862, 0.8992642760276794, 0.9035087823867798, 0.8972835540771484, 0.9026598930358887, 0.9057725071907043, 0.9012450575828552, 0.9094510674476624, 0.9009620547294617, 0.9063384532928467, 0.9026598930358887, 0.912563681602478, 0.9114317893981934, 0.90888512134552, 0.9173740744590759, 0.9063384532928467, 0.9159592390060425, 0.9102999567985535, 0.9046406149864197, 0.9040747284889221, 0.9035087823867798, 0.9134125709533691], 'val_loss': [0.9181000590324402, 0.8963621258735657, 0.8710314631462097, 0.8714612722396851, 0.8770650625228882, 0.846301257610321, 0.8770153522491455, 0.8547587394714355, 0.8170790672302246, 0.8075418472290039, 0.8109475374221802, 0.7954479455947876, 0.8030513525009155, 0.7920336723327637, 0.7305529713630676, 0.7396209239959717, 0.7274859547615051, 0.7368909120559692, 0.7123367786407471, 0.7608698010444641, 0.7089027762413025, 0.7197889089584351, 0.6922057867050171, 0.7057464718818665, 0.6934608221054077, 0.710437536239624, 0.7101487517356873, 0.7177413105964661, 0.7387461066246033, 0.7590399980545044, 0.7812403440475464, 0.7352540493011475, 0.7318149209022522, 0.7467302083969116, 0.7338300943374634, 0.8123490214347839, 0.7719024419784546, 0.7492536306381226, 0.7568398714065552, 0.7505110502243042, 0.7589008212089539, 0.759841799736023, 0.7792128920555115, 0.7948137521743774, 0.7811569571495056, 0.8337488174438477, 0.7707680463790894, 0.7673698663711548, 0.784098207950592, 0.7917872667312622, 0.7842103242874146, 0.7837910652160645, 0.7861920595169067, 0.7788220643997192, 0.7675544023513794, 0.7764914631843567, 0.7760374546051025, 0.8205193281173706, 0.788077175617218, 0.781846284866333, 0.7940168976783752, 0.8107919692993164, 0.8076635003089905, 0.7931568026542664, 0.7715531587600708, 0.7919450998306274, 0.8071506023406982, 0.8066798448562622, 0.8053780794143677, 0.8076812624931335, 0.9514169692993164, 0.8449339270591736, 0.8350138664245605, 0.8800594210624695, 0.8848105669021606, 0.9117825627326965, 0.8348961472511292, 0.8458855152130127, 0.8320544958114624, 0.877526044845581, 0.8445433378219604, 0.9295140504837036, 0.8399186134338379, 0.8481392860412598, 0.8735069632530212, 0.8486078381538391, 0.8544398546218872, 0.8680840134620667, 0.8438133597373962, 0.8404051065444946, 0.8309566974639893, 0.8611176013946533, 0.8674968481063843, 0.8871660232543945, 0.8585502505302429, 0.925777792930603, 0.8703590035438538, 0.851925790309906, 0.8830260038375854, 0.9359925389289856], 'val_accuracy': [0.5067873597145081, 0.5113122463226318, 0.529411792755127, 0.529411792755127, 0.5305429697036743, 0.5667420625686646, 0.5384615659713745, 0.5610859990119934, 0.6425339579582214, 0.6719456911087036, 0.6470588445663452, 0.6809954643249512, 0.6436651349067688, 0.6719456911087036, 0.7319004535675049, 0.7036198973655701, 0.7285068035125732, 0.7251130938529968, 0.7364253401756287, 0.6968325972557068, 0.7296379804611206, 0.7047511339187622, 0.7567873597145081, 0.7375565767288208, 0.7466063499450684, 0.7477375268936157, 0.7466063499450684, 0.7533936500549316, 0.7273755669593811, 0.7183257937431335, 0.7070135474205017, 0.7443438768386841, 0.7420814633369446, 0.7533936500549316, 0.7420814633369446, 0.709276020526886, 0.7533936500549316, 0.7511312365531921, 0.7488687634468079, 0.7443438768386841, 0.75, 0.7454751133918762, 0.7567873597145081, 0.7307692170143127, 0.7285068035125732, 0.6934388875961304, 0.7273755669593811, 0.7511312365531921, 0.733031690120697, 0.75, 0.7341628670692444, 0.7533936500549316, 0.7432126402854919, 0.7443438768386841, 0.7443438768386841, 0.7398189902305603, 0.7545248866081238, 0.7454751133918762, 0.7375565767288208, 0.7488687634468079, 0.7398189902305603, 0.7228506803512573, 0.7533936500549316, 0.7251130938529968, 0.7454751133918762, 0.7375565767288208, 0.7477375268936157, 0.726244330406189, 0.7307692170143127, 0.733031690120697, 0.7149321436882019, 0.7239819169044495, 0.7398189902305603, 0.7070135474205017, 0.7024886608123779, 0.6911764740943909, 0.7251130938529968, 0.7488687634468079, 0.7341628670692444, 0.7070135474205017, 0.7432126402854919, 0.692307710647583, 0.7319004535675049, 0.7319004535675049, 0.709276020526886, 0.7319004535675049, 0.7443438768386841, 0.7522624731063843, 0.7386877536773682, 0.7364253401756287, 0.7341628670692444, 0.7194570302963257, 0.7466063499450684, 0.7239819169044495, 0.7239819169044495, 0.7409502267837524, 0.7432126402854919, 0.7477375268936157, 0.7228506803512573, 0.7183257937431335]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","31/31 [==============================] - 8s 53ms/step - loss: 0.5421 - accuracy: 0.8403 - val_loss: 0.9527 - val_accuracy: 0.5165\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 2/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5351 - accuracy: 0.8370 - val_loss: 0.8976 - val_accuracy: 0.5248\n","Epoch 3/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.5321 - accuracy: 0.8432 - val_loss: 0.8982 - val_accuracy: 0.5258\n","Epoch 4/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5288 - accuracy: 0.8377 - val_loss: 0.8659 - val_accuracy: 0.5424\n","Epoch 5/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.5147 - accuracy: 0.8525 - val_loss: 0.8815 - val_accuracy: 0.5372\n","Epoch 6/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5233 - accuracy: 0.8465 - val_loss: 0.8419 - val_accuracy: 0.5651\n","Epoch 7/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.5090 - accuracy: 0.8522 - val_loss: 0.8677 - val_accuracy: 0.5558\n","Epoch 8/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5040 - accuracy: 0.8602 - val_loss: 0.8278 - val_accuracy: 0.6043\n","Epoch 9/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.5203 - accuracy: 0.8416 - val_loss: 0.8648 - val_accuracy: 0.5671\n","Epoch 10/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5042 - accuracy: 0.8561 - val_loss: 0.8290 - val_accuracy: 0.6043\n","Epoch 11/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.5019 - accuracy: 0.8571 - val_loss: 0.8004 - val_accuracy: 0.6477\n","Epoch 12/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5083 - accuracy: 0.8512 - val_loss: 0.8368 - val_accuracy: 0.6074\n","Epoch 13/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.5018 - accuracy: 0.8496 - val_loss: 0.7961 - val_accuracy: 0.6622\n","Epoch 14/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.5065 - accuracy: 0.8556 - val_loss: 0.7555 - val_accuracy: 0.6932\n","Epoch 15/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.5041 - accuracy: 0.8481 - val_loss: 0.7660 - val_accuracy: 0.6870\n","Epoch 16/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4930 - accuracy: 0.8594 - val_loss: 0.7478 - val_accuracy: 0.7118\n","Epoch 17/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4896 - accuracy: 0.8659 - val_loss: 0.7404 - val_accuracy: 0.7221\n","Epoch 18/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4937 - accuracy: 0.8571 - val_loss: 0.7516 - val_accuracy: 0.7128\n","Epoch 19/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4880 - accuracy: 0.8592 - val_loss: 0.7584 - val_accuracy: 0.7190\n","Epoch 20/100\n","31/31 [==============================] - 1s 26ms/step - loss: 0.4838 - accuracy: 0.8620 - val_loss: 0.7413 - val_accuracy: 0.7283\n","Epoch 21/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4842 - accuracy: 0.8680 - val_loss: 0.8069 - val_accuracy: 0.7097\n","Epoch 22/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4795 - accuracy: 0.8615 - val_loss: 0.7514 - val_accuracy: 0.7211\n","Epoch 23/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4769 - accuracy: 0.8693 - val_loss: 0.7729 - val_accuracy: 0.7273\n","Epoch 24/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4745 - accuracy: 0.8674 - val_loss: 0.7883 - val_accuracy: 0.7190\n","Epoch 25/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4903 - accuracy: 0.8630 - val_loss: 0.7899 - val_accuracy: 0.7159\n","Epoch 26/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4746 - accuracy: 0.8690 - val_loss: 0.8187 - val_accuracy: 0.7252\n","Epoch 27/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4719 - accuracy: 0.8690 - val_loss: 0.7972 - val_accuracy: 0.7190\n","Epoch 28/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.5023 - accuracy: 0.8594 - val_loss: 0.8305 - val_accuracy: 0.7169\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4759 - accuracy: 0.8700 - val_loss: 0.8205 - val_accuracy: 0.7231\n","Epoch 30/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.4785 - accuracy: 0.8638 - val_loss: 0.8456 - val_accuracy: 0.7293\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4700 - accuracy: 0.8700 - val_loss: 0.8414 - val_accuracy: 0.7118\n","Epoch 32/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4664 - accuracy: 0.8804 - val_loss: 0.8597 - val_accuracy: 0.7262\n","Epoch 33/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4686 - accuracy: 0.8736 - val_loss: 0.9249 - val_accuracy: 0.7128\n","Epoch 34/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4614 - accuracy: 0.8705 - val_loss: 0.8636 - val_accuracy: 0.7304\n","Epoch 35/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4688 - accuracy: 0.8713 - val_loss: 0.9267 - val_accuracy: 0.6818\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4566 - accuracy: 0.8755 - val_loss: 0.8474 - val_accuracy: 0.7118\n","Epoch 37/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4510 - accuracy: 0.8770 - val_loss: 0.8550 - val_accuracy: 0.7097\n","Epoch 38/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4547 - accuracy: 0.8783 - val_loss: 0.8663 - val_accuracy: 0.7211\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4518 - accuracy: 0.8827 - val_loss: 0.8575 - val_accuracy: 0.7169\n","Epoch 40/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4508 - accuracy: 0.8791 - val_loss: 0.8754 - val_accuracy: 0.7128\n","Epoch 41/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4522 - accuracy: 0.8791 - val_loss: 0.8850 - val_accuracy: 0.7231\n","Epoch 42/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4589 - accuracy: 0.8760 - val_loss: 0.8788 - val_accuracy: 0.7128\n","Epoch 43/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4553 - accuracy: 0.8786 - val_loss: 0.8951 - val_accuracy: 0.7221\n","Epoch 44/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4549 - accuracy: 0.8734 - val_loss: 0.9021 - val_accuracy: 0.7045\n","Epoch 45/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4524 - accuracy: 0.8742 - val_loss: 0.9408 - val_accuracy: 0.6663\n","Epoch 46/100\n","31/31 [==============================] - 1s 21ms/step - loss: 0.4466 - accuracy: 0.8798 - val_loss: 0.8929 - val_accuracy: 0.7304\n","Epoch 47/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4407 - accuracy: 0.8837 - val_loss: 0.8683 - val_accuracy: 0.7138\n","Epoch 48/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4385 - accuracy: 0.8824 - val_loss: 0.9077 - val_accuracy: 0.6973\n","Epoch 49/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4358 - accuracy: 0.8817 - val_loss: 0.9270 - val_accuracy: 0.6911\n","Epoch 50/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4401 - accuracy: 0.8848 - val_loss: 0.8919 - val_accuracy: 0.7149\n","Epoch 51/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4305 - accuracy: 0.8881 - val_loss: 0.8904 - val_accuracy: 0.7118\n","Epoch 52/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4299 - accuracy: 0.8907 - val_loss: 0.9099 - val_accuracy: 0.7076\n","Epoch 53/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4363 - accuracy: 0.8840 - val_loss: 0.9058 - val_accuracy: 0.7107\n","Epoch 54/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4377 - accuracy: 0.8848 - val_loss: 0.9353 - val_accuracy: 0.7159\n","Epoch 55/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4352 - accuracy: 0.8819 - val_loss: 0.8909 - val_accuracy: 0.7118\n","Epoch 56/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4290 - accuracy: 0.8873 - val_loss: 0.8936 - val_accuracy: 0.7149\n","Epoch 57/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4255 - accuracy: 0.8902 - val_loss: 0.9720 - val_accuracy: 0.6746\n","Epoch 58/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4154 - accuracy: 0.8933 - val_loss: 0.9164 - val_accuracy: 0.7025\n","Epoch 59/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4300 - accuracy: 0.8876 - val_loss: 0.9573 - val_accuracy: 0.7025\n","Epoch 60/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4354 - accuracy: 0.8824 - val_loss: 0.9561 - val_accuracy: 0.7076\n","Epoch 61/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4237 - accuracy: 0.8912 - val_loss: 0.9018 - val_accuracy: 0.7087\n","Epoch 62/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4282 - accuracy: 0.8910 - val_loss: 0.9554 - val_accuracy: 0.7056\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4202 - accuracy: 0.8886 - val_loss: 0.9042 - val_accuracy: 0.7138\n","Epoch 64/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4118 - accuracy: 0.8912 - val_loss: 0.9570 - val_accuracy: 0.7076\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4181 - accuracy: 0.8897 - val_loss: 0.9341 - val_accuracy: 0.7118\n","Epoch 66/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4161 - accuracy: 0.8907 - val_loss: 0.9748 - val_accuracy: 0.7025\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4119 - accuracy: 0.8935 - val_loss: 0.9378 - val_accuracy: 0.7159\n","Epoch 68/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4165 - accuracy: 0.8915 - val_loss: 0.9297 - val_accuracy: 0.7066\n","Epoch 69/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4381 - accuracy: 0.8778 - val_loss: 0.9599 - val_accuracy: 0.7087\n","Epoch 70/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4095 - accuracy: 0.8966 - val_loss: 0.9688 - val_accuracy: 0.7107\n","Epoch 71/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4159 - accuracy: 0.8941 - val_loss: 0.9806 - val_accuracy: 0.7087\n","Epoch 72/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4157 - accuracy: 0.8946 - val_loss: 0.9528 - val_accuracy: 0.7107\n","Epoch 73/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4001 - accuracy: 0.9005 - val_loss: 0.9751 - val_accuracy: 0.6973\n","Epoch 74/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.4070 - accuracy: 0.8930 - val_loss: 1.0483 - val_accuracy: 0.6849\n","Epoch 75/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.4269 - accuracy: 0.8891 - val_loss: 1.0164 - val_accuracy: 0.6694\n","Epoch 76/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4048 - accuracy: 0.8946 - val_loss: 0.9496 - val_accuracy: 0.7004\n","Epoch 77/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4090 - accuracy: 0.8943 - val_loss: 1.0488 - val_accuracy: 0.6612\n","Epoch 78/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3990 - accuracy: 0.8997 - val_loss: 0.9935 - val_accuracy: 0.7097\n","Epoch 79/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3970 - accuracy: 0.9003 - val_loss: 0.9778 - val_accuracy: 0.7025\n","Epoch 80/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3993 - accuracy: 0.9047 - val_loss: 0.9591 - val_accuracy: 0.7159\n","Epoch 81/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3904 - accuracy: 0.9044 - val_loss: 1.0054 - val_accuracy: 0.6932\n","Epoch 82/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4000 - accuracy: 0.8946 - val_loss: 0.9705 - val_accuracy: 0.7056\n","Epoch 83/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3958 - accuracy: 0.8987 - val_loss: 1.1323 - val_accuracy: 0.6384\n","Epoch 84/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4081 - accuracy: 0.9005 - val_loss: 0.9695 - val_accuracy: 0.6983\n","Epoch 85/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3973 - accuracy: 0.9039 - val_loss: 0.9566 - val_accuracy: 0.6973\n","Epoch 86/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3908 - accuracy: 0.9067 - val_loss: 0.9875 - val_accuracy: 0.6849\n","Epoch 87/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4071 - accuracy: 0.8966 - val_loss: 1.1194 - val_accuracy: 0.6446\n","Epoch 88/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3849 - accuracy: 0.9039 - val_loss: 0.9854 - val_accuracy: 0.6942\n","Epoch 89/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3939 - accuracy: 0.8925 - val_loss: 1.0013 - val_accuracy: 0.6798\n","Epoch 90/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3989 - accuracy: 0.8951 - val_loss: 1.0170 - val_accuracy: 0.6839\n","Epoch 91/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3848 - accuracy: 0.9088 - val_loss: 1.0082 - val_accuracy: 0.7035\n","Epoch 92/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3799 - accuracy: 0.9083 - val_loss: 0.9756 - val_accuracy: 0.7045\n","Epoch 93/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3807 - accuracy: 0.9096 - val_loss: 0.9759 - val_accuracy: 0.7056\n","Epoch 94/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3943 - accuracy: 0.9013 - val_loss: 1.0452 - val_accuracy: 0.7076\n","Epoch 95/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3900 - accuracy: 0.9052 - val_loss: 1.0511 - val_accuracy: 0.6994\n","Epoch 96/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3916 - accuracy: 0.9023 - val_loss: 1.0176 - val_accuracy: 0.6890\n","Epoch 97/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3811 - accuracy: 0.9059 - val_loss: 0.9930 - val_accuracy: 0.7045\n","Epoch 98/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3873 - accuracy: 0.9062 - val_loss: 0.9974 - val_accuracy: 0.6994\n","Epoch 99/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3685 - accuracy: 0.9145 - val_loss: 1.0659 - val_accuracy: 0.6767\n","Epoch 100/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3687 - accuracy: 0.9109 - val_loss: 1.0343 - val_accuracy: 0.6963\n","{'loss': [0.5421227812767029, 0.5351047515869141, 0.532087504863739, 0.5287758111953735, 0.5147473216056824, 0.5233234763145447, 0.508962094783783, 0.5039869546890259, 0.520283043384552, 0.5041971206665039, 0.501900315284729, 0.5083286762237549, 0.5017808675765991, 0.5064566135406494, 0.5041219592094421, 0.4929746687412262, 0.48959752917289734, 0.49374645948410034, 0.4880490303039551, 0.4838089048862457, 0.4841744303703308, 0.47946733236312866, 0.4769194424152374, 0.4745129942893982, 0.490346759557724, 0.47456878423690796, 0.47190234065055847, 0.5023478865623474, 0.47588375210762024, 0.47851815819740295, 0.47001951932907104, 0.4663713574409485, 0.46855613589286804, 0.461421400308609, 0.4687861204147339, 0.45655569434165955, 0.45103946328163147, 0.4547043442726135, 0.45177119970321655, 0.45078155398368835, 0.4521586298942566, 0.4589436650276184, 0.4553298354148865, 0.4549453556537628, 0.4524478614330292, 0.4465639591217041, 0.44069117307662964, 0.4385364353656769, 0.43579256534576416, 0.4400738775730133, 0.43047547340393066, 0.4298975169658661, 0.4363093972206116, 0.43773338198661804, 0.4352070093154907, 0.4289711117744446, 0.4255025386810303, 0.4154399037361145, 0.42995595932006836, 0.4354484975337982, 0.42373308539390564, 0.42817193269729614, 0.42019763588905334, 0.41179752349853516, 0.4180564880371094, 0.41607004404067993, 0.4119258224964142, 0.4165208339691162, 0.43813952803611755, 0.4095478951931, 0.41589871048927307, 0.41574692726135254, 0.40013429522514343, 0.40701261162757874, 0.4269150197505951, 0.4048098921775818, 0.4089529514312744, 0.39897340536117554, 0.39701810479164124, 0.3993317782878876, 0.39038142561912537, 0.39996469020843506, 0.39582470059394836, 0.4080790579319, 0.3973228335380554, 0.3907967805862427, 0.4070571959018707, 0.3849213123321533, 0.3939023017883301, 0.39894720911979675, 0.38482415676116943, 0.3799472153186798, 0.38069668412208557, 0.39427515864372253, 0.3899799585342407, 0.39157405495643616, 0.3810926675796509, 0.38726067543029785, 0.3685343563556671, 0.3686579763889313], 'accuracy': [0.8403100967407227, 0.8369508981704712, 0.8431524634361267, 0.8377261161804199, 0.8524547815322876, 0.8465116024017334, 0.8521963953971863, 0.8602067232131958, 0.841602087020874, 0.8560723662376404, 0.8571059703826904, 0.8511627912521362, 0.8496124148368835, 0.855555534362793, 0.8480620384216309, 0.8594315052032471, 0.8658914566040039, 0.8571059703826904, 0.8591731190681458, 0.8620154857635498, 0.867958664894104, 0.8614987134933472, 0.8692506551742554, 0.8674418330192566, 0.8630490899085999, 0.868992269039154, 0.868992269039154, 0.8594315052032471, 0.8700258135795593, 0.8638243079185486, 0.8700258135795593, 0.8803617358207703, 0.8736433982849121, 0.8705426454544067, 0.8713178038597107, 0.8754522204399109, 0.8770025968551636, 0.8782945871353149, 0.8826873302459717, 0.8790697455406189, 0.8790697455406189, 0.8759689927101135, 0.8785529732704163, 0.8733850121498108, 0.8741602301597595, 0.8798449635505676, 0.8837209343910217, 0.8824289441108704, 0.8816537261009216, 0.8847545385360718, 0.8881136775016785, 0.8906976580619812, 0.883979320526123, 0.8847545385360718, 0.8819121718406677, 0.8873385190963745, 0.8901808857917786, 0.8932816386222839, 0.8875969052314758, 0.8824289441108704, 0.8912144899368286, 0.8909560441970825, 0.8886305093765259, 0.8912144899368286, 0.8896640539169312, 0.8906976580619812, 0.8935400247573853, 0.8914728760719299, 0.8777777552604675, 0.8966408371925354, 0.8940568566322327, 0.8945736289024353, 0.9005168080329895, 0.8930232524871826, 0.8891472816467285, 0.8945736289024353, 0.894315242767334, 0.8997415900230408, 0.9002584218978882, 0.9046511650085449, 0.9043927788734436, 0.8945736289024353, 0.8987079858779907, 0.9005168080329895, 0.9038759469985962, 0.906718373298645, 0.8966408371925354, 0.9038759469985962, 0.89250648021698, 0.8950904607772827, 0.9087855219841003, 0.9082687497138977, 0.9095607399940491, 0.9012919664382935, 0.9051679372787476, 0.9023255705833435, 0.9059431552886963, 0.9062015414237976, 0.9144702553749084, 0.9108527302742004], 'val_loss': [0.952692985534668, 0.8975809216499329, 0.898201584815979, 0.8659102916717529, 0.8814813494682312, 0.8418934345245361, 0.8677197098731995, 0.8277795314788818, 0.8648046255111694, 0.829043447971344, 0.8003743290901184, 0.8367729783058167, 0.7960925102233887, 0.755462646484375, 0.7660086750984192, 0.7478141188621521, 0.7404133677482605, 0.7515739798545837, 0.7584296464920044, 0.7413411140441895, 0.8069333434104919, 0.7514328956604004, 0.7729034423828125, 0.7882900238037109, 0.7899083495140076, 0.8186721801757812, 0.7971879839897156, 0.8304755091667175, 0.8204631805419922, 0.8455631732940674, 0.84135901927948, 0.8597106337547302, 0.9249417185783386, 0.8635721206665039, 0.9267094731330872, 0.8474198579788208, 0.8550386428833008, 0.8663485050201416, 0.8574652671813965, 0.8753632307052612, 0.8850210905075073, 0.8787854313850403, 0.8950650095939636, 0.9020528197288513, 0.9407547116279602, 0.8929480314254761, 0.868285059928894, 0.9077497124671936, 0.9270381927490234, 0.8919287919998169, 0.8904157876968384, 0.9099056124687195, 0.905802845954895, 0.935314416885376, 0.8908851146697998, 0.893608033657074, 0.9719727039337158, 0.9164489507675171, 0.9572725892066956, 0.9561123251914978, 0.9018422365188599, 0.9553965926170349, 0.9042161703109741, 0.9569889307022095, 0.9341058135032654, 0.974836528301239, 0.9377979040145874, 0.9296679496765137, 0.9598846435546875, 0.9687991738319397, 0.9806446433067322, 0.9528428316116333, 0.9750828146934509, 1.0482791662216187, 1.0163675546646118, 0.9496167302131653, 1.0488213300704956, 0.9934977293014526, 0.977769136428833, 0.9590724110603333, 1.0053930282592773, 0.9705211520195007, 1.1323283910751343, 0.9694693088531494, 0.956567645072937, 0.9874728322029114, 1.1193898916244507, 0.985425591468811, 1.0013222694396973, 1.0169670581817627, 1.0082348585128784, 0.9756420254707336, 0.9758567214012146, 1.045225739479065, 1.0511360168457031, 1.017587661743164, 0.9929742813110352, 0.9974009394645691, 1.0658721923828125, 1.0343067646026611], 'val_accuracy': [0.5165289044380188, 0.5247933864593506, 0.5258264541625977, 0.5423553586006165, 0.5371900796890259, 0.5650826692581177, 0.5557851195335388, 0.6043388247489929, 0.567148745059967, 0.6043388247489929, 0.6477272510528564, 0.6074380278587341, 0.6621900796890259, 0.6931818127632141, 0.6869834661483765, 0.711776852607727, 0.7221074104309082, 0.7128099203109741, 0.7190082669258118, 0.7283057570457458, 0.7097107172012329, 0.7210744023323059, 0.7272727489471436, 0.7190082669258118, 0.7159090638160706, 0.7252066135406494, 0.7190082669258118, 0.7169421315193176, 0.7231404781341553, 0.7293388247489929, 0.711776852607727, 0.7262396812438965, 0.7128099203109741, 0.73037189245224, 0.6818181872367859, 0.711776852607727, 0.7097107172012329, 0.7210744023323059, 0.7169421315193176, 0.7128099203109741, 0.7231404781341553, 0.7128099203109741, 0.7221074104309082, 0.7045454382896423, 0.6663222908973694, 0.73037189245224, 0.7138429880142212, 0.6973140239715576, 0.69111567735672, 0.7148760557174683, 0.711776852607727, 0.7076446413993835, 0.71074378490448, 0.7159090638160706, 0.711776852607727, 0.7148760557174683, 0.6745867729187012, 0.702479362487793, 0.702479362487793, 0.7076446413993835, 0.7086777091026306, 0.7055785059928894, 0.7138429880142212, 0.7076446413993835, 0.711776852607727, 0.702479362487793, 0.7159090638160706, 0.7066115736961365, 0.7086777091026306, 0.71074378490448, 0.7086777091026306, 0.71074378490448, 0.6973140239715576, 0.6849173307418823, 0.6694214940071106, 0.7004132270812988, 0.6611570119857788, 0.7097107172012329, 0.702479362487793, 0.7159090638160706, 0.6931818127632141, 0.7055785059928894, 0.6384297609329224, 0.6983470916748047, 0.6973140239715576, 0.6849173307418823, 0.64462810754776, 0.6942148804664612, 0.6797520518302917, 0.68388432264328, 0.7035123705863953, 0.7045454382896423, 0.7055785059928894, 0.7076446413993835, 0.6993801593780518, 0.6890496015548706, 0.7045454382896423, 0.6993801593780518, 0.6766529083251953, 0.6962810158729553]}\n","32/32 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/29 [===========================>..] - ETA: 0s - loss: 0.4266 - accuracy: 0.8864"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["29/29 [==============================] - 7s 68ms/step - loss: 0.4284 - accuracy: 0.8869 - val_loss: 0.8375 - val_accuracy: 0.5625\n","Epoch 2/100\n","29/29 [==============================] - 1s 27ms/step - loss: 0.4178 - accuracy: 0.8955 - val_loss: 0.8343 - val_accuracy: 0.5797\n","Epoch 3/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.4172 - accuracy: 0.8860 - val_loss: 0.8241 - val_accuracy: 0.6315\n","Epoch 4/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.4045 - accuracy: 0.8930 - val_loss: 0.8276 - val_accuracy: 0.5905\n","Epoch 5/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3890 - accuracy: 0.9054 - val_loss: 0.8330 - val_accuracy: 0.5841\n","Epoch 6/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3916 - accuracy: 0.9038 - val_loss: 0.8141 - val_accuracy: 0.6336\n","Epoch 7/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3929 - accuracy: 0.9009 - val_loss: 0.8250 - val_accuracy: 0.6024\n","Epoch 8/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3923 - accuracy: 0.8987 - val_loss: 0.8447 - val_accuracy: 0.5668\n","Epoch 9/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3852 - accuracy: 0.9033 - val_loss: 0.7701 - val_accuracy: 0.6573\n","Epoch 10/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3857 - accuracy: 0.8987 - val_loss: 0.7958 - val_accuracy: 0.6315\n","Epoch 11/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3967 - accuracy: 0.8984 - val_loss: 0.8032 - val_accuracy: 0.6196\n","Epoch 12/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3963 - accuracy: 0.8990 - val_loss: 0.7369 - val_accuracy: 0.6940\n","Epoch 13/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3851 - accuracy: 0.9095 - val_loss: 0.7214 - val_accuracy: 0.6994\n","Epoch 14/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3931 - accuracy: 0.8995 - val_loss: 0.7253 - val_accuracy: 0.6789\n","Epoch 15/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3702 - accuracy: 0.9127 - val_loss: 0.7141 - val_accuracy: 0.7188\n","Epoch 16/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3700 - accuracy: 0.9084 - val_loss: 0.6938 - val_accuracy: 0.7252\n","Epoch 17/100\n","29/29 [==============================] - 1s 23ms/step - loss: 0.3706 - accuracy: 0.9141 - val_loss: 0.7043 - val_accuracy: 0.7306\n","Epoch 18/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3638 - accuracy: 0.9130 - val_loss: 0.6907 - val_accuracy: 0.7274\n","Epoch 19/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3612 - accuracy: 0.9149 - val_loss: 0.6838 - val_accuracy: 0.7435\n","Epoch 20/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3731 - accuracy: 0.9098 - val_loss: 0.6774 - val_accuracy: 0.7575\n","Epoch 21/100\n","29/29 [==============================] - 1s 25ms/step - loss: 0.3697 - accuracy: 0.9124 - val_loss: 0.6663 - val_accuracy: 0.7726\n","Epoch 22/100\n","29/29 [==============================] - 1s 24ms/step - loss: 0.3593 - accuracy: 0.9157 - val_loss: 0.6971 - val_accuracy: 0.7748\n","Epoch 23/100\n","29/29 [==============================] - 1s 32ms/step - loss: 0.3582 - accuracy: 0.9170 - val_loss: 0.6806 - val_accuracy: 0.7759\n","Epoch 24/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3610 - accuracy: 0.9133 - val_loss: 0.7411 - val_accuracy: 0.7597\n","Epoch 25/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3612 - accuracy: 0.9178 - val_loss: 0.7274 - val_accuracy: 0.7672\n","Epoch 26/100\n","29/29 [==============================] - 1s 29ms/step - loss: 0.3612 - accuracy: 0.9162 - val_loss: 0.7348 - val_accuracy: 0.7780\n","Epoch 27/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3580 - accuracy: 0.9162 - val_loss: 0.8505 - val_accuracy: 0.7414\n","Epoch 28/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3486 - accuracy: 0.9259 - val_loss: 0.7338 - val_accuracy: 0.7759\n","Epoch 29/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3509 - accuracy: 0.9168 - val_loss: 0.7519 - val_accuracy: 0.7748\n","Epoch 30/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3662 - accuracy: 0.9079 - val_loss: 0.7522 - val_accuracy: 0.7672\n","Epoch 31/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3542 - accuracy: 0.9184 - val_loss: 0.7737 - val_accuracy: 0.7565\n","Epoch 32/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3597 - accuracy: 0.9138 - val_loss: 0.7725 - val_accuracy: 0.7769\n","Epoch 33/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3471 - accuracy: 0.9173 - val_loss: 0.8270 - val_accuracy: 0.7565\n","Epoch 34/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3508 - accuracy: 0.9240 - val_loss: 0.7787 - val_accuracy: 0.7759\n","Epoch 35/100\n","29/29 [==============================] - 1s 21ms/step - loss: 0.3653 - accuracy: 0.9165 - val_loss: 0.7729 - val_accuracy: 0.7823\n","Epoch 36/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3581 - accuracy: 0.9106 - val_loss: 0.8597 - val_accuracy: 0.7360\n","Epoch 37/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3420 - accuracy: 0.9203 - val_loss: 0.7775 - val_accuracy: 0.7791\n","Epoch 38/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3405 - accuracy: 0.9254 - val_loss: 0.8773 - val_accuracy: 0.7328\n","Epoch 39/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3562 - accuracy: 0.9168 - val_loss: 0.8208 - val_accuracy: 0.7759\n","Epoch 40/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3451 - accuracy: 0.9211 - val_loss: 0.7851 - val_accuracy: 0.7791\n","Epoch 41/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3374 - accuracy: 0.9240 - val_loss: 0.8289 - val_accuracy: 0.7619\n","Epoch 42/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3434 - accuracy: 0.9243 - val_loss: 0.7940 - val_accuracy: 0.7759\n","Epoch 43/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3539 - accuracy: 0.9216 - val_loss: 0.8389 - val_accuracy: 0.7500\n","Epoch 44/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3363 - accuracy: 0.9227 - val_loss: 0.8344 - val_accuracy: 0.7683\n","Epoch 45/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3290 - accuracy: 0.9313 - val_loss: 0.7999 - val_accuracy: 0.7726\n","Epoch 46/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3412 - accuracy: 0.9254 - val_loss: 0.8447 - val_accuracy: 0.7500\n","Epoch 47/100\n","29/29 [==============================] - 1s 22ms/step - loss: 0.3459 - accuracy: 0.9265 - val_loss: 0.7928 - val_accuracy: 0.7834\n","Epoch 48/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3291 - accuracy: 0.9332 - val_loss: 0.8471 - val_accuracy: 0.7425\n","Epoch 49/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3365 - accuracy: 0.9232 - val_loss: 0.8774 - val_accuracy: 0.7651\n","Epoch 50/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3454 - accuracy: 0.9259 - val_loss: 0.9048 - val_accuracy: 0.7328\n","Epoch 51/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3439 - accuracy: 0.9203 - val_loss: 0.8658 - val_accuracy: 0.7629\n","Epoch 52/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3367 - accuracy: 0.9235 - val_loss: 0.8311 - val_accuracy: 0.7716\n","Epoch 53/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3452 - accuracy: 0.9184 - val_loss: 0.8629 - val_accuracy: 0.7694\n","Epoch 54/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3265 - accuracy: 0.9283 - val_loss: 0.8139 - val_accuracy: 0.7726\n","Epoch 55/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3292 - accuracy: 0.9278 - val_loss: 0.8632 - val_accuracy: 0.7694\n","Epoch 56/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3325 - accuracy: 0.9248 - val_loss: 0.8408 - val_accuracy: 0.7608\n","Epoch 57/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3242 - accuracy: 0.9310 - val_loss: 0.8593 - val_accuracy: 0.7694\n","Epoch 58/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3258 - accuracy: 0.9305 - val_loss: 0.8661 - val_accuracy: 0.7640\n","Epoch 59/100\n","29/29 [==============================] - 1s 17ms/step - loss: 0.3254 - accuracy: 0.9302 - val_loss: 0.8433 - val_accuracy: 0.7672\n","Epoch 60/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3165 - accuracy: 0.9345 - val_loss: 0.8654 - val_accuracy: 0.7608\n","Epoch 61/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3188 - accuracy: 0.9308 - val_loss: 0.8650 - val_accuracy: 0.7640\n","Epoch 62/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3291 - accuracy: 0.9243 - val_loss: 0.9098 - val_accuracy: 0.7435\n","Epoch 63/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3267 - accuracy: 0.9305 - val_loss: 0.8465 - val_accuracy: 0.7662\n","Epoch 64/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3138 - accuracy: 0.9397 - val_loss: 0.9794 - val_accuracy: 0.7349\n","Epoch 65/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3293 - accuracy: 0.9246 - val_loss: 0.8658 - val_accuracy: 0.7705\n","Epoch 66/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3233 - accuracy: 0.9353 - val_loss: 0.8413 - val_accuracy: 0.7716\n","Epoch 67/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3085 - accuracy: 0.9367 - val_loss: 0.9017 - val_accuracy: 0.7586\n","Epoch 68/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3247 - accuracy: 0.9318 - val_loss: 0.8636 - val_accuracy: 0.7716\n","Epoch 69/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3317 - accuracy: 0.9302 - val_loss: 0.9165 - val_accuracy: 0.7468\n","Epoch 70/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3146 - accuracy: 0.9351 - val_loss: 0.8711 - val_accuracy: 0.7705\n","Epoch 71/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3056 - accuracy: 0.9386 - val_loss: 0.8861 - val_accuracy: 0.7726\n","Epoch 72/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3176 - accuracy: 0.9332 - val_loss: 0.8920 - val_accuracy: 0.7565\n","Epoch 73/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3164 - accuracy: 0.9310 - val_loss: 0.8861 - val_accuracy: 0.7575\n","Epoch 74/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3061 - accuracy: 0.9423 - val_loss: 0.8906 - val_accuracy: 0.7511\n","Epoch 75/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3025 - accuracy: 0.9367 - val_loss: 0.8816 - val_accuracy: 0.7716\n","Epoch 76/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3160 - accuracy: 0.9340 - val_loss: 0.9262 - val_accuracy: 0.7478\n","Epoch 77/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3393 - accuracy: 0.9211 - val_loss: 0.9764 - val_accuracy: 0.7349\n","Epoch 78/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3024 - accuracy: 0.9391 - val_loss: 0.9089 - val_accuracy: 0.7662\n","Epoch 79/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3132 - accuracy: 0.9386 - val_loss: 0.8907 - val_accuracy: 0.7705\n","Epoch 80/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2969 - accuracy: 0.9378 - val_loss: 0.9459 - val_accuracy: 0.7295\n","Epoch 81/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2953 - accuracy: 0.9421 - val_loss: 0.8946 - val_accuracy: 0.7554\n","Epoch 82/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2950 - accuracy: 0.9391 - val_loss: 0.8933 - val_accuracy: 0.7500\n","Epoch 83/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2927 - accuracy: 0.9415 - val_loss: 0.9363 - val_accuracy: 0.7543\n","Epoch 84/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2939 - accuracy: 0.9407 - val_loss: 0.8956 - val_accuracy: 0.7640\n","Epoch 85/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2961 - accuracy: 0.9448 - val_loss: 0.9184 - val_accuracy: 0.7640\n","Epoch 86/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2904 - accuracy: 0.9453 - val_loss: 1.0023 - val_accuracy: 0.7468\n","Epoch 87/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3006 - accuracy: 0.9397 - val_loss: 0.9435 - val_accuracy: 0.7629\n","Epoch 88/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.3071 - accuracy: 0.9383 - val_loss: 0.9272 - val_accuracy: 0.7662\n","Epoch 89/100\n","29/29 [==============================] - 0s 17ms/step - loss: 0.2959 - accuracy: 0.9440 - val_loss: 1.0021 - val_accuracy: 0.7457\n","Epoch 90/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3209 - accuracy: 0.9337 - val_loss: 0.9537 - val_accuracy: 0.7575\n","Epoch 91/100\n","29/29 [==============================] - 1s 19ms/step - loss: 0.3022 - accuracy: 0.9415 - val_loss: 0.9608 - val_accuracy: 0.7392\n","Epoch 92/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.2873 - accuracy: 0.9434 - val_loss: 0.9030 - val_accuracy: 0.7608\n","Epoch 93/100\n","29/29 [==============================] - 1s 18ms/step - loss: 0.3032 - accuracy: 0.9397 - val_loss: 0.9429 - val_accuracy: 0.7381\n","Epoch 94/100\n","29/29 [==============================] - 0s 16ms/step - loss: 0.3046 - accuracy: 0.9364 - val_loss: 0.9399 - val_accuracy: 0.7608\n","Epoch 95/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2912 - accuracy: 0.9418 - val_loss: 0.9140 - val_accuracy: 0.7726\n","Epoch 96/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.2961 - accuracy: 0.9418 - val_loss: 0.9374 - val_accuracy: 0.7543\n","Epoch 97/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.2958 - accuracy: 0.9367 - val_loss: 0.9143 - val_accuracy: 0.7586\n","Epoch 98/100\n","29/29 [==============================] - 0s 15ms/step - loss: 0.3146 - accuracy: 0.9305 - val_loss: 1.3072 - val_accuracy: 0.7015\n","Epoch 99/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3562 - accuracy: 0.9143 - val_loss: 0.9759 - val_accuracy: 0.7575\n","Epoch 100/100\n","29/29 [==============================] - 0s 14ms/step - loss: 0.3181 - accuracy: 0.9324 - val_loss: 0.9567 - val_accuracy: 0.7392\n","{'loss': [0.4284009635448456, 0.41783615946769714, 0.4172457754611969, 0.4044560194015503, 0.38898056745529175, 0.3915761709213257, 0.39286649227142334, 0.39234212040901184, 0.3852366507053375, 0.38570016622543335, 0.3966577649116516, 0.39632469415664673, 0.3850778043270111, 0.393107533454895, 0.3702448904514313, 0.37003231048583984, 0.3706207871437073, 0.3638467788696289, 0.36116477847099304, 0.37308791279792786, 0.3697047829627991, 0.3592895567417145, 0.3582477271556854, 0.36099520325660706, 0.3611646294593811, 0.3611712157726288, 0.3579750955104828, 0.34861335158348083, 0.35090288519859314, 0.36623644828796387, 0.35419708490371704, 0.3596595823764801, 0.34710457921028137, 0.3508099913597107, 0.36527732014656067, 0.3580758571624756, 0.34203463792800903, 0.3404737710952759, 0.3562089204788208, 0.3450770080089569, 0.33740606904029846, 0.3434048295021057, 0.3538755178451538, 0.3362845182418823, 0.32904550433158875, 0.34119555354118347, 0.34590014815330505, 0.3290957510471344, 0.3364863991737366, 0.34542712569236755, 0.34390491247177124, 0.3367375135421753, 0.34515178203582764, 0.32646283507347107, 0.3291878402233124, 0.33251839876174927, 0.3241632580757141, 0.32583025097846985, 0.32539358735084534, 0.3164588212966919, 0.3187966048717499, 0.3290848433971405, 0.32671889662742615, 0.31380143761634827, 0.32932794094085693, 0.32334306836128235, 0.3085453510284424, 0.32467129826545715, 0.3317050635814667, 0.31463152170181274, 0.30556520819664, 0.3176198899745941, 0.31638801097869873, 0.30607500672340393, 0.30250421166419983, 0.3160307705402374, 0.3393275737762451, 0.30240416526794434, 0.3132249712944031, 0.29685404896736145, 0.2953391671180725, 0.2949577271938324, 0.2926550507545471, 0.2938511371612549, 0.2961471676826477, 0.2903873920440674, 0.30064547061920166, 0.3071228563785553, 0.29589417576789856, 0.3208521008491516, 0.3022482097148895, 0.287276953458786, 0.3031553030014038, 0.3045843243598938, 0.2911732494831085, 0.2961423099040985, 0.29583054780960083, 0.3146330714225769, 0.3562014698982239, 0.31809142231941223], 'accuracy': [0.8868534564971924, 0.8954741358757019, 0.8860452771186829, 0.8930495977401733, 0.9054418206214905, 0.9038254022598267, 0.9008620977401733, 0.8987069129943848, 0.9032866358757019, 0.8987069129943848, 0.8984375, 0.8989762663841248, 0.9094827771186829, 0.8995150923728943, 0.912715494632721, 0.9084051847457886, 0.9140625, 0.9129849076271057, 0.9148706793785095, 0.9097521305084229, 0.912446141242981, 0.915678858757019, 0.9170258641242981, 0.9132543206214905, 0.9178340435028076, 0.9162176847457886, 0.9162176847457886, 0.9259159564971924, 0.9167564511299133, 0.907866358757019, 0.9183728694915771, 0.9137930870056152, 0.9172952771186829, 0.9240301847457886, 0.9164870977401733, 0.9105603694915771, 0.920258641242981, 0.9253771305084229, 0.9167564511299133, 0.9210668206214905, 0.9240301847457886, 0.9242995977401733, 0.9216055870056152, 0.9226831793785095, 0.931303858757019, 0.9253771305084229, 0.9264547228813171, 0.9331896305084229, 0.923222005367279, 0.9259159564971924, 0.920258641242981, 0.923491358757019, 0.9183728694915771, 0.928340494632721, 0.9278017282485962, 0.9248383641242981, 0.931034505367279, 0.9304956793785095, 0.9302262663841248, 0.9345366358757019, 0.9307650923728943, 0.9242995977401733, 0.9304956793785095, 0.9396551847457886, 0.9245689511299133, 0.9353448152542114, 0.9366918206214905, 0.9318426847457886, 0.9302262663841248, 0.9350754022598267, 0.9385775923728943, 0.9331896305084229, 0.931034505367279, 0.9423491358757019, 0.9366918206214905, 0.9339978694915771, 0.9210668206214905, 0.939116358757019, 0.9385775923728943, 0.9377694129943848, 0.9420797228813171, 0.939116358757019, 0.9415409564971924, 0.9407327771186829, 0.9447737336158752, 0.9453125, 0.9396551847457886, 0.9383081793785095, 0.943965494632721, 0.9337284564971924, 0.9415409564971924, 0.9434267282485962, 0.9396551847457886, 0.9364224076271057, 0.9418103694915771, 0.9418103694915771, 0.9366918206214905, 0.9304956793785095, 0.9143319129943848, 0.9323814511299133], 'val_loss': [0.8375086784362793, 0.8343430757522583, 0.8241077661514282, 0.8275843858718872, 0.8330003023147583, 0.8140680193901062, 0.8249704837799072, 0.8447262048721313, 0.7700965404510498, 0.7958311438560486, 0.8032384514808655, 0.7368994355201721, 0.7214385271072388, 0.7253069877624512, 0.7141488194465637, 0.6938108205795288, 0.7042884230613708, 0.6906917095184326, 0.6838011145591736, 0.6773619651794434, 0.666342556476593, 0.6971350908279419, 0.6805875301361084, 0.7410736083984375, 0.7274497747421265, 0.7348294854164124, 0.8504570722579956, 0.7338221073150635, 0.751885175704956, 0.7521833181381226, 0.7737067937850952, 0.7724698781967163, 0.8269517421722412, 0.7787215113639832, 0.7729092836380005, 0.8597177863121033, 0.7774991393089294, 0.8773491978645325, 0.8208194375038147, 0.7851141691207886, 0.828855574131012, 0.794022262096405, 0.8389303684234619, 0.8343647122383118, 0.7999221682548523, 0.8447474241256714, 0.79278165102005, 0.8470711708068848, 0.8774127960205078, 0.9047948122024536, 0.8657644391059875, 0.8310703635215759, 0.8629022836685181, 0.813937783241272, 0.863174557685852, 0.8407605290412903, 0.8592544198036194, 0.8661376237869263, 0.843332827091217, 0.8653619885444641, 0.8649737238883972, 0.9097626209259033, 0.8464515805244446, 0.979353129863739, 0.8658321499824524, 0.841313898563385, 0.9017192125320435, 0.8636243343353271, 0.9165468811988831, 0.8711059093475342, 0.8860623836517334, 0.8920140266418457, 0.8860819339752197, 0.8906247615814209, 0.8815814256668091, 0.9261564016342163, 0.9764062166213989, 0.9088786840438843, 0.890680193901062, 0.9458606839179993, 0.8946300745010376, 0.8933187127113342, 0.9363383054733276, 0.8956394791603088, 0.9183733463287354, 1.0023049116134644, 0.9435175061225891, 0.9271785020828247, 1.00213623046875, 0.9536964893341064, 0.9607917666435242, 0.9029807448387146, 0.9428836703300476, 0.9399350881576538, 0.9139805436134338, 0.9374474883079529, 0.9143273830413818, 1.3071807622909546, 0.9758886098861694, 0.9566909074783325], 'val_accuracy': [0.5625, 0.579741358757019, 0.631465494632721, 0.5905172228813171, 0.5840517282485962, 0.6336206793785095, 0.6023706793785095, 0.5668103694915771, 0.6573275923728943, 0.631465494632721, 0.6196120977401733, 0.693965494632721, 0.6993534564971924, 0.6788793206214905, 0.71875, 0.725215494632721, 0.7306034564971924, 0.7273706793785095, 0.743534505367279, 0.7575430870056152, 0.7726293206214905, 0.774784505367279, 0.7758620977401733, 0.7596982717514038, 0.767241358757019, 0.7780172228813171, 0.7413793206214905, 0.7758620977401733, 0.774784505367279, 0.767241358757019, 0.756465494632721, 0.7769396305084229, 0.756465494632721, 0.7758620977401733, 0.7823275923728943, 0.735991358757019, 0.7790948152542114, 0.732758641242981, 0.7758620977401733, 0.7790948152542114, 0.7618534564971924, 0.7758620977401733, 0.75, 0.7683189511299133, 0.7726293206214905, 0.75, 0.7834051847457886, 0.7424569129943848, 0.7650862336158752, 0.732758641242981, 0.7629310488700867, 0.7715517282485962, 0.7693965435028076, 0.7726293206214905, 0.7693965435028076, 0.7607758641242981, 0.7693965435028076, 0.764008641242981, 0.767241358757019, 0.7607758641242981, 0.764008641242981, 0.743534505367279, 0.7661637663841248, 0.7349137663841248, 0.7704741358757019, 0.7715517282485962, 0.7586206793785095, 0.7715517282485962, 0.7467672228813171, 0.7704741358757019, 0.7726293206214905, 0.756465494632721, 0.7575430870056152, 0.7510775923728943, 0.7715517282485962, 0.7478448152542114, 0.7349137663841248, 0.7661637663841248, 0.7704741358757019, 0.7295258641242981, 0.7553879022598267, 0.75, 0.7543103694915771, 0.764008641242981, 0.764008641242981, 0.7467672228813171, 0.7629310488700867, 0.7661637663841248, 0.7456896305084229, 0.7575430870056152, 0.7392241358757019, 0.7607758641242981, 0.7381465435028076, 0.7607758641242981, 0.7726293206214905, 0.7543103694915771, 0.7586206793785095, 0.701508641242981, 0.7575430870056152, 0.7392241358757019]}\n","38/38 [==============================] - 1s 5ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","28/28 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.8749"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/28 [==============================] - 8s 56ms/step - loss: 0.4416 - accuracy: 0.8749 - val_loss: 0.8831 - val_accuracy: 0.5170\n","Epoch 2/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.4269 - accuracy: 0.8809 - val_loss: 0.8245 - val_accuracy: 0.6233\n","Epoch 3/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4308 - accuracy: 0.8860 - val_loss: 0.8277 - val_accuracy: 0.6063\n","Epoch 4/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.4132 - accuracy: 0.8899 - val_loss: 0.8255 - val_accuracy: 0.6335\n","Epoch 5/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4202 - accuracy: 0.8857 - val_loss: 0.8120 - val_accuracy: 0.5984\n","Epoch 6/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4061 - accuracy: 0.8970 - val_loss: 0.8044 - val_accuracy: 0.6324\n","Epoch 7/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.4093 - accuracy: 0.8916 - val_loss: 0.8560 - val_accuracy: 0.5566\n","Epoch 8/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3996 - accuracy: 0.8911 - val_loss: 0.8069 - val_accuracy: 0.6233\n","Epoch 9/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3970 - accuracy: 0.8947 - val_loss: 0.8409 - val_accuracy: 0.5701\n","Epoch 10/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4014 - accuracy: 0.8933 - val_loss: 0.7855 - val_accuracy: 0.6041\n","Epoch 11/100\n","28/28 [==============================] - 0s 18ms/step - loss: 0.4117 - accuracy: 0.8860 - val_loss: 0.7727 - val_accuracy: 0.6278\n","Epoch 12/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3996 - accuracy: 0.8945 - val_loss: 0.7491 - val_accuracy: 0.6878\n","Epoch 13/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.4109 - accuracy: 0.8908 - val_loss: 0.7189 - val_accuracy: 0.6663\n","Epoch 14/100\n","28/28 [==============================] - 1s 28ms/step - loss: 0.4018 - accuracy: 0.8993 - val_loss: 0.7303 - val_accuracy: 0.7048\n","Epoch 15/100\n","28/28 [==============================] - 1s 35ms/step - loss: 0.3927 - accuracy: 0.8945 - val_loss: 0.7015 - val_accuracy: 0.7229\n","Epoch 16/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3881 - accuracy: 0.9021 - val_loss: 0.7123 - val_accuracy: 0.7070\n","Epoch 17/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3828 - accuracy: 0.8990 - val_loss: 0.6566 - val_accuracy: 0.7466\n","Epoch 18/100\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3780 - accuracy: 0.9072 - val_loss: 0.6833 - val_accuracy: 0.7511\n","Epoch 19/100\n","28/28 [==============================] - 1s 24ms/step - loss: 0.3896 - accuracy: 0.8981 - val_loss: 0.6513 - val_accuracy: 0.7579\n","Epoch 20/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3777 - accuracy: 0.9061 - val_loss: 0.6418 - val_accuracy: 0.7670\n","Epoch 21/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3764 - accuracy: 0.9078 - val_loss: 0.6549 - val_accuracy: 0.7704\n","Epoch 22/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3667 - accuracy: 0.9126 - val_loss: 0.7160 - val_accuracy: 0.7308\n","Epoch 23/100\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3717 - accuracy: 0.9100 - val_loss: 0.6416 - val_accuracy: 0.7726\n","Epoch 24/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3913 - accuracy: 0.8978 - val_loss: 0.6916 - val_accuracy: 0.7523\n","Epoch 25/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.4022 - accuracy: 0.8973 - val_loss: 0.7002 - val_accuracy: 0.7590\n","Epoch 26/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3941 - accuracy: 0.8978 - val_loss: 0.6690 - val_accuracy: 0.7658\n","Epoch 27/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3838 - accuracy: 0.8998 - val_loss: 0.6764 - val_accuracy: 0.7670\n","Epoch 28/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3744 - accuracy: 0.9106 - val_loss: 0.7035 - val_accuracy: 0.7873\n","Epoch 29/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3685 - accuracy: 0.9083 - val_loss: 0.6726 - val_accuracy: 0.7851\n","Epoch 30/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3750 - accuracy: 0.9058 - val_loss: 0.6766 - val_accuracy: 0.7794\n","Epoch 31/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3714 - accuracy: 0.9044 - val_loss: 0.7347 - val_accuracy: 0.7410\n","Epoch 32/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3734 - accuracy: 0.9032 - val_loss: 0.7064 - val_accuracy: 0.7749\n","Epoch 33/100\n","28/28 [==============================] - 1s 23ms/step - loss: 0.3583 - accuracy: 0.9092 - val_loss: 0.6720 - val_accuracy: 0.7896\n","Epoch 34/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3755 - accuracy: 0.9066 - val_loss: 0.7028 - val_accuracy: 0.7817\n","Epoch 35/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3573 - accuracy: 0.9154 - val_loss: 0.6962 - val_accuracy: 0.7783\n","Epoch 36/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3536 - accuracy: 0.9188 - val_loss: 0.7230 - val_accuracy: 0.7749\n","Epoch 37/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3690 - accuracy: 0.9061 - val_loss: 0.7251 - val_accuracy: 0.7489\n","Epoch 38/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3496 - accuracy: 0.9188 - val_loss: 0.7611 - val_accuracy: 0.7432\n","Epoch 39/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3523 - accuracy: 0.9148 - val_loss: 0.7330 - val_accuracy: 0.7534\n","Epoch 40/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3572 - accuracy: 0.9177 - val_loss: 0.7958 - val_accuracy: 0.7523\n","Epoch 41/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3559 - accuracy: 0.9128 - val_loss: 0.7306 - val_accuracy: 0.7602\n","Epoch 42/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3455 - accuracy: 0.9191 - val_loss: 0.6986 - val_accuracy: 0.7862\n","Epoch 43/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3531 - accuracy: 0.9111 - val_loss: 0.7530 - val_accuracy: 0.7500\n","Epoch 44/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3446 - accuracy: 0.9225 - val_loss: 0.7205 - val_accuracy: 0.7896\n","Epoch 45/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3373 - accuracy: 0.9216 - val_loss: 0.8016 - val_accuracy: 0.7523\n","Epoch 46/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3639 - accuracy: 0.9069 - val_loss: 0.7629 - val_accuracy: 0.7783\n","Epoch 47/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3475 - accuracy: 0.9211 - val_loss: 0.7266 - val_accuracy: 0.7862\n","Epoch 48/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3472 - accuracy: 0.9196 - val_loss: 0.7454 - val_accuracy: 0.7896\n","Epoch 49/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3499 - accuracy: 0.9148 - val_loss: 0.7574 - val_accuracy: 0.7715\n","Epoch 50/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3382 - accuracy: 0.9244 - val_loss: 0.8024 - val_accuracy: 0.7330\n","Epoch 51/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3543 - accuracy: 0.9216 - val_loss: 0.7736 - val_accuracy: 0.7817\n","Epoch 52/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3523 - accuracy: 0.9131 - val_loss: 0.7827 - val_accuracy: 0.7805\n","Epoch 53/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3485 - accuracy: 0.9162 - val_loss: 0.8108 - val_accuracy: 0.7285\n","Epoch 54/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3605 - accuracy: 0.9143 - val_loss: 0.8403 - val_accuracy: 0.7636\n","Epoch 55/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3598 - accuracy: 0.9171 - val_loss: 0.7981 - val_accuracy: 0.7387\n","Epoch 56/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3420 - accuracy: 0.9154 - val_loss: 0.7332 - val_accuracy: 0.7839\n","Epoch 57/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3403 - accuracy: 0.9222 - val_loss: 0.7403 - val_accuracy: 0.7704\n","Epoch 58/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3369 - accuracy: 0.9191 - val_loss: 0.7514 - val_accuracy: 0.7738\n","Epoch 59/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3469 - accuracy: 0.9222 - val_loss: 0.8325 - val_accuracy: 0.7285\n","Epoch 60/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3333 - accuracy: 0.9247 - val_loss: 0.7420 - val_accuracy: 0.7704\n","Epoch 61/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3495 - accuracy: 0.9256 - val_loss: 0.8174 - val_accuracy: 0.7613\n","Epoch 62/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3362 - accuracy: 0.9264 - val_loss: 0.7279 - val_accuracy: 0.7828\n","Epoch 63/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3287 - accuracy: 0.9287 - val_loss: 0.7538 - val_accuracy: 0.7851\n","Epoch 64/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3255 - accuracy: 0.9278 - val_loss: 0.7477 - val_accuracy: 0.7805\n","Epoch 65/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3418 - accuracy: 0.9239 - val_loss: 0.7856 - val_accuracy: 0.7760\n","Epoch 66/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3370 - accuracy: 0.9219 - val_loss: 0.7554 - val_accuracy: 0.7704\n","Epoch 67/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3676 - accuracy: 0.9165 - val_loss: 0.8905 - val_accuracy: 0.7172\n","Epoch 68/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3250 - accuracy: 0.9358 - val_loss: 0.7632 - val_accuracy: 0.7828\n","Epoch 69/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3199 - accuracy: 0.9301 - val_loss: 0.9846 - val_accuracy: 0.6912\n","Epoch 70/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3278 - accuracy: 0.9307 - val_loss: 0.7456 - val_accuracy: 0.7704\n","Epoch 71/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.3182 - accuracy: 0.9284 - val_loss: 0.7812 - val_accuracy: 0.7692\n","Epoch 72/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3327 - accuracy: 0.9196 - val_loss: 0.8965 - val_accuracy: 0.7172\n","Epoch 73/100\n","28/28 [==============================] - 1s 21ms/step - loss: 0.3293 - accuracy: 0.9261 - val_loss: 0.7593 - val_accuracy: 0.7692\n","Epoch 74/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3314 - accuracy: 0.9267 - val_loss: 0.7941 - val_accuracy: 0.7455\n","Epoch 75/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3294 - accuracy: 0.9213 - val_loss: 0.8256 - val_accuracy: 0.7579\n","Epoch 76/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3388 - accuracy: 0.9179 - val_loss: 0.7704 - val_accuracy: 0.7726\n","Epoch 77/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3373 - accuracy: 0.9185 - val_loss: 1.1975 - val_accuracy: 0.6482\n","Epoch 78/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3298 - accuracy: 0.9219 - val_loss: 0.8071 - val_accuracy: 0.7432\n","Epoch 79/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3270 - accuracy: 0.9301 - val_loss: 0.8625 - val_accuracy: 0.7511\n","Epoch 80/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3343 - accuracy: 0.9230 - val_loss: 0.7813 - val_accuracy: 0.7692\n","Epoch 81/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3155 - accuracy: 0.9295 - val_loss: 0.7948 - val_accuracy: 0.7692\n","Epoch 82/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3301 - accuracy: 0.9213 - val_loss: 0.8611 - val_accuracy: 0.7511\n","Epoch 83/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3387 - accuracy: 0.9233 - val_loss: 0.9430 - val_accuracy: 0.7511\n","Epoch 84/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3405 - accuracy: 0.9216 - val_loss: 0.8832 - val_accuracy: 0.7217\n","Epoch 85/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3169 - accuracy: 0.9329 - val_loss: 0.8567 - val_accuracy: 0.7647\n","Epoch 86/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3053 - accuracy: 0.9344 - val_loss: 0.7810 - val_accuracy: 0.7771\n","Epoch 87/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3091 - accuracy: 0.9324 - val_loss: 0.8836 - val_accuracy: 0.7704\n","Epoch 88/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3168 - accuracy: 0.9293 - val_loss: 0.9292 - val_accuracy: 0.7624\n","Epoch 89/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3145 - accuracy: 0.9276 - val_loss: 0.8110 - val_accuracy: 0.7738\n","Epoch 90/100\n","28/28 [==============================] - 0s 17ms/step - loss: 0.3189 - accuracy: 0.9332 - val_loss: 0.8155 - val_accuracy: 0.7568\n","Epoch 91/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3063 - accuracy: 0.9352 - val_loss: 0.7876 - val_accuracy: 0.7726\n","Epoch 92/100\n","28/28 [==============================] - 0s 15ms/step - loss: 0.3082 - accuracy: 0.9346 - val_loss: 0.7874 - val_accuracy: 0.7715\n","Epoch 93/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3068 - accuracy: 0.9369 - val_loss: 0.9055 - val_accuracy: 0.7658\n","Epoch 94/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.3205 - accuracy: 0.9315 - val_loss: 0.8829 - val_accuracy: 0.7692\n","Epoch 95/100\n","28/28 [==============================] - 0s 16ms/step - loss: 0.2957 - accuracy: 0.9403 - val_loss: 0.7916 - val_accuracy: 0.7726\n","Epoch 96/100\n","28/28 [==============================] - 1s 18ms/step - loss: 0.3098 - accuracy: 0.9355 - val_loss: 0.8588 - val_accuracy: 0.7760\n","Epoch 97/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3076 - accuracy: 0.9366 - val_loss: 0.9599 - val_accuracy: 0.7093\n","Epoch 98/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3073 - accuracy: 0.9346 - val_loss: 0.7957 - val_accuracy: 0.7670\n","Epoch 99/100\n","28/28 [==============================] - 1s 19ms/step - loss: 0.2980 - accuracy: 0.9386 - val_loss: 0.8251 - val_accuracy: 0.7466\n","Epoch 100/100\n","28/28 [==============================] - 1s 20ms/step - loss: 0.3017 - accuracy: 0.9417 - val_loss: 0.9308 - val_accuracy: 0.7251\n","{'loss': [0.4416123628616333, 0.4268698990345001, 0.43076395988464355, 0.4131666123867035, 0.42019227147102356, 0.40611910820007324, 0.4092639088630676, 0.39957913756370544, 0.3970046639442444, 0.4013963043689728, 0.4117128252983093, 0.39958709478378296, 0.4109342396259308, 0.40182599425315857, 0.39267805218696594, 0.38807979226112366, 0.3827902674674988, 0.3779987692832947, 0.3896351754665375, 0.3777152895927429, 0.3764359652996063, 0.36667171120643616, 0.3717467486858368, 0.3913295865058899, 0.40220263600349426, 0.3941105604171753, 0.38376912474632263, 0.3744426369667053, 0.3684525191783905, 0.37496745586395264, 0.37141653895378113, 0.3734114170074463, 0.3583254814147949, 0.37552934885025024, 0.3573380410671234, 0.35361722111701965, 0.3689596652984619, 0.3495904803276062, 0.35225534439086914, 0.35716137290000916, 0.3559068441390991, 0.3454675078392029, 0.35308927297592163, 0.3446404039859772, 0.337324857711792, 0.36394521594047546, 0.3475405275821686, 0.347181499004364, 0.349895179271698, 0.33824723958969116, 0.3543461859226227, 0.35229745507240295, 0.34845060110092163, 0.3605411648750305, 0.35982459783554077, 0.34197941422462463, 0.34028470516204834, 0.33690145611763, 0.34690266847610474, 0.33334439992904663, 0.3494890630245209, 0.3362460136413574, 0.3286746144294739, 0.3254612982273102, 0.34182944893836975, 0.3370126783847809, 0.36759713292121887, 0.32501962780952454, 0.3198922276496887, 0.3277646005153656, 0.318172425031662, 0.33268988132476807, 0.32928335666656494, 0.33135858178138733, 0.329369455575943, 0.3388376235961914, 0.3373165428638458, 0.3297690451145172, 0.3269786536693573, 0.33434757590293884, 0.31547293066978455, 0.3300740122795105, 0.33870336413383484, 0.34047597646713257, 0.31685671210289, 0.30533725023269653, 0.309084415435791, 0.31675848364830017, 0.3144703209400177, 0.3189067542552948, 0.30628737807273865, 0.3081660568714142, 0.30682000517845154, 0.3204619586467743, 0.2957160472869873, 0.30981960892677307, 0.30762651562690735, 0.30726101994514465, 0.29798009991645813, 0.30170679092407227], 'accuracy': [0.8749292492866516, 0.8808715343475342, 0.8859649300575256, 0.8899264335632324, 0.8856819272041321, 0.8970005512237549, 0.8916242122650146, 0.8910582661628723, 0.8947368264198303, 0.8933219909667969, 0.8859649300575256, 0.8944538831710815, 0.8907753229141235, 0.8992642760276794, 0.8944538831710815, 0.9020939469337463, 0.8989813327789307, 0.9071873426437378, 0.8981324434280396, 0.9060554504394531, 0.9077532291412354, 0.912563681602478, 0.9100169539451599, 0.897849440574646, 0.8972835540771484, 0.897849440574646, 0.8998302221298218, 0.9105829000473022, 0.9083191752433777, 0.9057725071907043, 0.9043576717376709, 0.9032257795333862, 0.9091680645942688, 0.9066213965415955, 0.9153932929039001, 0.9187889099121094, 0.9060554504394531, 0.9187889099121094, 0.9148274064064026, 0.9176570177078247, 0.9128466248512268, 0.9190718531608582, 0.9111488461494446, 0.9224674701690674, 0.9216185808181763, 0.9069043397903442, 0.9210526347160339, 0.9196377992630005, 0.9148274064064026, 0.9244481921195984, 0.9216185808181763, 0.9131296277046204, 0.916242241859436, 0.9142614603042603, 0.9170911312103271, 0.9153932929039001, 0.9221844673156738, 0.9190718531608582, 0.9221844673156738, 0.9247311949729919, 0.9255800843238831, 0.9264289736747742, 0.9286926984786987, 0.9278438091278076, 0.9238823056221008, 0.921901524066925, 0.9165251851081848, 0.9357668161392212, 0.9301075339317322, 0.9306734800338745, 0.92840975522995, 0.9196377992630005, 0.9261460304260254, 0.926711916923523, 0.9213355779647827, 0.9179400205612183, 0.9185059666633606, 0.921901524066925, 0.9301075339317322, 0.9230334162712097, 0.9295415878295898, 0.9213355779647827, 0.9233163595199585, 0.9216185808181763, 0.9329372048377991, 0.9343519806861877, 0.9323712587356567, 0.9292586445808411, 0.9275608658790588, 0.9332201480865479, 0.9352009296417236, 0.9346349835395813, 0.9368987083435059, 0.9315223693847656, 0.9402942657470703, 0.9354838728904724, 0.9366157054901123, 0.9346349835395813, 0.9385964870452881, 0.9417091012001038], 'val_loss': [0.8831400871276855, 0.8244993686676025, 0.827691376209259, 0.8254873156547546, 0.8120105266571045, 0.8044277429580688, 0.8559845685958862, 0.8069356083869934, 0.84092116355896, 0.7855489253997803, 0.7726773023605347, 0.7491269111633301, 0.718895435333252, 0.7302889823913574, 0.701484739780426, 0.712291955947876, 0.6566317677497864, 0.6832705736160278, 0.6512824892997742, 0.6418089866638184, 0.6548923254013062, 0.715972363948822, 0.6416337490081787, 0.6915849447250366, 0.7001900672912598, 0.6690396070480347, 0.6764015555381775, 0.7035129070281982, 0.6725755333900452, 0.6766247749328613, 0.7346586585044861, 0.7063850164413452, 0.6720063090324402, 0.7027825117111206, 0.6961846947669983, 0.7230209708213806, 0.7251393795013428, 0.761107861995697, 0.7330211400985718, 0.7957727313041687, 0.7306485176086426, 0.6985733509063721, 0.7530280351638794, 0.7204519510269165, 0.8016431927680969, 0.7628501057624817, 0.7265809774398804, 0.745448112487793, 0.7573500871658325, 0.8023636937141418, 0.7735790610313416, 0.782707691192627, 0.8108342289924622, 0.8402848243713379, 0.7981362342834473, 0.7331880331039429, 0.7402923703193665, 0.7514318227767944, 0.832452654838562, 0.742006242275238, 0.8174249529838562, 0.7278832197189331, 0.7537894248962402, 0.7477080225944519, 0.7856020927429199, 0.7553854584693909, 0.8904732465744019, 0.7631568312644958, 0.9846305251121521, 0.7456112504005432, 0.781185507774353, 0.8964595198631287, 0.7593252062797546, 0.7940952777862549, 0.8255659341812134, 0.7703771591186523, 1.1974736452102661, 0.8071269989013672, 0.862508237361908, 0.7812575101852417, 0.7948204278945923, 0.8611060380935669, 0.943006694316864, 0.883231520652771, 0.8566566109657288, 0.7809797525405884, 0.883639395236969, 0.9291732311248779, 0.8109679818153381, 0.815484881401062, 0.7876163721084595, 0.7873764634132385, 0.9055227041244507, 0.8829495310783386, 0.7915989756584167, 0.8588327169418335, 0.9599073529243469, 0.7957115769386292, 0.8250611424446106, 0.9308465719223022], 'val_accuracy': [0.516968309879303, 0.6233031749725342, 0.6063348650932312, 0.6334841847419739, 0.598416268825531, 0.6323529481887817, 0.5565611124038696, 0.6233031749725342, 0.570135772228241, 0.6040723919868469, 0.627828061580658, 0.6877828240394592, 0.6662895679473877, 0.7047511339187622, 0.7228506803512573, 0.7070135474205017, 0.7466063499450684, 0.7511312365531921, 0.7579185366630554, 0.766968309879303, 0.7703620195388794, 0.7307692170143127, 0.7726244330406189, 0.7522624731063843, 0.7590497732162476, 0.7658371329307556, 0.766968309879303, 0.7873303294181824, 0.7850678563117981, 0.779411792755127, 0.7409502267837524, 0.7748869061470032, 0.7895927429199219, 0.7816742062568665, 0.7782805562019348, 0.7748869061470032, 0.7488687634468079, 0.7432126402854919, 0.7533936500549316, 0.7522624731063843, 0.7601810097694397, 0.7861990928649902, 0.75, 0.7895927429199219, 0.7522624731063843, 0.7782805562019348, 0.7861990928649902, 0.7895927429199219, 0.7714931964874268, 0.733031690120697, 0.7816742062568665, 0.7805429697036743, 0.7285068035125732, 0.7635746598243713, 0.7386877536773682, 0.7839366793632507, 0.7703620195388794, 0.773755669593811, 0.7285068035125732, 0.7703620195388794, 0.7613122463226318, 0.7828054428100586, 0.7850678563117981, 0.7805429697036743, 0.7760180830955505, 0.7703620195388794, 0.7171945571899414, 0.7828054428100586, 0.6911764740943909, 0.7703620195388794, 0.7692307829856873, 0.7171945571899414, 0.7692307829856873, 0.7454751133918762, 0.7579185366630554, 0.7726244330406189, 0.6481900215148926, 0.7432126402854919, 0.7511312365531921, 0.7692307829856873, 0.7692307829856873, 0.7511312365531921, 0.7511312365531921, 0.7217194437980652, 0.7647058963775635, 0.7771493196487427, 0.7703620195388794, 0.7624434232711792, 0.773755669593811, 0.7567873597145081, 0.7726244330406189, 0.7714931964874268, 0.7658371329307556, 0.7692307829856873, 0.7726244330406189, 0.7760180830955505, 0.709276020526886, 0.766968309879303, 0.7466063499450684, 0.7251130938529968]}\n","45/45 [==============================] - 1s 4ms/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 37, 256)           22528     \n","                                                                 \n"," batch_normalization (Batch  (None, 37, 256)           1024      \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 19, 256)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           196864    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 10, 256)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 10, 512)           393728    \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 5, 512)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 3, 1024)           1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 3, 1024)           0         \n","                                                                 \n"," gru (GRU)                   (None, 3, 256)            984576    \n","                                                                 \n"," gru_1 (GRU)                 (None, 3, 256)            394752    \n","                                                                 \n"," flatten (Flatten)           (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               393728    \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                8224      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 4100673 (15.64 MB)\n","Trainable params: 4100161 (15.64 MB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","30/31 [============================>.] - ETA: 0s - loss: 0.4419 - accuracy: 0.8760"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/31 [==============================] - 11s 61ms/step - loss: 0.4427 - accuracy: 0.8755 - val_loss: 0.8237 - val_accuracy: 0.6054\n","Epoch 2/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4530 - accuracy: 0.8721 - val_loss: 0.8326 - val_accuracy: 0.5981\n","Epoch 3/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4308 - accuracy: 0.8835 - val_loss: 0.8330 - val_accuracy: 0.5579\n","Epoch 4/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4193 - accuracy: 0.8899 - val_loss: 0.8262 - val_accuracy: 0.5775\n","Epoch 5/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4094 - accuracy: 0.8969 - val_loss: 0.8147 - val_accuracy: 0.6023\n","Epoch 6/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.4070 - accuracy: 0.8933 - val_loss: 0.8100 - val_accuracy: 0.5971\n","Epoch 7/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4117 - accuracy: 0.8922 - val_loss: 0.7894 - val_accuracy: 0.6539\n","Epoch 8/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4047 - accuracy: 0.8928 - val_loss: 0.8359 - val_accuracy: 0.5826\n","Epoch 9/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4097 - accuracy: 0.8873 - val_loss: 0.8417 - val_accuracy: 0.5857\n","Epoch 10/100\n","31/31 [==============================] - 1s 24ms/step - loss: 0.4234 - accuracy: 0.8855 - val_loss: 0.7553 - val_accuracy: 0.6715\n","Epoch 11/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4094 - accuracy: 0.8881 - val_loss: 0.8987 - val_accuracy: 0.5816\n","Epoch 12/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4032 - accuracy: 0.8961 - val_loss: 0.7521 - val_accuracy: 0.6901\n","Epoch 13/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4027 - accuracy: 0.8904 - val_loss: 0.7649 - val_accuracy: 0.6694\n","Epoch 14/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.4122 - accuracy: 0.8899 - val_loss: 0.7745 - val_accuracy: 0.6798\n","Epoch 15/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4065 - accuracy: 0.8902 - val_loss: 0.7358 - val_accuracy: 0.6942\n","Epoch 16/100\n","31/31 [==============================] - 1s 23ms/step - loss: 0.4033 - accuracy: 0.9000 - val_loss: 0.7455 - val_accuracy: 0.7107\n","Epoch 17/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.4173 - accuracy: 0.8912 - val_loss: 0.7280 - val_accuracy: 0.7045\n","Epoch 18/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4081 - accuracy: 0.8928 - val_loss: 0.7579 - val_accuracy: 0.6756\n","Epoch 19/100\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4009 - accuracy: 0.8959 - val_loss: 0.6940 - val_accuracy: 0.7510\n","Epoch 20/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3977 - accuracy: 0.9000 - val_loss: 0.6995 - val_accuracy: 0.7459\n","Epoch 21/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.4026 - accuracy: 0.8953 - val_loss: 0.7496 - val_accuracy: 0.7262\n","Epoch 22/100\n","31/31 [==============================] - 1s 29ms/step - loss: 0.3862 - accuracy: 0.9070 - val_loss: 0.7212 - val_accuracy: 0.7521\n","Epoch 23/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3969 - accuracy: 0.8969 - val_loss: 0.7824 - val_accuracy: 0.7273\n","Epoch 24/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3893 - accuracy: 0.9052 - val_loss: 0.7532 - val_accuracy: 0.7583\n","Epoch 25/100\n","31/31 [==============================] - 1s 25ms/step - loss: 0.3843 - accuracy: 0.9080 - val_loss: 0.7691 - val_accuracy: 0.7686\n","Epoch 26/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3750 - accuracy: 0.9114 - val_loss: 0.7817 - val_accuracy: 0.7593\n","Epoch 27/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3853 - accuracy: 0.8990 - val_loss: 0.8762 - val_accuracy: 0.7324\n","Epoch 28/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3813 - accuracy: 0.9065 - val_loss: 0.7792 - val_accuracy: 0.7593\n","Epoch 29/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3939 - accuracy: 0.9003 - val_loss: 0.8206 - val_accuracy: 0.7448\n","Epoch 30/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3921 - accuracy: 0.9008 - val_loss: 0.8165 - val_accuracy: 0.7469\n","Epoch 31/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3751 - accuracy: 0.9072 - val_loss: 0.8026 - val_accuracy: 0.7634\n","Epoch 32/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3772 - accuracy: 0.9062 - val_loss: 0.8116 - val_accuracy: 0.7469\n","Epoch 33/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3696 - accuracy: 0.9067 - val_loss: 0.8140 - val_accuracy: 0.7593\n","Epoch 34/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3786 - accuracy: 0.9013 - val_loss: 0.8992 - val_accuracy: 0.6932\n","Epoch 35/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3722 - accuracy: 0.9080 - val_loss: 0.8876 - val_accuracy: 0.7159\n","Epoch 36/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3684 - accuracy: 0.9106 - val_loss: 0.8359 - val_accuracy: 0.7552\n","Epoch 37/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3890 - accuracy: 0.8966 - val_loss: 0.8496 - val_accuracy: 0.7572\n","Epoch 38/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3695 - accuracy: 0.9119 - val_loss: 0.9907 - val_accuracy: 0.6777\n","Epoch 39/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3673 - accuracy: 0.9119 - val_loss: 0.9026 - val_accuracy: 0.7459\n","Epoch 40/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.4063 - accuracy: 0.8925 - val_loss: 0.8347 - val_accuracy: 0.7490\n","Epoch 41/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3740 - accuracy: 0.9088 - val_loss: 0.8442 - val_accuracy: 0.7541\n","Epoch 42/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3698 - accuracy: 0.9119 - val_loss: 0.8471 - val_accuracy: 0.7552\n","Epoch 43/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3901 - accuracy: 0.8979 - val_loss: 0.8793 - val_accuracy: 0.7572\n","Epoch 44/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3678 - accuracy: 0.9121 - val_loss: 0.8348 - val_accuracy: 0.7583\n","Epoch 45/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3747 - accuracy: 0.9080 - val_loss: 0.8726 - val_accuracy: 0.7231\n","Epoch 46/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3608 - accuracy: 0.9083 - val_loss: 0.9437 - val_accuracy: 0.6901\n","Epoch 47/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3518 - accuracy: 0.9173 - val_loss: 0.9314 - val_accuracy: 0.7076\n","Epoch 48/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3916 - accuracy: 0.8979 - val_loss: 0.8670 - val_accuracy: 0.7572\n","Epoch 49/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3592 - accuracy: 0.9098 - val_loss: 0.8525 - val_accuracy: 0.7459\n","Epoch 50/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3525 - accuracy: 0.9191 - val_loss: 0.8699 - val_accuracy: 0.7552\n","Epoch 51/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3609 - accuracy: 0.9165 - val_loss: 0.9664 - val_accuracy: 0.7366\n","Epoch 52/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3606 - accuracy: 0.9145 - val_loss: 0.9813 - val_accuracy: 0.6839\n","Epoch 53/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3603 - accuracy: 0.9142 - val_loss: 0.8709 - val_accuracy: 0.7510\n","Epoch 54/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3557 - accuracy: 0.9106 - val_loss: 0.9397 - val_accuracy: 0.7190\n","Epoch 55/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3526 - accuracy: 0.9199 - val_loss: 0.8786 - val_accuracy: 0.7562\n","Epoch 56/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3420 - accuracy: 0.9251 - val_loss: 0.9412 - val_accuracy: 0.7273\n","Epoch 57/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3525 - accuracy: 0.9114 - val_loss: 0.8918 - val_accuracy: 0.7448\n","Epoch 58/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3420 - accuracy: 0.9207 - val_loss: 0.9137 - val_accuracy: 0.7376\n","Epoch 59/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3438 - accuracy: 0.9220 - val_loss: 0.8916 - val_accuracy: 0.7572\n","Epoch 60/100\n","31/31 [==============================] - 1s 16ms/step - loss: 0.3458 - accuracy: 0.9178 - val_loss: 0.9470 - val_accuracy: 0.7056\n","Epoch 61/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3372 - accuracy: 0.9194 - val_loss: 0.8734 - val_accuracy: 0.7469\n","Epoch 62/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3411 - accuracy: 0.9230 - val_loss: 1.0012 - val_accuracy: 0.7242\n","Epoch 63/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3384 - accuracy: 0.9217 - val_loss: 0.8794 - val_accuracy: 0.7438\n","Epoch 64/100\n","31/31 [==============================] - 1s 17ms/step - loss: 0.3336 - accuracy: 0.9222 - val_loss: 0.9188 - val_accuracy: 0.7231\n","Epoch 65/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3346 - accuracy: 0.9276 - val_loss: 0.8946 - val_accuracy: 0.7438\n","Epoch 66/100\n","31/31 [==============================] - 0s 16ms/step - loss: 0.3412 - accuracy: 0.9253 - val_loss: 0.9098 - val_accuracy: 0.7335\n","Epoch 67/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3443 - accuracy: 0.9220 - val_loss: 0.9640 - val_accuracy: 0.7510\n","Epoch 68/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3355 - accuracy: 0.9276 - val_loss: 0.9879 - val_accuracy: 0.7304\n","Epoch 69/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3389 - accuracy: 0.9238 - val_loss: 1.0080 - val_accuracy: 0.7159\n","Epoch 70/100\n","31/31 [==============================] - 0s 15ms/step - loss: 0.3338 - accuracy: 0.9245 - val_loss: 0.9324 - val_accuracy: 0.7242\n","Epoch 71/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3408 - accuracy: 0.9233 - val_loss: 1.0166 - val_accuracy: 0.7386\n","Epoch 72/100\n","31/31 [==============================] - 1s 20ms/step - loss: 0.3241 - accuracy: 0.9269 - val_loss: 0.9347 - val_accuracy: 0.7428\n","Epoch 73/100\n","31/31 [==============================] - 1s 18ms/step - loss: 0.3330 - accuracy: 0.9183 - val_loss: 0.9430 - val_accuracy: 0.7448\n","Epoch 74/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3257 - accuracy: 0.9305 - val_loss: 0.9583 - val_accuracy: 0.7417\n","Epoch 75/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3330 - accuracy: 0.9207 - val_loss: 1.0049 - val_accuracy: 0.7335\n","Epoch 76/100\n","31/31 [==============================] - 1s 22ms/step - loss: 0.3332 - accuracy: 0.9271 - val_loss: 1.1001 - val_accuracy: 0.7221\n","Epoch 77/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3436 - accuracy: 0.9207 - val_loss: 0.9415 - val_accuracy: 0.7293\n","Epoch 78/100\n","31/31 [==============================] - 1s 19ms/step - loss: 0.3351 - accuracy: 0.9233 - val_loss: 0.9603 - val_accuracy: 0.7438\n","Epoch 79/100\n"," 1/31 [..............................] - ETA: 0s - loss: 0.3401 - accuracy: 0.9297"]}]},{"cell_type":"code","source":["metrics_df_gru"],"metadata":{"collapsed":true,"id":"kleLoWSV5B7Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metrics_df_gru.round(4).to_csv('/content/drive/MyDrive/EEG Signal /results/FLresults/TF Domain/GRU/Theta_tf_GRU.csv', index = False)"],"metadata":{"id":"QWSx6aHR5Bwr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('hello')"],"metadata":{"id":"JOIXJgmr5vGB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717508047644,"user_tz":-360,"elapsed":399,"user":{"displayName":"FAZLA RABBY RAIHAN","userId":"17152406706401381757"}},"outputId":"ad9d9dbb-d909-40af-8c6c-dbf84b2b0e48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["hello\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"VpaPQDa2dP9h"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}